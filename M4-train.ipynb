{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2    False\n",
      "dtype: bool\n",
      "all training set length:  48000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import progressive_blocks\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "training_set = pd.read_csv('./Datasets/M4-Dataset/Train/Monthly-train.csv')\n",
    "\n",
    "training_set = training_set.iloc[:,1:2] #electricity values in time\n",
    "any_missing = training_set.isnull().any()\n",
    "print(any_missing)\n",
    "print(\"all training set length: \",len(training_set))\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "training_set = sc.fit_transform(training_set)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 1)\n"
     ]
    }
   ],
   "source": [
    "train_set=training_set[:42500]\n",
    "print(train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('hour')\n",
    "plt.ylabel('value')\n",
    "plt.plot(training_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set = pd.read_csv('./Datasets/M4-Dataset/Test/Monthly-test.csv')\n",
    "\n",
    "test_set = test_set.iloc[:,1:2].values\n",
    "sc = MinMaxScaler()\n",
    "test_set = sc.fit_transform(test_set)\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('value')\n",
    "plt.plot(test_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41987, 512, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seq_length = 512 #it is tau in the paper\n",
    "x, y = utils.sliding_windows(train_set, seq_length)\n",
    "trainX=torch.Tensor(np.array(x))\n",
    "print(trainX.shape)\n",
    "batch_size=trainX.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "torch.Size([41987, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "sequences=utils.real_seq(training_set,seq_length)\n",
    "sequences=sequences[:41987]\n",
    "print(sequences.dtype)\n",
    "sequences=torch.Tensor(sequences)\n",
    "sequences.unsqueeze(0).unsqueeze(1)\n",
    "sequences=sequences.permute(0,2,1)\n",
    "print(sequences.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *TRAIN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_loss(fake_data, real_data):\n",
    "    fake_mean = fake_data.mean()\n",
    "    real_mean = real_data.mean()\n",
    "    fake_std = fake_data.std()\n",
    "    real_std = real_data.std()\n",
    "    return abs(fake_mean - real_mean) + abs(fake_std - real_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new models directory is created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path=\"Models/M4\"\n",
    "utils.create_folder(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda enabled: using GPU\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 1/347] [D loss: 0.946291] [G loss: 1.284566]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 2/347] [D loss: 0.901853] [G loss: 1.216780]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 3/347] [D loss: 0.898354] [G loss: 1.206042]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 4/347] [D loss: 0.896533] [G loss: 1.195593]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 5/347] [D loss: 0.895009] [G loss: 1.186763]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 6/347] [D loss: 0.893503] [G loss: 1.182574]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 7/347] [D loss: 0.892073] [G loss: 1.172734]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 8/347] [D loss: 0.890676] [G loss: 1.163751]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 9/347] [D loss: 0.889301] [G loss: 1.148946]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 10/347] [D loss: 0.887930] [G loss: 1.145422]\n",
      "[Epoch 1/100] [Batch 11/347] [D loss: 0.886563] [G loss: 1.155373]\n",
      "[Epoch 1/100] [Batch 12/347] [D loss: 0.885217] [G loss: 1.155872]\n",
      "[Epoch 1/100] [Batch 13/347] [D loss: 0.883867] [G loss: 1.155797]\n",
      "[Epoch 1/100] [Batch 14/347] [D loss: 0.882525] [G loss: 1.154032]\n",
      "[Epoch 1/100] [Batch 15/347] [D loss: 0.881183] [G loss: 1.146252]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 16/347] [D loss: 0.879843] [G loss: 1.138510]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 17/347] [D loss: 0.878529] [G loss: 1.123154]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 18/347] [D loss: 0.877196] [G loss: 1.112504]\n",
      "[Epoch 1/100] [Batch 19/347] [D loss: 0.875896] [G loss: 1.121913]\n",
      "[Epoch 1/100] [Batch 20/347] [D loss: 0.874576] [G loss: 1.131891]\n",
      "[Epoch 1/100] [Batch 21/347] [D loss: 0.873283] [G loss: 1.125108]\n",
      "[Epoch 1/100] [Batch 22/347] [D loss: 0.871974] [G loss: 1.117247]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 23/347] [D loss: 0.870675] [G loss: 1.108215]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 24/347] [D loss: 0.869395] [G loss: 1.104749]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 25/347] [D loss: 0.868085] [G loss: 1.101705]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 26/347] [D loss: 0.866806] [G loss: 1.084824]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 27/347] [D loss: 0.865552] [G loss: 1.076524]\n",
      "[Epoch 1/100] [Batch 28/347] [D loss: 0.864295] [G loss: 1.085623]\n",
      "[Epoch 1/100] [Batch 29/347] [D loss: 0.863026] [G loss: 1.102151]\n",
      "[Epoch 1/100] [Batch 30/347] [D loss: 0.861768] [G loss: 1.106498]\n",
      "[Epoch 1/100] [Batch 31/347] [D loss: 0.860521] [G loss: 1.106529]\n",
      "[Epoch 1/100] [Batch 32/347] [D loss: 0.859291] [G loss: 1.097319]\n",
      "[Epoch 1/100] [Batch 33/347] [D loss: 0.858057] [G loss: 1.090914]\n",
      "[Epoch 1/100] [Batch 34/347] [D loss: 0.856833] [G loss: 1.089814]\n",
      "[Epoch 1/100] [Batch 35/347] [D loss: 0.855607] [G loss: 1.086528]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 36/347] [D loss: 0.854374] [G loss: 1.075410]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 37/347] [D loss: 0.853160] [G loss: 1.047576]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 38/347] [D loss: 0.851929] [G loss: 1.030244]\n",
      "[Epoch 1/100] [Batch 39/347] [D loss: 0.850744] [G loss: 1.037565]\n",
      "[Epoch 1/100] [Batch 40/347] [D loss: 0.849531] [G loss: 1.042990]\n",
      "[Epoch 1/100] [Batch 41/347] [D loss: 0.848357] [G loss: 1.037744]\n",
      "[Epoch 1/100] [Batch 42/347] [D loss: 0.847163] [G loss: 1.038262]\n",
      "[Epoch 1/100] [Batch 43/347] [D loss: 0.845971] [G loss: 1.047800]\n",
      "[Epoch 1/100] [Batch 44/347] [D loss: 0.844792] [G loss: 1.063098]\n",
      "[Epoch 1/100] [Batch 45/347] [D loss: 0.843631] [G loss: 1.077267]\n",
      "[Epoch 1/100] [Batch 46/347] [D loss: 0.842466] [G loss: 1.068912]\n",
      "[Epoch 1/100] [Batch 47/347] [D loss: 0.841314] [G loss: 1.037112]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 48/347] [D loss: 0.840158] [G loss: 1.001736]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 49/347] [D loss: 0.838996] [G loss: 0.990217]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 50/347] [D loss: 0.837841] [G loss: 0.971645]\n",
      "[Epoch 1/100] [Batch 51/347] [D loss: 0.836705] [G loss: 0.983979]\n",
      "[Epoch 1/100] [Batch 52/347] [D loss: 0.835569] [G loss: 1.027473]\n",
      "[Epoch 1/100] [Batch 53/347] [D loss: 0.834442] [G loss: 1.014847]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 54/347] [D loss: 0.833314] [G loss: 0.958667]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 55/347] [D loss: 0.832181] [G loss: 0.932715]\n",
      "[Epoch 1/100] [Batch 56/347] [D loss: 0.831075] [G loss: 0.942350]\n",
      "[Epoch 1/100] [Batch 57/347] [D loss: 0.829962] [G loss: 0.973351]\n",
      "[Epoch 1/100] [Batch 58/347] [D loss: 0.828838] [G loss: 1.002101]\n",
      "[Epoch 1/100] [Batch 59/347] [D loss: 0.827752] [G loss: 0.983525]\n",
      "[Epoch 1/100] [Batch 60/347] [D loss: 0.826649] [G loss: 0.960881]\n",
      "[Epoch 1/100] [Batch 61/347] [D loss: 0.825548] [G loss: 0.944391]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 62/347] [D loss: 0.824468] [G loss: 0.916442]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 63/347] [D loss: 0.823379] [G loss: 0.910653]\n",
      "[Epoch 1/100] [Batch 64/347] [D loss: 0.822291] [G loss: 0.944007]\n",
      "[Epoch 1/100] [Batch 65/347] [D loss: 0.821206] [G loss: 0.992016]\n",
      "[Epoch 1/100] [Batch 66/347] [D loss: 0.820139] [G loss: 0.976443]\n",
      "[Epoch 1/100] [Batch 67/347] [D loss: 0.819067] [G loss: 0.949036]\n",
      "[Epoch 1/100] [Batch 68/347] [D loss: 0.818016] [G loss: 0.927220]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 69/347] [D loss: 0.816949] [G loss: 0.904454]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 70/347] [D loss: 0.815896] [G loss: 0.902116]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 71/347] [D loss: 0.814842] [G loss: 0.896306]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 72/347] [D loss: 0.813775] [G loss: 0.890113]\n",
      "[Epoch 1/100] [Batch 73/347] [D loss: 0.812732] [G loss: 0.911102]\n",
      "[Epoch 1/100] [Batch 74/347] [D loss: 0.811684] [G loss: 0.921209]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 75/347] [D loss: 0.810649] [G loss: 0.887123]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 76/347] [D loss: 0.809617] [G loss: 0.880956]\n",
      "[Epoch 1/100] [Batch 77/347] [D loss: 0.808579] [G loss: 0.911217]\n",
      "[Epoch 1/100] [Batch 78/347] [D loss: 0.807563] [G loss: 0.941455]\n",
      "[Epoch 1/100] [Batch 79/347] [D loss: 0.806517] [G loss: 0.949339]\n",
      "[Epoch 1/100] [Batch 80/347] [D loss: 0.805493] [G loss: 0.943136]\n",
      "[Epoch 1/100] [Batch 81/347] [D loss: 0.804475] [G loss: 0.944517]\n",
      "[Epoch 1/100] [Batch 82/347] [D loss: 0.803476] [G loss: 0.934715]\n",
      "[Epoch 1/100] [Batch 83/347] [D loss: 0.802450] [G loss: 0.930256]\n",
      "[Epoch 1/100] [Batch 84/347] [D loss: 0.801450] [G loss: 0.939111]\n",
      "[Epoch 1/100] [Batch 85/347] [D loss: 0.800447] [G loss: 0.937266]\n",
      "[Epoch 1/100] [Batch 86/347] [D loss: 0.799451] [G loss: 0.929195]\n",
      "[Epoch 1/100] [Batch 87/347] [D loss: 0.798462] [G loss: 0.924726]\n",
      "[Epoch 1/100] [Batch 88/347] [D loss: 0.797456] [G loss: 0.925895]\n",
      "[Epoch 1/100] [Batch 89/347] [D loss: 0.796467] [G loss: 0.927192]\n",
      "[Epoch 1/100] [Batch 90/347] [D loss: 0.795466] [G loss: 0.921400]\n",
      "[Epoch 1/100] [Batch 91/347] [D loss: 0.794482] [G loss: 0.918051]\n",
      "[Epoch 1/100] [Batch 92/347] [D loss: 0.793499] [G loss: 0.917696]\n",
      "[Epoch 1/100] [Batch 93/347] [D loss: 0.792521] [G loss: 0.913915]\n",
      "[Epoch 1/100] [Batch 94/347] [D loss: 0.791537] [G loss: 0.908670]\n",
      "[Epoch 1/100] [Batch 95/347] [D loss: 0.790555] [G loss: 0.907598]\n",
      "[Epoch 1/100] [Batch 96/347] [D loss: 0.789589] [G loss: 0.901331]\n",
      "[Epoch 1/100] [Batch 97/347] [D loss: 0.788632] [G loss: 0.894712]\n",
      "[Epoch 1/100] [Batch 98/347] [D loss: 0.787675] [G loss: 0.898170]\n",
      "[Epoch 1/100] [Batch 99/347] [D loss: 0.786698] [G loss: 0.900496]\n",
      "[Epoch 1/100] [Batch 100/347] [D loss: 0.785735] [G loss: 0.895457]\n",
      "[Epoch 1/100] [Batch 101/347] [D loss: 0.784788] [G loss: 0.888878]\n",
      "[Epoch 1/100] [Batch 102/347] [D loss: 0.783811] [G loss: 0.889027]\n",
      "[Epoch 1/100] [Batch 103/347] [D loss: 0.782868] [G loss: 0.888308]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 104/347] [D loss: 0.781925] [G loss: 0.878007]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 105/347] [D loss: 0.780972] [G loss: 0.875794]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 106/347] [D loss: 0.780037] [G loss: 0.873288]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 107/347] [D loss: 0.779096] [G loss: 0.860606]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 108/347] [D loss: 0.778165] [G loss: 0.840939]\n",
      "[Epoch 1/100] [Batch 109/347] [D loss: 0.777229] [G loss: 0.844905]\n",
      "[Epoch 1/100] [Batch 110/347] [D loss: 0.776282] [G loss: 0.865500]\n",
      "[Epoch 1/100] [Batch 111/347] [D loss: 0.775349] [G loss: 0.844848]\n",
      "[Epoch 1/100] [Batch 112/347] [D loss: 0.774443] [G loss: 0.843424]\n",
      "[Epoch 1/100] [Batch 113/347] [D loss: 0.773510] [G loss: 0.872436]\n",
      "[Epoch 1/100] [Batch 114/347] [D loss: 0.772582] [G loss: 0.890433]\n",
      "[Epoch 1/100] [Batch 115/347] [D loss: 0.771662] [G loss: 0.889099]\n",
      "[Epoch 1/100] [Batch 116/347] [D loss: 0.770740] [G loss: 0.880933]\n",
      "[Epoch 1/100] [Batch 117/347] [D loss: 0.769845] [G loss: 0.851929]\n",
      "[Epoch 1/100] [Batch 118/347] [D loss: 0.768927] [G loss: 0.841045]\n",
      "[Epoch 1/100] [Batch 119/347] [D loss: 0.768015] [G loss: 0.846655]\n",
      "[Epoch 1/100] [Batch 120/347] [D loss: 0.767107] [G loss: 0.841170]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 121/347] [D loss: 0.766221] [G loss: 0.840054]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 122/347] [D loss: 0.765300] [G loss: 0.838964]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 123/347] [D loss: 0.764415] [G loss: 0.836570]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 124/347] [D loss: 0.763522] [G loss: 0.835942]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 125/347] [D loss: 0.762635] [G loss: 0.835368]\n",
      "[Epoch 1/100] [Batch 126/347] [D loss: 0.761749] [G loss: 0.846404]\n",
      "[Epoch 1/100] [Batch 127/347] [D loss: 0.760868] [G loss: 0.846196]\n",
      "[Epoch 1/100] [Batch 128/347] [D loss: 0.759988] [G loss: 0.839161]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 129/347] [D loss: 0.759122] [G loss: 0.832736]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 130/347] [D loss: 0.758257] [G loss: 0.823277]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 131/347] [D loss: 0.757378] [G loss: 0.808803]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 132/347] [D loss: 0.756524] [G loss: 0.806593]\n",
      "[Epoch 1/100] [Batch 133/347] [D loss: 0.755671] [G loss: 0.807808]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 134/347] [D loss: 0.754803] [G loss: 0.805711]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 135/347] [D loss: 0.753950] [G loss: 0.795717]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 136/347] [D loss: 0.753099] [G loss: 0.788172]\n",
      "[Epoch 1/100] [Batch 137/347] [D loss: 0.752259] [G loss: 0.808551]\n",
      "[Epoch 1/100] [Batch 138/347] [D loss: 0.751406] [G loss: 0.801796]\n",
      "[Epoch 1/100] [Batch 139/347] [D loss: 0.750564] [G loss: 0.812288]\n",
      "[Epoch 1/100] [Batch 140/347] [D loss: 0.749710] [G loss: 0.810750]\n",
      "[Epoch 1/100] [Batch 141/347] [D loss: 0.748889] [G loss: 0.813946]\n",
      "[Epoch 1/100] [Batch 142/347] [D loss: 0.748047] [G loss: 0.813112]\n",
      "[Epoch 1/100] [Batch 143/347] [D loss: 0.747215] [G loss: 0.816886]\n",
      "[Epoch 1/100] [Batch 144/347] [D loss: 0.746395] [G loss: 0.824113]\n",
      "[Epoch 1/100] [Batch 145/347] [D loss: 0.745614] [G loss: 0.830091]\n",
      "[Epoch 1/100] [Batch 146/347] [D loss: 0.744795] [G loss: 0.833757]\n",
      "[Epoch 1/100] [Batch 147/347] [D loss: 0.743995] [G loss: 0.820546]\n",
      "[Epoch 1/100] [Batch 148/347] [D loss: 0.743232] [G loss: 0.811905]\n",
      "[Epoch 1/100] [Batch 149/347] [D loss: 0.742473] [G loss: 0.812661]\n",
      "[Epoch 1/100] [Batch 150/347] [D loss: 0.741700] [G loss: 0.805208]\n",
      "[Epoch 1/100] [Batch 151/347] [D loss: 0.740939] [G loss: 0.789724]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 152/347] [D loss: 0.740187] [G loss: 0.782187]\n",
      "[Epoch 1/100] [Batch 153/347] [D loss: 0.739419] [G loss: 0.791512]\n",
      "[Epoch 1/100] [Batch 154/347] [D loss: 0.738638] [G loss: 0.804169]\n",
      "[Epoch 1/100] [Batch 155/347] [D loss: 0.737863] [G loss: 0.801354]\n",
      "[Epoch 1/100] [Batch 156/347] [D loss: 0.737064] [G loss: 0.787144]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 157/347] [D loss: 0.736271] [G loss: 0.771801]\n",
      "[Epoch 1/100] [Batch 158/347] [D loss: 0.735470] [G loss: 0.779716]\n",
      "[Epoch 1/100] [Batch 159/347] [D loss: 0.734655] [G loss: 0.789158]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 160/347] [D loss: 0.733846] [G loss: 0.767847]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 161/347] [D loss: 0.733034] [G loss: 0.750881]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 162/347] [D loss: 0.732212] [G loss: 0.750234]\n",
      "[Epoch 1/100] [Batch 163/347] [D loss: 0.731426] [G loss: 0.757963]\n",
      "[Epoch 1/100] [Batch 164/347] [D loss: 0.730592] [G loss: 0.765483]\n",
      "[Epoch 1/100] [Batch 165/347] [D loss: 0.729773] [G loss: 0.772729]\n",
      "[Epoch 1/100] [Batch 166/347] [D loss: 0.728968] [G loss: 0.761268]\n",
      "[Epoch 1/100] [Batch 167/347] [D loss: 0.728170] [G loss: 0.760866]\n",
      "[Epoch 1/100] [Batch 168/347] [D loss: 0.727342] [G loss: 0.768314]\n",
      "[Epoch 1/100] [Batch 169/347] [D loss: 0.726541] [G loss: 0.773535]\n",
      "[Epoch 1/100] [Batch 170/347] [D loss: 0.725728] [G loss: 0.782975]\n",
      "[Epoch 1/100] [Batch 171/347] [D loss: 0.724929] [G loss: 0.792834]\n",
      "[Epoch 1/100] [Batch 172/347] [D loss: 0.724132] [G loss: 0.796054]\n",
      "[Epoch 1/100] [Batch 173/347] [D loss: 0.723330] [G loss: 0.783199]\n",
      "[Epoch 1/100] [Batch 174/347] [D loss: 0.722511] [G loss: 0.779252]\n",
      "[Epoch 1/100] [Batch 175/347] [D loss: 0.721733] [G loss: 0.787755]\n",
      "[Epoch 1/100] [Batch 176/347] [D loss: 0.720927] [G loss: 0.799803]\n",
      "[Epoch 1/100] [Batch 177/347] [D loss: 0.720140] [G loss: 0.799431]\n",
      "[Epoch 1/100] [Batch 178/347] [D loss: 0.719360] [G loss: 0.792175]\n",
      "[Epoch 1/100] [Batch 179/347] [D loss: 0.718570] [G loss: 0.784254]\n",
      "[Epoch 1/100] [Batch 180/347] [D loss: 0.717797] [G loss: 0.776639]\n",
      "[Epoch 1/100] [Batch 181/347] [D loss: 0.717007] [G loss: 0.775958]\n",
      "[Epoch 1/100] [Batch 182/347] [D loss: 0.716227] [G loss: 0.772797]\n",
      "[Epoch 1/100] [Batch 183/347] [D loss: 0.715455] [G loss: 0.775784]\n",
      "[Epoch 1/100] [Batch 184/347] [D loss: 0.714687] [G loss: 0.778667]\n",
      "[Epoch 1/100] [Batch 185/347] [D loss: 0.713918] [G loss: 0.776122]\n",
      "[Epoch 1/100] [Batch 186/347] [D loss: 0.713149] [G loss: 0.774916]\n",
      "[Epoch 1/100] [Batch 187/347] [D loss: 0.712380] [G loss: 0.768593]\n",
      "[Epoch 1/100] [Batch 188/347] [D loss: 0.711621] [G loss: 0.764335]\n",
      "[Epoch 1/100] [Batch 189/347] [D loss: 0.710846] [G loss: 0.762544]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 190/347] [D loss: 0.710095] [G loss: 0.749710]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 191/347] [D loss: 0.709318] [G loss: 0.736096]\n",
      "[Epoch 1/100] [Batch 192/347] [D loss: 0.708545] [G loss: 0.736843]\n",
      "[Epoch 1/100] [Batch 193/347] [D loss: 0.707790] [G loss: 0.744328]\n",
      "[Epoch 1/100] [Batch 194/347] [D loss: 0.707018] [G loss: 0.738810]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 195/347] [D loss: 0.706244] [G loss: 0.733895]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 196/347] [D loss: 0.705469] [G loss: 0.730994]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 197/347] [D loss: 0.704714] [G loss: 0.725692]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 198/347] [D loss: 0.703924] [G loss: 0.720086]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 199/347] [D loss: 0.703135] [G loss: 0.717581]\n",
      "[Epoch 1/100] [Batch 200/347] [D loss: 0.702355] [G loss: 0.720127]\n",
      "[Epoch 1/100] [Batch 201/347] [D loss: 0.701588] [G loss: 0.720302]\n",
      "[Epoch 1/100] [Batch 202/347] [D loss: 0.700787] [G loss: 0.731095]\n",
      "[Epoch 1/100] [Batch 203/347] [D loss: 0.700002] [G loss: 0.739646]\n",
      "[Epoch 1/100] [Batch 204/347] [D loss: 0.699207] [G loss: 0.735896]\n",
      "[Epoch 1/100] [Batch 205/347] [D loss: 0.698415] [G loss: 0.727759]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 206/347] [D loss: 0.697621] [G loss: 0.715222]\n",
      "[Epoch 1/100] [Batch 207/347] [D loss: 0.696819] [G loss: 0.721577]\n",
      "[Epoch 1/100] [Batch 208/347] [D loss: 0.696030] [G loss: 0.720662]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 209/347] [D loss: 0.695230] [G loss: 0.713332]\n",
      "[Epoch 1/100] [Batch 210/347] [D loss: 0.694443] [G loss: 0.717823]\n",
      "[Epoch 1/100] [Batch 211/347] [D loss: 0.693651] [G loss: 0.714501]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 212/347] [D loss: 0.692853] [G loss: 0.706444]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 213/347] [D loss: 0.692081] [G loss: 0.699015]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 214/347] [D loss: 0.691312] [G loss: 0.684911]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 215/347] [D loss: 0.690571] [G loss: 0.684390]\n",
      "[Epoch 1/100] [Batch 216/347] [D loss: 0.689826] [G loss: 0.688849]\n",
      "[Epoch 1/100] [Batch 217/347] [D loss: 0.689079] [G loss: 0.702495]\n",
      "[Epoch 1/100] [Batch 218/347] [D loss: 0.688331] [G loss: 0.716601]\n",
      "[Epoch 1/100] [Batch 219/347] [D loss: 0.687582] [G loss: 0.727594]\n",
      "[Epoch 1/100] [Batch 220/347] [D loss: 0.686806] [G loss: 0.742063]\n",
      "[Epoch 1/100] [Batch 221/347] [D loss: 0.686005] [G loss: 0.742065]\n",
      "[Epoch 1/100] [Batch 222/347] [D loss: 0.685221] [G loss: 0.732758]\n",
      "[Epoch 1/100] [Batch 223/347] [D loss: 0.684488] [G loss: 0.730201]\n",
      "[Epoch 1/100] [Batch 224/347] [D loss: 0.683744] [G loss: 0.724863]\n",
      "[Epoch 1/100] [Batch 225/347] [D loss: 0.683027] [G loss: 0.695192]\n",
      "[Epoch 1/100] [Batch 226/347] [D loss: 0.682332] [G loss: 0.688491]\n",
      "[Epoch 1/100] [Batch 227/347] [D loss: 0.681652] [G loss: 0.712210]\n",
      "[Epoch 1/100] [Batch 228/347] [D loss: 0.680985] [G loss: 0.720413]\n",
      "[Epoch 1/100] [Batch 229/347] [D loss: 0.680320] [G loss: 0.713982]\n",
      "[Epoch 1/100] [Batch 230/347] [D loss: 0.679681] [G loss: 0.708749]\n",
      "[Epoch 1/100] [Batch 231/347] [D loss: 0.679059] [G loss: 0.707624]\n",
      "[Epoch 1/100] [Batch 232/347] [D loss: 0.678457] [G loss: 0.702664]\n",
      "[Epoch 1/100] [Batch 233/347] [D loss: 0.677919] [G loss: 0.692339]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 234/347] [D loss: 0.677394] [G loss: 0.684272]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 235/347] [D loss: 0.676889] [G loss: 0.673203]\n",
      "[Epoch 1/100] [Batch 236/347] [D loss: 0.676373] [G loss: 0.677572]\n",
      "[Epoch 1/100] [Batch 237/347] [D loss: 0.675844] [G loss: 0.689157]\n",
      "[Epoch 1/100] [Batch 238/347] [D loss: 0.675303] [G loss: 0.691974]\n",
      "[Epoch 1/100] [Batch 239/347] [D loss: 0.674710] [G loss: 0.688744]\n",
      "[Epoch 1/100] [Batch 240/347] [D loss: 0.674106] [G loss: 0.683729]\n",
      "[Epoch 1/100] [Batch 241/347] [D loss: 0.673488] [G loss: 0.676734]\n",
      "[Epoch 1/100] [Batch 242/347] [D loss: 0.672870] [G loss: 0.673680]\n",
      "[Epoch 1/100] [Batch 243/347] [D loss: 0.672246] [G loss: 0.680209]\n",
      "[Epoch 1/100] [Batch 244/347] [D loss: 0.671586] [G loss: 0.687966]\n",
      "[Epoch 1/100] [Batch 245/347] [D loss: 0.670950] [G loss: 0.685488]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 246/347] [D loss: 0.670323] [G loss: 0.660469]\n",
      "[Epoch 1/100] [Batch 247/347] [D loss: 0.669666] [G loss: 0.680916]\n",
      "[Epoch 1/100] [Batch 248/347] [D loss: 0.669030] [G loss: 0.689831]\n",
      "[Epoch 1/100] [Batch 249/347] [D loss: 0.668400] [G loss: 0.687914]\n",
      "[Epoch 1/100] [Batch 250/347] [D loss: 0.667756] [G loss: 0.664894]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 251/347] [D loss: 0.667111] [G loss: 0.658262]\n",
      "[Epoch 1/100] [Batch 252/347] [D loss: 0.666472] [G loss: 0.665678]\n",
      "[Epoch 1/100] [Batch 253/347] [D loss: 0.665819] [G loss: 0.664878]\n",
      "[Epoch 1/100] [Batch 254/347] [D loss: 0.665180] [G loss: 0.668152]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 255/347] [D loss: 0.664532] [G loss: 0.655502]\n",
      "[Epoch 1/100] [Batch 256/347] [D loss: 0.663863] [G loss: 0.660075]\n",
      "[Epoch 1/100] [Batch 257/347] [D loss: 0.663230] [G loss: 0.673277]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 258/347] [D loss: 0.662573] [G loss: 0.655047]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 259/347] [D loss: 0.661926] [G loss: 0.645792]\n",
      "[Epoch 1/100] [Batch 260/347] [D loss: 0.661261] [G loss: 0.646899]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 261/347] [D loss: 0.660618] [G loss: 0.638155]\n",
      "[Epoch 1/100] [Batch 262/347] [D loss: 0.659979] [G loss: 0.641489]\n",
      "[Epoch 1/100] [Batch 263/347] [D loss: 0.659328] [G loss: 0.641800]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 264/347] [D loss: 0.658678] [G loss: 0.637903]\n",
      "[Epoch 1/100] [Batch 265/347] [D loss: 0.658043] [G loss: 0.638701]\n",
      "[Epoch 1/100] [Batch 266/347] [D loss: 0.657430] [G loss: 0.640314]\n",
      "[Epoch 1/100] [Batch 267/347] [D loss: 0.656839] [G loss: 0.640175]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 268/347] [D loss: 0.656246] [G loss: 0.633612]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 269/347] [D loss: 0.655682] [G loss: 0.630158]\n",
      "[Epoch 1/100] [Batch 270/347] [D loss: 0.655110] [G loss: 0.631206]\n",
      "[Epoch 1/100] [Batch 271/347] [D loss: 0.654526] [G loss: 0.632481]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 272/347] [D loss: 0.653960] [G loss: 0.628191]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 273/347] [D loss: 0.653356] [G loss: 0.618226]\n",
      "[Epoch 1/100] [Batch 274/347] [D loss: 0.652765] [G loss: 0.632058]\n",
      "[Epoch 1/100] [Batch 275/347] [D loss: 0.652166] [G loss: 0.628558]\n",
      "[Epoch 1/100] [Batch 276/347] [D loss: 0.651548] [G loss: 0.618563]\n",
      "[Epoch 1/100] [Batch 277/347] [D loss: 0.650989] [G loss: 0.620372]\n",
      "[Epoch 1/100] [Batch 278/347] [D loss: 0.650392] [G loss: 0.629962]\n",
      "[Epoch 1/100] [Batch 279/347] [D loss: 0.649829] [G loss: 0.622967]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 280/347] [D loss: 0.649254] [G loss: 0.617109]\n",
      "[Epoch 1/100] [Batch 281/347] [D loss: 0.648688] [G loss: 0.617162]\n",
      "[Epoch 1/100] [Batch 282/347] [D loss: 0.648138] [G loss: 0.617283]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 283/347] [D loss: 0.647591] [G loss: 0.609999]\n",
      "[Epoch 1/100] [Batch 284/347] [D loss: 0.647018] [G loss: 0.610731]\n",
      "[Epoch 1/100] [Batch 285/347] [D loss: 0.646448] [G loss: 0.617267]\n",
      "[Epoch 1/100] [Batch 286/347] [D loss: 0.645880] [G loss: 0.616106]\n",
      "[Epoch 1/100] [Batch 287/347] [D loss: 0.645292] [G loss: 0.613849]\n",
      "[Epoch 1/100] [Batch 288/347] [D loss: 0.644689] [G loss: 0.621123]\n",
      "[Epoch 1/100] [Batch 289/347] [D loss: 0.644106] [G loss: 0.624107]\n",
      "[Epoch 1/100] [Batch 290/347] [D loss: 0.643501] [G loss: 0.616092]\n",
      "[Epoch 1/100] [Batch 291/347] [D loss: 0.642931] [G loss: 0.617875]\n",
      "[Epoch 1/100] [Batch 292/347] [D loss: 0.642354] [G loss: 0.610213]\n",
      "[Epoch 1/100] [Batch 293/347] [D loss: 0.641781] [G loss: 0.623471]\n",
      "[Epoch 1/100] [Batch 294/347] [D loss: 0.641224] [G loss: 0.627403]\n",
      "[Epoch 1/100] [Batch 295/347] [D loss: 0.640668] [G loss: 0.614088]\n",
      "[Epoch 1/100] [Batch 296/347] [D loss: 0.640133] [G loss: 0.620194]\n",
      "[Epoch 1/100] [Batch 297/347] [D loss: 0.639564] [G loss: 0.635607]\n",
      "[Epoch 1/100] [Batch 298/347] [D loss: 0.638995] [G loss: 0.629124]\n",
      "[Epoch 1/100] [Batch 299/347] [D loss: 0.638386] [G loss: 0.626546]\n",
      "[Epoch 1/100] [Batch 300/347] [D loss: 0.637776] [G loss: 0.620693]\n",
      "[Epoch 1/100] [Batch 301/347] [D loss: 0.637180] [G loss: 0.615458]\n",
      "[Epoch 1/100] [Batch 302/347] [D loss: 0.636577] [G loss: 0.620362]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 303/347] [D loss: 0.635942] [G loss: 0.594386]\n",
      "[Epoch 1/100] [Batch 304/347] [D loss: 0.635317] [G loss: 0.607148]\n",
      "[Epoch 1/100] [Batch 305/347] [D loss: 0.634681] [G loss: 0.618309]\n",
      "[Epoch 1/100] [Batch 306/347] [D loss: 0.634083] [G loss: 0.607708]\n",
      "[Epoch 1/100] [Batch 307/347] [D loss: 0.633443] [G loss: 0.596159]\n",
      "[Epoch 1/100] [Batch 308/347] [D loss: 0.632821] [G loss: 0.596141]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 309/347] [D loss: 0.632206] [G loss: 0.593046]\n",
      "[Epoch 1/100] [Batch 310/347] [D loss: 0.631580] [G loss: 0.612473]\n",
      "[Epoch 1/100] [Batch 311/347] [D loss: 0.630969] [G loss: 0.614006]\n",
      "[Epoch 1/100] [Batch 312/347] [D loss: 0.630316] [G loss: 0.612423]\n",
      "[Epoch 1/100] [Batch 313/347] [D loss: 0.629693] [G loss: 0.610349]\n",
      "[Epoch 1/100] [Batch 314/347] [D loss: 0.629061] [G loss: 0.602692]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 315/347] [D loss: 0.628419] [G loss: 0.592267]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 316/347] [D loss: 0.627788] [G loss: 0.585181]\n",
      "[Epoch 1/100] [Batch 317/347] [D loss: 0.627121] [G loss: 0.602644]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 318/347] [D loss: 0.626499] [G loss: 0.579231]\n",
      "[Epoch 1/100] [Batch 319/347] [D loss: 0.625874] [G loss: 0.610013]\n",
      "[Epoch 1/100] [Batch 320/347] [D loss: 0.625211] [G loss: 0.622508]\n",
      "[Epoch 1/100] [Batch 321/347] [D loss: 0.624573] [G loss: 0.610875]\n",
      "[Epoch 1/100] [Batch 322/347] [D loss: 0.623919] [G loss: 0.596597]\n",
      "[Epoch 1/100] [Batch 323/347] [D loss: 0.623261] [G loss: 0.594574]\n",
      "[Epoch 1/100] [Batch 324/347] [D loss: 0.622627] [G loss: 0.596490]\n",
      "[Epoch 1/100] [Batch 325/347] [D loss: 0.621985] [G loss: 0.584629]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 326/347] [D loss: 0.621328] [G loss: 0.571776]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 327/347] [D loss: 0.620699] [G loss: 0.569336]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 328/347] [D loss: 0.620068] [G loss: 0.567088]\n",
      "[Epoch 1/100] [Batch 329/347] [D loss: 0.619423] [G loss: 0.570289]\n",
      "[Epoch 1/100] [Batch 330/347] [D loss: 0.618803] [G loss: 0.578879]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 331/347] [D loss: 0.618157] [G loss: 0.566149]\n",
      "[Epoch 1/100] [Batch 332/347] [D loss: 0.617561] [G loss: 0.576717]\n",
      "[Epoch 1/100] [Batch 333/347] [D loss: 0.616950] [G loss: 0.587001]\n",
      "[Epoch 1/100] [Batch 334/347] [D loss: 0.616329] [G loss: 0.587286]\n",
      "[Epoch 1/100] [Batch 335/347] [D loss: 0.615727] [G loss: 0.574126]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 336/347] [D loss: 0.615107] [G loss: 0.558538]\n",
      "[Epoch 1/100] [Batch 337/347] [D loss: 0.614470] [G loss: 0.563445]\n",
      "[Epoch 1/100] [Batch 338/347] [D loss: 0.613855] [G loss: 0.577006]\n",
      "[Epoch 1/100] [Batch 339/347] [D loss: 0.613231] [G loss: 0.581319]\n",
      "[Epoch 1/100] [Batch 340/347] [D loss: 0.612589] [G loss: 0.580601]\n",
      "[Epoch 1/100] [Batch 341/347] [D loss: 0.611935] [G loss: 0.574735]\n",
      "[Epoch 1/100] [Batch 342/347] [D loss: 0.611287] [G loss: 0.566006]\n",
      "[Epoch 1/100] [Batch 343/347] [D loss: 0.610619] [G loss: 0.569611]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 1/100] [Batch 344/347] [D loss: 0.609919] [G loss: 0.557425]\n",
      "[Epoch 1/100] [Batch 345/347] [D loss: 0.609233] [G loss: 0.561444]\n",
      "[Epoch 1/100] [Batch 346/347] [D loss: 0.608509] [G loss: 0.567967]\n",
      "[Epoch 1/100] [Batch 347/347] [D loss: 0.607801] [G loss: 0.573037]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 1/347] [D loss: 0.607124] [G loss: 0.743393]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 2/347] [D loss: 0.606415] [G loss: 0.741291]\n",
      "[Epoch 2/100] [Batch 3/347] [D loss: 0.605687] [G loss: 0.746453]\n",
      "[Epoch 2/100] [Batch 4/347] [D loss: 0.604997] [G loss: 0.742397]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 5/347] [D loss: 0.604308] [G loss: 0.736288]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 6/347] [D loss: 0.603643] [G loss: 0.732534]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 7/347] [D loss: 0.603019] [G loss: 0.722073]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 8/347] [D loss: 0.602430] [G loss: 0.711700]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 9/347] [D loss: 0.601890] [G loss: 0.695010]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 10/347] [D loss: 0.601383] [G loss: 0.689488]\n",
      "[Epoch 2/100] [Batch 11/347] [D loss: 0.600942] [G loss: 0.697164]\n",
      "[Epoch 2/100] [Batch 12/347] [D loss: 0.600573] [G loss: 0.695510]\n",
      "[Epoch 2/100] [Batch 13/347] [D loss: 0.600253] [G loss: 0.693419]\n",
      "[Epoch 2/100] [Batch 14/347] [D loss: 0.599985] [G loss: 0.689664]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 15/347] [D loss: 0.599771] [G loss: 0.680254]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 16/347] [D loss: 0.599604] [G loss: 0.670883]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 17/347] [D loss: 0.599479] [G loss: 0.653697]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 18/347] [D loss: 0.599385] [G loss: 0.641327]\n",
      "[Epoch 2/100] [Batch 19/347] [D loss: 0.599315] [G loss: 0.648834]\n",
      "[Epoch 2/100] [Batch 20/347] [D loss: 0.599255] [G loss: 0.656803]\n",
      "[Epoch 2/100] [Batch 21/347] [D loss: 0.599201] [G loss: 0.648557]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 22/347] [D loss: 0.599150] [G loss: 0.639062]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 23/347] [D loss: 0.599105] [G loss: 0.628417]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 24/347] [D loss: 0.599066] [G loss: 0.623680]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 25/347] [D loss: 0.599030] [G loss: 0.618883]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 26/347] [D loss: 0.598995] [G loss: 0.600513]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 27/347] [D loss: 0.598961] [G loss: 0.590594]\n",
      "[Epoch 2/100] [Batch 28/347] [D loss: 0.598928] [G loss: 0.597977]\n",
      "[Epoch 2/100] [Batch 29/347] [D loss: 0.598897] [G loss: 0.613314]\n",
      "[Epoch 2/100] [Batch 30/347] [D loss: 0.598864] [G loss: 0.616341]\n",
      "[Epoch 2/100] [Batch 31/347] [D loss: 0.598833] [G loss: 0.615364]\n",
      "[Epoch 2/100] [Batch 32/347] [D loss: 0.598802] [G loss: 0.605492]\n",
      "[Epoch 2/100] [Batch 33/347] [D loss: 0.598769] [G loss: 0.598256]\n",
      "[Epoch 2/100] [Batch 34/347] [D loss: 0.598736] [G loss: 0.596026]\n",
      "[Epoch 2/100] [Batch 35/347] [D loss: 0.598703] [G loss: 0.591627]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 36/347] [D loss: 0.598671] [G loss: 0.585732]\n",
      "[Epoch 2/100] [Batch 37/347] [D loss: 0.598637] [G loss: 0.594222]\n",
      "[Epoch 2/100] [Batch 38/347] [D loss: 0.598604] [G loss: 0.606548]\n",
      "[Epoch 2/100] [Batch 39/347] [D loss: 0.598572] [G loss: 0.610267]\n",
      "[Epoch 2/100] [Batch 40/347] [D loss: 0.598541] [G loss: 0.616299]\n",
      "[Epoch 2/100] [Batch 41/347] [D loss: 0.598508] [G loss: 0.616544]\n",
      "[Epoch 2/100] [Batch 42/347] [D loss: 0.598477] [G loss: 0.608261]\n",
      "[Epoch 2/100] [Batch 43/347] [D loss: 0.598446] [G loss: 0.589006]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 44/347] [D loss: 0.598414] [G loss: 0.575245]\n",
      "[Epoch 2/100] [Batch 45/347] [D loss: 0.598383] [G loss: 0.592158]\n",
      "[Epoch 2/100] [Batch 46/347] [D loss: 0.598352] [G loss: 0.586418]\n",
      "[Epoch 2/100] [Batch 47/347] [D loss: 0.598321] [G loss: 0.577507]\n",
      "[Epoch 2/100] [Batch 48/347] [D loss: 0.598290] [G loss: 0.586215]\n",
      "[Epoch 2/100] [Batch 49/347] [D loss: 0.598259] [G loss: 0.583938]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 50/347] [D loss: 0.598228] [G loss: 0.572415]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 51/347] [D loss: 0.598197] [G loss: 0.557968]\n",
      "[Epoch 2/100] [Batch 52/347] [D loss: 0.598166] [G loss: 0.558794]\n",
      "[Epoch 2/100] [Batch 53/347] [D loss: 0.598135] [G loss: 0.561433]\n",
      "[Epoch 2/100] [Batch 54/347] [D loss: 0.598104] [G loss: 0.573052]\n",
      "[Epoch 2/100] [Batch 55/347] [D loss: 0.598073] [G loss: 0.596836]\n",
      "[Epoch 2/100] [Batch 56/347] [D loss: 0.598042] [G loss: 0.592054]\n",
      "[Epoch 2/100] [Batch 57/347] [D loss: 0.598011] [G loss: 0.560407]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 58/347] [D loss: 0.597980] [G loss: 0.552193]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 59/347] [D loss: 0.597949] [G loss: 0.545162]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 60/347] [D loss: 0.597918] [G loss: 0.545025]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 61/347] [D loss: 0.597887] [G loss: 0.543812]\n",
      "[Epoch 2/100] [Batch 62/347] [D loss: 0.597856] [G loss: 0.557296]\n",
      "[Epoch 2/100] [Batch 63/347] [D loss: 0.597825] [G loss: 0.574033]\n",
      "[Epoch 2/100] [Batch 64/347] [D loss: 0.597794] [G loss: 0.550231]\n",
      "[Epoch 2/100] [Batch 65/347] [D loss: 0.597763] [G loss: 0.568820]\n",
      "[Epoch 2/100] [Batch 66/347] [D loss: 0.597733] [G loss: 0.557269]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 67/347] [D loss: 0.597701] [G loss: 0.533758]\n",
      "[Epoch 2/100] [Batch 68/347] [D loss: 0.597670] [G loss: 0.533774]\n",
      "[Epoch 2/100] [Batch 69/347] [D loss: 0.597639] [G loss: 0.550562]\n",
      "[Epoch 2/100] [Batch 70/347] [D loss: 0.597608] [G loss: 0.559781]\n",
      "[Epoch 2/100] [Batch 71/347] [D loss: 0.597577] [G loss: 0.547986]\n",
      "[Epoch 2/100] [Batch 72/347] [D loss: 0.597546] [G loss: 0.548466]\n",
      "[Epoch 2/100] [Batch 73/347] [D loss: 0.597515] [G loss: 0.539359]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 74/347] [D loss: 0.597484] [G loss: 0.528772]\n",
      "[Epoch 2/100] [Batch 75/347] [D loss: 0.597453] [G loss: 0.540012]\n",
      "[Epoch 2/100] [Batch 76/347] [D loss: 0.597421] [G loss: 0.541844]\n",
      "[Epoch 2/100] [Batch 77/347] [D loss: 0.597390] [G loss: 0.530925]\n",
      "[Epoch 2/100] [Batch 78/347] [D loss: 0.597359] [G loss: 0.564986]\n",
      "[Epoch 2/100] [Batch 79/347] [D loss: 0.597328] [G loss: 0.576215]\n",
      "[Epoch 2/100] [Batch 80/347] [D loss: 0.597297] [G loss: 0.573082]\n",
      "[Epoch 2/100] [Batch 81/347] [D loss: 0.597266] [G loss: 0.577608]\n",
      "[Epoch 2/100] [Batch 82/347] [D loss: 0.597234] [G loss: 0.570725]\n",
      "[Epoch 2/100] [Batch 83/347] [D loss: 0.597203] [G loss: 0.568542]\n",
      "[Epoch 2/100] [Batch 84/347] [D loss: 0.597172] [G loss: 0.578855]\n",
      "[Epoch 2/100] [Batch 85/347] [D loss: 0.597141] [G loss: 0.578439]\n",
      "[Epoch 2/100] [Batch 86/347] [D loss: 0.597109] [G loss: 0.571659]\n",
      "[Epoch 2/100] [Batch 87/347] [D loss: 0.597078] [G loss: 0.568099]\n",
      "[Epoch 2/100] [Batch 88/347] [D loss: 0.597047] [G loss: 0.570124]\n",
      "[Epoch 2/100] [Batch 89/347] [D loss: 0.597016] [G loss: 0.572102]\n",
      "[Epoch 2/100] [Batch 90/347] [D loss: 0.596984] [G loss: 0.566940]\n",
      "[Epoch 2/100] [Batch 91/347] [D loss: 0.596953] [G loss: 0.564141]\n",
      "[Epoch 2/100] [Batch 92/347] [D loss: 0.596922] [G loss: 0.564277]\n",
      "[Epoch 2/100] [Batch 93/347] [D loss: 0.596890] [G loss: 0.560916]\n",
      "[Epoch 2/100] [Batch 94/347] [D loss: 0.596859] [G loss: 0.556049]\n",
      "[Epoch 2/100] [Batch 95/347] [D loss: 0.596828] [G loss: 0.555237]\n",
      "[Epoch 2/100] [Batch 96/347] [D loss: 0.596796] [G loss: 0.549112]\n",
      "[Epoch 2/100] [Batch 97/347] [D loss: 0.596765] [G loss: 0.542705]\n",
      "[Epoch 2/100] [Batch 98/347] [D loss: 0.596733] [G loss: 0.546323]\n",
      "[Epoch 2/100] [Batch 99/347] [D loss: 0.596702] [G loss: 0.548685]\n",
      "[Epoch 2/100] [Batch 100/347] [D loss: 0.596671] [G loss: 0.543763]\n",
      "[Epoch 2/100] [Batch 101/347] [D loss: 0.596639] [G loss: 0.540306]\n",
      "[Epoch 2/100] [Batch 102/347] [D loss: 0.596608] [G loss: 0.541515]\n",
      "[Epoch 2/100] [Batch 103/347] [D loss: 0.596576] [G loss: 0.541088]\n",
      "[Epoch 2/100] [Batch 104/347] [D loss: 0.596545] [G loss: 0.543046]\n",
      "[Epoch 2/100] [Batch 105/347] [D loss: 0.596513] [G loss: 0.544364]\n",
      "[Epoch 2/100] [Batch 106/347] [D loss: 0.596482] [G loss: 0.543010]\n",
      "[Epoch 2/100] [Batch 107/347] [D loss: 0.596450] [G loss: 0.534420]\n",
      "[Epoch 2/100] [Batch 108/347] [D loss: 0.596419] [G loss: 0.534034]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 109/347] [D loss: 0.596387] [G loss: 0.527067]\n",
      "[Epoch 2/100] [Batch 110/347] [D loss: 0.596356] [G loss: 0.532049]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 111/347] [D loss: 0.596324] [G loss: 0.520738]\n",
      "[Epoch 2/100] [Batch 112/347] [D loss: 0.596293] [G loss: 0.526006]\n",
      "[Epoch 2/100] [Batch 113/347] [D loss: 0.596261] [G loss: 0.548118]\n",
      "[Epoch 2/100] [Batch 114/347] [D loss: 0.596230] [G loss: 0.568932]\n",
      "[Epoch 2/100] [Batch 115/347] [D loss: 0.596198] [G loss: 0.570156]\n",
      "[Epoch 2/100] [Batch 116/347] [D loss: 0.596166] [G loss: 0.564310]\n",
      "[Epoch 2/100] [Batch 117/347] [D loss: 0.596135] [G loss: 0.537632]\n",
      "[Epoch 2/100] [Batch 118/347] [D loss: 0.596103] [G loss: 0.523583]\n",
      "[Epoch 2/100] [Batch 119/347] [D loss: 0.596071] [G loss: 0.528648]\n",
      "[Epoch 2/100] [Batch 120/347] [D loss: 0.596040] [G loss: 0.525492]\n",
      "[Epoch 2/100] [Batch 121/347] [D loss: 0.596008] [G loss: 0.524496]\n",
      "[Epoch 2/100] [Batch 122/347] [D loss: 0.595977] [G loss: 0.524589]\n",
      "[Epoch 2/100] [Batch 123/347] [D loss: 0.595945] [G loss: 0.525815]\n",
      "[Epoch 2/100] [Batch 124/347] [D loss: 0.595913] [G loss: 0.523669]\n",
      "[Epoch 2/100] [Batch 125/347] [D loss: 0.595882] [G loss: 0.533443]\n",
      "[Epoch 2/100] [Batch 126/347] [D loss: 0.595850] [G loss: 0.545850]\n",
      "[Epoch 2/100] [Batch 127/347] [D loss: 0.595818] [G loss: 0.547099]\n",
      "[Epoch 2/100] [Batch 128/347] [D loss: 0.595787] [G loss: 0.541263]\n",
      "[Epoch 2/100] [Batch 129/347] [D loss: 0.595755] [G loss: 0.535936]\n",
      "[Epoch 2/100] [Batch 130/347] [D loss: 0.595723] [G loss: 0.529098]\n",
      "[Epoch 2/100] [Batch 131/347] [D loss: 0.595691] [G loss: 0.526935]\n",
      "[Epoch 2/100] [Batch 132/347] [D loss: 0.595659] [G loss: 0.548788]\n",
      "[Epoch 2/100] [Batch 133/347] [D loss: 0.595628] [G loss: 0.556307]\n",
      "[Epoch 2/100] [Batch 134/347] [D loss: 0.595596] [G loss: 0.571888]\n",
      "[Epoch 2/100] [Batch 135/347] [D loss: 0.595564] [G loss: 0.581429]\n",
      "[Epoch 2/100] [Batch 136/347] [D loss: 0.595532] [G loss: 0.540130]\n",
      "[Epoch 2/100] [Batch 137/347] [D loss: 0.595501] [G loss: 0.525824]\n",
      "[Epoch 2/100] [Batch 138/347] [D loss: 0.595469] [G loss: 0.545363]\n",
      "[Epoch 2/100] [Batch 139/347] [D loss: 0.595437] [G loss: 0.569172]\n",
      "[Epoch 2/100] [Batch 140/347] [D loss: 0.595405] [G loss: 0.580539]\n",
      "[Epoch 2/100] [Batch 141/347] [D loss: 0.595373] [G loss: 0.587263]\n",
      "[Epoch 2/100] [Batch 142/347] [D loss: 0.595341] [G loss: 0.595183]\n",
      "[Epoch 2/100] [Batch 143/347] [D loss: 0.595310] [G loss: 0.617084]\n",
      "[Epoch 2/100] [Batch 144/347] [D loss: 0.595278] [G loss: 0.619128]\n",
      "[Epoch 2/100] [Batch 145/347] [D loss: 0.595246] [G loss: 0.604844]\n",
      "[Epoch 2/100] [Batch 146/347] [D loss: 0.595214] [G loss: 0.587761]\n",
      "[Epoch 2/100] [Batch 147/347] [D loss: 0.595182] [G loss: 0.559467]\n",
      "[Epoch 2/100] [Batch 148/347] [D loss: 0.595151] [G loss: 0.546544]\n",
      "[Epoch 2/100] [Batch 149/347] [D loss: 0.595119] [G loss: 0.558950]\n",
      "[Epoch 2/100] [Batch 150/347] [D loss: 0.595086] [G loss: 0.558485]\n",
      "[Epoch 2/100] [Batch 151/347] [D loss: 0.595055] [G loss: 0.546738]\n",
      "[Epoch 2/100] [Batch 152/347] [D loss: 0.595023] [G loss: 0.556890]\n",
      "[Epoch 2/100] [Batch 153/347] [D loss: 0.594991] [G loss: 0.576807]\n",
      "[Epoch 2/100] [Batch 154/347] [D loss: 0.594959] [G loss: 0.580294]\n",
      "[Epoch 2/100] [Batch 155/347] [D loss: 0.594927] [G loss: 0.566718]\n",
      "[Epoch 2/100] [Batch 156/347] [D loss: 0.594895] [G loss: 0.549607]\n",
      "[Epoch 2/100] [Batch 157/347] [D loss: 0.594863] [G loss: 0.555258]\n",
      "[Epoch 2/100] [Batch 158/347] [D loss: 0.594831] [G loss: 0.578146]\n",
      "[Epoch 2/100] [Batch 159/347] [D loss: 0.594799] [G loss: 0.574668]\n",
      "[Epoch 2/100] [Batch 160/347] [D loss: 0.594767] [G loss: 0.553905]\n",
      "[Epoch 2/100] [Batch 161/347] [D loss: 0.594735] [G loss: 0.544659]\n",
      "[Epoch 2/100] [Batch 162/347] [D loss: 0.594703] [G loss: 0.549474]\n",
      "[Epoch 2/100] [Batch 163/347] [D loss: 0.594671] [G loss: 0.567227]\n",
      "[Epoch 2/100] [Batch 164/347] [D loss: 0.594639] [G loss: 0.581331]\n",
      "[Epoch 2/100] [Batch 165/347] [D loss: 0.594607] [G loss: 0.571445]\n",
      "[Epoch 2/100] [Batch 166/347] [D loss: 0.594575] [G loss: 0.532536]\n",
      "[Epoch 2/100] [Batch 167/347] [D loss: 0.594543] [G loss: 0.539615]\n",
      "[Epoch 2/100] [Batch 168/347] [D loss: 0.594511] [G loss: 0.550679]\n",
      "[Epoch 2/100] [Batch 169/347] [D loss: 0.594479] [G loss: 0.549961]\n",
      "[Epoch 2/100] [Batch 170/347] [D loss: 0.594447] [G loss: 0.561917]\n",
      "[Epoch 2/100] [Batch 171/347] [D loss: 0.594415] [G loss: 0.574490]\n",
      "[Epoch 2/100] [Batch 172/347] [D loss: 0.594382] [G loss: 0.579750]\n",
      "[Epoch 2/100] [Batch 173/347] [D loss: 0.594350] [G loss: 0.568613]\n",
      "[Epoch 2/100] [Batch 174/347] [D loss: 0.594318] [G loss: 0.566061]\n",
      "[Epoch 2/100] [Batch 175/347] [D loss: 0.594286] [G loss: 0.575596]\n",
      "[Epoch 2/100] [Batch 176/347] [D loss: 0.594254] [G loss: 0.588599]\n",
      "[Epoch 2/100] [Batch 177/347] [D loss: 0.594222] [G loss: 0.588917]\n",
      "[Epoch 2/100] [Batch 178/347] [D loss: 0.594190] [G loss: 0.582436]\n",
      "[Epoch 2/100] [Batch 179/347] [D loss: 0.594157] [G loss: 0.575150]\n",
      "[Epoch 2/100] [Batch 180/347] [D loss: 0.594125] [G loss: 0.568111]\n",
      "[Epoch 2/100] [Batch 181/347] [D loss: 0.594093] [G loss: 0.567806]\n",
      "[Epoch 2/100] [Batch 182/347] [D loss: 0.594061] [G loss: 0.564724]\n",
      "[Epoch 2/100] [Batch 183/347] [D loss: 0.594029] [G loss: 0.567789]\n",
      "[Epoch 2/100] [Batch 184/347] [D loss: 0.593997] [G loss: 0.570625]\n",
      "[Epoch 2/100] [Batch 185/347] [D loss: 0.593965] [G loss: 0.568355]\n",
      "[Epoch 2/100] [Batch 186/347] [D loss: 0.593932] [G loss: 0.567216]\n",
      "[Epoch 2/100] [Batch 187/347] [D loss: 0.593900] [G loss: 0.560985]\n",
      "[Epoch 2/100] [Batch 188/347] [D loss: 0.593868] [G loss: 0.556885]\n",
      "[Epoch 2/100] [Batch 189/347] [D loss: 0.593836] [G loss: 0.555058]\n",
      "[Epoch 2/100] [Batch 190/347] [D loss: 0.593803] [G loss: 0.542125]\n",
      "[Epoch 2/100] [Batch 191/347] [D loss: 0.593771] [G loss: 0.528470]\n",
      "[Epoch 2/100] [Batch 192/347] [D loss: 0.593739] [G loss: 0.528840]\n",
      "[Epoch 2/100] [Batch 193/347] [D loss: 0.593707] [G loss: 0.535960]\n",
      "[Epoch 2/100] [Batch 194/347] [D loss: 0.593674] [G loss: 0.530347]\n",
      "[Epoch 2/100] [Batch 195/347] [D loss: 0.593642] [G loss: 0.531023]\n",
      "[Epoch 2/100] [Batch 196/347] [D loss: 0.593610] [G loss: 0.529968]\n",
      "[Epoch 2/100] [Batch 197/347] [D loss: 0.593577] [G loss: 0.526198]\n",
      "[Epoch 2/100] [Batch 198/347] [D loss: 0.593545] [G loss: 0.520993]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 199/347] [D loss: 0.593513] [G loss: 0.520648]\n",
      "[Epoch 2/100] [Batch 200/347] [D loss: 0.593481] [G loss: 0.520832]\n",
      "[Epoch 2/100] [Batch 201/347] [D loss: 0.593449] [G loss: 0.523646]\n",
      "[Epoch 2/100] [Batch 202/347] [D loss: 0.593416] [G loss: 0.535092]\n",
      "[Epoch 2/100] [Batch 203/347] [D loss: 0.593384] [G loss: 0.543570]\n",
      "[Epoch 2/100] [Batch 204/347] [D loss: 0.593351] [G loss: 0.539905]\n",
      "[Epoch 2/100] [Batch 205/347] [D loss: 0.593319] [G loss: 0.531780]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 206/347] [D loss: 0.593287] [G loss: 0.519208]\n",
      "[Epoch 2/100] [Batch 207/347] [D loss: 0.593255] [G loss: 0.528096]\n",
      "[Epoch 2/100] [Batch 208/347] [D loss: 0.593222] [G loss: 0.529184]\n",
      "[Epoch 2/100] [Batch 209/347] [D loss: 0.593190] [G loss: 0.523789]\n",
      "[Epoch 2/100] [Batch 210/347] [D loss: 0.593158] [G loss: 0.529826]\n",
      "[Epoch 2/100] [Batch 211/347] [D loss: 0.593125] [G loss: 0.527919]\n",
      "[Epoch 2/100] [Batch 212/347] [D loss: 0.593093] [G loss: 0.521275]\n",
      "[Epoch 2/100] [Batch 213/347] [D loss: 0.593060] [G loss: 0.526354]\n",
      "[Epoch 2/100] [Batch 214/347] [D loss: 0.593028] [G loss: 0.535985]\n",
      "[Epoch 2/100] [Batch 215/347] [D loss: 0.592996] [G loss: 0.544422]\n",
      "[Epoch 2/100] [Batch 216/347] [D loss: 0.592963] [G loss: 0.525657]\n",
      "[Epoch 2/100] [Batch 217/347] [D loss: 0.592931] [G loss: 0.526271]\n",
      "[Epoch 2/100] [Batch 218/347] [D loss: 0.592899] [G loss: 0.536720]\n",
      "[Epoch 2/100] [Batch 219/347] [D loss: 0.592866] [G loss: 0.548520]\n",
      "[Epoch 2/100] [Batch 220/347] [D loss: 0.592834] [G loss: 0.564175]\n",
      "[Epoch 2/100] [Batch 221/347] [D loss: 0.592802] [G loss: 0.565373]\n",
      "[Epoch 2/100] [Batch 222/347] [D loss: 0.592769] [G loss: 0.557080]\n",
      "[Epoch 2/100] [Batch 223/347] [D loss: 0.592736] [G loss: 0.555345]\n",
      "[Epoch 2/100] [Batch 224/347] [D loss: 0.592704] [G loss: 0.550719]\n",
      "[Epoch 2/100] [Batch 225/347] [D loss: 0.592672] [G loss: 0.533704]\n",
      "[Epoch 2/100] [Batch 226/347] [D loss: 0.592639] [G loss: 0.534309]\n",
      "[Epoch 2/100] [Batch 227/347] [D loss: 0.592606] [G loss: 0.545293]\n",
      "[Epoch 2/100] [Batch 228/347] [D loss: 0.592574] [G loss: 0.550181]\n",
      "[Epoch 2/100] [Batch 229/347] [D loss: 0.592542] [G loss: 0.545891]\n",
      "[Epoch 2/100] [Batch 230/347] [D loss: 0.592509] [G loss: 0.542546]\n",
      "[Epoch 2/100] [Batch 231/347] [D loss: 0.592477] [G loss: 0.542678]\n",
      "[Epoch 2/100] [Batch 232/347] [D loss: 0.592444] [G loss: 0.538434]\n",
      "[Epoch 2/100] [Batch 233/347] [D loss: 0.592412] [G loss: 0.534302]\n",
      "[Epoch 2/100] [Batch 234/347] [D loss: 0.592380] [G loss: 0.538989]\n",
      "[Epoch 2/100] [Batch 235/347] [D loss: 0.592347] [G loss: 0.527573]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 236/347] [D loss: 0.592315] [G loss: 0.518707]\n",
      "[Epoch 2/100] [Batch 237/347] [D loss: 0.592282] [G loss: 0.523744]\n",
      "[Epoch 2/100] [Batch 238/347] [D loss: 0.592250] [G loss: 0.527945]\n",
      "[Epoch 2/100] [Batch 239/347] [D loss: 0.592217] [G loss: 0.526134]\n",
      "[Epoch 2/100] [Batch 240/347] [D loss: 0.592184] [G loss: 0.522313]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 241/347] [D loss: 0.592152] [G loss: 0.516313]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 242/347] [D loss: 0.592119] [G loss: 0.513956]\n",
      "[Epoch 2/100] [Batch 243/347] [D loss: 0.592087] [G loss: 0.521044]\n",
      "[Epoch 2/100] [Batch 244/347] [D loss: 0.592054] [G loss: 0.529335]\n",
      "[Epoch 2/100] [Batch 245/347] [D loss: 0.592022] [G loss: 0.527417]\n",
      "[Epoch 2/100] [Batch 246/347] [D loss: 0.591989] [G loss: 0.519433]\n",
      "[Epoch 2/100] [Batch 247/347] [D loss: 0.591957] [G loss: 0.534835]\n",
      "[Epoch 2/100] [Batch 248/347] [D loss: 0.591924] [G loss: 0.541233]\n",
      "[Epoch 2/100] [Batch 249/347] [D loss: 0.591892] [G loss: 0.547128]\n",
      "[Epoch 2/100] [Batch 250/347] [D loss: 0.591859] [G loss: 0.538946]\n",
      "[Epoch 2/100] [Batch 251/347] [D loss: 0.591827] [G loss: 0.517509]\n",
      "[Epoch 2/100] [Batch 252/347] [D loss: 0.591795] [G loss: 0.520616]\n",
      "[Epoch 2/100] [Batch 253/347] [D loss: 0.591762] [G loss: 0.521212]\n",
      "[Epoch 2/100] [Batch 254/347] [D loss: 0.591729] [G loss: 0.519531]\n",
      "[Epoch 2/100] [Batch 255/347] [D loss: 0.591697] [G loss: 0.518052]\n",
      "[Epoch 2/100] [Batch 256/347] [D loss: 0.591664] [G loss: 0.522898]\n",
      "[Epoch 2/100] [Batch 257/347] [D loss: 0.591631] [G loss: 0.524783]\n",
      "[Epoch 2/100] [Batch 258/347] [D loss: 0.591599] [G loss: 0.518422]\n",
      "[Epoch 2/100] [Batch 259/347] [D loss: 0.591566] [G loss: 0.538929]\n",
      "[Epoch 2/100] [Batch 260/347] [D loss: 0.591533] [G loss: 0.553578]\n",
      "[Epoch 2/100] [Batch 261/347] [D loss: 0.591501] [G loss: 0.546357]\n",
      "[Epoch 2/100] [Batch 262/347] [D loss: 0.591469] [G loss: 0.531464]\n",
      "[Epoch 2/100] [Batch 263/347] [D loss: 0.591436] [G loss: 0.532559]\n",
      "[Epoch 2/100] [Batch 264/347] [D loss: 0.591403] [G loss: 0.546997]\n",
      "[Epoch 2/100] [Batch 265/347] [D loss: 0.591371] [G loss: 0.551934]\n",
      "[Epoch 2/100] [Batch 266/347] [D loss: 0.591338] [G loss: 0.544508]\n",
      "[Epoch 2/100] [Batch 267/347] [D loss: 0.591305] [G loss: 0.537500]\n",
      "[Epoch 2/100] [Batch 268/347] [D loss: 0.591273] [G loss: 0.544145]\n",
      "[Epoch 2/100] [Batch 269/347] [D loss: 0.591240] [G loss: 0.554857]\n",
      "[Epoch 2/100] [Batch 270/347] [D loss: 0.591208] [G loss: 0.551019]\n",
      "[Epoch 2/100] [Batch 271/347] [D loss: 0.591175] [G loss: 0.538798]\n",
      "[Epoch 2/100] [Batch 272/347] [D loss: 0.591142] [G loss: 0.529643]\n",
      "[Epoch 2/100] [Batch 273/347] [D loss: 0.591110] [G loss: 0.540995]\n",
      "[Epoch 2/100] [Batch 274/347] [D loss: 0.591077] [G loss: 0.574187]\n",
      "[Epoch 2/100] [Batch 275/347] [D loss: 0.591044] [G loss: 0.570504]\n",
      "[Epoch 2/100] [Batch 276/347] [D loss: 0.591012] [G loss: 0.537573]\n",
      "[Epoch 2/100] [Batch 277/347] [D loss: 0.590979] [G loss: 0.522349]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 278/347] [D loss: 0.590947] [G loss: 0.511712]\n",
      "[Epoch 2/100] [Batch 279/347] [D loss: 0.590914] [G loss: 0.513470]\n",
      "[Epoch 2/100] [Batch 280/347] [D loss: 0.590881] [G loss: 0.518284]\n",
      "[Epoch 2/100] [Batch 281/347] [D loss: 0.590849] [G loss: 0.517622]\n",
      "[Epoch 2/100] [Batch 282/347] [D loss: 0.590816] [G loss: 0.516271]\n",
      "[Epoch 2/100] [Batch 283/347] [D loss: 0.590783] [G loss: 0.517320]\n",
      "[Epoch 2/100] [Batch 284/347] [D loss: 0.590751] [G loss: 0.520138]\n",
      "[Epoch 2/100] [Batch 285/347] [D loss: 0.590718] [G loss: 0.516425]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 286/347] [D loss: 0.590685] [G loss: 0.511154]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 287/347] [D loss: 0.590653] [G loss: 0.509034]\n",
      "[Epoch 2/100] [Batch 288/347] [D loss: 0.590620] [G loss: 0.535570]\n",
      "[Epoch 2/100] [Batch 289/347] [D loss: 0.590587] [G loss: 0.539867]\n",
      "[Epoch 2/100] [Batch 290/347] [D loss: 0.590554] [G loss: 0.517565]\n",
      "[Epoch 2/100] [Batch 291/347] [D loss: 0.590522] [G loss: 0.520114]\n",
      "[Epoch 2/100] [Batch 292/347] [D loss: 0.590489] [G loss: 0.511259]\n",
      "[Epoch 2/100] [Batch 293/347] [D loss: 0.590457] [G loss: 0.527574]\n",
      "[Epoch 2/100] [Batch 294/347] [D loss: 0.590424] [G loss: 0.536569]\n",
      "[Epoch 2/100] [Batch 295/347] [D loss: 0.590391] [G loss: 0.534418]\n",
      "[Epoch 2/100] [Batch 296/347] [D loss: 0.590359] [G loss: 0.530454]\n",
      "[Epoch 2/100] [Batch 297/347] [D loss: 0.590326] [G loss: 0.546368]\n",
      "[Epoch 2/100] [Batch 298/347] [D loss: 0.590293] [G loss: 0.541237]\n",
      "[Epoch 2/100] [Batch 299/347] [D loss: 0.590260] [G loss: 0.539631]\n",
      "[Epoch 2/100] [Batch 300/347] [D loss: 0.590228] [G loss: 0.534450]\n",
      "[Epoch 2/100] [Batch 301/347] [D loss: 0.590195] [G loss: 0.530917]\n",
      "[Epoch 2/100] [Batch 302/347] [D loss: 0.590162] [G loss: 0.535613]\n",
      "[Epoch 2/100] [Batch 303/347] [D loss: 0.590130] [G loss: 0.519444]\n",
      "[Epoch 2/100] [Batch 304/347] [D loss: 0.590097] [G loss: 0.523681]\n",
      "[Epoch 2/100] [Batch 305/347] [D loss: 0.590064] [G loss: 0.536823]\n",
      "[Epoch 2/100] [Batch 306/347] [D loss: 0.590031] [G loss: 0.527992]\n",
      "[Epoch 2/100] [Batch 307/347] [D loss: 0.589999] [G loss: 0.537939]\n",
      "[Epoch 2/100] [Batch 308/347] [D loss: 0.589966] [G loss: 0.534473]\n",
      "[Epoch 2/100] [Batch 309/347] [D loss: 0.589933] [G loss: 0.517837]\n",
      "[Epoch 2/100] [Batch 310/347] [D loss: 0.589901] [G loss: 0.533354]\n",
      "[Epoch 2/100] [Batch 311/347] [D loss: 0.589868] [G loss: 0.536378]\n",
      "[Epoch 2/100] [Batch 312/347] [D loss: 0.589835] [G loss: 0.536189]\n",
      "[Epoch 2/100] [Batch 313/347] [D loss: 0.589803] [G loss: 0.535384]\n",
      "[Epoch 2/100] [Batch 314/347] [D loss: 0.589770] [G loss: 0.528979]\n",
      "[Epoch 2/100] [Batch 315/347] [D loss: 0.589737] [G loss: 0.519359]\n",
      "[Epoch 2/100] [Batch 316/347] [D loss: 0.589704] [G loss: 0.516649]\n",
      "[Epoch 2/100] [Batch 317/347] [D loss: 0.589671] [G loss: 0.535215]\n",
      "[Epoch 2/100] [Batch 318/347] [D loss: 0.589638] [G loss: 0.513129]\n",
      "[Epoch 2/100] [Batch 319/347] [D loss: 0.589606] [G loss: 0.539963]\n",
      "[Epoch 2/100] [Batch 320/347] [D loss: 0.589573] [G loss: 0.553456]\n",
      "[Epoch 2/100] [Batch 321/347] [D loss: 0.589541] [G loss: 0.542826]\n",
      "[Epoch 2/100] [Batch 322/347] [D loss: 0.589508] [G loss: 0.529854]\n",
      "[Epoch 2/100] [Batch 323/347] [D loss: 0.589475] [G loss: 0.529004]\n",
      "[Epoch 2/100] [Batch 324/347] [D loss: 0.589442] [G loss: 0.531552]\n",
      "[Epoch 2/100] [Batch 325/347] [D loss: 0.589409] [G loss: 0.520181]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 326/347] [D loss: 0.589377] [G loss: 0.508603]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 2/100] [Batch 327/347] [D loss: 0.589344] [G loss: 0.506237]\n",
      "[Epoch 2/100] [Batch 328/347] [D loss: 0.589311] [G loss: 0.509041]\n",
      "[Epoch 2/100] [Batch 329/347] [D loss: 0.589278] [G loss: 0.531339]\n",
      "[Epoch 2/100] [Batch 330/347] [D loss: 0.589245] [G loss: 0.546757]\n",
      "[Epoch 2/100] [Batch 331/347] [D loss: 0.589212] [G loss: 0.528519]\n",
      "[Epoch 2/100] [Batch 332/347] [D loss: 0.589180] [G loss: 0.518440]\n",
      "[Epoch 2/100] [Batch 333/347] [D loss: 0.589147] [G loss: 0.529956]\n",
      "[Epoch 2/100] [Batch 334/347] [D loss: 0.589114] [G loss: 0.531621]\n",
      "[Epoch 2/100] [Batch 335/347] [D loss: 0.589082] [G loss: 0.519923]\n",
      "[Epoch 2/100] [Batch 336/347] [D loss: 0.589049] [G loss: 0.507171]\n",
      "[Epoch 2/100] [Batch 337/347] [D loss: 0.589016] [G loss: 0.511865]\n",
      "[Epoch 2/100] [Batch 338/347] [D loss: 0.588983] [G loss: 0.526166]\n",
      "[Epoch 2/100] [Batch 339/347] [D loss: 0.588951] [G loss: 0.531261]\n",
      "[Epoch 2/100] [Batch 340/347] [D loss: 0.588918] [G loss: 0.531229]\n",
      "[Epoch 2/100] [Batch 341/347] [D loss: 0.588885] [G loss: 0.526128]\n",
      "[Epoch 2/100] [Batch 342/347] [D loss: 0.588852] [G loss: 0.518237]\n",
      "[Epoch 2/100] [Batch 343/347] [D loss: 0.588819] [G loss: 0.522553]\n",
      "[Epoch 2/100] [Batch 344/347] [D loss: 0.588786] [G loss: 0.520262]\n",
      "[Epoch 2/100] [Batch 345/347] [D loss: 0.588754] [G loss: 0.532167]\n",
      "[Epoch 2/100] [Batch 346/347] [D loss: 0.588721] [G loss: 0.550915]\n",
      "[Epoch 2/100] [Batch 347/347] [D loss: 0.588688] [G loss: 0.557561]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 1/347] [D loss: 0.588655] [G loss: 0.522082]\n",
      "[Epoch 3/100] [Batch 2/347] [D loss: 0.588623] [G loss: 0.527213]\n",
      "[Epoch 3/100] [Batch 3/347] [D loss: 0.588590] [G loss: 0.527064]\n",
      "[Epoch 3/100] [Batch 4/347] [D loss: 0.588557] [G loss: 0.528086]\n",
      "[Epoch 3/100] [Batch 5/347] [D loss: 0.588524] [G loss: 0.526895]\n",
      "[Epoch 3/100] [Batch 6/347] [D loss: 0.588491] [G loss: 0.526902]\n",
      "[Epoch 3/100] [Batch 7/347] [D loss: 0.588458] [G loss: 0.526261]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 8/347] [D loss: 0.588426] [G loss: 0.521125]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 9/347] [D loss: 0.588393] [G loss: 0.519693]\n",
      "[Epoch 3/100] [Batch 10/347] [D loss: 0.588360] [G loss: 0.520771]\n",
      "[Epoch 3/100] [Batch 11/347] [D loss: 0.588327] [G loss: 0.520117]\n",
      "[Epoch 3/100] [Batch 12/347] [D loss: 0.588294] [G loss: 0.520141]\n",
      "[Epoch 3/100] [Batch 13/347] [D loss: 0.588262] [G loss: 0.520143]\n",
      "[Epoch 3/100] [Batch 14/347] [D loss: 0.588229] [G loss: 0.522707]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 15/347] [D loss: 0.588196] [G loss: 0.519141]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 16/347] [D loss: 0.588163] [G loss: 0.515174]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 17/347] [D loss: 0.588130] [G loss: 0.505420]\n",
      "[Epoch 3/100] [Batch 18/347] [D loss: 0.588098] [G loss: 0.512105]\n",
      "[Epoch 3/100] [Batch 19/347] [D loss: 0.588065] [G loss: 0.508634]\n",
      "[Epoch 3/100] [Batch 20/347] [D loss: 0.588032] [G loss: 0.520976]\n",
      "[Epoch 3/100] [Batch 21/347] [D loss: 0.587999] [G loss: 0.517151]\n",
      "[Epoch 3/100] [Batch 22/347] [D loss: 0.587966] [G loss: 0.511956]\n",
      "[Epoch 3/100] [Batch 23/347] [D loss: 0.587933] [G loss: 0.506091]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 24/347] [D loss: 0.587901] [G loss: 0.504691]\n",
      "[Epoch 3/100] [Batch 25/347] [D loss: 0.587868] [G loss: 0.504872]\n",
      "[Epoch 3/100] [Batch 26/347] [D loss: 0.587835] [G loss: 0.517136]\n",
      "[Epoch 3/100] [Batch 27/347] [D loss: 0.587802] [G loss: 0.522457]\n",
      "[Epoch 3/100] [Batch 28/347] [D loss: 0.587769] [G loss: 0.521672]\n",
      "[Epoch 3/100] [Batch 29/347] [D loss: 0.587737] [G loss: 0.515912]\n",
      "[Epoch 3/100] [Batch 30/347] [D loss: 0.587704] [G loss: 0.523026]\n",
      "[Epoch 3/100] [Batch 31/347] [D loss: 0.587671] [G loss: 0.525805]\n",
      "[Epoch 3/100] [Batch 32/347] [D loss: 0.587638] [G loss: 0.523003]\n",
      "[Epoch 3/100] [Batch 33/347] [D loss: 0.587605] [G loss: 0.515530]\n",
      "[Epoch 3/100] [Batch 34/347] [D loss: 0.587572] [G loss: 0.516502]\n",
      "[Epoch 3/100] [Batch 35/347] [D loss: 0.587539] [G loss: 0.515142]\n",
      "[Epoch 3/100] [Batch 36/347] [D loss: 0.587507] [G loss: 0.508608]\n",
      "[Epoch 3/100] [Batch 37/347] [D loss: 0.587474] [G loss: 0.526278]\n",
      "[Epoch 3/100] [Batch 38/347] [D loss: 0.587441] [G loss: 0.541656]\n",
      "[Epoch 3/100] [Batch 39/347] [D loss: 0.587408] [G loss: 0.532374]\n",
      "[Epoch 3/100] [Batch 40/347] [D loss: 0.587375] [G loss: 0.529801]\n",
      "[Epoch 3/100] [Batch 41/347] [D loss: 0.587343] [G loss: 0.531302]\n",
      "[Epoch 3/100] [Batch 42/347] [D loss: 0.587310] [G loss: 0.524426]\n",
      "[Epoch 3/100] [Batch 43/347] [D loss: 0.587277] [G loss: 0.511332]\n",
      "[Epoch 3/100] [Batch 44/347] [D loss: 0.587244] [G loss: 0.512513]\n",
      "[Epoch 3/100] [Batch 45/347] [D loss: 0.587211] [G loss: 0.530141]\n",
      "[Epoch 3/100] [Batch 46/347] [D loss: 0.587179] [G loss: 0.525132]\n",
      "[Epoch 3/100] [Batch 47/347] [D loss: 0.587146] [G loss: 0.507849]\n",
      "[Epoch 3/100] [Batch 48/347] [D loss: 0.587112] [G loss: 0.539851]\n",
      "[Epoch 3/100] [Batch 49/347] [D loss: 0.587079] [G loss: 0.548374]\n",
      "[Epoch 3/100] [Batch 50/347] [D loss: 0.587047] [G loss: 0.564182]\n",
      "[Epoch 3/100] [Batch 51/347] [D loss: 0.587014] [G loss: 0.548950]\n",
      "[Epoch 3/100] [Batch 52/347] [D loss: 0.586981] [G loss: 0.515277]\n",
      "[Epoch 3/100] [Batch 53/347] [D loss: 0.586949] [G loss: 0.511501]\n",
      "[Epoch 3/100] [Batch 54/347] [D loss: 0.586916] [G loss: 0.563602]\n",
      "[Epoch 3/100] [Batch 55/347] [D loss: 0.586883] [G loss: 0.585591]\n",
      "[Epoch 3/100] [Batch 56/347] [D loss: 0.586850] [G loss: 0.572470]\n",
      "[Epoch 3/100] [Batch 57/347] [D loss: 0.586817] [G loss: 0.538211]\n",
      "[Epoch 3/100] [Batch 58/347] [D loss: 0.586785] [G loss: 0.514542]\n",
      "[Epoch 3/100] [Batch 59/347] [D loss: 0.586752] [G loss: 0.520801]\n",
      "[Epoch 3/100] [Batch 60/347] [D loss: 0.586719] [G loss: 0.538890]\n",
      "[Epoch 3/100] [Batch 61/347] [D loss: 0.586686] [G loss: 0.550699]\n",
      "[Epoch 3/100] [Batch 62/347] [D loss: 0.586653] [G loss: 0.574077]\n",
      "[Epoch 3/100] [Batch 63/347] [D loss: 0.586620] [G loss: 0.575993]\n",
      "[Epoch 3/100] [Batch 64/347] [D loss: 0.586587] [G loss: 0.539135]\n",
      "[Epoch 3/100] [Batch 65/347] [D loss: 0.586555] [G loss: 0.520380]\n",
      "[Epoch 3/100] [Batch 66/347] [D loss: 0.586522] [G loss: 0.523082]\n",
      "[Epoch 3/100] [Batch 67/347] [D loss: 0.586489] [G loss: 0.521711]\n",
      "[Epoch 3/100] [Batch 68/347] [D loss: 0.586456] [G loss: 0.539198]\n",
      "[Epoch 3/100] [Batch 69/347] [D loss: 0.586423] [G loss: 0.557315]\n",
      "[Epoch 3/100] [Batch 70/347] [D loss: 0.586390] [G loss: 0.555838]\n",
      "[Epoch 3/100] [Batch 71/347] [D loss: 0.586358] [G loss: 0.558376]\n",
      "[Epoch 3/100] [Batch 72/347] [D loss: 0.586325] [G loss: 0.560801]\n",
      "[Epoch 3/100] [Batch 73/347] [D loss: 0.586292] [G loss: 0.535765]\n",
      "[Epoch 3/100] [Batch 74/347] [D loss: 0.586260] [G loss: 0.521597]\n",
      "[Epoch 3/100] [Batch 75/347] [D loss: 0.586227] [G loss: 0.550538]\n",
      "[Epoch 3/100] [Batch 76/347] [D loss: 0.586194] [G loss: 0.551670]\n",
      "[Epoch 3/100] [Batch 77/347] [D loss: 0.586161] [G loss: 0.516942]\n",
      "[Epoch 3/100] [Batch 78/347] [D loss: 0.586128] [G loss: 0.530095]\n",
      "[Epoch 3/100] [Batch 79/347] [D loss: 0.586096] [G loss: 0.532067]\n",
      "[Epoch 3/100] [Batch 80/347] [D loss: 0.586063] [G loss: 0.529664]\n",
      "[Epoch 3/100] [Batch 81/347] [D loss: 0.586030] [G loss: 0.535194]\n",
      "[Epoch 3/100] [Batch 82/347] [D loss: 0.585997] [G loss: 0.540391]\n",
      "[Epoch 3/100] [Batch 83/347] [D loss: 0.585964] [G loss: 0.532791]\n",
      "[Epoch 3/100] [Batch 84/347] [D loss: 0.585931] [G loss: 0.539540]\n",
      "[Epoch 3/100] [Batch 85/347] [D loss: 0.585898] [G loss: 0.540177]\n",
      "[Epoch 3/100] [Batch 86/347] [D loss: 0.585865] [G loss: 0.534398]\n",
      "[Epoch 3/100] [Batch 87/347] [D loss: 0.585833] [G loss: 0.531842]\n",
      "[Epoch 3/100] [Batch 88/347] [D loss: 0.585800] [G loss: 0.534810]\n",
      "[Epoch 3/100] [Batch 89/347] [D loss: 0.585767] [G loss: 0.537724]\n",
      "[Epoch 3/100] [Batch 90/347] [D loss: 0.585735] [G loss: 0.533434]\n",
      "[Epoch 3/100] [Batch 91/347] [D loss: 0.585702] [G loss: 0.531475]\n",
      "[Epoch 3/100] [Batch 92/347] [D loss: 0.585669] [G loss: 0.532392]\n",
      "[Epoch 3/100] [Batch 93/347] [D loss: 0.585636] [G loss: 0.529874]\n",
      "[Epoch 3/100] [Batch 94/347] [D loss: 0.585603] [G loss: 0.525781]\n",
      "[Epoch 3/100] [Batch 95/347] [D loss: 0.585571] [G loss: 0.525605]\n",
      "[Epoch 3/100] [Batch 96/347] [D loss: 0.585538] [G loss: 0.520312]\n",
      "[Epoch 3/100] [Batch 97/347] [D loss: 0.585505] [G loss: 0.514607]\n",
      "[Epoch 3/100] [Batch 98/347] [D loss: 0.585472] [G loss: 0.518847]\n",
      "[Epoch 3/100] [Batch 99/347] [D loss: 0.585439] [G loss: 0.521957]\n",
      "[Epoch 3/100] [Batch 100/347] [D loss: 0.585407] [G loss: 0.517675]\n",
      "[Epoch 3/100] [Batch 101/347] [D loss: 0.585374] [G loss: 0.511853]\n",
      "[Epoch 3/100] [Batch 102/347] [D loss: 0.585341] [G loss: 0.512735]\n",
      "[Epoch 3/100] [Batch 103/347] [D loss: 0.585308] [G loss: 0.512660]\n",
      "[Epoch 3/100] [Batch 104/347] [D loss: 0.585275] [G loss: 0.510766]\n",
      "[Epoch 3/100] [Batch 105/347] [D loss: 0.585242] [G loss: 0.513415]\n",
      "[Epoch 3/100] [Batch 106/347] [D loss: 0.585210] [G loss: 0.513377]\n",
      "[Epoch 3/100] [Batch 107/347] [D loss: 0.585177] [G loss: 0.507971]\n",
      "[Epoch 3/100] [Batch 108/347] [D loss: 0.585144] [G loss: 0.525529]\n",
      "[Epoch 3/100] [Batch 109/347] [D loss: 0.585111] [G loss: 0.519145]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 110/347] [D loss: 0.585079] [G loss: 0.501641]\n",
      "[Epoch 3/100] [Batch 111/347] [D loss: 0.585046] [G loss: 0.513845]\n",
      "[Epoch 3/100] [Batch 112/347] [D loss: 0.585013] [G loss: 0.512405]\n",
      "[Epoch 3/100] [Batch 113/347] [D loss: 0.584980] [G loss: 0.516739]\n",
      "[Epoch 3/100] [Batch 114/347] [D loss: 0.584948] [G loss: 0.537615]\n",
      "[Epoch 3/100] [Batch 115/347] [D loss: 0.584915] [G loss: 0.538940]\n",
      "[Epoch 3/100] [Batch 116/347] [D loss: 0.584882] [G loss: 0.533211]\n",
      "[Epoch 3/100] [Batch 117/347] [D loss: 0.584849] [G loss: 0.507271]\n",
      "[Epoch 3/100] [Batch 118/347] [D loss: 0.584816] [G loss: 0.516496]\n",
      "[Epoch 3/100] [Batch 119/347] [D loss: 0.584783] [G loss: 0.518824]\n",
      "[Epoch 3/100] [Batch 120/347] [D loss: 0.584750] [G loss: 0.517976]\n",
      "[Epoch 3/100] [Batch 121/347] [D loss: 0.584718] [G loss: 0.516403]\n",
      "[Epoch 3/100] [Batch 122/347] [D loss: 0.584685] [G loss: 0.503554]\n",
      "[Epoch 3/100] [Batch 123/347] [D loss: 0.584653] [G loss: 0.502177]\n",
      "[Epoch 3/100] [Batch 124/347] [D loss: 0.584620] [G loss: 0.503652]\n",
      "[Epoch 3/100] [Batch 125/347] [D loss: 0.584587] [G loss: 0.504231]\n",
      "[Epoch 3/100] [Batch 126/347] [D loss: 0.584554] [G loss: 0.517102]\n",
      "[Epoch 3/100] [Batch 127/347] [D loss: 0.584522] [G loss: 0.518812]\n",
      "[Epoch 3/100] [Batch 128/347] [D loss: 0.584489] [G loss: 0.513438]\n",
      "[Epoch 3/100] [Batch 129/347] [D loss: 0.584456] [G loss: 0.508730]\n",
      "[Epoch 3/100] [Batch 130/347] [D loss: 0.584423] [G loss: 0.512098]\n",
      "[Epoch 3/100] [Batch 131/347] [D loss: 0.584390] [G loss: 0.511810]\n",
      "[Epoch 3/100] [Batch 132/347] [D loss: 0.584357] [G loss: 0.536480]\n",
      "[Epoch 3/100] [Batch 133/347] [D loss: 0.584325] [G loss: 0.543255]\n",
      "[Epoch 3/100] [Batch 134/347] [D loss: 0.584292] [G loss: 0.558228]\n",
      "[Epoch 3/100] [Batch 135/347] [D loss: 0.584259] [G loss: 0.567237]\n",
      "[Epoch 3/100] [Batch 136/347] [D loss: 0.584227] [G loss: 0.525477]\n",
      "[Epoch 3/100] [Batch 137/347] [D loss: 0.584194] [G loss: 0.511292]\n",
      "[Epoch 3/100] [Batch 138/347] [D loss: 0.584161] [G loss: 0.530026]\n",
      "[Epoch 3/100] [Batch 139/347] [D loss: 0.584128] [G loss: 0.553586]\n",
      "[Epoch 3/100] [Batch 140/347] [D loss: 0.584096] [G loss: 0.564771]\n",
      "[Epoch 3/100] [Batch 141/347] [D loss: 0.584063] [G loss: 0.571363]\n",
      "[Epoch 3/100] [Batch 142/347] [D loss: 0.584030] [G loss: 0.579118]\n",
      "[Epoch 3/100] [Batch 143/347] [D loss: 0.583998] [G loss: 0.600943]\n",
      "[Epoch 3/100] [Batch 144/347] [D loss: 0.583965] [G loss: 0.602942]\n",
      "[Epoch 3/100] [Batch 145/347] [D loss: 0.583932] [G loss: 0.588663]\n",
      "[Epoch 3/100] [Batch 146/347] [D loss: 0.583900] [G loss: 0.571653]\n",
      "[Epoch 3/100] [Batch 147/347] [D loss: 0.583867] [G loss: 0.543344]\n",
      "[Epoch 3/100] [Batch 148/347] [D loss: 0.583834] [G loss: 0.530609]\n",
      "[Epoch 3/100] [Batch 149/347] [D loss: 0.583802] [G loss: 0.543225]\n",
      "[Epoch 3/100] [Batch 150/347] [D loss: 0.583769] [G loss: 0.542944]\n",
      "[Epoch 3/100] [Batch 151/347] [D loss: 0.583736] [G loss: 0.531420]\n",
      "[Epoch 3/100] [Batch 152/347] [D loss: 0.583704] [G loss: 0.541879]\n",
      "[Epoch 3/100] [Batch 153/347] [D loss: 0.583671] [G loss: 0.562009]\n",
      "[Epoch 3/100] [Batch 154/347] [D loss: 0.583638] [G loss: 0.565662]\n",
      "[Epoch 3/100] [Batch 155/347] [D loss: 0.583605] [G loss: 0.552417]\n",
      "[Epoch 3/100] [Batch 156/347] [D loss: 0.583573] [G loss: 0.535512]\n",
      "[Epoch 3/100] [Batch 157/347] [D loss: 0.583540] [G loss: 0.541469]\n",
      "[Epoch 3/100] [Batch 158/347] [D loss: 0.583507] [G loss: 0.564593]\n",
      "[Epoch 3/100] [Batch 159/347] [D loss: 0.583475] [G loss: 0.561517]\n",
      "[Epoch 3/100] [Batch 160/347] [D loss: 0.583442] [G loss: 0.541015]\n",
      "[Epoch 3/100] [Batch 161/347] [D loss: 0.583410] [G loss: 0.532075]\n",
      "[Epoch 3/100] [Batch 162/347] [D loss: 0.583377] [G loss: 0.537248]\n",
      "[Epoch 3/100] [Batch 163/347] [D loss: 0.583344] [G loss: 0.555316]\n",
      "[Epoch 3/100] [Batch 164/347] [D loss: 0.583311] [G loss: 0.569801]\n",
      "[Epoch 3/100] [Batch 165/347] [D loss: 0.583278] [G loss: 0.560261]\n",
      "[Epoch 3/100] [Batch 166/347] [D loss: 0.583246] [G loss: 0.521650]\n",
      "[Epoch 3/100] [Batch 167/347] [D loss: 0.583213] [G loss: 0.523643]\n",
      "[Epoch 3/100] [Batch 168/347] [D loss: 0.583181] [G loss: 0.534617]\n",
      "[Epoch 3/100] [Batch 169/347] [D loss: 0.583148] [G loss: 0.533793]\n",
      "[Epoch 3/100] [Batch 170/347] [D loss: 0.583115] [G loss: 0.533348]\n",
      "[Epoch 3/100] [Batch 171/347] [D loss: 0.583082] [G loss: 0.545700]\n",
      "[Epoch 3/100] [Batch 172/347] [D loss: 0.583049] [G loss: 0.550841]\n",
      "[Epoch 3/100] [Batch 173/347] [D loss: 0.583017] [G loss: 0.539626]\n",
      "[Epoch 3/100] [Batch 174/347] [D loss: 0.582984] [G loss: 0.537082]\n",
      "[Epoch 3/100] [Batch 175/347] [D loss: 0.582952] [G loss: 0.546593]\n",
      "[Epoch 3/100] [Batch 176/347] [D loss: 0.582919] [G loss: 0.559710]\n",
      "[Epoch 3/100] [Batch 177/347] [D loss: 0.582886] [G loss: 0.560095]\n",
      "[Epoch 3/100] [Batch 178/347] [D loss: 0.582854] [G loss: 0.553750]\n",
      "[Epoch 3/100] [Batch 179/347] [D loss: 0.582821] [G loss: 0.546645]\n",
      "[Epoch 3/100] [Batch 180/347] [D loss: 0.582788] [G loss: 0.539812]\n",
      "[Epoch 3/100] [Batch 181/347] [D loss: 0.582756] [G loss: 0.539610]\n",
      "[Epoch 3/100] [Batch 182/347] [D loss: 0.582723] [G loss: 0.536771]\n",
      "[Epoch 3/100] [Batch 183/347] [D loss: 0.582690] [G loss: 0.540100]\n",
      "[Epoch 3/100] [Batch 184/347] [D loss: 0.582658] [G loss: 0.543235]\n",
      "[Epoch 3/100] [Batch 185/347] [D loss: 0.582625] [G loss: 0.541126]\n",
      "[Epoch 3/100] [Batch 186/347] [D loss: 0.582592] [G loss: 0.540236]\n",
      "[Epoch 3/100] [Batch 187/347] [D loss: 0.582560] [G loss: 0.534315]\n",
      "[Epoch 3/100] [Batch 188/347] [D loss: 0.582527] [G loss: 0.530437]\n",
      "[Epoch 3/100] [Batch 189/347] [D loss: 0.582494] [G loss: 0.528872]\n",
      "[Epoch 3/100] [Batch 190/347] [D loss: 0.582462] [G loss: 0.516273]\n",
      "[Epoch 3/100] [Batch 191/347] [D loss: 0.582429] [G loss: 0.502858]\n",
      "[Epoch 3/100] [Batch 192/347] [D loss: 0.582396] [G loss: 0.503548]\n",
      "[Epoch 3/100] [Batch 193/347] [D loss: 0.582364] [G loss: 0.511004]\n",
      "[Epoch 3/100] [Batch 194/347] [D loss: 0.582331] [G loss: 0.505645]\n",
      "[Epoch 3/100] [Batch 195/347] [D loss: 0.582299] [G loss: 0.506428]\n",
      "[Epoch 3/100] [Batch 196/347] [D loss: 0.582266] [G loss: 0.505322]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 197/347] [D loss: 0.582233] [G loss: 0.501506]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 198/347] [D loss: 0.582201] [G loss: 0.498896]\n",
      "[Epoch 3/100] [Batch 199/347] [D loss: 0.582168] [G loss: 0.500862]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 200/347] [D loss: 0.582135] [G loss: 0.496447]\n",
      "[Epoch 3/100] [Batch 201/347] [D loss: 0.582103] [G loss: 0.499481]\n",
      "[Epoch 3/100] [Batch 202/347] [D loss: 0.582070] [G loss: 0.511231]\n",
      "[Epoch 3/100] [Batch 203/347] [D loss: 0.582038] [G loss: 0.520009]\n",
      "[Epoch 3/100] [Batch 204/347] [D loss: 0.582005] [G loss: 0.516598]\n",
      "[Epoch 3/100] [Batch 205/347] [D loss: 0.581972] [G loss: 0.508743]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 206/347] [D loss: 0.581940] [G loss: 0.496422]\n",
      "[Epoch 3/100] [Batch 207/347] [D loss: 0.581907] [G loss: 0.505151]\n",
      "[Epoch 3/100] [Batch 208/347] [D loss: 0.581875] [G loss: 0.506229]\n",
      "[Epoch 3/100] [Batch 209/347] [D loss: 0.581842] [G loss: 0.500885]\n",
      "[Epoch 3/100] [Batch 210/347] [D loss: 0.581810] [G loss: 0.507406]\n",
      "[Epoch 3/100] [Batch 211/347] [D loss: 0.581777] [G loss: 0.505170]\n",
      "[Epoch 3/100] [Batch 212/347] [D loss: 0.581744] [G loss: 0.503732]\n",
      "[Epoch 3/100] [Batch 213/347] [D loss: 0.581712] [G loss: 0.509213]\n",
      "[Epoch 3/100] [Batch 214/347] [D loss: 0.581679] [G loss: 0.519745]\n",
      "[Epoch 3/100] [Batch 215/347] [D loss: 0.581647] [G loss: 0.528025]\n",
      "[Epoch 3/100] [Batch 216/347] [D loss: 0.581614] [G loss: 0.507989]\n",
      "[Epoch 3/100] [Batch 217/347] [D loss: 0.581582] [G loss: 0.508450]\n",
      "[Epoch 3/100] [Batch 218/347] [D loss: 0.581549] [G loss: 0.514833]\n",
      "[Epoch 3/100] [Batch 219/347] [D loss: 0.581517] [G loss: 0.526801]\n",
      "[Epoch 3/100] [Batch 220/347] [D loss: 0.581484] [G loss: 0.542524]\n",
      "[Epoch 3/100] [Batch 221/347] [D loss: 0.581452] [G loss: 0.543785]\n",
      "[Epoch 3/100] [Batch 222/347] [D loss: 0.581419] [G loss: 0.535691]\n",
      "[Epoch 3/100] [Batch 223/347] [D loss: 0.581386] [G loss: 0.534053]\n",
      "[Epoch 3/100] [Batch 224/347] [D loss: 0.581354] [G loss: 0.529566]\n",
      "[Epoch 3/100] [Batch 225/347] [D loss: 0.581321] [G loss: 0.515601]\n",
      "[Epoch 3/100] [Batch 226/347] [D loss: 0.581288] [G loss: 0.516482]\n",
      "[Epoch 3/100] [Batch 227/347] [D loss: 0.581256] [G loss: 0.527334]\n",
      "[Epoch 3/100] [Batch 228/347] [D loss: 0.581223] [G loss: 0.529428]\n",
      "[Epoch 3/100] [Batch 229/347] [D loss: 0.581191] [G loss: 0.525138]\n",
      "[Epoch 3/100] [Batch 230/347] [D loss: 0.581159] [G loss: 0.521769]\n",
      "[Epoch 3/100] [Batch 231/347] [D loss: 0.581126] [G loss: 0.521917]\n",
      "[Epoch 3/100] [Batch 232/347] [D loss: 0.581094] [G loss: 0.517726]\n",
      "[Epoch 3/100] [Batch 233/347] [D loss: 0.581061] [G loss: 0.515899]\n",
      "[Epoch 3/100] [Batch 234/347] [D loss: 0.581029] [G loss: 0.520630]\n",
      "[Epoch 3/100] [Batch 235/347] [D loss: 0.580996] [G loss: 0.509275]\n",
      "[Epoch 3/100] [Batch 236/347] [D loss: 0.580964] [G loss: 0.500360]\n",
      "[Epoch 3/100] [Batch 237/347] [D loss: 0.580931] [G loss: 0.503222]\n",
      "[Epoch 3/100] [Batch 238/347] [D loss: 0.580899] [G loss: 0.507386]\n",
      "[Epoch 3/100] [Batch 239/347] [D loss: 0.580866] [G loss: 0.505556]\n",
      "[Epoch 3/100] [Batch 240/347] [D loss: 0.580834] [G loss: 0.501736]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 241/347] [D loss: 0.580801] [G loss: 0.495757]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 242/347] [D loss: 0.580769] [G loss: 0.493530]\n",
      "[Epoch 3/100] [Batch 243/347] [D loss: 0.580736] [G loss: 0.500695]\n",
      "[Epoch 3/100] [Batch 244/347] [D loss: 0.580704] [G loss: 0.509069]\n",
      "[Epoch 3/100] [Batch 245/347] [D loss: 0.580671] [G loss: 0.508019]\n",
      "[Epoch 3/100] [Batch 246/347] [D loss: 0.580639] [G loss: 0.500935]\n",
      "[Epoch 3/100] [Batch 247/347] [D loss: 0.580606] [G loss: 0.516063]\n",
      "[Epoch 3/100] [Batch 248/347] [D loss: 0.580574] [G loss: 0.521249]\n",
      "[Epoch 3/100] [Batch 249/347] [D loss: 0.580541] [G loss: 0.528109]\n",
      "[Epoch 3/100] [Batch 250/347] [D loss: 0.580509] [G loss: 0.519824]\n",
      "[Epoch 3/100] [Batch 251/347] [D loss: 0.580477] [G loss: 0.498691]\n",
      "[Epoch 3/100] [Batch 252/347] [D loss: 0.580444] [G loss: 0.501702]\n",
      "[Epoch 3/100] [Batch 253/347] [D loss: 0.580412] [G loss: 0.502200]\n",
      "[Epoch 3/100] [Batch 254/347] [D loss: 0.580379] [G loss: 0.500497]\n",
      "[Epoch 3/100] [Batch 255/347] [D loss: 0.580347] [G loss: 0.498922]\n",
      "[Epoch 3/100] [Batch 256/347] [D loss: 0.580314] [G loss: 0.503749]\n",
      "[Epoch 3/100] [Batch 257/347] [D loss: 0.580282] [G loss: 0.505499]\n",
      "[Epoch 3/100] [Batch 258/347] [D loss: 0.580250] [G loss: 0.499377]\n",
      "[Epoch 3/100] [Batch 259/347] [D loss: 0.580217] [G loss: 0.519257]\n",
      "[Epoch 3/100] [Batch 260/347] [D loss: 0.580184] [G loss: 0.533827]\n",
      "[Epoch 3/100] [Batch 261/347] [D loss: 0.580152] [G loss: 0.526535]\n",
      "[Epoch 3/100] [Batch 262/347] [D loss: 0.580120] [G loss: 0.511579]\n",
      "[Epoch 3/100] [Batch 263/347] [D loss: 0.580087] [G loss: 0.512658]\n",
      "[Epoch 3/100] [Batch 264/347] [D loss: 0.580055] [G loss: 0.527107]\n",
      "[Epoch 3/100] [Batch 265/347] [D loss: 0.580023] [G loss: 0.532091]\n",
      "[Epoch 3/100] [Batch 266/347] [D loss: 0.579990] [G loss: 0.524740]\n",
      "[Epoch 3/100] [Batch 267/347] [D loss: 0.579958] [G loss: 0.517793]\n",
      "[Epoch 3/100] [Batch 268/347] [D loss: 0.579926] [G loss: 0.524446]\n",
      "[Epoch 3/100] [Batch 269/347] [D loss: 0.579893] [G loss: 0.535304]\n",
      "[Epoch 3/100] [Batch 270/347] [D loss: 0.579861] [G loss: 0.531532]\n",
      "[Epoch 3/100] [Batch 271/347] [D loss: 0.579828] [G loss: 0.519413]\n",
      "[Epoch 3/100] [Batch 272/347] [D loss: 0.579796] [G loss: 0.510435]\n",
      "[Epoch 3/100] [Batch 273/347] [D loss: 0.579764] [G loss: 0.521848]\n",
      "[Epoch 3/100] [Batch 274/347] [D loss: 0.579731] [G loss: 0.555192]\n",
      "[Epoch 3/100] [Batch 275/347] [D loss: 0.579699] [G loss: 0.551658]\n",
      "[Epoch 3/100] [Batch 276/347] [D loss: 0.579667] [G loss: 0.518834]\n",
      "[Epoch 3/100] [Batch 277/347] [D loss: 0.579635] [G loss: 0.503807]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 278/347] [D loss: 0.579602] [G loss: 0.492973]\n",
      "[Epoch 3/100] [Batch 279/347] [D loss: 0.579570] [G loss: 0.495241]\n",
      "[Epoch 3/100] [Batch 280/347] [D loss: 0.579537] [G loss: 0.498562]\n",
      "[Epoch 3/100] [Batch 281/347] [D loss: 0.579505] [G loss: 0.497638]\n",
      "[Epoch 3/100] [Batch 282/347] [D loss: 0.579473] [G loss: 0.496752]\n",
      "[Epoch 3/100] [Batch 283/347] [D loss: 0.579440] [G loss: 0.498472]\n",
      "[Epoch 3/100] [Batch 284/347] [D loss: 0.579408] [G loss: 0.501301]\n",
      "[Epoch 3/100] [Batch 285/347] [D loss: 0.579376] [G loss: 0.497895]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 286/347] [D loss: 0.579343] [G loss: 0.491797]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 287/347] [D loss: 0.579311] [G loss: 0.491111]\n",
      "[Epoch 3/100] [Batch 288/347] [D loss: 0.579279] [G loss: 0.515690]\n",
      "[Epoch 3/100] [Batch 289/347] [D loss: 0.579246] [G loss: 0.519824]\n",
      "[Epoch 3/100] [Batch 290/347] [D loss: 0.579214] [G loss: 0.497338]\n",
      "[Epoch 3/100] [Batch 291/347] [D loss: 0.579182] [G loss: 0.499839]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 292/347] [D loss: 0.579149] [G loss: 0.490921]\n",
      "[Epoch 3/100] [Batch 293/347] [D loss: 0.579117] [G loss: 0.509641]\n",
      "[Epoch 3/100] [Batch 294/347] [D loss: 0.579085] [G loss: 0.519734]\n",
      "[Epoch 3/100] [Batch 295/347] [D loss: 0.579053] [G loss: 0.517600]\n",
      "[Epoch 3/100] [Batch 296/347] [D loss: 0.579020] [G loss: 0.513678]\n",
      "[Epoch 3/100] [Batch 297/347] [D loss: 0.578988] [G loss: 0.528092]\n",
      "[Epoch 3/100] [Batch 298/347] [D loss: 0.578956] [G loss: 0.522992]\n",
      "[Epoch 3/100] [Batch 299/347] [D loss: 0.578924] [G loss: 0.521514]\n",
      "[Epoch 3/100] [Batch 300/347] [D loss: 0.578891] [G loss: 0.516508]\n",
      "[Epoch 3/100] [Batch 301/347] [D loss: 0.578859] [G loss: 0.514537]\n",
      "[Epoch 3/100] [Batch 302/347] [D loss: 0.578827] [G loss: 0.519200]\n",
      "[Epoch 3/100] [Batch 303/347] [D loss: 0.578795] [G loss: 0.503128]\n",
      "[Epoch 3/100] [Batch 304/347] [D loss: 0.578762] [G loss: 0.501063]\n",
      "[Epoch 3/100] [Batch 305/347] [D loss: 0.578730] [G loss: 0.514209]\n",
      "[Epoch 3/100] [Batch 306/347] [D loss: 0.578698] [G loss: 0.505345]\n",
      "[Epoch 3/100] [Batch 307/347] [D loss: 0.578666] [G loss: 0.515941]\n",
      "[Epoch 3/100] [Batch 308/347] [D loss: 0.578633] [G loss: 0.512398]\n",
      "[Epoch 3/100] [Batch 309/347] [D loss: 0.578602] [G loss: 0.495284]\n",
      "[Epoch 3/100] [Batch 310/347] [D loss: 0.578569] [G loss: 0.516539]\n",
      "[Epoch 3/100] [Batch 311/347] [D loss: 0.578537] [G loss: 0.519588]\n",
      "[Epoch 3/100] [Batch 312/347] [D loss: 0.578505] [G loss: 0.519426]\n",
      "[Epoch 3/100] [Batch 313/347] [D loss: 0.578473] [G loss: 0.518659]\n",
      "[Epoch 3/100] [Batch 314/347] [D loss: 0.578440] [G loss: 0.512313]\n",
      "[Epoch 3/100] [Batch 315/347] [D loss: 0.578408] [G loss: 0.502771]\n",
      "[Epoch 3/100] [Batch 316/347] [D loss: 0.578376] [G loss: 0.494338]\n",
      "[Epoch 3/100] [Batch 317/347] [D loss: 0.578344] [G loss: 0.512871]\n",
      "[Epoch 3/100] [Batch 318/347] [D loss: 0.578311] [G loss: 0.491044]\n",
      "[Epoch 3/100] [Batch 319/347] [D loss: 0.578280] [G loss: 0.523188]\n",
      "[Epoch 3/100] [Batch 320/347] [D loss: 0.578248] [G loss: 0.536328]\n",
      "[Epoch 3/100] [Batch 321/347] [D loss: 0.578215] [G loss: 0.525401]\n",
      "[Epoch 3/100] [Batch 322/347] [D loss: 0.578183] [G loss: 0.512175]\n",
      "[Epoch 3/100] [Batch 323/347] [D loss: 0.578151] [G loss: 0.511122]\n",
      "[Epoch 3/100] [Batch 324/347] [D loss: 0.578119] [G loss: 0.513531]\n",
      "[Epoch 3/100] [Batch 325/347] [D loss: 0.578087] [G loss: 0.502002]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 326/347] [D loss: 0.578054] [G loss: 0.489463]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 3/100] [Batch 327/347] [D loss: 0.578022] [G loss: 0.487308]\n",
      "[Epoch 3/100] [Batch 328/347] [D loss: 0.577990] [G loss: 0.490056]\n",
      "[Epoch 3/100] [Batch 329/347] [D loss: 0.577958] [G loss: 0.511710]\n",
      "[Epoch 3/100] [Batch 330/347] [D loss: 0.577926] [G loss: 0.527588]\n",
      "[Epoch 3/100] [Batch 331/347] [D loss: 0.577894] [G loss: 0.509771]\n",
      "[Epoch 3/100] [Batch 332/347] [D loss: 0.577862] [G loss: 0.497729]\n",
      "[Epoch 3/100] [Batch 333/347] [D loss: 0.577830] [G loss: 0.508904]\n",
      "[Epoch 3/100] [Batch 334/347] [D loss: 0.577798] [G loss: 0.510248]\n",
      "[Epoch 3/100] [Batch 335/347] [D loss: 0.577766] [G loss: 0.498260]\n",
      "[Epoch 3/100] [Batch 336/347] [D loss: 0.577734] [G loss: 0.487921]\n",
      "[Epoch 3/100] [Batch 337/347] [D loss: 0.577701] [G loss: 0.490171]\n",
      "[Epoch 3/100] [Batch 338/347] [D loss: 0.577669] [G loss: 0.504739]\n",
      "[Epoch 3/100] [Batch 339/347] [D loss: 0.577637] [G loss: 0.510046]\n",
      "[Epoch 3/100] [Batch 340/347] [D loss: 0.577605] [G loss: 0.510273]\n",
      "[Epoch 3/100] [Batch 341/347] [D loss: 0.577573] [G loss: 0.505315]\n",
      "[Epoch 3/100] [Batch 342/347] [D loss: 0.577541] [G loss: 0.497649]\n",
      "[Epoch 3/100] [Batch 343/347] [D loss: 0.577509] [G loss: 0.502138]\n",
      "[Epoch 3/100] [Batch 344/347] [D loss: 0.577477] [G loss: 0.501459]\n",
      "[Epoch 3/100] [Batch 345/347] [D loss: 0.577445] [G loss: 0.513052]\n",
      "[Epoch 3/100] [Batch 346/347] [D loss: 0.577413] [G loss: 0.531686]\n",
      "[Epoch 3/100] [Batch 347/347] [D loss: 0.577381] [G loss: 0.538183]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 1/347] [D loss: 0.577349] [G loss: 0.502587]\n",
      "[Epoch 4/100] [Batch 2/347] [D loss: 0.577317] [G loss: 0.507666]\n",
      "[Epoch 4/100] [Batch 3/347] [D loss: 0.577285] [G loss: 0.507449]\n",
      "[Epoch 4/100] [Batch 4/347] [D loss: 0.577253] [G loss: 0.508433]\n",
      "[Epoch 4/100] [Batch 5/347] [D loss: 0.577221] [G loss: 0.507230]\n",
      "[Epoch 4/100] [Batch 6/347] [D loss: 0.577189] [G loss: 0.507236]\n",
      "[Epoch 4/100] [Batch 7/347] [D loss: 0.577157] [G loss: 0.506657]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 8/347] [D loss: 0.577125] [G loss: 0.501558]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 9/347] [D loss: 0.577093] [G loss: 0.500100]\n",
      "[Epoch 4/100] [Batch 10/347] [D loss: 0.577061] [G loss: 0.501250]\n",
      "[Epoch 4/100] [Batch 11/347] [D loss: 0.577029] [G loss: 0.500681]\n",
      "[Epoch 4/100] [Batch 12/347] [D loss: 0.576997] [G loss: 0.500706]\n",
      "[Epoch 4/100] [Batch 13/347] [D loss: 0.576965] [G loss: 0.500396]\n",
      "[Epoch 4/100] [Batch 14/347] [D loss: 0.576933] [G loss: 0.502886]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 15/347] [D loss: 0.576901] [G loss: 0.499308]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 16/347] [D loss: 0.576869] [G loss: 0.495323]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 17/347] [D loss: 0.576837] [G loss: 0.485446]\n",
      "[Epoch 4/100] [Batch 18/347] [D loss: 0.576805] [G loss: 0.492729]\n",
      "[Epoch 4/100] [Batch 19/347] [D loss: 0.576773] [G loss: 0.488669]\n",
      "[Epoch 4/100] [Batch 20/347] [D loss: 0.576741] [G loss: 0.501280]\n",
      "[Epoch 4/100] [Batch 21/347] [D loss: 0.576709] [G loss: 0.497464]\n",
      "[Epoch 4/100] [Batch 22/347] [D loss: 0.576677] [G loss: 0.492294]\n",
      "[Epoch 4/100] [Batch 23/347] [D loss: 0.576645] [G loss: 0.486822]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 24/347] [D loss: 0.576613] [G loss: 0.485158]\n",
      "[Epoch 4/100] [Batch 25/347] [D loss: 0.576582] [G loss: 0.485570]\n",
      "[Epoch 4/100] [Batch 26/347] [D loss: 0.576550] [G loss: 0.497484]\n",
      "[Epoch 4/100] [Batch 27/347] [D loss: 0.576517] [G loss: 0.502755]\n",
      "[Epoch 4/100] [Batch 28/347] [D loss: 0.576486] [G loss: 0.501888]\n",
      "[Epoch 4/100] [Batch 29/347] [D loss: 0.576454] [G loss: 0.496500]\n",
      "[Epoch 4/100] [Batch 30/347] [D loss: 0.576422] [G loss: 0.503624]\n",
      "[Epoch 4/100] [Batch 31/347] [D loss: 0.576390] [G loss: 0.506386]\n",
      "[Epoch 4/100] [Batch 32/347] [D loss: 0.576358] [G loss: 0.503175]\n",
      "[Epoch 4/100] [Batch 33/347] [D loss: 0.576326] [G loss: 0.496173]\n",
      "[Epoch 4/100] [Batch 34/347] [D loss: 0.576294] [G loss: 0.497152]\n",
      "[Epoch 4/100] [Batch 35/347] [D loss: 0.576262] [G loss: 0.495879]\n",
      "[Epoch 4/100] [Batch 36/347] [D loss: 0.576230] [G loss: 0.489008]\n",
      "[Epoch 4/100] [Batch 37/347] [D loss: 0.576198] [G loss: 0.506141]\n",
      "[Epoch 4/100] [Batch 38/347] [D loss: 0.576166] [G loss: 0.521488]\n",
      "[Epoch 4/100] [Batch 39/347] [D loss: 0.576134] [G loss: 0.512127]\n",
      "[Epoch 4/100] [Batch 40/347] [D loss: 0.576103] [G loss: 0.510035]\n",
      "[Epoch 4/100] [Batch 41/347] [D loss: 0.576071] [G loss: 0.511516]\n",
      "[Epoch 4/100] [Batch 42/347] [D loss: 0.576039] [G loss: 0.504607]\n",
      "[Epoch 4/100] [Batch 43/347] [D loss: 0.576007] [G loss: 0.491006]\n",
      "[Epoch 4/100] [Batch 44/347] [D loss: 0.575976] [G loss: 0.493629]\n",
      "[Epoch 4/100] [Batch 45/347] [D loss: 0.575944] [G loss: 0.511226]\n",
      "[Epoch 4/100] [Batch 46/347] [D loss: 0.575912] [G loss: 0.506197]\n",
      "[Epoch 4/100] [Batch 47/347] [D loss: 0.575880] [G loss: 0.487615]\n",
      "[Epoch 4/100] [Batch 48/347] [D loss: 0.575847] [G loss: 0.519656]\n",
      "[Epoch 4/100] [Batch 49/347] [D loss: 0.575816] [G loss: 0.528180]\n",
      "[Epoch 4/100] [Batch 50/347] [D loss: 0.575784] [G loss: 0.543951]\n",
      "[Epoch 4/100] [Batch 51/347] [D loss: 0.575752] [G loss: 0.528738]\n",
      "[Epoch 4/100] [Batch 52/347] [D loss: 0.575721] [G loss: 0.495716]\n",
      "[Epoch 4/100] [Batch 53/347] [D loss: 0.575689] [G loss: 0.491361]\n",
      "[Epoch 4/100] [Batch 54/347] [D loss: 0.575657] [G loss: 0.543503]\n",
      "[Epoch 4/100] [Batch 55/347] [D loss: 0.575625] [G loss: 0.565593]\n",
      "[Epoch 4/100] [Batch 56/347] [D loss: 0.575593] [G loss: 0.552488]\n",
      "[Epoch 4/100] [Batch 57/347] [D loss: 0.575562] [G loss: 0.518270]\n",
      "[Epoch 4/100] [Batch 58/347] [D loss: 0.575530] [G loss: 0.494838]\n",
      "[Epoch 4/100] [Batch 59/347] [D loss: 0.575499] [G loss: 0.500950]\n",
      "[Epoch 4/100] [Batch 60/347] [D loss: 0.575467] [G loss: 0.519157]\n",
      "[Epoch 4/100] [Batch 61/347] [D loss: 0.575435] [G loss: 0.531097]\n",
      "[Epoch 4/100] [Batch 62/347] [D loss: 0.575403] [G loss: 0.554585]\n",
      "[Epoch 4/100] [Batch 63/347] [D loss: 0.575371] [G loss: 0.556495]\n",
      "[Epoch 4/100] [Batch 64/347] [D loss: 0.575339] [G loss: 0.519715]\n",
      "[Epoch 4/100] [Batch 65/347] [D loss: 0.575308] [G loss: 0.500220]\n",
      "[Epoch 4/100] [Batch 66/347] [D loss: 0.575277] [G loss: 0.502845]\n",
      "[Epoch 4/100] [Batch 67/347] [D loss: 0.575244] [G loss: 0.502613]\n",
      "[Epoch 4/100] [Batch 68/347] [D loss: 0.575213] [G loss: 0.520172]\n",
      "[Epoch 4/100] [Batch 69/347] [D loss: 0.575181] [G loss: 0.538404]\n",
      "[Epoch 4/100] [Batch 70/347] [D loss: 0.575149] [G loss: 0.536985]\n",
      "[Epoch 4/100] [Batch 71/347] [D loss: 0.575117] [G loss: 0.539650]\n",
      "[Epoch 4/100] [Batch 72/347] [D loss: 0.575086] [G loss: 0.542074]\n",
      "[Epoch 4/100] [Batch 73/347] [D loss: 0.575054] [G loss: 0.517147]\n",
      "[Epoch 4/100] [Batch 74/347] [D loss: 0.575023] [G loss: 0.503042]\n",
      "[Epoch 4/100] [Batch 75/347] [D loss: 0.574991] [G loss: 0.532175]\n",
      "[Epoch 4/100] [Batch 76/347] [D loss: 0.574959] [G loss: 0.533476]\n",
      "[Epoch 4/100] [Batch 77/347] [D loss: 0.574927] [G loss: 0.498868]\n",
      "[Epoch 4/100] [Batch 78/347] [D loss: 0.574896] [G loss: 0.509181]\n",
      "[Epoch 4/100] [Batch 79/347] [D loss: 0.574864] [G loss: 0.511053]\n",
      "[Epoch 4/100] [Batch 80/347] [D loss: 0.574833] [G loss: 0.508078]\n",
      "[Epoch 4/100] [Batch 81/347] [D loss: 0.574801] [G loss: 0.513520]\n",
      "[Epoch 4/100] [Batch 82/347] [D loss: 0.574769] [G loss: 0.519250]\n",
      "[Epoch 4/100] [Batch 83/347] [D loss: 0.574737] [G loss: 0.511627]\n",
      "[Epoch 4/100] [Batch 84/347] [D loss: 0.574706] [G loss: 0.517695]\n",
      "[Epoch 4/100] [Batch 85/347] [D loss: 0.574674] [G loss: 0.518337]\n",
      "[Epoch 4/100] [Batch 86/347] [D loss: 0.574642] [G loss: 0.512575]\n",
      "[Epoch 4/100] [Batch 87/347] [D loss: 0.574611] [G loss: 0.510094]\n",
      "[Epoch 4/100] [Batch 88/347] [D loss: 0.574579] [G loss: 0.513109]\n",
      "[Epoch 4/100] [Batch 89/347] [D loss: 0.574547] [G loss: 0.516082]\n",
      "[Epoch 4/100] [Batch 90/347] [D loss: 0.574516] [G loss: 0.511854]\n",
      "[Epoch 4/100] [Batch 91/347] [D loss: 0.574484] [G loss: 0.510013]\n",
      "[Epoch 4/100] [Batch 92/347] [D loss: 0.574453] [G loss: 0.511043]\n",
      "[Epoch 4/100] [Batch 93/347] [D loss: 0.574421] [G loss: 0.508636]\n",
      "[Epoch 4/100] [Batch 94/347] [D loss: 0.574389] [G loss: 0.504565]\n",
      "[Epoch 4/100] [Batch 95/347] [D loss: 0.574358] [G loss: 0.504572]\n",
      "[Epoch 4/100] [Batch 96/347] [D loss: 0.574326] [G loss: 0.499395]\n",
      "[Epoch 4/100] [Batch 97/347] [D loss: 0.574295] [G loss: 0.493794]\n",
      "[Epoch 4/100] [Batch 98/347] [D loss: 0.574263] [G loss: 0.498183]\n",
      "[Epoch 4/100] [Batch 99/347] [D loss: 0.574231] [G loss: 0.501414]\n",
      "[Epoch 4/100] [Batch 100/347] [D loss: 0.574200] [G loss: 0.497282]\n",
      "[Epoch 4/100] [Batch 101/347] [D loss: 0.574168] [G loss: 0.491577]\n",
      "[Epoch 4/100] [Batch 102/347] [D loss: 0.574137] [G loss: 0.492567]\n",
      "[Epoch 4/100] [Batch 103/347] [D loss: 0.574105] [G loss: 0.492688]\n",
      "[Epoch 4/100] [Batch 104/347] [D loss: 0.574074] [G loss: 0.491256]\n",
      "[Epoch 4/100] [Batch 105/347] [D loss: 0.574042] [G loss: 0.493883]\n",
      "[Epoch 4/100] [Batch 106/347] [D loss: 0.574010] [G loss: 0.493725]\n",
      "[Epoch 4/100] [Batch 107/347] [D loss: 0.573979] [G loss: 0.488262]\n",
      "[Epoch 4/100] [Batch 108/347] [D loss: 0.573947] [G loss: 0.505784]\n",
      "[Epoch 4/100] [Batch 109/347] [D loss: 0.573916] [G loss: 0.499344]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 110/347] [D loss: 0.573884] [G loss: 0.482157]\n",
      "[Epoch 4/100] [Batch 111/347] [D loss: 0.573853] [G loss: 0.494012]\n",
      "[Epoch 4/100] [Batch 112/347] [D loss: 0.573821] [G loss: 0.492551]\n",
      "[Epoch 4/100] [Batch 113/347] [D loss: 0.573790] [G loss: 0.497280]\n",
      "[Epoch 4/100] [Batch 114/347] [D loss: 0.573758] [G loss: 0.518149]\n",
      "[Epoch 4/100] [Batch 115/347] [D loss: 0.573727] [G loss: 0.519467]\n",
      "[Epoch 4/100] [Batch 116/347] [D loss: 0.573695] [G loss: 0.513782]\n",
      "[Epoch 4/100] [Batch 117/347] [D loss: 0.573664] [G loss: 0.487655]\n",
      "[Epoch 4/100] [Batch 118/347] [D loss: 0.573632] [G loss: 0.496611]\n",
      "[Epoch 4/100] [Batch 119/347] [D loss: 0.573600] [G loss: 0.498902]\n",
      "[Epoch 4/100] [Batch 120/347] [D loss: 0.573569] [G loss: 0.498021]\n",
      "[Epoch 4/100] [Batch 121/347] [D loss: 0.573538] [G loss: 0.496437]\n",
      "[Epoch 4/100] [Batch 122/347] [D loss: 0.573506] [G loss: 0.483548]\n",
      "[Epoch 4/100] [Batch 123/347] [D loss: 0.573475] [G loss: 0.482370]\n",
      "[Epoch 4/100] [Batch 124/347] [D loss: 0.573444] [G loss: 0.483703]\n",
      "[Epoch 4/100] [Batch 125/347] [D loss: 0.573412] [G loss: 0.484876]\n",
      "[Epoch 4/100] [Batch 126/347] [D loss: 0.573381] [G loss: 0.497702]\n",
      "[Epoch 4/100] [Batch 127/347] [D loss: 0.573350] [G loss: 0.499343]\n",
      "[Epoch 4/100] [Batch 128/347] [D loss: 0.573318] [G loss: 0.493952]\n",
      "[Epoch 4/100] [Batch 129/347] [D loss: 0.573286] [G loss: 0.489094]\n",
      "[Epoch 4/100] [Batch 130/347] [D loss: 0.573255] [G loss: 0.492494]\n",
      "[Epoch 4/100] [Batch 131/347] [D loss: 0.573224] [G loss: 0.491920]\n",
      "[Epoch 4/100] [Batch 132/347] [D loss: 0.573192] [G loss: 0.516575]\n",
      "[Epoch 4/100] [Batch 133/347] [D loss: 0.573161] [G loss: 0.523325]\n",
      "[Epoch 4/100] [Batch 134/347] [D loss: 0.573129] [G loss: 0.538270]\n",
      "[Epoch 4/100] [Batch 135/347] [D loss: 0.573098] [G loss: 0.547302]\n",
      "[Epoch 4/100] [Batch 136/347] [D loss: 0.573067] [G loss: 0.505491]\n",
      "[Epoch 4/100] [Batch 137/347] [D loss: 0.573036] [G loss: 0.491746]\n",
      "[Epoch 4/100] [Batch 138/347] [D loss: 0.573004] [G loss: 0.510180]\n",
      "[Epoch 4/100] [Batch 139/347] [D loss: 0.572973] [G loss: 0.533833]\n",
      "[Epoch 4/100] [Batch 140/347] [D loss: 0.572941] [G loss: 0.545046]\n",
      "[Epoch 4/100] [Batch 141/347] [D loss: 0.572910] [G loss: 0.551678]\n",
      "[Epoch 4/100] [Batch 142/347] [D loss: 0.572878] [G loss: 0.559450]\n",
      "[Epoch 4/100] [Batch 143/347] [D loss: 0.572847] [G loss: 0.581294]\n",
      "[Epoch 4/100] [Batch 144/347] [D loss: 0.572816] [G loss: 0.583398]\n",
      "[Epoch 4/100] [Batch 145/347] [D loss: 0.572785] [G loss: 0.569102]\n",
      "[Epoch 4/100] [Batch 146/347] [D loss: 0.572754] [G loss: 0.552187]\n",
      "[Epoch 4/100] [Batch 147/347] [D loss: 0.572722] [G loss: 0.523977]\n",
      "[Epoch 4/100] [Batch 148/347] [D loss: 0.572691] [G loss: 0.511387]\n",
      "[Epoch 4/100] [Batch 149/347] [D loss: 0.572660] [G loss: 0.524016]\n",
      "[Epoch 4/100] [Batch 150/347] [D loss: 0.572629] [G loss: 0.523932]\n",
      "[Epoch 4/100] [Batch 151/347] [D loss: 0.572597] [G loss: 0.512591]\n",
      "[Epoch 4/100] [Batch 152/347] [D loss: 0.572566] [G loss: 0.523100]\n",
      "[Epoch 4/100] [Batch 153/347] [D loss: 0.572535] [G loss: 0.543395]\n",
      "[Epoch 4/100] [Batch 154/347] [D loss: 0.572503] [G loss: 0.547233]\n",
      "[Epoch 4/100] [Batch 155/347] [D loss: 0.572472] [G loss: 0.534068]\n",
      "[Epoch 4/100] [Batch 156/347] [D loss: 0.572441] [G loss: 0.517281]\n",
      "[Epoch 4/100] [Batch 157/347] [D loss: 0.572410] [G loss: 0.523371]\n",
      "[Epoch 4/100] [Batch 158/347] [D loss: 0.572379] [G loss: 0.546639]\n",
      "[Epoch 4/100] [Batch 159/347] [D loss: 0.572347] [G loss: 0.543661]\n",
      "[Epoch 4/100] [Batch 160/347] [D loss: 0.572316] [G loss: 0.523353]\n",
      "[Epoch 4/100] [Batch 161/347] [D loss: 0.572286] [G loss: 0.514550]\n",
      "[Epoch 4/100] [Batch 162/347] [D loss: 0.572254] [G loss: 0.519897]\n",
      "[Epoch 4/100] [Batch 163/347] [D loss: 0.572223] [G loss: 0.538141]\n",
      "[Epoch 4/100] [Batch 164/347] [D loss: 0.572192] [G loss: 0.552762]\n",
      "[Epoch 4/100] [Batch 165/347] [D loss: 0.572160] [G loss: 0.543463]\n",
      "[Epoch 4/100] [Batch 166/347] [D loss: 0.572129] [G loss: 0.504957]\n",
      "[Epoch 4/100] [Batch 167/347] [D loss: 0.572099] [G loss: 0.502273]\n",
      "[Epoch 4/100] [Batch 168/347] [D loss: 0.572068] [G loss: 0.513174]\n",
      "[Epoch 4/100] [Batch 169/347] [D loss: 0.572036] [G loss: 0.512263]\n",
      "[Epoch 4/100] [Batch 170/347] [D loss: 0.572005] [G loss: 0.510126]\n",
      "[Epoch 4/100] [Batch 171/347] [D loss: 0.571974] [G loss: 0.522363]\n",
      "[Epoch 4/100] [Batch 172/347] [D loss: 0.571943] [G loss: 0.527374]\n",
      "[Epoch 4/100] [Batch 173/347] [D loss: 0.571912] [G loss: 0.516133]\n",
      "[Epoch 4/100] [Batch 174/347] [D loss: 0.571880] [G loss: 0.513551]\n",
      "[Epoch 4/100] [Batch 175/347] [D loss: 0.571849] [G loss: 0.523148]\n",
      "[Epoch 4/100] [Batch 176/347] [D loss: 0.571818] [G loss: 0.536248]\n",
      "[Epoch 4/100] [Batch 177/347] [D loss: 0.571787] [G loss: 0.536700]\n",
      "[Epoch 4/100] [Batch 178/347] [D loss: 0.571756] [G loss: 0.530450]\n",
      "[Epoch 4/100] [Batch 179/347] [D loss: 0.571725] [G loss: 0.523396]\n",
      "[Epoch 4/100] [Batch 180/347] [D loss: 0.571694] [G loss: 0.516603]\n",
      "[Epoch 4/100] [Batch 181/347] [D loss: 0.571663] [G loss: 0.516537]\n",
      "[Epoch 4/100] [Batch 182/347] [D loss: 0.571632] [G loss: 0.513803]\n",
      "[Epoch 4/100] [Batch 183/347] [D loss: 0.571600] [G loss: 0.517252]\n",
      "[Epoch 4/100] [Batch 184/347] [D loss: 0.571569] [G loss: 0.520458]\n",
      "[Epoch 4/100] [Batch 185/347] [D loss: 0.571538] [G loss: 0.518525]\n",
      "[Epoch 4/100] [Batch 186/347] [D loss: 0.571507] [G loss: 0.517757]\n",
      "[Epoch 4/100] [Batch 187/347] [D loss: 0.571476] [G loss: 0.511946]\n",
      "[Epoch 4/100] [Batch 188/347] [D loss: 0.571445] [G loss: 0.508218]\n",
      "[Epoch 4/100] [Batch 189/347] [D loss: 0.571414] [G loss: 0.506769]\n",
      "[Epoch 4/100] [Batch 190/347] [D loss: 0.571383] [G loss: 0.494327]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 191/347] [D loss: 0.571352] [G loss: 0.481092]\n",
      "[Epoch 4/100] [Batch 192/347] [D loss: 0.571321] [G loss: 0.481897]\n",
      "[Epoch 4/100] [Batch 193/347] [D loss: 0.571290] [G loss: 0.489474]\n",
      "[Epoch 4/100] [Batch 194/347] [D loss: 0.571259] [G loss: 0.484351]\n",
      "[Epoch 4/100] [Batch 195/347] [D loss: 0.571228] [G loss: 0.487511]\n",
      "[Epoch 4/100] [Batch 196/347] [D loss: 0.571197] [G loss: 0.486320]\n",
      "[Epoch 4/100] [Batch 197/347] [D loss: 0.571166] [G loss: 0.482402]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 198/347] [D loss: 0.571135] [G loss: 0.480485]\n",
      "[Epoch 4/100] [Batch 199/347] [D loss: 0.571104] [G loss: 0.482379]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 200/347] [D loss: 0.571073] [G loss: 0.477832]\n",
      "[Epoch 4/100] [Batch 201/347] [D loss: 0.571042] [G loss: 0.480530]\n",
      "[Epoch 4/100] [Batch 202/347] [D loss: 0.571011] [G loss: 0.492368]\n",
      "[Epoch 4/100] [Batch 203/347] [D loss: 0.570980] [G loss: 0.501220]\n",
      "[Epoch 4/100] [Batch 204/347] [D loss: 0.570949] [G loss: 0.497904]\n",
      "[Epoch 4/100] [Batch 205/347] [D loss: 0.570918] [G loss: 0.490119]\n",
      "[Epoch 4/100] [Batch 206/347] [D loss: 0.570887] [G loss: 0.477923]\n",
      "[Epoch 4/100] [Batch 207/347] [D loss: 0.570856] [G loss: 0.484437]\n",
      "[Epoch 4/100] [Batch 208/347] [D loss: 0.570825] [G loss: 0.485511]\n",
      "[Epoch 4/100] [Batch 209/347] [D loss: 0.570794] [G loss: 0.480139]\n",
      "[Epoch 4/100] [Batch 210/347] [D loss: 0.570763] [G loss: 0.486204]\n",
      "[Epoch 4/100] [Batch 211/347] [D loss: 0.570732] [G loss: 0.484448]\n",
      "[Epoch 4/100] [Batch 212/347] [D loss: 0.570701] [G loss: 0.482605]\n",
      "[Epoch 4/100] [Batch 213/347] [D loss: 0.570670] [G loss: 0.488138]\n",
      "[Epoch 4/100] [Batch 214/347] [D loss: 0.570639] [G loss: 0.501048]\n",
      "[Epoch 4/100] [Batch 215/347] [D loss: 0.570608] [G loss: 0.509354]\n",
      "[Epoch 4/100] [Batch 216/347] [D loss: 0.570577] [G loss: 0.487093]\n",
      "[Epoch 4/100] [Batch 217/347] [D loss: 0.570547] [G loss: 0.487626]\n",
      "[Epoch 4/100] [Batch 218/347] [D loss: 0.570516] [G loss: 0.494285]\n",
      "[Epoch 4/100] [Batch 219/347] [D loss: 0.570485] [G loss: 0.506242]\n",
      "[Epoch 4/100] [Batch 220/347] [D loss: 0.570454] [G loss: 0.521930]\n",
      "[Epoch 4/100] [Batch 221/347] [D loss: 0.570423] [G loss: 0.523285]\n",
      "[Epoch 4/100] [Batch 222/347] [D loss: 0.570392] [G loss: 0.515171]\n",
      "[Epoch 4/100] [Batch 223/347] [D loss: 0.570361] [G loss: 0.513582]\n",
      "[Epoch 4/100] [Batch 224/347] [D loss: 0.570330] [G loss: 0.509155]\n",
      "[Epoch 4/100] [Batch 225/347] [D loss: 0.570300] [G loss: 0.495151]\n",
      "[Epoch 4/100] [Batch 226/347] [D loss: 0.570268] [G loss: 0.497412]\n",
      "[Epoch 4/100] [Batch 227/347] [D loss: 0.570237] [G loss: 0.508173]\n",
      "[Epoch 4/100] [Batch 228/347] [D loss: 0.570207] [G loss: 0.510269]\n",
      "[Epoch 4/100] [Batch 229/347] [D loss: 0.570176] [G loss: 0.505877]\n",
      "[Epoch 4/100] [Batch 230/347] [D loss: 0.570146] [G loss: 0.502454]\n",
      "[Epoch 4/100] [Batch 231/347] [D loss: 0.570115] [G loss: 0.502576]\n",
      "[Epoch 4/100] [Batch 232/347] [D loss: 0.570084] [G loss: 0.498457]\n",
      "[Epoch 4/100] [Batch 233/347] [D loss: 0.570053] [G loss: 0.496515]\n",
      "[Epoch 4/100] [Batch 234/347] [D loss: 0.570023] [G loss: 0.501288]\n",
      "[Epoch 4/100] [Batch 235/347] [D loss: 0.569992] [G loss: 0.489964]\n",
      "[Epoch 4/100] [Batch 236/347] [D loss: 0.569961] [G loss: 0.480157]\n",
      "[Epoch 4/100] [Batch 237/347] [D loss: 0.569930] [G loss: 0.483122]\n",
      "[Epoch 4/100] [Batch 238/347] [D loss: 0.569899] [G loss: 0.487220]\n",
      "[Epoch 4/100] [Batch 239/347] [D loss: 0.569869] [G loss: 0.485373]\n",
      "[Epoch 4/100] [Batch 240/347] [D loss: 0.569838] [G loss: 0.481545]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 241/347] [D loss: 0.569807] [G loss: 0.475595]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 242/347] [D loss: 0.569776] [G loss: 0.473345]\n",
      "[Epoch 4/100] [Batch 243/347] [D loss: 0.569745] [G loss: 0.480576]\n",
      "[Epoch 4/100] [Batch 244/347] [D loss: 0.569715] [G loss: 0.489048]\n",
      "[Epoch 4/100] [Batch 245/347] [D loss: 0.569684] [G loss: 0.487850]\n",
      "[Epoch 4/100] [Batch 246/347] [D loss: 0.569653] [G loss: 0.480819]\n",
      "[Epoch 4/100] [Batch 247/347] [D loss: 0.569622] [G loss: 0.496616]\n",
      "[Epoch 4/100] [Batch 248/347] [D loss: 0.569591] [G loss: 0.501748]\n",
      "[Epoch 4/100] [Batch 249/347] [D loss: 0.569561] [G loss: 0.508550]\n",
      "[Epoch 4/100] [Batch 250/347] [D loss: 0.569530] [G loss: 0.500249]\n",
      "[Epoch 4/100] [Batch 251/347] [D loss: 0.569500] [G loss: 0.479068]\n",
      "[Epoch 4/100] [Batch 252/347] [D loss: 0.569469] [G loss: 0.482160]\n",
      "[Epoch 4/100] [Batch 253/347] [D loss: 0.569438] [G loss: 0.482724]\n",
      "[Epoch 4/100] [Batch 254/347] [D loss: 0.569408] [G loss: 0.481068]\n",
      "[Epoch 4/100] [Batch 255/347] [D loss: 0.569377] [G loss: 0.479538]\n",
      "[Epoch 4/100] [Batch 256/347] [D loss: 0.569346] [G loss: 0.484492]\n",
      "[Epoch 4/100] [Batch 257/347] [D loss: 0.569315] [G loss: 0.485829]\n",
      "[Epoch 4/100] [Batch 258/347] [D loss: 0.569285] [G loss: 0.480247]\n",
      "[Epoch 4/100] [Batch 259/347] [D loss: 0.569254] [G loss: 0.499562]\n",
      "[Epoch 4/100] [Batch 260/347] [D loss: 0.569223] [G loss: 0.514099]\n",
      "[Epoch 4/100] [Batch 261/347] [D loss: 0.569193] [G loss: 0.506780]\n",
      "[Epoch 4/100] [Batch 262/347] [D loss: 0.569162] [G loss: 0.491820]\n",
      "[Epoch 4/100] [Batch 263/347] [D loss: 0.569132] [G loss: 0.492878]\n",
      "[Epoch 4/100] [Batch 264/347] [D loss: 0.569101] [G loss: 0.507336]\n",
      "[Epoch 4/100] [Batch 265/347] [D loss: 0.569070] [G loss: 0.512332]\n",
      "[Epoch 4/100] [Batch 266/347] [D loss: 0.569040] [G loss: 0.505008]\n",
      "[Epoch 4/100] [Batch 267/347] [D loss: 0.569009] [G loss: 0.498134]\n",
      "[Epoch 4/100] [Batch 268/347] [D loss: 0.568979] [G loss: 0.504846]\n",
      "[Epoch 4/100] [Batch 269/347] [D loss: 0.568948] [G loss: 0.515757]\n",
      "[Epoch 4/100] [Batch 270/347] [D loss: 0.568917] [G loss: 0.512077]\n",
      "[Epoch 4/100] [Batch 271/347] [D loss: 0.568887] [G loss: 0.499970]\n",
      "[Epoch 4/100] [Batch 272/347] [D loss: 0.568856] [G loss: 0.491070]\n",
      "[Epoch 4/100] [Batch 273/347] [D loss: 0.568826] [G loss: 0.502604]\n",
      "[Epoch 4/100] [Batch 274/347] [D loss: 0.568795] [G loss: 0.536020]\n",
      "[Epoch 4/100] [Batch 275/347] [D loss: 0.568765] [G loss: 0.532577]\n",
      "[Epoch 4/100] [Batch 276/347] [D loss: 0.568734] [G loss: 0.499892]\n",
      "[Epoch 4/100] [Batch 277/347] [D loss: 0.568704] [G loss: 0.484912]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 278/347] [D loss: 0.568673] [G loss: 0.472598]\n",
      "[Epoch 4/100] [Batch 279/347] [D loss: 0.568643] [G loss: 0.476580]\n",
      "[Epoch 4/100] [Batch 280/347] [D loss: 0.568612] [G loss: 0.480001]\n",
      "[Epoch 4/100] [Batch 281/347] [D loss: 0.568582] [G loss: 0.478442]\n",
      "[Epoch 4/100] [Batch 282/347] [D loss: 0.568551] [G loss: 0.477445]\n",
      "[Epoch 4/100] [Batch 283/347] [D loss: 0.568521] [G loss: 0.480229]\n",
      "[Epoch 4/100] [Batch 284/347] [D loss: 0.568490] [G loss: 0.481954]\n",
      "[Epoch 4/100] [Batch 285/347] [D loss: 0.568460] [G loss: 0.478584]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 286/347] [D loss: 0.568429] [G loss: 0.472066]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 287/347] [D loss: 0.568399] [G loss: 0.471695]\n",
      "[Epoch 4/100] [Batch 288/347] [D loss: 0.568368] [G loss: 0.497564]\n",
      "[Epoch 4/100] [Batch 289/347] [D loss: 0.568338] [G loss: 0.501711]\n",
      "[Epoch 4/100] [Batch 290/347] [D loss: 0.568307] [G loss: 0.479255]\n",
      "[Epoch 4/100] [Batch 291/347] [D loss: 0.568277] [G loss: 0.481807]\n",
      "[Epoch 4/100] [Batch 292/347] [D loss: 0.568246] [G loss: 0.472904]\n",
      "[Epoch 4/100] [Batch 293/347] [D loss: 0.568216] [G loss: 0.489832]\n",
      "[Epoch 4/100] [Batch 294/347] [D loss: 0.568186] [G loss: 0.499852]\n",
      "[Epoch 4/100] [Batch 295/347] [D loss: 0.568155] [G loss: 0.497676]\n",
      "[Epoch 4/100] [Batch 296/347] [D loss: 0.568125] [G loss: 0.493702]\n",
      "[Epoch 4/100] [Batch 297/347] [D loss: 0.568094] [G loss: 0.506548]\n",
      "[Epoch 4/100] [Batch 298/347] [D loss: 0.568064] [G loss: 0.501481]\n",
      "[Epoch 4/100] [Batch 299/347] [D loss: 0.568033] [G loss: 0.499985]\n",
      "[Epoch 4/100] [Batch 300/347] [D loss: 0.568003] [G loss: 0.495018]\n",
      "[Epoch 4/100] [Batch 301/347] [D loss: 0.567973] [G loss: 0.494542]\n",
      "[Epoch 4/100] [Batch 302/347] [D loss: 0.567942] [G loss: 0.499232]\n",
      "[Epoch 4/100] [Batch 303/347] [D loss: 0.567912] [G loss: 0.483204]\n",
      "[Epoch 4/100] [Batch 304/347] [D loss: 0.567881] [G loss: 0.481611]\n",
      "[Epoch 4/100] [Batch 305/347] [D loss: 0.567851] [G loss: 0.494734]\n",
      "[Epoch 4/100] [Batch 306/347] [D loss: 0.567820] [G loss: 0.485848]\n",
      "[Epoch 4/100] [Batch 307/347] [D loss: 0.567790] [G loss: 0.497822]\n",
      "[Epoch 4/100] [Batch 308/347] [D loss: 0.567760] [G loss: 0.494232]\n",
      "[Epoch 4/100] [Batch 309/347] [D loss: 0.567729] [G loss: 0.475721]\n",
      "[Epoch 4/100] [Batch 310/347] [D loss: 0.567699] [G loss: 0.495394]\n",
      "[Epoch 4/100] [Batch 311/347] [D loss: 0.567669] [G loss: 0.498430]\n",
      "[Epoch 4/100] [Batch 312/347] [D loss: 0.567638] [G loss: 0.498241]\n",
      "[Epoch 4/100] [Batch 313/347] [D loss: 0.567608] [G loss: 0.497464]\n",
      "[Epoch 4/100] [Batch 314/347] [D loss: 0.567578] [G loss: 0.491112]\n",
      "[Epoch 4/100] [Batch 315/347] [D loss: 0.567547] [G loss: 0.481634]\n",
      "[Epoch 4/100] [Batch 316/347] [D loss: 0.567517] [G loss: 0.474809]\n",
      "[Epoch 4/100] [Batch 317/347] [D loss: 0.567486] [G loss: 0.493386]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 318/347] [D loss: 0.567456] [G loss: 0.471308]\n",
      "[Epoch 4/100] [Batch 319/347] [D loss: 0.567426] [G loss: 0.502664]\n",
      "[Epoch 4/100] [Batch 320/347] [D loss: 0.567396] [G loss: 0.516230]\n",
      "[Epoch 4/100] [Batch 321/347] [D loss: 0.567366] [G loss: 0.505656]\n",
      "[Epoch 4/100] [Batch 322/347] [D loss: 0.567335] [G loss: 0.492772]\n",
      "[Epoch 4/100] [Batch 323/347] [D loss: 0.567305] [G loss: 0.491979]\n",
      "[Epoch 4/100] [Batch 324/347] [D loss: 0.567275] [G loss: 0.494733]\n",
      "[Epoch 4/100] [Batch 325/347] [D loss: 0.567245] [G loss: 0.483518]\n",
      "[Epoch 4/100] [Batch 326/347] [D loss: 0.567214] [G loss: 0.472234]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 327/347] [D loss: 0.567184] [G loss: 0.469937]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 328/347] [D loss: 0.567154] [G loss: 0.467709]\n",
      "[Epoch 4/100] [Batch 329/347] [D loss: 0.567124] [G loss: 0.490204]\n",
      "[Epoch 4/100] [Batch 330/347] [D loss: 0.567093] [G loss: 0.506250]\n",
      "[Epoch 4/100] [Batch 331/347] [D loss: 0.567063] [G loss: 0.488552]\n",
      "[Epoch 4/100] [Batch 332/347] [D loss: 0.567033] [G loss: 0.479543]\n",
      "[Epoch 4/100] [Batch 333/347] [D loss: 0.567003] [G loss: 0.490583]\n",
      "[Epoch 4/100] [Batch 334/347] [D loss: 0.566973] [G loss: 0.491817]\n",
      "[Epoch 4/100] [Batch 335/347] [D loss: 0.566943] [G loss: 0.479750]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 4/100] [Batch 336/347] [D loss: 0.566912] [G loss: 0.467395]\n",
      "[Epoch 4/100] [Batch 337/347] [D loss: 0.566882] [G loss: 0.471443]\n",
      "[Epoch 4/100] [Batch 338/347] [D loss: 0.566852] [G loss: 0.485944]\n",
      "[Epoch 4/100] [Batch 339/347] [D loss: 0.566822] [G loss: 0.491211]\n",
      "[Epoch 4/100] [Batch 340/347] [D loss: 0.566792] [G loss: 0.491403]\n",
      "[Epoch 4/100] [Batch 341/347] [D loss: 0.566762] [G loss: 0.486465]\n",
      "[Epoch 4/100] [Batch 342/347] [D loss: 0.566732] [G loss: 0.478734]\n",
      "[Epoch 4/100] [Batch 343/347] [D loss: 0.566702] [G loss: 0.483273]\n",
      "[Epoch 4/100] [Batch 344/347] [D loss: 0.566671] [G loss: 0.481849]\n",
      "[Epoch 4/100] [Batch 345/347] [D loss: 0.566641] [G loss: 0.492662]\n",
      "[Epoch 4/100] [Batch 346/347] [D loss: 0.566611] [G loss: 0.511278]\n",
      "[Epoch 4/100] [Batch 347/347] [D loss: 0.566581] [G loss: 0.517770]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 1/347] [D loss: 0.566551] [G loss: 0.483025]\n",
      "[Epoch 5/100] [Batch 2/347] [D loss: 0.566521] [G loss: 0.488140]\n",
      "[Epoch 5/100] [Batch 3/347] [D loss: 0.566491] [G loss: 0.487940]\n",
      "[Epoch 5/100] [Batch 4/347] [D loss: 0.566461] [G loss: 0.488936]\n",
      "[Epoch 5/100] [Batch 5/347] [D loss: 0.566431] [G loss: 0.487846]\n",
      "[Epoch 5/100] [Batch 6/347] [D loss: 0.566401] [G loss: 0.487908]\n",
      "[Epoch 5/100] [Batch 7/347] [D loss: 0.566371] [G loss: 0.487382]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 8/347] [D loss: 0.566341] [G loss: 0.482356]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 9/347] [D loss: 0.566311] [G loss: 0.480983]\n",
      "[Epoch 5/100] [Batch 10/347] [D loss: 0.566281] [G loss: 0.482174]\n",
      "[Epoch 5/100] [Batch 11/347] [D loss: 0.566251] [G loss: 0.481690]\n",
      "[Epoch 5/100] [Batch 12/347] [D loss: 0.566221] [G loss: 0.481816]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 13/347] [D loss: 0.566191] [G loss: 0.480948]\n",
      "[Epoch 5/100] [Batch 14/347] [D loss: 0.566161] [G loss: 0.483421]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 15/347] [D loss: 0.566131] [G loss: 0.479788]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 16/347] [D loss: 0.566101] [G loss: 0.475799]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 17/347] [D loss: 0.566071] [G loss: 0.465679]\n",
      "[Epoch 5/100] [Batch 18/347] [D loss: 0.566041] [G loss: 0.472675]\n",
      "[Epoch 5/100] [Batch 19/347] [D loss: 0.566011] [G loss: 0.469589]\n",
      "[Epoch 5/100] [Batch 20/347] [D loss: 0.565981] [G loss: 0.482738]\n",
      "[Epoch 5/100] [Batch 21/347] [D loss: 0.565951] [G loss: 0.479196]\n",
      "[Epoch 5/100] [Batch 22/347] [D loss: 0.565921] [G loss: 0.474283]\n",
      "[Epoch 5/100] [Batch 23/347] [D loss: 0.565891] [G loss: 0.467984]\n",
      "[Epoch 5/100] [Batch 24/347] [D loss: 0.565861] [G loss: 0.467169]\n",
      "[Epoch 5/100] [Batch 25/347] [D loss: 0.565831] [G loss: 0.466380]\n",
      "[Epoch 5/100] [Batch 26/347] [D loss: 0.565801] [G loss: 0.476786]\n",
      "[Epoch 5/100] [Batch 27/347] [D loss: 0.565771] [G loss: 0.482577]\n",
      "[Epoch 5/100] [Batch 28/347] [D loss: 0.565741] [G loss: 0.481876]\n",
      "[Epoch 5/100] [Batch 29/347] [D loss: 0.565712] [G loss: 0.476595]\n",
      "[Epoch 5/100] [Batch 30/347] [D loss: 0.565682] [G loss: 0.483366]\n",
      "[Epoch 5/100] [Batch 31/347] [D loss: 0.565652] [G loss: 0.485822]\n",
      "[Epoch 5/100] [Batch 32/347] [D loss: 0.565622] [G loss: 0.481627]\n",
      "[Epoch 5/100] [Batch 33/347] [D loss: 0.565592] [G loss: 0.475038]\n",
      "[Epoch 5/100] [Batch 34/347] [D loss: 0.565562] [G loss: 0.475891]\n",
      "[Epoch 5/100] [Batch 35/347] [D loss: 0.565532] [G loss: 0.474428]\n",
      "[Epoch 5/100] [Batch 36/347] [D loss: 0.565502] [G loss: 0.466628]\n",
      "[Epoch 5/100] [Batch 37/347] [D loss: 0.565472] [G loss: 0.488622]\n",
      "[Epoch 5/100] [Batch 38/347] [D loss: 0.565442] [G loss: 0.504028]\n",
      "[Epoch 5/100] [Batch 39/347] [D loss: 0.565412] [G loss: 0.494728]\n",
      "[Epoch 5/100] [Batch 40/347] [D loss: 0.565383] [G loss: 0.493622]\n",
      "[Epoch 5/100] [Batch 41/347] [D loss: 0.565353] [G loss: 0.495195]\n",
      "[Epoch 5/100] [Batch 42/347] [D loss: 0.565323] [G loss: 0.488397]\n",
      "[Epoch 5/100] [Batch 43/347] [D loss: 0.565293] [G loss: 0.473966]\n",
      "[Epoch 5/100] [Batch 44/347] [D loss: 0.565263] [G loss: 0.471319]\n",
      "[Epoch 5/100] [Batch 45/347] [D loss: 0.565234] [G loss: 0.488801]\n",
      "[Epoch 5/100] [Batch 46/347] [D loss: 0.565204] [G loss: 0.483681]\n",
      "[Epoch 5/100] [Batch 47/347] [D loss: 0.565174] [G loss: 0.470987]\n",
      "[Epoch 5/100] [Batch 48/347] [D loss: 0.565144] [G loss: 0.503097]\n",
      "[Epoch 5/100] [Batch 49/347] [D loss: 0.565114] [G loss: 0.511699]\n",
      "[Epoch 5/100] [Batch 50/347] [D loss: 0.565084] [G loss: 0.527511]\n",
      "[Epoch 5/100] [Batch 51/347] [D loss: 0.565054] [G loss: 0.512280]\n",
      "[Epoch 5/100] [Batch 52/347] [D loss: 0.565025] [G loss: 0.471908]\n",
      "[Epoch 5/100] [Batch 53/347] [D loss: 0.564995] [G loss: 0.475047]\n",
      "[Epoch 5/100] [Batch 54/347] [D loss: 0.564965] [G loss: 0.527292]\n",
      "[Epoch 5/100] [Batch 55/347] [D loss: 0.564935] [G loss: 0.549399]\n",
      "[Epoch 5/100] [Batch 56/347] [D loss: 0.564905] [G loss: 0.536384]\n",
      "[Epoch 5/100] [Batch 57/347] [D loss: 0.564876] [G loss: 0.502155]\n",
      "[Epoch 5/100] [Batch 58/347] [D loss: 0.564847] [G loss: 0.470730]\n",
      "[Epoch 5/100] [Batch 59/347] [D loss: 0.564817] [G loss: 0.484974]\n",
      "[Epoch 5/100] [Batch 60/347] [D loss: 0.564787] [G loss: 0.503278]\n",
      "[Epoch 5/100] [Batch 61/347] [D loss: 0.564757] [G loss: 0.515305]\n",
      "[Epoch 5/100] [Batch 62/347] [D loss: 0.564727] [G loss: 0.538934]\n",
      "[Epoch 5/100] [Batch 63/347] [D loss: 0.564697] [G loss: 0.540953]\n",
      "[Epoch 5/100] [Batch 64/347] [D loss: 0.564668] [G loss: 0.504222]\n",
      "[Epoch 5/100] [Batch 65/347] [D loss: 0.564639] [G loss: 0.475755]\n",
      "[Epoch 5/100] [Batch 66/347] [D loss: 0.564609] [G loss: 0.478320]\n",
      "[Epoch 5/100] [Batch 67/347] [D loss: 0.564579] [G loss: 0.487301]\n",
      "[Epoch 5/100] [Batch 68/347] [D loss: 0.564549] [G loss: 0.504988]\n",
      "[Epoch 5/100] [Batch 69/347] [D loss: 0.564519] [G loss: 0.523339]\n",
      "[Epoch 5/100] [Batch 70/347] [D loss: 0.564489] [G loss: 0.522007]\n",
      "[Epoch 5/100] [Batch 71/347] [D loss: 0.564460] [G loss: 0.524671]\n",
      "[Epoch 5/100] [Batch 72/347] [D loss: 0.564431] [G loss: 0.527162]\n",
      "[Epoch 5/100] [Batch 73/347] [D loss: 0.564401] [G loss: 0.502297]\n",
      "[Epoch 5/100] [Batch 74/347] [D loss: 0.564372] [G loss: 0.488265]\n",
      "[Epoch 5/100] [Batch 75/347] [D loss: 0.564342] [G loss: 0.517564]\n",
      "[Epoch 5/100] [Batch 76/347] [D loss: 0.564312] [G loss: 0.519035]\n",
      "[Epoch 5/100] [Batch 77/347] [D loss: 0.564283] [G loss: 0.484465]\n",
      "[Epoch 5/100] [Batch 78/347] [D loss: 0.564254] [G loss: 0.484051]\n",
      "[Epoch 5/100] [Batch 79/347] [D loss: 0.564224] [G loss: 0.485881]\n",
      "[Epoch 5/100] [Batch 80/347] [D loss: 0.564194] [G loss: 0.482900]\n",
      "[Epoch 5/100] [Batch 81/347] [D loss: 0.564165] [G loss: 0.488257]\n",
      "[Epoch 5/100] [Batch 82/347] [D loss: 0.564135] [G loss: 0.493853]\n",
      "[Epoch 5/100] [Batch 83/347] [D loss: 0.564106] [G loss: 0.486239]\n",
      "[Epoch 5/100] [Batch 84/347] [D loss: 0.564076] [G loss: 0.492324]\n",
      "[Epoch 5/100] [Batch 85/347] [D loss: 0.564047] [G loss: 0.492939]\n",
      "[Epoch 5/100] [Batch 86/347] [D loss: 0.564017] [G loss: 0.487227]\n",
      "[Epoch 5/100] [Batch 87/347] [D loss: 0.563988] [G loss: 0.484785]\n",
      "[Epoch 5/100] [Batch 88/347] [D loss: 0.563959] [G loss: 0.487825]\n",
      "[Epoch 5/100] [Batch 89/347] [D loss: 0.563929] [G loss: 0.490826]\n",
      "[Epoch 5/100] [Batch 90/347] [D loss: 0.563900] [G loss: 0.486693]\n",
      "[Epoch 5/100] [Batch 91/347] [D loss: 0.563871] [G loss: 0.484913]\n",
      "[Epoch 5/100] [Batch 92/347] [D loss: 0.563841] [G loss: 0.486068]\n",
      "[Epoch 5/100] [Batch 93/347] [D loss: 0.563812] [G loss: 0.483708]\n",
      "[Epoch 5/100] [Batch 94/347] [D loss: 0.563783] [G loss: 0.479741]\n",
      "[Epoch 5/100] [Batch 95/347] [D loss: 0.563753] [G loss: 0.479845]\n",
      "[Epoch 5/100] [Batch 96/347] [D loss: 0.563724] [G loss: 0.474791]\n",
      "[Epoch 5/100] [Batch 97/347] [D loss: 0.563695] [G loss: 0.469284]\n",
      "[Epoch 5/100] [Batch 98/347] [D loss: 0.563665] [G loss: 0.473758]\n",
      "[Epoch 5/100] [Batch 99/347] [D loss: 0.563636] [G loss: 0.477090]\n",
      "[Epoch 5/100] [Batch 100/347] [D loss: 0.563607] [G loss: 0.473081]\n",
      "[Epoch 5/100] [Batch 101/347] [D loss: 0.563577] [G loss: 0.471455]\n",
      "[Epoch 5/100] [Batch 102/347] [D loss: 0.563548] [G loss: 0.472400]\n",
      "[Epoch 5/100] [Batch 103/347] [D loss: 0.563518] [G loss: 0.471887]\n",
      "[Epoch 5/100] [Batch 104/347] [D loss: 0.563489] [G loss: 0.473855]\n",
      "[Epoch 5/100] [Batch 105/347] [D loss: 0.563459] [G loss: 0.475238]\n",
      "[Epoch 5/100] [Batch 106/347] [D loss: 0.563430] [G loss: 0.474038]\n",
      "[Epoch 5/100] [Batch 107/347] [D loss: 0.563400] [G loss: 0.467942]\n",
      "[Epoch 5/100] [Batch 108/347] [D loss: 0.563371] [G loss: 0.484727]\n",
      "[Epoch 5/100] [Batch 109/347] [D loss: 0.563341] [G loss: 0.477601]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 110/347] [D loss: 0.563312] [G loss: 0.465330]\n",
      "[Epoch 5/100] [Batch 111/347] [D loss: 0.563282] [G loss: 0.471202]\n",
      "[Epoch 5/100] [Batch 112/347] [D loss: 0.563253] [G loss: 0.476758]\n",
      "[Epoch 5/100] [Batch 113/347] [D loss: 0.563223] [G loss: 0.481461]\n",
      "[Epoch 5/100] [Batch 114/347] [D loss: 0.563194] [G loss: 0.502336]\n",
      "[Epoch 5/100] [Batch 115/347] [D loss: 0.563165] [G loss: 0.503665]\n",
      "[Epoch 5/100] [Batch 116/347] [D loss: 0.563135] [G loss: 0.497975]\n",
      "[Epoch 5/100] [Batch 117/347] [D loss: 0.563106] [G loss: 0.472669]\n",
      "[Epoch 5/100] [Batch 118/347] [D loss: 0.563076] [G loss: 0.473222]\n",
      "[Epoch 5/100] [Batch 119/347] [D loss: 0.563046] [G loss: 0.475459]\n",
      "[Epoch 5/100] [Batch 120/347] [D loss: 0.563017] [G loss: 0.474540]\n",
      "[Epoch 5/100] [Batch 121/347] [D loss: 0.562988] [G loss: 0.472905]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 122/347] [D loss: 0.562958] [G loss: 0.459990]\n",
      "[Epoch 5/100] [Batch 123/347] [D loss: 0.562929] [G loss: 0.460827]\n",
      "[Epoch 5/100] [Batch 124/347] [D loss: 0.562900] [G loss: 0.460569]\n",
      "[Epoch 5/100] [Batch 125/347] [D loss: 0.562870] [G loss: 0.468512]\n",
      "[Epoch 5/100] [Batch 126/347] [D loss: 0.562841] [G loss: 0.481024]\n",
      "[Epoch 5/100] [Batch 127/347] [D loss: 0.562812] [G loss: 0.482383]\n",
      "[Epoch 5/100] [Batch 128/347] [D loss: 0.562782] [G loss: 0.476705]\n",
      "[Epoch 5/100] [Batch 129/347] [D loss: 0.562752] [G loss: 0.472032]\n",
      "[Epoch 5/100] [Batch 130/347] [D loss: 0.562723] [G loss: 0.475192]\n",
      "[Epoch 5/100] [Batch 131/347] [D loss: 0.562694] [G loss: 0.472803]\n",
      "[Epoch 5/100] [Batch 132/347] [D loss: 0.562664] [G loss: 0.495802]\n",
      "[Epoch 5/100] [Batch 133/347] [D loss: 0.562635] [G loss: 0.503039]\n",
      "[Epoch 5/100] [Batch 134/347] [D loss: 0.562606] [G loss: 0.518418]\n",
      "[Epoch 5/100] [Batch 135/347] [D loss: 0.562576] [G loss: 0.527836]\n",
      "[Epoch 5/100] [Batch 136/347] [D loss: 0.562547] [G loss: 0.486404]\n",
      "[Epoch 5/100] [Batch 137/347] [D loss: 0.562519] [G loss: 0.471251]\n",
      "[Epoch 5/100] [Batch 138/347] [D loss: 0.562489] [G loss: 0.491738]\n",
      "[Epoch 5/100] [Batch 139/347] [D loss: 0.562459] [G loss: 0.515693]\n",
      "[Epoch 5/100] [Batch 140/347] [D loss: 0.562430] [G loss: 0.527196]\n",
      "[Epoch 5/100] [Batch 141/347] [D loss: 0.562401] [G loss: 0.534153]\n",
      "[Epoch 5/100] [Batch 142/347] [D loss: 0.562371] [G loss: 0.542125]\n",
      "[Epoch 5/100] [Batch 143/347] [D loss: 0.562342] [G loss: 0.564113]\n",
      "[Epoch 5/100] [Batch 144/347] [D loss: 0.562313] [G loss: 0.566405]\n",
      "[Epoch 5/100] [Batch 145/347] [D loss: 0.562284] [G loss: 0.552309]\n",
      "[Epoch 5/100] [Batch 146/347] [D loss: 0.562255] [G loss: 0.535583]\n",
      "[Epoch 5/100] [Batch 147/347] [D loss: 0.562226] [G loss: 0.507513]\n",
      "[Epoch 5/100] [Batch 148/347] [D loss: 0.562197] [G loss: 0.495063]\n",
      "[Epoch 5/100] [Batch 149/347] [D loss: 0.562168] [G loss: 0.507966]\n",
      "[Epoch 5/100] [Batch 150/347] [D loss: 0.562138] [G loss: 0.508054]\n",
      "[Epoch 5/100] [Batch 151/347] [D loss: 0.562110] [G loss: 0.496896]\n",
      "[Epoch 5/100] [Batch 152/347] [D loss: 0.562081] [G loss: 0.507593]\n",
      "[Epoch 5/100] [Batch 153/347] [D loss: 0.562051] [G loss: 0.528068]\n",
      "[Epoch 5/100] [Batch 154/347] [D loss: 0.562022] [G loss: 0.532080]\n",
      "[Epoch 5/100] [Batch 155/347] [D loss: 0.561993] [G loss: 0.518998]\n",
      "[Epoch 5/100] [Batch 156/347] [D loss: 0.561964] [G loss: 0.502392]\n",
      "[Epoch 5/100] [Batch 157/347] [D loss: 0.561936] [G loss: 0.508597]\n",
      "[Epoch 5/100] [Batch 158/347] [D loss: 0.561906] [G loss: 0.532019]\n",
      "[Epoch 5/100] [Batch 159/347] [D loss: 0.561877] [G loss: 0.529207]\n",
      "[Epoch 5/100] [Batch 160/347] [D loss: 0.561848] [G loss: 0.509067]\n",
      "[Epoch 5/100] [Batch 161/347] [D loss: 0.561820] [G loss: 0.500400]\n",
      "[Epoch 5/100] [Batch 162/347] [D loss: 0.561791] [G loss: 0.505881]\n",
      "[Epoch 5/100] [Batch 163/347] [D loss: 0.561762] [G loss: 0.524292]\n",
      "[Epoch 5/100] [Batch 164/347] [D loss: 0.561733] [G loss: 0.539109]\n",
      "[Epoch 5/100] [Batch 165/347] [D loss: 0.561703] [G loss: 0.529882]\n",
      "[Epoch 5/100] [Batch 166/347] [D loss: 0.561675] [G loss: 0.491549]\n",
      "[Epoch 5/100] [Batch 167/347] [D loss: 0.561646] [G loss: 0.477039]\n",
      "[Epoch 5/100] [Batch 168/347] [D loss: 0.561617] [G loss: 0.487839]\n",
      "[Epoch 5/100] [Batch 169/347] [D loss: 0.561588] [G loss: 0.486899]\n",
      "[Epoch 5/100] [Batch 170/347] [D loss: 0.561559] [G loss: 0.483904]\n",
      "[Epoch 5/100] [Batch 171/347] [D loss: 0.561531] [G loss: 0.496001]\n",
      "[Epoch 5/100] [Batch 172/347] [D loss: 0.561502] [G loss: 0.500966]\n",
      "[Epoch 5/100] [Batch 173/347] [D loss: 0.561473] [G loss: 0.489683]\n",
      "[Epoch 5/100] [Batch 174/347] [D loss: 0.561443] [G loss: 0.487093]\n",
      "[Epoch 5/100] [Batch 175/347] [D loss: 0.561415] [G loss: 0.496686]\n",
      "[Epoch 5/100] [Batch 176/347] [D loss: 0.561386] [G loss: 0.509859]\n",
      "[Epoch 5/100] [Batch 177/347] [D loss: 0.561357] [G loss: 0.510388]\n",
      "[Epoch 5/100] [Batch 178/347] [D loss: 0.561328] [G loss: 0.504143]\n",
      "[Epoch 5/100] [Batch 179/347] [D loss: 0.561299] [G loss: 0.497103]\n",
      "[Epoch 5/100] [Batch 180/347] [D loss: 0.561270] [G loss: 0.490390]\n",
      "[Epoch 5/100] [Batch 181/347] [D loss: 0.561241] [G loss: 0.490384]\n",
      "[Epoch 5/100] [Batch 182/347] [D loss: 0.561212] [G loss: 0.487806]\n",
      "[Epoch 5/100] [Batch 183/347] [D loss: 0.561184] [G loss: 0.491317]\n",
      "[Epoch 5/100] [Batch 184/347] [D loss: 0.561155] [G loss: 0.494674]\n",
      "[Epoch 5/100] [Batch 185/347] [D loss: 0.561126] [G loss: 0.492811]\n",
      "[Epoch 5/100] [Batch 186/347] [D loss: 0.561097] [G loss: 0.492177]\n",
      "[Epoch 5/100] [Batch 187/347] [D loss: 0.561068] [G loss: 0.486443]\n",
      "[Epoch 5/100] [Batch 188/347] [D loss: 0.561039] [G loss: 0.482804]\n",
      "[Epoch 5/100] [Batch 189/347] [D loss: 0.561011] [G loss: 0.481517]\n",
      "[Epoch 5/100] [Batch 190/347] [D loss: 0.560982] [G loss: 0.469151]\n",
      "[Epoch 5/100] [Batch 191/347] [D loss: 0.560953] [G loss: 0.465889]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 192/347] [D loss: 0.560924] [G loss: 0.457411]\n",
      "[Epoch 5/100] [Batch 193/347] [D loss: 0.560896] [G loss: 0.465484]\n",
      "[Epoch 5/100] [Batch 194/347] [D loss: 0.560867] [G loss: 0.461910]\n",
      "[Epoch 5/100] [Batch 195/347] [D loss: 0.560838] [G loss: 0.471092]\n",
      "[Epoch 5/100] [Batch 196/347] [D loss: 0.560809] [G loss: 0.469091]\n",
      "[Epoch 5/100] [Batch 197/347] [D loss: 0.560781] [G loss: 0.464549]\n",
      "[Epoch 5/100] [Batch 198/347] [D loss: 0.560752] [G loss: 0.462378]\n",
      "[Epoch 5/100] [Batch 199/347] [D loss: 0.560723] [G loss: 0.463772]\n",
      "[Epoch 5/100] [Batch 200/347] [D loss: 0.560695] [G loss: 0.458803]\n",
      "[Epoch 5/100] [Batch 201/347] [D loss: 0.560666] [G loss: 0.460547]\n",
      "[Epoch 5/100] [Batch 202/347] [D loss: 0.560637] [G loss: 0.472009]\n",
      "[Epoch 5/100] [Batch 203/347] [D loss: 0.560609] [G loss: 0.480542]\n",
      "[Epoch 5/100] [Batch 204/347] [D loss: 0.560580] [G loss: 0.476958]\n",
      "[Epoch 5/100] [Batch 205/347] [D loss: 0.560552] [G loss: 0.468949]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 206/347] [D loss: 0.560523] [G loss: 0.456536]\n",
      "[Epoch 5/100] [Batch 207/347] [D loss: 0.560494] [G loss: 0.466364]\n",
      "[Epoch 5/100] [Batch 208/347] [D loss: 0.560466] [G loss: 0.467618]\n",
      "[Epoch 5/100] [Batch 209/347] [D loss: 0.560437] [G loss: 0.462351]\n",
      "[Epoch 5/100] [Batch 210/347] [D loss: 0.560408] [G loss: 0.469219]\n",
      "[Epoch 5/100] [Batch 211/347] [D loss: 0.560380] [G loss: 0.466954]\n",
      "[Epoch 5/100] [Batch 212/347] [D loss: 0.560351] [G loss: 0.465703]\n",
      "[Epoch 5/100] [Batch 213/347] [D loss: 0.560323] [G loss: 0.471341]\n",
      "[Epoch 5/100] [Batch 214/347] [D loss: 0.560294] [G loss: 0.479146]\n",
      "[Epoch 5/100] [Batch 215/347] [D loss: 0.560265] [G loss: 0.487319]\n",
      "[Epoch 5/100] [Batch 216/347] [D loss: 0.560237] [G loss: 0.470479]\n",
      "[Epoch 5/100] [Batch 217/347] [D loss: 0.560208] [G loss: 0.471054]\n",
      "[Epoch 5/100] [Batch 218/347] [D loss: 0.560180] [G loss: 0.477626]\n",
      "[Epoch 5/100] [Batch 219/347] [D loss: 0.560151] [G loss: 0.489674]\n",
      "[Epoch 5/100] [Batch 220/347] [D loss: 0.560123] [G loss: 0.505495]\n",
      "[Epoch 5/100] [Batch 221/347] [D loss: 0.560094] [G loss: 0.506875]\n",
      "[Epoch 5/100] [Batch 222/347] [D loss: 0.560065] [G loss: 0.498791]\n",
      "[Epoch 5/100] [Batch 223/347] [D loss: 0.560037] [G loss: 0.497259]\n",
      "[Epoch 5/100] [Batch 224/347] [D loss: 0.560008] [G loss: 0.492894]\n",
      "[Epoch 5/100] [Batch 225/347] [D loss: 0.559980] [G loss: 0.478970]\n",
      "[Epoch 5/100] [Batch 226/347] [D loss: 0.559951] [G loss: 0.474576]\n",
      "[Epoch 5/100] [Batch 227/347] [D loss: 0.559922] [G loss: 0.485243]\n",
      "[Epoch 5/100] [Batch 228/347] [D loss: 0.559894] [G loss: 0.487334]\n",
      "[Epoch 5/100] [Batch 229/347] [D loss: 0.559866] [G loss: 0.482888]\n",
      "[Epoch 5/100] [Batch 230/347] [D loss: 0.559837] [G loss: 0.479406]\n",
      "[Epoch 5/100] [Batch 231/347] [D loss: 0.559809] [G loss: 0.479520]\n",
      "[Epoch 5/100] [Batch 232/347] [D loss: 0.559780] [G loss: 0.475391]\n",
      "[Epoch 5/100] [Batch 233/347] [D loss: 0.559752] [G loss: 0.473296]\n",
      "[Epoch 5/100] [Batch 234/347] [D loss: 0.559723] [G loss: 0.478084]\n",
      "[Epoch 5/100] [Batch 235/347] [D loss: 0.559695] [G loss: 0.466752]\n",
      "[Epoch 5/100] [Batch 236/347] [D loss: 0.559667] [G loss: 0.464198]\n",
      "[Epoch 5/100] [Batch 237/347] [D loss: 0.559638] [G loss: 0.467389]\n",
      "[Epoch 5/100] [Batch 238/347] [D loss: 0.559609] [G loss: 0.471507]\n",
      "[Epoch 5/100] [Batch 239/347] [D loss: 0.559581] [G loss: 0.469609]\n",
      "[Epoch 5/100] [Batch 240/347] [D loss: 0.559552] [G loss: 0.465807]\n",
      "[Epoch 5/100] [Batch 241/347] [D loss: 0.559524] [G loss: 0.459823]\n",
      "[Epoch 5/100] [Batch 242/347] [D loss: 0.559495] [G loss: 0.457592]\n",
      "[Epoch 5/100] [Batch 243/347] [D loss: 0.559467] [G loss: 0.464855]\n",
      "[Epoch 5/100] [Batch 244/347] [D loss: 0.559439] [G loss: 0.473313]\n",
      "[Epoch 5/100] [Batch 245/347] [D loss: 0.559411] [G loss: 0.471878]\n",
      "[Epoch 5/100] [Batch 246/347] [D loss: 0.559382] [G loss: 0.464914]\n",
      "[Epoch 5/100] [Batch 247/347] [D loss: 0.559353] [G loss: 0.473312]\n",
      "[Epoch 5/100] [Batch 248/347] [D loss: 0.559324] [G loss: 0.478656]\n",
      "[Epoch 5/100] [Batch 249/347] [D loss: 0.559296] [G loss: 0.485206]\n",
      "[Epoch 5/100] [Batch 250/347] [D loss: 0.559268] [G loss: 0.476851]\n",
      "[Epoch 5/100] [Batch 251/347] [D loss: 0.559240] [G loss: 0.463365]\n",
      "[Epoch 5/100] [Batch 252/347] [D loss: 0.559212] [G loss: 0.466449]\n",
      "[Epoch 5/100] [Batch 253/347] [D loss: 0.559183] [G loss: 0.467013]\n",
      "[Epoch 5/100] [Batch 254/347] [D loss: 0.559155] [G loss: 0.465368]\n",
      "[Epoch 5/100] [Batch 255/347] [D loss: 0.559126] [G loss: 0.463858]\n",
      "[Epoch 5/100] [Batch 256/347] [D loss: 0.559098] [G loss: 0.468851]\n",
      "[Epoch 5/100] [Batch 257/347] [D loss: 0.559069] [G loss: 0.470453]\n",
      "[Epoch 5/100] [Batch 258/347] [D loss: 0.559041] [G loss: 0.464753]\n",
      "[Epoch 5/100] [Batch 259/347] [D loss: 0.559012] [G loss: 0.476044]\n",
      "[Epoch 5/100] [Batch 260/347] [D loss: 0.558984] [G loss: 0.490546]\n",
      "[Epoch 5/100] [Batch 261/347] [D loss: 0.558956] [G loss: 0.483170]\n",
      "[Epoch 5/100] [Batch 262/347] [D loss: 0.558927] [G loss: 0.468181]\n",
      "[Epoch 5/100] [Batch 263/347] [D loss: 0.558899] [G loss: 0.469213]\n",
      "[Epoch 5/100] [Batch 264/347] [D loss: 0.558871] [G loss: 0.483649]\n",
      "[Epoch 5/100] [Batch 265/347] [D loss: 0.558842] [G loss: 0.488699]\n",
      "[Epoch 5/100] [Batch 266/347] [D loss: 0.558814] [G loss: 0.481388]\n",
      "[Epoch 5/100] [Batch 267/347] [D loss: 0.558786] [G loss: 0.474458]\n",
      "[Epoch 5/100] [Batch 268/347] [D loss: 0.558758] [G loss: 0.481239]\n",
      "[Epoch 5/100] [Batch 269/347] [D loss: 0.558729] [G loss: 0.492184]\n",
      "[Epoch 5/100] [Batch 270/347] [D loss: 0.558701] [G loss: 0.488530]\n",
      "[Epoch 5/100] [Batch 271/347] [D loss: 0.558673] [G loss: 0.476515]\n",
      "[Epoch 5/100] [Batch 272/347] [D loss: 0.558645] [G loss: 0.467607]\n",
      "[Epoch 5/100] [Batch 273/347] [D loss: 0.558616] [G loss: 0.479176]\n",
      "[Epoch 5/100] [Batch 274/347] [D loss: 0.558588] [G loss: 0.512672]\n",
      "[Epoch 5/100] [Batch 275/347] [D loss: 0.558560] [G loss: 0.509290]\n",
      "[Epoch 5/100] [Batch 276/347] [D loss: 0.558532] [G loss: 0.476628]\n",
      "[Epoch 5/100] [Batch 277/347] [D loss: 0.558504] [G loss: 0.461686]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 278/347] [D loss: 0.558475] [G loss: 0.451944]\n",
      "[Epoch 5/100] [Batch 279/347] [D loss: 0.558447] [G loss: 0.458032]\n",
      "[Epoch 5/100] [Batch 280/347] [D loss: 0.558419] [G loss: 0.461732]\n",
      "[Epoch 5/100] [Batch 281/347] [D loss: 0.558391] [G loss: 0.460067]\n",
      "[Epoch 5/100] [Batch 282/347] [D loss: 0.558363] [G loss: 0.457876]\n",
      "[Epoch 5/100] [Batch 283/347] [D loss: 0.558334] [G loss: 0.461357]\n",
      "[Epoch 5/100] [Batch 284/347] [D loss: 0.558307] [G loss: 0.460410]\n",
      "[Epoch 5/100] [Batch 285/347] [D loss: 0.558278] [G loss: 0.456172]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 286/347] [D loss: 0.558250] [G loss: 0.451040]\n",
      "[Epoch 5/100] [Batch 287/347] [D loss: 0.558222] [G loss: 0.454511]\n",
      "[Epoch 5/100] [Batch 288/347] [D loss: 0.558194] [G loss: 0.480898]\n",
      "[Epoch 5/100] [Batch 289/347] [D loss: 0.558166] [G loss: 0.484849]\n",
      "[Epoch 5/100] [Batch 290/347] [D loss: 0.558138] [G loss: 0.462189]\n",
      "[Epoch 5/100] [Batch 291/347] [D loss: 0.558110] [G loss: 0.464551]\n",
      "[Epoch 5/100] [Batch 292/347] [D loss: 0.558082] [G loss: 0.455582]\n",
      "[Epoch 5/100] [Batch 293/347] [D loss: 0.558054] [G loss: 0.467867]\n",
      "[Epoch 5/100] [Batch 294/347] [D loss: 0.558026] [G loss: 0.478070]\n",
      "[Epoch 5/100] [Batch 295/347] [D loss: 0.557998] [G loss: 0.475938]\n",
      "[Epoch 5/100] [Batch 296/347] [D loss: 0.557970] [G loss: 0.472074]\n",
      "[Epoch 5/100] [Batch 297/347] [D loss: 0.557941] [G loss: 0.485490]\n",
      "[Epoch 5/100] [Batch 298/347] [D loss: 0.557914] [G loss: 0.480464]\n",
      "[Epoch 5/100] [Batch 299/347] [D loss: 0.557885] [G loss: 0.479066]\n",
      "[Epoch 5/100] [Batch 300/347] [D loss: 0.557857] [G loss: 0.474158]\n",
      "[Epoch 5/100] [Batch 301/347] [D loss: 0.557830] [G loss: 0.473395]\n",
      "[Epoch 5/100] [Batch 302/347] [D loss: 0.557801] [G loss: 0.478197]\n",
      "[Epoch 5/100] [Batch 303/347] [D loss: 0.557773] [G loss: 0.462288]\n",
      "[Epoch 5/100] [Batch 304/347] [D loss: 0.557745] [G loss: 0.463673]\n",
      "[Epoch 5/100] [Batch 305/347] [D loss: 0.557717] [G loss: 0.476679]\n",
      "[Epoch 5/100] [Batch 306/347] [D loss: 0.557689] [G loss: 0.467781]\n",
      "[Epoch 5/100] [Batch 307/347] [D loss: 0.557661] [G loss: 0.479320]\n",
      "[Epoch 5/100] [Batch 308/347] [D loss: 0.557633] [G loss: 0.475674]\n",
      "[Epoch 5/100] [Batch 309/347] [D loss: 0.557606] [G loss: 0.457474]\n",
      "[Epoch 5/100] [Batch 310/347] [D loss: 0.557578] [G loss: 0.475234]\n",
      "[Epoch 5/100] [Batch 311/347] [D loss: 0.557550] [G loss: 0.478267]\n",
      "[Epoch 5/100] [Batch 312/347] [D loss: 0.557522] [G loss: 0.478090]\n",
      "[Epoch 5/100] [Batch 313/347] [D loss: 0.557494] [G loss: 0.477310]\n",
      "[Epoch 5/100] [Batch 314/347] [D loss: 0.557466] [G loss: 0.470980]\n",
      "[Epoch 5/100] [Batch 315/347] [D loss: 0.557438] [G loss: 0.461486]\n",
      "[Epoch 5/100] [Batch 316/347] [D loss: 0.557410] [G loss: 0.456456]\n",
      "[Epoch 5/100] [Batch 317/347] [D loss: 0.557382] [G loss: 0.475001]\n",
      "[Epoch 5/100] [Batch 318/347] [D loss: 0.557354] [G loss: 0.452889]\n",
      "[Epoch 5/100] [Batch 319/347] [D loss: 0.557326] [G loss: 0.482747]\n",
      "[Epoch 5/100] [Batch 320/347] [D loss: 0.557299] [G loss: 0.496317]\n",
      "[Epoch 5/100] [Batch 321/347] [D loss: 0.557271] [G loss: 0.485788]\n",
      "[Epoch 5/100] [Batch 322/347] [D loss: 0.557243] [G loss: 0.472852]\n",
      "[Epoch 5/100] [Batch 323/347] [D loss: 0.557215] [G loss: 0.472086]\n",
      "[Epoch 5/100] [Batch 324/347] [D loss: 0.557187] [G loss: 0.474872]\n",
      "[Epoch 5/100] [Batch 325/347] [D loss: 0.557159] [G loss: 0.463704]\n",
      "[Epoch 5/100] [Batch 326/347] [D loss: 0.557131] [G loss: 0.452034]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 327/347] [D loss: 0.557103] [G loss: 0.449791]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 328/347] [D loss: 0.557075] [G loss: 0.448769]\n",
      "[Epoch 5/100] [Batch 329/347] [D loss: 0.557048] [G loss: 0.470659]\n",
      "[Epoch 5/100] [Batch 330/347] [D loss: 0.557019] [G loss: 0.486307]\n",
      "[Epoch 5/100] [Batch 331/347] [D loss: 0.556992] [G loss: 0.468260]\n",
      "[Epoch 5/100] [Batch 332/347] [D loss: 0.556964] [G loss: 0.461481]\n",
      "[Epoch 5/100] [Batch 333/347] [D loss: 0.556937] [G loss: 0.472824]\n",
      "[Epoch 5/100] [Batch 334/347] [D loss: 0.556909] [G loss: 0.474280]\n",
      "[Epoch 5/100] [Batch 335/347] [D loss: 0.556881] [G loss: 0.462424]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 5/100] [Batch 336/347] [D loss: 0.556853] [G loss: 0.448222]\n",
      "[Epoch 5/100] [Batch 337/347] [D loss: 0.556825] [G loss: 0.454151]\n",
      "[Epoch 5/100] [Batch 338/347] [D loss: 0.556797] [G loss: 0.468497]\n",
      "[Epoch 5/100] [Batch 339/347] [D loss: 0.556769] [G loss: 0.473552]\n",
      "[Epoch 5/100] [Batch 340/347] [D loss: 0.556742] [G loss: 0.473643]\n",
      "[Epoch 5/100] [Batch 341/347] [D loss: 0.556714] [G loss: 0.468594]\n",
      "[Epoch 5/100] [Batch 342/347] [D loss: 0.556686] [G loss: 0.460796]\n",
      "[Epoch 5/100] [Batch 343/347] [D loss: 0.556658] [G loss: 0.465223]\n",
      "[Epoch 5/100] [Batch 344/347] [D loss: 0.556630] [G loss: 0.461664]\n",
      "[Epoch 5/100] [Batch 345/347] [D loss: 0.556603] [G loss: 0.472169]\n",
      "[Epoch 5/100] [Batch 346/347] [D loss: 0.556575] [G loss: 0.490811]\n",
      "[Epoch 5/100] [Batch 347/347] [D loss: 0.556547] [G loss: 0.497306]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 1/347] [D loss: 0.556520] [G loss: 0.463136]\n",
      "[Epoch 6/100] [Batch 2/347] [D loss: 0.556492] [G loss: 0.468327]\n",
      "[Epoch 6/100] [Batch 3/347] [D loss: 0.556464] [G loss: 0.468207]\n",
      "[Epoch 6/100] [Batch 4/347] [D loss: 0.556437] [G loss: 0.469314]\n",
      "[Epoch 6/100] [Batch 5/347] [D loss: 0.556409] [G loss: 0.468316]\n",
      "[Epoch 6/100] [Batch 6/347] [D loss: 0.556381] [G loss: 0.468486]\n",
      "[Epoch 6/100] [Batch 7/347] [D loss: 0.556354] [G loss: 0.467987]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 8/347] [D loss: 0.556326] [G loss: 0.463046]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 9/347] [D loss: 0.556298] [G loss: 0.461760]\n",
      "[Epoch 6/100] [Batch 10/347] [D loss: 0.556271] [G loss: 0.463069]\n",
      "[Epoch 6/100] [Batch 11/347] [D loss: 0.556243] [G loss: 0.462607]\n",
      "[Epoch 6/100] [Batch 12/347] [D loss: 0.556216] [G loss: 0.462859]\n",
      "[Epoch 6/100] [Batch 13/347] [D loss: 0.556188] [G loss: 0.461981]\n",
      "[Epoch 6/100] [Batch 14/347] [D loss: 0.556160] [G loss: 0.464403]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 15/347] [D loss: 0.556133] [G loss: 0.460723]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 16/347] [D loss: 0.556105] [G loss: 0.456704]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 17/347] [D loss: 0.556078] [G loss: 0.446190]\n",
      "[Epoch 6/100] [Batch 18/347] [D loss: 0.556050] [G loss: 0.453191]\n",
      "[Epoch 6/100] [Batch 19/347] [D loss: 0.556023] [G loss: 0.450482]\n",
      "[Epoch 6/100] [Batch 20/347] [D loss: 0.555995] [G loss: 0.463623]\n",
      "[Epoch 6/100] [Batch 21/347] [D loss: 0.555968] [G loss: 0.460076]\n",
      "[Epoch 6/100] [Batch 22/347] [D loss: 0.555940] [G loss: 0.455184]\n",
      "[Epoch 6/100] [Batch 23/347] [D loss: 0.555913] [G loss: 0.448833]\n",
      "[Epoch 6/100] [Batch 24/347] [D loss: 0.555885] [G loss: 0.448069]\n",
      "[Epoch 6/100] [Batch 25/347] [D loss: 0.555858] [G loss: 0.447276]\n",
      "[Epoch 6/100] [Batch 26/347] [D loss: 0.555830] [G loss: 0.457306]\n",
      "[Epoch 6/100] [Batch 27/347] [D loss: 0.555803] [G loss: 0.463045]\n",
      "[Epoch 6/100] [Batch 28/347] [D loss: 0.555775] [G loss: 0.461836]\n",
      "[Epoch 6/100] [Batch 29/347] [D loss: 0.555748] [G loss: 0.457580]\n",
      "[Epoch 6/100] [Batch 30/347] [D loss: 0.555721] [G loss: 0.464378]\n",
      "[Epoch 6/100] [Batch 31/347] [D loss: 0.555693] [G loss: 0.466851]\n",
      "[Epoch 6/100] [Batch 32/347] [D loss: 0.555666] [G loss: 0.461679]\n",
      "[Epoch 6/100] [Batch 33/347] [D loss: 0.555638] [G loss: 0.456087]\n",
      "[Epoch 6/100] [Batch 34/347] [D loss: 0.555611] [G loss: 0.456930]\n",
      "[Epoch 6/100] [Batch 35/347] [D loss: 0.555583] [G loss: 0.455519]\n",
      "[Epoch 6/100] [Batch 36/347] [D loss: 0.555556] [G loss: 0.446759]\n",
      "[Epoch 6/100] [Batch 37/347] [D loss: 0.555529] [G loss: 0.468875]\n",
      "[Epoch 6/100] [Batch 38/347] [D loss: 0.555501] [G loss: 0.484279]\n",
      "[Epoch 6/100] [Batch 39/347] [D loss: 0.555474] [G loss: 0.474930]\n",
      "[Epoch 6/100] [Batch 40/347] [D loss: 0.555447] [G loss: 0.474817]\n",
      "[Epoch 6/100] [Batch 41/347] [D loss: 0.555420] [G loss: 0.476343]\n",
      "[Epoch 6/100] [Batch 42/347] [D loss: 0.555393] [G loss: 0.469529]\n",
      "[Epoch 6/100] [Batch 43/347] [D loss: 0.555366] [G loss: 0.454083]\n",
      "[Epoch 6/100] [Batch 44/347] [D loss: 0.555339] [G loss: 0.452644]\n",
      "[Epoch 6/100] [Batch 45/347] [D loss: 0.555311] [G loss: 0.470102]\n",
      "[Epoch 6/100] [Batch 46/347] [D loss: 0.555284] [G loss: 0.464961]\n",
      "[Epoch 6/100] [Batch 47/347] [D loss: 0.555257] [G loss: 0.451208]\n",
      "[Epoch 6/100] [Batch 48/347] [D loss: 0.555229] [G loss: 0.483343]\n",
      "[Epoch 6/100] [Batch 49/347] [D loss: 0.555202] [G loss: 0.491915]\n",
      "[Epoch 6/100] [Batch 50/347] [D loss: 0.555175] [G loss: 0.507723]\n",
      "[Epoch 6/100] [Batch 51/347] [D loss: 0.555148] [G loss: 0.492521]\n",
      "[Epoch 6/100] [Batch 52/347] [D loss: 0.555121] [G loss: 0.452189]\n",
      "[Epoch 6/100] [Batch 53/347] [D loss: 0.555094] [G loss: 0.455243]\n",
      "[Epoch 6/100] [Batch 54/347] [D loss: 0.555066] [G loss: 0.507550]\n",
      "[Epoch 6/100] [Batch 55/347] [D loss: 0.555038] [G loss: 0.529735]\n",
      "[Epoch 6/100] [Batch 56/347] [D loss: 0.555011] [G loss: 0.516668]\n",
      "[Epoch 6/100] [Batch 57/347] [D loss: 0.554985] [G loss: 0.482459]\n",
      "[Epoch 6/100] [Batch 58/347] [D loss: 0.554958] [G loss: 0.450914]\n",
      "[Epoch 6/100] [Batch 59/347] [D loss: 0.554931] [G loss: 0.465305]\n",
      "[Epoch 6/100] [Batch 60/347] [D loss: 0.554903] [G loss: 0.483662]\n",
      "[Epoch 6/100] [Batch 61/347] [D loss: 0.554875] [G loss: 0.495776]\n",
      "[Epoch 6/100] [Batch 62/347] [D loss: 0.554848] [G loss: 0.519474]\n",
      "[Epoch 6/100] [Batch 63/347] [D loss: 0.554820] [G loss: 0.521506]\n",
      "[Epoch 6/100] [Batch 64/347] [D loss: 0.554793] [G loss: 0.484750]\n",
      "[Epoch 6/100] [Batch 65/347] [D loss: 0.554767] [G loss: 0.455792]\n",
      "[Epoch 6/100] [Batch 66/347] [D loss: 0.554740] [G loss: 0.458276]\n",
      "[Epoch 6/100] [Batch 67/347] [D loss: 0.554712] [G loss: 0.467998]\n",
      "[Epoch 6/100] [Batch 68/347] [D loss: 0.554684] [G loss: 0.485691]\n",
      "[Epoch 6/100] [Batch 69/347] [D loss: 0.554657] [G loss: 0.504136]\n",
      "[Epoch 6/100] [Batch 70/347] [D loss: 0.554629] [G loss: 0.502798]\n",
      "[Epoch 6/100] [Batch 71/347] [D loss: 0.554602] [G loss: 0.505436]\n",
      "[Epoch 6/100] [Batch 72/347] [D loss: 0.554575] [G loss: 0.507979]\n",
      "[Epoch 6/100] [Batch 73/347] [D loss: 0.554548] [G loss: 0.483177]\n",
      "[Epoch 6/100] [Batch 74/347] [D loss: 0.554521] [G loss: 0.469123]\n",
      "[Epoch 6/100] [Batch 75/347] [D loss: 0.554494] [G loss: 0.498499]\n",
      "[Epoch 6/100] [Batch 76/347] [D loss: 0.554466] [G loss: 0.500054]\n",
      "[Epoch 6/100] [Batch 77/347] [D loss: 0.554439] [G loss: 0.465573]\n",
      "[Epoch 6/100] [Batch 78/347] [D loss: 0.554412] [G loss: 0.463639]\n",
      "[Epoch 6/100] [Batch 79/347] [D loss: 0.554385] [G loss: 0.465512]\n",
      "[Epoch 6/100] [Batch 80/347] [D loss: 0.554358] [G loss: 0.463170]\n",
      "[Epoch 6/100] [Batch 81/347] [D loss: 0.554330] [G loss: 0.468435]\n",
      "[Epoch 6/100] [Batch 82/347] [D loss: 0.554303] [G loss: 0.473471]\n",
      "[Epoch 6/100] [Batch 83/347] [D loss: 0.554276] [G loss: 0.465903]\n",
      "[Epoch 6/100] [Batch 84/347] [D loss: 0.554249] [G loss: 0.472401]\n",
      "[Epoch 6/100] [Batch 85/347] [D loss: 0.554222] [G loss: 0.473012]\n",
      "[Epoch 6/100] [Batch 86/347] [D loss: 0.554195] [G loss: 0.467227]\n",
      "[Epoch 6/100] [Batch 87/347] [D loss: 0.554167] [G loss: 0.464806]\n",
      "[Epoch 6/100] [Batch 88/347] [D loss: 0.554140] [G loss: 0.467895]\n",
      "[Epoch 6/100] [Batch 89/347] [D loss: 0.554113] [G loss: 0.470989]\n",
      "[Epoch 6/100] [Batch 90/347] [D loss: 0.554086] [G loss: 0.466848]\n",
      "[Epoch 6/100] [Batch 91/347] [D loss: 0.554059] [G loss: 0.465150]\n",
      "[Epoch 6/100] [Batch 92/347] [D loss: 0.554032] [G loss: 0.466249]\n",
      "[Epoch 6/100] [Batch 93/347] [D loss: 0.554005] [G loss: 0.463982]\n",
      "[Epoch 6/100] [Batch 94/347] [D loss: 0.553978] [G loss: 0.460067]\n",
      "[Epoch 6/100] [Batch 95/347] [D loss: 0.553951] [G loss: 0.460254]\n",
      "[Epoch 6/100] [Batch 96/347] [D loss: 0.553924] [G loss: 0.455203]\n",
      "[Epoch 6/100] [Batch 97/347] [D loss: 0.553897] [G loss: 0.449798]\n",
      "[Epoch 6/100] [Batch 98/347] [D loss: 0.553870] [G loss: 0.454316]\n",
      "[Epoch 6/100] [Batch 99/347] [D loss: 0.553843] [G loss: 0.457723]\n",
      "[Epoch 6/100] [Batch 100/347] [D loss: 0.553816] [G loss: 0.453775]\n",
      "[Epoch 6/100] [Batch 101/347] [D loss: 0.553790] [G loss: 0.452257]\n",
      "[Epoch 6/100] [Batch 102/347] [D loss: 0.553763] [G loss: 0.453197]\n",
      "[Epoch 6/100] [Batch 103/347] [D loss: 0.553736] [G loss: 0.452637]\n",
      "[Epoch 6/100] [Batch 104/347] [D loss: 0.553709] [G loss: 0.454593]\n",
      "[Epoch 6/100] [Batch 105/347] [D loss: 0.553682] [G loss: 0.455978]\n",
      "[Epoch 6/100] [Batch 106/347] [D loss: 0.553655] [G loss: 0.454742]\n",
      "[Epoch 6/100] [Batch 107/347] [D loss: 0.553628] [G loss: 0.448647]\n",
      "[Epoch 6/100] [Batch 108/347] [D loss: 0.553601] [G loss: 0.465431]\n",
      "[Epoch 6/100] [Batch 109/347] [D loss: 0.553575] [G loss: 0.458342]\n",
      "[Epoch 6/100] [Batch 110/347] [D loss: 0.553548] [G loss: 0.446234]\n",
      "[Epoch 6/100] [Batch 111/347] [D loss: 0.553521] [G loss: 0.451971]\n",
      "[Epoch 6/100] [Batch 112/347] [D loss: 0.553494] [G loss: 0.457626]\n",
      "[Epoch 6/100] [Batch 113/347] [D loss: 0.553467] [G loss: 0.462317]\n",
      "[Epoch 6/100] [Batch 114/347] [D loss: 0.553441] [G loss: 0.483189]\n",
      "[Epoch 6/100] [Batch 115/347] [D loss: 0.553414] [G loss: 0.484526]\n",
      "[Epoch 6/100] [Batch 116/347] [D loss: 0.553387] [G loss: 0.478802]\n",
      "[Epoch 6/100] [Batch 117/347] [D loss: 0.553360] [G loss: 0.453484]\n",
      "[Epoch 6/100] [Batch 118/347] [D loss: 0.553333] [G loss: 0.454050]\n",
      "[Epoch 6/100] [Batch 119/347] [D loss: 0.553306] [G loss: 0.456228]\n",
      "[Epoch 6/100] [Batch 120/347] [D loss: 0.553279] [G loss: 0.455251]\n",
      "[Epoch 6/100] [Batch 121/347] [D loss: 0.553253] [G loss: 0.453606]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 122/347] [D loss: 0.553226] [G loss: 0.440698]\n",
      "[Epoch 6/100] [Batch 123/347] [D loss: 0.553199] [G loss: 0.441813]\n",
      "[Epoch 6/100] [Batch 124/347] [D loss: 0.553172] [G loss: 0.441308]\n",
      "[Epoch 6/100] [Batch 125/347] [D loss: 0.553146] [G loss: 0.449433]\n",
      "[Epoch 6/100] [Batch 126/347] [D loss: 0.553119] [G loss: 0.461931]\n",
      "[Epoch 6/100] [Batch 127/347] [D loss: 0.553092] [G loss: 0.463256]\n",
      "[Epoch 6/100] [Batch 128/347] [D loss: 0.553065] [G loss: 0.457627]\n",
      "[Epoch 6/100] [Batch 129/347] [D loss: 0.553038] [G loss: 0.452978]\n",
      "[Epoch 6/100] [Batch 130/347] [D loss: 0.553012] [G loss: 0.456149]\n",
      "[Epoch 6/100] [Batch 131/347] [D loss: 0.552985] [G loss: 0.453808]\n",
      "[Epoch 6/100] [Batch 132/347] [D loss: 0.552958] [G loss: 0.476548]\n",
      "[Epoch 6/100] [Batch 133/347] [D loss: 0.552931] [G loss: 0.483777]\n",
      "[Epoch 6/100] [Batch 134/347] [D loss: 0.552904] [G loss: 0.499118]\n",
      "[Epoch 6/100] [Batch 135/347] [D loss: 0.552878] [G loss: 0.508506]\n",
      "[Epoch 6/100] [Batch 136/347] [D loss: 0.552851] [G loss: 0.467055]\n",
      "[Epoch 6/100] [Batch 137/347] [D loss: 0.552825] [G loss: 0.452353]\n",
      "[Epoch 6/100] [Batch 138/347] [D loss: 0.552798] [G loss: 0.472437]\n",
      "[Epoch 6/100] [Batch 139/347] [D loss: 0.552771] [G loss: 0.496426]\n",
      "[Epoch 6/100] [Batch 140/347] [D loss: 0.552744] [G loss: 0.507941]\n",
      "[Epoch 6/100] [Batch 141/347] [D loss: 0.552718] [G loss: 0.514877]\n",
      "[Epoch 6/100] [Batch 142/347] [D loss: 0.552691] [G loss: 0.522818]\n",
      "[Epoch 6/100] [Batch 143/347] [D loss: 0.552664] [G loss: 0.544794]\n",
      "[Epoch 6/100] [Batch 144/347] [D loss: 0.552638] [G loss: 0.547127]\n",
      "[Epoch 6/100] [Batch 145/347] [D loss: 0.552611] [G loss: 0.533063]\n",
      "[Epoch 6/100] [Batch 146/347] [D loss: 0.552585] [G loss: 0.516352]\n",
      "[Epoch 6/100] [Batch 147/347] [D loss: 0.552559] [G loss: 0.488298]\n",
      "[Epoch 6/100] [Batch 148/347] [D loss: 0.552532] [G loss: 0.475903]\n",
      "[Epoch 6/100] [Batch 149/347] [D loss: 0.552506] [G loss: 0.488903]\n",
      "[Epoch 6/100] [Batch 150/347] [D loss: 0.552479] [G loss: 0.489044]\n",
      "[Epoch 6/100] [Batch 151/347] [D loss: 0.552453] [G loss: 0.477958]\n",
      "[Epoch 6/100] [Batch 152/347] [D loss: 0.552426] [G loss: 0.488766]\n",
      "[Epoch 6/100] [Batch 153/347] [D loss: 0.552399] [G loss: 0.509268]\n",
      "[Epoch 6/100] [Batch 154/347] [D loss: 0.552372] [G loss: 0.513328]\n",
      "[Epoch 6/100] [Batch 155/347] [D loss: 0.552346] [G loss: 0.500372]\n",
      "[Epoch 6/100] [Batch 156/347] [D loss: 0.552319] [G loss: 0.483758]\n",
      "[Epoch 6/100] [Batch 157/347] [D loss: 0.552293] [G loss: 0.490014]\n",
      "[Epoch 6/100] [Batch 158/347] [D loss: 0.552266] [G loss: 0.513563]\n",
      "[Epoch 6/100] [Batch 159/347] [D loss: 0.552240] [G loss: 0.510784]\n",
      "[Epoch 6/100] [Batch 160/347] [D loss: 0.552213] [G loss: 0.490755]\n",
      "[Epoch 6/100] [Batch 161/347] [D loss: 0.552187] [G loss: 0.482171]\n",
      "[Epoch 6/100] [Batch 162/347] [D loss: 0.552160] [G loss: 0.487690]\n",
      "[Epoch 6/100] [Batch 163/347] [D loss: 0.552134] [G loss: 0.506200]\n",
      "[Epoch 6/100] [Batch 164/347] [D loss: 0.552107] [G loss: 0.521118]\n",
      "[Epoch 6/100] [Batch 165/347] [D loss: 0.552080] [G loss: 0.512003]\n",
      "[Epoch 6/100] [Batch 166/347] [D loss: 0.552054] [G loss: 0.473698]\n",
      "[Epoch 6/100] [Batch 167/347] [D loss: 0.552028] [G loss: 0.457251]\n",
      "[Epoch 6/100] [Batch 168/347] [D loss: 0.552002] [G loss: 0.467985]\n",
      "[Epoch 6/100] [Batch 169/347] [D loss: 0.551975] [G loss: 0.466939]\n",
      "[Epoch 6/100] [Batch 170/347] [D loss: 0.551949] [G loss: 0.463276]\n",
      "[Epoch 6/100] [Batch 171/347] [D loss: 0.551922] [G loss: 0.475326]\n",
      "[Epoch 6/100] [Batch 172/347] [D loss: 0.551895] [G loss: 0.480288]\n",
      "[Epoch 6/100] [Batch 173/347] [D loss: 0.551869] [G loss: 0.469029]\n",
      "[Epoch 6/100] [Batch 174/347] [D loss: 0.551842] [G loss: 0.466445]\n",
      "[Epoch 6/100] [Batch 175/347] [D loss: 0.551816] [G loss: 0.476079]\n",
      "[Epoch 6/100] [Batch 176/347] [D loss: 0.551790] [G loss: 0.489256]\n",
      "[Epoch 6/100] [Batch 177/347] [D loss: 0.551763] [G loss: 0.489828]\n",
      "[Epoch 6/100] [Batch 178/347] [D loss: 0.551737] [G loss: 0.483614]\n",
      "[Epoch 6/100] [Batch 179/347] [D loss: 0.551711] [G loss: 0.476682]\n",
      "[Epoch 6/100] [Batch 180/347] [D loss: 0.551684] [G loss: 0.470002]\n",
      "[Epoch 6/100] [Batch 181/347] [D loss: 0.551658] [G loss: 0.470084]\n",
      "[Epoch 6/100] [Batch 182/347] [D loss: 0.551631] [G loss: 0.467534]\n",
      "[Epoch 6/100] [Batch 183/347] [D loss: 0.551605] [G loss: 0.471148]\n",
      "[Epoch 6/100] [Batch 184/347] [D loss: 0.551579] [G loss: 0.474564]\n",
      "[Epoch 6/100] [Batch 185/347] [D loss: 0.551553] [G loss: 0.472765]\n",
      "[Epoch 6/100] [Batch 186/347] [D loss: 0.551526] [G loss: 0.472214]\n",
      "[Epoch 6/100] [Batch 187/347] [D loss: 0.551500] [G loss: 0.466540]\n",
      "[Epoch 6/100] [Batch 188/347] [D loss: 0.551473] [G loss: 0.462972]\n",
      "[Epoch 6/100] [Batch 189/347] [D loss: 0.551447] [G loss: 0.461761]\n",
      "[Epoch 6/100] [Batch 190/347] [D loss: 0.551421] [G loss: 0.449445]\n",
      "[Epoch 6/100] [Batch 191/347] [D loss: 0.551394] [G loss: 0.447980]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 192/347] [D loss: 0.551368] [G loss: 0.438741]\n",
      "[Epoch 6/100] [Batch 193/347] [D loss: 0.551342] [G loss: 0.446435]\n",
      "[Epoch 6/100] [Batch 194/347] [D loss: 0.551316] [G loss: 0.443000]\n",
      "[Epoch 6/100] [Batch 195/347] [D loss: 0.551289] [G loss: 0.451759]\n",
      "[Epoch 6/100] [Batch 196/347] [D loss: 0.551263] [G loss: 0.449470]\n",
      "[Epoch 6/100] [Batch 197/347] [D loss: 0.551237] [G loss: 0.444623]\n",
      "[Epoch 6/100] [Batch 198/347] [D loss: 0.551211] [G loss: 0.441720]\n",
      "[Epoch 6/100] [Batch 199/347] [D loss: 0.551184] [G loss: 0.442896]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 200/347] [D loss: 0.551158] [G loss: 0.437725]\n",
      "[Epoch 6/100] [Batch 201/347] [D loss: 0.551132] [G loss: 0.439720]\n",
      "[Epoch 6/100] [Batch 202/347] [D loss: 0.551106] [G loss: 0.451055]\n",
      "[Epoch 6/100] [Batch 203/347] [D loss: 0.551079] [G loss: 0.459453]\n",
      "[Epoch 6/100] [Batch 204/347] [D loss: 0.551053] [G loss: 0.455737]\n",
      "[Epoch 6/100] [Batch 205/347] [D loss: 0.551027] [G loss: 0.447607]\n",
      "[Epoch 6/100] [Batch 206/347] [D loss: 0.551001] [G loss: 0.438865]\n",
      "[Epoch 6/100] [Batch 207/347] [D loss: 0.550975] [G loss: 0.449729]\n",
      "[Epoch 6/100] [Batch 208/347] [D loss: 0.550949] [G loss: 0.450651]\n",
      "[Epoch 6/100] [Batch 209/347] [D loss: 0.550923] [G loss: 0.445138]\n",
      "[Epoch 6/100] [Batch 210/347] [D loss: 0.550896] [G loss: 0.451218]\n",
      "[Epoch 6/100] [Batch 211/347] [D loss: 0.550870] [G loss: 0.449313]\n",
      "[Epoch 6/100] [Batch 212/347] [D loss: 0.550844] [G loss: 0.447243]\n",
      "[Epoch 6/100] [Batch 213/347] [D loss: 0.550818] [G loss: 0.452722]\n",
      "[Epoch 6/100] [Batch 214/347] [D loss: 0.550792] [G loss: 0.459197]\n",
      "[Epoch 6/100] [Batch 215/347] [D loss: 0.550766] [G loss: 0.467508]\n",
      "[Epoch 6/100] [Batch 216/347] [D loss: 0.550740] [G loss: 0.451445]\n",
      "[Epoch 6/100] [Batch 217/347] [D loss: 0.550714] [G loss: 0.451907]\n",
      "[Epoch 6/100] [Batch 218/347] [D loss: 0.550688] [G loss: 0.459182]\n",
      "[Epoch 6/100] [Batch 219/347] [D loss: 0.550662] [G loss: 0.471214]\n",
      "[Epoch 6/100] [Batch 220/347] [D loss: 0.550636] [G loss: 0.486918]\n",
      "[Epoch 6/100] [Batch 221/347] [D loss: 0.550610] [G loss: 0.488202]\n",
      "[Epoch 6/100] [Batch 222/347] [D loss: 0.550583] [G loss: 0.480057]\n",
      "[Epoch 6/100] [Batch 223/347] [D loss: 0.550557] [G loss: 0.478501]\n",
      "[Epoch 6/100] [Batch 224/347] [D loss: 0.550531] [G loss: 0.474162]\n",
      "[Epoch 6/100] [Batch 225/347] [D loss: 0.550505] [G loss: 0.459308]\n",
      "[Epoch 6/100] [Batch 226/347] [D loss: 0.550478] [G loss: 0.455366]\n",
      "[Epoch 6/100] [Batch 227/347] [D loss: 0.550452] [G loss: 0.466016]\n",
      "[Epoch 6/100] [Batch 228/347] [D loss: 0.550426] [G loss: 0.468962]\n",
      "[Epoch 6/100] [Batch 229/347] [D loss: 0.550400] [G loss: 0.464476]\n",
      "[Epoch 6/100] [Batch 230/347] [D loss: 0.550375] [G loss: 0.460959]\n",
      "[Epoch 6/100] [Batch 231/347] [D loss: 0.550349] [G loss: 0.461090]\n",
      "[Epoch 6/100] [Batch 232/347] [D loss: 0.550323] [G loss: 0.456991]\n",
      "[Epoch 6/100] [Batch 233/347] [D loss: 0.550297] [G loss: 0.454021]\n",
      "[Epoch 6/100] [Batch 234/347] [D loss: 0.550271] [G loss: 0.458886]\n",
      "[Epoch 6/100] [Batch 235/347] [D loss: 0.550245] [G loss: 0.447600]\n",
      "[Epoch 6/100] [Batch 236/347] [D loss: 0.550219] [G loss: 0.444403]\n",
      "[Epoch 6/100] [Batch 237/347] [D loss: 0.550193] [G loss: 0.448468]\n",
      "[Epoch 6/100] [Batch 238/347] [D loss: 0.550167] [G loss: 0.452557]\n",
      "[Epoch 6/100] [Batch 239/347] [D loss: 0.550141] [G loss: 0.450637]\n",
      "[Epoch 6/100] [Batch 240/347] [D loss: 0.550115] [G loss: 0.446774]\n",
      "[Epoch 6/100] [Batch 241/347] [D loss: 0.550089] [G loss: 0.440839]\n",
      "[Epoch 6/100] [Batch 242/347] [D loss: 0.550063] [G loss: 0.438638]\n",
      "[Epoch 6/100] [Batch 243/347] [D loss: 0.550037] [G loss: 0.445915]\n",
      "[Epoch 6/100] [Batch 244/347] [D loss: 0.550011] [G loss: 0.454406]\n",
      "[Epoch 6/100] [Batch 245/347] [D loss: 0.549986] [G loss: 0.452735]\n",
      "[Epoch 6/100] [Batch 246/347] [D loss: 0.549960] [G loss: 0.445166]\n",
      "[Epoch 6/100] [Batch 247/347] [D loss: 0.549934] [G loss: 0.454246]\n",
      "[Epoch 6/100] [Batch 248/347] [D loss: 0.549907] [G loss: 0.460344]\n",
      "[Epoch 6/100] [Batch 249/347] [D loss: 0.549882] [G loss: 0.466099]\n",
      "[Epoch 6/100] [Batch 250/347] [D loss: 0.549856] [G loss: 0.457739]\n",
      "[Epoch 6/100] [Batch 251/347] [D loss: 0.549831] [G loss: 0.444011]\n",
      "[Epoch 6/100] [Batch 252/347] [D loss: 0.549805] [G loss: 0.447150]\n",
      "[Epoch 6/100] [Batch 253/347] [D loss: 0.549779] [G loss: 0.447777]\n",
      "[Epoch 6/100] [Batch 254/347] [D loss: 0.549753] [G loss: 0.446123]\n",
      "[Epoch 6/100] [Batch 255/347] [D loss: 0.549728] [G loss: 0.444703]\n",
      "[Epoch 6/100] [Batch 256/347] [D loss: 0.549702] [G loss: 0.449730]\n",
      "[Epoch 6/100] [Batch 257/347] [D loss: 0.549676] [G loss: 0.451621]\n",
      "[Epoch 6/100] [Batch 258/347] [D loss: 0.549650] [G loss: 0.445717]\n",
      "[Epoch 6/100] [Batch 259/347] [D loss: 0.549624] [G loss: 0.456912]\n",
      "[Epoch 6/100] [Batch 260/347] [D loss: 0.549598] [G loss: 0.471352]\n",
      "[Epoch 6/100] [Batch 261/347] [D loss: 0.549573] [G loss: 0.463976]\n",
      "[Epoch 6/100] [Batch 262/347] [D loss: 0.549547] [G loss: 0.448966]\n",
      "[Epoch 6/100] [Batch 263/347] [D loss: 0.549522] [G loss: 0.449970]\n",
      "[Epoch 6/100] [Batch 264/347] [D loss: 0.549496] [G loss: 0.464411]\n",
      "[Epoch 6/100] [Batch 265/347] [D loss: 0.549470] [G loss: 0.469473]\n",
      "[Epoch 6/100] [Batch 266/347] [D loss: 0.549444] [G loss: 0.462219]\n",
      "[Epoch 6/100] [Batch 267/347] [D loss: 0.549419] [G loss: 0.455356]\n",
      "[Epoch 6/100] [Batch 268/347] [D loss: 0.549393] [G loss: 0.462120]\n",
      "[Epoch 6/100] [Batch 269/347] [D loss: 0.549368] [G loss: 0.473061]\n",
      "[Epoch 6/100] [Batch 270/347] [D loss: 0.549342] [G loss: 0.469515]\n",
      "[Epoch 6/100] [Batch 271/347] [D loss: 0.549317] [G loss: 0.457479]\n",
      "[Epoch 6/100] [Batch 272/347] [D loss: 0.549291] [G loss: 0.448638]\n",
      "[Epoch 6/100] [Batch 273/347] [D loss: 0.549265] [G loss: 0.460254]\n",
      "[Epoch 6/100] [Batch 274/347] [D loss: 0.549240] [G loss: 0.493816]\n",
      "[Epoch 6/100] [Batch 275/347] [D loss: 0.549214] [G loss: 0.490459]\n",
      "[Epoch 6/100] [Batch 276/347] [D loss: 0.549188] [G loss: 0.457855]\n",
      "[Epoch 6/100] [Batch 277/347] [D loss: 0.549163] [G loss: 0.442976]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 278/347] [D loss: 0.549137] [G loss: 0.432816]\n",
      "[Epoch 6/100] [Batch 279/347] [D loss: 0.549112] [G loss: 0.439036]\n",
      "[Epoch 6/100] [Batch 280/347] [D loss: 0.549086] [G loss: 0.442691]\n",
      "[Epoch 6/100] [Batch 281/347] [D loss: 0.549061] [G loss: 0.440989]\n",
      "[Epoch 6/100] [Batch 282/347] [D loss: 0.549035] [G loss: 0.438801]\n",
      "[Epoch 6/100] [Batch 283/347] [D loss: 0.549009] [G loss: 0.442865]\n",
      "[Epoch 6/100] [Batch 284/347] [D loss: 0.548984] [G loss: 0.441307]\n",
      "[Epoch 6/100] [Batch 285/347] [D loss: 0.548958] [G loss: 0.437112]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 286/347] [D loss: 0.548933] [G loss: 0.432588]\n",
      "[Epoch 6/100] [Batch 287/347] [D loss: 0.548907] [G loss: 0.436074]\n",
      "[Epoch 6/100] [Batch 288/347] [D loss: 0.548881] [G loss: 0.462476]\n",
      "[Epoch 6/100] [Batch 289/347] [D loss: 0.548856] [G loss: 0.466429]\n",
      "[Epoch 6/100] [Batch 290/347] [D loss: 0.548830] [G loss: 0.443754]\n",
      "[Epoch 6/100] [Batch 291/347] [D loss: 0.548805] [G loss: 0.446134]\n",
      "[Epoch 6/100] [Batch 292/347] [D loss: 0.548779] [G loss: 0.437182]\n",
      "[Epoch 6/100] [Batch 293/347] [D loss: 0.548754] [G loss: 0.448869]\n",
      "[Epoch 6/100] [Batch 294/347] [D loss: 0.548729] [G loss: 0.458988]\n",
      "[Epoch 6/100] [Batch 295/347] [D loss: 0.548703] [G loss: 0.456871]\n",
      "[Epoch 6/100] [Batch 296/347] [D loss: 0.548677] [G loss: 0.452988]\n",
      "[Epoch 6/100] [Batch 297/347] [D loss: 0.548652] [G loss: 0.465904]\n",
      "[Epoch 6/100] [Batch 298/347] [D loss: 0.548627] [G loss: 0.460873]\n",
      "[Epoch 6/100] [Batch 299/347] [D loss: 0.548601] [G loss: 0.459475]\n",
      "[Epoch 6/100] [Batch 300/347] [D loss: 0.548575] [G loss: 0.454573]\n",
      "[Epoch 6/100] [Batch 301/347] [D loss: 0.548550] [G loss: 0.454352]\n",
      "[Epoch 6/100] [Batch 302/347] [D loss: 0.548524] [G loss: 0.459234]\n",
      "[Epoch 6/100] [Batch 303/347] [D loss: 0.548499] [G loss: 0.443315]\n",
      "[Epoch 6/100] [Batch 304/347] [D loss: 0.548473] [G loss: 0.444847]\n",
      "[Epoch 6/100] [Batch 305/347] [D loss: 0.548447] [G loss: 0.457833]\n",
      "[Epoch 6/100] [Batch 306/347] [D loss: 0.548422] [G loss: 0.448862]\n",
      "[Epoch 6/100] [Batch 307/347] [D loss: 0.548396] [G loss: 0.460949]\n",
      "[Epoch 6/100] [Batch 308/347] [D loss: 0.548370] [G loss: 0.457267]\n",
      "[Epoch 6/100] [Batch 309/347] [D loss: 0.548345] [G loss: 0.438498]\n",
      "[Epoch 6/100] [Batch 310/347] [D loss: 0.548320] [G loss: 0.455922]\n",
      "[Epoch 6/100] [Batch 311/347] [D loss: 0.548295] [G loss: 0.458901]\n",
      "[Epoch 6/100] [Batch 312/347] [D loss: 0.548269] [G loss: 0.458715]\n",
      "[Epoch 6/100] [Batch 313/347] [D loss: 0.548244] [G loss: 0.457948]\n",
      "[Epoch 6/100] [Batch 314/347] [D loss: 0.548218] [G loss: 0.451587]\n",
      "[Epoch 6/100] [Batch 315/347] [D loss: 0.548193] [G loss: 0.442116]\n",
      "[Epoch 6/100] [Batch 316/347] [D loss: 0.548167] [G loss: 0.437554]\n",
      "[Epoch 6/100] [Batch 317/347] [D loss: 0.548141] [G loss: 0.456041]\n",
      "[Epoch 6/100] [Batch 318/347] [D loss: 0.548116] [G loss: 0.433911]\n",
      "[Epoch 6/100] [Batch 319/347] [D loss: 0.548091] [G loss: 0.463485]\n",
      "[Epoch 6/100] [Batch 320/347] [D loss: 0.548066] [G loss: 0.477042]\n",
      "[Epoch 6/100] [Batch 321/347] [D loss: 0.548041] [G loss: 0.466533]\n",
      "[Epoch 6/100] [Batch 322/347] [D loss: 0.548015] [G loss: 0.453605]\n",
      "[Epoch 6/100] [Batch 323/347] [D loss: 0.547989] [G loss: 0.452829]\n",
      "[Epoch 6/100] [Batch 324/347] [D loss: 0.547964] [G loss: 0.455624]\n",
      "[Epoch 6/100] [Batch 325/347] [D loss: 0.547939] [G loss: 0.444521]\n",
      "[Epoch 6/100] [Batch 326/347] [D loss: 0.547913] [G loss: 0.433334]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 327/347] [D loss: 0.547888] [G loss: 0.431158]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 328/347] [D loss: 0.547863] [G loss: 0.429715]\n",
      "[Epoch 6/100] [Batch 329/347] [D loss: 0.547837] [G loss: 0.452003]\n",
      "[Epoch 6/100] [Batch 330/347] [D loss: 0.547812] [G loss: 0.467565]\n",
      "[Epoch 6/100] [Batch 331/347] [D loss: 0.547787] [G loss: 0.449483]\n",
      "[Epoch 6/100] [Batch 332/347] [D loss: 0.547762] [G loss: 0.442606]\n",
      "[Epoch 6/100] [Batch 333/347] [D loss: 0.547737] [G loss: 0.453961]\n",
      "[Epoch 6/100] [Batch 334/347] [D loss: 0.547712] [G loss: 0.455403]\n",
      "[Epoch 6/100] [Batch 335/347] [D loss: 0.547687] [G loss: 0.443560]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 6/100] [Batch 336/347] [D loss: 0.547662] [G loss: 0.429633]\n",
      "[Epoch 6/100] [Batch 337/347] [D loss: 0.547636] [G loss: 0.435285]\n",
      "[Epoch 6/100] [Batch 338/347] [D loss: 0.547611] [G loss: 0.449690]\n",
      "[Epoch 6/100] [Batch 339/347] [D loss: 0.547586] [G loss: 0.454835]\n",
      "[Epoch 6/100] [Batch 340/347] [D loss: 0.547561] [G loss: 0.454943]\n",
      "[Epoch 6/100] [Batch 341/347] [D loss: 0.547536] [G loss: 0.449940]\n",
      "[Epoch 6/100] [Batch 342/347] [D loss: 0.547511] [G loss: 0.442189]\n",
      "[Epoch 6/100] [Batch 343/347] [D loss: 0.547485] [G loss: 0.446681]\n",
      "[Epoch 6/100] [Batch 344/347] [D loss: 0.547460] [G loss: 0.442876]\n",
      "[Epoch 6/100] [Batch 345/347] [D loss: 0.547435] [G loss: 0.453014]\n",
      "[Epoch 6/100] [Batch 346/347] [D loss: 0.547409] [G loss: 0.471595]\n",
      "[Epoch 6/100] [Batch 347/347] [D loss: 0.547384] [G loss: 0.478051]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 1/347] [D loss: 0.547359] [G loss: 0.444366]\n",
      "[Epoch 7/100] [Batch 2/347] [D loss: 0.547334] [G loss: 0.449591]\n",
      "[Epoch 7/100] [Batch 3/347] [D loss: 0.547309] [G loss: 0.449515]\n",
      "[Epoch 7/100] [Batch 4/347] [D loss: 0.547284] [G loss: 0.450691]\n",
      "[Epoch 7/100] [Batch 5/347] [D loss: 0.547259] [G loss: 0.449754]\n",
      "[Epoch 7/100] [Batch 6/347] [D loss: 0.547234] [G loss: 0.449929]\n",
      "[Epoch 7/100] [Batch 7/347] [D loss: 0.547208] [G loss: 0.449513]\n",
      "[Epoch 7/100] [Batch 8/347] [D loss: 0.547183] [G loss: 0.444597]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 9/347] [D loss: 0.547158] [G loss: 0.443383]\n",
      "[Epoch 7/100] [Batch 10/347] [D loss: 0.547133] [G loss: 0.444767]\n",
      "[Epoch 7/100] [Batch 11/347] [D loss: 0.547108] [G loss: 0.444354]\n",
      "[Epoch 7/100] [Batch 12/347] [D loss: 0.547082] [G loss: 0.444603]\n",
      "[Epoch 7/100] [Batch 13/347] [D loss: 0.547057] [G loss: 0.443477]\n",
      "[Epoch 7/100] [Batch 14/347] [D loss: 0.547032] [G loss: 0.445854]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 15/347] [D loss: 0.547007] [G loss: 0.442185]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 16/347] [D loss: 0.546982] [G loss: 0.438149]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 17/347] [D loss: 0.546957] [G loss: 0.427949]\n",
      "[Epoch 7/100] [Batch 18/347] [D loss: 0.546931] [G loss: 0.434236]\n",
      "[Epoch 7/100] [Batch 19/347] [D loss: 0.546906] [G loss: 0.431828]\n",
      "[Epoch 7/100] [Batch 20/347] [D loss: 0.546881] [G loss: 0.444981]\n",
      "[Epoch 7/100] [Batch 21/347] [D loss: 0.546856] [G loss: 0.441423]\n",
      "[Epoch 7/100] [Batch 22/347] [D loss: 0.546831] [G loss: 0.436480]\n",
      "[Epoch 7/100] [Batch 23/347] [D loss: 0.546806] [G loss: 0.430199]\n",
      "[Epoch 7/100] [Batch 24/347] [D loss: 0.546781] [G loss: 0.429459]\n",
      "[Epoch 7/100] [Batch 25/347] [D loss: 0.546756] [G loss: 0.428668]\n",
      "[Epoch 7/100] [Batch 26/347] [D loss: 0.546731] [G loss: 0.438341]\n",
      "[Epoch 7/100] [Batch 27/347] [D loss: 0.546706] [G loss: 0.444073]\n",
      "[Epoch 7/100] [Batch 28/347] [D loss: 0.546681] [G loss: 0.442927]\n",
      "[Epoch 7/100] [Batch 29/347] [D loss: 0.546656] [G loss: 0.439037]\n",
      "[Epoch 7/100] [Batch 30/347] [D loss: 0.546631] [G loss: 0.445868]\n",
      "[Epoch 7/100] [Batch 31/347] [D loss: 0.546606] [G loss: 0.448367]\n",
      "[Epoch 7/100] [Batch 32/347] [D loss: 0.546581] [G loss: 0.442846]\n",
      "[Epoch 7/100] [Batch 33/347] [D loss: 0.546556] [G loss: 0.437588]\n",
      "[Epoch 7/100] [Batch 34/347] [D loss: 0.546531] [G loss: 0.438482]\n",
      "[Epoch 7/100] [Batch 35/347] [D loss: 0.546506] [G loss: 0.437093]\n",
      "[Epoch 7/100] [Batch 36/347] [D loss: 0.546481] [G loss: 0.428121]\n",
      "[Epoch 7/100] [Batch 37/347] [D loss: 0.546456] [G loss: 0.449712]\n",
      "[Epoch 7/100] [Batch 38/347] [D loss: 0.546431] [G loss: 0.465065]\n",
      "[Epoch 7/100] [Batch 39/347] [D loss: 0.546406] [G loss: 0.455714]\n",
      "[Epoch 7/100] [Batch 40/347] [D loss: 0.546382] [G loss: 0.455709]\n",
      "[Epoch 7/100] [Batch 41/347] [D loss: 0.546357] [G loss: 0.457235]\n",
      "[Epoch 7/100] [Batch 42/347] [D loss: 0.546332] [G loss: 0.450391]\n",
      "[Epoch 7/100] [Batch 43/347] [D loss: 0.546307] [G loss: 0.434784]\n",
      "[Epoch 7/100] [Batch 44/347] [D loss: 0.546283] [G loss: 0.434425]\n",
      "[Epoch 7/100] [Batch 45/347] [D loss: 0.546258] [G loss: 0.451872]\n",
      "[Epoch 7/100] [Batch 46/347] [D loss: 0.546233] [G loss: 0.446704]\n",
      "[Epoch 7/100] [Batch 47/347] [D loss: 0.546208] [G loss: 0.432003]\n",
      "[Epoch 7/100] [Batch 48/347] [D loss: 0.546183] [G loss: 0.464152]\n",
      "[Epoch 7/100] [Batch 49/347] [D loss: 0.546157] [G loss: 0.472734]\n",
      "[Epoch 7/100] [Batch 50/347] [D loss: 0.546133] [G loss: 0.488513]\n",
      "[Epoch 7/100] [Batch 51/347] [D loss: 0.546108] [G loss: 0.473273]\n",
      "[Epoch 7/100] [Batch 52/347] [D loss: 0.546083] [G loss: 0.433820]\n",
      "[Epoch 7/100] [Batch 53/347] [D loss: 0.546059] [G loss: 0.436024]\n",
      "[Epoch 7/100] [Batch 54/347] [D loss: 0.546034] [G loss: 0.488366]\n",
      "[Epoch 7/100] [Batch 55/347] [D loss: 0.546008] [G loss: 0.510589]\n",
      "[Epoch 7/100] [Batch 56/347] [D loss: 0.545984] [G loss: 0.497573]\n",
      "[Epoch 7/100] [Batch 57/347] [D loss: 0.545960] [G loss: 0.463342]\n",
      "[Epoch 7/100] [Batch 58/347] [D loss: 0.545935] [G loss: 0.432468]\n",
      "[Epoch 7/100] [Batch 59/347] [D loss: 0.545911] [G loss: 0.446195]\n",
      "[Epoch 7/100] [Batch 60/347] [D loss: 0.545886] [G loss: 0.464612]\n",
      "[Epoch 7/100] [Batch 61/347] [D loss: 0.545861] [G loss: 0.476770]\n",
      "[Epoch 7/100] [Batch 62/347] [D loss: 0.545836] [G loss: 0.500550]\n",
      "[Epoch 7/100] [Batch 63/347] [D loss: 0.545811] [G loss: 0.502602]\n",
      "[Epoch 7/100] [Batch 64/347] [D loss: 0.545787] [G loss: 0.465820]\n",
      "[Epoch 7/100] [Batch 65/347] [D loss: 0.545763] [G loss: 0.437169]\n",
      "[Epoch 7/100] [Batch 66/347] [D loss: 0.545739] [G loss: 0.439655]\n",
      "[Epoch 7/100] [Batch 67/347] [D loss: 0.545714] [G loss: 0.449168]\n",
      "[Epoch 7/100] [Batch 68/347] [D loss: 0.545689] [G loss: 0.466948]\n",
      "[Epoch 7/100] [Batch 69/347] [D loss: 0.545664] [G loss: 0.485463]\n",
      "[Epoch 7/100] [Batch 70/347] [D loss: 0.545640] [G loss: 0.484141]\n",
      "[Epoch 7/100] [Batch 71/347] [D loss: 0.545615] [G loss: 0.486773]\n",
      "[Epoch 7/100] [Batch 72/347] [D loss: 0.545591] [G loss: 0.489277]\n",
      "[Epoch 7/100] [Batch 73/347] [D loss: 0.545566] [G loss: 0.464555]\n",
      "[Epoch 7/100] [Batch 74/347] [D loss: 0.545543] [G loss: 0.450533]\n",
      "[Epoch 7/100] [Batch 75/347] [D loss: 0.545519] [G loss: 0.479972]\n",
      "[Epoch 7/100] [Batch 76/347] [D loss: 0.545493] [G loss: 0.481552]\n",
      "[Epoch 7/100] [Batch 77/347] [D loss: 0.545469] [G loss: 0.447131]\n",
      "[Epoch 7/100] [Batch 78/347] [D loss: 0.545446] [G loss: 0.444693]\n",
      "[Epoch 7/100] [Batch 79/347] [D loss: 0.545421] [G loss: 0.446481]\n",
      "[Epoch 7/100] [Batch 80/347] [D loss: 0.545397] [G loss: 0.444088]\n",
      "[Epoch 7/100] [Batch 81/347] [D loss: 0.545372] [G loss: 0.449354]\n",
      "[Epoch 7/100] [Batch 82/347] [D loss: 0.545348] [G loss: 0.454210]\n",
      "[Epoch 7/100] [Batch 83/347] [D loss: 0.545324] [G loss: 0.446548]\n",
      "[Epoch 7/100] [Batch 84/347] [D loss: 0.545299] [G loss: 0.453259]\n",
      "[Epoch 7/100] [Batch 85/347] [D loss: 0.545275] [G loss: 0.453894]\n",
      "[Epoch 7/100] [Batch 86/347] [D loss: 0.545251] [G loss: 0.448186]\n",
      "[Epoch 7/100] [Batch 87/347] [D loss: 0.545226] [G loss: 0.445740]\n",
      "[Epoch 7/100] [Batch 88/347] [D loss: 0.545202] [G loss: 0.448872]\n",
      "[Epoch 7/100] [Batch 89/347] [D loss: 0.545178] [G loss: 0.452041]\n",
      "[Epoch 7/100] [Batch 90/347] [D loss: 0.545154] [G loss: 0.447938]\n",
      "[Epoch 7/100] [Batch 91/347] [D loss: 0.545129] [G loss: 0.446237]\n",
      "[Epoch 7/100] [Batch 92/347] [D loss: 0.545105] [G loss: 0.447419]\n",
      "[Epoch 7/100] [Batch 93/347] [D loss: 0.545081] [G loss: 0.445174]\n",
      "[Epoch 7/100] [Batch 94/347] [D loss: 0.545057] [G loss: 0.441330]\n",
      "[Epoch 7/100] [Batch 95/347] [D loss: 0.545032] [G loss: 0.441548]\n",
      "[Epoch 7/100] [Batch 96/347] [D loss: 0.545008] [G loss: 0.436507]\n",
      "[Epoch 7/100] [Batch 97/347] [D loss: 0.544984] [G loss: 0.431189]\n",
      "[Epoch 7/100] [Batch 98/347] [D loss: 0.544960] [G loss: 0.435767]\n",
      "[Epoch 7/100] [Batch 99/347] [D loss: 0.544936] [G loss: 0.439213]\n",
      "[Epoch 7/100] [Batch 100/347] [D loss: 0.544911] [G loss: 0.435307]\n",
      "[Epoch 7/100] [Batch 101/347] [D loss: 0.544887] [G loss: 0.434208]\n",
      "[Epoch 7/100] [Batch 102/347] [D loss: 0.544863] [G loss: 0.435137]\n",
      "[Epoch 7/100] [Batch 103/347] [D loss: 0.544839] [G loss: 0.434549]\n",
      "[Epoch 7/100] [Batch 104/347] [D loss: 0.544815] [G loss: 0.436483]\n",
      "[Epoch 7/100] [Batch 105/347] [D loss: 0.544790] [G loss: 0.437903]\n",
      "[Epoch 7/100] [Batch 106/347] [D loss: 0.544766] [G loss: 0.436684]\n",
      "[Epoch 7/100] [Batch 107/347] [D loss: 0.544742] [G loss: 0.429692]\n",
      "[Epoch 7/100] [Batch 108/347] [D loss: 0.544717] [G loss: 0.446453]\n",
      "[Epoch 7/100] [Batch 109/347] [D loss: 0.544693] [G loss: 0.439349]\n",
      "[Epoch 7/100] [Batch 110/347] [D loss: 0.544669] [G loss: 0.427974]\n",
      "[Epoch 7/100] [Batch 111/347] [D loss: 0.544644] [G loss: 0.433002]\n",
      "[Epoch 7/100] [Batch 112/347] [D loss: 0.544620] [G loss: 0.438367]\n",
      "[Epoch 7/100] [Batch 113/347] [D loss: 0.544595] [G loss: 0.443988]\n",
      "[Epoch 7/100] [Batch 114/347] [D loss: 0.544571] [G loss: 0.464831]\n",
      "[Epoch 7/100] [Batch 115/347] [D loss: 0.544547] [G loss: 0.466196]\n",
      "[Epoch 7/100] [Batch 116/347] [D loss: 0.544522] [G loss: 0.460531]\n",
      "[Epoch 7/100] [Batch 117/347] [D loss: 0.544498] [G loss: 0.434214]\n",
      "[Epoch 7/100] [Batch 118/347] [D loss: 0.544473] [G loss: 0.435132]\n",
      "[Epoch 7/100] [Batch 119/347] [D loss: 0.544448] [G loss: 0.437343]\n",
      "[Epoch 7/100] [Batch 120/347] [D loss: 0.544424] [G loss: 0.436355]\n",
      "[Epoch 7/100] [Batch 121/347] [D loss: 0.544400] [G loss: 0.434678]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 122/347] [D loss: 0.544376] [G loss: 0.421719]\n",
      "[Epoch 7/100] [Batch 123/347] [D loss: 0.544351] [G loss: 0.423592]\n",
      "[Epoch 7/100] [Batch 124/347] [D loss: 0.544327] [G loss: 0.422335]\n",
      "[Epoch 7/100] [Batch 125/347] [D loss: 0.544303] [G loss: 0.431217]\n",
      "[Epoch 7/100] [Batch 126/347] [D loss: 0.544279] [G loss: 0.443720]\n",
      "[Epoch 7/100] [Batch 127/347] [D loss: 0.544254] [G loss: 0.445044]\n",
      "[Epoch 7/100] [Batch 128/347] [D loss: 0.544230] [G loss: 0.439386]\n",
      "[Epoch 7/100] [Batch 129/347] [D loss: 0.544205] [G loss: 0.434305]\n",
      "[Epoch 7/100] [Batch 130/347] [D loss: 0.544181] [G loss: 0.436974]\n",
      "[Epoch 7/100] [Batch 131/347] [D loss: 0.544157] [G loss: 0.434724]\n",
      "[Epoch 7/100] [Batch 132/347] [D loss: 0.544132] [G loss: 0.457600]\n",
      "[Epoch 7/100] [Batch 133/347] [D loss: 0.544108] [G loss: 0.464813]\n",
      "[Epoch 7/100] [Batch 134/347] [D loss: 0.544083] [G loss: 0.480163]\n",
      "[Epoch 7/100] [Batch 135/347] [D loss: 0.544059] [G loss: 0.489546]\n",
      "[Epoch 7/100] [Batch 136/347] [D loss: 0.544034] [G loss: 0.448068]\n",
      "[Epoch 7/100] [Batch 137/347] [D loss: 0.544011] [G loss: 0.433741]\n",
      "[Epoch 7/100] [Batch 138/347] [D loss: 0.543986] [G loss: 0.453481]\n",
      "[Epoch 7/100] [Batch 139/347] [D loss: 0.543961] [G loss: 0.477473]\n",
      "[Epoch 7/100] [Batch 140/347] [D loss: 0.543937] [G loss: 0.488988]\n",
      "[Epoch 7/100] [Batch 141/347] [D loss: 0.543913] [G loss: 0.495952]\n",
      "[Epoch 7/100] [Batch 142/347] [D loss: 0.543888] [G loss: 0.503916]\n",
      "[Epoch 7/100] [Batch 143/347] [D loss: 0.543864] [G loss: 0.525869]\n",
      "[Epoch 7/100] [Batch 144/347] [D loss: 0.543839] [G loss: 0.528200]\n",
      "[Epoch 7/100] [Batch 145/347] [D loss: 0.543815] [G loss: 0.514146]\n",
      "[Epoch 7/100] [Batch 146/347] [D loss: 0.543791] [G loss: 0.497413]\n",
      "[Epoch 7/100] [Batch 147/347] [D loss: 0.543767] [G loss: 0.469447]\n",
      "[Epoch 7/100] [Batch 148/347] [D loss: 0.543743] [G loss: 0.457027]\n",
      "[Epoch 7/100] [Batch 149/347] [D loss: 0.543719] [G loss: 0.470121]\n",
      "[Epoch 7/100] [Batch 150/347] [D loss: 0.543694] [G loss: 0.470359]\n",
      "[Epoch 7/100] [Batch 151/347] [D loss: 0.543670] [G loss: 0.459321]\n",
      "[Epoch 7/100] [Batch 152/347] [D loss: 0.543646] [G loss: 0.470183]\n",
      "[Epoch 7/100] [Batch 153/347] [D loss: 0.543621] [G loss: 0.490751]\n",
      "[Epoch 7/100] [Batch 154/347] [D loss: 0.543596] [G loss: 0.494843]\n",
      "[Epoch 7/100] [Batch 155/347] [D loss: 0.543572] [G loss: 0.481962]\n",
      "[Epoch 7/100] [Batch 156/347] [D loss: 0.543548] [G loss: 0.465370]\n",
      "[Epoch 7/100] [Batch 157/347] [D loss: 0.543524] [G loss: 0.471669]\n",
      "[Epoch 7/100] [Batch 158/347] [D loss: 0.543500] [G loss: 0.495269]\n",
      "[Epoch 7/100] [Batch 159/347] [D loss: 0.543475] [G loss: 0.492558]\n",
      "[Epoch 7/100] [Batch 160/347] [D loss: 0.543451] [G loss: 0.472554]\n",
      "[Epoch 7/100] [Batch 161/347] [D loss: 0.543428] [G loss: 0.464051]\n",
      "[Epoch 7/100] [Batch 162/347] [D loss: 0.543403] [G loss: 0.469658]\n",
      "[Epoch 7/100] [Batch 163/347] [D loss: 0.543379] [G loss: 0.488217]\n",
      "[Epoch 7/100] [Batch 164/347] [D loss: 0.543354] [G loss: 0.503193]\n",
      "[Epoch 7/100] [Batch 165/347] [D loss: 0.543330] [G loss: 0.494132]\n",
      "[Epoch 7/100] [Batch 166/347] [D loss: 0.543306] [G loss: 0.455893]\n",
      "[Epoch 7/100] [Batch 167/347] [D loss: 0.543283] [G loss: 0.438201]\n",
      "[Epoch 7/100] [Batch 168/347] [D loss: 0.543259] [G loss: 0.448943]\n",
      "[Epoch 7/100] [Batch 169/347] [D loss: 0.543235] [G loss: 0.447856]\n",
      "[Epoch 7/100] [Batch 170/347] [D loss: 0.543211] [G loss: 0.444137]\n",
      "[Epoch 7/100] [Batch 171/347] [D loss: 0.543187] [G loss: 0.455743]\n",
      "[Epoch 7/100] [Batch 172/347] [D loss: 0.543163] [G loss: 0.460686]\n",
      "[Epoch 7/100] [Batch 173/347] [D loss: 0.543139] [G loss: 0.449409]\n",
      "[Epoch 7/100] [Batch 174/347] [D loss: 0.543115] [G loss: 0.446834]\n",
      "[Epoch 7/100] [Batch 175/347] [D loss: 0.543091] [G loss: 0.456441]\n",
      "[Epoch 7/100] [Batch 176/347] [D loss: 0.543067] [G loss: 0.469635]\n",
      "[Epoch 7/100] [Batch 177/347] [D loss: 0.543043] [G loss: 0.470205]\n",
      "[Epoch 7/100] [Batch 178/347] [D loss: 0.543019] [G loss: 0.464017]\n",
      "[Epoch 7/100] [Batch 179/347] [D loss: 0.542995] [G loss: 0.457088]\n",
      "[Epoch 7/100] [Batch 180/347] [D loss: 0.542971] [G loss: 0.450476]\n",
      "[Epoch 7/100] [Batch 181/347] [D loss: 0.542947] [G loss: 0.450605]\n",
      "[Epoch 7/100] [Batch 182/347] [D loss: 0.542923] [G loss: 0.448079]\n",
      "[Epoch 7/100] [Batch 183/347] [D loss: 0.542899] [G loss: 0.451747]\n",
      "[Epoch 7/100] [Batch 184/347] [D loss: 0.542875] [G loss: 0.455239]\n",
      "[Epoch 7/100] [Batch 185/347] [D loss: 0.542851] [G loss: 0.453477]\n",
      "[Epoch 7/100] [Batch 186/347] [D loss: 0.542826] [G loss: 0.452947]\n",
      "[Epoch 7/100] [Batch 187/347] [D loss: 0.542803] [G loss: 0.447329]\n",
      "[Epoch 7/100] [Batch 188/347] [D loss: 0.542778] [G loss: 0.443829]\n",
      "[Epoch 7/100] [Batch 189/347] [D loss: 0.542755] [G loss: 0.442654]\n",
      "[Epoch 7/100] [Batch 190/347] [D loss: 0.542731] [G loss: 0.430422]\n",
      "[Epoch 7/100] [Batch 191/347] [D loss: 0.542707] [G loss: 0.429566]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 192/347] [D loss: 0.542683] [G loss: 0.420362]\n",
      "[Epoch 7/100] [Batch 193/347] [D loss: 0.542660] [G loss: 0.427566]\n",
      "[Epoch 7/100] [Batch 194/347] [D loss: 0.542636] [G loss: 0.424512]\n",
      "[Epoch 7/100] [Batch 195/347] [D loss: 0.542612] [G loss: 0.433299]\n",
      "[Epoch 7/100] [Batch 196/347] [D loss: 0.542590] [G loss: 0.430957]\n",
      "[Epoch 7/100] [Batch 197/347] [D loss: 0.542566] [G loss: 0.426094]\n",
      "[Epoch 7/100] [Batch 198/347] [D loss: 0.542544] [G loss: 0.423439]\n",
      "[Epoch 7/100] [Batch 199/347] [D loss: 0.542521] [G loss: 0.424615]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 200/347] [D loss: 0.542498] [G loss: 0.419466]\n",
      "[Epoch 7/100] [Batch 201/347] [D loss: 0.542475] [G loss: 0.421260]\n",
      "[Epoch 7/100] [Batch 202/347] [D loss: 0.542451] [G loss: 0.432655]\n",
      "[Epoch 7/100] [Batch 203/347] [D loss: 0.542428] [G loss: 0.441076]\n",
      "[Epoch 7/100] [Batch 204/347] [D loss: 0.542404] [G loss: 0.437407]\n",
      "[Epoch 7/100] [Batch 205/347] [D loss: 0.542381] [G loss: 0.429309]\n",
      "[Epoch 7/100] [Batch 206/347] [D loss: 0.542357] [G loss: 0.420066]\n",
      "[Epoch 7/100] [Batch 207/347] [D loss: 0.542334] [G loss: 0.430922]\n",
      "[Epoch 7/100] [Batch 208/347] [D loss: 0.542311] [G loss: 0.431849]\n",
      "[Epoch 7/100] [Batch 209/347] [D loss: 0.542287] [G loss: 0.426327]\n",
      "[Epoch 7/100] [Batch 210/347] [D loss: 0.542263] [G loss: 0.432478]\n",
      "[Epoch 7/100] [Batch 211/347] [D loss: 0.542240] [G loss: 0.430495]\n",
      "[Epoch 7/100] [Batch 212/347] [D loss: 0.542216] [G loss: 0.428502]\n",
      "[Epoch 7/100] [Batch 213/347] [D loss: 0.542192] [G loss: 0.433951]\n",
      "[Epoch 7/100] [Batch 214/347] [D loss: 0.542169] [G loss: 0.441061]\n",
      "[Epoch 7/100] [Batch 215/347] [D loss: 0.542145] [G loss: 0.449342]\n",
      "[Epoch 7/100] [Batch 216/347] [D loss: 0.542121] [G loss: 0.432728]\n",
      "[Epoch 7/100] [Batch 217/347] [D loss: 0.542098] [G loss: 0.433197]\n",
      "[Epoch 7/100] [Batch 218/347] [D loss: 0.542074] [G loss: 0.440437]\n",
      "[Epoch 7/100] [Batch 219/347] [D loss: 0.542051] [G loss: 0.452429]\n",
      "[Epoch 7/100] [Batch 220/347] [D loss: 0.542027] [G loss: 0.468198]\n",
      "[Epoch 7/100] [Batch 221/347] [D loss: 0.542004] [G loss: 0.469496]\n",
      "[Epoch 7/100] [Batch 222/347] [D loss: 0.541980] [G loss: 0.461340]\n",
      "[Epoch 7/100] [Batch 223/347] [D loss: 0.541956] [G loss: 0.459797]\n",
      "[Epoch 7/100] [Batch 224/347] [D loss: 0.541933] [G loss: 0.455423]\n",
      "[Epoch 7/100] [Batch 225/347] [D loss: 0.541909] [G loss: 0.440734]\n",
      "[Epoch 7/100] [Batch 226/347] [D loss: 0.541885] [G loss: 0.437064]\n",
      "[Epoch 7/100] [Batch 227/347] [D loss: 0.541861] [G loss: 0.447659]\n",
      "[Epoch 7/100] [Batch 228/347] [D loss: 0.541838] [G loss: 0.450522]\n",
      "[Epoch 7/100] [Batch 229/347] [D loss: 0.541814] [G loss: 0.446007]\n",
      "[Epoch 7/100] [Batch 230/347] [D loss: 0.541791] [G loss: 0.442470]\n",
      "[Epoch 7/100] [Batch 231/347] [D loss: 0.541768] [G loss: 0.442601]\n",
      "[Epoch 7/100] [Batch 232/347] [D loss: 0.541744] [G loss: 0.438511]\n",
      "[Epoch 7/100] [Batch 233/347] [D loss: 0.541721] [G loss: 0.435546]\n",
      "[Epoch 7/100] [Batch 234/347] [D loss: 0.541697] [G loss: 0.440414]\n",
      "[Epoch 7/100] [Batch 235/347] [D loss: 0.541674] [G loss: 0.429133]\n",
      "[Epoch 7/100] [Batch 236/347] [D loss: 0.541650] [G loss: 0.425937]\n",
      "[Epoch 7/100] [Batch 237/347] [D loss: 0.541627] [G loss: 0.430020]\n",
      "[Epoch 7/100] [Batch 238/347] [D loss: 0.541603] [G loss: 0.434063]\n",
      "[Epoch 7/100] [Batch 239/347] [D loss: 0.541579] [G loss: 0.432123]\n",
      "[Epoch 7/100] [Batch 240/347] [D loss: 0.541556] [G loss: 0.428280]\n",
      "[Epoch 7/100] [Batch 241/347] [D loss: 0.541532] [G loss: 0.422294]\n",
      "[Epoch 7/100] [Batch 242/347] [D loss: 0.541509] [G loss: 0.420120]\n",
      "[Epoch 7/100] [Batch 243/347] [D loss: 0.541485] [G loss: 0.427437]\n",
      "[Epoch 7/100] [Batch 244/347] [D loss: 0.541462] [G loss: 0.436001]\n",
      "[Epoch 7/100] [Batch 245/347] [D loss: 0.541439] [G loss: 0.434329]\n",
      "[Epoch 7/100] [Batch 246/347] [D loss: 0.541415] [G loss: 0.426689]\n",
      "[Epoch 7/100] [Batch 247/347] [D loss: 0.541391] [G loss: 0.435795]\n",
      "[Epoch 7/100] [Batch 248/347] [D loss: 0.541367] [G loss: 0.441876]\n",
      "[Epoch 7/100] [Batch 249/347] [D loss: 0.541344] [G loss: 0.447585]\n",
      "[Epoch 7/100] [Batch 250/347] [D loss: 0.541321] [G loss: 0.439172]\n",
      "[Epoch 7/100] [Batch 251/347] [D loss: 0.541297] [G loss: 0.425693]\n",
      "[Epoch 7/100] [Batch 252/347] [D loss: 0.541275] [G loss: 0.428839]\n",
      "[Epoch 7/100] [Batch 253/347] [D loss: 0.541251] [G loss: 0.429465]\n",
      "[Epoch 7/100] [Batch 254/347] [D loss: 0.541227] [G loss: 0.427836]\n",
      "[Epoch 7/100] [Batch 255/347] [D loss: 0.541204] [G loss: 0.426374]\n",
      "[Epoch 7/100] [Batch 256/347] [D loss: 0.541180] [G loss: 0.431423]\n",
      "[Epoch 7/100] [Batch 257/347] [D loss: 0.541157] [G loss: 0.433400]\n",
      "[Epoch 7/100] [Batch 258/347] [D loss: 0.541134] [G loss: 0.427503]\n",
      "[Epoch 7/100] [Batch 259/347] [D loss: 0.541110] [G loss: 0.438269]\n",
      "[Epoch 7/100] [Batch 260/347] [D loss: 0.541086] [G loss: 0.452724]\n",
      "[Epoch 7/100] [Batch 261/347] [D loss: 0.541064] [G loss: 0.445302]\n",
      "[Epoch 7/100] [Batch 262/347] [D loss: 0.541040] [G loss: 0.430271]\n",
      "[Epoch 7/100] [Batch 263/347] [D loss: 0.541018] [G loss: 0.431277]\n",
      "[Epoch 7/100] [Batch 264/347] [D loss: 0.540994] [G loss: 0.445754]\n",
      "[Epoch 7/100] [Batch 265/347] [D loss: 0.540971] [G loss: 0.450852]\n",
      "[Epoch 7/100] [Batch 266/347] [D loss: 0.540947] [G loss: 0.443588]\n",
      "[Epoch 7/100] [Batch 267/347] [D loss: 0.540924] [G loss: 0.436679]\n",
      "[Epoch 7/100] [Batch 268/347] [D loss: 0.540901] [G loss: 0.443478]\n",
      "[Epoch 7/100] [Batch 269/347] [D loss: 0.540878] [G loss: 0.454497]\n",
      "[Epoch 7/100] [Batch 270/347] [D loss: 0.540854] [G loss: 0.450892]\n",
      "[Epoch 7/100] [Batch 271/347] [D loss: 0.540831] [G loss: 0.438937]\n",
      "[Epoch 7/100] [Batch 272/347] [D loss: 0.540808] [G loss: 0.430167]\n",
      "[Epoch 7/100] [Batch 273/347] [D loss: 0.540785] [G loss: 0.441772]\n",
      "[Epoch 7/100] [Batch 274/347] [D loss: 0.540762] [G loss: 0.475375]\n",
      "[Epoch 7/100] [Batch 275/347] [D loss: 0.540738] [G loss: 0.472066]\n",
      "[Epoch 7/100] [Batch 276/347] [D loss: 0.540715] [G loss: 0.439537]\n",
      "[Epoch 7/100] [Batch 277/347] [D loss: 0.540692] [G loss: 0.424661]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 278/347] [D loss: 0.540668] [G loss: 0.414296]\n",
      "[Epoch 7/100] [Batch 279/347] [D loss: 0.540646] [G loss: 0.420666]\n",
      "[Epoch 7/100] [Batch 280/347] [D loss: 0.540622] [G loss: 0.424317]\n",
      "[Epoch 7/100] [Batch 281/347] [D loss: 0.540599] [G loss: 0.422575]\n",
      "[Epoch 7/100] [Batch 282/347] [D loss: 0.540576] [G loss: 0.420397]\n",
      "[Epoch 7/100] [Batch 283/347] [D loss: 0.540552] [G loss: 0.424764]\n",
      "[Epoch 7/100] [Batch 284/347] [D loss: 0.540529] [G loss: 0.422945]\n",
      "[Epoch 7/100] [Batch 285/347] [D loss: 0.540506] [G loss: 0.418746]\n",
      "[Epoch 7/100] [Batch 286/347] [D loss: 0.540483] [G loss: 0.414463]\n",
      "[Epoch 7/100] [Batch 287/347] [D loss: 0.540460] [G loss: 0.417935]\n",
      "[Epoch 7/100] [Batch 288/347] [D loss: 0.540436] [G loss: 0.444347]\n",
      "[Epoch 7/100] [Batch 289/347] [D loss: 0.540413] [G loss: 0.448367]\n",
      "[Epoch 7/100] [Batch 290/347] [D loss: 0.540389] [G loss: 0.425731]\n",
      "[Epoch 7/100] [Batch 291/347] [D loss: 0.540367] [G loss: 0.428134]\n",
      "[Epoch 7/100] [Batch 292/347] [D loss: 0.540343] [G loss: 0.419164]\n",
      "[Epoch 7/100] [Batch 293/347] [D loss: 0.540320] [G loss: 0.430527]\n",
      "[Epoch 7/100] [Batch 294/347] [D loss: 0.540298] [G loss: 0.440611]\n",
      "[Epoch 7/100] [Batch 295/347] [D loss: 0.540274] [G loss: 0.438485]\n",
      "[Epoch 7/100] [Batch 296/347] [D loss: 0.540251] [G loss: 0.434607]\n",
      "[Epoch 7/100] [Batch 297/347] [D loss: 0.540227] [G loss: 0.446988]\n",
      "[Epoch 7/100] [Batch 298/347] [D loss: 0.540204] [G loss: 0.441930]\n",
      "[Epoch 7/100] [Batch 299/347] [D loss: 0.540181] [G loss: 0.440553]\n",
      "[Epoch 7/100] [Batch 300/347] [D loss: 0.540158] [G loss: 0.435736]\n",
      "[Epoch 7/100] [Batch 301/347] [D loss: 0.540135] [G loss: 0.436080]\n",
      "[Epoch 7/100] [Batch 302/347] [D loss: 0.540111] [G loss: 0.440938]\n",
      "[Epoch 7/100] [Batch 303/347] [D loss: 0.540088] [G loss: 0.425068]\n",
      "[Epoch 7/100] [Batch 304/347] [D loss: 0.540064] [G loss: 0.426373]\n",
      "[Epoch 7/100] [Batch 305/347] [D loss: 0.540041] [G loss: 0.439294]\n",
      "[Epoch 7/100] [Batch 306/347] [D loss: 0.540018] [G loss: 0.430285]\n",
      "[Epoch 7/100] [Batch 307/347] [D loss: 0.539995] [G loss: 0.442976]\n",
      "[Epoch 7/100] [Batch 308/347] [D loss: 0.539972] [G loss: 0.439265]\n",
      "[Epoch 7/100] [Batch 309/347] [D loss: 0.539949] [G loss: 0.419826]\n",
      "[Epoch 7/100] [Batch 310/347] [D loss: 0.539926] [G loss: 0.437216]\n",
      "[Epoch 7/100] [Batch 311/347] [D loss: 0.539903] [G loss: 0.440195]\n",
      "[Epoch 7/100] [Batch 312/347] [D loss: 0.539880] [G loss: 0.439992]\n",
      "[Epoch 7/100] [Batch 313/347] [D loss: 0.539856] [G loss: 0.439204]\n",
      "[Epoch 7/100] [Batch 314/347] [D loss: 0.539833] [G loss: 0.432843]\n",
      "[Epoch 7/100] [Batch 315/347] [D loss: 0.539810] [G loss: 0.423446]\n",
      "[Epoch 7/100] [Batch 316/347] [D loss: 0.539787] [G loss: 0.418968]\n",
      "[Epoch 7/100] [Batch 317/347] [D loss: 0.539763] [G loss: 0.437499]\n",
      "[Epoch 7/100] [Batch 318/347] [D loss: 0.539740] [G loss: 0.415339]\n",
      "[Epoch 7/100] [Batch 319/347] [D loss: 0.539718] [G loss: 0.444831]\n",
      "[Epoch 7/100] [Batch 320/347] [D loss: 0.539695] [G loss: 0.458416]\n",
      "[Epoch 7/100] [Batch 321/347] [D loss: 0.539672] [G loss: 0.447937]\n",
      "[Epoch 7/100] [Batch 322/347] [D loss: 0.539648] [G loss: 0.434992]\n",
      "[Epoch 7/100] [Batch 323/347] [D loss: 0.539625] [G loss: 0.434204]\n",
      "[Epoch 7/100] [Batch 324/347] [D loss: 0.539602] [G loss: 0.437024]\n",
      "[Epoch 7/100] [Batch 325/347] [D loss: 0.539579] [G loss: 0.425951]\n",
      "[Epoch 7/100] [Batch 326/347] [D loss: 0.539556] [G loss: 0.415287]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 327/347] [D loss: 0.539533] [G loss: 0.413143]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 7/100] [Batch 328/347] [D loss: 0.539510] [G loss: 0.411054]\n",
      "[Epoch 7/100] [Batch 329/347] [D loss: 0.539486] [G loss: 0.433751]\n",
      "[Epoch 7/100] [Batch 330/347] [D loss: 0.539463] [G loss: 0.449322]\n",
      "[Epoch 7/100] [Batch 331/347] [D loss: 0.539440] [G loss: 0.431213]\n",
      "[Epoch 7/100] [Batch 332/347] [D loss: 0.539418] [G loss: 0.424273]\n",
      "[Epoch 7/100] [Batch 333/347] [D loss: 0.539396] [G loss: 0.435662]\n",
      "[Epoch 7/100] [Batch 334/347] [D loss: 0.539373] [G loss: 0.437130]\n",
      "[Epoch 7/100] [Batch 335/347] [D loss: 0.539350] [G loss: 0.425266]\n",
      "[Epoch 7/100] [Batch 336/347] [D loss: 0.539327] [G loss: 0.411747]\n",
      "[Epoch 7/100] [Batch 337/347] [D loss: 0.539304] [G loss: 0.417002]\n",
      "[Epoch 7/100] [Batch 338/347] [D loss: 0.539282] [G loss: 0.431437]\n",
      "[Epoch 7/100] [Batch 339/347] [D loss: 0.539259] [G loss: 0.436645]\n",
      "[Epoch 7/100] [Batch 340/347] [D loss: 0.539236] [G loss: 0.436759]\n",
      "[Epoch 7/100] [Batch 341/347] [D loss: 0.539213] [G loss: 0.431817]\n",
      "[Epoch 7/100] [Batch 342/347] [D loss: 0.539191] [G loss: 0.424055]\n",
      "[Epoch 7/100] [Batch 343/347] [D loss: 0.539168] [G loss: 0.428617]\n",
      "[Epoch 7/100] [Batch 344/347] [D loss: 0.539146] [G loss: 0.423951]\n",
      "[Epoch 7/100] [Batch 345/347] [D loss: 0.539123] [G loss: 0.434405]\n",
      "[Epoch 7/100] [Batch 346/347] [D loss: 0.539100] [G loss: 0.452962]\n",
      "[Epoch 7/100] [Batch 347/347] [D loss: 0.539077] [G loss: 0.459392]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 1/347] [D loss: 0.539055] [G loss: 0.425382]\n",
      "[Epoch 8/100] [Batch 2/347] [D loss: 0.539032] [G loss: 0.430617]\n",
      "[Epoch 8/100] [Batch 3/347] [D loss: 0.539009] [G loss: 0.430533]\n",
      "[Epoch 8/100] [Batch 4/347] [D loss: 0.538987] [G loss: 0.431703]\n",
      "[Epoch 8/100] [Batch 5/347] [D loss: 0.538965] [G loss: 0.430768]\n",
      "[Epoch 8/100] [Batch 6/347] [D loss: 0.538942] [G loss: 0.431033]\n",
      "[Epoch 8/100] [Batch 7/347] [D loss: 0.538919] [G loss: 0.430621]\n",
      "[Epoch 8/100] [Batch 8/347] [D loss: 0.538896] [G loss: 0.425809]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 9/347] [D loss: 0.538873] [G loss: 0.424618]\n",
      "[Epoch 8/100] [Batch 10/347] [D loss: 0.538851] [G loss: 0.426020]\n",
      "[Epoch 8/100] [Batch 11/347] [D loss: 0.538828] [G loss: 0.425632]\n",
      "[Epoch 8/100] [Batch 12/347] [D loss: 0.538806] [G loss: 0.425942]\n",
      "[Epoch 8/100] [Batch 13/347] [D loss: 0.538782] [G loss: 0.425388]\n",
      "[Epoch 8/100] [Batch 14/347] [D loss: 0.538760] [G loss: 0.427767]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 15/347] [D loss: 0.538737] [G loss: 0.424065]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 16/347] [D loss: 0.538714] [G loss: 0.419996]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 17/347] [D loss: 0.538691] [G loss: 0.409463]\n",
      "[Epoch 8/100] [Batch 18/347] [D loss: 0.538669] [G loss: 0.415782]\n",
      "[Epoch 8/100] [Batch 19/347] [D loss: 0.538646] [G loss: 0.413718]\n",
      "[Epoch 8/100] [Batch 20/347] [D loss: 0.538624] [G loss: 0.426869]\n",
      "[Epoch 8/100] [Batch 21/347] [D loss: 0.538601] [G loss: 0.423329]\n",
      "[Epoch 8/100] [Batch 22/347] [D loss: 0.538579] [G loss: 0.418415]\n",
      "[Epoch 8/100] [Batch 23/347] [D loss: 0.538557] [G loss: 0.412094]\n",
      "[Epoch 8/100] [Batch 24/347] [D loss: 0.538534] [G loss: 0.411337]\n",
      "[Epoch 8/100] [Batch 25/347] [D loss: 0.538512] [G loss: 0.410625]\n",
      "[Epoch 8/100] [Batch 26/347] [D loss: 0.538490] [G loss: 0.419857]\n",
      "[Epoch 8/100] [Batch 27/347] [D loss: 0.538467] [G loss: 0.425575]\n",
      "[Epoch 8/100] [Batch 28/347] [D loss: 0.538445] [G loss: 0.424889]\n",
      "[Epoch 8/100] [Batch 29/347] [D loss: 0.538423] [G loss: 0.421024]\n",
      "[Epoch 8/100] [Batch 30/347] [D loss: 0.538400] [G loss: 0.427841]\n",
      "[Epoch 8/100] [Batch 31/347] [D loss: 0.538378] [G loss: 0.430341]\n",
      "[Epoch 8/100] [Batch 32/347] [D loss: 0.538355] [G loss: 0.424858]\n",
      "[Epoch 8/100] [Batch 33/347] [D loss: 0.538332] [G loss: 0.419651]\n",
      "[Epoch 8/100] [Batch 34/347] [D loss: 0.538309] [G loss: 0.420559]\n",
      "[Epoch 8/100] [Batch 35/347] [D loss: 0.538287] [G loss: 0.419185]\n",
      "[Epoch 8/100] [Batch 36/347] [D loss: 0.538264] [G loss: 0.410164]\n",
      "[Epoch 8/100] [Batch 37/347] [D loss: 0.538242] [G loss: 0.431047]\n",
      "[Epoch 8/100] [Batch 38/347] [D loss: 0.538219] [G loss: 0.446395]\n",
      "[Epoch 8/100] [Batch 39/347] [D loss: 0.538196] [G loss: 0.436999]\n",
      "[Epoch 8/100] [Batch 40/347] [D loss: 0.538174] [G loss: 0.437066]\n",
      "[Epoch 8/100] [Batch 41/347] [D loss: 0.538152] [G loss: 0.438587]\n",
      "[Epoch 8/100] [Batch 42/347] [D loss: 0.538129] [G loss: 0.431744]\n",
      "[Epoch 8/100] [Batch 43/347] [D loss: 0.538107] [G loss: 0.416045]\n",
      "[Epoch 8/100] [Batch 44/347] [D loss: 0.538085] [G loss: 0.416712]\n",
      "[Epoch 8/100] [Batch 45/347] [D loss: 0.538063] [G loss: 0.434156]\n",
      "[Epoch 8/100] [Batch 46/347] [D loss: 0.538040] [G loss: 0.428966]\n",
      "[Epoch 8/100] [Batch 47/347] [D loss: 0.538017] [G loss: 0.413351]\n",
      "[Epoch 8/100] [Batch 48/347] [D loss: 0.537994] [G loss: 0.445518]\n",
      "[Epoch 8/100] [Batch 49/347] [D loss: 0.537971] [G loss: 0.454078]\n",
      "[Epoch 8/100] [Batch 50/347] [D loss: 0.537949] [G loss: 0.469855]\n",
      "[Epoch 8/100] [Batch 51/347] [D loss: 0.537927] [G loss: 0.454592]\n",
      "[Epoch 8/100] [Batch 52/347] [D loss: 0.537904] [G loss: 0.415953]\n",
      "[Epoch 8/100] [Batch 53/347] [D loss: 0.537882] [G loss: 0.417321]\n",
      "[Epoch 8/100] [Batch 54/347] [D loss: 0.537859] [G loss: 0.469687]\n",
      "[Epoch 8/100] [Batch 55/347] [D loss: 0.537835] [G loss: 0.491929]\n",
      "[Epoch 8/100] [Batch 56/347] [D loss: 0.537812] [G loss: 0.478936]\n",
      "[Epoch 8/100] [Batch 57/347] [D loss: 0.537790] [G loss: 0.444715]\n",
      "[Epoch 8/100] [Batch 58/347] [D loss: 0.537768] [G loss: 0.414588]\n",
      "[Epoch 8/100] [Batch 59/347] [D loss: 0.537745] [G loss: 0.427551]\n",
      "[Epoch 8/100] [Batch 60/347] [D loss: 0.537722] [G loss: 0.446061]\n",
      "[Epoch 8/100] [Batch 61/347] [D loss: 0.537699] [G loss: 0.458314]\n",
      "[Epoch 8/100] [Batch 62/347] [D loss: 0.537676] [G loss: 0.482063]\n",
      "[Epoch 8/100] [Batch 63/347] [D loss: 0.537653] [G loss: 0.484113]\n",
      "[Epoch 8/100] [Batch 64/347] [D loss: 0.537630] [G loss: 0.447372]\n",
      "[Epoch 8/100] [Batch 65/347] [D loss: 0.537609] [G loss: 0.419114]\n",
      "[Epoch 8/100] [Batch 66/347] [D loss: 0.537586] [G loss: 0.421555]\n",
      "[Epoch 8/100] [Batch 67/347] [D loss: 0.537562] [G loss: 0.430791]\n",
      "[Epoch 8/100] [Batch 68/347] [D loss: 0.537540] [G loss: 0.448584]\n",
      "[Epoch 8/100] [Batch 69/347] [D loss: 0.537516] [G loss: 0.467196]\n",
      "[Epoch 8/100] [Batch 70/347] [D loss: 0.537493] [G loss: 0.465887]\n",
      "[Epoch 8/100] [Batch 71/347] [D loss: 0.537471] [G loss: 0.468483]\n",
      "[Epoch 8/100] [Batch 72/347] [D loss: 0.537448] [G loss: 0.471059]\n",
      "[Epoch 8/100] [Batch 73/347] [D loss: 0.537426] [G loss: 0.446267]\n",
      "[Epoch 8/100] [Batch 74/347] [D loss: 0.537404] [G loss: 0.432302]\n",
      "[Epoch 8/100] [Batch 75/347] [D loss: 0.537382] [G loss: 0.461818]\n",
      "[Epoch 8/100] [Batch 76/347] [D loss: 0.537358] [G loss: 0.463467]\n",
      "[Epoch 8/100] [Batch 77/347] [D loss: 0.537335] [G loss: 0.429047]\n",
      "[Epoch 8/100] [Batch 78/347] [D loss: 0.537314] [G loss: 0.426352]\n",
      "[Epoch 8/100] [Batch 79/347] [D loss: 0.537291] [G loss: 0.428044]\n",
      "[Epoch 8/100] [Batch 80/347] [D loss: 0.537269] [G loss: 0.425598]\n",
      "[Epoch 8/100] [Batch 81/347] [D loss: 0.537246] [G loss: 0.430782]\n",
      "[Epoch 8/100] [Batch 82/347] [D loss: 0.537224] [G loss: 0.435720]\n",
      "[Epoch 8/100] [Batch 83/347] [D loss: 0.537201] [G loss: 0.428043]\n",
      "[Epoch 8/100] [Batch 84/347] [D loss: 0.537179] [G loss: 0.434648]\n",
      "[Epoch 8/100] [Batch 85/347] [D loss: 0.537157] [G loss: 0.435297]\n",
      "[Epoch 8/100] [Batch 86/347] [D loss: 0.537135] [G loss: 0.429562]\n",
      "[Epoch 8/100] [Batch 87/347] [D loss: 0.537113] [G loss: 0.427152]\n",
      "[Epoch 8/100] [Batch 88/347] [D loss: 0.537091] [G loss: 0.430319]\n",
      "[Epoch 8/100] [Batch 89/347] [D loss: 0.537069] [G loss: 0.433488]\n",
      "[Epoch 8/100] [Batch 90/347] [D loss: 0.537047] [G loss: 0.429452]\n",
      "[Epoch 8/100] [Batch 91/347] [D loss: 0.537025] [G loss: 0.427798]\n",
      "[Epoch 8/100] [Batch 92/347] [D loss: 0.537003] [G loss: 0.428969]\n",
      "[Epoch 8/100] [Batch 93/347] [D loss: 0.536981] [G loss: 0.426750]\n",
      "[Epoch 8/100] [Batch 94/347] [D loss: 0.536959] [G loss: 0.422946]\n",
      "[Epoch 8/100] [Batch 95/347] [D loss: 0.536937] [G loss: 0.423233]\n",
      "[Epoch 8/100] [Batch 96/347] [D loss: 0.536915] [G loss: 0.418218]\n",
      "[Epoch 8/100] [Batch 97/347] [D loss: 0.536892] [G loss: 0.412958]\n",
      "[Epoch 8/100] [Batch 98/347] [D loss: 0.536870] [G loss: 0.417578]\n",
      "[Epoch 8/100] [Batch 99/347] [D loss: 0.536848] [G loss: 0.421060]\n",
      "[Epoch 8/100] [Batch 100/347] [D loss: 0.536826] [G loss: 0.417217]\n",
      "[Epoch 8/100] [Batch 101/347] [D loss: 0.536803] [G loss: 0.415770]\n",
      "[Epoch 8/100] [Batch 102/347] [D loss: 0.536782] [G loss: 0.416678]\n",
      "[Epoch 8/100] [Batch 103/347] [D loss: 0.536760] [G loss: 0.416130]\n",
      "[Epoch 8/100] [Batch 104/347] [D loss: 0.536738] [G loss: 0.418059]\n",
      "[Epoch 8/100] [Batch 105/347] [D loss: 0.536715] [G loss: 0.419453]\n",
      "[Epoch 8/100] [Batch 106/347] [D loss: 0.536694] [G loss: 0.418191]\n",
      "[Epoch 8/100] [Batch 107/347] [D loss: 0.536672] [G loss: 0.411241]\n",
      "[Epoch 8/100] [Batch 108/347] [D loss: 0.536649] [G loss: 0.428018]\n",
      "[Epoch 8/100] [Batch 109/347] [D loss: 0.536628] [G loss: 0.420946]\n",
      "[Epoch 8/100] [Batch 110/347] [D loss: 0.536606] [G loss: 0.409976]\n",
      "[Epoch 8/100] [Batch 111/347] [D loss: 0.536584] [G loss: 0.414700]\n",
      "[Epoch 8/100] [Batch 112/347] [D loss: 0.536561] [G loss: 0.419949]\n",
      "[Epoch 8/100] [Batch 113/347] [D loss: 0.536539] [G loss: 0.425310]\n",
      "[Epoch 8/100] [Batch 114/347] [D loss: 0.536518] [G loss: 0.445879]\n",
      "[Epoch 8/100] [Batch 115/347] [D loss: 0.536495] [G loss: 0.446955]\n",
      "[Epoch 8/100] [Batch 116/347] [D loss: 0.536473] [G loss: 0.441055]\n",
      "[Epoch 8/100] [Batch 117/347] [D loss: 0.536451] [G loss: 0.414313]\n",
      "[Epoch 8/100] [Batch 118/347] [D loss: 0.536428] [G loss: 0.418689]\n",
      "[Epoch 8/100] [Batch 119/347] [D loss: 0.536406] [G loss: 0.421025]\n",
      "[Epoch 8/100] [Batch 120/347] [D loss: 0.536384] [G loss: 0.420135]\n",
      "[Epoch 8/100] [Batch 121/347] [D loss: 0.536362] [G loss: 0.418588]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 122/347] [D loss: 0.536339] [G loss: 0.405922]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 123/347] [D loss: 0.536318] [G loss: 0.405011]\n",
      "[Epoch 8/100] [Batch 124/347] [D loss: 0.536295] [G loss: 0.406308]\n",
      "[Epoch 8/100] [Batch 125/347] [D loss: 0.536273] [G loss: 0.411091]\n",
      "[Epoch 8/100] [Batch 126/347] [D loss: 0.536251] [G loss: 0.423794]\n",
      "[Epoch 8/100] [Batch 127/347] [D loss: 0.536229] [G loss: 0.425290]\n",
      "[Epoch 8/100] [Batch 128/347] [D loss: 0.536206] [G loss: 0.419803]\n",
      "[Epoch 8/100] [Batch 129/347] [D loss: 0.536184] [G loss: 0.415166]\n",
      "[Epoch 8/100] [Batch 130/347] [D loss: 0.536162] [G loss: 0.418563]\n",
      "[Epoch 8/100] [Batch 131/347] [D loss: 0.536139] [G loss: 0.416428]\n",
      "[Epoch 8/100] [Batch 132/347] [D loss: 0.536116] [G loss: 0.440230]\n",
      "[Epoch 8/100] [Batch 133/347] [D loss: 0.536094] [G loss: 0.447276]\n",
      "[Epoch 8/100] [Batch 134/347] [D loss: 0.536072] [G loss: 0.462487]\n",
      "[Epoch 8/100] [Batch 135/347] [D loss: 0.536049] [G loss: 0.471780]\n",
      "[Epoch 8/100] [Batch 136/347] [D loss: 0.536027] [G loss: 0.430217]\n",
      "[Epoch 8/100] [Batch 137/347] [D loss: 0.536006] [G loss: 0.416209]\n",
      "[Epoch 8/100] [Batch 138/347] [D loss: 0.535983] [G loss: 0.435549]\n",
      "[Epoch 8/100] [Batch 139/347] [D loss: 0.535960] [G loss: 0.459525]\n",
      "[Epoch 8/100] [Batch 140/347] [D loss: 0.535937] [G loss: 0.471025]\n",
      "[Epoch 8/100] [Batch 141/347] [D loss: 0.535915] [G loss: 0.477984]\n",
      "[Epoch 8/100] [Batch 142/347] [D loss: 0.535893] [G loss: 0.485853]\n",
      "[Epoch 8/100] [Batch 143/347] [D loss: 0.535871] [G loss: 0.507791]\n",
      "[Epoch 8/100] [Batch 144/347] [D loss: 0.535848] [G loss: 0.510132]\n",
      "[Epoch 8/100] [Batch 145/347] [D loss: 0.535826] [G loss: 0.495986]\n",
      "[Epoch 8/100] [Batch 146/347] [D loss: 0.535804] [G loss: 0.479298]\n",
      "[Epoch 8/100] [Batch 147/347] [D loss: 0.535782] [G loss: 0.451285]\n",
      "[Epoch 8/100] [Batch 148/347] [D loss: 0.535761] [G loss: 0.438922]\n",
      "[Epoch 8/100] [Batch 149/347] [D loss: 0.535738] [G loss: 0.452019]\n",
      "[Epoch 8/100] [Batch 150/347] [D loss: 0.535715] [G loss: 0.452290]\n",
      "[Epoch 8/100] [Batch 151/347] [D loss: 0.535694] [G loss: 0.441283]\n",
      "[Epoch 8/100] [Batch 152/347] [D loss: 0.535672] [G loss: 0.452212]\n",
      "[Epoch 8/100] [Batch 153/347] [D loss: 0.535649] [G loss: 0.472803]\n",
      "[Epoch 8/100] [Batch 154/347] [D loss: 0.535626] [G loss: 0.476935]\n",
      "[Epoch 8/100] [Batch 155/347] [D loss: 0.535604] [G loss: 0.464076]\n",
      "[Epoch 8/100] [Batch 156/347] [D loss: 0.535583] [G loss: 0.447499]\n",
      "[Epoch 8/100] [Batch 157/347] [D loss: 0.535561] [G loss: 0.453836]\n",
      "[Epoch 8/100] [Batch 158/347] [D loss: 0.535539] [G loss: 0.477492]\n",
      "[Epoch 8/100] [Batch 159/347] [D loss: 0.535516] [G loss: 0.474797]\n",
      "[Epoch 8/100] [Batch 160/347] [D loss: 0.535494] [G loss: 0.454836]\n",
      "[Epoch 8/100] [Batch 161/347] [D loss: 0.535474] [G loss: 0.446389]\n",
      "[Epoch 8/100] [Batch 162/347] [D loss: 0.535451] [G loss: 0.452010]\n",
      "[Epoch 8/100] [Batch 163/347] [D loss: 0.535429] [G loss: 0.470635]\n",
      "[Epoch 8/100] [Batch 164/347] [D loss: 0.535407] [G loss: 0.485744]\n",
      "[Epoch 8/100] [Batch 165/347] [D loss: 0.535385] [G loss: 0.476688]\n",
      "[Epoch 8/100] [Batch 166/347] [D loss: 0.535363] [G loss: 0.438493]\n",
      "[Epoch 8/100] [Batch 167/347] [D loss: 0.535343] [G loss: 0.420438]\n",
      "[Epoch 8/100] [Batch 168/347] [D loss: 0.535321] [G loss: 0.431199]\n",
      "[Epoch 8/100] [Batch 169/347] [D loss: 0.535299] [G loss: 0.430053]\n",
      "[Epoch 8/100] [Batch 170/347] [D loss: 0.535277] [G loss: 0.426251]\n",
      "[Epoch 8/100] [Batch 171/347] [D loss: 0.535255] [G loss: 0.436555]\n",
      "[Epoch 8/100] [Batch 172/347] [D loss: 0.535233] [G loss: 0.441481]\n",
      "[Epoch 8/100] [Batch 173/347] [D loss: 0.535211] [G loss: 0.430194]\n",
      "[Epoch 8/100] [Batch 174/347] [D loss: 0.535189] [G loss: 0.427601]\n",
      "[Epoch 8/100] [Batch 175/347] [D loss: 0.535168] [G loss: 0.437247]\n",
      "[Epoch 8/100] [Batch 176/347] [D loss: 0.535147] [G loss: 0.450428]\n",
      "[Epoch 8/100] [Batch 177/347] [D loss: 0.535125] [G loss: 0.451034]\n",
      "[Epoch 8/100] [Batch 178/347] [D loss: 0.535104] [G loss: 0.444862]\n",
      "[Epoch 8/100] [Batch 179/347] [D loss: 0.535083] [G loss: 0.438002]\n",
      "[Epoch 8/100] [Batch 180/347] [D loss: 0.535062] [G loss: 0.431428]\n",
      "[Epoch 8/100] [Batch 181/347] [D loss: 0.535041] [G loss: 0.431582]\n",
      "[Epoch 8/100] [Batch 182/347] [D loss: 0.535020] [G loss: 0.429086]\n",
      "[Epoch 8/100] [Batch 183/347] [D loss: 0.534999] [G loss: 0.432802]\n",
      "[Epoch 8/100] [Batch 184/347] [D loss: 0.534977] [G loss: 0.436356]\n",
      "[Epoch 8/100] [Batch 185/347] [D loss: 0.534956] [G loss: 0.434622]\n",
      "[Epoch 8/100] [Batch 186/347] [D loss: 0.534934] [G loss: 0.434127]\n",
      "[Epoch 8/100] [Batch 187/347] [D loss: 0.534913] [G loss: 0.428551]\n",
      "[Epoch 8/100] [Batch 188/347] [D loss: 0.534891] [G loss: 0.425127]\n",
      "[Epoch 8/100] [Batch 189/347] [D loss: 0.534869] [G loss: 0.423970]\n",
      "[Epoch 8/100] [Batch 190/347] [D loss: 0.534847] [G loss: 0.411802]\n",
      "[Epoch 8/100] [Batch 191/347] [D loss: 0.534825] [G loss: 0.410673]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 192/347] [D loss: 0.534802] [G loss: 0.401412]\n",
      "[Epoch 8/100] [Batch 193/347] [D loss: 0.534781] [G loss: 0.409078]\n",
      "[Epoch 8/100] [Batch 194/347] [D loss: 0.534759] [G loss: 0.405485]\n",
      "[Epoch 8/100] [Batch 195/347] [D loss: 0.534737] [G loss: 0.414236]\n",
      "[Epoch 8/100] [Batch 196/347] [D loss: 0.534715] [G loss: 0.411952]\n",
      "[Epoch 8/100] [Batch 197/347] [D loss: 0.534693] [G loss: 0.407107]\n",
      "[Epoch 8/100] [Batch 198/347] [D loss: 0.534671] [G loss: 0.405605]\n",
      "[Epoch 8/100] [Batch 199/347] [D loss: 0.534649] [G loss: 0.406748]\n",
      "[Epoch 8/100] [Batch 200/347] [D loss: 0.534627] [G loss: 0.401568]\n",
      "[Epoch 8/100] [Batch 201/347] [D loss: 0.534606] [G loss: 0.402285]\n",
      "[Epoch 8/100] [Batch 202/347] [D loss: 0.534583] [G loss: 0.413707]\n",
      "[Epoch 8/100] [Batch 203/347] [D loss: 0.534561] [G loss: 0.422178]\n",
      "[Epoch 8/100] [Batch 204/347] [D loss: 0.534539] [G loss: 0.418514]\n",
      "[Epoch 8/100] [Batch 205/347] [D loss: 0.534518] [G loss: 0.410464]\n",
      "[Epoch 8/100] [Batch 206/347] [D loss: 0.534496] [G loss: 0.401576]\n",
      "[Epoch 8/100] [Batch 207/347] [D loss: 0.534474] [G loss: 0.412429]\n",
      "[Epoch 8/100] [Batch 208/347] [D loss: 0.534452] [G loss: 0.413310]\n",
      "[Epoch 8/100] [Batch 209/347] [D loss: 0.534430] [G loss: 0.407778]\n",
      "[Epoch 8/100] [Batch 210/347] [D loss: 0.534408] [G loss: 0.414918]\n",
      "[Epoch 8/100] [Batch 211/347] [D loss: 0.534386] [G loss: 0.412076]\n",
      "[Epoch 8/100] [Batch 212/347] [D loss: 0.534364] [G loss: 0.410855]\n",
      "[Epoch 8/100] [Batch 213/347] [D loss: 0.534342] [G loss: 0.416287]\n",
      "[Epoch 8/100] [Batch 214/347] [D loss: 0.534320] [G loss: 0.423224]\n",
      "[Epoch 8/100] [Batch 215/347] [D loss: 0.534297] [G loss: 0.431515]\n",
      "[Epoch 8/100] [Batch 216/347] [D loss: 0.534275] [G loss: 0.414892]\n",
      "[Epoch 8/100] [Batch 217/347] [D loss: 0.534254] [G loss: 0.415305]\n",
      "[Epoch 8/100] [Batch 218/347] [D loss: 0.534232] [G loss: 0.422087]\n",
      "[Epoch 8/100] [Batch 219/347] [D loss: 0.534210] [G loss: 0.434151]\n",
      "[Epoch 8/100] [Batch 220/347] [D loss: 0.534189] [G loss: 0.449857]\n",
      "[Epoch 8/100] [Batch 221/347] [D loss: 0.534167] [G loss: 0.451199]\n",
      "[Epoch 8/100] [Batch 222/347] [D loss: 0.534144] [G loss: 0.443080]\n",
      "[Epoch 8/100] [Batch 223/347] [D loss: 0.534122] [G loss: 0.441520]\n",
      "[Epoch 8/100] [Batch 224/347] [D loss: 0.534101] [G loss: 0.437192]\n",
      "[Epoch 8/100] [Batch 225/347] [D loss: 0.534078] [G loss: 0.422712]\n",
      "[Epoch 8/100] [Batch 226/347] [D loss: 0.534056] [G loss: 0.418959]\n",
      "[Epoch 8/100] [Batch 227/347] [D loss: 0.534034] [G loss: 0.429531]\n",
      "[Epoch 8/100] [Batch 228/347] [D loss: 0.534012] [G loss: 0.432173]\n",
      "[Epoch 8/100] [Batch 229/347] [D loss: 0.533990] [G loss: 0.427593]\n",
      "[Epoch 8/100] [Batch 230/347] [D loss: 0.533969] [G loss: 0.424027]\n",
      "[Epoch 8/100] [Batch 231/347] [D loss: 0.533947] [G loss: 0.424149]\n",
      "[Epoch 8/100] [Batch 232/347] [D loss: 0.533925] [G loss: 0.420096]\n",
      "[Epoch 8/100] [Batch 233/347] [D loss: 0.533904] [G loss: 0.417286]\n",
      "[Epoch 8/100] [Batch 234/347] [D loss: 0.533882] [G loss: 0.422135]\n",
      "[Epoch 8/100] [Batch 235/347] [D loss: 0.533860] [G loss: 0.410822]\n",
      "[Epoch 8/100] [Batch 236/347] [D loss: 0.533839] [G loss: 0.407967]\n",
      "[Epoch 8/100] [Batch 237/347] [D loss: 0.533817] [G loss: 0.411940]\n",
      "[Epoch 8/100] [Batch 238/347] [D loss: 0.533796] [G loss: 0.415989]\n",
      "[Epoch 8/100] [Batch 239/347] [D loss: 0.533774] [G loss: 0.414029]\n",
      "[Epoch 8/100] [Batch 240/347] [D loss: 0.533752] [G loss: 0.410156]\n",
      "[Epoch 8/100] [Batch 241/347] [D loss: 0.533730] [G loss: 0.404223]\n",
      "[Epoch 8/100] [Batch 242/347] [D loss: 0.533709] [G loss: 0.402059]\n",
      "[Epoch 8/100] [Batch 243/347] [D loss: 0.533687] [G loss: 0.409409]\n",
      "[Epoch 8/100] [Batch 244/347] [D loss: 0.533666] [G loss: 0.417919]\n",
      "[Epoch 8/100] [Batch 245/347] [D loss: 0.533645] [G loss: 0.416299]\n",
      "[Epoch 8/100] [Batch 246/347] [D loss: 0.533623] [G loss: 0.408739]\n",
      "[Epoch 8/100] [Batch 247/347] [D loss: 0.533601] [G loss: 0.417507]\n",
      "[Epoch 8/100] [Batch 248/347] [D loss: 0.533579] [G loss: 0.423568]\n",
      "[Epoch 8/100] [Batch 249/347] [D loss: 0.533558] [G loss: 0.429201]\n",
      "[Epoch 8/100] [Batch 250/347] [D loss: 0.533538] [G loss: 0.420761]\n",
      "[Epoch 8/100] [Batch 251/347] [D loss: 0.533518] [G loss: 0.407871]\n",
      "[Epoch 8/100] [Batch 252/347] [D loss: 0.533498] [G loss: 0.411024]\n",
      "[Epoch 8/100] [Batch 253/347] [D loss: 0.533478] [G loss: 0.411586]\n",
      "[Epoch 8/100] [Batch 254/347] [D loss: 0.533457] [G loss: 0.409942]\n",
      "[Epoch 8/100] [Batch 255/347] [D loss: 0.533436] [G loss: 0.408514]\n",
      "[Epoch 8/100] [Batch 256/347] [D loss: 0.533415] [G loss: 0.413534]\n",
      "[Epoch 8/100] [Batch 257/347] [D loss: 0.533393] [G loss: 0.415570]\n",
      "[Epoch 8/100] [Batch 258/347] [D loss: 0.533373] [G loss: 0.409726]\n",
      "[Epoch 8/100] [Batch 259/347] [D loss: 0.533351] [G loss: 0.419871]\n",
      "[Epoch 8/100] [Batch 260/347] [D loss: 0.533329] [G loss: 0.434268]\n",
      "[Epoch 8/100] [Batch 261/347] [D loss: 0.533309] [G loss: 0.426804]\n",
      "[Epoch 8/100] [Batch 262/347] [D loss: 0.533287] [G loss: 0.411741]\n",
      "[Epoch 8/100] [Batch 263/347] [D loss: 0.533267] [G loss: 0.412736]\n",
      "[Epoch 8/100] [Batch 264/347] [D loss: 0.533245] [G loss: 0.427182]\n",
      "[Epoch 8/100] [Batch 265/347] [D loss: 0.533224] [G loss: 0.432250]\n",
      "[Epoch 8/100] [Batch 266/347] [D loss: 0.533202] [G loss: 0.425059]\n",
      "[Epoch 8/100] [Batch 267/347] [D loss: 0.533181] [G loss: 0.418214]\n",
      "[Epoch 8/100] [Batch 268/347] [D loss: 0.533160] [G loss: 0.425003]\n",
      "[Epoch 8/100] [Batch 269/347] [D loss: 0.533138] [G loss: 0.436013]\n",
      "[Epoch 8/100] [Batch 270/347] [D loss: 0.533117] [G loss: 0.432445]\n",
      "[Epoch 8/100] [Batch 271/347] [D loss: 0.533095] [G loss: 0.420500]\n",
      "[Epoch 8/100] [Batch 272/347] [D loss: 0.533074] [G loss: 0.411748]\n",
      "[Epoch 8/100] [Batch 273/347] [D loss: 0.533052] [G loss: 0.423426]\n",
      "[Epoch 8/100] [Batch 274/347] [D loss: 0.533030] [G loss: 0.456988]\n",
      "[Epoch 8/100] [Batch 275/347] [D loss: 0.533008] [G loss: 0.453761]\n",
      "[Epoch 8/100] [Batch 276/347] [D loss: 0.532987] [G loss: 0.421217]\n",
      "[Epoch 8/100] [Batch 277/347] [D loss: 0.532965] [G loss: 0.406406]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 278/347] [D loss: 0.532944] [G loss: 0.396273]\n",
      "[Epoch 8/100] [Batch 279/347] [D loss: 0.532922] [G loss: 0.402736]\n",
      "[Epoch 8/100] [Batch 280/347] [D loss: 0.532900] [G loss: 0.406372]\n",
      "[Epoch 8/100] [Batch 281/347] [D loss: 0.532878] [G loss: 0.404626]\n",
      "[Epoch 8/100] [Batch 282/347] [D loss: 0.532856] [G loss: 0.402415]\n",
      "[Epoch 8/100] [Batch 283/347] [D loss: 0.532834] [G loss: 0.406607]\n",
      "[Epoch 8/100] [Batch 284/347] [D loss: 0.532812] [G loss: 0.405009]\n",
      "[Epoch 8/100] [Batch 285/347] [D loss: 0.532790] [G loss: 0.400811]\n",
      "[Epoch 8/100] [Batch 286/347] [D loss: 0.532768] [G loss: 0.396337]\n",
      "[Epoch 8/100] [Batch 287/347] [D loss: 0.532746] [G loss: 0.399825]\n",
      "[Epoch 8/100] [Batch 288/347] [D loss: 0.532723] [G loss: 0.426218]\n",
      "[Epoch 8/100] [Batch 289/347] [D loss: 0.532702] [G loss: 0.430255]\n",
      "[Epoch 8/100] [Batch 290/347] [D loss: 0.532680] [G loss: 0.407539]\n",
      "[Epoch 8/100] [Batch 291/347] [D loss: 0.532658] [G loss: 0.409983]\n",
      "[Epoch 8/100] [Batch 292/347] [D loss: 0.532636] [G loss: 0.401064]\n",
      "[Epoch 8/100] [Batch 293/347] [D loss: 0.532615] [G loss: 0.412555]\n",
      "[Epoch 8/100] [Batch 294/347] [D loss: 0.532594] [G loss: 0.422627]\n",
      "[Epoch 8/100] [Batch 295/347] [D loss: 0.532572] [G loss: 0.420485]\n",
      "[Epoch 8/100] [Batch 296/347] [D loss: 0.532550] [G loss: 0.416595]\n",
      "[Epoch 8/100] [Batch 297/347] [D loss: 0.532528] [G loss: 0.428705]\n",
      "[Epoch 8/100] [Batch 298/347] [D loss: 0.532507] [G loss: 0.423639]\n",
      "[Epoch 8/100] [Batch 299/347] [D loss: 0.532485] [G loss: 0.422186]\n",
      "[Epoch 8/100] [Batch 300/347] [D loss: 0.532463] [G loss: 0.417380]\n",
      "[Epoch 8/100] [Batch 301/347] [D loss: 0.532442] [G loss: 0.418104]\n",
      "[Epoch 8/100] [Batch 302/347] [D loss: 0.532420] [G loss: 0.423019]\n",
      "[Epoch 8/100] [Batch 303/347] [D loss: 0.532399] [G loss: 0.407189]\n",
      "[Epoch 8/100] [Batch 304/347] [D loss: 0.532377] [G loss: 0.407974]\n",
      "[Epoch 8/100] [Batch 305/347] [D loss: 0.532355] [G loss: 0.420840]\n",
      "[Epoch 8/100] [Batch 306/347] [D loss: 0.532334] [G loss: 0.412070]\n",
      "[Epoch 8/100] [Batch 307/347] [D loss: 0.532313] [G loss: 0.424778]\n",
      "[Epoch 8/100] [Batch 308/347] [D loss: 0.532292] [G loss: 0.421022]\n",
      "[Epoch 8/100] [Batch 309/347] [D loss: 0.532271] [G loss: 0.401525]\n",
      "[Epoch 8/100] [Batch 310/347] [D loss: 0.532251] [G loss: 0.419183]\n",
      "[Epoch 8/100] [Batch 311/347] [D loss: 0.532229] [G loss: 0.422141]\n",
      "[Epoch 8/100] [Batch 312/347] [D loss: 0.532208] [G loss: 0.421922]\n",
      "[Epoch 8/100] [Batch 313/347] [D loss: 0.532187] [G loss: 0.421145]\n",
      "[Epoch 8/100] [Batch 314/347] [D loss: 0.532165] [G loss: 0.414800]\n",
      "[Epoch 8/100] [Batch 315/347] [D loss: 0.532144] [G loss: 0.405368]\n",
      "[Epoch 8/100] [Batch 316/347] [D loss: 0.532123] [G loss: 0.401057]\n",
      "[Epoch 8/100] [Batch 317/347] [D loss: 0.532100] [G loss: 0.419621]\n",
      "[Epoch 8/100] [Batch 318/347] [D loss: 0.532079] [G loss: 0.397466]\n",
      "[Epoch 8/100] [Batch 319/347] [D loss: 0.532059] [G loss: 0.426933]\n",
      "[Epoch 8/100] [Batch 320/347] [D loss: 0.532038] [G loss: 0.440553]\n",
      "[Epoch 8/100] [Batch 321/347] [D loss: 0.532017] [G loss: 0.430005]\n",
      "[Epoch 8/100] [Batch 322/347] [D loss: 0.531995] [G loss: 0.417044]\n",
      "[Epoch 8/100] [Batch 323/347] [D loss: 0.531973] [G loss: 0.416262]\n",
      "[Epoch 8/100] [Batch 324/347] [D loss: 0.531951] [G loss: 0.419062]\n",
      "[Epoch 8/100] [Batch 325/347] [D loss: 0.531930] [G loss: 0.408043]\n",
      "[Epoch 8/100] [Batch 326/347] [D loss: 0.531908] [G loss: 0.396769]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 327/347] [D loss: 0.531887] [G loss: 0.394570]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 8/100] [Batch 328/347] [D loss: 0.531865] [G loss: 0.393247]\n",
      "[Epoch 8/100] [Batch 329/347] [D loss: 0.531843] [G loss: 0.415227]\n",
      "[Epoch 8/100] [Batch 330/347] [D loss: 0.531821] [G loss: 0.430764]\n",
      "[Epoch 8/100] [Batch 331/347] [D loss: 0.531800] [G loss: 0.412597]\n",
      "[Epoch 8/100] [Batch 332/347] [D loss: 0.531779] [G loss: 0.406584]\n",
      "[Epoch 8/100] [Batch 333/347] [D loss: 0.531758] [G loss: 0.418008]\n",
      "[Epoch 8/100] [Batch 334/347] [D loss: 0.531736] [G loss: 0.419461]\n",
      "[Epoch 8/100] [Batch 335/347] [D loss: 0.531715] [G loss: 0.407571]\n",
      "[Epoch 8/100] [Batch 336/347] [D loss: 0.531693] [G loss: 0.393323]\n",
      "[Epoch 8/100] [Batch 337/347] [D loss: 0.531671] [G loss: 0.399279]\n",
      "[Epoch 8/100] [Batch 338/347] [D loss: 0.531650] [G loss: 0.413713]\n",
      "[Epoch 8/100] [Batch 339/347] [D loss: 0.531629] [G loss: 0.418944]\n",
      "[Epoch 8/100] [Batch 340/347] [D loss: 0.531607] [G loss: 0.419095]\n",
      "[Epoch 8/100] [Batch 341/347] [D loss: 0.531586] [G loss: 0.414145]\n",
      "[Epoch 8/100] [Batch 342/347] [D loss: 0.531565] [G loss: 0.406387]\n",
      "[Epoch 8/100] [Batch 343/347] [D loss: 0.531544] [G loss: 0.410942]\n",
      "[Epoch 8/100] [Batch 344/347] [D loss: 0.531522] [G loss: 0.405350]\n",
      "[Epoch 8/100] [Batch 345/347] [D loss: 0.531500] [G loss: 0.415639]\n",
      "[Epoch 8/100] [Batch 346/347] [D loss: 0.531479] [G loss: 0.434216]\n",
      "[Epoch 8/100] [Batch 347/347] [D loss: 0.531457] [G loss: 0.440599]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 1/347] [D loss: 0.531437] [G loss: 0.406588]\n",
      "[Epoch 9/100] [Batch 2/347] [D loss: 0.531416] [G loss: 0.411797]\n",
      "[Epoch 9/100] [Batch 3/347] [D loss: 0.531395] [G loss: 0.411678]\n",
      "[Epoch 9/100] [Batch 4/347] [D loss: 0.531375] [G loss: 0.412820]\n",
      "[Epoch 9/100] [Batch 5/347] [D loss: 0.531354] [G loss: 0.411923]\n",
      "[Epoch 9/100] [Batch 6/347] [D loss: 0.531333] [G loss: 0.412156]\n",
      "[Epoch 9/100] [Batch 7/347] [D loss: 0.531313] [G loss: 0.411802]\n",
      "[Epoch 9/100] [Batch 8/347] [D loss: 0.531292] [G loss: 0.406959]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 9/347] [D loss: 0.531272] [G loss: 0.405799]\n",
      "[Epoch 9/100] [Batch 10/347] [D loss: 0.531251] [G loss: 0.407255]\n",
      "[Epoch 9/100] [Batch 11/347] [D loss: 0.531230] [G loss: 0.406896]\n",
      "[Epoch 9/100] [Batch 12/347] [D loss: 0.531209] [G loss: 0.407257]\n",
      "[Epoch 9/100] [Batch 13/347] [D loss: 0.531188] [G loss: 0.407659]\n",
      "[Epoch 9/100] [Batch 14/347] [D loss: 0.531167] [G loss: 0.410008]\n",
      "[Epoch 9/100] [Batch 15/347] [D loss: 0.531145] [G loss: 0.406254]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 16/347] [D loss: 0.531123] [G loss: 0.402165]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 17/347] [D loss: 0.531102] [G loss: 0.390860]\n",
      "[Epoch 9/100] [Batch 18/347] [D loss: 0.531080] [G loss: 0.397278]\n",
      "[Epoch 9/100] [Batch 19/347] [D loss: 0.531058] [G loss: 0.395857]\n",
      "[Epoch 9/100] [Batch 20/347] [D loss: 0.531038] [G loss: 0.409021]\n",
      "[Epoch 9/100] [Batch 21/347] [D loss: 0.531017] [G loss: 0.405460]\n",
      "[Epoch 9/100] [Batch 22/347] [D loss: 0.530995] [G loss: 0.400540]\n",
      "[Epoch 9/100] [Batch 23/347] [D loss: 0.530974] [G loss: 0.394270]\n",
      "[Epoch 9/100] [Batch 24/347] [D loss: 0.530953] [G loss: 0.393517]\n",
      "[Epoch 9/100] [Batch 25/347] [D loss: 0.530932] [G loss: 0.392822]\n",
      "[Epoch 9/100] [Batch 26/347] [D loss: 0.530910] [G loss: 0.401256]\n",
      "[Epoch 9/100] [Batch 27/347] [D loss: 0.530888] [G loss: 0.406980]\n",
      "[Epoch 9/100] [Batch 28/347] [D loss: 0.530867] [G loss: 0.407106]\n",
      "[Epoch 9/100] [Batch 29/347] [D loss: 0.530846] [G loss: 0.403281]\n",
      "[Epoch 9/100] [Batch 30/347] [D loss: 0.530823] [G loss: 0.410078]\n",
      "[Epoch 9/100] [Batch 31/347] [D loss: 0.530802] [G loss: 0.412574]\n",
      "[Epoch 9/100] [Batch 32/347] [D loss: 0.530780] [G loss: 0.407052]\n",
      "[Epoch 9/100] [Batch 33/347] [D loss: 0.530757] [G loss: 0.401836]\n",
      "[Epoch 9/100] [Batch 34/347] [D loss: 0.530735] [G loss: 0.402793]\n",
      "[Epoch 9/100] [Batch 35/347] [D loss: 0.530712] [G loss: 0.401458]\n",
      "[Epoch 9/100] [Batch 36/347] [D loss: 0.530690] [G loss: 0.392473]\n",
      "[Epoch 9/100] [Batch 37/347] [D loss: 0.530667] [G loss: 0.412280]\n",
      "[Epoch 9/100] [Batch 38/347] [D loss: 0.530645] [G loss: 0.427585]\n",
      "[Epoch 9/100] [Batch 39/347] [D loss: 0.530622] [G loss: 0.418139]\n",
      "[Epoch 9/100] [Batch 40/347] [D loss: 0.530601] [G loss: 0.418137]\n",
      "[Epoch 9/100] [Batch 41/347] [D loss: 0.530578] [G loss: 0.419609]\n",
      "[Epoch 9/100] [Batch 42/347] [D loss: 0.530556] [G loss: 0.412752]\n",
      "[Epoch 9/100] [Batch 43/347] [D loss: 0.530535] [G loss: 0.397084]\n",
      "[Epoch 9/100] [Batch 44/347] [D loss: 0.530514] [G loss: 0.399111]\n",
      "[Epoch 9/100] [Batch 45/347] [D loss: 0.530492] [G loss: 0.416506]\n",
      "[Epoch 9/100] [Batch 46/347] [D loss: 0.530470] [G loss: 0.411296]\n",
      "[Epoch 9/100] [Batch 47/347] [D loss: 0.530447] [G loss: 0.394489]\n",
      "[Epoch 9/100] [Batch 48/347] [D loss: 0.530425] [G loss: 0.426670]\n",
      "[Epoch 9/100] [Batch 49/347] [D loss: 0.530402] [G loss: 0.435240]\n",
      "[Epoch 9/100] [Batch 50/347] [D loss: 0.530381] [G loss: 0.450988]\n",
      "[Epoch 9/100] [Batch 51/347] [D loss: 0.530360] [G loss: 0.435659]\n",
      "[Epoch 9/100] [Batch 52/347] [D loss: 0.530340] [G loss: 0.398311]\n",
      "[Epoch 9/100] [Batch 53/347] [D loss: 0.530320] [G loss: 0.398439]\n",
      "[Epoch 9/100] [Batch 54/347] [D loss: 0.530297] [G loss: 0.450853]\n",
      "[Epoch 9/100] [Batch 55/347] [D loss: 0.530274] [G loss: 0.473107]\n",
      "[Epoch 9/100] [Batch 56/347] [D loss: 0.530253] [G loss: 0.460078]\n",
      "[Epoch 9/100] [Batch 57/347] [D loss: 0.530234] [G loss: 0.425852]\n",
      "[Epoch 9/100] [Batch 58/347] [D loss: 0.530215] [G loss: 0.396844]\n",
      "[Epoch 9/100] [Batch 59/347] [D loss: 0.530195] [G loss: 0.408711]\n",
      "[Epoch 9/100] [Batch 60/347] [D loss: 0.530173] [G loss: 0.427274]\n",
      "[Epoch 9/100] [Batch 61/347] [D loss: 0.530153] [G loss: 0.439552]\n",
      "[Epoch 9/100] [Batch 62/347] [D loss: 0.530132] [G loss: 0.463317]\n",
      "[Epoch 9/100] [Batch 63/347] [D loss: 0.530111] [G loss: 0.465425]\n",
      "[Epoch 9/100] [Batch 64/347] [D loss: 0.530091] [G loss: 0.428686]\n",
      "[Epoch 9/100] [Batch 65/347] [D loss: 0.530073] [G loss: 0.401256]\n",
      "[Epoch 9/100] [Batch 66/347] [D loss: 0.530054] [G loss: 0.403739]\n",
      "[Epoch 9/100] [Batch 67/347] [D loss: 0.530032] [G loss: 0.412156]\n",
      "[Epoch 9/100] [Batch 68/347] [D loss: 0.530011] [G loss: 0.430020]\n",
      "[Epoch 9/100] [Batch 69/347] [D loss: 0.529989] [G loss: 0.448610]\n",
      "[Epoch 9/100] [Batch 70/347] [D loss: 0.529967] [G loss: 0.447351]\n",
      "[Epoch 9/100] [Batch 71/347] [D loss: 0.529946] [G loss: 0.449969]\n",
      "[Epoch 9/100] [Batch 72/347] [D loss: 0.529925] [G loss: 0.452480]\n",
      "[Epoch 9/100] [Batch 73/347] [D loss: 0.529903] [G loss: 0.427752]\n",
      "[Epoch 9/100] [Batch 74/347] [D loss: 0.529883] [G loss: 0.413771]\n",
      "[Epoch 9/100] [Batch 75/347] [D loss: 0.529861] [G loss: 0.443329]\n",
      "[Epoch 9/100] [Batch 76/347] [D loss: 0.529837] [G loss: 0.445063]\n",
      "[Epoch 9/100] [Batch 77/347] [D loss: 0.529815] [G loss: 0.410681]\n",
      "[Epoch 9/100] [Batch 78/347] [D loss: 0.529796] [G loss: 0.408197]\n",
      "[Epoch 9/100] [Batch 79/347] [D loss: 0.529773] [G loss: 0.409891]\n",
      "[Epoch 9/100] [Batch 80/347] [D loss: 0.529750] [G loss: 0.407287]\n",
      "[Epoch 9/100] [Batch 81/347] [D loss: 0.529728] [G loss: 0.412399]\n",
      "[Epoch 9/100] [Batch 82/347] [D loss: 0.529705] [G loss: 0.417379]\n",
      "[Epoch 9/100] [Batch 83/347] [D loss: 0.529683] [G loss: 0.409692]\n",
      "[Epoch 9/100] [Batch 84/347] [D loss: 0.529660] [G loss: 0.416187]\n",
      "[Epoch 9/100] [Batch 85/347] [D loss: 0.529637] [G loss: 0.416824]\n",
      "[Epoch 9/100] [Batch 86/347] [D loss: 0.529615] [G loss: 0.411117]\n",
      "[Epoch 9/100] [Batch 87/347] [D loss: 0.529592] [G loss: 0.408750]\n",
      "[Epoch 9/100] [Batch 88/347] [D loss: 0.529570] [G loss: 0.411905]\n",
      "[Epoch 9/100] [Batch 89/347] [D loss: 0.529547] [G loss: 0.415087]\n",
      "[Epoch 9/100] [Batch 90/347] [D loss: 0.529525] [G loss: 0.411047]\n",
      "[Epoch 9/100] [Batch 91/347] [D loss: 0.529503] [G loss: 0.409376]\n",
      "[Epoch 9/100] [Batch 92/347] [D loss: 0.529480] [G loss: 0.410647]\n",
      "[Epoch 9/100] [Batch 93/347] [D loss: 0.529458] [G loss: 0.408446]\n",
      "[Epoch 9/100] [Batch 94/347] [D loss: 0.529435] [G loss: 0.404682]\n",
      "[Epoch 9/100] [Batch 95/347] [D loss: 0.529414] [G loss: 0.404931]\n",
      "[Epoch 9/100] [Batch 96/347] [D loss: 0.529391] [G loss: 0.400034]\n",
      "[Epoch 9/100] [Batch 97/347] [D loss: 0.529369] [G loss: 0.394740]\n",
      "[Epoch 9/100] [Batch 98/347] [D loss: 0.529346] [G loss: 0.399390]\n",
      "[Epoch 9/100] [Batch 99/347] [D loss: 0.529324] [G loss: 0.402946]\n",
      "[Epoch 9/100] [Batch 100/347] [D loss: 0.529302] [G loss: 0.399118]\n",
      "[Epoch 9/100] [Batch 101/347] [D loss: 0.529279] [G loss: 0.396929]\n",
      "[Epoch 9/100] [Batch 102/347] [D loss: 0.529257] [G loss: 0.397757]\n",
      "[Epoch 9/100] [Batch 103/347] [D loss: 0.529235] [G loss: 0.397156]\n",
      "[Epoch 9/100] [Batch 104/347] [D loss: 0.529213] [G loss: 0.399050]\n",
      "[Epoch 9/100] [Batch 105/347] [D loss: 0.529190] [G loss: 0.400414]\n",
      "[Epoch 9/100] [Batch 106/347] [D loss: 0.529168] [G loss: 0.399201]\n",
      "[Epoch 9/100] [Batch 107/347] [D loss: 0.529146] [G loss: 0.392332]\n",
      "[Epoch 9/100] [Batch 108/347] [D loss: 0.529123] [G loss: 0.409078]\n",
      "[Epoch 9/100] [Batch 109/347] [D loss: 0.529102] [G loss: 0.401996]\n",
      "[Epoch 9/100] [Batch 110/347] [D loss: 0.529080] [G loss: 0.391960]\n",
      "[Epoch 9/100] [Batch 111/347] [D loss: 0.529058] [G loss: 0.396683]\n",
      "[Epoch 9/100] [Batch 112/347] [D loss: 0.529036] [G loss: 0.401885]\n",
      "[Epoch 9/100] [Batch 113/347] [D loss: 0.529015] [G loss: 0.407249]\n",
      "[Epoch 9/100] [Batch 114/347] [D loss: 0.528995] [G loss: 0.427840]\n",
      "[Epoch 9/100] [Batch 115/347] [D loss: 0.528973] [G loss: 0.428901]\n",
      "[Epoch 9/100] [Batch 116/347] [D loss: 0.528952] [G loss: 0.422949]\n",
      "[Epoch 9/100] [Batch 117/347] [D loss: 0.528931] [G loss: 0.396206]\n",
      "[Epoch 9/100] [Batch 118/347] [D loss: 0.528908] [G loss: 0.399733]\n",
      "[Epoch 9/100] [Batch 119/347] [D loss: 0.528887] [G loss: 0.402056]\n",
      "[Epoch 9/100] [Batch 120/347] [D loss: 0.528866] [G loss: 0.401141]\n",
      "[Epoch 9/100] [Batch 121/347] [D loss: 0.528844] [G loss: 0.399568]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 122/347] [D loss: 0.528823] [G loss: 0.386845]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 123/347] [D loss: 0.528801] [G loss: 0.385918]\n",
      "[Epoch 9/100] [Batch 124/347] [D loss: 0.528778] [G loss: 0.387270]\n",
      "[Epoch 9/100] [Batch 125/347] [D loss: 0.528756] [G loss: 0.393056]\n",
      "[Epoch 9/100] [Batch 126/347] [D loss: 0.528733] [G loss: 0.405729]\n",
      "[Epoch 9/100] [Batch 127/347] [D loss: 0.528711] [G loss: 0.407185]\n",
      "[Epoch 9/100] [Batch 128/347] [D loss: 0.528688] [G loss: 0.401695]\n",
      "[Epoch 9/100] [Batch 129/347] [D loss: 0.528665] [G loss: 0.397030]\n",
      "[Epoch 9/100] [Batch 130/347] [D loss: 0.528642] [G loss: 0.400458]\n",
      "[Epoch 9/100] [Batch 131/347] [D loss: 0.528619] [G loss: 0.398350]\n",
      "[Epoch 9/100] [Batch 132/347] [D loss: 0.528594] [G loss: 0.421181]\n",
      "[Epoch 9/100] [Batch 133/347] [D loss: 0.528572] [G loss: 0.428216]\n",
      "[Epoch 9/100] [Batch 134/347] [D loss: 0.528549] [G loss: 0.443412]\n",
      "[Epoch 9/100] [Batch 135/347] [D loss: 0.528527] [G loss: 0.452678]\n",
      "[Epoch 9/100] [Batch 136/347] [D loss: 0.528505] [G loss: 0.411080]\n",
      "[Epoch 9/100] [Batch 137/347] [D loss: 0.528485] [G loss: 0.398176]\n",
      "[Epoch 9/100] [Batch 138/347] [D loss: 0.528462] [G loss: 0.416408]\n",
      "[Epoch 9/100] [Batch 139/347] [D loss: 0.528439] [G loss: 0.440396]\n",
      "[Epoch 9/100] [Batch 140/347] [D loss: 0.528416] [G loss: 0.451898]\n",
      "[Epoch 9/100] [Batch 141/347] [D loss: 0.528394] [G loss: 0.458818]\n",
      "[Epoch 9/100] [Batch 142/347] [D loss: 0.528371] [G loss: 0.466749]\n",
      "[Epoch 9/100] [Batch 143/347] [D loss: 0.528349] [G loss: 0.488639]\n",
      "[Epoch 9/100] [Batch 144/347] [D loss: 0.528326] [G loss: 0.490928]\n",
      "[Epoch 9/100] [Batch 145/347] [D loss: 0.528303] [G loss: 0.476847]\n",
      "[Epoch 9/100] [Batch 146/347] [D loss: 0.528281] [G loss: 0.460122]\n",
      "[Epoch 9/100] [Batch 147/347] [D loss: 0.528258] [G loss: 0.432129]\n",
      "[Epoch 9/100] [Batch 148/347] [D loss: 0.528237] [G loss: 0.419759]\n",
      "[Epoch 9/100] [Batch 149/347] [D loss: 0.528214] [G loss: 0.432943]\n",
      "[Epoch 9/100] [Batch 150/347] [D loss: 0.528189] [G loss: 0.433247]\n",
      "[Epoch 9/100] [Batch 151/347] [D loss: 0.528167] [G loss: 0.422227]\n",
      "[Epoch 9/100] [Batch 152/347] [D loss: 0.528144] [G loss: 0.433248]\n",
      "[Epoch 9/100] [Batch 153/347] [D loss: 0.528120] [G loss: 0.453920]\n",
      "[Epoch 9/100] [Batch 154/347] [D loss: 0.528096] [G loss: 0.458010]\n",
      "[Epoch 9/100] [Batch 155/347] [D loss: 0.528074] [G loss: 0.445171]\n",
      "[Epoch 9/100] [Batch 156/347] [D loss: 0.528052] [G loss: 0.428678]\n",
      "[Epoch 9/100] [Batch 157/347] [D loss: 0.528030] [G loss: 0.434992]\n",
      "[Epoch 9/100] [Batch 158/347] [D loss: 0.528006] [G loss: 0.458673]\n",
      "[Epoch 9/100] [Batch 159/347] [D loss: 0.527982] [G loss: 0.456112]\n",
      "[Epoch 9/100] [Batch 160/347] [D loss: 0.527960] [G loss: 0.436073]\n",
      "[Epoch 9/100] [Batch 161/347] [D loss: 0.527938] [G loss: 0.427702]\n",
      "[Epoch 9/100] [Batch 162/347] [D loss: 0.527914] [G loss: 0.433410]\n",
      "[Epoch 9/100] [Batch 163/347] [D loss: 0.527891] [G loss: 0.452050]\n",
      "[Epoch 9/100] [Batch 164/347] [D loss: 0.527867] [G loss: 0.467175]\n",
      "[Epoch 9/100] [Batch 165/347] [D loss: 0.527843] [G loss: 0.458215]\n",
      "[Epoch 9/100] [Batch 166/347] [D loss: 0.527821] [G loss: 0.420016]\n",
      "[Epoch 9/100] [Batch 167/347] [D loss: 0.527800] [G loss: 0.401515]\n",
      "[Epoch 9/100] [Batch 168/347] [D loss: 0.527778] [G loss: 0.412214]\n",
      "[Epoch 9/100] [Batch 169/347] [D loss: 0.527755] [G loss: 0.410993]\n",
      "[Epoch 9/100] [Batch 170/347] [D loss: 0.527731] [G loss: 0.407169]\n",
      "[Epoch 9/100] [Batch 171/347] [D loss: 0.527710] [G loss: 0.417127]\n",
      "[Epoch 9/100] [Batch 172/347] [D loss: 0.527686] [G loss: 0.422002]\n",
      "[Epoch 9/100] [Batch 173/347] [D loss: 0.527663] [G loss: 0.410665]\n",
      "[Epoch 9/100] [Batch 174/347] [D loss: 0.527640] [G loss: 0.408066]\n",
      "[Epoch 9/100] [Batch 175/347] [D loss: 0.527618] [G loss: 0.417706]\n",
      "[Epoch 9/100] [Batch 176/347] [D loss: 0.527596] [G loss: 0.430891]\n",
      "[Epoch 9/100] [Batch 177/347] [D loss: 0.527574] [G loss: 0.431553]\n",
      "[Epoch 9/100] [Batch 178/347] [D loss: 0.527552] [G loss: 0.425382]\n",
      "[Epoch 9/100] [Batch 179/347] [D loss: 0.527529] [G loss: 0.418534]\n",
      "[Epoch 9/100] [Batch 180/347] [D loss: 0.527506] [G loss: 0.411893]\n",
      "[Epoch 9/100] [Batch 181/347] [D loss: 0.527484] [G loss: 0.412066]\n",
      "[Epoch 9/100] [Batch 182/347] [D loss: 0.527461] [G loss: 0.409640]\n",
      "[Epoch 9/100] [Batch 183/347] [D loss: 0.527439] [G loss: 0.413397]\n",
      "[Epoch 9/100] [Batch 184/347] [D loss: 0.527417] [G loss: 0.416941]\n",
      "[Epoch 9/100] [Batch 185/347] [D loss: 0.527394] [G loss: 0.415244]\n",
      "[Epoch 9/100] [Batch 186/347] [D loss: 0.527371] [G loss: 0.414774]\n",
      "[Epoch 9/100] [Batch 187/347] [D loss: 0.527348] [G loss: 0.409253]\n",
      "[Epoch 9/100] [Batch 188/347] [D loss: 0.527325] [G loss: 0.405797]\n",
      "[Epoch 9/100] [Batch 189/347] [D loss: 0.527302] [G loss: 0.404712]\n",
      "[Epoch 9/100] [Batch 190/347] [D loss: 0.527277] [G loss: 0.392554]\n",
      "[Epoch 9/100] [Batch 191/347] [D loss: 0.527252] [G loss: 0.391578]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 192/347] [D loss: 0.527229] [G loss: 0.382302]\n",
      "[Epoch 9/100] [Batch 193/347] [D loss: 0.527207] [G loss: 0.389927]\n",
      "[Epoch 9/100] [Batch 194/347] [D loss: 0.527182] [G loss: 0.386286]\n",
      "[Epoch 9/100] [Batch 195/347] [D loss: 0.527157] [G loss: 0.394980]\n",
      "[Epoch 9/100] [Batch 196/347] [D loss: 0.527131] [G loss: 0.392626]\n",
      "[Epoch 9/100] [Batch 197/347] [D loss: 0.527106] [G loss: 0.387801]\n",
      "[Epoch 9/100] [Batch 198/347] [D loss: 0.527083] [G loss: 0.386469]\n",
      "[Epoch 9/100] [Batch 199/347] [D loss: 0.527057] [G loss: 0.387618]\n",
      "[Epoch 9/100] [Batch 200/347] [D loss: 0.527032] [G loss: 0.382465]\n",
      "[Epoch 9/100] [Batch 201/347] [D loss: 0.527008] [G loss: 0.383029]\n",
      "[Epoch 9/100] [Batch 202/347] [D loss: 0.526984] [G loss: 0.394444]\n",
      "[Epoch 9/100] [Batch 203/347] [D loss: 0.526960] [G loss: 0.402908]\n",
      "[Epoch 9/100] [Batch 204/347] [D loss: 0.526938] [G loss: 0.399257]\n",
      "[Epoch 9/100] [Batch 205/347] [D loss: 0.526917] [G loss: 0.391188]\n",
      "[Epoch 9/100] [Batch 206/347] [D loss: 0.526894] [G loss: 0.382334]\n",
      "[Epoch 9/100] [Batch 207/347] [D loss: 0.526874] [G loss: 0.393173]\n",
      "[Epoch 9/100] [Batch 208/347] [D loss: 0.526852] [G loss: 0.394019]\n",
      "[Epoch 9/100] [Batch 209/347] [D loss: 0.526828] [G loss: 0.388463]\n",
      "[Epoch 9/100] [Batch 210/347] [D loss: 0.526806] [G loss: 0.395673]\n",
      "[Epoch 9/100] [Batch 211/347] [D loss: 0.526783] [G loss: 0.392815]\n",
      "[Epoch 9/100] [Batch 212/347] [D loss: 0.526760] [G loss: 0.391561]\n",
      "[Epoch 9/100] [Batch 213/347] [D loss: 0.526736] [G loss: 0.396972]\n",
      "[Epoch 9/100] [Batch 214/347] [D loss: 0.526712] [G loss: 0.404094]\n",
      "[Epoch 9/100] [Batch 215/347] [D loss: 0.526687] [G loss: 0.412355]\n",
      "[Epoch 9/100] [Batch 216/347] [D loss: 0.526664] [G loss: 0.395626]\n",
      "[Epoch 9/100] [Batch 217/347] [D loss: 0.526640] [G loss: 0.396106]\n",
      "[Epoch 9/100] [Batch 218/347] [D loss: 0.526617] [G loss: 0.402751]\n",
      "[Epoch 9/100] [Batch 219/347] [D loss: 0.526593] [G loss: 0.414790]\n",
      "[Epoch 9/100] [Batch 220/347] [D loss: 0.526569] [G loss: 0.430527]\n",
      "[Epoch 9/100] [Batch 221/347] [D loss: 0.526545] [G loss: 0.431822]\n",
      "[Epoch 9/100] [Batch 222/347] [D loss: 0.526520] [G loss: 0.423653]\n",
      "[Epoch 9/100] [Batch 223/347] [D loss: 0.526495] [G loss: 0.422136]\n",
      "[Epoch 9/100] [Batch 224/347] [D loss: 0.526470] [G loss: 0.417791]\n",
      "[Epoch 9/100] [Batch 225/347] [D loss: 0.526445] [G loss: 0.403427]\n",
      "[Epoch 9/100] [Batch 226/347] [D loss: 0.526418] [G loss: 0.399538]\n",
      "[Epoch 9/100] [Batch 227/347] [D loss: 0.526392] [G loss: 0.410039]\n",
      "[Epoch 9/100] [Batch 228/347] [D loss: 0.526368] [G loss: 0.412519]\n",
      "[Epoch 9/100] [Batch 229/347] [D loss: 0.526342] [G loss: 0.407915]\n",
      "[Epoch 9/100] [Batch 230/347] [D loss: 0.526318] [G loss: 0.404321]\n",
      "[Epoch 9/100] [Batch 231/347] [D loss: 0.526292] [G loss: 0.404404]\n",
      "[Epoch 9/100] [Batch 232/347] [D loss: 0.526268] [G loss: 0.400303]\n",
      "[Epoch 9/100] [Batch 233/347] [D loss: 0.526243] [G loss: 0.397494]\n",
      "[Epoch 9/100] [Batch 234/347] [D loss: 0.526218] [G loss: 0.402401]\n",
      "[Epoch 9/100] [Batch 235/347] [D loss: 0.526194] [G loss: 0.391161]\n",
      "[Epoch 9/100] [Batch 236/347] [D loss: 0.526170] [G loss: 0.388633]\n",
      "[Epoch 9/100] [Batch 237/347] [D loss: 0.526148] [G loss: 0.392550]\n",
      "[Epoch 9/100] [Batch 238/347] [D loss: 0.526124] [G loss: 0.396545]\n",
      "[Epoch 9/100] [Batch 239/347] [D loss: 0.526101] [G loss: 0.394559]\n",
      "[Epoch 9/100] [Batch 240/347] [D loss: 0.526080] [G loss: 0.390686]\n",
      "[Epoch 9/100] [Batch 241/347] [D loss: 0.526058] [G loss: 0.384709]\n",
      "[Epoch 9/100] [Batch 242/347] [D loss: 0.526034] [G loss: 0.382547]\n",
      "[Epoch 9/100] [Batch 243/347] [D loss: 0.526011] [G loss: 0.389919]\n",
      "[Epoch 9/100] [Batch 244/347] [D loss: 0.525987] [G loss: 0.398514]\n",
      "[Epoch 9/100] [Batch 245/347] [D loss: 0.525964] [G loss: 0.396824]\n",
      "[Epoch 9/100] [Batch 246/347] [D loss: 0.525937] [G loss: 0.389253]\n",
      "[Epoch 9/100] [Batch 247/347] [D loss: 0.525911] [G loss: 0.397651]\n",
      "[Epoch 9/100] [Batch 248/347] [D loss: 0.525883] [G loss: 0.403653]\n",
      "[Epoch 9/100] [Batch 249/347] [D loss: 0.525857] [G loss: 0.409233]\n",
      "[Epoch 9/100] [Batch 250/347] [D loss: 0.525832] [G loss: 0.400743]\n",
      "[Epoch 9/100] [Batch 251/347] [D loss: 0.525806] [G loss: 0.388462]\n",
      "[Epoch 9/100] [Batch 252/347] [D loss: 0.525781] [G loss: 0.391595]\n",
      "[Epoch 9/100] [Batch 253/347] [D loss: 0.525754] [G loss: 0.392140]\n",
      "[Epoch 9/100] [Batch 254/347] [D loss: 0.525726] [G loss: 0.390460]\n",
      "[Epoch 9/100] [Batch 255/347] [D loss: 0.525700] [G loss: 0.388967]\n",
      "[Epoch 9/100] [Batch 256/347] [D loss: 0.525672] [G loss: 0.394015]\n",
      "[Epoch 9/100] [Batch 257/347] [D loss: 0.525646] [G loss: 0.395992]\n",
      "[Epoch 9/100] [Batch 258/347] [D loss: 0.525619] [G loss: 0.390168]\n",
      "[Epoch 9/100] [Batch 259/347] [D loss: 0.525590] [G loss: 0.399540]\n",
      "[Epoch 9/100] [Batch 260/347] [D loss: 0.525563] [G loss: 0.413952]\n",
      "[Epoch 9/100] [Batch 261/347] [D loss: 0.525538] [G loss: 0.406464]\n",
      "[Epoch 9/100] [Batch 262/347] [D loss: 0.525512] [G loss: 0.391368]\n",
      "[Epoch 9/100] [Batch 263/347] [D loss: 0.525487] [G loss: 0.392324]\n",
      "[Epoch 9/100] [Batch 264/347] [D loss: 0.525461] [G loss: 0.406759]\n",
      "[Epoch 9/100] [Batch 265/347] [D loss: 0.525436] [G loss: 0.411859]\n",
      "[Epoch 9/100] [Batch 266/347] [D loss: 0.525411] [G loss: 0.404604]\n",
      "[Epoch 9/100] [Batch 267/347] [D loss: 0.525387] [G loss: 0.397728]\n",
      "[Epoch 9/100] [Batch 268/347] [D loss: 0.525363] [G loss: 0.404564]\n",
      "[Epoch 9/100] [Batch 269/347] [D loss: 0.525337] [G loss: 0.415598]\n",
      "[Epoch 9/100] [Batch 270/347] [D loss: 0.525312] [G loss: 0.412025]\n",
      "[Epoch 9/100] [Batch 271/347] [D loss: 0.525288] [G loss: 0.400053]\n",
      "[Epoch 9/100] [Batch 272/347] [D loss: 0.525263] [G loss: 0.391320]\n",
      "[Epoch 9/100] [Batch 273/347] [D loss: 0.525238] [G loss: 0.403009]\n",
      "[Epoch 9/100] [Batch 274/347] [D loss: 0.525211] [G loss: 0.436675]\n",
      "[Epoch 9/100] [Batch 275/347] [D loss: 0.525186] [G loss: 0.433374]\n",
      "[Epoch 9/100] [Batch 276/347] [D loss: 0.525160] [G loss: 0.400873]\n",
      "[Epoch 9/100] [Batch 277/347] [D loss: 0.525136] [G loss: 0.386084]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 278/347] [D loss: 0.525110] [G loss: 0.376139]\n",
      "[Epoch 9/100] [Batch 279/347] [D loss: 0.525086] [G loss: 0.382771]\n",
      "[Epoch 9/100] [Batch 280/347] [D loss: 0.525061] [G loss: 0.386337]\n",
      "[Epoch 9/100] [Batch 281/347] [D loss: 0.525038] [G loss: 0.384576]\n",
      "[Epoch 9/100] [Batch 282/347] [D loss: 0.525016] [G loss: 0.382401]\n",
      "[Epoch 9/100] [Batch 283/347] [D loss: 0.524994] [G loss: 0.386340]\n",
      "[Epoch 9/100] [Batch 284/347] [D loss: 0.524973] [G loss: 0.384970]\n",
      "[Epoch 9/100] [Batch 285/347] [D loss: 0.524952] [G loss: 0.380794]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 286/347] [D loss: 0.524927] [G loss: 0.376070]\n",
      "[Epoch 9/100] [Batch 287/347] [D loss: 0.524904] [G loss: 0.379548]\n",
      "[Epoch 9/100] [Batch 288/347] [D loss: 0.524876] [G loss: 0.405936]\n",
      "[Epoch 9/100] [Batch 289/347] [D loss: 0.524849] [G loss: 0.409991]\n",
      "[Epoch 9/100] [Batch 290/347] [D loss: 0.524823] [G loss: 0.387235]\n",
      "[Epoch 9/100] [Batch 291/347] [D loss: 0.524794] [G loss: 0.389622]\n",
      "[Epoch 9/100] [Batch 292/347] [D loss: 0.524766] [G loss: 0.380711]\n",
      "[Epoch 9/100] [Batch 293/347] [D loss: 0.524738] [G loss: 0.392342]\n",
      "[Epoch 9/100] [Batch 294/347] [D loss: 0.524711] [G loss: 0.402352]\n",
      "[Epoch 9/100] [Batch 295/347] [D loss: 0.524681] [G loss: 0.400131]\n",
      "[Epoch 9/100] [Batch 296/347] [D loss: 0.524651] [G loss: 0.396211]\n",
      "[Epoch 9/100] [Batch 297/347] [D loss: 0.524623] [G loss: 0.407892]\n",
      "[Epoch 9/100] [Batch 298/347] [D loss: 0.524593] [G loss: 0.402780]\n",
      "[Epoch 9/100] [Batch 299/347] [D loss: 0.524565] [G loss: 0.401372]\n",
      "[Epoch 9/100] [Batch 300/347] [D loss: 0.524535] [G loss: 0.396557]\n",
      "[Epoch 9/100] [Batch 301/347] [D loss: 0.524509] [G loss: 0.397646]\n",
      "[Epoch 9/100] [Batch 302/347] [D loss: 0.524482] [G loss: 0.402576]\n",
      "[Epoch 9/100] [Batch 303/347] [D loss: 0.524456] [G loss: 0.386755]\n",
      "[Epoch 9/100] [Batch 304/347] [D loss: 0.524428] [G loss: 0.386980]\n",
      "[Epoch 9/100] [Batch 305/347] [D loss: 0.524402] [G loss: 0.399800]\n",
      "[Epoch 9/100] [Batch 306/347] [D loss: 0.524375] [G loss: 0.391459]\n",
      "[Epoch 9/100] [Batch 307/347] [D loss: 0.524347] [G loss: 0.404103]\n",
      "[Epoch 9/100] [Batch 308/347] [D loss: 0.524318] [G loss: 0.400316]\n",
      "[Epoch 9/100] [Batch 309/347] [D loss: 0.524291] [G loss: 0.380312]\n",
      "[Epoch 9/100] [Batch 310/347] [D loss: 0.524265] [G loss: 0.398198]\n",
      "[Epoch 9/100] [Batch 311/347] [D loss: 0.524235] [G loss: 0.401105]\n",
      "[Epoch 9/100] [Batch 312/347] [D loss: 0.524204] [G loss: 0.400847]\n",
      "[Epoch 9/100] [Batch 313/347] [D loss: 0.524175] [G loss: 0.400042]\n",
      "[Epoch 9/100] [Batch 314/347] [D loss: 0.524143] [G loss: 0.393646]\n",
      "[Epoch 9/100] [Batch 315/347] [D loss: 0.524115] [G loss: 0.384211]\n",
      "[Epoch 9/100] [Batch 316/347] [D loss: 0.524082] [G loss: 0.379604]\n",
      "[Epoch 9/100] [Batch 317/347] [D loss: 0.524049] [G loss: 0.398104]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 318/347] [D loss: 0.524021] [G loss: 0.375938]\n",
      "[Epoch 9/100] [Batch 319/347] [D loss: 0.523993] [G loss: 0.405716]\n",
      "[Epoch 9/100] [Batch 320/347] [D loss: 0.523965] [G loss: 0.419279]\n",
      "[Epoch 9/100] [Batch 321/347] [D loss: 0.523935] [G loss: 0.408748]\n",
      "[Epoch 9/100] [Batch 322/347] [D loss: 0.523904] [G loss: 0.395727]\n",
      "[Epoch 9/100] [Batch 323/347] [D loss: 0.523876] [G loss: 0.394906]\n",
      "[Epoch 9/100] [Batch 324/347] [D loss: 0.523847] [G loss: 0.397725]\n",
      "[Epoch 9/100] [Batch 325/347] [D loss: 0.523817] [G loss: 0.386703]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 326/347] [D loss: 0.523785] [G loss: 0.375817]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 327/347] [D loss: 0.523757] [G loss: 0.373638]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 328/347] [D loss: 0.523726] [G loss: 0.371446]\n",
      "[Epoch 9/100] [Batch 329/347] [D loss: 0.523696] [G loss: 0.394040]\n",
      "[Epoch 9/100] [Batch 330/347] [D loss: 0.523664] [G loss: 0.409859]\n",
      "[Epoch 9/100] [Batch 331/347] [D loss: 0.523635] [G loss: 0.391924]\n",
      "[Epoch 9/100] [Batch 332/347] [D loss: 0.523609] [G loss: 0.383983]\n",
      "[Epoch 9/100] [Batch 333/347] [D loss: 0.523580] [G loss: 0.395133]\n",
      "[Epoch 9/100] [Batch 334/347] [D loss: 0.523552] [G loss: 0.396388]\n",
      "[Epoch 9/100] [Batch 335/347] [D loss: 0.523523] [G loss: 0.384295]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 9/100] [Batch 336/347] [D loss: 0.523495] [G loss: 0.370411]\n",
      "[Epoch 9/100] [Batch 337/347] [D loss: 0.523467] [G loss: 0.376017]\n",
      "[Epoch 9/100] [Batch 338/347] [D loss: 0.523443] [G loss: 0.390655]\n",
      "[Epoch 9/100] [Batch 339/347] [D loss: 0.523419] [G loss: 0.396015]\n",
      "[Epoch 9/100] [Batch 340/347] [D loss: 0.523390] [G loss: 0.396317]\n",
      "[Epoch 9/100] [Batch 341/347] [D loss: 0.523366] [G loss: 0.391528]\n",
      "[Epoch 9/100] [Batch 342/347] [D loss: 0.523338] [G loss: 0.383880]\n",
      "[Epoch 9/100] [Batch 343/347] [D loss: 0.523313] [G loss: 0.388535]\n",
      "[Epoch 9/100] [Batch 344/347] [D loss: 0.523284] [G loss: 0.383899]\n",
      "[Epoch 9/100] [Batch 345/347] [D loss: 0.523253] [G loss: 0.394204]\n",
      "[Epoch 9/100] [Batch 346/347] [D loss: 0.523222] [G loss: 0.412596]\n",
      "[Epoch 9/100] [Batch 347/347] [D loss: 0.523190] [G loss: 0.418874]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 1/347] [D loss: 0.523164] [G loss: 0.384605]\n",
      "[Epoch 10/100] [Batch 2/347] [D loss: 0.523135] [G loss: 0.389691]\n",
      "[Epoch 10/100] [Batch 3/347] [D loss: 0.523105] [G loss: 0.389476]\n",
      "[Epoch 10/100] [Batch 4/347] [D loss: 0.523076] [G loss: 0.390556]\n",
      "[Epoch 10/100] [Batch 5/347] [D loss: 0.523046] [G loss: 0.389579]\n",
      "[Epoch 10/100] [Batch 6/347] [D loss: 0.523018] [G loss: 0.389712]\n",
      "[Epoch 10/100] [Batch 7/347] [D loss: 0.522988] [G loss: 0.389352]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 8/347] [D loss: 0.522956] [G loss: 0.384499]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 9/347] [D loss: 0.522923] [G loss: 0.383277]\n",
      "[Epoch 10/100] [Batch 10/347] [D loss: 0.522889] [G loss: 0.384612]\n",
      "[Epoch 10/100] [Batch 11/347] [D loss: 0.522854] [G loss: 0.384219]\n",
      "[Epoch 10/100] [Batch 12/347] [D loss: 0.522818] [G loss: 0.384511]\n",
      "[Epoch 10/100] [Batch 13/347] [D loss: 0.522782] [G loss: 0.385425]\n",
      "[Epoch 10/100] [Batch 14/347] [D loss: 0.522745] [G loss: 0.387700]\n",
      "[Epoch 10/100] [Batch 15/347] [D loss: 0.522708] [G loss: 0.383871]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 16/347] [D loss: 0.522668] [G loss: 0.379775]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 17/347] [D loss: 0.522632] [G loss: 0.367915]\n",
      "[Epoch 10/100] [Batch 18/347] [D loss: 0.522593] [G loss: 0.374411]\n",
      "[Epoch 10/100] [Batch 19/347] [D loss: 0.522556] [G loss: 0.373334]\n",
      "[Epoch 10/100] [Batch 20/347] [D loss: 0.522520] [G loss: 0.386456]\n",
      "[Epoch 10/100] [Batch 21/347] [D loss: 0.522482] [G loss: 0.382837]\n",
      "[Epoch 10/100] [Batch 22/347] [D loss: 0.522447] [G loss: 0.377897]\n",
      "[Epoch 10/100] [Batch 23/347] [D loss: 0.522413] [G loss: 0.371582]\n",
      "[Epoch 10/100] [Batch 24/347] [D loss: 0.522380] [G loss: 0.370818]\n",
      "[Epoch 10/100] [Batch 25/347] [D loss: 0.522350] [G loss: 0.370113]\n",
      "[Epoch 10/100] [Batch 26/347] [D loss: 0.522321] [G loss: 0.377927]\n",
      "[Epoch 10/100] [Batch 27/347] [D loss: 0.522293] [G loss: 0.383626]\n",
      "[Epoch 10/100] [Batch 28/347] [D loss: 0.522271] [G loss: 0.384479]\n",
      "[Epoch 10/100] [Batch 29/347] [D loss: 0.522245] [G loss: 0.380538]\n",
      "[Epoch 10/100] [Batch 30/347] [D loss: 0.522219] [G loss: 0.387342]\n",
      "[Epoch 10/100] [Batch 31/347] [D loss: 0.522194] [G loss: 0.389831]\n",
      "[Epoch 10/100] [Batch 32/347] [D loss: 0.522164] [G loss: 0.384366]\n",
      "[Epoch 10/100] [Batch 33/347] [D loss: 0.522133] [G loss: 0.379068]\n",
      "[Epoch 10/100] [Batch 34/347] [D loss: 0.522102] [G loss: 0.379984]\n",
      "[Epoch 10/100] [Batch 35/347] [D loss: 0.522070] [G loss: 0.378583]\n",
      "[Epoch 10/100] [Batch 36/347] [D loss: 0.522036] [G loss: 0.369708]\n",
      "[Epoch 10/100] [Batch 37/347] [D loss: 0.522000] [G loss: 0.388460]\n",
      "[Epoch 10/100] [Batch 38/347] [D loss: 0.521962] [G loss: 0.403674]\n",
      "[Epoch 10/100] [Batch 39/347] [D loss: 0.521927] [G loss: 0.394155]\n",
      "[Epoch 10/100] [Batch 40/347] [D loss: 0.521892] [G loss: 0.394006]\n",
      "[Epoch 10/100] [Batch 41/347] [D loss: 0.521855] [G loss: 0.395434]\n",
      "[Epoch 10/100] [Batch 42/347] [D loss: 0.521817] [G loss: 0.388506]\n",
      "[Epoch 10/100] [Batch 43/347] [D loss: 0.521783] [G loss: 0.372848]\n",
      "[Epoch 10/100] [Batch 44/347] [D loss: 0.521747] [G loss: 0.376020]\n",
      "[Epoch 10/100] [Batch 45/347] [D loss: 0.521710] [G loss: 0.393342]\n",
      "[Epoch 10/100] [Batch 46/347] [D loss: 0.521672] [G loss: 0.388044]\n",
      "[Epoch 10/100] [Batch 47/347] [D loss: 0.521627] [G loss: 0.370077]\n",
      "[Epoch 10/100] [Batch 48/347] [D loss: 0.521586] [G loss: 0.402206]\n",
      "[Epoch 10/100] [Batch 49/347] [D loss: 0.521543] [G loss: 0.410685]\n",
      "[Epoch 10/100] [Batch 50/347] [D loss: 0.521502] [G loss: 0.426343]\n",
      "[Epoch 10/100] [Batch 51/347] [D loss: 0.521464] [G loss: 0.410980]\n",
      "[Epoch 10/100] [Batch 52/347] [D loss: 0.521426] [G loss: 0.374765]\n",
      "[Epoch 10/100] [Batch 53/347] [D loss: 0.521388] [G loss: 0.373577]\n",
      "[Epoch 10/100] [Batch 54/347] [D loss: 0.521343] [G loss: 0.425963]\n",
      "[Epoch 10/100] [Batch 55/347] [D loss: 0.521296] [G loss: 0.448220]\n",
      "[Epoch 10/100] [Batch 56/347] [D loss: 0.521255] [G loss: 0.435138]\n",
      "[Epoch 10/100] [Batch 57/347] [D loss: 0.521224] [G loss: 0.400806]\n",
      "[Epoch 10/100] [Batch 58/347] [D loss: 0.521191] [G loss: 0.372902]\n",
      "[Epoch 10/100] [Batch 59/347] [D loss: 0.521155] [G loss: 0.383574]\n",
      "[Epoch 10/100] [Batch 60/347] [D loss: 0.521113] [G loss: 0.402088]\n",
      "[Epoch 10/100] [Batch 61/347] [D loss: 0.521078] [G loss: 0.414374]\n",
      "[Epoch 10/100] [Batch 62/347] [D loss: 0.521037] [G loss: 0.438183]\n",
      "[Epoch 10/100] [Batch 63/347] [D loss: 0.520994] [G loss: 0.440184]\n",
      "[Epoch 10/100] [Batch 64/347] [D loss: 0.520963] [G loss: 0.403367]\n",
      "[Epoch 10/100] [Batch 65/347] [D loss: 0.520936] [G loss: 0.376778]\n",
      "[Epoch 10/100] [Batch 66/347] [D loss: 0.520899] [G loss: 0.379104]\n",
      "[Epoch 10/100] [Batch 67/347] [D loss: 0.520855] [G loss: 0.386760]\n",
      "[Epoch 10/100] [Batch 68/347] [D loss: 0.520818] [G loss: 0.404560]\n",
      "[Epoch 10/100] [Batch 69/347] [D loss: 0.520775] [G loss: 0.423182]\n",
      "[Epoch 10/100] [Batch 70/347] [D loss: 0.520735] [G loss: 0.421868]\n",
      "[Epoch 10/100] [Batch 71/347] [D loss: 0.520699] [G loss: 0.424389]\n",
      "[Epoch 10/100] [Batch 72/347] [D loss: 0.520658] [G loss: 0.426880]\n",
      "[Epoch 10/100] [Batch 73/347] [D loss: 0.520624] [G loss: 0.402076]\n",
      "[Epoch 10/100] [Batch 74/347] [D loss: 0.520591] [G loss: 0.388040]\n",
      "[Epoch 10/100] [Batch 75/347] [D loss: 0.520549] [G loss: 0.417598]\n",
      "[Epoch 10/100] [Batch 76/347] [D loss: 0.520508] [G loss: 0.419331]\n",
      "[Epoch 10/100] [Batch 77/347] [D loss: 0.520479] [G loss: 0.384914]\n",
      "[Epoch 10/100] [Batch 78/347] [D loss: 0.520450] [G loss: 0.382689]\n",
      "[Epoch 10/100] [Batch 79/347] [D loss: 0.520416] [G loss: 0.384293]\n",
      "[Epoch 10/100] [Batch 80/347] [D loss: 0.520379] [G loss: 0.381504]\n",
      "[Epoch 10/100] [Batch 81/347] [D loss: 0.520345] [G loss: 0.386527]\n",
      "[Epoch 10/100] [Batch 82/347] [D loss: 0.520310] [G loss: 0.391588]\n",
      "[Epoch 10/100] [Batch 83/347] [D loss: 0.520272] [G loss: 0.383831]\n",
      "[Epoch 10/100] [Batch 84/347] [D loss: 0.520237] [G loss: 0.390097]\n",
      "[Epoch 10/100] [Batch 85/347] [D loss: 0.520198] [G loss: 0.390692]\n",
      "[Epoch 10/100] [Batch 86/347] [D loss: 0.520159] [G loss: 0.384927]\n",
      "[Epoch 10/100] [Batch 87/347] [D loss: 0.520121] [G loss: 0.382532]\n",
      "[Epoch 10/100] [Batch 88/347] [D loss: 0.520080] [G loss: 0.385652]\n",
      "[Epoch 10/100] [Batch 89/347] [D loss: 0.520039] [G loss: 0.388747]\n",
      "[Epoch 10/100] [Batch 90/347] [D loss: 0.519994] [G loss: 0.384652]\n",
      "[Epoch 10/100] [Batch 91/347] [D loss: 0.519948] [G loss: 0.382920]\n",
      "[Epoch 10/100] [Batch 92/347] [D loss: 0.519899] [G loss: 0.384116]\n",
      "[Epoch 10/100] [Batch 93/347] [D loss: 0.519849] [G loss: 0.381884]\n",
      "[Epoch 10/100] [Batch 94/347] [D loss: 0.519797] [G loss: 0.377992]\n",
      "[Epoch 10/100] [Batch 95/347] [D loss: 0.519749] [G loss: 0.378207]\n",
      "[Epoch 10/100] [Batch 96/347] [D loss: 0.519702] [G loss: 0.373265]\n",
      "[Epoch 10/100] [Batch 97/347] [D loss: 0.519656] [G loss: 0.367969]\n",
      "[Epoch 10/100] [Batch 98/347] [D loss: 0.519617] [G loss: 0.372575]\n",
      "[Epoch 10/100] [Batch 99/347] [D loss: 0.519585] [G loss: 0.376076]\n",
      "[Epoch 10/100] [Batch 100/347] [D loss: 0.519548] [G loss: 0.372259]\n",
      "[Epoch 10/100] [Batch 101/347] [D loss: 0.519509] [G loss: 0.369178]\n",
      "[Epoch 10/100] [Batch 102/347] [D loss: 0.519468] [G loss: 0.369951]\n",
      "[Epoch 10/100] [Batch 103/347] [D loss: 0.519422] [G loss: 0.369360]\n",
      "[Epoch 10/100] [Batch 104/347] [D loss: 0.519375] [G loss: 0.371442]\n",
      "[Epoch 10/100] [Batch 105/347] [D loss: 0.519326] [G loss: 0.373116]\n",
      "[Epoch 10/100] [Batch 106/347] [D loss: 0.519281] [G loss: 0.372137]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 107/347] [D loss: 0.519230] [G loss: 0.365415]\n",
      "[Epoch 10/100] [Batch 108/347] [D loss: 0.519180] [G loss: 0.382299]\n",
      "[Epoch 10/100] [Batch 109/347] [D loss: 0.519135] [G loss: 0.375340]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 110/347] [D loss: 0.519089] [G loss: 0.362542]\n",
      "[Epoch 10/100] [Batch 111/347] [D loss: 0.519041] [G loss: 0.369223]\n",
      "[Epoch 10/100] [Batch 112/347] [D loss: 0.518993] [G loss: 0.372078]\n",
      "[Epoch 10/100] [Batch 113/347] [D loss: 0.518949] [G loss: 0.377726]\n",
      "[Epoch 10/100] [Batch 114/347] [D loss: 0.518907] [G loss: 0.398364]\n",
      "[Epoch 10/100] [Batch 115/347] [D loss: 0.518859] [G loss: 0.399489]\n",
      "[Epoch 10/100] [Batch 116/347] [D loss: 0.518812] [G loss: 0.393603]\n",
      "[Epoch 10/100] [Batch 117/347] [D loss: 0.518761] [G loss: 0.366869]\n",
      "[Epoch 10/100] [Batch 118/347] [D loss: 0.518706] [G loss: 0.371559]\n",
      "[Epoch 10/100] [Batch 119/347] [D loss: 0.518654] [G loss: 0.373663]\n",
      "[Epoch 10/100] [Batch 120/347] [D loss: 0.518607] [G loss: 0.372570]\n",
      "[Epoch 10/100] [Batch 121/347] [D loss: 0.518558] [G loss: 0.370823]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 122/347] [D loss: 0.518512] [G loss: 0.357927]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 123/347] [D loss: 0.518472] [G loss: 0.356814]\n",
      "[Epoch 10/100] [Batch 124/347] [D loss: 0.518428] [G loss: 0.358061]\n",
      "[Epoch 10/100] [Batch 125/347] [D loss: 0.518386] [G loss: 0.363680]\n",
      "[Epoch 10/100] [Batch 126/347] [D loss: 0.518345] [G loss: 0.376308]\n",
      "[Epoch 10/100] [Batch 127/347] [D loss: 0.518308] [G loss: 0.377723]\n",
      "[Epoch 10/100] [Batch 128/347] [D loss: 0.518259] [G loss: 0.372187]\n",
      "[Epoch 10/100] [Batch 129/347] [D loss: 0.518215] [G loss: 0.367521]\n",
      "[Epoch 10/100] [Batch 130/347] [D loss: 0.518178] [G loss: 0.370905]\n",
      "[Epoch 10/100] [Batch 131/347] [D loss: 0.518127] [G loss: 0.368800]\n",
      "[Epoch 10/100] [Batch 132/347] [D loss: 0.518082] [G loss: 0.391110]\n",
      "[Epoch 10/100] [Batch 133/347] [D loss: 0.518036] [G loss: 0.398052]\n",
      "[Epoch 10/100] [Batch 134/347] [D loss: 0.517989] [G loss: 0.413148]\n",
      "[Epoch 10/100] [Batch 135/347] [D loss: 0.517946] [G loss: 0.422300]\n",
      "[Epoch 10/100] [Batch 136/347] [D loss: 0.517910] [G loss: 0.380574]\n",
      "[Epoch 10/100] [Batch 137/347] [D loss: 0.517872] [G loss: 0.368373]\n",
      "[Epoch 10/100] [Batch 138/347] [D loss: 0.517819] [G loss: 0.385687]\n",
      "[Epoch 10/100] [Batch 139/347] [D loss: 0.517763] [G loss: 0.409576]\n",
      "[Epoch 10/100] [Batch 140/347] [D loss: 0.517713] [G loss: 0.420990]\n",
      "[Epoch 10/100] [Batch 141/347] [D loss: 0.517657] [G loss: 0.427801]\n",
      "[Epoch 10/100] [Batch 142/347] [D loss: 0.517602] [G loss: 0.435527]\n",
      "[Epoch 10/100] [Batch 143/347] [D loss: 0.517539] [G loss: 0.457303]\n",
      "[Epoch 10/100] [Batch 144/347] [D loss: 0.517479] [G loss: 0.459490]\n",
      "[Epoch 10/100] [Batch 145/347] [D loss: 0.517420] [G loss: 0.445204]\n",
      "[Epoch 10/100] [Batch 146/347] [D loss: 0.517363] [G loss: 0.428363]\n",
      "[Epoch 10/100] [Batch 147/347] [D loss: 0.517311] [G loss: 0.400255]\n",
      "[Epoch 10/100] [Batch 148/347] [D loss: 0.517258] [G loss: 0.387824]\n",
      "[Epoch 10/100] [Batch 149/347] [D loss: 0.517197] [G loss: 0.400854]\n",
      "[Epoch 10/100] [Batch 150/347] [D loss: 0.517138] [G loss: 0.401124]\n",
      "[Epoch 10/100] [Batch 151/347] [D loss: 0.517088] [G loss: 0.390065]\n",
      "[Epoch 10/100] [Batch 152/347] [D loss: 0.517033] [G loss: 0.400986]\n",
      "[Epoch 10/100] [Batch 153/347] [D loss: 0.516976] [G loss: 0.421564]\n",
      "[Epoch 10/100] [Batch 154/347] [D loss: 0.516920] [G loss: 0.425574]\n",
      "[Epoch 10/100] [Batch 155/347] [D loss: 0.516871] [G loss: 0.412662]\n",
      "[Epoch 10/100] [Batch 156/347] [D loss: 0.516824] [G loss: 0.396071]\n",
      "[Epoch 10/100] [Batch 157/347] [D loss: 0.516774] [G loss: 0.402250]\n",
      "[Epoch 10/100] [Batch 158/347] [D loss: 0.516713] [G loss: 0.425841]\n",
      "[Epoch 10/100] [Batch 159/347] [D loss: 0.516652] [G loss: 0.423216]\n",
      "[Epoch 10/100] [Batch 160/347] [D loss: 0.516610] [G loss: 0.403138]\n",
      "[Epoch 10/100] [Batch 161/347] [D loss: 0.516559] [G loss: 0.394610]\n",
      "[Epoch 10/100] [Batch 162/347] [D loss: 0.516500] [G loss: 0.400256]\n",
      "[Epoch 10/100] [Batch 163/347] [D loss: 0.516440] [G loss: 0.418788]\n",
      "[Epoch 10/100] [Batch 164/347] [D loss: 0.516376] [G loss: 0.433855]\n",
      "[Epoch 10/100] [Batch 165/347] [D loss: 0.516318] [G loss: 0.424789]\n",
      "[Epoch 10/100] [Batch 166/347] [D loss: 0.516273] [G loss: 0.386487]\n",
      "[Epoch 10/100] [Batch 167/347] [D loss: 0.516238] [G loss: 0.367799]\n",
      "[Epoch 10/100] [Batch 168/347] [D loss: 0.516189] [G loss: 0.378352]\n",
      "[Epoch 10/100] [Batch 169/347] [D loss: 0.516138] [G loss: 0.377010]\n",
      "[Epoch 10/100] [Batch 170/347] [D loss: 0.516090] [G loss: 0.373028]\n",
      "[Epoch 10/100] [Batch 171/347] [D loss: 0.516039] [G loss: 0.382477]\n",
      "[Epoch 10/100] [Batch 172/347] [D loss: 0.515984] [G loss: 0.387200]\n",
      "[Epoch 10/100] [Batch 173/347] [D loss: 0.515922] [G loss: 0.375713]\n",
      "[Epoch 10/100] [Batch 174/347] [D loss: 0.515860] [G loss: 0.372951]\n",
      "[Epoch 10/100] [Batch 175/347] [D loss: 0.515801] [G loss: 0.382459]\n",
      "[Epoch 10/100] [Batch 176/347] [D loss: 0.515746] [G loss: 0.395539]\n",
      "[Epoch 10/100] [Batch 177/347] [D loss: 0.515688] [G loss: 0.396077]\n",
      "[Epoch 10/100] [Batch 178/347] [D loss: 0.515629] [G loss: 0.389800]\n",
      "[Epoch 10/100] [Batch 179/347] [D loss: 0.515571] [G loss: 0.382793]\n",
      "[Epoch 10/100] [Batch 180/347] [D loss: 0.515513] [G loss: 0.376081]\n",
      "[Epoch 10/100] [Batch 181/347] [D loss: 0.515450] [G loss: 0.376093]\n",
      "[Epoch 10/100] [Batch 182/347] [D loss: 0.515383] [G loss: 0.373531]\n",
      "[Epoch 10/100] [Batch 183/347] [D loss: 0.515317] [G loss: 0.377132]\n",
      "[Epoch 10/100] [Batch 184/347] [D loss: 0.515246] [G loss: 0.380565]\n",
      "[Epoch 10/100] [Batch 185/347] [D loss: 0.515173] [G loss: 0.378658]\n",
      "[Epoch 10/100] [Batch 186/347] [D loss: 0.515099] [G loss: 0.378063]\n",
      "[Epoch 10/100] [Batch 187/347] [D loss: 0.515024] [G loss: 0.372371]\n",
      "[Epoch 10/100] [Batch 188/347] [D loss: 0.514951] [G loss: 0.368777]\n",
      "[Epoch 10/100] [Batch 189/347] [D loss: 0.514875] [G loss: 0.367536]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 190/347] [D loss: 0.514801] [G loss: 0.355266]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 191/347] [D loss: 0.514726] [G loss: 0.353847]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 192/347] [D loss: 0.514669] [G loss: 0.344361]\n",
      "[Epoch 10/100] [Batch 193/347] [D loss: 0.514614] [G loss: 0.352335]\n",
      "[Epoch 10/100] [Batch 194/347] [D loss: 0.514550] [G loss: 0.348047]\n",
      "[Epoch 10/100] [Batch 195/347] [D loss: 0.514495] [G loss: 0.356664]\n",
      "[Epoch 10/100] [Batch 196/347] [D loss: 0.514436] [G loss: 0.354146]\n",
      "[Epoch 10/100] [Batch 197/347] [D loss: 0.514384] [G loss: 0.349165]\n",
      "[Epoch 10/100] [Batch 198/347] [D loss: 0.514328] [G loss: 0.347901]\n",
      "[Epoch 10/100] [Batch 199/347] [D loss: 0.514273] [G loss: 0.348915]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 200/347] [D loss: 0.514213] [G loss: 0.343608]\n",
      "[Epoch 10/100] [Batch 201/347] [D loss: 0.514156] [G loss: 0.343840]\n",
      "[Epoch 10/100] [Batch 202/347] [D loss: 0.514091] [G loss: 0.355122]\n",
      "[Epoch 10/100] [Batch 203/347] [D loss: 0.514026] [G loss: 0.363424]\n",
      "[Epoch 10/100] [Batch 204/347] [D loss: 0.513960] [G loss: 0.359583]\n",
      "[Epoch 10/100] [Batch 205/347] [D loss: 0.513893] [G loss: 0.351419]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 206/347] [D loss: 0.513825] [G loss: 0.342779]\n",
      "[Epoch 10/100] [Batch 207/347] [D loss: 0.513764] [G loss: 0.353380]\n",
      "[Epoch 10/100] [Batch 208/347] [D loss: 0.513689] [G loss: 0.354072]\n",
      "[Epoch 10/100] [Batch 209/347] [D loss: 0.513616] [G loss: 0.348270]\n",
      "[Epoch 10/100] [Batch 210/347] [D loss: 0.513547] [G loss: 0.355433]\n",
      "[Epoch 10/100] [Batch 211/347] [D loss: 0.513480] [G loss: 0.352371]\n",
      "[Epoch 10/100] [Batch 212/347] [D loss: 0.513409] [G loss: 0.350969]\n",
      "[Epoch 10/100] [Batch 213/347] [D loss: 0.513347] [G loss: 0.356261]\n",
      "[Epoch 10/100] [Batch 214/347] [D loss: 0.513277] [G loss: 0.362828]\n",
      "[Epoch 10/100] [Batch 215/347] [D loss: 0.513211] [G loss: 0.370944]\n",
      "[Epoch 10/100] [Batch 216/347] [D loss: 0.513163] [G loss: 0.354480]\n",
      "[Epoch 10/100] [Batch 217/347] [D loss: 0.513100] [G loss: 0.354799]\n",
      "[Epoch 10/100] [Batch 218/347] [D loss: 0.513047] [G loss: 0.361144]\n",
      "[Epoch 10/100] [Batch 219/347] [D loss: 0.512992] [G loss: 0.373036]\n",
      "[Epoch 10/100] [Batch 220/347] [D loss: 0.512933] [G loss: 0.388593]\n",
      "[Epoch 10/100] [Batch 221/347] [D loss: 0.512867] [G loss: 0.389679]\n",
      "[Epoch 10/100] [Batch 222/347] [D loss: 0.512799] [G loss: 0.381357]\n",
      "[Epoch 10/100] [Batch 223/347] [D loss: 0.512734] [G loss: 0.379640]\n",
      "[Epoch 10/100] [Batch 224/347] [D loss: 0.512663] [G loss: 0.375095]\n",
      "[Epoch 10/100] [Batch 225/347] [D loss: 0.512581] [G loss: 0.360689]\n",
      "[Epoch 10/100] [Batch 226/347] [D loss: 0.512489] [G loss: 0.356029]\n",
      "[Epoch 10/100] [Batch 227/347] [D loss: 0.512404] [G loss: 0.366250]\n",
      "[Epoch 10/100] [Batch 228/347] [D loss: 0.512327] [G loss: 0.368385]\n",
      "[Epoch 10/100] [Batch 229/347] [D loss: 0.512253] [G loss: 0.363487]\n",
      "[Epoch 10/100] [Batch 230/347] [D loss: 0.512180] [G loss: 0.359606]\n",
      "[Epoch 10/100] [Batch 231/347] [D loss: 0.512093] [G loss: 0.359462]\n",
      "[Epoch 10/100] [Batch 232/347] [D loss: 0.512023] [G loss: 0.355138]\n",
      "[Epoch 10/100] [Batch 233/347] [D loss: 0.511939] [G loss: 0.352179]\n",
      "[Epoch 10/100] [Batch 234/347] [D loss: 0.511856] [G loss: 0.356853]\n",
      "[Epoch 10/100] [Batch 235/347] [D loss: 0.511785] [G loss: 0.345372]\n",
      "[Epoch 10/100] [Batch 236/347] [D loss: 0.511706] [G loss: 0.343507]\n",
      "[Epoch 10/100] [Batch 237/347] [D loss: 0.511636] [G loss: 0.347007]\n",
      "[Epoch 10/100] [Batch 238/347] [D loss: 0.511551] [G loss: 0.350752]\n",
      "[Epoch 10/100] [Batch 239/347] [D loss: 0.511468] [G loss: 0.348488]\n",
      "[Epoch 10/100] [Batch 240/347] [D loss: 0.511387] [G loss: 0.344351]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 241/347] [D loss: 0.511303] [G loss: 0.338125]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 242/347] [D loss: 0.511218] [G loss: 0.335716]\n",
      "[Epoch 10/100] [Batch 243/347] [D loss: 0.511142] [G loss: 0.342849]\n",
      "[Epoch 10/100] [Batch 244/347] [D loss: 0.511064] [G loss: 0.351204]\n",
      "[Epoch 10/100] [Batch 245/347] [D loss: 0.510991] [G loss: 0.349328]\n",
      "[Epoch 10/100] [Batch 246/347] [D loss: 0.510903] [G loss: 0.341663]\n",
      "[Epoch 10/100] [Batch 247/347] [D loss: 0.510808] [G loss: 0.348904]\n",
      "[Epoch 10/100] [Batch 248/347] [D loss: 0.510728] [G loss: 0.354603]\n",
      "[Epoch 10/100] [Batch 249/347] [D loss: 0.510646] [G loss: 0.360068]\n",
      "[Epoch 10/100] [Batch 250/347] [D loss: 0.510591] [G loss: 0.351361]\n",
      "[Epoch 10/100] [Batch 251/347] [D loss: 0.510546] [G loss: 0.340017]\n",
      "[Epoch 10/100] [Batch 252/347] [D loss: 0.510498] [G loss: 0.343008]\n",
      "[Epoch 10/100] [Batch 253/347] [D loss: 0.510452] [G loss: 0.343394]\n",
      "[Epoch 10/100] [Batch 254/347] [D loss: 0.510398] [G loss: 0.341570]\n",
      "[Epoch 10/100] [Batch 255/347] [D loss: 0.510340] [G loss: 0.339860]\n",
      "[Epoch 10/100] [Batch 256/347] [D loss: 0.510278] [G loss: 0.344750]\n",
      "[Epoch 10/100] [Batch 257/347] [D loss: 0.510222] [G loss: 0.346454]\n",
      "[Epoch 10/100] [Batch 258/347] [D loss: 0.510146] [G loss: 0.340574]\n",
      "[Epoch 10/100] [Batch 259/347] [D loss: 0.510066] [G loss: 0.348534]\n",
      "[Epoch 10/100] [Batch 260/347] [D loss: 0.509992] [G loss: 0.362716]\n",
      "[Epoch 10/100] [Batch 261/347] [D loss: 0.509934] [G loss: 0.354983]\n",
      "[Epoch 10/100] [Batch 262/347] [D loss: 0.509869] [G loss: 0.339638]\n",
      "[Epoch 10/100] [Batch 263/347] [D loss: 0.509792] [G loss: 0.340315]\n",
      "[Epoch 10/100] [Batch 264/347] [D loss: 0.509712] [G loss: 0.354481]\n",
      "[Epoch 10/100] [Batch 265/347] [D loss: 0.509629] [G loss: 0.359352]\n",
      "[Epoch 10/100] [Batch 266/347] [D loss: 0.509556] [G loss: 0.351844]\n",
      "[Epoch 10/100] [Batch 267/347] [D loss: 0.509483] [G loss: 0.344748]\n",
      "[Epoch 10/100] [Batch 268/347] [D loss: 0.509403] [G loss: 0.351250]\n",
      "[Epoch 10/100] [Batch 269/347] [D loss: 0.509317] [G loss: 0.362014]\n",
      "[Epoch 10/100] [Batch 270/347] [D loss: 0.509239] [G loss: 0.358206]\n",
      "[Epoch 10/100] [Batch 271/347] [D loss: 0.509163] [G loss: 0.345994]\n",
      "[Epoch 10/100] [Batch 272/347] [D loss: 0.509089] [G loss: 0.337010]\n",
      "[Epoch 10/100] [Batch 273/347] [D loss: 0.509009] [G loss: 0.348448]\n",
      "[Epoch 10/100] [Batch 274/347] [D loss: 0.508918] [G loss: 0.381821]\n",
      "[Epoch 10/100] [Batch 275/347] [D loss: 0.508838] [G loss: 0.378297]\n",
      "[Epoch 10/100] [Batch 276/347] [D loss: 0.508768] [G loss: 0.345527]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 277/347] [D loss: 0.508695] [G loss: 0.330484]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 278/347] [D loss: 0.508618] [G loss: 0.321014]\n",
      "[Epoch 10/100] [Batch 279/347] [D loss: 0.508538] [G loss: 0.327550]\n",
      "[Epoch 10/100] [Batch 280/347] [D loss: 0.508459] [G loss: 0.330739]\n",
      "[Epoch 10/100] [Batch 281/347] [D loss: 0.508379] [G loss: 0.328679]\n",
      "[Epoch 10/100] [Batch 282/347] [D loss: 0.508295] [G loss: 0.326179]\n",
      "[Epoch 10/100] [Batch 283/347] [D loss: 0.508209] [G loss: 0.329051]\n",
      "[Epoch 10/100] [Batch 284/347] [D loss: 0.508132] [G loss: 0.328141]\n",
      "[Epoch 10/100] [Batch 285/347] [D loss: 0.508052] [G loss: 0.323658]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 286/347] [D loss: 0.507963] [G loss: 0.317823]\n",
      "[Epoch 10/100] [Batch 287/347] [D loss: 0.507890] [G loss: 0.320993]\n",
      "[Epoch 10/100] [Batch 288/347] [D loss: 0.507779] [G loss: 0.347111]\n",
      "[Epoch 10/100] [Batch 289/347] [D loss: 0.507698] [G loss: 0.350848]\n",
      "[Epoch 10/100] [Batch 290/347] [D loss: 0.507639] [G loss: 0.327815]\n",
      "[Epoch 10/100] [Batch 291/347] [D loss: 0.507556] [G loss: 0.329953]\n",
      "[Epoch 10/100] [Batch 292/347] [D loss: 0.507489] [G loss: 0.320817]\n",
      "[Epoch 10/100] [Batch 293/347] [D loss: 0.507441] [G loss: 0.332976]\n",
      "[Epoch 10/100] [Batch 294/347] [D loss: 0.507383] [G loss: 0.342684]\n",
      "[Epoch 10/100] [Batch 295/347] [D loss: 0.507298] [G loss: 0.340157]\n",
      "[Epoch 10/100] [Batch 296/347] [D loss: 0.507232] [G loss: 0.335962]\n",
      "[Epoch 10/100] [Batch 297/347] [D loss: 0.507166] [G loss: 0.347009]\n",
      "[Epoch 10/100] [Batch 298/347] [D loss: 0.507089] [G loss: 0.341631]\n",
      "[Epoch 10/100] [Batch 299/347] [D loss: 0.507024] [G loss: 0.339948]\n",
      "[Epoch 10/100] [Batch 300/347] [D loss: 0.506941] [G loss: 0.334829]\n",
      "[Epoch 10/100] [Batch 301/347] [D loss: 0.506875] [G loss: 0.335979]\n",
      "[Epoch 10/100] [Batch 302/347] [D loss: 0.506808] [G loss: 0.340632]\n",
      "[Epoch 10/100] [Batch 303/347] [D loss: 0.506711] [G loss: 0.324504]\n",
      "[Epoch 10/100] [Batch 304/347] [D loss: 0.506608] [G loss: 0.323260]\n",
      "[Epoch 10/100] [Batch 305/347] [D loss: 0.506523] [G loss: 0.335712]\n",
      "[Epoch 10/100] [Batch 306/347] [D loss: 0.506439] [G loss: 0.327401]\n",
      "[Epoch 10/100] [Batch 307/347] [D loss: 0.506358] [G loss: 0.339671]\n",
      "[Epoch 10/100] [Batch 308/347] [D loss: 0.506279] [G loss: 0.335524]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 309/347] [D loss: 0.506218] [G loss: 0.314819]\n",
      "[Epoch 10/100] [Batch 310/347] [D loss: 0.506163] [G loss: 0.333485]\n",
      "[Epoch 10/100] [Batch 311/347] [D loss: 0.506084] [G loss: 0.336094]\n",
      "[Epoch 10/100] [Batch 312/347] [D loss: 0.506017] [G loss: 0.335518]\n",
      "[Epoch 10/100] [Batch 313/347] [D loss: 0.505949] [G loss: 0.334470]\n",
      "[Epoch 10/100] [Batch 314/347] [D loss: 0.505885] [G loss: 0.327860]\n",
      "[Epoch 10/100] [Batch 315/347] [D loss: 0.505827] [G loss: 0.318145]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 316/347] [D loss: 0.505742] [G loss: 0.312333]\n",
      "[Epoch 10/100] [Batch 317/347] [D loss: 0.505660] [G loss: 0.330615]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 318/347] [D loss: 0.505633] [G loss: 0.308128]\n",
      "[Epoch 10/100] [Batch 319/347] [D loss: 0.505603] [G loss: 0.338746]\n",
      "[Epoch 10/100] [Batch 320/347] [D loss: 0.505555] [G loss: 0.352006]\n",
      "[Epoch 10/100] [Batch 321/347] [D loss: 0.505481] [G loss: 0.341155]\n",
      "[Epoch 10/100] [Batch 322/347] [D loss: 0.505405] [G loss: 0.327795]\n",
      "[Epoch 10/100] [Batch 323/347] [D loss: 0.505334] [G loss: 0.326621]\n",
      "[Epoch 10/100] [Batch 324/347] [D loss: 0.505264] [G loss: 0.329152]\n",
      "[Epoch 10/100] [Batch 325/347] [D loss: 0.505178] [G loss: 0.317785]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 326/347] [D loss: 0.505089] [G loss: 0.306958]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 327/347] [D loss: 0.505016] [G loss: 0.304491]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 328/347] [D loss: 0.504942] [G loss: 0.301726]\n",
      "[Epoch 10/100] [Batch 329/347] [D loss: 0.504861] [G loss: 0.323086]\n",
      "[Epoch 10/100] [Batch 330/347] [D loss: 0.504779] [G loss: 0.338570]\n",
      "[Epoch 10/100] [Batch 331/347] [D loss: 0.504741] [G loss: 0.320347]\n",
      "[Epoch 10/100] [Batch 332/347] [D loss: 0.504719] [G loss: 0.313296]\n",
      "[Epoch 10/100] [Batch 333/347] [D loss: 0.504662] [G loss: 0.324161]\n",
      "[Epoch 10/100] [Batch 334/347] [D loss: 0.504611] [G loss: 0.325127]\n",
      "[Epoch 10/100] [Batch 335/347] [D loss: 0.504546] [G loss: 0.312784]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 10/100] [Batch 336/347] [D loss: 0.504473] [G loss: 0.298194]\n",
      "[Epoch 10/100] [Batch 337/347] [D loss: 0.504413] [G loss: 0.303537]\n",
      "[Epoch 10/100] [Batch 338/347] [D loss: 0.504364] [G loss: 0.317592]\n",
      "[Epoch 10/100] [Batch 339/347] [D loss: 0.504314] [G loss: 0.322395]\n",
      "[Epoch 10/100] [Batch 340/347] [D loss: 0.504252] [G loss: 0.322213]\n",
      "[Epoch 10/100] [Batch 341/347] [D loss: 0.504188] [G loss: 0.316872]\n",
      "[Epoch 10/100] [Batch 342/347] [D loss: 0.504123] [G loss: 0.308748]\n",
      "[Epoch 10/100] [Batch 343/347] [D loss: 0.504066] [G loss: 0.312927]\n",
      "[Epoch 10/100] [Batch 344/347] [D loss: 0.503995] [G loss: 0.310914]\n",
      "[Epoch 10/100] [Batch 345/347] [D loss: 0.503905] [G loss: 0.320229]\n",
      "[Epoch 10/100] [Batch 346/347] [D loss: 0.503831] [G loss: 0.338400]\n",
      "[Epoch 10/100] [Batch 347/347] [D loss: 0.503764] [G loss: 0.344386]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 1/347] [D loss: 0.503747] [G loss: 0.310949]\n",
      "[Epoch 11/100] [Batch 2/347] [D loss: 0.503683] [G loss: 0.315835]\n",
      "[Epoch 11/100] [Batch 3/347] [D loss: 0.503631] [G loss: 0.315445]\n",
      "[Epoch 11/100] [Batch 4/347] [D loss: 0.503576] [G loss: 0.316302]\n",
      "[Epoch 11/100] [Batch 5/347] [D loss: 0.503514] [G loss: 0.315110]\n",
      "[Epoch 11/100] [Batch 6/347] [D loss: 0.503461] [G loss: 0.315079]\n",
      "[Epoch 11/100] [Batch 7/347] [D loss: 0.503401] [G loss: 0.314490]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 8/347] [D loss: 0.503350] [G loss: 0.309419]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 9/347] [D loss: 0.503288] [G loss: 0.307909]\n",
      "[Epoch 11/100] [Batch 10/347] [D loss: 0.503235] [G loss: 0.309086]\n",
      "[Epoch 11/100] [Batch 11/347] [D loss: 0.503197] [G loss: 0.308429]\n",
      "[Epoch 11/100] [Batch 12/347] [D loss: 0.503149] [G loss: 0.308500]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 13/347] [D loss: 0.503106] [G loss: 0.303414]\n",
      "[Epoch 11/100] [Batch 14/347] [D loss: 0.503062] [G loss: 0.305551]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 15/347] [D loss: 0.503010] [G loss: 0.301722]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 16/347] [D loss: 0.502957] [G loss: 0.297560]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 17/347] [D loss: 0.502904] [G loss: 0.289194]\n",
      "[Epoch 11/100] [Batch 18/347] [D loss: 0.502846] [G loss: 0.294078]\n",
      "[Epoch 11/100] [Batch 19/347] [D loss: 0.502806] [G loss: 0.290824]\n",
      "[Epoch 11/100] [Batch 20/347] [D loss: 0.502767] [G loss: 0.303849]\n",
      "[Epoch 11/100] [Batch 21/347] [D loss: 0.502714] [G loss: 0.300105]\n",
      "[Epoch 11/100] [Batch 22/347] [D loss: 0.502663] [G loss: 0.295013]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 23/347] [D loss: 0.502612] [G loss: 0.288563]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 24/347] [D loss: 0.502573] [G loss: 0.287639]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 25/347] [D loss: 0.502539] [G loss: 0.286785]\n",
      "[Epoch 11/100] [Batch 26/347] [D loss: 0.502478] [G loss: 0.294286]\n",
      "[Epoch 11/100] [Batch 27/347] [D loss: 0.502447] [G loss: 0.299615]\n",
      "[Epoch 11/100] [Batch 28/347] [D loss: 0.502430] [G loss: 0.299825]\n",
      "[Epoch 11/100] [Batch 29/347] [D loss: 0.502402] [G loss: 0.296574]\n",
      "[Epoch 11/100] [Batch 30/347] [D loss: 0.502384] [G loss: 0.303214]\n",
      "[Epoch 11/100] [Batch 31/347] [D loss: 0.502356] [G loss: 0.305527]\n",
      "[Epoch 11/100] [Batch 32/347] [D loss: 0.502317] [G loss: 0.299001]\n",
      "[Epoch 11/100] [Batch 33/347] [D loss: 0.502271] [G loss: 0.294392]\n",
      "[Epoch 11/100] [Batch 34/347] [D loss: 0.502241] [G loss: 0.295056]\n",
      "[Epoch 11/100] [Batch 35/347] [D loss: 0.502203] [G loss: 0.293473]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 36/347] [D loss: 0.502158] [G loss: 0.283939]\n",
      "[Epoch 11/100] [Batch 37/347] [D loss: 0.502087] [G loss: 0.301335]\n",
      "[Epoch 11/100] [Batch 38/347] [D loss: 0.502022] [G loss: 0.316234]\n",
      "[Epoch 11/100] [Batch 39/347] [D loss: 0.501985] [G loss: 0.306402]\n",
      "[Epoch 11/100] [Batch 40/347] [D loss: 0.501957] [G loss: 0.306394]\n",
      "[Epoch 11/100] [Batch 41/347] [D loss: 0.501912] [G loss: 0.307463]\n",
      "[Epoch 11/100] [Batch 42/347] [D loss: 0.501882] [G loss: 0.300195]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 43/347] [D loss: 0.501882] [G loss: 0.283890]\n",
      "[Epoch 11/100] [Batch 44/347] [D loss: 0.501876] [G loss: 0.288892]\n",
      "[Epoch 11/100] [Batch 45/347] [D loss: 0.501867] [G loss: 0.306031]\n",
      "[Epoch 11/100] [Batch 46/347] [D loss: 0.501831] [G loss: 0.300545]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 47/347] [D loss: 0.501757] [G loss: 0.280439]\n",
      "[Epoch 11/100] [Batch 48/347] [D loss: 0.501675] [G loss: 0.312527]\n",
      "[Epoch 11/100] [Batch 49/347] [D loss: 0.501633] [G loss: 0.320961]\n",
      "[Epoch 11/100] [Batch 50/347] [D loss: 0.501611] [G loss: 0.336575]\n",
      "[Epoch 11/100] [Batch 51/347] [D loss: 0.501629] [G loss: 0.321162]\n",
      "[Epoch 11/100] [Batch 52/347] [D loss: 0.501667] [G loss: 0.286895]\n",
      "[Epoch 11/100] [Batch 53/347] [D loss: 0.501652] [G loss: 0.283582]\n",
      "[Epoch 11/100] [Batch 54/347] [D loss: 0.501571] [G loss: 0.335877]\n",
      "[Epoch 11/100] [Batch 55/347] [D loss: 0.501492] [G loss: 0.358087]\n",
      "[Epoch 11/100] [Batch 56/347] [D loss: 0.501498] [G loss: 0.344890]\n",
      "[Epoch 11/100] [Batch 57/347] [D loss: 0.501555] [G loss: 0.310374]\n",
      "[Epoch 11/100] [Batch 58/347] [D loss: 0.501582] [G loss: 0.284479]\n",
      "[Epoch 11/100] [Batch 59/347] [D loss: 0.501543] [G loss: 0.292815]\n",
      "[Epoch 11/100] [Batch 60/347] [D loss: 0.501514] [G loss: 0.311206]\n",
      "[Epoch 11/100] [Batch 61/347] [D loss: 0.501474] [G loss: 0.323405]\n",
      "[Epoch 11/100] [Batch 62/347] [D loss: 0.501415] [G loss: 0.346999]\n",
      "[Epoch 11/100] [Batch 63/347] [D loss: 0.501354] [G loss: 0.348824]\n",
      "[Epoch 11/100] [Batch 64/347] [D loss: 0.501400] [G loss: 0.311774]\n",
      "[Epoch 11/100] [Batch 65/347] [D loss: 0.501467] [G loss: 0.287039]\n",
      "[Epoch 11/100] [Batch 66/347] [D loss: 0.501439] [G loss: 0.289131]\n",
      "[Epoch 11/100] [Batch 67/347] [D loss: 0.501374] [G loss: 0.294597]\n",
      "[Epoch 11/100] [Batch 68/347] [D loss: 0.501334] [G loss: 0.312207]\n",
      "[Epoch 11/100] [Batch 69/347] [D loss: 0.501253] [G loss: 0.330690]\n",
      "[Epoch 11/100] [Batch 70/347] [D loss: 0.501224] [G loss: 0.329195]\n",
      "[Epoch 11/100] [Batch 71/347] [D loss: 0.501212] [G loss: 0.331434]\n",
      "[Epoch 11/100] [Batch 72/347] [D loss: 0.501175] [G loss: 0.333635]\n",
      "[Epoch 11/100] [Batch 73/347] [D loss: 0.501194] [G loss: 0.308630]\n",
      "[Epoch 11/100] [Batch 74/347] [D loss: 0.501217] [G loss: 0.294444]\n",
      "[Epoch 11/100] [Batch 75/347] [D loss: 0.501151] [G loss: 0.323885]\n",
      "[Epoch 11/100] [Batch 76/347] [D loss: 0.501105] [G loss: 0.325406]\n",
      "[Epoch 11/100] [Batch 77/347] [D loss: 0.501141] [G loss: 0.290841]\n",
      "[Epoch 11/100] [Batch 78/347] [D loss: 0.501209] [G loss: 0.290208]\n",
      "[Epoch 11/100] [Batch 79/347] [D loss: 0.501202] [G loss: 0.291643]\n",
      "[Epoch 11/100] [Batch 80/347] [D loss: 0.501185] [G loss: 0.288492]\n",
      "[Epoch 11/100] [Batch 81/347] [D loss: 0.501188] [G loss: 0.293371]\n",
      "[Epoch 11/100] [Batch 82/347] [D loss: 0.501172] [G loss: 0.298520]\n",
      "[Epoch 11/100] [Batch 83/347] [D loss: 0.501148] [G loss: 0.290633]\n",
      "[Epoch 11/100] [Batch 84/347] [D loss: 0.501138] [G loss: 0.296517]\n",
      "[Epoch 11/100] [Batch 85/347] [D loss: 0.501122] [G loss: 0.297008]\n",
      "[Epoch 11/100] [Batch 86/347] [D loss: 0.501107] [G loss: 0.291139]\n",
      "[Epoch 11/100] [Batch 87/347] [D loss: 0.501083] [G loss: 0.288622]\n",
      "[Epoch 11/100] [Batch 88/347] [D loss: 0.501076] [G loss: 0.291666]\n",
      "[Epoch 11/100] [Batch 89/347] [D loss: 0.501067] [G loss: 0.294740]\n",
      "[Epoch 11/100] [Batch 90/347] [D loss: 0.501047] [G loss: 0.290592]\n",
      "[Epoch 11/100] [Batch 91/347] [D loss: 0.501038] [G loss: 0.288847]\n",
      "[Epoch 11/100] [Batch 92/347] [D loss: 0.501028] [G loss: 0.290028]\n",
      "[Epoch 11/100] [Batch 93/347] [D loss: 0.501012] [G loss: 0.287739]\n",
      "[Epoch 11/100] [Batch 94/347] [D loss: 0.500990] [G loss: 0.283866]\n",
      "[Epoch 11/100] [Batch 95/347] [D loss: 0.500980] [G loss: 0.284083]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 96/347] [D loss: 0.500972] [G loss: 0.279054]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 97/347] [D loss: 0.500948] [G loss: 0.273764]\n",
      "[Epoch 11/100] [Batch 98/347] [D loss: 0.500942] [G loss: 0.278360]\n",
      "[Epoch 11/100] [Batch 99/347] [D loss: 0.500935] [G loss: 0.281850]\n",
      "[Epoch 11/100] [Batch 100/347] [D loss: 0.500919] [G loss: 0.277973]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 101/347] [D loss: 0.500900] [G loss: 0.272492]\n",
      "[Epoch 11/100] [Batch 102/347] [D loss: 0.500898] [G loss: 0.274128]\n",
      "[Epoch 11/100] [Batch 103/347] [D loss: 0.500888] [G loss: 0.274747]\n",
      "[Epoch 11/100] [Batch 104/347] [D loss: 0.500864] [G loss: 0.275435]\n",
      "[Epoch 11/100] [Batch 105/347] [D loss: 0.500855] [G loss: 0.277403]\n",
      "[Epoch 11/100] [Batch 106/347] [D loss: 0.500848] [G loss: 0.276679]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 107/347] [D loss: 0.500837] [G loss: 0.270158]\n",
      "[Epoch 11/100] [Batch 108/347] [D loss: 0.500826] [G loss: 0.287230]\n",
      "[Epoch 11/100] [Batch 109/347] [D loss: 0.500838] [G loss: 0.280445]\n",
      "[Epoch 11/100] [Batch 110/347] [D loss: 0.500851] [G loss: 0.266349]\n",
      "[Epoch 11/100] [Batch 111/347] [D loss: 0.500825] [G loss: 0.274632]\n",
      "[Epoch 11/100] [Batch 112/347] [D loss: 0.500829] [G loss: 0.275439]\n",
      "[Epoch 11/100] [Batch 113/347] [D loss: 0.500860] [G loss: 0.281180]\n",
      "[Epoch 11/100] [Batch 114/347] [D loss: 0.500880] [G loss: 0.301699]\n",
      "[Epoch 11/100] [Batch 115/347] [D loss: 0.500884] [G loss: 0.302759]\n",
      "[Epoch 11/100] [Batch 116/347] [D loss: 0.500872] [G loss: 0.296799]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 117/347] [D loss: 0.500830] [G loss: 0.269981]\n",
      "[Epoch 11/100] [Batch 118/347] [D loss: 0.500771] [G loss: 0.277759]\n",
      "[Epoch 11/100] [Batch 119/347] [D loss: 0.500747] [G loss: 0.279952]\n",
      "[Epoch 11/100] [Batch 120/347] [D loss: 0.500756] [G loss: 0.278882]\n",
      "[Epoch 11/100] [Batch 121/347] [D loss: 0.500752] [G loss: 0.277195]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 122/347] [D loss: 0.500765] [G loss: 0.264713]\n",
      "[Epoch 11/100] [Batch 123/347] [D loss: 0.500765] [G loss: 0.263678]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 124/347] [D loss: 0.500753] [G loss: 0.264597]\n",
      "[Epoch 11/100] [Batch 125/347] [D loss: 0.500771] [G loss: 0.266667]\n",
      "[Epoch 11/100] [Batch 126/347] [D loss: 0.500794] [G loss: 0.279340]\n",
      "[Epoch 11/100] [Batch 127/347] [D loss: 0.500796] [G loss: 0.280756]\n",
      "[Epoch 11/100] [Batch 128/347] [D loss: 0.500781] [G loss: 0.275237]\n",
      "[Epoch 11/100] [Batch 129/347] [D loss: 0.500775] [G loss: 0.270260]\n",
      "[Epoch 11/100] [Batch 130/347] [D loss: 0.500772] [G loss: 0.273621]\n",
      "[Epoch 11/100] [Batch 131/347] [D loss: 0.500738] [G loss: 0.273274]\n",
      "[Epoch 11/100] [Batch 132/347] [D loss: 0.500700] [G loss: 0.297814]\n",
      "[Epoch 11/100] [Batch 133/347] [D loss: 0.500680] [G loss: 0.304460]\n",
      "[Epoch 11/100] [Batch 134/347] [D loss: 0.500652] [G loss: 0.319294]\n",
      "[Epoch 11/100] [Batch 135/347] [D loss: 0.500648] [G loss: 0.328242]\n",
      "[Epoch 11/100] [Batch 136/347] [D loss: 0.500705] [G loss: 0.286344]\n",
      "[Epoch 11/100] [Batch 137/347] [D loss: 0.500734] [G loss: 0.273610]\n",
      "[Epoch 11/100] [Batch 138/347] [D loss: 0.500677] [G loss: 0.291196]\n",
      "[Epoch 11/100] [Batch 139/347] [D loss: 0.500620] [G loss: 0.314994]\n",
      "[Epoch 11/100] [Batch 140/347] [D loss: 0.500597] [G loss: 0.326296]\n",
      "[Epoch 11/100] [Batch 141/347] [D loss: 0.500573] [G loss: 0.333095]\n",
      "[Epoch 11/100] [Batch 142/347] [D loss: 0.500558] [G loss: 0.340798]\n",
      "[Epoch 11/100] [Batch 143/347] [D loss: 0.500508] [G loss: 0.362471]\n",
      "[Epoch 11/100] [Batch 144/347] [D loss: 0.500488] [G loss: 0.364621]\n",
      "[Epoch 11/100] [Batch 145/347] [D loss: 0.500486] [G loss: 0.350301]\n",
      "[Epoch 11/100] [Batch 146/347] [D loss: 0.500501] [G loss: 0.333487]\n",
      "[Epoch 11/100] [Batch 147/347] [D loss: 0.500555] [G loss: 0.305413]\n",
      "[Epoch 11/100] [Batch 148/347] [D loss: 0.500588] [G loss: 0.292939]\n",
      "[Epoch 11/100] [Batch 149/347] [D loss: 0.500556] [G loss: 0.306053]\n",
      "[Epoch 11/100] [Batch 150/347] [D loss: 0.500553] [G loss: 0.306414]\n",
      "[Epoch 11/100] [Batch 151/347] [D loss: 0.500594] [G loss: 0.295452]\n",
      "[Epoch 11/100] [Batch 152/347] [D loss: 0.500583] [G loss: 0.306407]\n",
      "[Epoch 11/100] [Batch 153/347] [D loss: 0.500530] [G loss: 0.327074]\n",
      "[Epoch 11/100] [Batch 154/347] [D loss: 0.500489] [G loss: 0.331181]\n",
      "[Epoch 11/100] [Batch 155/347] [D loss: 0.500509] [G loss: 0.318313]\n",
      "[Epoch 11/100] [Batch 156/347] [D loss: 0.500548] [G loss: 0.301768]\n",
      "[Epoch 11/100] [Batch 157/347] [D loss: 0.500567] [G loss: 0.308062]\n",
      "[Epoch 11/100] [Batch 158/347] [D loss: 0.500503] [G loss: 0.331760]\n",
      "[Epoch 11/100] [Batch 159/347] [D loss: 0.500475] [G loss: 0.329215]\n",
      "[Epoch 11/100] [Batch 160/347] [D loss: 0.500545] [G loss: 0.309263]\n",
      "[Epoch 11/100] [Batch 161/347] [D loss: 0.500591] [G loss: 0.300892]\n",
      "[Epoch 11/100] [Batch 162/347] [D loss: 0.500565] [G loss: 0.306660]\n",
      "[Epoch 11/100] [Batch 163/347] [D loss: 0.500516] [G loss: 0.325347]\n",
      "[Epoch 11/100] [Batch 164/347] [D loss: 0.500466] [G loss: 0.340582]\n",
      "[Epoch 11/100] [Batch 165/347] [D loss: 0.500464] [G loss: 0.331722]\n",
      "[Epoch 11/100] [Batch 166/347] [D loss: 0.500541] [G loss: 0.293494]\n",
      "[Epoch 11/100] [Batch 167/347] [D loss: 0.500648] [G loss: 0.277530]\n",
      "[Epoch 11/100] [Batch 168/347] [D loss: 0.500675] [G loss: 0.288152]\n",
      "[Epoch 11/100] [Batch 169/347] [D loss: 0.500693] [G loss: 0.287003]\n",
      "[Epoch 11/100] [Batch 170/347] [D loss: 0.500701] [G loss: 0.283122]\n",
      "[Epoch 11/100] [Batch 171/347] [D loss: 0.500729] [G loss: 0.291496]\n",
      "[Epoch 11/100] [Batch 172/347] [D loss: 0.500740] [G loss: 0.296398]\n",
      "[Epoch 11/100] [Batch 173/347] [D loss: 0.500708] [G loss: 0.285090]\n",
      "[Epoch 11/100] [Batch 174/347] [D loss: 0.500694] [G loss: 0.282541]\n",
      "[Epoch 11/100] [Batch 175/347] [D loss: 0.500711] [G loss: 0.292247]\n",
      "[Epoch 11/100] [Batch 176/347] [D loss: 0.500738] [G loss: 0.305497]\n",
      "[Epoch 11/100] [Batch 177/347] [D loss: 0.500738] [G loss: 0.306200]\n",
      "[Epoch 11/100] [Batch 178/347] [D loss: 0.500722] [G loss: 0.300193]\n",
      "[Epoch 11/100] [Batch 179/347] [D loss: 0.500701] [G loss: 0.293388]\n",
      "[Epoch 11/100] [Batch 180/347] [D loss: 0.500684] [G loss: 0.286841]\n",
      "[Epoch 11/100] [Batch 181/347] [D loss: 0.500680] [G loss: 0.287137]\n",
      "[Epoch 11/100] [Batch 182/347] [D loss: 0.500662] [G loss: 0.284766]\n",
      "[Epoch 11/100] [Batch 183/347] [D loss: 0.500671] [G loss: 0.288710]\n",
      "[Epoch 11/100] [Batch 184/347] [D loss: 0.500671] [G loss: 0.292367]\n",
      "[Epoch 11/100] [Batch 185/347] [D loss: 0.500668] [G loss: 0.290761]\n",
      "[Epoch 11/100] [Batch 186/347] [D loss: 0.500670] [G loss: 0.290407]\n",
      "[Epoch 11/100] [Batch 187/347] [D loss: 0.500655] [G loss: 0.285000]\n",
      "[Epoch 11/100] [Batch 188/347] [D loss: 0.500643] [G loss: 0.281676]\n",
      "[Epoch 11/100] [Batch 189/347] [D loss: 0.500635] [G loss: 0.280658]\n",
      "[Epoch 11/100] [Batch 190/347] [D loss: 0.500597] [G loss: 0.268627]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 191/347] [D loss: 0.500552] [G loss: 0.264170]\n",
      "[Epoch 11/100] [Batch 192/347] [D loss: 0.500567] [G loss: 0.257540]\n",
      "[Epoch 11/100] [Batch 193/347] [D loss: 0.500592] [G loss: 0.266028]\n",
      "[Epoch 11/100] [Batch 194/347] [D loss: 0.500563] [G loss: 0.261556]\n",
      "[Epoch 11/100] [Batch 195/347] [D loss: 0.500540] [G loss: 0.269031]\n",
      "[Epoch 11/100] [Batch 196/347] [D loss: 0.500522] [G loss: 0.267346]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 197/347] [D loss: 0.500523] [G loss: 0.263123]\n",
      "[Epoch 11/100] [Batch 198/347] [D loss: 0.500536] [G loss: 0.263433]\n",
      "[Epoch 11/100] [Batch 199/347] [D loss: 0.500530] [G loss: 0.264993]\n",
      "[Epoch 11/100] [Batch 200/347] [D loss: 0.500531] [G loss: 0.260236]\n",
      "[Epoch 11/100] [Batch 201/347] [D loss: 0.500537] [G loss: 0.260299]\n",
      "[Epoch 11/100] [Batch 202/347] [D loss: 0.500506] [G loss: 0.272165]\n",
      "[Epoch 11/100] [Batch 203/347] [D loss: 0.500481] [G loss: 0.281022]\n",
      "[Epoch 11/100] [Batch 204/347] [D loss: 0.500488] [G loss: 0.277691]\n",
      "[Epoch 11/100] [Batch 205/347] [D loss: 0.500502] [G loss: 0.269939]\n",
      "[Epoch 11/100] [Batch 206/347] [D loss: 0.500526] [G loss: 0.257807]\n",
      "[Epoch 11/100] [Batch 207/347] [D loss: 0.500568] [G loss: 0.265196]\n",
      "[Epoch 11/100] [Batch 208/347] [D loss: 0.500560] [G loss: 0.266198]\n",
      "[Epoch 11/100] [Batch 209/347] [D loss: 0.500538] [G loss: 0.260744]\n",
      "[Epoch 11/100] [Batch 210/347] [D loss: 0.500569] [G loss: 0.268790]\n",
      "[Epoch 11/100] [Batch 211/347] [D loss: 0.500565] [G loss: 0.266092]\n",
      "[Epoch 11/100] [Batch 212/347] [D loss: 0.500551] [G loss: 0.265000]\n",
      "[Epoch 11/100] [Batch 213/347] [D loss: 0.500547] [G loss: 0.270617]\n",
      "[Epoch 11/100] [Batch 214/347] [D loss: 0.500503] [G loss: 0.282980]\n",
      "[Epoch 11/100] [Batch 215/347] [D loss: 0.500484] [G loss: 0.291208]\n",
      "[Epoch 11/100] [Batch 216/347] [D loss: 0.500524] [G loss: 0.269730]\n",
      "[Epoch 11/100] [Batch 217/347] [D loss: 0.500548] [G loss: 0.270329]\n",
      "[Epoch 11/100] [Batch 218/347] [D loss: 0.500574] [G loss: 0.276402]\n",
      "[Epoch 11/100] [Batch 219/347] [D loss: 0.500607] [G loss: 0.288526]\n",
      "[Epoch 11/100] [Batch 220/347] [D loss: 0.500645] [G loss: 0.304345]\n",
      "[Epoch 11/100] [Batch 221/347] [D loss: 0.500654] [G loss: 0.305753]\n",
      "[Epoch 11/100] [Batch 222/347] [D loss: 0.500640] [G loss: 0.297710]\n",
      "[Epoch 11/100] [Batch 223/347] [D loss: 0.500633] [G loss: 0.296318]\n",
      "[Epoch 11/100] [Batch 224/347] [D loss: 0.500624] [G loss: 0.292141]\n",
      "[Epoch 11/100] [Batch 225/347] [D loss: 0.500562] [G loss: 0.278606]\n",
      "[Epoch 11/100] [Batch 226/347] [D loss: 0.500462] [G loss: 0.278390]\n",
      "[Epoch 11/100] [Batch 227/347] [D loss: 0.500395] [G loss: 0.288801]\n",
      "[Epoch 11/100] [Batch 228/347] [D loss: 0.500389] [G loss: 0.290494]\n",
      "[Epoch 11/100] [Batch 229/347] [D loss: 0.500408] [G loss: 0.285753]\n",
      "[Epoch 11/100] [Batch 230/347] [D loss: 0.500420] [G loss: 0.282060]\n",
      "[Epoch 11/100] [Batch 231/347] [D loss: 0.500404] [G loss: 0.282140]\n",
      "[Epoch 11/100] [Batch 232/347] [D loss: 0.500418] [G loss: 0.278106]\n",
      "[Epoch 11/100] [Batch 233/347] [D loss: 0.500425] [G loss: 0.276104]\n",
      "[Epoch 11/100] [Batch 234/347] [D loss: 0.500424] [G loss: 0.281062]\n",
      "[Epoch 11/100] [Batch 235/347] [D loss: 0.500463] [G loss: 0.269842]\n",
      "[Epoch 11/100] [Batch 236/347] [D loss: 0.500496] [G loss: 0.264802]\n",
      "[Epoch 11/100] [Batch 237/347] [D loss: 0.500524] [G loss: 0.267960]\n",
      "[Epoch 11/100] [Batch 238/347] [D loss: 0.500521] [G loss: 0.271976]\n",
      "[Epoch 11/100] [Batch 239/347] [D loss: 0.500512] [G loss: 0.269986]\n",
      "[Epoch 11/100] [Batch 240/347] [D loss: 0.500505] [G loss: 0.266151]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 241/347] [D loss: 0.500491] [G loss: 0.260241]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 242/347] [D loss: 0.500481] [G loss: 0.258166]\n",
      "[Epoch 11/100] [Batch 243/347] [D loss: 0.500493] [G loss: 0.265597]\n",
      "[Epoch 11/100] [Batch 244/347] [D loss: 0.500512] [G loss: 0.274236]\n",
      "[Epoch 11/100] [Batch 245/347] [D loss: 0.500535] [G loss: 0.272671]\n",
      "[Epoch 11/100] [Batch 246/347] [D loss: 0.500477] [G loss: 0.265949]\n",
      "[Epoch 11/100] [Batch 247/347] [D loss: 0.500402] [G loss: 0.276743]\n",
      "[Epoch 11/100] [Batch 248/347] [D loss: 0.500368] [G loss: 0.281980]\n",
      "[Epoch 11/100] [Batch 249/347] [D loss: 0.500352] [G loss: 0.288263]\n",
      "[Epoch 11/100] [Batch 250/347] [D loss: 0.500403] [G loss: 0.279760]\n",
      "[Epoch 11/100] [Batch 251/347] [D loss: 0.500466] [G loss: 0.265618]\n",
      "[Epoch 11/100] [Batch 252/347] [D loss: 0.500493] [G loss: 0.268789]\n",
      "[Epoch 11/100] [Batch 253/347] [D loss: 0.500496] [G loss: 0.269403]\n",
      "[Epoch 11/100] [Batch 254/347] [D loss: 0.500489] [G loss: 0.267778]\n",
      "[Epoch 11/100] [Batch 255/347] [D loss: 0.500473] [G loss: 0.266401]\n",
      "[Epoch 11/100] [Batch 256/347] [D loss: 0.500485] [G loss: 0.271493]\n",
      "[Epoch 11/100] [Batch 257/347] [D loss: 0.500513] [G loss: 0.273146]\n",
      "[Epoch 11/100] [Batch 258/347] [D loss: 0.500481] [G loss: 0.267842]\n",
      "[Epoch 11/100] [Batch 259/347] [D loss: 0.500405] [G loss: 0.279017]\n",
      "[Epoch 11/100] [Batch 260/347] [D loss: 0.500368] [G loss: 0.293441]\n",
      "[Epoch 11/100] [Batch 261/347] [D loss: 0.500394] [G loss: 0.285926]\n",
      "[Epoch 11/100] [Batch 262/347] [D loss: 0.500411] [G loss: 0.270835]\n",
      "[Epoch 11/100] [Batch 263/347] [D loss: 0.500408] [G loss: 0.271779]\n",
      "[Epoch 11/100] [Batch 264/347] [D loss: 0.500382] [G loss: 0.286251]\n",
      "[Epoch 11/100] [Batch 265/347] [D loss: 0.500363] [G loss: 0.291429]\n",
      "[Epoch 11/100] [Batch 266/347] [D loss: 0.500370] [G loss: 0.284268]\n",
      "[Epoch 11/100] [Batch 267/347] [D loss: 0.500382] [G loss: 0.277485]\n",
      "[Epoch 11/100] [Batch 268/347] [D loss: 0.500377] [G loss: 0.284346]\n",
      "[Epoch 11/100] [Batch 269/347] [D loss: 0.500360] [G loss: 0.295402]\n",
      "[Epoch 11/100] [Batch 270/347] [D loss: 0.500358] [G loss: 0.291960]\n",
      "[Epoch 11/100] [Batch 271/347] [D loss: 0.500373] [G loss: 0.280051]\n",
      "[Epoch 11/100] [Batch 272/347] [D loss: 0.500395] [G loss: 0.271393]\n",
      "[Epoch 11/100] [Batch 273/347] [D loss: 0.500384] [G loss: 0.283156]\n",
      "[Epoch 11/100] [Batch 274/347] [D loss: 0.500342] [G loss: 0.316921]\n",
      "[Epoch 11/100] [Batch 275/347] [D loss: 0.500343] [G loss: 0.313742]\n",
      "[Epoch 11/100] [Batch 276/347] [D loss: 0.500380] [G loss: 0.281285]\n",
      "[Epoch 11/100] [Batch 277/347] [D loss: 0.500399] [G loss: 0.266610]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 278/347] [D loss: 0.500419] [G loss: 0.253921]\n",
      "[Epoch 11/100] [Batch 279/347] [D loss: 0.500422] [G loss: 0.260667]\n",
      "[Epoch 11/100] [Batch 280/347] [D loss: 0.500413] [G loss: 0.264270]\n",
      "[Epoch 11/100] [Batch 281/347] [D loss: 0.500412] [G loss: 0.262551]\n",
      "[Epoch 11/100] [Batch 282/347] [D loss: 0.500410] [G loss: 0.261233]\n",
      "[Epoch 11/100] [Batch 283/347] [D loss: 0.500399] [G loss: 0.267084]\n",
      "[Epoch 11/100] [Batch 284/347] [D loss: 0.500407] [G loss: 0.264681]\n",
      "[Epoch 11/100] [Batch 285/347] [D loss: 0.500417] [G loss: 0.260437]\n",
      "[Epoch 11/100] [Batch 286/347] [D loss: 0.500403] [G loss: 0.255495]\n",
      "[Epoch 11/100] [Batch 287/347] [D loss: 0.500404] [G loss: 0.258536]\n",
      "[Epoch 11/100] [Batch 288/347] [D loss: 0.500333] [G loss: 0.284545]\n",
      "[Epoch 11/100] [Batch 289/347] [D loss: 0.500322] [G loss: 0.288233]\n",
      "[Epoch 11/100] [Batch 290/347] [D loss: 0.500374] [G loss: 0.265152]\n",
      "[Epoch 11/100] [Batch 291/347] [D loss: 0.500360] [G loss: 0.267315]\n",
      "[Epoch 11/100] [Batch 292/347] [D loss: 0.500391] [G loss: 0.258171]\n",
      "[Epoch 11/100] [Batch 293/347] [D loss: 0.500471] [G loss: 0.276286]\n",
      "[Epoch 11/100] [Batch 294/347] [D loss: 0.500505] [G loss: 0.286601]\n",
      "[Epoch 11/100] [Batch 295/347] [D loss: 0.500478] [G loss: 0.284680]\n",
      "[Epoch 11/100] [Batch 296/347] [D loss: 0.500482] [G loss: 0.281051]\n",
      "[Epoch 11/100] [Batch 297/347] [D loss: 0.500505] [G loss: 0.291683]\n",
      "[Epoch 11/100] [Batch 298/347] [D loss: 0.500485] [G loss: 0.286789]\n",
      "[Epoch 11/100] [Batch 299/347] [D loss: 0.500494] [G loss: 0.285617]\n",
      "[Epoch 11/100] [Batch 300/347] [D loss: 0.500476] [G loss: 0.281049]\n",
      "[Epoch 11/100] [Batch 301/347] [D loss: 0.500486] [G loss: 0.283822]\n",
      "[Epoch 11/100] [Batch 302/347] [D loss: 0.500504] [G loss: 0.289004]\n",
      "[Epoch 11/100] [Batch 303/347] [D loss: 0.500435] [G loss: 0.273395]\n",
      "[Epoch 11/100] [Batch 304/347] [D loss: 0.500359] [G loss: 0.261908]\n",
      "[Epoch 11/100] [Batch 305/347] [D loss: 0.500339] [G loss: 0.274607]\n",
      "[Epoch 11/100] [Batch 306/347] [D loss: 0.500333] [G loss: 0.267838]\n",
      "[Epoch 11/100] [Batch 307/347] [D loss: 0.500327] [G loss: 0.280424]\n",
      "[Epoch 11/100] [Batch 308/347] [D loss: 0.500324] [G loss: 0.276588]\n",
      "[Epoch 11/100] [Batch 309/347] [D loss: 0.500383] [G loss: 0.257294]\n",
      "[Epoch 11/100] [Batch 310/347] [D loss: 0.500434] [G loss: 0.284170]\n",
      "[Epoch 11/100] [Batch 311/347] [D loss: 0.500434] [G loss: 0.286882]\n",
      "[Epoch 11/100] [Batch 312/347] [D loss: 0.500428] [G loss: 0.286434]\n",
      "[Epoch 11/100] [Batch 313/347] [D loss: 0.500429] [G loss: 0.285478]\n",
      "[Epoch 11/100] [Batch 314/347] [D loss: 0.500430] [G loss: 0.278933]\n",
      "[Epoch 11/100] [Batch 315/347] [D loss: 0.500433] [G loss: 0.269422]\n",
      "[Epoch 11/100] [Batch 316/347] [D loss: 0.500370] [G loss: 0.256775]\n",
      "[Epoch 11/100] [Batch 317/347] [D loss: 0.500307] [G loss: 0.275522]\n",
      "[Epoch 11/100] [Batch 318/347] [D loss: 0.500373] [G loss: 0.258050]\n",
      "[Epoch 11/100] [Batch 319/347] [D loss: 0.500451] [G loss: 0.290471]\n",
      "[Epoch 11/100] [Batch 320/347] [D loss: 0.500481] [G loss: 0.303709]\n",
      "[Epoch 11/100] [Batch 321/347] [D loss: 0.500458] [G loss: 0.292896]\n",
      "[Epoch 11/100] [Batch 322/347] [D loss: 0.500428] [G loss: 0.279631]\n",
      "[Epoch 11/100] [Batch 323/347] [D loss: 0.500425] [G loss: 0.278554]\n",
      "[Epoch 11/100] [Batch 324/347] [D loss: 0.500435] [G loss: 0.281183]\n",
      "[Epoch 11/100] [Batch 325/347] [D loss: 0.500409] [G loss: 0.270056]\n",
      "[Epoch 11/100] [Batch 326/347] [D loss: 0.500376] [G loss: 0.259797]\n",
      "[Epoch 11/100] [Batch 327/347] [D loss: 0.500374] [G loss: 0.257551]\n",
      "[Epoch 11/100] [Batch 328/347] [D loss: 0.500360] [G loss: 0.254626]\n",
      "[Epoch 11/100] [Batch 329/347] [D loss: 0.500305] [G loss: 0.276690]\n",
      "[Epoch 11/100] [Batch 330/347] [D loss: 0.500260] [G loss: 0.292629]\n",
      "[Epoch 11/100] [Batch 331/347] [D loss: 0.500297] [G loss: 0.274848]\n",
      "[Epoch 11/100] [Batch 332/347] [D loss: 0.500368] [G loss: 0.267148]\n",
      "[Epoch 11/100] [Batch 333/347] [D loss: 0.500383] [G loss: 0.278279]\n",
      "[Epoch 11/100] [Batch 334/347] [D loss: 0.500399] [G loss: 0.279510]\n",
      "[Epoch 11/100] [Batch 335/347] [D loss: 0.500381] [G loss: 0.267418]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 11/100] [Batch 336/347] [D loss: 0.500350] [G loss: 0.253910]\n",
      "[Epoch 11/100] [Batch 337/347] [D loss: 0.500351] [G loss: 0.259139]\n",
      "[Epoch 11/100] [Batch 338/347] [D loss: 0.500376] [G loss: 0.273763]\n",
      "[Epoch 11/100] [Batch 339/347] [D loss: 0.500389] [G loss: 0.279209]\n",
      "[Epoch 11/100] [Batch 340/347] [D loss: 0.500383] [G loss: 0.279645]\n",
      "[Epoch 11/100] [Batch 341/347] [D loss: 0.500382] [G loss: 0.274854]\n",
      "[Epoch 11/100] [Batch 342/347] [D loss: 0.500363] [G loss: 0.267299]\n",
      "[Epoch 11/100] [Batch 343/347] [D loss: 0.500359] [G loss: 0.272039]\n",
      "[Epoch 11/100] [Batch 344/347] [D loss: 0.500334] [G loss: 0.268525]\n",
      "[Epoch 11/100] [Batch 345/347] [D loss: 0.500264] [G loss: 0.278529]\n",
      "[Epoch 11/100] [Batch 346/347] [D loss: 0.500229] [G loss: 0.296985]\n",
      "[Epoch 11/100] [Batch 347/347] [D loss: 0.500219] [G loss: 0.303256]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 1/347] [D loss: 0.500304] [G loss: 0.269570]\n",
      "[Epoch 12/100] [Batch 2/347] [D loss: 0.500300] [G loss: 0.274784]\n",
      "[Epoch 12/100] [Batch 3/347] [D loss: 0.500316] [G loss: 0.274668]\n",
      "[Epoch 12/100] [Batch 4/347] [D loss: 0.500313] [G loss: 0.275878]\n",
      "[Epoch 12/100] [Batch 5/347] [D loss: 0.500314] [G loss: 0.275021]\n",
      "[Epoch 12/100] [Batch 6/347] [D loss: 0.500318] [G loss: 0.275312]\n",
      "[Epoch 12/100] [Batch 7/347] [D loss: 0.500307] [G loss: 0.275029]\n",
      "[Epoch 12/100] [Batch 8/347] [D loss: 0.500310] [G loss: 0.270266]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 9/347] [D loss: 0.500286] [G loss: 0.269152]\n",
      "[Epoch 12/100] [Batch 10/347] [D loss: 0.500286] [G loss: 0.270630]\n",
      "[Epoch 12/100] [Batch 11/347] [D loss: 0.500313] [G loss: 0.270363]\n",
      "[Epoch 12/100] [Batch 12/347] [D loss: 0.500321] [G loss: 0.270776]\n",
      "[Epoch 12/100] [Batch 13/347] [D loss: 0.500332] [G loss: 0.270022]\n",
      "[Epoch 12/100] [Batch 14/347] [D loss: 0.500345] [G loss: 0.272401]\n",
      "[Epoch 12/100] [Batch 15/347] [D loss: 0.500342] [G loss: 0.268675]\n",
      "[Epoch 12/100] [Batch 16/347] [D loss: 0.500334] [G loss: 0.264591]\n",
      "[Epoch 12/100] [Batch 17/347] [D loss: 0.500323] [G loss: 0.254782]\n",
      "[Epoch 12/100] [Batch 18/347] [D loss: 0.500308] [G loss: 0.260536]\n",
      "[Epoch 12/100] [Batch 19/347] [D loss: 0.500333] [G loss: 0.258429]\n",
      "[Epoch 12/100] [Batch 20/347] [D loss: 0.500354] [G loss: 0.271639]\n",
      "[Epoch 12/100] [Batch 21/347] [D loss: 0.500342] [G loss: 0.268112]\n",
      "[Epoch 12/100] [Batch 22/347] [D loss: 0.500330] [G loss: 0.263269]\n",
      "[Epoch 12/100] [Batch 23/347] [D loss: 0.500322] [G loss: 0.257054]\n",
      "[Epoch 12/100] [Batch 24/347] [D loss: 0.500322] [G loss: 0.256363]\n",
      "[Epoch 12/100] [Batch 25/347] [D loss: 0.500320] [G loss: 0.255767]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 26/347] [D loss: 0.500281] [G loss: 0.264661]\n",
      "[Epoch 12/100] [Batch 27/347] [D loss: 0.500292] [G loss: 0.270382]\n",
      "[Epoch 12/100] [Batch 28/347] [D loss: 0.500335] [G loss: 0.269556]\n",
      "[Epoch 12/100] [Batch 29/347] [D loss: 0.500353] [G loss: 0.266600]\n",
      "[Epoch 12/100] [Batch 30/347] [D loss: 0.500370] [G loss: 0.273517]\n",
      "[Epoch 12/100] [Batch 31/347] [D loss: 0.500385] [G loss: 0.276109]\n",
      "[Epoch 12/100] [Batch 32/347] [D loss: 0.500371] [G loss: 0.269788]\n",
      "[Epoch 12/100] [Batch 33/347] [D loss: 0.500347] [G loss: 0.265489]\n",
      "[Epoch 12/100] [Batch 34/347] [D loss: 0.500344] [G loss: 0.266544]\n",
      "[Epoch 12/100] [Batch 35/347] [D loss: 0.500342] [G loss: 0.265320]\n",
      "[Epoch 12/100] [Batch 36/347] [D loss: 0.500322] [G loss: 0.256101]\n",
      "[Epoch 12/100] [Batch 37/347] [D loss: 0.500257] [G loss: 0.275816]\n",
      "[Epoch 12/100] [Batch 38/347] [D loss: 0.500205] [G loss: 0.291088]\n",
      "[Epoch 12/100] [Batch 39/347] [D loss: 0.500214] [G loss: 0.281632]\n",
      "[Epoch 12/100] [Batch 40/347] [D loss: 0.500216] [G loss: 0.282128]\n",
      "[Epoch 12/100] [Batch 41/347] [D loss: 0.500207] [G loss: 0.283516]\n",
      "[Epoch 12/100] [Batch 42/347] [D loss: 0.500219] [G loss: 0.276604]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 43/347] [D loss: 0.500276] [G loss: 0.260518]\n",
      "[Epoch 12/100] [Batch 44/347] [D loss: 0.500326] [G loss: 0.263879]\n",
      "[Epoch 12/100] [Batch 45/347] [D loss: 0.500368] [G loss: 0.281301]\n",
      "[Epoch 12/100] [Batch 46/347] [D loss: 0.500364] [G loss: 0.276092]\n",
      "[Epoch 12/100] [Batch 47/347] [D loss: 0.500288] [G loss: 0.258310]\n",
      "[Epoch 12/100] [Batch 48/347] [D loss: 0.500214] [G loss: 0.290583]\n",
      "[Epoch 12/100] [Batch 49/347] [D loss: 0.500185] [G loss: 0.299168]\n",
      "[Epoch 12/100] [Batch 50/347] [D loss: 0.500172] [G loss: 0.314901]\n",
      "[Epoch 12/100] [Batch 51/347] [D loss: 0.500228] [G loss: 0.299591]\n",
      "[Epoch 12/100] [Batch 52/347] [D loss: 0.500305] [G loss: 0.263210]\n",
      "[Epoch 12/100] [Batch 53/347] [D loss: 0.500291] [G loss: 0.262384]\n",
      "[Epoch 12/100] [Batch 54/347] [D loss: 0.500168] [G loss: 0.314923]\n",
      "[Epoch 12/100] [Batch 55/347] [D loss: 0.500067] [G loss: 0.337303]\n",
      "[Epoch 12/100] [Batch 56/347] [D loss: 0.500084] [G loss: 0.324294]\n",
      "[Epoch 12/100] [Batch 57/347] [D loss: 0.500209] [G loss: 0.290017]\n",
      "[Epoch 12/100] [Batch 58/347] [D loss: 0.500297] [G loss: 0.262056]\n",
      "[Epoch 12/100] [Batch 59/347] [D loss: 0.500269] [G loss: 0.272966]\n",
      "[Epoch 12/100] [Batch 60/347] [D loss: 0.500228] [G loss: 0.291671]\n",
      "[Epoch 12/100] [Batch 61/347] [D loss: 0.500201] [G loss: 0.304110]\n",
      "[Epoch 12/100] [Batch 62/347] [D loss: 0.500130] [G loss: 0.328066]\n",
      "[Epoch 12/100] [Batch 63/347] [D loss: 0.500070] [G loss: 0.330189]\n",
      "[Epoch 12/100] [Batch 64/347] [D loss: 0.500182] [G loss: 0.293431]\n",
      "[Epoch 12/100] [Batch 65/347] [D loss: 0.500329] [G loss: 0.266476]\n",
      "[Epoch 12/100] [Batch 66/347] [D loss: 0.500320] [G loss: 0.268865]\n",
      "[Epoch 12/100] [Batch 67/347] [D loss: 0.500251] [G loss: 0.277196]\n",
      "[Epoch 12/100] [Batch 68/347] [D loss: 0.500209] [G loss: 0.295182]\n",
      "[Epoch 12/100] [Batch 69/347] [D loss: 0.500128] [G loss: 0.313991]\n",
      "[Epoch 12/100] [Batch 70/347] [D loss: 0.500106] [G loss: 0.312765]\n",
      "[Epoch 12/100] [Batch 71/347] [D loss: 0.500126] [G loss: 0.315318]\n",
      "[Epoch 12/100] [Batch 72/347] [D loss: 0.500109] [G loss: 0.317899]\n",
      "[Epoch 12/100] [Batch 73/347] [D loss: 0.500172] [G loss: 0.293182]\n",
      "[Epoch 12/100] [Batch 74/347] [D loss: 0.500247] [G loss: 0.279245]\n",
      "[Epoch 12/100] [Batch 75/347] [D loss: 0.500175] [G loss: 0.309025]\n",
      "[Epoch 12/100] [Batch 76/347] [D loss: 0.500122] [G loss: 0.310947]\n",
      "[Epoch 12/100] [Batch 77/347] [D loss: 0.500216] [G loss: 0.276617]\n",
      "[Epoch 12/100] [Batch 78/347] [D loss: 0.500336] [G loss: 0.273359]\n",
      "[Epoch 12/100] [Batch 79/347] [D loss: 0.500362] [G loss: 0.275059]\n",
      "[Epoch 12/100] [Batch 80/347] [D loss: 0.500346] [G loss: 0.272032]\n",
      "[Epoch 12/100] [Batch 81/347] [D loss: 0.500370] [G loss: 0.277131]\n",
      "[Epoch 12/100] [Batch 82/347] [D loss: 0.500367] [G loss: 0.282532]\n",
      "[Epoch 12/100] [Batch 83/347] [D loss: 0.500351] [G loss: 0.274866]\n",
      "[Epoch 12/100] [Batch 84/347] [D loss: 0.500355] [G loss: 0.280990]\n",
      "[Epoch 12/100] [Batch 85/347] [D loss: 0.500347] [G loss: 0.281703]\n",
      "[Epoch 12/100] [Batch 86/347] [D loss: 0.500335] [G loss: 0.276100]\n",
      "[Epoch 12/100] [Batch 87/347] [D loss: 0.500322] [G loss: 0.273847]\n",
      "[Epoch 12/100] [Batch 88/347] [D loss: 0.500327] [G loss: 0.277144]\n",
      "[Epoch 12/100] [Batch 89/347] [D loss: 0.500329] [G loss: 0.280448]\n",
      "[Epoch 12/100] [Batch 90/347] [D loss: 0.500317] [G loss: 0.276561]\n",
      "[Epoch 12/100] [Batch 91/347] [D loss: 0.500312] [G loss: 0.275053]\n",
      "[Epoch 12/100] [Batch 92/347] [D loss: 0.500311] [G loss: 0.276451]\n",
      "[Epoch 12/100] [Batch 93/347] [D loss: 0.500302] [G loss: 0.274374]\n",
      "[Epoch 12/100] [Batch 94/347] [D loss: 0.500290] [G loss: 0.270731]\n",
      "[Epoch 12/100] [Batch 95/347] [D loss: 0.500290] [G loss: 0.271207]\n",
      "[Epoch 12/100] [Batch 96/347] [D loss: 0.500284] [G loss: 0.266388]\n",
      "[Epoch 12/100] [Batch 97/347] [D loss: 0.500270] [G loss: 0.261240]\n",
      "[Epoch 12/100] [Batch 98/347] [D loss: 0.500269] [G loss: 0.266108]\n",
      "[Epoch 12/100] [Batch 99/347] [D loss: 0.500277] [G loss: 0.269778]\n",
      "[Epoch 12/100] [Batch 100/347] [D loss: 0.500268] [G loss: 0.266070]\n",
      "[Epoch 12/100] [Batch 101/347] [D loss: 0.500252] [G loss: 0.263325]\n",
      "[Epoch 12/100] [Batch 102/347] [D loss: 0.500254] [G loss: 0.264173]\n",
      "[Epoch 12/100] [Batch 103/347] [D loss: 0.500261] [G loss: 0.263779]\n",
      "[Epoch 12/100] [Batch 104/347] [D loss: 0.500235] [G loss: 0.265942]\n",
      "[Epoch 12/100] [Batch 105/347] [D loss: 0.500230] [G loss: 0.267731]\n",
      "[Epoch 12/100] [Batch 106/347] [D loss: 0.500231] [G loss: 0.266834]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 107/347] [D loss: 0.500224] [G loss: 0.260429]\n",
      "[Epoch 12/100] [Batch 108/347] [D loss: 0.500216] [G loss: 0.277448]\n",
      "[Epoch 12/100] [Batch 109/347] [D loss: 0.500243] [G loss: 0.270596]\n",
      "[Epoch 12/100] [Batch 110/347] [D loss: 0.500271] [G loss: 0.258082]\n",
      "[Epoch 12/100] [Batch 111/347] [D loss: 0.500247] [G loss: 0.264739]\n",
      "[Epoch 12/100] [Batch 112/347] [D loss: 0.500253] [G loss: 0.268076]\n",
      "[Epoch 12/100] [Batch 113/347] [D loss: 0.500310] [G loss: 0.273682]\n",
      "[Epoch 12/100] [Batch 114/347] [D loss: 0.500351] [G loss: 0.294448]\n",
      "[Epoch 12/100] [Batch 115/347] [D loss: 0.500356] [G loss: 0.295728]\n",
      "[Epoch 12/100] [Batch 116/347] [D loss: 0.500349] [G loss: 0.289981]\n",
      "[Epoch 12/100] [Batch 117/347] [D loss: 0.500295] [G loss: 0.263392]\n",
      "[Epoch 12/100] [Batch 118/347] [D loss: 0.500215] [G loss: 0.268166]\n",
      "[Epoch 12/100] [Batch 119/347] [D loss: 0.500196] [G loss: 0.270392]\n",
      "[Epoch 12/100] [Batch 120/347] [D loss: 0.500210] [G loss: 0.269372]\n",
      "[Epoch 12/100] [Batch 121/347] [D loss: 0.500209] [G loss: 0.267712]\n",
      "[Epoch 12/100] [Batch 122/347] [D loss: 0.500236] [G loss: 0.254769]\n",
      "[Epoch 12/100] [Batch 123/347] [D loss: 0.500245] [G loss: 0.253811]\n",
      "[Epoch 12/100] [Batch 124/347] [D loss: 0.500233] [G loss: 0.255277]\n",
      "[Epoch 12/100] [Batch 125/347] [D loss: 0.500259] [G loss: 0.261478]\n",
      "[Epoch 12/100] [Batch 126/347] [D loss: 0.500298] [G loss: 0.274232]\n",
      "[Epoch 12/100] [Batch 127/347] [D loss: 0.500308] [G loss: 0.275772]\n",
      "[Epoch 12/100] [Batch 128/347] [D loss: 0.500292] [G loss: 0.270363]\n",
      "[Epoch 12/100] [Batch 129/347] [D loss: 0.500293] [G loss: 0.265568]\n",
      "[Epoch 12/100] [Batch 130/347] [D loss: 0.500286] [G loss: 0.269034]\n",
      "[Epoch 12/100] [Batch 131/347] [D loss: 0.500246] [G loss: 0.267018]\n",
      "[Epoch 12/100] [Batch 132/347] [D loss: 0.500190] [G loss: 0.289381]\n",
      "[Epoch 12/100] [Batch 133/347] [D loss: 0.500170] [G loss: 0.296397]\n",
      "[Epoch 12/100] [Batch 134/347] [D loss: 0.500133] [G loss: 0.311560]\n",
      "[Epoch 12/100] [Batch 135/347] [D loss: 0.500131] [G loss: 0.320797]\n",
      "[Epoch 12/100] [Batch 136/347] [D loss: 0.500217] [G loss: 0.279133]\n",
      "[Epoch 12/100] [Batch 137/347] [D loss: 0.500266] [G loss: 0.267403]\n",
      "[Epoch 12/100] [Batch 138/347] [D loss: 0.500185] [G loss: 0.284537]\n",
      "[Epoch 12/100] [Batch 139/347] [D loss: 0.500106] [G loss: 0.308583]\n",
      "[Epoch 12/100] [Batch 140/347] [D loss: 0.500078] [G loss: 0.320140]\n",
      "[Epoch 12/100] [Batch 141/347] [D loss: 0.500051] [G loss: 0.327133]\n",
      "[Epoch 12/100] [Batch 142/347] [D loss: 0.500035] [G loss: 0.334984]\n",
      "[Epoch 12/100] [Batch 143/347] [D loss: 0.499969] [G loss: 0.356868]\n",
      "[Epoch 12/100] [Batch 144/347] [D loss: 0.499948] [G loss: 0.359196]\n",
      "[Epoch 12/100] [Batch 145/347] [D loss: 0.499955] [G loss: 0.345007]\n",
      "[Epoch 12/100] [Batch 146/347] [D loss: 0.499974] [G loss: 0.328353]\n",
      "[Epoch 12/100] [Batch 147/347] [D loss: 0.500059] [G loss: 0.300397]\n",
      "[Epoch 12/100] [Batch 148/347] [D loss: 0.500108] [G loss: 0.288105]\n",
      "[Epoch 12/100] [Batch 149/347] [D loss: 0.500072] [G loss: 0.301397]\n",
      "[Epoch 12/100] [Batch 150/347] [D loss: 0.500071] [G loss: 0.301907]\n",
      "[Epoch 12/100] [Batch 151/347] [D loss: 0.500128] [G loss: 0.291098]\n",
      "[Epoch 12/100] [Batch 152/347] [D loss: 0.500119] [G loss: 0.302197]\n",
      "[Epoch 12/100] [Batch 153/347] [D loss: 0.500047] [G loss: 0.322948]\n",
      "[Epoch 12/100] [Batch 154/347] [D loss: 0.499999] [G loss: 0.327204]\n",
      "[Epoch 12/100] [Batch 155/347] [D loss: 0.500028] [G loss: 0.314428]\n",
      "[Epoch 12/100] [Batch 156/347] [D loss: 0.500088] [G loss: 0.298023]\n",
      "[Epoch 12/100] [Batch 157/347] [D loss: 0.500115] [G loss: 0.304425]\n",
      "[Epoch 12/100] [Batch 158/347] [D loss: 0.500035] [G loss: 0.328183]\n",
      "[Epoch 12/100] [Batch 159/347] [D loss: 0.500003] [G loss: 0.325760]\n",
      "[Epoch 12/100] [Batch 160/347] [D loss: 0.500098] [G loss: 0.305959]\n",
      "[Epoch 12/100] [Batch 161/347] [D loss: 0.500156] [G loss: 0.297599]\n",
      "[Epoch 12/100] [Batch 162/347] [D loss: 0.500134] [G loss: 0.303487]\n",
      "[Epoch 12/100] [Batch 163/347] [D loss: 0.500072] [G loss: 0.322287]\n",
      "[Epoch 12/100] [Batch 164/347] [D loss: 0.500008] [G loss: 0.337580]\n",
      "[Epoch 12/100] [Batch 165/347] [D loss: 0.500007] [G loss: 0.328791]\n",
      "[Epoch 12/100] [Batch 166/347] [D loss: 0.500116] [G loss: 0.290647]\n",
      "[Epoch 12/100] [Batch 167/347] [D loss: 0.500250] [G loss: 0.270622]\n",
      "[Epoch 12/100] [Batch 168/347] [D loss: 0.500293] [G loss: 0.281262]\n",
      "[Epoch 12/100] [Batch 169/347] [D loss: 0.500313] [G loss: 0.280046]\n",
      "[Epoch 12/100] [Batch 170/347] [D loss: 0.500327] [G loss: 0.276197]\n",
      "[Epoch 12/100] [Batch 171/347] [D loss: 0.500362] [G loss: 0.286159]\n",
      "[Epoch 12/100] [Batch 172/347] [D loss: 0.500373] [G loss: 0.291010]\n",
      "[Epoch 12/100] [Batch 173/347] [D loss: 0.500339] [G loss: 0.279736]\n",
      "[Epoch 12/100] [Batch 174/347] [D loss: 0.500324] [G loss: 0.277194]\n",
      "[Epoch 12/100] [Batch 175/347] [D loss: 0.500342] [G loss: 0.286952]\n",
      "[Epoch 12/100] [Batch 176/347] [D loss: 0.500383] [G loss: 0.300285]\n",
      "[Epoch 12/100] [Batch 177/347] [D loss: 0.500382] [G loss: 0.301064]\n",
      "[Epoch 12/100] [Batch 178/347] [D loss: 0.500363] [G loss: 0.295007]\n",
      "[Epoch 12/100] [Batch 179/347] [D loss: 0.500340] [G loss: 0.288244]\n",
      "[Epoch 12/100] [Batch 180/347] [D loss: 0.500315] [G loss: 0.281743]\n",
      "[Epoch 12/100] [Batch 181/347] [D loss: 0.500317] [G loss: 0.282063]\n",
      "[Epoch 12/100] [Batch 182/347] [D loss: 0.500296] [G loss: 0.279845]\n",
      "[Epoch 12/100] [Batch 183/347] [D loss: 0.500311] [G loss: 0.283778]\n",
      "[Epoch 12/100] [Batch 184/347] [D loss: 0.500314] [G loss: 0.287500]\n",
      "[Epoch 12/100] [Batch 185/347] [D loss: 0.500312] [G loss: 0.285953]\n",
      "[Epoch 12/100] [Batch 186/347] [D loss: 0.500313] [G loss: 0.285685]\n",
      "[Epoch 12/100] [Batch 187/347] [D loss: 0.500300] [G loss: 0.280313]\n",
      "[Epoch 12/100] [Batch 188/347] [D loss: 0.500284] [G loss: 0.277009]\n",
      "[Epoch 12/100] [Batch 189/347] [D loss: 0.500276] [G loss: 0.276101]\n",
      "[Epoch 12/100] [Batch 190/347] [D loss: 0.500234] [G loss: 0.264111]\n",
      "[Epoch 12/100] [Batch 191/347] [D loss: 0.500176] [G loss: 0.263825]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 192/347] [D loss: 0.500201] [G loss: 0.254423]\n",
      "[Epoch 12/100] [Batch 193/347] [D loss: 0.500235] [G loss: 0.262015]\n",
      "[Epoch 12/100] [Batch 194/347] [D loss: 0.500201] [G loss: 0.258444]\n",
      "[Epoch 12/100] [Batch 195/347] [D loss: 0.500175] [G loss: 0.267154]\n",
      "[Epoch 12/100] [Batch 196/347] [D loss: 0.500159] [G loss: 0.264817]\n",
      "[Epoch 12/100] [Batch 197/347] [D loss: 0.500167] [G loss: 0.260036]\n",
      "[Epoch 12/100] [Batch 198/347] [D loss: 0.500186] [G loss: 0.258507]\n",
      "[Epoch 12/100] [Batch 199/347] [D loss: 0.500183] [G loss: 0.259686]\n",
      "[Epoch 12/100] [Batch 200/347] [D loss: 0.500191] [G loss: 0.254607]\n",
      "[Epoch 12/100] [Batch 201/347] [D loss: 0.500197] [G loss: 0.255470]\n",
      "[Epoch 12/100] [Batch 202/347] [D loss: 0.500163] [G loss: 0.267001]\n",
      "[Epoch 12/100] [Batch 203/347] [D loss: 0.500135] [G loss: 0.275531]\n",
      "[Epoch 12/100] [Batch 204/347] [D loss: 0.500149] [G loss: 0.271935]\n",
      "[Epoch 12/100] [Batch 205/347] [D loss: 0.500167] [G loss: 0.263961]\n",
      "[Epoch 12/100] [Batch 206/347] [D loss: 0.500201] [G loss: 0.255291]\n",
      "[Epoch 12/100] [Batch 207/347] [D loss: 0.500256] [G loss: 0.266113]\n",
      "[Epoch 12/100] [Batch 208/347] [D loss: 0.500244] [G loss: 0.266980]\n",
      "[Epoch 12/100] [Batch 209/347] [D loss: 0.500221] [G loss: 0.261399]\n",
      "[Epoch 12/100] [Batch 210/347] [D loss: 0.500262] [G loss: 0.268367]\n",
      "[Epoch 12/100] [Batch 211/347] [D loss: 0.500255] [G loss: 0.265666]\n",
      "[Epoch 12/100] [Batch 212/347] [D loss: 0.500242] [G loss: 0.264473]\n",
      "[Epoch 12/100] [Batch 213/347] [D loss: 0.500239] [G loss: 0.270078]\n",
      "[Epoch 12/100] [Batch 214/347] [D loss: 0.500185] [G loss: 0.277112]\n",
      "[Epoch 12/100] [Batch 215/347] [D loss: 0.500162] [G loss: 0.285442]\n",
      "[Epoch 12/100] [Batch 216/347] [D loss: 0.500214] [G loss: 0.269153]\n",
      "[Epoch 12/100] [Batch 217/347] [D loss: 0.500248] [G loss: 0.269764]\n",
      "[Epoch 12/100] [Batch 218/347] [D loss: 0.500280] [G loss: 0.276363]\n",
      "[Epoch 12/100] [Batch 219/347] [D loss: 0.500324] [G loss: 0.288477]\n",
      "[Epoch 12/100] [Batch 220/347] [D loss: 0.500376] [G loss: 0.304271]\n",
      "[Epoch 12/100] [Batch 221/347] [D loss: 0.500382] [G loss: 0.305599]\n",
      "[Epoch 12/100] [Batch 222/347] [D loss: 0.500368] [G loss: 0.297549]\n",
      "[Epoch 12/100] [Batch 223/347] [D loss: 0.500365] [G loss: 0.296102]\n",
      "[Epoch 12/100] [Batch 224/347] [D loss: 0.500354] [G loss: 0.291843]\n",
      "[Epoch 12/100] [Batch 225/347] [D loss: 0.500277] [G loss: 0.278013]\n",
      "[Epoch 12/100] [Batch 226/347] [D loss: 0.500149] [G loss: 0.273202]\n",
      "[Epoch 12/100] [Batch 227/347] [D loss: 0.500072] [G loss: 0.283648]\n",
      "[Epoch 12/100] [Batch 228/347] [D loss: 0.500063] [G loss: 0.285591]\n",
      "[Epoch 12/100] [Batch 229/347] [D loss: 0.500094] [G loss: 0.280889]\n",
      "[Epoch 12/100] [Batch 230/347] [D loss: 0.500113] [G loss: 0.277233]\n",
      "[Epoch 12/100] [Batch 231/347] [D loss: 0.500089] [G loss: 0.277303]\n",
      "[Epoch 12/100] [Batch 232/347] [D loss: 0.500110] [G loss: 0.273262]\n",
      "[Epoch 12/100] [Batch 233/347] [D loss: 0.500121] [G loss: 0.271027]\n",
      "[Epoch 12/100] [Batch 234/347] [D loss: 0.500119] [G loss: 0.275996]\n",
      "[Epoch 12/100] [Batch 235/347] [D loss: 0.500167] [G loss: 0.264824]\n",
      "[Epoch 12/100] [Batch 236/347] [D loss: 0.500215] [G loss: 0.264476]\n",
      "[Epoch 12/100] [Batch 237/347] [D loss: 0.500247] [G loss: 0.267843]\n",
      "[Epoch 12/100] [Batch 238/347] [D loss: 0.500247] [G loss: 0.271869]\n",
      "[Epoch 12/100] [Batch 239/347] [D loss: 0.500236] [G loss: 0.269907]\n",
      "[Epoch 12/100] [Batch 240/347] [D loss: 0.500231] [G loss: 0.266051]\n",
      "[Epoch 12/100] [Batch 241/347] [D loss: 0.500212] [G loss: 0.260153]\n",
      "[Epoch 12/100] [Batch 242/347] [D loss: 0.500202] [G loss: 0.258103]\n",
      "[Epoch 12/100] [Batch 243/347] [D loss: 0.500220] [G loss: 0.265569]\n",
      "[Epoch 12/100] [Batch 244/347] [D loss: 0.500244] [G loss: 0.274229]\n",
      "[Epoch 12/100] [Batch 245/347] [D loss: 0.500272] [G loss: 0.272718]\n",
      "[Epoch 12/100] [Batch 246/347] [D loss: 0.500203] [G loss: 0.265819]\n",
      "[Epoch 12/100] [Batch 247/347] [D loss: 0.500112] [G loss: 0.272017]\n",
      "[Epoch 12/100] [Batch 248/347] [D loss: 0.500074] [G loss: 0.277483]\n",
      "[Epoch 12/100] [Batch 249/347] [D loss: 0.500054] [G loss: 0.283596]\n",
      "[Epoch 12/100] [Batch 250/347] [D loss: 0.500118] [G loss: 0.275079]\n",
      "[Epoch 12/100] [Batch 251/347] [D loss: 0.500201] [G loss: 0.265654]\n",
      "[Epoch 12/100] [Batch 252/347] [D loss: 0.500234] [G loss: 0.268856]\n",
      "[Epoch 12/100] [Batch 253/347] [D loss: 0.500236] [G loss: 0.269449]\n",
      "[Epoch 12/100] [Batch 254/347] [D loss: 0.500232] [G loss: 0.267842]\n",
      "[Epoch 12/100] [Batch 255/347] [D loss: 0.500215] [G loss: 0.266418]\n",
      "[Epoch 12/100] [Batch 256/347] [D loss: 0.500233] [G loss: 0.271574]\n",
      "[Epoch 12/100] [Batch 257/347] [D loss: 0.500265] [G loss: 0.273259]\n",
      "[Epoch 12/100] [Batch 258/347] [D loss: 0.500227] [G loss: 0.267936]\n",
      "[Epoch 12/100] [Batch 259/347] [D loss: 0.500134] [G loss: 0.274383]\n",
      "[Epoch 12/100] [Batch 260/347] [D loss: 0.500089] [G loss: 0.288775]\n",
      "[Epoch 12/100] [Batch 261/347] [D loss: 0.500123] [G loss: 0.281276]\n",
      "[Epoch 12/100] [Batch 262/347] [D loss: 0.500145] [G loss: 0.266154]\n",
      "[Epoch 12/100] [Batch 263/347] [D loss: 0.500142] [G loss: 0.267071]\n",
      "[Epoch 12/100] [Batch 264/347] [D loss: 0.500113] [G loss: 0.281558]\n",
      "[Epoch 12/100] [Batch 265/347] [D loss: 0.500093] [G loss: 0.286730]\n",
      "[Epoch 12/100] [Batch 266/347] [D loss: 0.500105] [G loss: 0.279572]\n",
      "[Epoch 12/100] [Batch 267/347] [D loss: 0.500116] [G loss: 0.272783]\n",
      "[Epoch 12/100] [Batch 268/347] [D loss: 0.500113] [G loss: 0.279637]\n",
      "[Epoch 12/100] [Batch 269/347] [D loss: 0.500091] [G loss: 0.290729]\n",
      "[Epoch 12/100] [Batch 270/347] [D loss: 0.500092] [G loss: 0.287311]\n",
      "[Epoch 12/100] [Batch 271/347] [D loss: 0.500114] [G loss: 0.275445]\n",
      "[Epoch 12/100] [Batch 272/347] [D loss: 0.500141] [G loss: 0.266764]\n",
      "[Epoch 12/100] [Batch 273/347] [D loss: 0.500132] [G loss: 0.278542]\n",
      "[Epoch 12/100] [Batch 274/347] [D loss: 0.500082] [G loss: 0.312320]\n",
      "[Epoch 12/100] [Batch 275/347] [D loss: 0.500081] [G loss: 0.309174]\n",
      "[Epoch 12/100] [Batch 276/347] [D loss: 0.500123] [G loss: 0.276752]\n",
      "[Epoch 12/100] [Batch 277/347] [D loss: 0.500153] [G loss: 0.262057]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 278/347] [D loss: 0.500179] [G loss: 0.254234]\n",
      "[Epoch 12/100] [Batch 279/347] [D loss: 0.500181] [G loss: 0.260823]\n",
      "[Epoch 12/100] [Batch 280/347] [D loss: 0.500175] [G loss: 0.264392]\n",
      "[Epoch 12/100] [Batch 281/347] [D loss: 0.500175] [G loss: 0.262657]\n",
      "[Epoch 12/100] [Batch 282/347] [D loss: 0.500173] [G loss: 0.260505]\n",
      "[Epoch 12/100] [Batch 283/347] [D loss: 0.500156] [G loss: 0.262996]\n",
      "[Epoch 12/100] [Batch 284/347] [D loss: 0.500169] [G loss: 0.263214]\n",
      "[Epoch 12/100] [Batch 285/347] [D loss: 0.500178] [G loss: 0.259085]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 12/100] [Batch 286/347] [D loss: 0.500161] [G loss: 0.252898]\n",
      "[Epoch 12/100] [Batch 287/347] [D loss: 0.500160] [G loss: 0.256438]\n",
      "[Epoch 12/100] [Batch 288/347] [D loss: 0.500071] [G loss: 0.282910]\n",
      "[Epoch 12/100] [Batch 289/347] [D loss: 0.500051] [G loss: 0.287012]\n",
      "[Epoch 12/100] [Batch 290/347] [D loss: 0.500121] [G loss: 0.264302]\n",
      "[Epoch 12/100] [Batch 291/347] [D loss: 0.500107] [G loss: 0.266792]\n",
      "[Epoch 12/100] [Batch 292/347] [D loss: 0.500142] [G loss: 0.257970]\n",
      "[Epoch 12/100] [Batch 293/347] [D loss: 0.500237] [G loss: 0.271332]\n",
      "[Epoch 12/100] [Batch 294/347] [D loss: 0.500277] [G loss: 0.281343]\n",
      "[Epoch 12/100] [Batch 295/347] [D loss: 0.500245] [G loss: 0.279118]\n",
      "[Epoch 12/100] [Batch 296/347] [D loss: 0.500252] [G loss: 0.275231]\n",
      "[Epoch 12/100] [Batch 297/347] [D loss: 0.500277] [G loss: 0.286826]\n",
      "[Epoch 12/100] [Batch 298/347] [D loss: 0.500257] [G loss: 0.281774]\n",
      "[Epoch 12/100] [Batch 299/347] [D loss: 0.500265] [G loss: 0.280449]\n",
      "[Epoch 12/100] [Batch 300/347] [D loss: 0.500249] [G loss: 0.275765]\n",
      "[Epoch 12/100] [Batch 301/347] [D loss: 0.500260] [G loss: 0.277139]\n",
      "[Epoch 12/100] [Batch 302/347] [D loss: 0.500282] [G loss: 0.282225]\n",
      "[Epoch 12/100] [Batch 303/347] [D loss: 0.500196] [G loss: 0.266531]\n",
      "[Epoch 12/100] [Batch 304/347] [D loss: 0.500105] [G loss: 0.265138]\n",
      "[Epoch 12/100] [Batch 305/347] [D loss: 0.500084] [G loss: 0.277961]\n",
      "[Epoch 12/100] [Batch 306/347] [D loss: 0.500076] [G loss: 0.269813]\n",
      "[Epoch 12/100] [Batch 307/347] [D loss: 0.500068] [G loss: 0.282424]\n",
      "[Epoch 12/100] [Batch 308/347] [D loss: 0.500068] [G loss: 0.278609]\n",
      "[Epoch 12/100] [Batch 309/347] [D loss: 0.500137] [G loss: 0.258446]\n",
      "[Epoch 12/100] [Batch 310/347] [D loss: 0.500204] [G loss: 0.278775]\n",
      "[Epoch 12/100] [Batch 311/347] [D loss: 0.500207] [G loss: 0.281718]\n",
      "[Epoch 12/100] [Batch 312/347] [D loss: 0.500202] [G loss: 0.281497]\n",
      "[Epoch 12/100] [Batch 313/347] [D loss: 0.500209] [G loss: 0.280737]\n",
      "[Epoch 12/100] [Batch 314/347] [D loss: 0.500211] [G loss: 0.274358]\n",
      "[Epoch 12/100] [Batch 315/347] [D loss: 0.500215] [G loss: 0.265033]\n",
      "[Epoch 12/100] [Batch 316/347] [D loss: 0.500138] [G loss: 0.258432]\n",
      "[Epoch 12/100] [Batch 317/347] [D loss: 0.500062] [G loss: 0.277021]\n",
      "[Epoch 12/100] [Batch 318/347] [D loss: 0.500143] [G loss: 0.254841]\n",
      "[Epoch 12/100] [Batch 319/347] [D loss: 0.500247] [G loss: 0.287059]\n",
      "[Epoch 12/100] [Batch 320/347] [D loss: 0.500285] [G loss: 0.300712]\n",
      "[Epoch 12/100] [Batch 321/347] [D loss: 0.500263] [G loss: 0.290292]\n",
      "[Epoch 12/100] [Batch 322/347] [D loss: 0.500226] [G loss: 0.277336]\n",
      "[Epoch 12/100] [Batch 323/347] [D loss: 0.500226] [G loss: 0.276550]\n",
      "[Epoch 12/100] [Batch 324/347] [D loss: 0.500237] [G loss: 0.279470]\n",
      "[Epoch 12/100] [Batch 325/347] [D loss: 0.500209] [G loss: 0.268629]\n",
      "[Epoch 12/100] [Batch 326/347] [D loss: 0.500170] [G loss: 0.258041]\n",
      "[Epoch 12/100] [Batch 327/347] [D loss: 0.500170] [G loss: 0.256044]\n",
      "[Epoch 12/100] [Batch 328/347] [D loss: 0.500153] [G loss: 0.253874]\n",
      "[Epoch 12/100] [Batch 329/347] [D loss: 0.500092] [G loss: 0.273711]\n",
      "[Epoch 12/100] [Batch 330/347] [D loss: 0.500033] [G loss: 0.289480]\n",
      "[Epoch 12/100] [Batch 331/347] [D loss: 0.500084] [G loss: 0.271511]\n",
      "[Epoch 12/100] [Batch 332/347] [D loss: 0.500175] [G loss: 0.267074]\n",
      "[Epoch 12/100] [Batch 333/347] [D loss: 0.500193] [G loss: 0.278337]\n",
      "[Epoch 12/100] [Batch 334/347] [D loss: 0.500214] [G loss: 0.279695]\n",
      "[Epoch 12/100] [Batch 335/347] [D loss: 0.500195] [G loss: 0.267656]\n",
      "[Epoch 12/100] [Batch 336/347] [D loss: 0.500153] [G loss: 0.253261]\n",
      "[Epoch 12/100] [Batch 337/347] [D loss: 0.500158] [G loss: 0.259173]\n",
      "[Epoch 12/100] [Batch 338/347] [D loss: 0.500187] [G loss: 0.273650]\n",
      "[Epoch 12/100] [Batch 339/347] [D loss: 0.500203] [G loss: 0.278870]\n",
      "[Epoch 12/100] [Batch 340/347] [D loss: 0.500199] [G loss: 0.279090]\n",
      "[Epoch 12/100] [Batch 341/347] [D loss: 0.500194] [G loss: 0.274151]\n",
      "[Epoch 12/100] [Batch 342/347] [D loss: 0.500171] [G loss: 0.266462]\n",
      "[Epoch 12/100] [Batch 343/347] [D loss: 0.500162] [G loss: 0.271057]\n",
      "[Epoch 12/100] [Batch 344/347] [D loss: 0.500136] [G loss: 0.266334]\n",
      "[Epoch 12/100] [Batch 345/347] [D loss: 0.500050] [G loss: 0.276455]\n",
      "[Epoch 12/100] [Batch 346/347] [D loss: 0.500003] [G loss: 0.294979]\n",
      "[Epoch 12/100] [Batch 347/347] [D loss: 0.499996] [G loss: 0.301330]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 13/100] [Batch 1/347] [D loss: 0.500104] [G loss: 0.267718]\n",
      "[Epoch 13/100] [Batch 2/347] [D loss: 0.500097] [G loss: 0.272974]\n",
      "[Epoch 13/100] [Batch 3/347] [D loss: 0.500118] [G loss: 0.272916]\n",
      "[Epoch 13/100] [Batch 4/347] [D loss: 0.500119] [G loss: 0.274162]\n",
      "[Epoch 13/100] [Batch 5/347] [D loss: 0.500117] [G loss: 0.273385]\n",
      "[Epoch 13/100] [Batch 6/347] [D loss: 0.500123] [G loss: 0.273678]\n",
      "[Epoch 13/100] [Batch 7/347] [D loss: 0.500111] [G loss: 0.273469]\n",
      "[Epoch 13/100] [Batch 8/347] [D loss: 0.500116] [G loss: 0.268747]\n",
      "[Epoch 13/100] [Batch 9/347] [D loss: 0.500090] [G loss: 0.267726]\n",
      "[Epoch 13/100] [Batch 10/347] [D loss: 0.500085] [G loss: 0.269220]\n",
      "[Epoch 13/100] [Batch 11/347] [D loss: 0.500120] [G loss: 0.268949]\n",
      "[Epoch 13/100] [Batch 12/347] [D loss: 0.500133] [G loss: 0.269393]\n",
      "[Epoch 13/100] [Batch 13/347] [D loss: 0.500149] [G loss: 0.267989]\n",
      "[Epoch 13/100] [Batch 14/347] [D loss: 0.500167] [G loss: 0.270340]\n",
      "[Epoch 13/100] [Batch 15/347] [D loss: 0.500160] [G loss: 0.266576]\n",
      "[Epoch 13/100] [Batch 16/347] [D loss: 0.500151] [G loss: 0.262489]\n",
      "[Epoch 13/100] [Batch 17/347] [D loss: 0.500136] [G loss: 0.253609]\n",
      "[Epoch 13/100] [Batch 18/347] [D loss: 0.500119] [G loss: 0.259507]\n",
      "[Epoch 13/100] [Batch 19/347] [D loss: 0.500153] [G loss: 0.256291]\n",
      "[Epoch 13/100] [Batch 20/347] [D loss: 0.500180] [G loss: 0.269520]\n",
      "[Epoch 13/100] [Batch 21/347] [D loss: 0.500163] [G loss: 0.265983]\n",
      "[Epoch 13/100] [Batch 22/347] [D loss: 0.500149] [G loss: 0.261147]\n",
      "[Epoch 13/100] [Batch 23/347] [D loss: 0.500138] [G loss: 0.254961]\n",
      "[Epoch 13/100] [Batch 24/347] [D loss: 0.500146] [G loss: 0.254269]\n",
      "[Epoch 13/100] [Batch 25/347] [D loss: 0.500141] [G loss: 0.253866]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 13/100] [Batch 26/347] [D loss: 0.500097] [G loss: 0.263346]\n",
      "[Epoch 13/100] [Batch 27/347] [D loss: 0.500114] [G loss: 0.268800]\n",
      "[Epoch 13/100] [Batch 28/347] [D loss: 0.500165] [G loss: 0.268706]\n",
      "[Epoch 13/100] [Batch 29/347] [D loss: 0.500189] [G loss: 0.265730]\n",
      "[Epoch 13/100] [Batch 30/347] [D loss: 0.500213] [G loss: 0.272849]\n",
      "[Epoch 13/100] [Batch 31/347] [D loss: 0.500232] [G loss: 0.275617]\n",
      "[Epoch 13/100] [Batch 32/347] [D loss: 0.500216] [G loss: 0.269926]\n",
      "[Epoch 13/100] [Batch 33/347] [D loss: 0.500191] [G loss: 0.265298]\n",
      "[Epoch 13/100] [Batch 34/347] [D loss: 0.500191] [G loss: 0.266485]\n",
      "[Epoch 13/100] [Batch 35/347] [D loss: 0.500188] [G loss: 0.265427]\n",
      "[Epoch 13/100] [Batch 36/347] [D loss: 0.500162] [G loss: 0.256538]\n",
      "[Epoch 13/100] [Batch 37/347] [D loss: 0.500082] [G loss: 0.272519]\n",
      "[Epoch 13/100] [Batch 38/347] [D loss: 0.500020] [G loss: 0.287691]\n",
      "[Epoch 13/100] [Batch 39/347] [D loss: 0.500032] [G loss: 0.278147]\n",
      "[Epoch 13/100] [Batch 40/347] [D loss: 0.500037] [G loss: 0.278162]\n",
      "[Epoch 13/100] [Batch 41/347] [D loss: 0.500024] [G loss: 0.279553]\n",
      "[Epoch 13/100] [Batch 42/347] [D loss: 0.500045] [G loss: 0.272593]\n",
      "[Epoch 13/100] [Batch 43/347] [D loss: 0.500116] [G loss: 0.256740]\n",
      "[Epoch 13/100] [Batch 44/347] [D loss: 0.500179] [G loss: 0.264934]\n",
      "[Epoch 13/100] [Batch 45/347] [D loss: 0.500227] [G loss: 0.282342]\n",
      "[Epoch 13/100] [Batch 46/347] [D loss: 0.500223] [G loss: 0.277146]\n",
      "[Epoch 13/100] [Batch 47/347] [D loss: 0.500134] [G loss: 0.254476]\n",
      "[Epoch 13/100] [Batch 48/347] [D loss: 0.500041] [G loss: 0.286743]\n",
      "[Epoch 13/100] [Batch 49/347] [D loss: 0.500009] [G loss: 0.295289]\n",
      "[Epoch 13/100] [Batch 50/347] [D loss: 0.499995] [G loss: 0.310968]\n",
      "[Epoch 13/100] [Batch 51/347] [D loss: 0.500064] [G loss: 0.295595]\n",
      "[Epoch 13/100] [Batch 52/347] [D loss: 0.500157] [G loss: 0.264634]\n",
      "[Epoch 13/100] [Batch 53/347] [D loss: 0.500139] [G loss: 0.259153]\n",
      "[Epoch 13/100] [Batch 54/347] [D loss: 0.499990] [G loss: 0.311197]\n",
      "[Epoch 13/100] [Batch 55/347] [D loss: 0.499868] [G loss: 0.333868]\n",
      "[Epoch 13/100] [Batch 56/347] [D loss: 0.499889] [G loss: 0.321113]\n",
      "[Epoch 13/100] [Batch 57/347] [D loss: 0.500040] [G loss: 0.287093]\n",
      "[Epoch 13/100] [Batch 58/347] [D loss: 0.500146] [G loss: 0.261873]\n",
      "[Epoch 13/100] [Batch 59/347] [D loss: 0.500117] [G loss: 0.270368]\n",
      "[Epoch 13/100] [Batch 60/347] [D loss: 0.500061] [G loss: 0.289224]\n",
      "[Epoch 13/100] [Batch 61/347] [D loss: 0.500027] [G loss: 0.301870]\n",
      "[Epoch 13/100] [Batch 62/347] [D loss: 0.499941] [G loss: 0.325961]\n",
      "[Epoch 13/100] [Batch 63/347] [D loss: 0.499871] [G loss: 0.328256]\n",
      "[Epoch 13/100] [Batch 64/347] [D loss: 0.500008] [G loss: 0.291547]\n",
      "[Epoch 13/100] [Batch 65/347] [D loss: 0.500187] [G loss: 0.265048]\n",
      "[Epoch 13/100] [Batch 66/347] [D loss: 0.500174] [G loss: 0.267337]\n",
      "[Epoch 13/100] [Batch 67/347] [D loss: 0.500091] [G loss: 0.275605]\n",
      "[Epoch 13/100] [Batch 68/347] [D loss: 0.500039] [G loss: 0.293717]\n",
      "[Epoch 13/100] [Batch 69/347] [D loss: 0.499941] [G loss: 0.312624]\n",
      "[Epoch 13/100] [Batch 70/347] [D loss: 0.499912] [G loss: 0.311461]\n",
      "[Epoch 13/100] [Batch 71/347] [D loss: 0.499941] [G loss: 0.314024]\n",
      "[Epoch 13/100] [Batch 72/347] [D loss: 0.499923] [G loss: 0.316623]\n",
      "[Epoch 13/100] [Batch 73/347] [D loss: 0.500000] [G loss: 0.291956]\n",
      "[Epoch 13/100] [Batch 74/347] [D loss: 0.500091] [G loss: 0.278061]\n",
      "[Epoch 13/100] [Batch 75/347] [D loss: 0.500002] [G loss: 0.307868]\n",
      "[Epoch 13/100] [Batch 76/347] [D loss: 0.499938] [G loss: 0.309894]\n",
      "[Epoch 13/100] [Batch 77/347] [D loss: 0.500056] [G loss: 0.275597]\n",
      "[Epoch 13/100] [Batch 78/347] [D loss: 0.500200] [G loss: 0.270952]\n",
      "[Epoch 13/100] [Batch 79/347] [D loss: 0.500228] [G loss: 0.272802]\n",
      "[Epoch 13/100] [Batch 80/347] [D loss: 0.500208] [G loss: 0.270231]\n",
      "[Epoch 13/100] [Batch 81/347] [D loss: 0.500238] [G loss: 0.275269]\n",
      "[Epoch 13/100] [Batch 82/347] [D loss: 0.500239] [G loss: 0.280142]\n",
      "[Epoch 13/100] [Batch 83/347] [D loss: 0.500219] [G loss: 0.272507]\n",
      "[Epoch 13/100] [Batch 84/347] [D loss: 0.500221] [G loss: 0.279063]\n",
      "[Epoch 13/100] [Batch 85/347] [D loss: 0.500214] [G loss: 0.279744]\n",
      "[Epoch 13/100] [Batch 86/347] [D loss: 0.500198] [G loss: 0.274089]\n",
      "[Epoch 13/100] [Batch 87/347] [D loss: 0.500185] [G loss: 0.271881]\n",
      "[Epoch 13/100] [Batch 88/347] [D loss: 0.500187] [G loss: 0.275198]\n",
      "[Epoch 13/100] [Batch 89/347] [D loss: 0.500191] [G loss: 0.278504]\n",
      "[Epoch 13/100] [Batch 90/347] [D loss: 0.500182] [G loss: 0.274678]\n",
      "[Epoch 13/100] [Batch 91/347] [D loss: 0.500174] [G loss: 0.273155]\n",
      "[Epoch 13/100] [Batch 92/347] [D loss: 0.500175] [G loss: 0.274565]\n",
      "[Epoch 13/100] [Batch 93/347] [D loss: 0.500167] [G loss: 0.272535]\n",
      "[Epoch 13/100] [Batch 94/347] [D loss: 0.500154] [G loss: 0.268931]\n",
      "[Epoch 13/100] [Batch 95/347] [D loss: 0.500158] [G loss: 0.269419]\n",
      "[Epoch 13/100] [Batch 96/347] [D loss: 0.500146] [G loss: 0.264642]\n",
      "[Epoch 13/100] [Batch 97/347] [D loss: 0.500124] [G loss: 0.259530]\n",
      "[Epoch 13/100] [Batch 98/347] [D loss: 0.500129] [G loss: 0.264418]\n",
      "[Epoch 13/100] [Batch 99/347] [D loss: 0.500139] [G loss: 0.268082]\n",
      "[Epoch 13/100] [Batch 100/347] [D loss: 0.500131] [G loss: 0.264466]\n",
      "[Epoch 13/100] [Batch 101/347] [D loss: 0.500110] [G loss: 0.262763]\n",
      "[Epoch 13/100] [Batch 102/347] [D loss: 0.500114] [G loss: 0.263590]\n",
      "[Epoch 13/100] [Batch 103/347] [D loss: 0.500120] [G loss: 0.263032]\n",
      "[Epoch 13/100] [Batch 104/347] [D loss: 0.500094] [G loss: 0.264921]\n",
      "[Epoch 13/100] [Batch 105/347] [D loss: 0.500091] [G loss: 0.266313]\n",
      "[Epoch 13/100] [Batch 106/347] [D loss: 0.500095] [G loss: 0.265106]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 13/100] [Batch 107/347] [D loss: 0.500088] [G loss: 0.258683]\n",
      "[Epoch 13/100] [Batch 108/347] [D loss: 0.500078] [G loss: 0.275476]\n",
      "[Epoch 13/100] [Batch 109/347] [D loss: 0.500109] [G loss: 0.268449]\n",
      "[Epoch 13/100] [Batch 110/347] [D loss: 0.500148] [G loss: 0.258236]\n",
      "[Epoch 13/100] [Batch 111/347] [D loss: 0.500119] [G loss: 0.263387]\n",
      "[Epoch 13/100] [Batch 112/347] [D loss: 0.500128] [G loss: 0.268614]\n",
      "[Epoch 13/100] [Batch 113/347] [D loss: 0.500194] [G loss: 0.273642]\n",
      "[Epoch 13/100] [Batch 114/347] [D loss: 0.500245] [G loss: 0.294230]\n",
      "[Epoch 13/100] [Batch 115/347] [D loss: 0.500248] [G loss: 0.295357]\n",
      "[Epoch 13/100] [Batch 116/347] [D loss: 0.500239] [G loss: 0.289505]\n",
      "[Epoch 13/100] [Batch 117/347] [D loss: 0.500176] [G loss: 0.263033]\n",
      "[Epoch 13/100] [Batch 118/347] [D loss: 0.500083] [G loss: 0.266689]\n",
      "[Epoch 13/100] [Batch 119/347] [D loss: 0.500062] [G loss: 0.268950]\n",
      "[Epoch 13/100] [Batch 120/347] [D loss: 0.500072] [G loss: 0.267993]\n",
      "[Epoch 13/100] [Batch 121/347] [D loss: 0.500072] [G loss: 0.266366]\n",
      "[Epoch 13/100] [Batch 122/347] [D loss: 0.500107] [G loss: 0.253581]\n",
      "[Epoch 13/100] [Batch 123/347] [D loss: 0.500116] [G loss: 0.252706]\n",
      "[Epoch 13/100] [Batch 124/347] [D loss: 0.500100] [G loss: 0.254115]\n",
      "[Epoch 13/100] [Batch 125/347] [D loss: 0.500139] [G loss: 0.260353]\n",
      "[Epoch 13/100] [Batch 126/347] [D loss: 0.500182] [G loss: 0.273064]\n",
      "[Epoch 13/100] [Batch 127/347] [D loss: 0.500194] [G loss: 0.274565]\n",
      "[Epoch 13/100] [Batch 128/347] [D loss: 0.500172] [G loss: 0.269101]\n",
      "[Epoch 13/100] [Batch 129/347] [D loss: 0.500170] [G loss: 0.264211]\n",
      "[Epoch 13/100] [Batch 130/347] [D loss: 0.500167] [G loss: 0.267675]\n",
      "[Epoch 13/100] [Batch 131/347] [D loss: 0.500117] [G loss: 0.265638]\n",
      "[Epoch 13/100] [Batch 132/347] [D loss: 0.500051] [G loss: 0.288503]\n",
      "[Epoch 13/100] [Batch 133/347] [D loss: 0.500028] [G loss: 0.295510]\n",
      "[Epoch 13/100] [Batch 134/347] [D loss: 0.499990] [G loss: 0.310661]\n",
      "[Epoch 13/100] [Batch 135/347] [D loss: 0.499985] [G loss: 0.319915]\n",
      "[Epoch 13/100] [Batch 136/347] [D loss: 0.500090] [G loss: 0.278269]\n",
      "[Epoch 13/100] [Batch 137/347] [D loss: 0.500147] [G loss: 0.266085]\n",
      "[Epoch 13/100] [Batch 138/347] [D loss: 0.500048] [G loss: 0.283757]\n",
      "[Epoch 13/100] [Batch 139/347] [D loss: 0.499958] [G loss: 0.307842]\n",
      "[Epoch 13/100] [Batch 140/347] [D loss: 0.499919] [G loss: 0.319403]\n",
      "[Epoch 13/100] [Batch 141/347] [D loss: 0.499889] [G loss: 0.326378]\n",
      "[Epoch 13/100] [Batch 142/347] [D loss: 0.499868] [G loss: 0.334238]\n",
      "[Epoch 13/100] [Batch 143/347] [D loss: 0.499795] [G loss: 0.356085]\n",
      "[Epoch 13/100] [Batch 144/347] [D loss: 0.499766] [G loss: 0.358438]\n",
      "[Epoch 13/100] [Batch 145/347] [D loss: 0.499780] [G loss: 0.344289]\n",
      "[Epoch 13/100] [Batch 146/347] [D loss: 0.499805] [G loss: 0.327612]\n",
      "[Epoch 13/100] [Batch 147/347] [D loss: 0.499903] [G loss: 0.299675]\n",
      "[Epoch 13/100] [Batch 148/347] [D loss: 0.499965] [G loss: 0.287443]\n",
      "[Epoch 13/100] [Batch 149/347] [D loss: 0.499920] [G loss: 0.300774]\n",
      "[Epoch 13/100] [Batch 150/347] [D loss: 0.499921] [G loss: 0.301275]\n",
      "[Epoch 13/100] [Batch 151/347] [D loss: 0.499987] [G loss: 0.290492]\n",
      "[Epoch 13/100] [Batch 152/347] [D loss: 0.499977] [G loss: 0.301685]\n",
      "[Epoch 13/100] [Batch 153/347] [D loss: 0.499892] [G loss: 0.322443]\n",
      "[Epoch 13/100] [Batch 154/347] [D loss: 0.499837] [G loss: 0.326724]\n",
      "[Epoch 13/100] [Batch 155/347] [D loss: 0.499873] [G loss: 0.314037]\n",
      "[Epoch 13/100] [Batch 156/347] [D loss: 0.499945] [G loss: 0.297537]\n",
      "[Epoch 13/100] [Batch 157/347] [D loss: 0.499970] [G loss: 0.303988]\n",
      "[Epoch 13/100] [Batch 158/347] [D loss: 0.499881] [G loss: 0.327829]\n",
      "[Epoch 13/100] [Batch 159/347] [D loss: 0.499847] [G loss: 0.325366]\n",
      "[Epoch 13/100] [Batch 160/347] [D loss: 0.499953] [G loss: 0.305607]\n",
      "[Epoch 13/100] [Batch 161/347] [D loss: 0.500026] [G loss: 0.297329]\n",
      "[Epoch 13/100] [Batch 162/347] [D loss: 0.500003] [G loss: 0.303175]\n",
      "[Epoch 13/100] [Batch 163/347] [D loss: 0.499928] [G loss: 0.322049]\n",
      "[Epoch 13/100] [Batch 164/347] [D loss: 0.499853] [G loss: 0.337399]\n",
      "[Epoch 13/100] [Batch 165/347] [D loss: 0.499851] [G loss: 0.328608]\n",
      "[Epoch 13/100] [Batch 166/347] [D loss: 0.499983] [G loss: 0.290516]\n",
      "[Epoch 13/100] [Batch 167/347] [D loss: 0.500139] [G loss: 0.269096]\n",
      "[Epoch 13/100] [Batch 168/347] [D loss: 0.500189] [G loss: 0.279743]\n",
      "[Epoch 13/100] [Batch 169/347] [D loss: 0.500210] [G loss: 0.278481]\n",
      "[Epoch 13/100] [Batch 170/347] [D loss: 0.500228] [G loss: 0.274601]\n",
      "[Epoch 13/100] [Batch 171/347] [D loss: 0.500269] [G loss: 0.284340]\n",
      "[Epoch 13/100] [Batch 172/347] [D loss: 0.500286] [G loss: 0.289220]\n",
      "[Epoch 13/100] [Batch 173/347] [D loss: 0.500240] [G loss: 0.277963]\n",
      "[Epoch 13/100] [Batch 174/347] [D loss: 0.500228] [G loss: 0.275456]\n",
      "[Epoch 13/100] [Batch 175/347] [D loss: 0.500248] [G loss: 0.285266]\n",
      "[Epoch 13/100] [Batch 176/347] [D loss: 0.500293] [G loss: 0.298664]\n",
      "[Epoch 13/100] [Batch 177/347] [D loss: 0.500294] [G loss: 0.299493]\n",
      "[Epoch 13/100] [Batch 178/347] [D loss: 0.500273] [G loss: 0.293462]\n",
      "[Epoch 13/100] [Batch 179/347] [D loss: 0.500245] [G loss: 0.286783]\n",
      "[Epoch 13/100] [Batch 180/347] [D loss: 0.500228] [G loss: 0.280367]\n",
      "[Epoch 13/100] [Batch 181/347] [D loss: 0.500224] [G loss: 0.280704]\n",
      "[Epoch 13/100] [Batch 182/347] [D loss: 0.500201] [G loss: 0.278563]\n",
      "[Epoch 13/100] [Batch 183/347] [D loss: 0.500214] [G loss: 0.282515]\n",
      "[Epoch 13/100] [Batch 184/347] [D loss: 0.500225] [G loss: 0.286345]\n",
      "[Epoch 13/100] [Batch 185/347] [D loss: 0.500221] [G loss: 0.284826]\n",
      "[Epoch 13/100] [Batch 186/347] [D loss: 0.500221] [G loss: 0.284585]\n",
      "[Epoch 13/100] [Batch 187/347] [D loss: 0.500206] [G loss: 0.279272]\n",
      "[Epoch 13/100] [Batch 188/347] [D loss: 0.500187] [G loss: 0.276012]\n",
      "[Epoch 13/100] [Batch 189/347] [D loss: 0.500187] [G loss: 0.275150]\n",
      "[Epoch 13/100] [Batch 190/347] [D loss: 0.500130] [G loss: 0.263199]\n",
      "[Epoch 13/100] [Batch 191/347] [D loss: 0.500067] [G loss: 0.264091]\n",
      "[Epoch 13/100] [Batch 192/347] [D loss: 0.500096] [G loss: 0.254726]\n",
      "[Epoch 13/100] [Batch 193/347] [D loss: 0.500137] [G loss: 0.261185]\n",
      "[Epoch 13/100] [Batch 194/347] [D loss: 0.500097] [G loss: 0.258635]\n",
      "[Epoch 13/100] [Batch 195/347] [D loss: 0.500068] [G loss: 0.267376]\n",
      "[Epoch 13/100] [Batch 196/347] [D loss: 0.500050] [G loss: 0.265007]\n",
      "[Epoch 13/100] [Batch 197/347] [D loss: 0.500060] [G loss: 0.260177]\n",
      "[Epoch 13/100] [Batch 198/347] [D loss: 0.500078] [G loss: 0.258766]\n",
      "[Epoch 13/100] [Batch 199/347] [D loss: 0.500077] [G loss: 0.259884]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 13/100] [Batch 200/347] [D loss: 0.500088] [G loss: 0.254761]\n",
      "[Epoch 13/100] [Batch 201/347] [D loss: 0.500095] [G loss: 0.255455]\n",
      "[Epoch 13/100] [Batch 202/347] [D loss: 0.500054] [G loss: 0.266950]\n",
      "[Epoch 13/100] [Batch 203/347] [D loss: 0.500023] [G loss: 0.275478]\n",
      "[Epoch 13/100] [Batch 204/347] [D loss: 0.500037] [G loss: 0.271839]\n",
      "[Epoch 13/100] [Batch 205/347] [D loss: 0.500059] [G loss: 0.263853]\n",
      "[Epoch 13/100] [Batch 206/347] [D loss: 0.500101] [G loss: 0.254007]\n",
      "[Epoch 13/100] [Batch 207/347] [D loss: 0.500166] [G loss: 0.264827]\n",
      "[Epoch 13/100] [Batch 208/347] [D loss: 0.500152] [G loss: 0.265651]\n",
      "[Epoch 13/100] [Batch 209/347] [D loss: 0.500128] [G loss: 0.260003]\n",
      "[Epoch 13/100] [Batch 210/347] [D loss: 0.500177] [G loss: 0.267077]\n",
      "[Epoch 13/100] [Batch 211/347] [D loss: 0.500166] [G loss: 0.264214]\n",
      "[Epoch 13/100] [Batch 212/347] [D loss: 0.500150] [G loss: 0.263008]\n",
      "[Epoch 13/100] [Batch 213/347] [D loss: 0.500148] [G loss: 0.268551]\n",
      "[Epoch 13/100] [Batch 214/347] [D loss: 0.500083] [G loss: 0.276812]\n",
      "[Epoch 13/100] [Batch 215/347] [D loss: 0.500057] [G loss: 0.285113]\n",
      "[Epoch 13/100] [Batch 216/347] [D loss: 0.500118] [G loss: 0.267420]\n",
      "[Epoch 13/100] [Batch 217/347] [D loss: 0.500160] [G loss: 0.267977]\n",
      "[Epoch 13/100] [Batch 218/347] [D loss: 0.500198] [G loss: 0.274888]\n",
      "[Epoch 13/100] [Batch 219/347] [D loss: 0.500251] [G loss: 0.287054]\n",
      "[Epoch 13/100] [Batch 220/347] [D loss: 0.500309] [G loss: 0.302791]\n",
      "[Epoch 13/100] [Batch 221/347] [D loss: 0.500319] [G loss: 0.304131]\n",
      "[Epoch 13/100] [Batch 222/347] [D loss: 0.500302] [G loss: 0.296059]\n",
      "[Epoch 13/100] [Batch 223/347] [D loss: 0.500298] [G loss: 0.294624]\n",
      "[Epoch 13/100] [Batch 224/347] [D loss: 0.500282] [G loss: 0.290377]\n",
      "[Epoch 13/100] [Batch 225/347] [D loss: 0.500192] [G loss: 0.275975]\n",
      "[Epoch 13/100] [Batch 226/347] [D loss: 0.500047] [G loss: 0.272683]\n",
      "[Epoch 13/100] [Batch 227/347] [D loss: 0.499952] [G loss: 0.283074]\n",
      "[Epoch 13/100] [Batch 228/347] [D loss: 0.499941] [G loss: 0.285584]\n",
      "[Epoch 13/100] [Batch 229/347] [D loss: 0.499981] [G loss: 0.280859]\n",
      "[Epoch 13/100] [Batch 230/347] [D loss: 0.500000] [G loss: 0.277140]\n",
      "[Epoch 13/100] [Batch 231/347] [D loss: 0.499975] [G loss: 0.277202]\n",
      "[Epoch 13/100] [Batch 232/347] [D loss: 0.500000] [G loss: 0.273183]\n",
      "[Epoch 13/100] [Batch 233/347] [D loss: 0.500013] [G loss: 0.270258]\n",
      "[Epoch 13/100] [Batch 234/347] [D loss: 0.500015] [G loss: 0.275256]\n",
      "[Epoch 13/100] [Batch 235/347] [D loss: 0.500068] [G loss: 0.264060]\n",
      "[Epoch 13/100] [Batch 236/347] [D loss: 0.500125] [G loss: 0.262390]\n",
      "[Epoch 13/100] [Batch 237/347] [D loss: 0.500165] [G loss: 0.266447]\n",
      "[Epoch 13/100] [Batch 238/347] [D loss: 0.500163] [G loss: 0.270445]\n",
      "[Epoch 13/100] [Batch 239/347] [D loss: 0.500152] [G loss: 0.268428]\n",
      "[Epoch 13/100] [Batch 240/347] [D loss: 0.500144] [G loss: 0.264569]\n",
      "[Epoch 13/100] [Batch 241/347] [D loss: 0.500126] [G loss: 0.258654]\n",
      "[Epoch 13/100] [Batch 242/347] [D loss: 0.500112] [G loss: 0.256583]\n",
      "[Epoch 13/100] [Batch 243/347] [D loss: 0.500134] [G loss: 0.264108]\n",
      "[Epoch 13/100] [Batch 244/347] [D loss: 0.500161] [G loss: 0.272771]\n",
      "[Epoch 13/100] [Batch 245/347] [D loss: 0.500194] [G loss: 0.271249]\n",
      "[Epoch 13/100] [Batch 246/347] [D loss: 0.500117] [G loss: 0.263638]\n",
      "[Epoch 13/100] [Batch 247/347] [D loss: 0.500006] [G loss: 0.271147]\n",
      "[Epoch 13/100] [Batch 248/347] [D loss: 0.499961] [G loss: 0.277329]\n",
      "[Epoch 13/100] [Batch 249/347] [D loss: 0.499938] [G loss: 0.282665]\n",
      "[Epoch 13/100] [Batch 250/347] [D loss: 0.500012] [G loss: 0.274152]\n",
      "[Epoch 13/100] [Batch 251/347] [D loss: 0.500116] [G loss: 0.263566]\n",
      "[Epoch 13/100] [Batch 252/347] [D loss: 0.500154] [G loss: 0.266751]\n",
      "[Epoch 13/100] [Batch 253/347] [D loss: 0.500155] [G loss: 0.267327]\n",
      "[Epoch 13/100] [Batch 254/347] [D loss: 0.500154] [G loss: 0.265698]\n",
      "[Epoch 13/100] [Batch 255/347] [D loss: 0.500129] [G loss: 0.264285]\n",
      "[Epoch 13/100] [Batch 256/347] [D loss: 0.500147] [G loss: 0.269474]\n",
      "[Epoch 13/100] [Batch 257/347] [D loss: 0.500190] [G loss: 0.271765]\n",
      "[Epoch 13/100] [Batch 258/347] [D loss: 0.500144] [G loss: 0.265914]\n",
      "[Epoch 13/100] [Batch 259/347] [D loss: 0.500032] [G loss: 0.273485]\n",
      "[Epoch 13/100] [Batch 260/347] [D loss: 0.499983] [G loss: 0.287870]\n",
      "[Epoch 13/100] [Batch 261/347] [D loss: 0.500022] [G loss: 0.280340]\n",
      "[Epoch 13/100] [Batch 262/347] [D loss: 0.500054] [G loss: 0.265242]\n",
      "[Epoch 13/100] [Batch 263/347] [D loss: 0.500047] [G loss: 0.266185]\n",
      "[Epoch 13/100] [Batch 264/347] [D loss: 0.500010] [G loss: 0.280682]\n",
      "[Epoch 13/100] [Batch 265/347] [D loss: 0.499985] [G loss: 0.285897]\n",
      "[Epoch 13/100] [Batch 266/347] [D loss: 0.500002] [G loss: 0.278714]\n",
      "[Epoch 13/100] [Batch 267/347] [D loss: 0.500019] [G loss: 0.271903]\n",
      "[Epoch 13/100] [Batch 268/347] [D loss: 0.500011] [G loss: 0.278808]\n",
      "[Epoch 13/100] [Batch 269/347] [D loss: 0.499989] [G loss: 0.289946]\n",
      "[Epoch 13/100] [Batch 270/347] [D loss: 0.499990] [G loss: 0.286485]\n",
      "[Epoch 13/100] [Batch 271/347] [D loss: 0.500016] [G loss: 0.274672]\n",
      "[Epoch 13/100] [Batch 272/347] [D loss: 0.500048] [G loss: 0.266007]\n",
      "[Epoch 13/100] [Batch 273/347] [D loss: 0.500033] [G loss: 0.277828]\n",
      "[Epoch 13/100] [Batch 274/347] [D loss: 0.499979] [G loss: 0.311600]\n",
      "[Epoch 13/100] [Batch 275/347] [D loss: 0.499977] [G loss: 0.308506]\n",
      "[Epoch 13/100] [Batch 276/347] [D loss: 0.500030] [G loss: 0.276105]\n",
      "[Epoch 13/100] [Batch 277/347] [D loss: 0.500059] [G loss: 0.261424]\n",
      "[Epoch 13/100] [Batch 278/347] [D loss: 0.500094] [G loss: 0.252934]\n",
      "[Epoch 13/100] [Batch 279/347] [D loss: 0.500095] [G loss: 0.259603]\n",
      "[Epoch 13/100] [Batch 280/347] [D loss: 0.500085] [G loss: 0.263141]\n",
      "[Epoch 13/100] [Batch 281/347] [D loss: 0.500090] [G loss: 0.261423]\n",
      "[Epoch 13/100] [Batch 282/347] [D loss: 0.500086] [G loss: 0.259303]\n",
      "[Epoch 13/100] [Batch 283/347] [D loss: 0.500067] [G loss: 0.262487]\n",
      "[Epoch 13/100] [Batch 284/347] [D loss: 0.500081] [G loss: 0.262032]\n",
      "[Epoch 13/100] [Batch 285/347] [D loss: 0.500093] [G loss: 0.257968]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 13/100] [Batch 286/347] [D loss: 0.500072] [G loss: 0.252438]\n",
      "[Epoch 13/100] [Batch 287/347] [D loss: 0.500070] [G loss: 0.256008]\n",
      "[Epoch 13/100] [Batch 288/347] [D loss: 0.499962] [G loss: 0.282490]\n",
      "[Epoch 13/100] [Batch 289/347] [D loss: 0.499945] [G loss: 0.286638]\n",
      "[Epoch 13/100] [Batch 290/347] [D loss: 0.500019] [G loss: 0.263957]\n",
      "[Epoch 13/100] [Batch 291/347] [D loss: 0.500008] [G loss: 0.266471]\n",
      "[Epoch 13/100] [Batch 292/347] [D loss: 0.500050] [G loss: 0.257686]\n",
      "[Epoch 13/100] [Batch 293/347] [D loss: 0.500160] [G loss: 0.270479]\n",
      "[Epoch 13/100] [Batch 294/347] [D loss: 0.500211] [G loss: 0.280520]\n",
      "[Epoch 13/100] [Batch 295/347] [D loss: 0.500175] [G loss: 0.278348]\n",
      "[Epoch 13/100] [Batch 296/347] [D loss: 0.500174] [G loss: 0.274492]\n",
      "[Epoch 13/100] [Batch 297/347] [D loss: 0.500209] [G loss: 0.285867]\n",
      "[Epoch 13/100] [Batch 298/347] [D loss: 0.500181] [G loss: 0.280864]\n",
      "[Epoch 13/100] [Batch 299/347] [D loss: 0.500197] [G loss: 0.279602]\n",
      "[Epoch 13/100] [Batch 300/347] [D loss: 0.500172] [G loss: 0.274979]\n",
      "[Epoch 13/100] [Batch 301/347] [D loss: 0.500186] [G loss: 0.276651]\n",
      "[Epoch 13/100] [Batch 302/347] [D loss: 0.500222] [G loss: 0.281809]\n",
      "[Epoch 13/100] [Batch 303/347] [D loss: 0.500120] [G loss: 0.266149]\n",
      "[Epoch 13/100] [Batch 304/347] [D loss: 0.500012] [G loss: 0.265206]\n",
      "[Epoch 13/100] [Batch 305/347] [D loss: 0.499979] [G loss: 0.277999]\n",
      "[Epoch 13/100] [Batch 306/347] [D loss: 0.499980] [G loss: 0.270154]\n",
      "[Epoch 13/100] [Batch 307/347] [D loss: 0.499967] [G loss: 0.282786]\n",
      "[Epoch 13/100] [Batch 308/347] [D loss: 0.499974] [G loss: 0.278973]\n",
      "[Epoch 13/100] [Batch 309/347] [D loss: 0.500051] [G loss: 0.258537]\n",
      "[Epoch 13/100] [Batch 310/347] [D loss: 0.500128] [G loss: 0.278396]\n",
      "[Epoch 13/100] [Batch 311/347] [D loss: 0.500136] [G loss: 0.281321]\n",
      "[Epoch 13/100] [Batch 312/347] [D loss: 0.500130] [G loss: 0.281073]\n",
      "[Epoch 13/100] [Batch 313/347] [D loss: 0.500137] [G loss: 0.280273]\n",
      "[Epoch 13/100] [Batch 314/347] [D loss: 0.500140] [G loss: 0.273919]\n",
      "[Epoch 13/100] [Batch 315/347] [D loss: 0.500143] [G loss: 0.264583]\n",
      "[Epoch 13/100] [Batch 316/347] [D loss: 0.500055] [G loss: 0.258478]\n",
      "[Epoch 13/100] [Batch 317/347] [D loss: 0.499970] [G loss: 0.277026]\n",
      "[Epoch 13/100] [Batch 318/347] [D loss: 0.500069] [G loss: 0.254778]\n",
      "[Epoch 13/100] [Batch 319/347] [D loss: 0.500189] [G loss: 0.286538]\n",
      "[Epoch 13/100] [Batch 320/347] [D loss: 0.500233] [G loss: 0.300162]\n",
      "[Epoch 13/100] [Batch 321/347] [D loss: 0.500205] [G loss: 0.289683]\n",
      "[Epoch 13/100] [Batch 322/347] [D loss: 0.500160] [G loss: 0.276652]\n",
      "[Epoch 13/100] [Batch 323/347] [D loss: 0.500164] [G loss: 0.275842]\n",
      "[Epoch 13/100] [Batch 324/347] [D loss: 0.500179] [G loss: 0.278782]\n",
      "[Epoch 13/100] [Batch 325/347] [D loss: 0.500147] [G loss: 0.267864]\n",
      "[Epoch 13/100] [Batch 326/347] [D loss: 0.500102] [G loss: 0.257564]\n",
      "[Epoch 13/100] [Batch 327/347] [D loss: 0.500098] [G loss: 0.255546]\n",
      "[Epoch 13/100] [Batch 328/347] [D loss: 0.500082] [G loss: 0.253119]\n",
      "[Epoch 13/100] [Batch 329/347] [D loss: 0.500004] [G loss: 0.273473]\n",
      "[Epoch 13/100] [Batch 330/347] [D loss: 0.499934] [G loss: 0.289189]\n",
      "[Epoch 13/100] [Batch 331/347] [D loss: 0.499999] [G loss: 0.271132]\n",
      "[Epoch 13/100] [Batch 332/347] [D loss: 0.500104] [G loss: 0.266245]\n",
      "[Epoch 13/100] [Batch 333/347] [D loss: 0.500131] [G loss: 0.277463]\n",
      "[Epoch 13/100] [Batch 334/347] [D loss: 0.500155] [G loss: 0.278776]\n",
      "[Epoch 13/100] [Batch 335/347] [D loss: 0.500130] [G loss: 0.266754]\n",
      "[Epoch 13/100] [Batch 336/347] [D loss: 0.500082] [G loss: 0.252509]\n",
      "[Epoch 13/100] [Batch 337/347] [D loss: 0.500088] [G loss: 0.258128]\n",
      "[Epoch 13/100] [Batch 338/347] [D loss: 0.500122] [G loss: 0.272589]\n",
      "[Epoch 13/100] [Batch 339/347] [D loss: 0.500141] [G loss: 0.277822]\n",
      "[Epoch 13/100] [Batch 340/347] [D loss: 0.500135] [G loss: 0.278051]\n",
      "[Epoch 13/100] [Batch 341/347] [D loss: 0.500130] [G loss: 0.273117]\n",
      "[Epoch 13/100] [Batch 342/347] [D loss: 0.500102] [G loss: 0.265376]\n",
      "[Epoch 13/100] [Batch 343/347] [D loss: 0.500096] [G loss: 0.270023]\n",
      "[Epoch 13/100] [Batch 344/347] [D loss: 0.500063] [G loss: 0.265686]\n",
      "[Epoch 13/100] [Batch 345/347] [D loss: 0.499960] [G loss: 0.275390]\n",
      "[Epoch 13/100] [Batch 346/347] [D loss: 0.499909] [G loss: 0.293905]\n",
      "[Epoch 13/100] [Batch 347/347] [D loss: 0.499894] [G loss: 0.300210]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 14/100] [Batch 1/347] [D loss: 0.500023] [G loss: 0.267095]\n",
      "[Epoch 14/100] [Batch 2/347] [D loss: 0.500017] [G loss: 0.272338]\n",
      "[Epoch 14/100] [Batch 3/347] [D loss: 0.500045] [G loss: 0.272292]\n",
      "[Epoch 14/100] [Batch 4/347] [D loss: 0.500040] [G loss: 0.273565]\n",
      "[Epoch 14/100] [Batch 5/347] [D loss: 0.500041] [G loss: 0.272790]\n",
      "[Epoch 14/100] [Batch 6/347] [D loss: 0.500047] [G loss: 0.273153]\n",
      "[Epoch 14/100] [Batch 7/347] [D loss: 0.500032] [G loss: 0.272938]\n",
      "[Epoch 14/100] [Batch 8/347] [D loss: 0.500039] [G loss: 0.268229]\n",
      "[Epoch 14/100] [Batch 9/347] [D loss: 0.500007] [G loss: 0.267185]\n",
      "[Epoch 14/100] [Batch 10/347] [D loss: 0.500008] [G loss: 0.268751]\n",
      "[Epoch 14/100] [Batch 11/347] [D loss: 0.500045] [G loss: 0.268521]\n",
      "[Epoch 14/100] [Batch 12/347] [D loss: 0.500057] [G loss: 0.269018]\n",
      "[Epoch 14/100] [Batch 13/347] [D loss: 0.500081] [G loss: 0.266954]\n",
      "[Epoch 14/100] [Batch 14/347] [D loss: 0.500100] [G loss: 0.269302]\n",
      "[Epoch 14/100] [Batch 15/347] [D loss: 0.500092] [G loss: 0.265539]\n",
      "[Epoch 14/100] [Batch 16/347] [D loss: 0.500086] [G loss: 0.261445]\n",
      "[Epoch 14/100] [Batch 17/347] [D loss: 0.500064] [G loss: 0.253354]\n",
      "[Epoch 14/100] [Batch 18/347] [D loss: 0.500048] [G loss: 0.258550]\n",
      "[Epoch 14/100] [Batch 19/347] [D loss: 0.500083] [G loss: 0.255315]\n",
      "[Epoch 14/100] [Batch 20/347] [D loss: 0.500118] [G loss: 0.268566]\n",
      "[Epoch 14/100] [Batch 21/347] [D loss: 0.500096] [G loss: 0.265067]\n",
      "[Epoch 14/100] [Batch 22/347] [D loss: 0.500079] [G loss: 0.260231]\n",
      "[Epoch 14/100] [Batch 23/347] [D loss: 0.500071] [G loss: 0.254836]\n",
      "[Epoch 14/100] [Batch 24/347] [D loss: 0.500079] [G loss: 0.253750]\n",
      "[Epoch 14/100] [Batch 25/347] [D loss: 0.500077] [G loss: 0.253516]\n",
      "[Epoch 14/100] [Batch 26/347] [D loss: 0.500024] [G loss: 0.262030]\n",
      "[Epoch 14/100] [Batch 27/347] [D loss: 0.500039] [G loss: 0.267562]\n",
      "[Epoch 14/100] [Batch 28/347] [D loss: 0.500103] [G loss: 0.267811]\n",
      "[Epoch 14/100] [Batch 29/347] [D loss: 0.500135] [G loss: 0.265459]\n",
      "[Epoch 14/100] [Batch 30/347] [D loss: 0.500163] [G loss: 0.272606]\n",
      "[Epoch 14/100] [Batch 31/347] [D loss: 0.500182] [G loss: 0.275401]\n",
      "[Epoch 14/100] [Batch 32/347] [D loss: 0.500165] [G loss: 0.269016]\n",
      "[Epoch 14/100] [Batch 33/347] [D loss: 0.500134] [G loss: 0.265076]\n",
      "[Epoch 14/100] [Batch 34/347] [D loss: 0.500136] [G loss: 0.266292]\n",
      "[Epoch 14/100] [Batch 35/347] [D loss: 0.500128] [G loss: 0.265245]\n",
      "[Epoch 14/100] [Batch 36/347] [D loss: 0.500101] [G loss: 0.256203]\n",
      "[Epoch 14/100] [Batch 37/347] [D loss: 0.500007] [G loss: 0.271940]\n",
      "[Epoch 14/100] [Batch 38/347] [D loss: 0.499935] [G loss: 0.287166]\n",
      "[Epoch 14/100] [Batch 39/347] [D loss: 0.499951] [G loss: 0.277617]\n",
      "[Epoch 14/100] [Batch 40/347] [D loss: 0.499954] [G loss: 0.278082]\n",
      "[Epoch 14/100] [Batch 41/347] [D loss: 0.499942] [G loss: 0.279423]\n",
      "[Epoch 14/100] [Batch 42/347] [D loss: 0.499965] [G loss: 0.272430]\n",
      "[Epoch 14/100] [Batch 43/347] [D loss: 0.500049] [G loss: 0.256303]\n",
      "[Epoch 14/100] [Batch 44/347] [D loss: 0.500126] [G loss: 0.264907]\n",
      "[Epoch 14/100] [Batch 45/347] [D loss: 0.500180] [G loss: 0.282341]\n",
      "[Epoch 14/100] [Batch 46/347] [D loss: 0.500179] [G loss: 0.277145]\n",
      "[Epoch 14/100] [Batch 47/347] [D loss: 0.500070] [G loss: 0.254180]\n",
      "[Epoch 14/100] [Batch 48/347] [D loss: 0.499962] [G loss: 0.286464]\n",
      "[Epoch 14/100] [Batch 49/347] [D loss: 0.499928] [G loss: 0.295003]\n",
      "[Epoch 14/100] [Batch 50/347] [D loss: 0.499908] [G loss: 0.310672]\n",
      "[Epoch 14/100] [Batch 51/347] [D loss: 0.499990] [G loss: 0.295307]\n",
      "[Epoch 14/100] [Batch 52/347] [D loss: 0.500105] [G loss: 0.264539]\n",
      "[Epoch 14/100] [Batch 53/347] [D loss: 0.500080] [G loss: 0.259036]\n",
      "[Epoch 14/100] [Batch 54/347] [D loss: 0.499906] [G loss: 0.310884]\n",
      "[Epoch 14/100] [Batch 55/347] [D loss: 0.499757] [G loss: 0.333571]\n",
      "[Epoch 14/100] [Batch 56/347] [D loss: 0.499788] [G loss: 0.320813]\n",
      "[Epoch 14/100] [Batch 57/347] [D loss: 0.499964] [G loss: 0.286710]\n",
      "[Epoch 14/100] [Batch 58/347] [D loss: 0.500090] [G loss: 0.261751]\n",
      "[Epoch 14/100] [Batch 59/347] [D loss: 0.500050] [G loss: 0.269949]\n",
      "[Epoch 14/100] [Batch 60/347] [D loss: 0.499989] [G loss: 0.288822]\n",
      "[Epoch 14/100] [Batch 61/347] [D loss: 0.499947] [G loss: 0.301485]\n",
      "[Epoch 14/100] [Batch 62/347] [D loss: 0.499844] [G loss: 0.325619]\n",
      "[Epoch 14/100] [Batch 63/347] [D loss: 0.499766] [G loss: 0.327862]\n",
      "[Epoch 14/100] [Batch 64/347] [D loss: 0.499927] [G loss: 0.291107]\n",
      "[Epoch 14/100] [Batch 65/347] [D loss: 0.500138] [G loss: 0.264766]\n",
      "[Epoch 14/100] [Batch 66/347] [D loss: 0.500125] [G loss: 0.267041]\n",
      "[Epoch 14/100] [Batch 67/347] [D loss: 0.500024] [G loss: 0.275146]\n",
      "[Epoch 14/100] [Batch 68/347] [D loss: 0.499962] [G loss: 0.293266]\n",
      "[Epoch 14/100] [Batch 69/347] [D loss: 0.499848] [G loss: 0.312205]\n",
      "[Epoch 14/100] [Batch 70/347] [D loss: 0.499817] [G loss: 0.310998]\n",
      "[Epoch 14/100] [Batch 71/347] [D loss: 0.499847] [G loss: 0.313538]\n",
      "[Epoch 14/100] [Batch 72/347] [D loss: 0.499823] [G loss: 0.316088]\n",
      "[Epoch 14/100] [Batch 73/347] [D loss: 0.499918] [G loss: 0.291443]\n",
      "[Epoch 14/100] [Batch 74/347] [D loss: 0.500022] [G loss: 0.277513]\n",
      "[Epoch 14/100] [Batch 75/347] [D loss: 0.499919] [G loss: 0.307322]\n",
      "[Epoch 14/100] [Batch 76/347] [D loss: 0.499843] [G loss: 0.309322]\n",
      "[Epoch 14/100] [Batch 77/347] [D loss: 0.499985] [G loss: 0.275079]\n",
      "[Epoch 14/100] [Batch 78/347] [D loss: 0.500153] [G loss: 0.270352]\n",
      "[Epoch 14/100] [Batch 79/347] [D loss: 0.500188] [G loss: 0.271963]\n",
      "[Epoch 14/100] [Batch 80/347] [D loss: 0.500167] [G loss: 0.269442]\n",
      "[Epoch 14/100] [Batch 81/347] [D loss: 0.500198] [G loss: 0.274396]\n",
      "[Epoch 14/100] [Batch 82/347] [D loss: 0.500199] [G loss: 0.279350]\n",
      "[Epoch 14/100] [Batch 83/347] [D loss: 0.500176] [G loss: 0.271697]\n",
      "[Epoch 14/100] [Batch 84/347] [D loss: 0.500182] [G loss: 0.278085]\n",
      "[Epoch 14/100] [Batch 85/347] [D loss: 0.500170] [G loss: 0.278820]\n",
      "[Epoch 14/100] [Batch 86/347] [D loss: 0.500155] [G loss: 0.273223]\n",
      "[Epoch 14/100] [Batch 87/347] [D loss: 0.500139] [G loss: 0.271008]\n",
      "[Epoch 14/100] [Batch 88/347] [D loss: 0.500145] [G loss: 0.274326]\n",
      "[Epoch 14/100] [Batch 89/347] [D loss: 0.500147] [G loss: 0.277692]\n",
      "[Epoch 14/100] [Batch 90/347] [D loss: 0.500137] [G loss: 0.273856]\n",
      "[Epoch 14/100] [Batch 91/347] [D loss: 0.500124] [G loss: 0.272359]\n",
      "[Epoch 14/100] [Batch 92/347] [D loss: 0.500126] [G loss: 0.273834]\n",
      "[Epoch 14/100] [Batch 93/347] [D loss: 0.500117] [G loss: 0.271794]\n",
      "[Epoch 14/100] [Batch 94/347] [D loss: 0.500100] [G loss: 0.268255]\n",
      "[Epoch 14/100] [Batch 95/347] [D loss: 0.500103] [G loss: 0.268709]\n",
      "[Epoch 14/100] [Batch 96/347] [D loss: 0.500092] [G loss: 0.264004]\n",
      "[Epoch 14/100] [Batch 97/347] [D loss: 0.500070] [G loss: 0.258923]\n",
      "[Epoch 14/100] [Batch 98/347] [D loss: 0.500075] [G loss: 0.263825]\n",
      "[Epoch 14/100] [Batch 99/347] [D loss: 0.500086] [G loss: 0.267573]\n",
      "[Epoch 14/100] [Batch 100/347] [D loss: 0.500075] [G loss: 0.263953]\n",
      "[Epoch 14/100] [Batch 101/347] [D loss: 0.500054] [G loss: 0.262055]\n",
      "[Epoch 14/100] [Batch 102/347] [D loss: 0.500059] [G loss: 0.262872]\n",
      "[Epoch 14/100] [Batch 103/347] [D loss: 0.500065] [G loss: 0.262270]\n",
      "[Epoch 14/100] [Batch 104/347] [D loss: 0.500034] [G loss: 0.264230]\n",
      "[Epoch 14/100] [Batch 105/347] [D loss: 0.500033] [G loss: 0.265596]\n",
      "[Epoch 14/100] [Batch 106/347] [D loss: 0.500035] [G loss: 0.264383]\n",
      "[Epoch 14/100] [Batch 107/347] [D loss: 0.500029] [G loss: 0.258144]\n",
      "[Epoch 14/100] [Batch 108/347] [D loss: 0.500016] [G loss: 0.274902]\n",
      "[Epoch 14/100] [Batch 109/347] [D loss: 0.500057] [G loss: 0.267861]\n",
      "[Epoch 14/100] [Batch 110/347] [D loss: 0.500100] [G loss: 0.257787]\n",
      "[Epoch 14/100] [Batch 111/347] [D loss: 0.500066] [G loss: 0.263064]\n",
      "[Epoch 14/100] [Batch 112/347] [D loss: 0.500075] [G loss: 0.268287]\n",
      "[Epoch 14/100] [Batch 113/347] [D loss: 0.500157] [G loss: 0.273151]\n",
      "[Epoch 14/100] [Batch 114/347] [D loss: 0.500210] [G loss: 0.293753]\n",
      "[Epoch 14/100] [Batch 115/347] [D loss: 0.500219] [G loss: 0.294861]\n",
      "[Epoch 14/100] [Batch 116/347] [D loss: 0.500206] [G loss: 0.288976]\n",
      "[Epoch 14/100] [Batch 117/347] [D loss: 0.500134] [G loss: 0.262651]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 14/100] [Batch 118/347] [D loss: 0.500022] [G loss: 0.266097]\n",
      "[Epoch 14/100] [Batch 119/347] [D loss: 0.499999] [G loss: 0.268326]\n",
      "[Epoch 14/100] [Batch 120/347] [D loss: 0.500011] [G loss: 0.267308]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 14/100] [Batch 121/347] [D loss: 0.500014] [G loss: 0.265664]\n",
      "[Epoch 14/100] [Batch 122/347] [D loss: 0.500051] [G loss: 0.252749]\n",
      "[Epoch 14/100] [Batch 123/347] [D loss: 0.500062] [G loss: 0.251906]\n",
      "[Epoch 14/100] [Batch 124/347] [D loss: 0.500042] [G loss: 0.253712]\n",
      "[Epoch 14/100] [Batch 125/347] [D loss: 0.500084] [G loss: 0.259283]\n",
      "[Epoch 14/100] [Batch 126/347] [D loss: 0.500133] [G loss: 0.271716]\n",
      "[Epoch 14/100] [Batch 127/347] [D loss: 0.500148] [G loss: 0.272977]\n",
      "[Epoch 14/100] [Batch 128/347] [D loss: 0.500122] [G loss: 0.267300]\n",
      "[Epoch 14/100] [Batch 129/347] [D loss: 0.500118] [G loss: 0.262201]\n",
      "[Epoch 14/100] [Batch 130/347] [D loss: 0.500114] [G loss: 0.264875]\n",
      "[Epoch 14/100] [Batch 131/347] [D loss: 0.500056] [G loss: 0.264618]\n",
      "[Epoch 14/100] [Batch 132/347] [D loss: 0.499977] [G loss: 0.289349]\n",
      "[Epoch 14/100] [Batch 133/347] [D loss: 0.499953] [G loss: 0.296193]\n",
      "[Epoch 14/100] [Batch 134/347] [D loss: 0.499902] [G loss: 0.311201]\n",
      "[Epoch 14/100] [Batch 135/347] [D loss: 0.499899] [G loss: 0.320277]\n",
      "[Epoch 14/100] [Batch 136/347] [D loss: 0.500030] [G loss: 0.278471]\n",
      "[Epoch 14/100] [Batch 137/347] [D loss: 0.500097] [G loss: 0.264415]\n",
      "[Epoch 14/100] [Batch 138/347] [D loss: 0.499981] [G loss: 0.283744]\n",
      "[Epoch 14/100] [Batch 139/347] [D loss: 0.499872] [G loss: 0.307758]\n",
      "[Epoch 14/100] [Batch 140/347] [D loss: 0.499834] [G loss: 0.319274]\n",
      "[Epoch 14/100] [Batch 141/347] [D loss: 0.499796] [G loss: 0.326185]\n",
      "[Epoch 14/100] [Batch 142/347] [D loss: 0.499773] [G loss: 0.333948]\n",
      "[Epoch 14/100] [Batch 143/347] [D loss: 0.499686] [G loss: 0.355699]\n",
      "[Epoch 14/100] [Batch 144/347] [D loss: 0.499653] [G loss: 0.357966]\n",
      "[Epoch 14/100] [Batch 145/347] [D loss: 0.499667] [G loss: 0.343767]\n",
      "[Epoch 14/100] [Batch 146/347] [D loss: 0.499699] [G loss: 0.327047]\n",
      "[Epoch 14/100] [Batch 147/347] [D loss: 0.499818] [G loss: 0.299019]\n",
      "[Epoch 14/100] [Batch 148/347] [D loss: 0.499883] [G loss: 0.286740]\n",
      "[Epoch 14/100] [Batch 149/347] [D loss: 0.499836] [G loss: 0.300079]\n",
      "[Epoch 14/100] [Batch 150/347] [D loss: 0.499835] [G loss: 0.300586]\n",
      "[Epoch 14/100] [Batch 151/347] [D loss: 0.499915] [G loss: 0.289752]\n",
      "[Epoch 14/100] [Batch 152/347] [D loss: 0.499899] [G loss: 0.300935]\n",
      "[Epoch 14/100] [Batch 153/347] [D loss: 0.499802] [G loss: 0.321755]\n",
      "[Epoch 14/100] [Batch 154/347] [D loss: 0.499741] [G loss: 0.325973]\n",
      "[Epoch 14/100] [Batch 155/347] [D loss: 0.499780] [G loss: 0.313253]\n",
      "[Epoch 14/100] [Batch 156/347] [D loss: 0.499864] [G loss: 0.296804]\n",
      "[Epoch 14/100] [Batch 157/347] [D loss: 0.499902] [G loss: 0.303199]\n",
      "[Epoch 14/100] [Batch 158/347] [D loss: 0.499790] [G loss: 0.327047]\n",
      "[Epoch 14/100] [Batch 159/347] [D loss: 0.499748] [G loss: 0.324664]\n",
      "[Epoch 14/100] [Batch 160/347] [D loss: 0.499879] [G loss: 0.304848]\n",
      "[Epoch 14/100] [Batch 161/347] [D loss: 0.499961] [G loss: 0.296571]\n",
      "[Epoch 14/100] [Batch 162/347] [D loss: 0.499931] [G loss: 0.302492]\n",
      "[Epoch 14/100] [Batch 163/347] [D loss: 0.499847] [G loss: 0.321344]\n",
      "[Epoch 14/100] [Batch 164/347] [D loss: 0.499764] [G loss: 0.336730]\n",
      "[Epoch 14/100] [Batch 165/347] [D loss: 0.499757] [G loss: 0.327971]\n",
      "[Epoch 14/100] [Batch 166/347] [D loss: 0.499911] [G loss: 0.289872]\n",
      "[Epoch 14/100] [Batch 167/347] [D loss: 0.500096] [G loss: 0.268186]\n",
      "[Epoch 14/100] [Batch 168/347] [D loss: 0.500152] [G loss: 0.278812]\n",
      "[Epoch 14/100] [Batch 169/347] [D loss: 0.500177] [G loss: 0.277568]\n",
      "[Epoch 14/100] [Batch 170/347] [D loss: 0.500201] [G loss: 0.273614]\n",
      "[Epoch 14/100] [Batch 171/347] [D loss: 0.500247] [G loss: 0.283048]\n",
      "[Epoch 14/100] [Batch 172/347] [D loss: 0.500263] [G loss: 0.287945]\n",
      "[Epoch 14/100] [Batch 173/347] [D loss: 0.500214] [G loss: 0.276656]\n",
      "[Epoch 14/100] [Batch 174/347] [D loss: 0.500196] [G loss: 0.274141]\n",
      "[Epoch 14/100] [Batch 175/347] [D loss: 0.500220] [G loss: 0.283948]\n",
      "[Epoch 14/100] [Batch 176/347] [D loss: 0.500275] [G loss: 0.297295]\n",
      "[Epoch 14/100] [Batch 177/347] [D loss: 0.500277] [G loss: 0.298151]\n",
      "[Epoch 14/100] [Batch 178/347] [D loss: 0.500250] [G loss: 0.292152]\n",
      "[Epoch 14/100] [Batch 179/347] [D loss: 0.500218] [G loss: 0.285473]\n",
      "[Epoch 14/100] [Batch 180/347] [D loss: 0.500190] [G loss: 0.279044]\n",
      "[Epoch 14/100] [Batch 181/347] [D loss: 0.500192] [G loss: 0.279488]\n",
      "[Epoch 14/100] [Batch 182/347] [D loss: 0.500164] [G loss: 0.277288]\n",
      "[Epoch 14/100] [Batch 183/347] [D loss: 0.500184] [G loss: 0.281321]\n",
      "[Epoch 14/100] [Batch 184/347] [D loss: 0.500190] [G loss: 0.285152]\n",
      "[Epoch 14/100] [Batch 185/347] [D loss: 0.500185] [G loss: 0.283681]\n",
      "[Epoch 14/100] [Batch 186/347] [D loss: 0.500188] [G loss: 0.283431]\n",
      "[Epoch 14/100] [Batch 187/347] [D loss: 0.500171] [G loss: 0.278153]\n",
      "[Epoch 14/100] [Batch 188/347] [D loss: 0.500153] [G loss: 0.274932]\n",
      "[Epoch 14/100] [Batch 189/347] [D loss: 0.500149] [G loss: 0.274071]\n",
      "[Epoch 14/100] [Batch 190/347] [D loss: 0.500083] [G loss: 0.262147]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 14/100] [Batch 191/347] [D loss: 0.500011] [G loss: 0.263070]\n",
      "[Epoch 14/100] [Batch 192/347] [D loss: 0.500040] [G loss: 0.253714]\n",
      "[Epoch 14/100] [Batch 193/347] [D loss: 0.500093] [G loss: 0.260292]\n",
      "[Epoch 14/100] [Batch 194/347] [D loss: 0.500046] [G loss: 0.257645]\n",
      "[Epoch 14/100] [Batch 195/347] [D loss: 0.500011] [G loss: 0.266363]\n",
      "[Epoch 14/100] [Batch 196/347] [D loss: 0.499992] [G loss: 0.263987]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 14/100] [Batch 197/347] [D loss: 0.500002] [G loss: 0.259199]\n",
      "[Epoch 14/100] [Batch 198/347] [D loss: 0.500025] [G loss: 0.258015]\n",
      "[Epoch 14/100] [Batch 199/347] [D loss: 0.500023] [G loss: 0.259190]\n",
      "[Epoch 14/100] [Batch 200/347] [D loss: 0.500033] [G loss: 0.254104]\n",
      "[Epoch 14/100] [Batch 201/347] [D loss: 0.500044] [G loss: 0.254587]\n",
      "[Epoch 14/100] [Batch 202/347] [D loss: 0.499998] [G loss: 0.266080]\n",
      "[Epoch 14/100] [Batch 203/347] [D loss: 0.499960] [G loss: 0.274678]\n",
      "[Epoch 14/100] [Batch 204/347] [D loss: 0.499979] [G loss: 0.271104]\n",
      "[Epoch 14/100] [Batch 205/347] [D loss: 0.500004] [G loss: 0.263123]\n",
      "[Epoch 14/100] [Batch 206/347] [D loss: 0.500052] [G loss: 0.253491]\n",
      "[Epoch 14/100] [Batch 207/347] [D loss: 0.500127] [G loss: 0.264329]\n",
      "[Epoch 14/100] [Batch 208/347] [D loss: 0.500112] [G loss: 0.265173]\n",
      "[Epoch 14/100] [Batch 209/347] [D loss: 0.500085] [G loss: 0.259528]\n",
      "[Epoch 14/100] [Batch 210/347] [D loss: 0.500138] [G loss: 0.266802]\n",
      "[Epoch 14/100] [Batch 211/347] [D loss: 0.500129] [G loss: 0.263965]\n",
      "[Epoch 14/100] [Batch 212/347] [D loss: 0.500108] [G loss: 0.262783]\n",
      "[Epoch 14/100] [Batch 213/347] [D loss: 0.500105] [G loss: 0.268331]\n",
      "[Epoch 14/100] [Batch 214/347] [D loss: 0.500033] [G loss: 0.276574]\n",
      "[Epoch 14/100] [Batch 215/347] [D loss: 0.500000] [G loss: 0.284863]\n",
      "[Epoch 14/100] [Batch 216/347] [D loss: 0.500071] [G loss: 0.267321]\n",
      "[Epoch 14/100] [Batch 217/347] [D loss: 0.500120] [G loss: 0.267910]\n",
      "[Epoch 14/100] [Batch 218/347] [D loss: 0.500168] [G loss: 0.274676]\n",
      "[Epoch 14/100] [Batch 219/347] [D loss: 0.500228] [G loss: 0.286821]\n",
      "[Epoch 14/100] [Batch 220/347] [D loss: 0.500295] [G loss: 0.302579]\n",
      "[Epoch 14/100] [Batch 221/347] [D loss: 0.500308] [G loss: 0.303902]\n",
      "[Epoch 14/100] [Batch 222/347] [D loss: 0.500288] [G loss: 0.295808]\n",
      "[Epoch 14/100] [Batch 223/347] [D loss: 0.500282] [G loss: 0.294383]\n",
      "[Epoch 14/100] [Batch 224/347] [D loss: 0.500268] [G loss: 0.290177]\n",
      "[Epoch 14/100] [Batch 225/347] [D loss: 0.500160] [G loss: 0.276015]\n",
      "[Epoch 14/100] [Batch 226/347] [D loss: 0.499991] [G loss: 0.272486]\n",
      "[Epoch 14/100] [Batch 227/347] [D loss: 0.499883] [G loss: 0.282907]\n",
      "[Epoch 14/100] [Batch 228/347] [D loss: 0.499873] [G loss: 0.285201]\n",
      "[Epoch 14/100] [Batch 229/347] [D loss: 0.499916] [G loss: 0.280425]\n",
      "[Epoch 14/100] [Batch 230/347] [D loss: 0.499940] [G loss: 0.276695]\n",
      "[Epoch 14/100] [Batch 231/347] [D loss: 0.499911] [G loss: 0.276774]\n",
      "[Epoch 14/100] [Batch 232/347] [D loss: 0.499937] [G loss: 0.272760]\n",
      "[Epoch 14/100] [Batch 233/347] [D loss: 0.499953] [G loss: 0.270064]\n",
      "[Epoch 14/100] [Batch 234/347] [D loss: 0.499953] [G loss: 0.275110]\n",
      "[Epoch 14/100] [Batch 235/347] [D loss: 0.500021] [G loss: 0.263903]\n",
      "[Epoch 14/100] [Batch 236/347] [D loss: 0.500086] [G loss: 0.262776]\n",
      "[Epoch 14/100] [Batch 237/347] [D loss: 0.500133] [G loss: 0.266602]\n",
      "[Epoch 14/100] [Batch 238/347] [D loss: 0.500129] [G loss: 0.270606]\n",
      "[Epoch 14/100] [Batch 239/347] [D loss: 0.500116] [G loss: 0.268590]\n",
      "[Epoch 14/100] [Batch 240/347] [D loss: 0.500109] [G loss: 0.264739]\n",
      "[Epoch 14/100] [Batch 241/347] [D loss: 0.500086] [G loss: 0.258882]\n",
      "[Epoch 14/100] [Batch 242/347] [D loss: 0.500068] [G loss: 0.256822]\n",
      "[Epoch 14/100] [Batch 243/347] [D loss: 0.500097] [G loss: 0.264339]\n",
      "[Epoch 14/100] [Batch 244/347] [D loss: 0.500131] [G loss: 0.273044]\n",
      "[Epoch 14/100] [Batch 245/347] [D loss: 0.500172] [G loss: 0.271542]\n",
      "[Epoch 14/100] [Batch 246/347] [D loss: 0.500073] [G loss: 0.264135]\n",
      "[Epoch 14/100] [Batch 247/347] [D loss: 0.499946] [G loss: 0.271199]\n",
      "[Epoch 14/100] [Batch 248/347] [D loss: 0.499898] [G loss: 0.277164]\n",
      "[Epoch 14/100] [Batch 249/347] [D loss: 0.499867] [G loss: 0.282705]\n",
      "[Epoch 14/100] [Batch 250/347] [D loss: 0.499959] [G loss: 0.274140]\n",
      "[Epoch 14/100] [Batch 251/347] [D loss: 0.500075] [G loss: 0.264177]\n",
      "[Epoch 14/100] [Batch 252/347] [D loss: 0.500120] [G loss: 0.267386]\n",
      "[Epoch 14/100] [Batch 253/347] [D loss: 0.500122] [G loss: 0.267967]\n",
      "[Epoch 14/100] [Batch 254/347] [D loss: 0.500120] [G loss: 0.266327]\n",
      "[Epoch 14/100] [Batch 255/347] [D loss: 0.500093] [G loss: 0.264864]\n",
      "[Epoch 14/100] [Batch 256/347] [D loss: 0.500118] [G loss: 0.270017]\n",
      "[Epoch 14/100] [Batch 257/347] [D loss: 0.500167] [G loss: 0.272145]\n",
      "[Epoch 14/100] [Batch 258/347] [D loss: 0.500113] [G loss: 0.266522]\n",
      "[Epoch 14/100] [Batch 259/347] [D loss: 0.499984] [G loss: 0.273457]\n",
      "[Epoch 14/100] [Batch 260/347] [D loss: 0.499922] [G loss: 0.287799]\n",
      "[Epoch 14/100] [Batch 261/347] [D loss: 0.499970] [G loss: 0.280245]\n",
      "[Epoch 14/100] [Batch 262/347] [D loss: 0.500003] [G loss: 0.265107]\n",
      "[Epoch 14/100] [Batch 263/347] [D loss: 0.500000] [G loss: 0.266018]\n",
      "[Epoch 14/100] [Batch 264/347] [D loss: 0.499959] [G loss: 0.280475]\n",
      "[Epoch 14/100] [Batch 265/347] [D loss: 0.499935] [G loss: 0.285652]\n",
      "[Epoch 14/100] [Batch 266/347] [D loss: 0.499947] [G loss: 0.278492]\n",
      "[Epoch 14/100] [Batch 267/347] [D loss: 0.499968] [G loss: 0.271681]\n",
      "[Epoch 14/100] [Batch 268/347] [D loss: 0.499961] [G loss: 0.278565]\n",
      "[Epoch 14/100] [Batch 269/347] [D loss: 0.499930] [G loss: 0.289656]\n",
      "[Epoch 14/100] [Batch 270/347] [D loss: 0.499931] [G loss: 0.286203]\n",
      "[Epoch 14/100] [Batch 271/347] [D loss: 0.499961] [G loss: 0.274342]\n",
      "[Epoch 14/100] [Batch 272/347] [D loss: 0.499999] [G loss: 0.265688]\n",
      "[Epoch 14/100] [Batch 273/347] [D loss: 0.499986] [G loss: 0.277504]\n",
      "[Epoch 14/100] [Batch 274/347] [D loss: 0.499916] [G loss: 0.311279]\n",
      "[Epoch 14/100] [Batch 275/347] [D loss: 0.499920] [G loss: 0.308193]\n",
      "[Epoch 14/100] [Batch 276/347] [D loss: 0.499980] [G loss: 0.275749]\n",
      "[Epoch 14/100] [Batch 277/347] [D loss: 0.500018] [G loss: 0.261099]\n",
      "[Epoch 14/100] [Batch 278/347] [D loss: 0.500054] [G loss: 0.252917]\n",
      "[Epoch 14/100] [Batch 279/347] [D loss: 0.500059] [G loss: 0.259820]\n",
      "[Epoch 14/100] [Batch 280/347] [D loss: 0.500050] [G loss: 0.263346]\n",
      "[Epoch 14/100] [Batch 281/347] [D loss: 0.500053] [G loss: 0.261574]\n",
      "[Epoch 14/100] [Batch 282/347] [D loss: 0.500051] [G loss: 0.259407]\n",
      "[Epoch 14/100] [Batch 283/347] [D loss: 0.500025] [G loss: 0.262168]\n",
      "[Epoch 14/100] [Batch 284/347] [D loss: 0.500044] [G loss: 0.262127]\n",
      "[Epoch 14/100] [Batch 285/347] [D loss: 0.500055] [G loss: 0.258055]\n",
      "[Epoch 14/100] [Batch 286/347] [D loss: 0.500032] [G loss: 0.252026]\n",
      "[Epoch 14/100] [Batch 287/347] [D loss: 0.500030] [G loss: 0.255558]\n",
      "[Epoch 14/100] [Batch 288/347] [D loss: 0.499906] [G loss: 0.282046]\n",
      "[Epoch 14/100] [Batch 289/347] [D loss: 0.499885] [G loss: 0.286189]\n",
      "[Epoch 14/100] [Batch 290/347] [D loss: 0.499982] [G loss: 0.263424]\n",
      "[Epoch 14/100] [Batch 291/347] [D loss: 0.499962] [G loss: 0.265902]\n",
      "[Epoch 14/100] [Batch 292/347] [D loss: 0.500011] [G loss: 0.257127]\n",
      "[Epoch 14/100] [Batch 293/347] [D loss: 0.500140] [G loss: 0.270440]\n",
      "[Epoch 14/100] [Batch 294/347] [D loss: 0.500197] [G loss: 0.280353]\n",
      "[Epoch 14/100] [Batch 295/347] [D loss: 0.500153] [G loss: 0.278140]\n",
      "[Epoch 14/100] [Batch 296/347] [D loss: 0.500161] [G loss: 0.274251]\n",
      "[Epoch 14/100] [Batch 297/347] [D loss: 0.500200] [G loss: 0.285299]\n",
      "[Epoch 14/100] [Batch 298/347] [D loss: 0.500169] [G loss: 0.280260]\n",
      "[Epoch 14/100] [Batch 299/347] [D loss: 0.500180] [G loss: 0.278983]\n",
      "[Epoch 14/100] [Batch 300/347] [D loss: 0.500157] [G loss: 0.274339]\n",
      "[Epoch 14/100] [Batch 301/347] [D loss: 0.500173] [G loss: 0.276261]\n",
      "[Epoch 14/100] [Batch 302/347] [D loss: 0.500204] [G loss: 0.281420]\n",
      "[Epoch 14/100] [Batch 303/347] [D loss: 0.500087] [G loss: 0.265794]\n",
      "[Epoch 14/100] [Batch 304/347] [D loss: 0.499965] [G loss: 0.264023]\n",
      "[Epoch 14/100] [Batch 305/347] [D loss: 0.499930] [G loss: 0.276789]\n",
      "[Epoch 14/100] [Batch 306/347] [D loss: 0.499926] [G loss: 0.269191]\n",
      "[Epoch 14/100] [Batch 307/347] [D loss: 0.499914] [G loss: 0.281802]\n",
      "[Epoch 14/100] [Batch 308/347] [D loss: 0.499915] [G loss: 0.277953]\n",
      "[Epoch 14/100] [Batch 309/347] [D loss: 0.500012] [G loss: 0.257178]\n",
      "[Epoch 14/100] [Batch 310/347] [D loss: 0.500103] [G loss: 0.277774]\n",
      "[Epoch 14/100] [Batch 311/347] [D loss: 0.500106] [G loss: 0.280681]\n",
      "[Epoch 14/100] [Batch 312/347] [D loss: 0.500103] [G loss: 0.280416]\n",
      "[Epoch 14/100] [Batch 313/347] [D loss: 0.500109] [G loss: 0.279637]\n",
      "[Epoch 14/100] [Batch 314/347] [D loss: 0.500110] [G loss: 0.273243]\n",
      "[Epoch 14/100] [Batch 315/347] [D loss: 0.500115] [G loss: 0.263920]\n",
      "[Epoch 14/100] [Batch 316/347] [D loss: 0.500010] [G loss: 0.257199]\n",
      "[Epoch 14/100] [Batch 317/347] [D loss: 0.499911] [G loss: 0.275755]\n",
      "[Epoch 14/100] [Batch 318/347] [D loss: 0.500020] [G loss: 0.253525]\n",
      "[Epoch 14/100] [Batch 319/347] [D loss: 0.500165] [G loss: 0.286001]\n",
      "[Epoch 14/100] [Batch 320/347] [D loss: 0.500219] [G loss: 0.299645]\n",
      "[Epoch 14/100] [Batch 321/347] [D loss: 0.500185] [G loss: 0.289207]\n",
      "[Epoch 14/100] [Batch 322/347] [D loss: 0.500137] [G loss: 0.276191]\n",
      "[Epoch 14/100] [Batch 323/347] [D loss: 0.500138] [G loss: 0.275387]\n",
      "[Epoch 14/100] [Batch 324/347] [D loss: 0.500157] [G loss: 0.278344]\n",
      "[Epoch 14/100] [Batch 325/347] [D loss: 0.500119] [G loss: 0.267469]\n",
      "[Epoch 14/100] [Batch 326/347] [D loss: 0.500062] [G loss: 0.257490]\n",
      "[Epoch 14/100] [Batch 327/347] [D loss: 0.500064] [G loss: 0.255556]\n",
      "[Epoch 14/100] [Batch 328/347] [D loss: 0.500042] [G loss: 0.252841]\n",
      "[Epoch 14/100] [Batch 329/347] [D loss: 0.499953] [G loss: 0.272702]\n",
      "[Epoch 14/100] [Batch 330/347] [D loss: 0.499870] [G loss: 0.288418]\n",
      "[Epoch 14/100] [Batch 331/347] [D loss: 0.499945] [G loss: 0.270416]\n",
      "[Epoch 14/100] [Batch 332/347] [D loss: 0.500069] [G loss: 0.266159]\n",
      "[Epoch 14/100] [Batch 333/347] [D loss: 0.500101] [G loss: 0.277441]\n",
      "[Epoch 14/100] [Batch 334/347] [D loss: 0.500123] [G loss: 0.278789]\n",
      "[Epoch 14/100] [Batch 335/347] [D loss: 0.500098] [G loss: 0.266729]\n",
      "[Epoch 14/100] [Batch 336/347] [D loss: 0.500043] [G loss: 0.252855]\n",
      "[Epoch 14/100] [Batch 337/347] [D loss: 0.500049] [G loss: 0.258207]\n",
      "[Epoch 14/100] [Batch 338/347] [D loss: 0.500093] [G loss: 0.272660]\n",
      "[Epoch 14/100] [Batch 339/347] [D loss: 0.500112] [G loss: 0.277955]\n",
      "[Epoch 14/100] [Batch 340/347] [D loss: 0.500104] [G loss: 0.278215]\n",
      "[Epoch 14/100] [Batch 341/347] [D loss: 0.500097] [G loss: 0.273324]\n",
      "[Epoch 14/100] [Batch 342/347] [D loss: 0.500069] [G loss: 0.265598]\n",
      "[Epoch 14/100] [Batch 343/347] [D loss: 0.500061] [G loss: 0.270206]\n",
      "[Epoch 14/100] [Batch 344/347] [D loss: 0.500019] [G loss: 0.264759]\n",
      "[Epoch 14/100] [Batch 345/347] [D loss: 0.499903] [G loss: 0.274793]\n",
      "[Epoch 14/100] [Batch 346/347] [D loss: 0.499841] [G loss: 0.293308]\n",
      "[Epoch 14/100] [Batch 347/347] [D loss: 0.499829] [G loss: 0.299567]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 15/100] [Batch 1/347] [D loss: 0.499977] [G loss: 0.266127]\n",
      "[Epoch 15/100] [Batch 2/347] [D loss: 0.499972] [G loss: 0.271396]\n",
      "[Epoch 15/100] [Batch 3/347] [D loss: 0.499998] [G loss: 0.271314]\n",
      "[Epoch 15/100] [Batch 4/347] [D loss: 0.499998] [G loss: 0.272596]\n",
      "[Epoch 15/100] [Batch 5/347] [D loss: 0.499999] [G loss: 0.271866]\n",
      "[Epoch 15/100] [Batch 6/347] [D loss: 0.500003] [G loss: 0.272185]\n",
      "[Epoch 15/100] [Batch 7/347] [D loss: 0.499988] [G loss: 0.272015]\n",
      "[Epoch 15/100] [Batch 8/347] [D loss: 0.499993] [G loss: 0.267334]\n",
      "[Epoch 15/100] [Batch 9/347] [D loss: 0.499960] [G loss: 0.266303]\n",
      "[Epoch 15/100] [Batch 10/347] [D loss: 0.499961] [G loss: 0.267875]\n",
      "[Epoch 15/100] [Batch 11/347] [D loss: 0.500004] [G loss: 0.267618]\n",
      "[Epoch 15/100] [Batch 12/347] [D loss: 0.500016] [G loss: 0.268156]\n",
      "[Epoch 15/100] [Batch 13/347] [D loss: 0.500046] [G loss: 0.267234]\n",
      "[Epoch 15/100] [Batch 14/347] [D loss: 0.500068] [G loss: 0.269579]\n",
      "[Epoch 15/100] [Batch 15/347] [D loss: 0.500057] [G loss: 0.265786]\n",
      "[Epoch 15/100] [Batch 16/347] [D loss: 0.500051] [G loss: 0.261689]\n",
      "[Epoch 15/100] [Batch 17/347] [D loss: 0.500029] [G loss: 0.252489]\n",
      "[Epoch 15/100] [Batch 18/347] [D loss: 0.500004] [G loss: 0.257981]\n",
      "[Epoch 15/100] [Batch 19/347] [D loss: 0.500050] [G loss: 0.255533]\n",
      "[Epoch 15/100] [Batch 20/347] [D loss: 0.500089] [G loss: 0.268806]\n",
      "[Epoch 15/100] [Batch 21/347] [D loss: 0.500065] [G loss: 0.265297]\n",
      "[Epoch 15/100] [Batch 22/347] [D loss: 0.500047] [G loss: 0.260468]\n",
      "[Epoch 15/100] [Batch 23/347] [D loss: 0.500035] [G loss: 0.254308]\n",
      "[Epoch 15/100] [Batch 24/347] [D loss: 0.500042] [G loss: 0.253670]\n",
      "[Epoch 15/100] [Batch 25/347] [D loss: 0.500035] [G loss: 0.253131]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 15/100] [Batch 26/347] [D loss: 0.499971] [G loss: 0.262261]\n",
      "[Epoch 15/100] [Batch 27/347] [D loss: 0.499991] [G loss: 0.268003]\n",
      "[Epoch 15/100] [Batch 28/347] [D loss: 0.500065] [G loss: 0.266721]\n",
      "[Epoch 15/100] [Batch 29/347] [D loss: 0.500101] [G loss: 0.264263]\n",
      "[Epoch 15/100] [Batch 30/347] [D loss: 0.500131] [G loss: 0.271221]\n",
      "[Epoch 15/100] [Batch 31/347] [D loss: 0.500153] [G loss: 0.273805]\n",
      "[Epoch 15/100] [Batch 32/347] [D loss: 0.500133] [G loss: 0.267214]\n",
      "[Epoch 15/100] [Batch 33/347] [D loss: 0.500096] [G loss: 0.263247]\n",
      "[Epoch 15/100] [Batch 34/347] [D loss: 0.500091] [G loss: 0.264359]\n",
      "[Epoch 15/100] [Batch 35/347] [D loss: 0.500091] [G loss: 0.263221]\n",
      "[Epoch 15/100] [Batch 36/347] [D loss: 0.500054] [G loss: 0.254097]\n",
      "[Epoch 15/100] [Batch 37/347] [D loss: 0.499947] [G loss: 0.273706]\n",
      "[Epoch 15/100] [Batch 38/347] [D loss: 0.499861] [G loss: 0.288944]\n",
      "[Epoch 15/100] [Batch 39/347] [D loss: 0.499878] [G loss: 0.279439]\n",
      "[Epoch 15/100] [Batch 40/347] [D loss: 0.499885] [G loss: 0.279880]\n",
      "[Epoch 15/100] [Batch 41/347] [D loss: 0.499871] [G loss: 0.281249]\n",
      "[Epoch 15/100] [Batch 42/347] [D loss: 0.499892] [G loss: 0.274251]\n",
      "[Epoch 15/100] [Batch 43/347] [D loss: 0.499991] [G loss: 0.258287]\n",
      "[Epoch 15/100] [Batch 44/347] [D loss: 0.500086] [G loss: 0.262464]\n",
      "[Epoch 15/100] [Batch 45/347] [D loss: 0.500150] [G loss: 0.279834]\n",
      "[Epoch 15/100] [Batch 46/347] [D loss: 0.500142] [G loss: 0.274569]\n",
      "[Epoch 15/100] [Batch 47/347] [D loss: 0.500016] [G loss: 0.256336]\n",
      "[Epoch 15/100] [Batch 48/347] [D loss: 0.499890] [G loss: 0.288683]\n",
      "[Epoch 15/100] [Batch 49/347] [D loss: 0.499847] [G loss: 0.297248]\n",
      "[Epoch 15/100] [Batch 50/347] [D loss: 0.499826] [G loss: 0.312888]\n",
      "[Epoch 15/100] [Batch 51/347] [D loss: 0.499923] [G loss: 0.297514]\n",
      "[Epoch 15/100] [Batch 52/347] [D loss: 0.500055] [G loss: 0.262122]\n",
      "[Epoch 15/100] [Batch 53/347] [D loss: 0.500029] [G loss: 0.260255]\n",
      "[Epoch 15/100] [Batch 54/347] [D loss: 0.499822] [G loss: 0.312846]\n",
      "[Epoch 15/100] [Batch 55/347] [D loss: 0.499657] [G loss: 0.335283]\n",
      "[Epoch 15/100] [Batch 56/347] [D loss: 0.499688] [G loss: 0.322264]\n",
      "[Epoch 15/100] [Batch 57/347] [D loss: 0.499902] [G loss: 0.287878]\n",
      "[Epoch 15/100] [Batch 58/347] [D loss: 0.500051] [G loss: 0.260848]\n",
      "[Epoch 15/100] [Batch 59/347] [D loss: 0.500003] [G loss: 0.270731]\n",
      "[Epoch 15/100] [Batch 60/347] [D loss: 0.499933] [G loss: 0.289500]\n",
      "[Epoch 15/100] [Batch 61/347] [D loss: 0.499884] [G loss: 0.302045]\n",
      "[Epoch 15/100] [Batch 62/347] [D loss: 0.499765] [G loss: 0.326046]\n",
      "[Epoch 15/100] [Batch 63/347] [D loss: 0.499676] [G loss: 0.328150]\n",
      "[Epoch 15/100] [Batch 64/347] [D loss: 0.499864] [G loss: 0.291304]\n",
      "[Epoch 15/100] [Batch 65/347] [D loss: 0.500111] [G loss: 0.264915]\n",
      "[Epoch 15/100] [Batch 66/347] [D loss: 0.500096] [G loss: 0.267236]\n",
      "[Epoch 15/100] [Batch 67/347] [D loss: 0.499980] [G loss: 0.275107]\n",
      "[Epoch 15/100] [Batch 68/347] [D loss: 0.499905] [G loss: 0.293171]\n",
      "[Epoch 15/100] [Batch 69/347] [D loss: 0.499773] [G loss: 0.312102]\n",
      "[Epoch 15/100] [Batch 70/347] [D loss: 0.499741] [G loss: 0.310892]\n",
      "[Epoch 15/100] [Batch 71/347] [D loss: 0.499778] [G loss: 0.313283]\n",
      "[Epoch 15/100] [Batch 72/347] [D loss: 0.499750] [G loss: 0.315826]\n",
      "[Epoch 15/100] [Batch 73/347] [D loss: 0.499860] [G loss: 0.291117]\n",
      "[Epoch 15/100] [Batch 74/347] [D loss: 0.499981] [G loss: 0.277201]\n",
      "[Epoch 15/100] [Batch 75/347] [D loss: 0.499857] [G loss: 0.307019]\n",
      "[Epoch 15/100] [Batch 76/347] [D loss: 0.499775] [G loss: 0.309033]\n",
      "[Epoch 15/100] [Batch 77/347] [D loss: 0.499940] [G loss: 0.274750]\n",
      "[Epoch 15/100] [Batch 78/347] [D loss: 0.500134] [G loss: 0.271170]\n",
      "[Epoch 15/100] [Batch 79/347] [D loss: 0.500178] [G loss: 0.272833]\n",
      "[Epoch 15/100] [Batch 80/347] [D loss: 0.500150] [G loss: 0.269225]\n",
      "[Epoch 15/100] [Batch 81/347] [D loss: 0.500188] [G loss: 0.274190]\n",
      "[Epoch 15/100] [Batch 82/347] [D loss: 0.500187] [G loss: 0.280098]\n",
      "[Epoch 15/100] [Batch 83/347] [D loss: 0.500162] [G loss: 0.272432]\n",
      "[Epoch 15/100] [Batch 84/347] [D loss: 0.500170] [G loss: 0.277995]\n",
      "[Epoch 15/100] [Batch 85/347] [D loss: 0.500152] [G loss: 0.278772]\n",
      "[Epoch 15/100] [Batch 86/347] [D loss: 0.500135] [G loss: 0.273195]\n",
      "[Epoch 15/100] [Batch 87/347] [D loss: 0.500118] [G loss: 0.271055]\n",
      "[Epoch 15/100] [Batch 88/347] [D loss: 0.500126] [G loss: 0.274441]\n",
      "[Epoch 15/100] [Batch 89/347] [D loss: 0.500125] [G loss: 0.277801]\n",
      "[Epoch 15/100] [Batch 90/347] [D loss: 0.500115] [G loss: 0.274022]\n",
      "[Epoch 15/100] [Batch 91/347] [D loss: 0.500103] [G loss: 0.272580]\n",
      "[Epoch 15/100] [Batch 92/347] [D loss: 0.500103] [G loss: 0.274071]\n",
      "[Epoch 15/100] [Batch 93/347] [D loss: 0.500093] [G loss: 0.272145]\n",
      "[Epoch 15/100] [Batch 94/347] [D loss: 0.500078] [G loss: 0.268585]\n",
      "[Epoch 15/100] [Batch 95/347] [D loss: 0.500078] [G loss: 0.269128]\n",
      "[Epoch 15/100] [Batch 96/347] [D loss: 0.500066] [G loss: 0.264445]\n",
      "[Epoch 15/100] [Batch 97/347] [D loss: 0.500038] [G loss: 0.259388]\n",
      "[Epoch 15/100] [Batch 98/347] [D loss: 0.500047] [G loss: 0.264331]\n",
      "[Epoch 15/100] [Batch 99/347] [D loss: 0.500060] [G loss: 0.268087]\n",
      "[Epoch 15/100] [Batch 100/347] [D loss: 0.500049] [G loss: 0.264505]\n",
      "[Epoch 15/100] [Batch 101/347] [D loss: 0.500022] [G loss: 0.261217]\n",
      "[Epoch 15/100] [Batch 102/347] [D loss: 0.500029] [G loss: 0.262046]\n",
      "[Epoch 15/100] [Batch 103/347] [D loss: 0.500034] [G loss: 0.262347]\n",
      "[Epoch 15/100] [Batch 104/347] [D loss: 0.499998] [G loss: 0.263686]\n",
      "[Epoch 15/100] [Batch 105/347] [D loss: 0.499993] [G loss: 0.265442]\n",
      "[Epoch 15/100] [Batch 106/347] [D loss: 0.499995] [G loss: 0.264552]\n",
      "[Epoch 15/100] [Batch 107/347] [D loss: 0.499986] [G loss: 0.258683]\n",
      "[Epoch 15/100] [Batch 108/347] [D loss: 0.499969] [G loss: 0.275658]\n",
      "[Epoch 15/100] [Batch 109/347] [D loss: 0.500015] [G loss: 0.268787]\n",
      "[Epoch 15/100] [Batch 110/347] [D loss: 0.500065] [G loss: 0.256679]\n",
      "[Epoch 15/100] [Batch 111/347] [D loss: 0.500025] [G loss: 0.262925]\n",
      "[Epoch 15/100] [Batch 112/347] [D loss: 0.500035] [G loss: 0.267138]\n",
      "[Epoch 15/100] [Batch 113/347] [D loss: 0.500133] [G loss: 0.272197]\n",
      "[Epoch 15/100] [Batch 114/347] [D loss: 0.500198] [G loss: 0.292919]\n",
      "[Epoch 15/100] [Batch 115/347] [D loss: 0.500208] [G loss: 0.294120]\n",
      "[Epoch 15/100] [Batch 116/347] [D loss: 0.500192] [G loss: 0.288318]\n",
      "[Epoch 15/100] [Batch 117/347] [D loss: 0.500107] [G loss: 0.262196]\n",
      "[Epoch 15/100] [Batch 118/347] [D loss: 0.499978] [G loss: 0.266263]\n",
      "[Epoch 15/100] [Batch 119/347] [D loss: 0.499951] [G loss: 0.268386]\n",
      "[Epoch 15/100] [Batch 120/347] [D loss: 0.499968] [G loss: 0.267243]\n",
      "[Epoch 15/100] [Batch 121/347] [D loss: 0.499973] [G loss: 0.265501]\n",
      "[Epoch 15/100] [Batch 122/347] [D loss: 0.500017] [G loss: 0.252510]\n",
      "[Epoch 15/100] [Batch 123/347] [D loss: 0.500028] [G loss: 0.251848]\n",
      "[Epoch 15/100] [Batch 124/347] [D loss: 0.500006] [G loss: 0.253372]\n",
      "[Epoch 15/100] [Batch 125/347] [D loss: 0.500059] [G loss: 0.259275]\n",
      "[Epoch 15/100] [Batch 126/347] [D loss: 0.500115] [G loss: 0.271737]\n",
      "[Epoch 15/100] [Batch 127/347] [D loss: 0.500130] [G loss: 0.273010]\n",
      "[Epoch 15/100] [Batch 128/347] [D loss: 0.500101] [G loss: 0.267400]\n",
      "[Epoch 15/100] [Batch 129/347] [D loss: 0.500097] [G loss: 0.262363]\n",
      "[Epoch 15/100] [Batch 130/347] [D loss: 0.500090] [G loss: 0.265304]\n",
      "[Epoch 15/100] [Batch 131/347] [D loss: 0.500019] [G loss: 0.264055]\n",
      "[Epoch 15/100] [Batch 132/347] [D loss: 0.499933] [G loss: 0.288742]\n",
      "[Epoch 15/100] [Batch 133/347] [D loss: 0.499903] [G loss: 0.295562]\n",
      "[Epoch 15/100] [Batch 134/347] [D loss: 0.499843] [G loss: 0.310527]\n",
      "[Epoch 15/100] [Batch 135/347] [D loss: 0.499839] [G loss: 0.319588]\n",
      "[Epoch 15/100] [Batch 136/347] [D loss: 0.499993] [G loss: 0.277764]\n",
      "[Epoch 15/100] [Batch 137/347] [D loss: 0.500071] [G loss: 0.265088]\n",
      "[Epoch 15/100] [Batch 138/347] [D loss: 0.499937] [G loss: 0.283012]\n",
      "[Epoch 15/100] [Batch 139/347] [D loss: 0.499809] [G loss: 0.307017]\n",
      "[Epoch 15/100] [Batch 140/347] [D loss: 0.499767] [G loss: 0.318519]\n",
      "[Epoch 15/100] [Batch 141/347] [D loss: 0.499717] [G loss: 0.325446]\n",
      "[Epoch 15/100] [Batch 142/347] [D loss: 0.499695] [G loss: 0.333172]\n",
      "[Epoch 15/100] [Batch 143/347] [D loss: 0.499594] [G loss: 0.354866]\n",
      "[Epoch 15/100] [Batch 144/347] [D loss: 0.499554] [G loss: 0.357153]\n",
      "[Epoch 15/100] [Batch 145/347] [D loss: 0.499574] [G loss: 0.342904]\n",
      "[Epoch 15/100] [Batch 146/347] [D loss: 0.499611] [G loss: 0.326172]\n",
      "[Epoch 15/100] [Batch 147/347] [D loss: 0.499746] [G loss: 0.298130]\n",
      "[Epoch 15/100] [Batch 148/347] [D loss: 0.499829] [G loss: 0.285828]\n",
      "[Epoch 15/100] [Batch 149/347] [D loss: 0.499768] [G loss: 0.299197]\n",
      "[Epoch 15/100] [Batch 150/347] [D loss: 0.499769] [G loss: 0.299738]\n",
      "[Epoch 15/100] [Batch 151/347] [D loss: 0.499862] [G loss: 0.288918]\n",
      "[Epoch 15/100] [Batch 152/347] [D loss: 0.499843] [G loss: 0.300118]\n",
      "[Epoch 15/100] [Batch 153/347] [D loss: 0.499731] [G loss: 0.320923]\n",
      "[Epoch 15/100] [Batch 154/347] [D loss: 0.499658] [G loss: 0.325166]\n",
      "[Epoch 15/100] [Batch 155/347] [D loss: 0.499706] [G loss: 0.312455]\n",
      "[Epoch 15/100] [Batch 156/347] [D loss: 0.499800] [G loss: 0.295980]\n",
      "[Epoch 15/100] [Batch 157/347] [D loss: 0.499840] [G loss: 0.302401]\n",
      "[Epoch 15/100] [Batch 158/347] [D loss: 0.499713] [G loss: 0.326277]\n",
      "[Epoch 15/100] [Batch 159/347] [D loss: 0.499666] [G loss: 0.323891]\n",
      "[Epoch 15/100] [Batch 160/347] [D loss: 0.499819] [G loss: 0.304104]\n",
      "[Epoch 15/100] [Batch 161/347] [D loss: 0.499911] [G loss: 0.295860]\n",
      "[Epoch 15/100] [Batch 162/347] [D loss: 0.499876] [G loss: 0.301812]\n",
      "[Epoch 15/100] [Batch 163/347] [D loss: 0.499779] [G loss: 0.320680]\n",
      "[Epoch 15/100] [Batch 164/347] [D loss: 0.499677] [G loss: 0.336128]\n",
      "[Epoch 15/100] [Batch 165/347] [D loss: 0.499679] [G loss: 0.327393]\n",
      "[Epoch 15/100] [Batch 166/347] [D loss: 0.499856] [G loss: 0.289306]\n",
      "[Epoch 15/100] [Batch 167/347] [D loss: 0.500067] [G loss: 0.268728]\n",
      "[Epoch 15/100] [Batch 168/347] [D loss: 0.500135] [G loss: 0.279346]\n",
      "[Epoch 15/100] [Batch 169/347] [D loss: 0.500165] [G loss: 0.278055]\n",
      "[Epoch 15/100] [Batch 170/347] [D loss: 0.500189] [G loss: 0.274130]\n",
      "[Epoch 15/100] [Batch 171/347] [D loss: 0.500243] [G loss: 0.283199]\n",
      "[Epoch 15/100] [Batch 172/347] [D loss: 0.500264] [G loss: 0.288079]\n",
      "[Epoch 15/100] [Batch 173/347] [D loss: 0.500206] [G loss: 0.276827]\n",
      "[Epoch 15/100] [Batch 174/347] [D loss: 0.500185] [G loss: 0.274338]\n",
      "[Epoch 15/100] [Batch 175/347] [D loss: 0.500216] [G loss: 0.284203]\n",
      "[Epoch 15/100] [Batch 176/347] [D loss: 0.500278] [G loss: 0.297615]\n",
      "[Epoch 15/100] [Batch 177/347] [D loss: 0.500271] [G loss: 0.298526]\n",
      "[Epoch 15/100] [Batch 178/347] [D loss: 0.500250] [G loss: 0.292533]\n",
      "[Epoch 15/100] [Batch 179/347] [D loss: 0.500213] [G loss: 0.285897]\n",
      "[Epoch 15/100] [Batch 180/347] [D loss: 0.500181] [G loss: 0.279538]\n",
      "[Epoch 15/100] [Batch 181/347] [D loss: 0.500181] [G loss: 0.280013]\n",
      "[Epoch 15/100] [Batch 182/347] [D loss: 0.500149] [G loss: 0.277915]\n",
      "[Epoch 15/100] [Batch 183/347] [D loss: 0.500170] [G loss: 0.281942]\n",
      "[Epoch 15/100] [Batch 184/347] [D loss: 0.500179] [G loss: 0.285835]\n",
      "[Epoch 15/100] [Batch 185/347] [D loss: 0.500175] [G loss: 0.284403]\n",
      "[Epoch 15/100] [Batch 186/347] [D loss: 0.500182] [G loss: 0.284199]\n",
      "[Epoch 15/100] [Batch 187/347] [D loss: 0.500163] [G loss: 0.278933]\n",
      "[Epoch 15/100] [Batch 188/347] [D loss: 0.500139] [G loss: 0.275710]\n",
      "[Epoch 15/100] [Batch 189/347] [D loss: 0.500133] [G loss: 0.274868]\n",
      "[Epoch 15/100] [Batch 190/347] [D loss: 0.500059] [G loss: 0.262986]\n",
      "[Epoch 15/100] [Batch 191/347] [D loss: 0.499974] [G loss: 0.262655]\n",
      "[Epoch 15/100] [Batch 192/347] [D loss: 0.500011] [G loss: 0.253243]\n",
      "[Epoch 15/100] [Batch 193/347] [D loss: 0.500069] [G loss: 0.261110]\n",
      "[Epoch 15/100] [Batch 194/347] [D loss: 0.500017] [G loss: 0.257091]\n",
      "[Epoch 15/100] [Batch 195/347] [D loss: 0.499976] [G loss: 0.265738]\n",
      "[Epoch 15/100] [Batch 196/347] [D loss: 0.499956] [G loss: 0.263338]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 15/100] [Batch 197/347] [D loss: 0.499964] [G loss: 0.258533]\n",
      "[Epoch 15/100] [Batch 198/347] [D loss: 0.499993] [G loss: 0.257638]\n",
      "[Epoch 15/100] [Batch 199/347] [D loss: 0.499994] [G loss: 0.258728]\n",
      "[Epoch 15/100] [Batch 200/347] [D loss: 0.500005] [G loss: 0.253559]\n",
      "[Epoch 15/100] [Batch 201/347] [D loss: 0.500016] [G loss: 0.253631]\n",
      "[Epoch 15/100] [Batch 202/347] [D loss: 0.499959] [G loss: 0.265141]\n",
      "[Epoch 15/100] [Batch 203/347] [D loss: 0.499921] [G loss: 0.273673]\n",
      "[Epoch 15/100] [Batch 204/347] [D loss: 0.499938] [G loss: 0.270025]\n",
      "[Epoch 15/100] [Batch 205/347] [D loss: 0.499967] [G loss: 0.261996]\n",
      "[Epoch 15/100] [Batch 206/347] [D loss: 0.500023] [G loss: 0.253659]\n",
      "[Epoch 15/100] [Batch 207/347] [D loss: 0.500112] [G loss: 0.264452]\n",
      "[Epoch 15/100] [Batch 208/347] [D loss: 0.500091] [G loss: 0.265244]\n",
      "[Epoch 15/100] [Batch 209/347] [D loss: 0.500060] [G loss: 0.259576]\n",
      "[Epoch 15/100] [Batch 210/347] [D loss: 0.500124] [G loss: 0.267153]\n",
      "[Epoch 15/100] [Batch 211/347] [D loss: 0.500113] [G loss: 0.264289]\n",
      "[Epoch 15/100] [Batch 212/347] [D loss: 0.500090] [G loss: 0.263045]\n",
      "[Epoch 15/100] [Batch 213/347] [D loss: 0.500085] [G loss: 0.268612]\n",
      "[Epoch 15/100] [Batch 214/347] [D loss: 0.499998] [G loss: 0.275544]\n",
      "[Epoch 15/100] [Batch 215/347] [D loss: 0.499962] [G loss: 0.283831]\n",
      "[Epoch 15/100] [Batch 216/347] [D loss: 0.500047] [G loss: 0.267529]\n",
      "[Epoch 15/100] [Batch 217/347] [D loss: 0.500106] [G loss: 0.268179]\n",
      "[Epoch 15/100] [Batch 218/347] [D loss: 0.500159] [G loss: 0.274638]\n",
      "[Epoch 15/100] [Batch 219/347] [D loss: 0.500227] [G loss: 0.286781]\n",
      "[Epoch 15/100] [Batch 220/347] [D loss: 0.500308] [G loss: 0.302590]\n",
      "[Epoch 15/100] [Batch 221/347] [D loss: 0.500321] [G loss: 0.303962]\n",
      "[Epoch 15/100] [Batch 222/347] [D loss: 0.500295] [G loss: 0.295868]\n",
      "[Epoch 15/100] [Batch 223/347] [D loss: 0.500294] [G loss: 0.294435]\n",
      "[Epoch 15/100] [Batch 224/347] [D loss: 0.500273] [G loss: 0.290295]\n",
      "[Epoch 15/100] [Batch 225/347] [D loss: 0.500149] [G loss: 0.276530]\n",
      "[Epoch 15/100] [Batch 226/347] [D loss: 0.499951] [G loss: 0.271654]\n",
      "[Epoch 15/100] [Batch 227/347] [D loss: 0.499828] [G loss: 0.282091]\n",
      "[Epoch 15/100] [Batch 228/347] [D loss: 0.499814] [G loss: 0.284012]\n",
      "[Epoch 15/100] [Batch 229/347] [D loss: 0.499866] [G loss: 0.279203]\n",
      "[Epoch 15/100] [Batch 230/347] [D loss: 0.499896] [G loss: 0.275441]\n",
      "[Epoch 15/100] [Batch 231/347] [D loss: 0.499861] [G loss: 0.275495]\n",
      "[Epoch 15/100] [Batch 232/347] [D loss: 0.499893] [G loss: 0.271476]\n",
      "[Epoch 15/100] [Batch 233/347] [D loss: 0.499912] [G loss: 0.269120]\n",
      "[Epoch 15/100] [Batch 234/347] [D loss: 0.499910] [G loss: 0.274128]\n",
      "[Epoch 15/100] [Batch 235/347] [D loss: 0.499987] [G loss: 0.262917]\n",
      "[Epoch 15/100] [Batch 236/347] [D loss: 0.500063] [G loss: 0.263416]\n",
      "[Epoch 15/100] [Batch 237/347] [D loss: 0.500118] [G loss: 0.266895]\n",
      "[Epoch 15/100] [Batch 238/347] [D loss: 0.500114] [G loss: 0.270866]\n",
      "[Epoch 15/100] [Batch 239/347] [D loss: 0.500100] [G loss: 0.268804]\n",
      "[Epoch 15/100] [Batch 240/347] [D loss: 0.500089] [G loss: 0.264914]\n",
      "[Epoch 15/100] [Batch 241/347] [D loss: 0.500064] [G loss: 0.259010]\n",
      "[Epoch 15/100] [Batch 242/347] [D loss: 0.500044] [G loss: 0.256948]\n",
      "[Epoch 15/100] [Batch 243/347] [D loss: 0.500076] [G loss: 0.264449]\n",
      "[Epoch 15/100] [Batch 244/347] [D loss: 0.500114] [G loss: 0.273172]\n",
      "[Epoch 15/100] [Batch 245/347] [D loss: 0.500163] [G loss: 0.271670]\n",
      "[Epoch 15/100] [Batch 246/347] [D loss: 0.500050] [G loss: 0.264587]\n",
      "[Epoch 15/100] [Batch 247/347] [D loss: 0.499904] [G loss: 0.270002]\n",
      "[Epoch 15/100] [Batch 248/347] [D loss: 0.499846] [G loss: 0.275652]\n",
      "[Epoch 15/100] [Batch 249/347] [D loss: 0.499818] [G loss: 0.281457]\n",
      "[Epoch 15/100] [Batch 250/347] [D loss: 0.499920] [G loss: 0.272854]\n",
      "[Epoch 15/100] [Batch 251/347] [D loss: 0.500053] [G loss: 0.264628]\n",
      "[Epoch 15/100] [Batch 252/347] [D loss: 0.500103] [G loss: 0.267828]\n",
      "[Epoch 15/100] [Batch 253/347] [D loss: 0.500109] [G loss: 0.268413]\n",
      "[Epoch 15/100] [Batch 254/347] [D loss: 0.500105] [G loss: 0.266733]\n",
      "[Epoch 15/100] [Batch 255/347] [D loss: 0.500070] [G loss: 0.265291]\n",
      "[Epoch 15/100] [Batch 256/347] [D loss: 0.500104] [G loss: 0.270447]\n",
      "[Epoch 15/100] [Batch 257/347] [D loss: 0.500160] [G loss: 0.272255]\n",
      "[Epoch 15/100] [Batch 258/347] [D loss: 0.500093] [G loss: 0.266962]\n",
      "[Epoch 15/100] [Batch 259/347] [D loss: 0.499947] [G loss: 0.272087]\n",
      "[Epoch 15/100] [Batch 260/347] [D loss: 0.499876] [G loss: 0.286419]\n",
      "[Epoch 15/100] [Batch 261/347] [D loss: 0.499933] [G loss: 0.278870]\n",
      "[Epoch 15/100] [Batch 262/347] [D loss: 0.499972] [G loss: 0.263717]\n",
      "[Epoch 15/100] [Batch 263/347] [D loss: 0.499966] [G loss: 0.264620]\n",
      "[Epoch 15/100] [Batch 264/347] [D loss: 0.499916] [G loss: 0.279064]\n",
      "[Epoch 15/100] [Batch 265/347] [D loss: 0.499887] [G loss: 0.284246]\n",
      "[Epoch 15/100] [Batch 266/347] [D loss: 0.499904] [G loss: 0.277091]\n",
      "[Epoch 15/100] [Batch 267/347] [D loss: 0.499928] [G loss: 0.270295]\n",
      "[Epoch 15/100] [Batch 268/347] [D loss: 0.499919] [G loss: 0.277147]\n",
      "[Epoch 15/100] [Batch 269/347] [D loss: 0.499887] [G loss: 0.288245]\n",
      "[Epoch 15/100] [Batch 270/347] [D loss: 0.499885] [G loss: 0.284804]\n",
      "[Epoch 15/100] [Batch 271/347] [D loss: 0.499921] [G loss: 0.272996]\n",
      "[Epoch 15/100] [Batch 272/347] [D loss: 0.499965] [G loss: 0.264333]\n",
      "[Epoch 15/100] [Batch 273/347] [D loss: 0.499954] [G loss: 0.276152]\n",
      "[Epoch 15/100] [Batch 274/347] [D loss: 0.499865] [G loss: 0.309963]\n",
      "[Epoch 15/100] [Batch 275/347] [D loss: 0.499867] [G loss: 0.306874]\n",
      "[Epoch 15/100] [Batch 276/347] [D loss: 0.499945] [G loss: 0.274460]\n",
      "[Epoch 15/100] [Batch 277/347] [D loss: 0.499985] [G loss: 0.259858]\n",
      "[Epoch 15/100] [Batch 278/347] [D loss: 0.500029] [G loss: 0.253327]\n",
      "[Epoch 15/100] [Batch 279/347] [D loss: 0.500032] [G loss: 0.260231]\n",
      "[Epoch 15/100] [Batch 280/347] [D loss: 0.500024] [G loss: 0.263656]\n",
      "[Epoch 15/100] [Batch 281/347] [D loss: 0.500025] [G loss: 0.261838]\n",
      "[Epoch 15/100] [Batch 282/347] [D loss: 0.500021] [G loss: 0.259648]\n",
      "[Epoch 15/100] [Batch 283/347] [D loss: 0.499992] [G loss: 0.260947]\n",
      "[Epoch 15/100] [Batch 284/347] [D loss: 0.500016] [G loss: 0.262277]\n",
      "[Epoch 15/100] [Batch 285/347] [D loss: 0.500030] [G loss: 0.258173]\n",
      "[Epoch 15/100] [Batch 286/347] [D loss: 0.500000] [G loss: 0.251056]\n",
      "[Epoch 15/100] [Batch 287/347] [D loss: 0.499995] [G loss: 0.254752]\n",
      "[Epoch 15/100] [Batch 288/347] [D loss: 0.499854] [G loss: 0.281553]\n",
      "[Epoch 15/100] [Batch 289/347] [D loss: 0.499827] [G loss: 0.285965]\n",
      "[Epoch 15/100] [Batch 290/347] [D loss: 0.499935] [G loss: 0.263424]\n",
      "[Epoch 15/100] [Batch 291/347] [D loss: 0.499910] [G loss: 0.266106]\n",
      "[Epoch 15/100] [Batch 292/347] [D loss: 0.499965] [G loss: 0.257526]\n",
      "[Epoch 15/100] [Batch 293/347] [D loss: 0.500111] [G loss: 0.268540]\n",
      "[Epoch 15/100] [Batch 294/347] [D loss: 0.500176] [G loss: 0.278274]\n",
      "[Epoch 15/100] [Batch 295/347] [D loss: 0.500120] [G loss: 0.275867]\n",
      "[Epoch 15/100] [Batch 296/347] [D loss: 0.500134] [G loss: 0.271785]\n",
      "[Epoch 15/100] [Batch 297/347] [D loss: 0.500177] [G loss: 0.283443]\n",
      "[Epoch 15/100] [Batch 298/347] [D loss: 0.500142] [G loss: 0.278273]\n",
      "[Epoch 15/100] [Batch 299/347] [D loss: 0.500148] [G loss: 0.276897]\n",
      "[Epoch 15/100] [Batch 300/347] [D loss: 0.500123] [G loss: 0.272262]\n",
      "[Epoch 15/100] [Batch 301/347] [D loss: 0.500142] [G loss: 0.273292]\n",
      "[Epoch 15/100] [Batch 302/347] [D loss: 0.500179] [G loss: 0.278364]\n",
      "[Epoch 15/100] [Batch 303/347] [D loss: 0.500040] [G loss: 0.262612]\n",
      "[Epoch 15/100] [Batch 304/347] [D loss: 0.499900] [G loss: 0.266862]\n",
      "[Epoch 15/100] [Batch 305/347] [D loss: 0.499865] [G loss: 0.279658]\n",
      "[Epoch 15/100] [Batch 306/347] [D loss: 0.499856] [G loss: 0.271099]\n",
      "[Epoch 15/100] [Batch 307/347] [D loss: 0.499842] [G loss: 0.283715]\n",
      "[Epoch 15/100] [Batch 308/347] [D loss: 0.499842] [G loss: 0.279888]\n",
      "[Epoch 15/100] [Batch 309/347] [D loss: 0.499959] [G loss: 0.260173]\n",
      "[Epoch 15/100] [Batch 310/347] [D loss: 0.500058] [G loss: 0.275446]\n",
      "[Epoch 15/100] [Batch 311/347] [D loss: 0.500063] [G loss: 0.278314]\n",
      "[Epoch 15/100] [Batch 312/347] [D loss: 0.500057] [G loss: 0.278025]\n",
      "[Epoch 15/100] [Batch 313/347] [D loss: 0.500066] [G loss: 0.277224]\n",
      "[Epoch 15/100] [Batch 314/347] [D loss: 0.500068] [G loss: 0.270818]\n",
      "[Epoch 15/100] [Batch 315/347] [D loss: 0.500071] [G loss: 0.261496]\n",
      "[Epoch 15/100] [Batch 316/347] [D loss: 0.499947] [G loss: 0.260476]\n",
      "[Epoch 15/100] [Batch 317/347] [D loss: 0.499837] [G loss: 0.279056]\n",
      "[Epoch 15/100] [Batch 318/347] [D loss: 0.499968] [G loss: 0.256824]\n",
      "[Epoch 15/100] [Batch 319/347] [D loss: 0.500132] [G loss: 0.283569]\n",
      "[Epoch 15/100] [Batch 320/347] [D loss: 0.500194] [G loss: 0.297225]\n",
      "[Epoch 15/100] [Batch 321/347] [D loss: 0.500154] [G loss: 0.286776]\n",
      "[Epoch 15/100] [Batch 322/347] [D loss: 0.500098] [G loss: 0.273731]\n",
      "[Epoch 15/100] [Batch 323/347] [D loss: 0.500102] [G loss: 0.272916]\n",
      "[Epoch 15/100] [Batch 324/347] [D loss: 0.500122] [G loss: 0.275888]\n",
      "[Epoch 15/100] [Batch 325/347] [D loss: 0.500077] [G loss: 0.265064]\n",
      "[Epoch 15/100] [Batch 326/347] [D loss: 0.500012] [G loss: 0.254005]\n",
      "[Epoch 15/100] [Batch 327/347] [D loss: 0.500011] [G loss: 0.252050]\n",
      "[Epoch 15/100] [Batch 328/347] [D loss: 0.499987] [G loss: 0.252693]\n",
      "[Epoch 15/100] [Batch 329/347] [D loss: 0.499885] [G loss: 0.274590]\n",
      "[Epoch 15/100] [Batch 330/347] [D loss: 0.499795] [G loss: 0.289970]\n",
      "[Epoch 15/100] [Batch 331/347] [D loss: 0.499885] [G loss: 0.271691]\n",
      "[Epoch 15/100] [Batch 332/347] [D loss: 0.500028] [G loss: 0.265022]\n",
      "[Epoch 15/100] [Batch 333/347] [D loss: 0.500070] [G loss: 0.276519]\n",
      "[Epoch 15/100] [Batch 334/347] [D loss: 0.500098] [G loss: 0.277994]\n",
      "[Epoch 15/100] [Batch 335/347] [D loss: 0.500070] [G loss: 0.266127]\n",
      "[Epoch 15/100] [Batch 336/347] [D loss: 0.500004] [G loss: 0.251803]\n",
      "[Epoch 15/100] [Batch 337/347] [D loss: 0.500011] [G loss: 0.257856]\n",
      "[Epoch 15/100] [Batch 338/347] [D loss: 0.500068] [G loss: 0.272495]\n",
      "[Epoch 15/100] [Batch 339/347] [D loss: 0.500092] [G loss: 0.277859]\n",
      "[Epoch 15/100] [Batch 340/347] [D loss: 0.500086] [G loss: 0.278212]\n",
      "[Epoch 15/100] [Batch 341/347] [D loss: 0.500079] [G loss: 0.273430]\n",
      "[Epoch 15/100] [Batch 342/347] [D loss: 0.500045] [G loss: 0.265840]\n",
      "[Epoch 15/100] [Batch 343/347] [D loss: 0.500036] [G loss: 0.270530]\n",
      "[Epoch 15/100] [Batch 344/347] [D loss: 0.499989] [G loss: 0.264183]\n",
      "[Epoch 15/100] [Batch 345/347] [D loss: 0.499849] [G loss: 0.274259]\n",
      "[Epoch 15/100] [Batch 346/347] [D loss: 0.499777] [G loss: 0.292671]\n",
      "[Epoch 15/100] [Batch 347/347] [D loss: 0.499767] [G loss: 0.298867]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 16/100] [Batch 1/347] [D loss: 0.499941] [G loss: 0.265098]\n",
      "[Epoch 16/100] [Batch 2/347] [D loss: 0.499935] [G loss: 0.270284]\n",
      "[Epoch 16/100] [Batch 3/347] [D loss: 0.499969] [G loss: 0.270143]\n",
      "[Epoch 16/100] [Batch 4/347] [D loss: 0.499968] [G loss: 0.271384]\n",
      "[Epoch 16/100] [Batch 5/347] [D loss: 0.499971] [G loss: 0.270565]\n",
      "[Epoch 16/100] [Batch 6/347] [D loss: 0.499976] [G loss: 0.270897]\n",
      "[Epoch 16/100] [Batch 7/347] [D loss: 0.499959] [G loss: 0.270705]\n",
      "[Epoch 16/100] [Batch 8/347] [D loss: 0.499962] [G loss: 0.266014]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 16/100] [Batch 9/347] [D loss: 0.499925] [G loss: 0.264943]\n",
      "[Epoch 16/100] [Batch 10/347] [D loss: 0.499922] [G loss: 0.266508]\n",
      "[Epoch 16/100] [Batch 11/347] [D loss: 0.499976] [G loss: 0.266211]\n",
      "[Epoch 16/100] [Batch 12/347] [D loss: 0.499995] [G loss: 0.266729]\n",
      "[Epoch 16/100] [Batch 13/347] [D loss: 0.500022] [G loss: 0.268095]\n",
      "[Epoch 16/100] [Batch 14/347] [D loss: 0.500050] [G loss: 0.270439]\n",
      "[Epoch 16/100] [Batch 15/347] [D loss: 0.500040] [G loss: 0.266627]\n",
      "[Epoch 16/100] [Batch 16/347] [D loss: 0.500029] [G loss: 0.262526]\n",
      "[Epoch 16/100] [Batch 17/347] [D loss: 0.500005] [G loss: 0.251087]\n",
      "[Epoch 16/100] [Batch 18/347] [D loss: 0.499977] [G loss: 0.256978]\n",
      "[Epoch 16/100] [Batch 19/347] [D loss: 0.500029] [G loss: 0.256419]\n",
      "[Epoch 16/100] [Batch 20/347] [D loss: 0.500073] [G loss: 0.269687]\n",
      "[Epoch 16/100] [Batch 21/347] [D loss: 0.500050] [G loss: 0.266176]\n",
      "[Epoch 16/100] [Batch 22/347] [D loss: 0.500028] [G loss: 0.261341]\n",
      "[Epoch 16/100] [Batch 23/347] [D loss: 0.500013] [G loss: 0.255168]\n",
      "[Epoch 16/100] [Batch 24/347] [D loss: 0.500020] [G loss: 0.254508]\n",
      "[Epoch 16/100] [Batch 25/347] [D loss: 0.500013] [G loss: 0.254024]\n",
      "[Epoch 16/100] [Batch 26/347] [D loss: 0.499940] [G loss: 0.261177]\n",
      "[Epoch 16/100] [Batch 27/347] [D loss: 0.499966] [G loss: 0.266893]\n",
      "[Epoch 16/100] [Batch 28/347] [D loss: 0.500045] [G loss: 0.268040]\n",
      "[Epoch 16/100] [Batch 29/347] [D loss: 0.500090] [G loss: 0.265147]\n",
      "[Epoch 16/100] [Batch 30/347] [D loss: 0.500125] [G loss: 0.272102]\n",
      "[Epoch 16/100] [Batch 31/347] [D loss: 0.500151] [G loss: 0.274699]\n",
      "[Epoch 16/100] [Batch 32/347] [D loss: 0.500126] [G loss: 0.268380]\n",
      "[Epoch 16/100] [Batch 33/347] [D loss: 0.500084] [G loss: 0.264120]\n",
      "[Epoch 16/100] [Batch 34/347] [D loss: 0.500079] [G loss: 0.265220]\n",
      "[Epoch 16/100] [Batch 35/347] [D loss: 0.500078] [G loss: 0.264073]\n",
      "[Epoch 16/100] [Batch 36/347] [D loss: 0.500035] [G loss: 0.254956]\n",
      "[Epoch 16/100] [Batch 37/347] [D loss: 0.499908] [G loss: 0.272322]\n",
      "[Epoch 16/100] [Batch 38/347] [D loss: 0.499811] [G loss: 0.287531]\n",
      "[Epoch 16/100] [Batch 39/347] [D loss: 0.499833] [G loss: 0.277976]\n",
      "[Epoch 16/100] [Batch 40/347] [D loss: 0.499843] [G loss: 0.278360]\n",
      "[Epoch 16/100] [Batch 41/347] [D loss: 0.499823] [G loss: 0.279716]\n",
      "[Epoch 16/100] [Batch 42/347] [D loss: 0.499851] [G loss: 0.272735]\n",
      "[Epoch 16/100] [Batch 43/347] [D loss: 0.499964] [G loss: 0.256625]\n",
      "[Epoch 16/100] [Batch 44/347] [D loss: 0.500068] [G loss: 0.263231]\n",
      "[Epoch 16/100] [Batch 45/347] [D loss: 0.500147] [G loss: 0.280589]\n",
      "[Epoch 16/100] [Batch 46/347] [D loss: 0.500137] [G loss: 0.275291]\n",
      "[Epoch 16/100] [Batch 47/347] [D loss: 0.499992] [G loss: 0.254626]\n",
      "[Epoch 16/100] [Batch 48/347] [D loss: 0.499841] [G loss: 0.286956]\n",
      "[Epoch 16/100] [Batch 49/347] [D loss: 0.499793] [G loss: 0.295473]\n",
      "[Epoch 16/100] [Batch 50/347] [D loss: 0.499771] [G loss: 0.311087]\n",
      "[Epoch 16/100] [Batch 51/347] [D loss: 0.499878] [G loss: 0.295708]\n",
      "[Epoch 16/100] [Batch 52/347] [D loss: 0.500036] [G loss: 0.262459]\n",
      "[Epoch 16/100] [Batch 53/347] [D loss: 0.500003] [G loss: 0.258425]\n",
      "[Epoch 16/100] [Batch 54/347] [D loss: 0.499761] [G loss: 0.311044]\n",
      "[Epoch 16/100] [Batch 55/347] [D loss: 0.499569] [G loss: 0.333465]\n",
      "[Epoch 16/100] [Batch 56/347] [D loss: 0.499610] [G loss: 0.320390]\n",
      "[Epoch 16/100] [Batch 57/347] [D loss: 0.499855] [G loss: 0.286007]\n",
      "[Epoch 16/100] [Batch 58/347] [D loss: 0.500028] [G loss: 0.261122]\n",
      "[Epoch 16/100] [Batch 59/347] [D loss: 0.499975] [G loss: 0.268858]\n",
      "[Epoch 16/100] [Batch 60/347] [D loss: 0.499894] [G loss: 0.287689]\n",
      "[Epoch 16/100] [Batch 61/347] [D loss: 0.499838] [G loss: 0.300271]\n",
      "[Epoch 16/100] [Batch 62/347] [D loss: 0.499698] [G loss: 0.324296]\n",
      "[Epoch 16/100] [Batch 63/347] [D loss: 0.499593] [G loss: 0.326414]\n",
      "[Epoch 16/100] [Batch 64/347] [D loss: 0.499813] [G loss: 0.289568]\n",
      "[Epoch 16/100] [Batch 65/347] [D loss: 0.500100] [G loss: 0.265179]\n",
      "[Epoch 16/100] [Batch 66/347] [D loss: 0.500080] [G loss: 0.267543]\n",
      "[Epoch 16/100] [Batch 67/347] [D loss: 0.499946] [G loss: 0.273472]\n",
      "[Epoch 16/100] [Batch 68/347] [D loss: 0.499862] [G loss: 0.291638]\n",
      "[Epoch 16/100] [Batch 69/347] [D loss: 0.499710] [G loss: 0.310563]\n",
      "[Epoch 16/100] [Batch 70/347] [D loss: 0.499669] [G loss: 0.309365]\n",
      "[Epoch 16/100] [Batch 71/347] [D loss: 0.499714] [G loss: 0.311757]\n",
      "[Epoch 16/100] [Batch 72/347] [D loss: 0.499680] [G loss: 0.314300]\n",
      "[Epoch 16/100] [Batch 73/347] [D loss: 0.499810] [G loss: 0.289610]\n",
      "[Epoch 16/100] [Batch 74/347] [D loss: 0.499948] [G loss: 0.275667]\n",
      "[Epoch 16/100] [Batch 75/347] [D loss: 0.499803] [G loss: 0.305583]\n",
      "[Epoch 16/100] [Batch 76/347] [D loss: 0.499709] [G loss: 0.307639]\n",
      "[Epoch 16/100] [Batch 77/347] [D loss: 0.499898] [G loss: 0.273387]\n",
      "[Epoch 16/100] [Batch 78/347] [D loss: 0.500126] [G loss: 0.271617]\n",
      "[Epoch 16/100] [Batch 79/347] [D loss: 0.500174] [G loss: 0.273230]\n",
      "[Epoch 16/100] [Batch 80/347] [D loss: 0.500144] [G loss: 0.270050]\n",
      "[Epoch 16/100] [Batch 81/347] [D loss: 0.500187] [G loss: 0.275030]\n",
      "[Epoch 16/100] [Batch 82/347] [D loss: 0.500184] [G loss: 0.280495]\n",
      "[Epoch 16/100] [Batch 83/347] [D loss: 0.500156] [G loss: 0.272833]\n",
      "[Epoch 16/100] [Batch 84/347] [D loss: 0.500163] [G loss: 0.278847]\n",
      "[Epoch 16/100] [Batch 85/347] [D loss: 0.500147] [G loss: 0.279642]\n",
      "[Epoch 16/100] [Batch 86/347] [D loss: 0.500125] [G loss: 0.274110]\n",
      "[Epoch 16/100] [Batch 87/347] [D loss: 0.500104] [G loss: 0.271996]\n",
      "[Epoch 16/100] [Batch 88/347] [D loss: 0.500113] [G loss: 0.275421]\n",
      "[Epoch 16/100] [Batch 89/347] [D loss: 0.500121] [G loss: 0.278838]\n",
      "[Epoch 16/100] [Batch 90/347] [D loss: 0.500099] [G loss: 0.275108]\n",
      "[Epoch 16/100] [Batch 91/347] [D loss: 0.500089] [G loss: 0.273687]\n",
      "[Epoch 16/100] [Batch 92/347] [D loss: 0.500094] [G loss: 0.275192]\n",
      "[Epoch 16/100] [Batch 93/347] [D loss: 0.500079] [G loss: 0.273239]\n",
      "[Epoch 16/100] [Batch 94/347] [D loss: 0.500056] [G loss: 0.269750]\n",
      "[Epoch 16/100] [Batch 95/347] [D loss: 0.500063] [G loss: 0.270334]\n",
      "[Epoch 16/100] [Batch 96/347] [D loss: 0.500047] [G loss: 0.265630]\n",
      "[Epoch 16/100] [Batch 97/347] [D loss: 0.500016] [G loss: 0.260591]\n",
      "[Epoch 16/100] [Batch 98/347] [D loss: 0.500027] [G loss: 0.265582]\n",
      "[Epoch 16/100] [Batch 99/347] [D loss: 0.500041] [G loss: 0.269316]\n",
      "[Epoch 16/100] [Batch 100/347] [D loss: 0.500027] [G loss: 0.265722]\n",
      "[Epoch 16/100] [Batch 101/347] [D loss: 0.500001] [G loss: 0.260609]\n",
      "[Epoch 16/100] [Batch 102/347] [D loss: 0.500006] [G loss: 0.262076]\n",
      "[Epoch 16/100] [Batch 103/347] [D loss: 0.500005] [G loss: 0.262703]\n",
      "[Epoch 16/100] [Batch 104/347] [D loss: 0.499961] [G loss: 0.264595]\n",
      "[Epoch 16/100] [Batch 105/347] [D loss: 0.499949] [G loss: 0.266934]\n",
      "[Epoch 16/100] [Batch 106/347] [D loss: 0.499946] [G loss: 0.266548]\n",
      "[Epoch 16/100] [Batch 107/347] [D loss: 0.499933] [G loss: 0.260133]\n",
      "[Epoch 16/100] [Batch 108/347] [D loss: 0.499911] [G loss: 0.277445]\n",
      "[Epoch 16/100] [Batch 109/347] [D loss: 0.499961] [G loss: 0.270825]\n",
      "[Epoch 16/100] [Batch 110/347] [D loss: 0.500016] [G loss: 0.254138]\n",
      "[Epoch 16/100] [Batch 111/347] [D loss: 0.499966] [G loss: 0.265441]\n",
      "[Epoch 16/100] [Batch 112/347] [D loss: 0.499980] [G loss: 0.263999]\n",
      "[Epoch 16/100] [Batch 113/347] [D loss: 0.500092] [G loss: 0.269154]\n",
      "[Epoch 16/100] [Batch 114/347] [D loss: 0.500167] [G loss: 0.289930]\n",
      "[Epoch 16/100] [Batch 115/347] [D loss: 0.500181] [G loss: 0.291215]\n",
      "[Epoch 16/100] [Batch 116/347] [D loss: 0.500163] [G loss: 0.285521]\n",
      "[Epoch 16/100] [Batch 117/347] [D loss: 0.500066] [G loss: 0.258910]\n",
      "[Epoch 16/100] [Batch 118/347] [D loss: 0.499915] [G loss: 0.268398]\n",
      "[Epoch 16/100] [Batch 119/347] [D loss: 0.499885] [G loss: 0.270464]\n",
      "[Epoch 16/100] [Batch 120/347] [D loss: 0.499906] [G loss: 0.269263]\n",
      "[Epoch 16/100] [Batch 121/347] [D loss: 0.499910] [G loss: 0.267449]\n",
      "[Epoch 16/100] [Batch 122/347] [D loss: 0.499962] [G loss: 0.254952]\n",
      "[Epoch 16/100] [Batch 123/347] [D loss: 0.499976] [G loss: 0.253902]\n",
      "[Epoch 16/100] [Batch 124/347] [D loss: 0.499959] [G loss: 0.254826]\n",
      "[Epoch 16/100] [Batch 125/347] [D loss: 0.500015] [G loss: 0.257366]\n",
      "[Epoch 16/100] [Batch 126/347] [D loss: 0.500087] [G loss: 0.270095]\n",
      "[Epoch 16/100] [Batch 127/347] [D loss: 0.500108] [G loss: 0.271609]\n",
      "[Epoch 16/100] [Batch 128/347] [D loss: 0.500076] [G loss: 0.266193]\n",
      "[Epoch 16/100] [Batch 129/347] [D loss: 0.500074] [G loss: 0.261367]\n",
      "[Epoch 16/100] [Batch 130/347] [D loss: 0.500065] [G loss: 0.264903]\n",
      "[Epoch 16/100] [Batch 131/347] [D loss: 0.499988] [G loss: 0.264007]\n",
      "[Epoch 16/100] [Batch 132/347] [D loss: 0.499885] [G loss: 0.288578]\n",
      "[Epoch 16/100] [Batch 133/347] [D loss: 0.499853] [G loss: 0.295270]\n",
      "[Epoch 16/100] [Batch 134/347] [D loss: 0.499786] [G loss: 0.310102]\n",
      "[Epoch 16/100] [Batch 135/347] [D loss: 0.499781] [G loss: 0.319078]\n",
      "[Epoch 16/100] [Batch 136/347] [D loss: 0.499963] [G loss: 0.277125]\n",
      "[Epoch 16/100] [Batch 137/347] [D loss: 0.500054] [G loss: 0.266249]\n",
      "[Epoch 16/100] [Batch 138/347] [D loss: 0.499897] [G loss: 0.282290]\n",
      "[Epoch 16/100] [Batch 139/347] [D loss: 0.499753] [G loss: 0.306277]\n",
      "[Epoch 16/100] [Batch 140/347] [D loss: 0.499700] [G loss: 0.317716]\n",
      "[Epoch 16/100] [Batch 141/347] [D loss: 0.499650] [G loss: 0.324583]\n",
      "[Epoch 16/100] [Batch 142/347] [D loss: 0.499622] [G loss: 0.332267]\n",
      "[Epoch 16/100] [Batch 143/347] [D loss: 0.499504] [G loss: 0.353909]\n",
      "[Epoch 16/100] [Batch 144/347] [D loss: 0.499458] [G loss: 0.356144]\n",
      "[Epoch 16/100] [Batch 145/347] [D loss: 0.499480] [G loss: 0.341843]\n",
      "[Epoch 16/100] [Batch 146/347] [D loss: 0.499528] [G loss: 0.325092]\n",
      "[Epoch 16/100] [Batch 147/347] [D loss: 0.499688] [G loss: 0.296994]\n",
      "[Epoch 16/100] [Batch 148/347] [D loss: 0.499780] [G loss: 0.284675]\n",
      "[Epoch 16/100] [Batch 149/347] [D loss: 0.499709] [G loss: 0.298088]\n",
      "[Epoch 16/100] [Batch 150/347] [D loss: 0.499713] [G loss: 0.298604]\n",
      "[Epoch 16/100] [Batch 151/347] [D loss: 0.499819] [G loss: 0.287811]\n",
      "[Epoch 16/100] [Batch 152/347] [D loss: 0.499796] [G loss: 0.299031]\n",
      "[Epoch 16/100] [Batch 153/347] [D loss: 0.499668] [G loss: 0.319805]\n",
      "[Epoch 16/100] [Batch 154/347] [D loss: 0.499584] [G loss: 0.324078]\n",
      "[Epoch 16/100] [Batch 155/347] [D loss: 0.499640] [G loss: 0.311356]\n",
      "[Epoch 16/100] [Batch 156/347] [D loss: 0.499751] [G loss: 0.294856]\n",
      "[Epoch 16/100] [Batch 157/347] [D loss: 0.499797] [G loss: 0.301307]\n",
      "[Epoch 16/100] [Batch 158/347] [D loss: 0.499644] [G loss: 0.325190]\n",
      "[Epoch 16/100] [Batch 159/347] [D loss: 0.499596] [G loss: 0.322809]\n",
      "[Epoch 16/100] [Batch 160/347] [D loss: 0.499770] [G loss: 0.303026]\n",
      "[Epoch 16/100] [Batch 161/347] [D loss: 0.499876] [G loss: 0.294792]\n",
      "[Epoch 16/100] [Batch 162/347] [D loss: 0.499836] [G loss: 0.300722]\n",
      "[Epoch 16/100] [Batch 163/347] [D loss: 0.499721] [G loss: 0.319653]\n",
      "[Epoch 16/100] [Batch 164/347] [D loss: 0.499608] [G loss: 0.335068]\n",
      "[Epoch 16/100] [Batch 165/347] [D loss: 0.499607] [G loss: 0.326382]\n",
      "[Epoch 16/100] [Batch 166/347] [D loss: 0.499815] [G loss: 0.288313]\n",
      "[Epoch 16/100] [Batch 167/347] [D loss: 0.500060] [G loss: 0.270718]\n",
      "[Epoch 16/100] [Batch 168/347] [D loss: 0.500135] [G loss: 0.281313]\n",
      "[Epoch 16/100] [Batch 169/347] [D loss: 0.500169] [G loss: 0.280010]\n",
      "[Epoch 16/100] [Batch 170/347] [D loss: 0.500195] [G loss: 0.276017]\n",
      "[Epoch 16/100] [Batch 171/347] [D loss: 0.500261] [G loss: 0.283616]\n",
      "[Epoch 16/100] [Batch 172/347] [D loss: 0.500284] [G loss: 0.288537]\n",
      "[Epoch 16/100] [Batch 173/347] [D loss: 0.500213] [G loss: 0.277312]\n",
      "[Epoch 16/100] [Batch 174/347] [D loss: 0.500193] [G loss: 0.274836]\n",
      "[Epoch 16/100] [Batch 175/347] [D loss: 0.500226] [G loss: 0.284699]\n",
      "[Epoch 16/100] [Batch 176/347] [D loss: 0.500297] [G loss: 0.298136]\n",
      "[Epoch 16/100] [Batch 177/347] [D loss: 0.500297] [G loss: 0.299042]\n",
      "[Epoch 16/100] [Batch 178/347] [D loss: 0.500262] [G loss: 0.293134]\n",
      "[Epoch 16/100] [Batch 179/347] [D loss: 0.500225] [G loss: 0.286513]\n",
      "[Epoch 16/100] [Batch 180/347] [D loss: 0.500189] [G loss: 0.280200]\n",
      "[Epoch 16/100] [Batch 181/347] [D loss: 0.500190] [G loss: 0.280699]\n",
      "[Epoch 16/100] [Batch 182/347] [D loss: 0.500154] [G loss: 0.278597]\n",
      "[Epoch 16/100] [Batch 183/347] [D loss: 0.500180] [G loss: 0.282693]\n",
      "[Epoch 16/100] [Batch 184/347] [D loss: 0.500189] [G loss: 0.286660]\n",
      "[Epoch 16/100] [Batch 185/347] [D loss: 0.500185] [G loss: 0.285191]\n",
      "[Epoch 16/100] [Batch 186/347] [D loss: 0.500191] [G loss: 0.285048]\n",
      "[Epoch 16/100] [Batch 187/347] [D loss: 0.500167] [G loss: 0.279799]\n",
      "[Epoch 16/100] [Batch 188/347] [D loss: 0.500140] [G loss: 0.276564]\n",
      "[Epoch 16/100] [Batch 189/347] [D loss: 0.500133] [G loss: 0.275738]\n",
      "[Epoch 16/100] [Batch 190/347] [D loss: 0.500051] [G loss: 0.263896]\n",
      "[Epoch 16/100] [Batch 191/347] [D loss: 0.499954] [G loss: 0.260200]\n",
      "[Epoch 16/100] [Batch 192/347] [D loss: 0.499997] [G loss: 0.253085]\n",
      "[Epoch 16/100] [Batch 193/347] [D loss: 0.500059] [G loss: 0.261719]\n",
      "[Epoch 16/100] [Batch 194/347] [D loss: 0.499999] [G loss: 0.257370]\n",
      "[Epoch 16/100] [Batch 195/347] [D loss: 0.499949] [G loss: 0.264482]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 16/100] [Batch 196/347] [D loss: 0.499918] [G loss: 0.262721]\n",
      "[Epoch 16/100] [Batch 197/347] [D loss: 0.499924] [G loss: 0.258427]\n",
      "[Epoch 16/100] [Batch 198/347] [D loss: 0.499952] [G loss: 0.258964]\n",
      "[Epoch 16/100] [Batch 199/347] [D loss: 0.499945] [G loss: 0.260400]\n",
      "[Epoch 16/100] [Batch 200/347] [D loss: 0.499958] [G loss: 0.255540]\n",
      "[Epoch 16/100] [Batch 201/347] [D loss: 0.499967] [G loss: 0.255139]\n",
      "[Epoch 16/100] [Batch 202/347] [D loss: 0.499905] [G loss: 0.266940]\n",
      "[Epoch 16/100] [Batch 203/347] [D loss: 0.499853] [G loss: 0.275755]\n",
      "[Epoch 16/100] [Batch 204/347] [D loss: 0.499876] [G loss: 0.272363]\n",
      "[Epoch 16/100] [Batch 205/347] [D loss: 0.499904] [G loss: 0.264576]\n",
      "[Epoch 16/100] [Batch 206/347] [D loss: 0.499968] [G loss: 0.252379]\n",
      "[Epoch 16/100] [Batch 207/347] [D loss: 0.500070] [G loss: 0.260484]\n",
      "[Epoch 16/100] [Batch 208/347] [D loss: 0.500049] [G loss: 0.261390]\n",
      "[Epoch 16/100] [Batch 209/347] [D loss: 0.500010] [G loss: 0.255783]\n",
      "[Epoch 16/100] [Batch 210/347] [D loss: 0.500087] [G loss: 0.264061]\n",
      "[Epoch 16/100] [Batch 211/347] [D loss: 0.500076] [G loss: 0.261296]\n",
      "[Epoch 16/100] [Batch 212/347] [D loss: 0.500052] [G loss: 0.260191]\n",
      "[Epoch 16/100] [Batch 213/347] [D loss: 0.500044] [G loss: 0.265871]\n",
      "[Epoch 16/100] [Batch 214/347] [D loss: 0.499946] [G loss: 0.277884]\n",
      "[Epoch 16/100] [Batch 215/347] [D loss: 0.499904] [G loss: 0.286110]\n",
      "[Epoch 16/100] [Batch 216/347] [D loss: 0.500002] [G loss: 0.265128]\n",
      "[Epoch 16/100] [Batch 217/347] [D loss: 0.500073] [G loss: 0.265828]\n",
      "[Epoch 16/100] [Batch 218/347] [D loss: 0.500136] [G loss: 0.271651]\n",
      "[Epoch 16/100] [Batch 219/347] [D loss: 0.500215] [G loss: 0.283915]\n",
      "[Epoch 16/100] [Batch 220/347] [D loss: 0.500310] [G loss: 0.299751]\n",
      "[Epoch 16/100] [Batch 221/347] [D loss: 0.500328] [G loss: 0.301122]\n",
      "[Epoch 16/100] [Batch 222/347] [D loss: 0.500296] [G loss: 0.293122]\n",
      "[Epoch 16/100] [Batch 223/347] [D loss: 0.500291] [G loss: 0.291782]\n",
      "[Epoch 16/100] [Batch 224/347] [D loss: 0.500270] [G loss: 0.287637]\n",
      "[Epoch 16/100] [Batch 225/347] [D loss: 0.500122] [G loss: 0.274678]\n",
      "[Epoch 16/100] [Batch 226/347] [D loss: 0.499895] [G loss: 0.273725]\n",
      "[Epoch 16/100] [Batch 227/347] [D loss: 0.499751] [G loss: 0.284083]\n",
      "[Epoch 16/100] [Batch 228/347] [D loss: 0.499740] [G loss: 0.285318]\n",
      "[Epoch 16/100] [Batch 229/347] [D loss: 0.499805] [G loss: 0.280463]\n",
      "[Epoch 16/100] [Batch 230/347] [D loss: 0.499835] [G loss: 0.276680]\n",
      "[Epoch 16/100] [Batch 231/347] [D loss: 0.499798] [G loss: 0.276747]\n",
      "[Epoch 16/100] [Batch 232/347] [D loss: 0.499833] [G loss: 0.272768]\n",
      "[Epoch 16/100] [Batch 233/347] [D loss: 0.499852] [G loss: 0.271093]\n",
      "[Epoch 16/100] [Batch 234/347] [D loss: 0.499853] [G loss: 0.276076]\n",
      "[Epoch 16/100] [Batch 235/347] [D loss: 0.499943] [G loss: 0.264936]\n",
      "[Epoch 16/100] [Batch 236/347] [D loss: 0.500032] [G loss: 0.262133]\n",
      "[Epoch 16/100] [Batch 237/347] [D loss: 0.500093] [G loss: 0.264919]\n",
      "[Epoch 16/100] [Batch 238/347] [D loss: 0.500089] [G loss: 0.268907]\n",
      "[Epoch 16/100] [Batch 239/347] [D loss: 0.500072] [G loss: 0.266847]\n",
      "[Epoch 16/100] [Batch 240/347] [D loss: 0.500061] [G loss: 0.262964]\n",
      "[Epoch 16/100] [Batch 241/347] [D loss: 0.500029] [G loss: 0.257067]\n",
      "[Epoch 16/100] [Batch 242/347] [D loss: 0.500010] [G loss: 0.255031]\n",
      "[Epoch 16/100] [Batch 243/347] [D loss: 0.500049] [G loss: 0.262589]\n",
      "[Epoch 16/100] [Batch 244/347] [D loss: 0.500095] [G loss: 0.271349]\n",
      "[Epoch 16/100] [Batch 245/347] [D loss: 0.500145] [G loss: 0.270140]\n",
      "[Epoch 16/100] [Batch 246/347] [D loss: 0.500016] [G loss: 0.263414]\n",
      "[Epoch 16/100] [Batch 247/347] [D loss: 0.499847] [G loss: 0.272087]\n",
      "[Epoch 16/100] [Batch 248/347] [D loss: 0.499779] [G loss: 0.277218]\n",
      "[Epoch 16/100] [Batch 249/347] [D loss: 0.499747] [G loss: 0.283452]\n",
      "[Epoch 16/100] [Batch 250/347] [D loss: 0.499864] [G loss: 0.274795]\n",
      "[Epoch 16/100] [Batch 251/347] [D loss: 0.500017] [G loss: 0.263315]\n",
      "[Epoch 16/100] [Batch 252/347] [D loss: 0.500077] [G loss: 0.266460]\n",
      "[Epoch 16/100] [Batch 253/347] [D loss: 0.500082] [G loss: 0.266962]\n",
      "[Epoch 16/100] [Batch 254/347] [D loss: 0.500080] [G loss: 0.265275]\n",
      "[Epoch 16/100] [Batch 255/347] [D loss: 0.500039] [G loss: 0.263769]\n",
      "[Epoch 16/100] [Batch 256/347] [D loss: 0.500073] [G loss: 0.268865]\n",
      "[Epoch 16/100] [Batch 257/347] [D loss: 0.500141] [G loss: 0.270595]\n",
      "[Epoch 16/100] [Batch 258/347] [D loss: 0.500067] [G loss: 0.265290]\n",
      "[Epoch 16/100] [Batch 259/347] [D loss: 0.499893] [G loss: 0.273898]\n",
      "[Epoch 16/100] [Batch 260/347] [D loss: 0.499810] [G loss: 0.288249]\n",
      "[Epoch 16/100] [Batch 261/347] [D loss: 0.499877] [G loss: 0.280635]\n",
      "[Epoch 16/100] [Batch 262/347] [D loss: 0.499922] [G loss: 0.265436]\n",
      "[Epoch 16/100] [Batch 263/347] [D loss: 0.499915] [G loss: 0.266311]\n",
      "[Epoch 16/100] [Batch 264/347] [D loss: 0.499857] [G loss: 0.280735]\n",
      "[Epoch 16/100] [Batch 265/347] [D loss: 0.499822] [G loss: 0.285922]\n",
      "[Epoch 16/100] [Batch 266/347] [D loss: 0.499842] [G loss: 0.278756]\n",
      "[Epoch 16/100] [Batch 267/347] [D loss: 0.499870] [G loss: 0.271966]\n",
      "[Epoch 16/100] [Batch 268/347] [D loss: 0.499857] [G loss: 0.278843]\n",
      "[Epoch 16/100] [Batch 269/347] [D loss: 0.499819] [G loss: 0.289978]\n",
      "[Epoch 16/100] [Batch 270/347] [D loss: 0.499823] [G loss: 0.286504]\n",
      "[Epoch 16/100] [Batch 271/347] [D loss: 0.499861] [G loss: 0.274628]\n",
      "[Epoch 16/100] [Batch 272/347] [D loss: 0.499912] [G loss: 0.266014]\n",
      "[Epoch 16/100] [Batch 273/347] [D loss: 0.499895] [G loss: 0.277856]\n",
      "[Epoch 16/100] [Batch 274/347] [D loss: 0.499793] [G loss: 0.311643]\n",
      "[Epoch 16/100] [Batch 275/347] [D loss: 0.499795] [G loss: 0.308564]\n",
      "[Epoch 16/100] [Batch 276/347] [D loss: 0.499886] [G loss: 0.276213]\n",
      "[Epoch 16/100] [Batch 277/347] [D loss: 0.499937] [G loss: 0.261563]\n",
      "[Epoch 16/100] [Batch 278/347] [D loss: 0.499989] [G loss: 0.251264]\n",
      "[Epoch 16/100] [Batch 279/347] [D loss: 0.499994] [G loss: 0.257748]\n",
      "[Epoch 16/100] [Batch 280/347] [D loss: 0.499978] [G loss: 0.261229]\n",
      "[Epoch 16/100] [Batch 281/347] [D loss: 0.499983] [G loss: 0.259421]\n",
      "[Epoch 16/100] [Batch 282/347] [D loss: 0.499978] [G loss: 0.257271]\n",
      "[Epoch 16/100] [Batch 283/347] [D loss: 0.499944] [G loss: 0.262838]\n",
      "[Epoch 16/100] [Batch 284/347] [D loss: 0.499969] [G loss: 0.260764]\n",
      "[Epoch 16/100] [Batch 285/347] [D loss: 0.499992] [G loss: 0.256381]\n",
      "[Epoch 16/100] [Batch 286/347] [D loss: 0.499960] [G loss: 0.252179]\n",
      "[Epoch 16/100] [Batch 287/347] [D loss: 0.499959] [G loss: 0.255484]\n",
      "[Epoch 16/100] [Batch 288/347] [D loss: 0.499794] [G loss: 0.281777]\n",
      "[Epoch 16/100] [Batch 289/347] [D loss: 0.499770] [G loss: 0.285755]\n",
      "[Epoch 16/100] [Batch 290/347] [D loss: 0.499899] [G loss: 0.262796]\n",
      "[Epoch 16/100] [Batch 291/347] [D loss: 0.499877] [G loss: 0.265082]\n",
      "[Epoch 16/100] [Batch 292/347] [D loss: 0.499941] [G loss: 0.256186]\n",
      "[Epoch 16/100] [Batch 293/347] [D loss: 0.500120] [G loss: 0.270833]\n",
      "[Epoch 16/100] [Batch 294/347] [D loss: 0.500195] [G loss: 0.280901]\n",
      "[Epoch 16/100] [Batch 295/347] [D loss: 0.500134] [G loss: 0.278784]\n",
      "[Epoch 16/100] [Batch 296/347] [D loss: 0.500152] [G loss: 0.275017]\n",
      "[Epoch 16/100] [Batch 297/347] [D loss: 0.500203] [G loss: 0.286066]\n",
      "[Epoch 16/100] [Batch 298/347] [D loss: 0.500163] [G loss: 0.281091]\n",
      "[Epoch 16/100] [Batch 299/347] [D loss: 0.500175] [G loss: 0.279859]\n",
      "[Epoch 16/100] [Batch 300/347] [D loss: 0.500148] [G loss: 0.275379]\n",
      "[Epoch 16/100] [Batch 301/347] [D loss: 0.500165] [G loss: 0.277630]\n",
      "[Epoch 16/100] [Batch 302/347] [D loss: 0.500208] [G loss: 0.282869]\n",
      "[Epoch 16/100] [Batch 303/347] [D loss: 0.500049] [G loss: 0.267316]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 16/100] [Batch 304/347] [D loss: 0.499892] [G loss: 0.262186]\n",
      "[Epoch 16/100] [Batch 305/347] [D loss: 0.499846] [G loss: 0.274825]\n",
      "[Epoch 16/100] [Batch 306/347] [D loss: 0.499841] [G loss: 0.267435]\n",
      "[Epoch 16/100] [Batch 307/347] [D loss: 0.499825] [G loss: 0.279926]\n",
      "[Epoch 16/100] [Batch 308/347] [D loss: 0.499826] [G loss: 0.275995]\n",
      "[Epoch 16/100] [Batch 309/347] [D loss: 0.499962] [G loss: 0.254849]\n",
      "[Epoch 16/100] [Batch 310/347] [D loss: 0.500082] [G loss: 0.279532]\n",
      "[Epoch 16/100] [Batch 311/347] [D loss: 0.500084] [G loss: 0.282386]\n",
      "[Epoch 16/100] [Batch 312/347] [D loss: 0.500078] [G loss: 0.282114]\n",
      "[Epoch 16/100] [Batch 313/347] [D loss: 0.500088] [G loss: 0.281321]\n",
      "[Epoch 16/100] [Batch 314/347] [D loss: 0.500093] [G loss: 0.274921]\n",
      "[Epoch 16/100] [Batch 315/347] [D loss: 0.500097] [G loss: 0.265596]\n",
      "[Epoch 16/100] [Batch 316/347] [D loss: 0.499954] [G loss: 0.254725]\n",
      "[Epoch 16/100] [Batch 317/347] [D loss: 0.499823] [G loss: 0.273294]\n",
      "[Epoch 16/100] [Batch 318/347] [D loss: 0.499977] [G loss: 0.254749]\n",
      "[Epoch 16/100] [Batch 319/347] [D loss: 0.500165] [G loss: 0.287411]\n",
      "[Epoch 16/100] [Batch 320/347] [D loss: 0.500232] [G loss: 0.300786]\n",
      "[Epoch 16/100] [Batch 321/347] [D loss: 0.500182] [G loss: 0.290079]\n",
      "[Epoch 16/100] [Batch 322/347] [D loss: 0.500115] [G loss: 0.276838]\n",
      "[Epoch 16/100] [Batch 323/347] [D loss: 0.500115] [G loss: 0.275792]\n",
      "[Epoch 16/100] [Batch 324/347] [D loss: 0.500137] [G loss: 0.278533]\n",
      "[Epoch 16/100] [Batch 325/347] [D loss: 0.500087] [G loss: 0.267583]\n",
      "[Epoch 16/100] [Batch 326/347] [D loss: 0.500012] [G loss: 0.257475]\n",
      "[Epoch 16/100] [Batch 327/347] [D loss: 0.500010] [G loss: 0.255430]\n",
      "[Epoch 16/100] [Batch 328/347] [D loss: 0.499980] [G loss: 0.252661]\n",
      "[Epoch 16/100] [Batch 329/347] [D loss: 0.499855] [G loss: 0.272457]\n",
      "[Epoch 16/100] [Batch 330/347] [D loss: 0.499751] [G loss: 0.288197]\n",
      "[Epoch 16/100] [Batch 331/347] [D loss: 0.499854] [G loss: 0.270218]\n",
      "[Epoch 16/100] [Batch 332/347] [D loss: 0.500019] [G loss: 0.265878]\n",
      "[Epoch 16/100] [Batch 333/347] [D loss: 0.500061] [G loss: 0.277069]\n",
      "[Epoch 16/100] [Batch 334/347] [D loss: 0.500092] [G loss: 0.278280]\n",
      "[Epoch 16/100] [Batch 335/347] [D loss: 0.500055] [G loss: 0.266217]\n",
      "[Epoch 16/100] [Batch 336/347] [D loss: 0.499980] [G loss: 0.251926]\n",
      "[Epoch 16/100] [Batch 337/347] [D loss: 0.499985] [G loss: 0.257561]\n",
      "[Epoch 16/100] [Batch 338/347] [D loss: 0.500046] [G loss: 0.272054]\n",
      "[Epoch 16/100] [Batch 339/347] [D loss: 0.500073] [G loss: 0.277268]\n",
      "[Epoch 16/100] [Batch 340/347] [D loss: 0.500069] [G loss: 0.277557]\n",
      "[Epoch 16/100] [Batch 341/347] [D loss: 0.500057] [G loss: 0.272677]\n",
      "[Epoch 16/100] [Batch 342/347] [D loss: 0.500015] [G loss: 0.264958]\n",
      "[Epoch 16/100] [Batch 343/347] [D loss: 0.500007] [G loss: 0.269581]\n",
      "[Epoch 16/100] [Batch 344/347] [D loss: 0.499951] [G loss: 0.265256]\n",
      "[Epoch 16/100] [Batch 345/347] [D loss: 0.499790] [G loss: 0.274954]\n",
      "[Epoch 16/100] [Batch 346/347] [D loss: 0.499703] [G loss: 0.293439]\n",
      "[Epoch 16/100] [Batch 347/347] [D loss: 0.499691] [G loss: 0.299656]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 17/100] [Batch 1/347] [D loss: 0.499892] [G loss: 0.266618]\n",
      "[Epoch 17/100] [Batch 2/347] [D loss: 0.499885] [G loss: 0.271858]\n",
      "[Epoch 17/100] [Batch 3/347] [D loss: 0.499924] [G loss: 0.271766]\n",
      "[Epoch 17/100] [Batch 4/347] [D loss: 0.499923] [G loss: 0.273033]\n",
      "[Epoch 17/100] [Batch 5/347] [D loss: 0.499923] [G loss: 0.272346]\n",
      "[Epoch 17/100] [Batch 6/347] [D loss: 0.499932] [G loss: 0.272714]\n",
      "[Epoch 17/100] [Batch 7/347] [D loss: 0.499912] [G loss: 0.272506]\n",
      "[Epoch 17/100] [Batch 8/347] [D loss: 0.499917] [G loss: 0.267853]\n",
      "[Epoch 17/100] [Batch 9/347] [D loss: 0.499869] [G loss: 0.266813]\n",
      "[Epoch 17/100] [Batch 10/347] [D loss: 0.499868] [G loss: 0.268455]\n",
      "[Epoch 17/100] [Batch 11/347] [D loss: 0.499933] [G loss: 0.268170]\n",
      "[Epoch 17/100] [Batch 12/347] [D loss: 0.499949] [G loss: 0.268733]\n",
      "[Epoch 17/100] [Batch 13/347] [D loss: 0.499985] [G loss: 0.266474]\n",
      "[Epoch 17/100] [Batch 14/347] [D loss: 0.500016] [G loss: 0.268805]\n",
      "[Epoch 17/100] [Batch 15/347] [D loss: 0.500005] [G loss: 0.264985]\n",
      "[Epoch 17/100] [Batch 16/347] [D loss: 0.499990] [G loss: 0.260864]\n",
      "[Epoch 17/100] [Batch 17/347] [D loss: 0.499961] [G loss: 0.253195]\n",
      "[Epoch 17/100] [Batch 18/347] [D loss: 0.499930] [G loss: 0.258202]\n",
      "[Epoch 17/100] [Batch 19/347] [D loss: 0.499990] [G loss: 0.254742]\n",
      "[Epoch 17/100] [Batch 20/347] [D loss: 0.500042] [G loss: 0.268014]\n",
      "[Epoch 17/100] [Batch 21/347] [D loss: 0.500012] [G loss: 0.264513]\n",
      "[Epoch 17/100] [Batch 22/347] [D loss: 0.499991] [G loss: 0.259711]\n",
      "[Epoch 17/100] [Batch 23/347] [D loss: 0.499971] [G loss: 0.254721]\n",
      "[Epoch 17/100] [Batch 24/347] [D loss: 0.499982] [G loss: 0.253229]\n",
      "[Epoch 17/100] [Batch 25/347] [D loss: 0.499979] [G loss: 0.253033]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 17/100] [Batch 26/347] [D loss: 0.499892] [G loss: 0.261647]\n",
      "[Epoch 17/100] [Batch 27/347] [D loss: 0.499923] [G loss: 0.267145]\n",
      "[Epoch 17/100] [Batch 28/347] [D loss: 0.500021] [G loss: 0.267130]\n",
      "[Epoch 17/100] [Batch 29/347] [D loss: 0.500072] [G loss: 0.265045]\n",
      "[Epoch 17/100] [Batch 30/347] [D loss: 0.500116] [G loss: 0.272168]\n",
      "[Epoch 17/100] [Batch 31/347] [D loss: 0.500149] [G loss: 0.274922]\n",
      "[Epoch 17/100] [Batch 32/347] [D loss: 0.500120] [G loss: 0.268414]\n",
      "[Epoch 17/100] [Batch 33/347] [D loss: 0.500073] [G loss: 0.264557]\n",
      "[Epoch 17/100] [Batch 34/347] [D loss: 0.500072] [G loss: 0.265812]\n",
      "[Epoch 17/100] [Batch 35/347] [D loss: 0.500067] [G loss: 0.264776]\n",
      "[Epoch 17/100] [Batch 36/347] [D loss: 0.500023] [G loss: 0.255747]\n",
      "[Epoch 17/100] [Batch 37/347] [D loss: 0.499874] [G loss: 0.271303]\n",
      "[Epoch 17/100] [Batch 38/347] [D loss: 0.499757] [G loss: 0.286442]\n",
      "[Epoch 17/100] [Batch 39/347] [D loss: 0.499783] [G loss: 0.276809]\n",
      "[Epoch 17/100] [Batch 40/347] [D loss: 0.499799] [G loss: 0.276943]\n",
      "[Epoch 17/100] [Batch 41/347] [D loss: 0.499778] [G loss: 0.278162]\n",
      "[Epoch 17/100] [Batch 42/347] [D loss: 0.499813] [G loss: 0.271076]\n",
      "[Epoch 17/100] [Batch 43/347] [D loss: 0.499945] [G loss: 0.255160]\n",
      "[Epoch 17/100] [Batch 44/347] [D loss: 0.500068] [G loss: 0.264521]\n",
      "[Epoch 17/100] [Batch 45/347] [D loss: 0.500159] [G loss: 0.281850]\n",
      "[Epoch 17/100] [Batch 46/347] [D loss: 0.500144] [G loss: 0.276557]\n",
      "[Epoch 17/100] [Batch 47/347] [D loss: 0.499973] [G loss: 0.253096]\n",
      "[Epoch 17/100] [Batch 48/347] [D loss: 0.499803] [G loss: 0.285393]\n",
      "[Epoch 17/100] [Batch 49/347] [D loss: 0.499742] [G loss: 0.293884]\n",
      "[Epoch 17/100] [Batch 50/347] [D loss: 0.499717] [G loss: 0.309484]\n",
      "[Epoch 17/100] [Batch 51/347] [D loss: 0.499843] [G loss: 0.294041]\n",
      "[Epoch 17/100] [Batch 52/347] [D loss: 0.500028] [G loss: 0.264323]\n",
      "[Epoch 17/100] [Batch 53/347] [D loss: 0.499989] [G loss: 0.258799]\n",
      "[Epoch 17/100] [Batch 54/347] [D loss: 0.499704] [G loss: 0.309581]\n",
      "[Epoch 17/100] [Batch 55/347] [D loss: 0.499478] [G loss: 0.332283]\n",
      "[Epoch 17/100] [Batch 56/347] [D loss: 0.499524] [G loss: 0.319447]\n",
      "[Epoch 17/100] [Batch 57/347] [D loss: 0.499809] [G loss: 0.285274]\n",
      "[Epoch 17/100] [Batch 58/347] [D loss: 0.500008] [G loss: 0.261566]\n",
      "[Epoch 17/100] [Batch 59/347] [D loss: 0.499942] [G loss: 0.268485]\n",
      "[Epoch 17/100] [Batch 60/347] [D loss: 0.499848] [G loss: 0.287475]\n",
      "[Epoch 17/100] [Batch 61/347] [D loss: 0.499781] [G loss: 0.300252]\n",
      "[Epoch 17/100] [Batch 62/347] [D loss: 0.499615] [G loss: 0.324464]\n",
      "[Epoch 17/100] [Batch 63/347] [D loss: 0.499491] [G loss: 0.326668]\n",
      "[Epoch 17/100] [Batch 64/347] [D loss: 0.499750] [G loss: 0.289874]\n",
      "[Epoch 17/100] [Batch 65/347] [D loss: 0.500084] [G loss: 0.264522]\n",
      "[Epoch 17/100] [Batch 66/347] [D loss: 0.500055] [G loss: 0.266745]\n",
      "[Epoch 17/100] [Batch 67/347] [D loss: 0.499902] [G loss: 0.274093]\n",
      "[Epoch 17/100] [Batch 68/347] [D loss: 0.499802] [G loss: 0.292334]\n",
      "[Epoch 17/100] [Batch 69/347] [D loss: 0.499622] [G loss: 0.311370]\n",
      "[Epoch 17/100] [Batch 70/347] [D loss: 0.499580] [G loss: 0.310253]\n",
      "[Epoch 17/100] [Batch 71/347] [D loss: 0.499628] [G loss: 0.312721]\n",
      "[Epoch 17/100] [Batch 72/347] [D loss: 0.499591] [G loss: 0.315290]\n",
      "[Epoch 17/100] [Batch 73/347] [D loss: 0.499739] [G loss: 0.290625]\n",
      "[Epoch 17/100] [Batch 74/347] [D loss: 0.499899] [G loss: 0.276761]\n",
      "[Epoch 17/100] [Batch 75/347] [D loss: 0.499729] [G loss: 0.306769]\n",
      "[Epoch 17/100] [Batch 76/347] [D loss: 0.499623] [G loss: 0.308858]\n",
      "[Epoch 17/100] [Batch 77/347] [D loss: 0.499841] [G loss: 0.274666]\n",
      "[Epoch 17/100] [Batch 78/347] [D loss: 0.500105] [G loss: 0.270164]\n",
      "[Epoch 17/100] [Batch 79/347] [D loss: 0.500157] [G loss: 0.271739]\n",
      "[Epoch 17/100] [Batch 80/347] [D loss: 0.500122] [G loss: 0.268587]\n",
      "[Epoch 17/100] [Batch 81/347] [D loss: 0.500170] [G loss: 0.273512]\n",
      "[Epoch 17/100] [Batch 82/347] [D loss: 0.500171] [G loss: 0.278983]\n",
      "[Epoch 17/100] [Batch 83/347] [D loss: 0.500130] [G loss: 0.271314]\n",
      "[Epoch 17/100] [Batch 84/347] [D loss: 0.500145] [G loss: 0.277294]\n",
      "[Epoch 17/100] [Batch 85/347] [D loss: 0.500128] [G loss: 0.278104]\n",
      "[Epoch 17/100] [Batch 86/347] [D loss: 0.500103] [G loss: 0.272555]\n",
      "[Epoch 17/100] [Batch 87/347] [D loss: 0.500077] [G loss: 0.270486]\n",
      "[Epoch 17/100] [Batch 88/347] [D loss: 0.500089] [G loss: 0.273889]\n",
      "[Epoch 17/100] [Batch 89/347] [D loss: 0.500093] [G loss: 0.277320]\n",
      "[Epoch 17/100] [Batch 90/347] [D loss: 0.500077] [G loss: 0.273583]\n",
      "[Epoch 17/100] [Batch 91/347] [D loss: 0.500058] [G loss: 0.272199]\n",
      "[Epoch 17/100] [Batch 92/347] [D loss: 0.500065] [G loss: 0.273761]\n",
      "[Epoch 17/100] [Batch 93/347] [D loss: 0.500052] [G loss: 0.271778]\n",
      "[Epoch 17/100] [Batch 94/347] [D loss: 0.500027] [G loss: 0.268268]\n",
      "[Epoch 17/100] [Batch 95/347] [D loss: 0.500030] [G loss: 0.268845]\n",
      "[Epoch 17/100] [Batch 96/347] [D loss: 0.500016] [G loss: 0.264203]\n",
      "[Epoch 17/100] [Batch 97/347] [D loss: 0.499976] [G loss: 0.259097]\n",
      "[Epoch 17/100] [Batch 98/347] [D loss: 0.499989] [G loss: 0.264064]\n",
      "[Epoch 17/100] [Batch 99/347] [D loss: 0.500009] [G loss: 0.267870]\n",
      "[Epoch 17/100] [Batch 100/347] [D loss: 0.499992] [G loss: 0.264238]\n",
      "[Epoch 17/100] [Batch 101/347] [D loss: 0.499958] [G loss: 0.261782]\n",
      "[Epoch 17/100] [Batch 102/347] [D loss: 0.499970] [G loss: 0.262495]\n",
      "[Epoch 17/100] [Batch 103/347] [D loss: 0.499975] [G loss: 0.262125]\n",
      "[Epoch 17/100] [Batch 104/347] [D loss: 0.499929] [G loss: 0.264046]\n",
      "[Epoch 17/100] [Batch 105/347] [D loss: 0.499920] [G loss: 0.265730]\n",
      "[Epoch 17/100] [Batch 106/347] [D loss: 0.499923] [G loss: 0.264750]\n",
      "[Epoch 17/100] [Batch 107/347] [D loss: 0.499909] [G loss: 0.258434]\n",
      "[Epoch 17/100] [Batch 108/347] [D loss: 0.499884] [G loss: 0.275342]\n",
      "[Epoch 17/100] [Batch 109/347] [D loss: 0.499940] [G loss: 0.268417]\n",
      "[Epoch 17/100] [Batch 110/347] [D loss: 0.500016] [G loss: 0.256078]\n",
      "[Epoch 17/100] [Batch 111/347] [D loss: 0.499957] [G loss: 0.262461]\n",
      "[Epoch 17/100] [Batch 112/347] [D loss: 0.499977] [G loss: 0.266028]\n",
      "[Epoch 17/100] [Batch 113/347] [D loss: 0.500102] [G loss: 0.271457]\n",
      "[Epoch 17/100] [Batch 114/347] [D loss: 0.500194] [G loss: 0.292143]\n",
      "[Epoch 17/100] [Batch 115/347] [D loss: 0.500208] [G loss: 0.293360]\n",
      "[Epoch 17/100] [Batch 116/347] [D loss: 0.500188] [G loss: 0.287607]\n",
      "[Epoch 17/100] [Batch 117/347] [D loss: 0.500072] [G loss: 0.261126]\n",
      "[Epoch 17/100] [Batch 118/347] [D loss: 0.499899] [G loss: 0.265834]\n",
      "[Epoch 17/100] [Batch 119/347] [D loss: 0.499859] [G loss: 0.267954]\n",
      "[Epoch 17/100] [Batch 120/347] [D loss: 0.499882] [G loss: 0.266800]\n",
      "[Epoch 17/100] [Batch 121/347] [D loss: 0.499890] [G loss: 0.265043]\n",
      "[Epoch 17/100] [Batch 122/347] [D loss: 0.499949] [G loss: 0.252209]\n",
      "[Epoch 17/100] [Batch 123/347] [D loss: 0.499970] [G loss: 0.251428]\n",
      "[Epoch 17/100] [Batch 124/347] [D loss: 0.499940] [G loss: 0.252952]\n",
      "[Epoch 17/100] [Batch 125/347] [D loss: 0.500006] [G loss: 0.258889]\n",
      "[Epoch 17/100] [Batch 126/347] [D loss: 0.500088] [G loss: 0.271380]\n",
      "[Epoch 17/100] [Batch 127/347] [D loss: 0.500107] [G loss: 0.272663]\n",
      "[Epoch 17/100] [Batch 128/347] [D loss: 0.500064] [G loss: 0.267069]\n",
      "[Epoch 17/100] [Batch 129/347] [D loss: 0.500063] [G loss: 0.262043]\n",
      "[Epoch 17/100] [Batch 130/347] [D loss: 0.500050] [G loss: 0.265112]\n",
      "[Epoch 17/100] [Batch 131/347] [D loss: 0.499960] [G loss: 0.263916]\n",
      "[Epoch 17/100] [Batch 132/347] [D loss: 0.499834] [G loss: 0.288636]\n",
      "[Epoch 17/100] [Batch 133/347] [D loss: 0.499796] [G loss: 0.295413]\n",
      "[Epoch 17/100] [Batch 134/347] [D loss: 0.499716] [G loss: 0.310346]\n",
      "[Epoch 17/100] [Batch 135/347] [D loss: 0.499705] [G loss: 0.319420]\n",
      "[Epoch 17/100] [Batch 136/347] [D loss: 0.499918] [G loss: 0.277531]\n",
      "[Epoch 17/100] [Batch 137/347] [D loss: 0.500025] [G loss: 0.265371]\n",
      "[Epoch 17/100] [Batch 138/347] [D loss: 0.499844] [G loss: 0.282784]\n",
      "[Epoch 17/100] [Batch 139/347] [D loss: 0.499673] [G loss: 0.306849]\n",
      "[Epoch 17/100] [Batch 140/347] [D loss: 0.499612] [G loss: 0.318338]\n",
      "[Epoch 17/100] [Batch 141/347] [D loss: 0.499557] [G loss: 0.325214]\n",
      "[Epoch 17/100] [Batch 142/347] [D loss: 0.499522] [G loss: 0.332900]\n",
      "[Epoch 17/100] [Batch 143/347] [D loss: 0.499382] [G loss: 0.354587]\n",
      "[Epoch 17/100] [Batch 144/347] [D loss: 0.499331] [G loss: 0.356773]\n",
      "[Epoch 17/100] [Batch 145/347] [D loss: 0.499359] [G loss: 0.342466]\n",
      "[Epoch 17/100] [Batch 146/347] [D loss: 0.499413] [G loss: 0.325724]\n",
      "[Epoch 17/100] [Batch 147/347] [D loss: 0.499599] [G loss: 0.297668]\n",
      "[Epoch 17/100] [Batch 148/347] [D loss: 0.499702] [G loss: 0.285298]\n",
      "[Epoch 17/100] [Batch 149/347] [D loss: 0.499621] [G loss: 0.298762]\n",
      "[Epoch 17/100] [Batch 150/347] [D loss: 0.499626] [G loss: 0.299358]\n",
      "[Epoch 17/100] [Batch 151/347] [D loss: 0.499748] [G loss: 0.288579]\n",
      "[Epoch 17/100] [Batch 152/347] [D loss: 0.499717] [G loss: 0.299812]\n",
      "[Epoch 17/100] [Batch 153/347] [D loss: 0.499566] [G loss: 0.320732]\n",
      "[Epoch 17/100] [Batch 154/347] [D loss: 0.499470] [G loss: 0.325010]\n",
      "[Epoch 17/100] [Batch 155/347] [D loss: 0.499537] [G loss: 0.312272]\n",
      "[Epoch 17/100] [Batch 156/347] [D loss: 0.499669] [G loss: 0.295897]\n",
      "[Epoch 17/100] [Batch 157/347] [D loss: 0.499715] [G loss: 0.302321]\n",
      "[Epoch 17/100] [Batch 158/347] [D loss: 0.499539] [G loss: 0.326239]\n",
      "[Epoch 17/100] [Batch 159/347] [D loss: 0.499483] [G loss: 0.323988]\n",
      "[Epoch 17/100] [Batch 160/347] [D loss: 0.499684] [G loss: 0.304252]\n",
      "[Epoch 17/100] [Batch 161/347] [D loss: 0.499806] [G loss: 0.296100]\n",
      "[Epoch 17/100] [Batch 162/347] [D loss: 0.499759] [G loss: 0.302118]\n",
      "[Epoch 17/100] [Batch 163/347] [D loss: 0.499626] [G loss: 0.321025]\n",
      "[Epoch 17/100] [Batch 164/347] [D loss: 0.499488] [G loss: 0.336585]\n",
      "[Epoch 17/100] [Batch 165/347] [D loss: 0.499493] [G loss: 0.327954]\n",
      "[Epoch 17/100] [Batch 166/347] [D loss: 0.499735] [G loss: 0.289838]\n",
      "[Epoch 17/100] [Batch 167/347] [D loss: 0.500018] [G loss: 0.268517]\n",
      "[Epoch 17/100] [Batch 168/347] [D loss: 0.500107] [G loss: 0.279129]\n",
      "[Epoch 17/100] [Batch 169/347] [D loss: 0.500143] [G loss: 0.277852]\n",
      "[Epoch 17/100] [Batch 170/347] [D loss: 0.500177] [G loss: 0.273882]\n",
      "[Epoch 17/100] [Batch 171/347] [D loss: 0.500251] [G loss: 0.282244]\n",
      "[Epoch 17/100] [Batch 172/347] [D loss: 0.500284] [G loss: 0.287120]\n",
      "[Epoch 17/100] [Batch 173/347] [D loss: 0.500204] [G loss: 0.275920]\n",
      "[Epoch 17/100] [Batch 174/347] [D loss: 0.500174] [G loss: 0.273473]\n",
      "[Epoch 17/100] [Batch 175/347] [D loss: 0.500215] [G loss: 0.283397]\n",
      "[Epoch 17/100] [Batch 176/347] [D loss: 0.500297] [G loss: 0.296884]\n",
      "[Epoch 17/100] [Batch 177/347] [D loss: 0.500302] [G loss: 0.297821]\n",
      "[Epoch 17/100] [Batch 178/347] [D loss: 0.500264] [G loss: 0.291908]\n",
      "[Epoch 17/100] [Batch 179/347] [D loss: 0.500217] [G loss: 0.285301]\n",
      "[Epoch 17/100] [Batch 180/347] [D loss: 0.500175] [G loss: 0.278913]\n",
      "[Epoch 17/100] [Batch 181/347] [D loss: 0.500175] [G loss: 0.279433]\n",
      "[Epoch 17/100] [Batch 182/347] [D loss: 0.500136] [G loss: 0.277335]\n",
      "[Epoch 17/100] [Batch 183/347] [D loss: 0.500168] [G loss: 0.281414]\n",
      "[Epoch 17/100] [Batch 184/347] [D loss: 0.500181] [G loss: 0.285286]\n",
      "[Epoch 17/100] [Batch 185/347] [D loss: 0.500174] [G loss: 0.283836]\n",
      "[Epoch 17/100] [Batch 186/347] [D loss: 0.500179] [G loss: 0.283613]\n",
      "[Epoch 17/100] [Batch 187/347] [D loss: 0.500150] [G loss: 0.278297]\n",
      "[Epoch 17/100] [Batch 188/347] [D loss: 0.500123] [G loss: 0.275019]\n",
      "[Epoch 17/100] [Batch 189/347] [D loss: 0.500114] [G loss: 0.274188]\n",
      "[Epoch 17/100] [Batch 190/347] [D loss: 0.500016] [G loss: 0.262257]\n",
      "[Epoch 17/100] [Batch 191/347] [D loss: 0.499901] [G loss: 0.262181]\n",
      "[Epoch 17/100] [Batch 192/347] [D loss: 0.499951] [G loss: 0.252550]\n",
      "[Epoch 17/100] [Batch 193/347] [D loss: 0.500028] [G loss: 0.260254]\n",
      "[Epoch 17/100] [Batch 194/347] [D loss: 0.499960] [G loss: 0.256112]\n",
      "[Epoch 17/100] [Batch 195/347] [D loss: 0.499901] [G loss: 0.265041]\n",
      "[Epoch 17/100] [Batch 196/347] [D loss: 0.499868] [G loss: 0.262868]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 17/100] [Batch 197/347] [D loss: 0.499881] [G loss: 0.258275]\n",
      "[Epoch 17/100] [Batch 198/347] [D loss: 0.499915] [G loss: 0.258018]\n",
      "[Epoch 17/100] [Batch 199/347] [D loss: 0.499911] [G loss: 0.259220]\n",
      "[Epoch 17/100] [Batch 200/347] [D loss: 0.499927] [G loss: 0.254208]\n",
      "[Epoch 17/100] [Batch 201/347] [D loss: 0.499940] [G loss: 0.254153]\n",
      "[Epoch 17/100] [Batch 202/347] [D loss: 0.499866] [G loss: 0.265834]\n",
      "[Epoch 17/100] [Batch 203/347] [D loss: 0.499806] [G loss: 0.274535]\n",
      "[Epoch 17/100] [Batch 204/347] [D loss: 0.499832] [G loss: 0.271016]\n",
      "[Epoch 17/100] [Batch 205/347] [D loss: 0.499866] [G loss: 0.263137]\n",
      "[Epoch 17/100] [Batch 206/347] [D loss: 0.499941] [G loss: 0.250895]\n",
      "[Epoch 17/100] [Batch 207/347] [D loss: 0.500066] [G loss: 0.261132]\n",
      "[Epoch 17/100] [Batch 208/347] [D loss: 0.500042] [G loss: 0.262122]\n",
      "[Epoch 17/100] [Batch 209/347] [D loss: 0.499995] [G loss: 0.256635]\n",
      "[Epoch 17/100] [Batch 210/347] [D loss: 0.500088] [G loss: 0.264739]\n",
      "[Epoch 17/100] [Batch 211/347] [D loss: 0.500075] [G loss: 0.262131]\n",
      "[Epoch 17/100] [Batch 212/347] [D loss: 0.500046] [G loss: 0.261146]\n",
      "[Epoch 17/100] [Batch 213/347] [D loss: 0.500039] [G loss: 0.266977]\n",
      "[Epoch 17/100] [Batch 214/347] [D loss: 0.499921] [G loss: 0.276314]\n",
      "[Epoch 17/100] [Batch 215/347] [D loss: 0.499872] [G loss: 0.284582]\n",
      "[Epoch 17/100] [Batch 216/347] [D loss: 0.499992] [G loss: 0.266596]\n",
      "[Epoch 17/100] [Batch 217/347] [D loss: 0.500072] [G loss: 0.267399]\n",
      "[Epoch 17/100] [Batch 218/347] [D loss: 0.500147] [G loss: 0.273602]\n",
      "[Epoch 17/100] [Batch 219/347] [D loss: 0.500242] [G loss: 0.285944]\n",
      "[Epoch 17/100] [Batch 220/347] [D loss: 0.500353] [G loss: 0.301832]\n",
      "[Epoch 17/100] [Batch 221/347] [D loss: 0.500370] [G loss: 0.303222]\n",
      "[Epoch 17/100] [Batch 222/347] [D loss: 0.500340] [G loss: 0.295298]\n",
      "[Epoch 17/100] [Batch 223/347] [D loss: 0.500332] [G loss: 0.294009]\n",
      "[Epoch 17/100] [Batch 224/347] [D loss: 0.500308] [G loss: 0.289909]\n",
      "[Epoch 17/100] [Batch 225/347] [D loss: 0.500134] [G loss: 0.276781]\n",
      "[Epoch 17/100] [Batch 226/347] [D loss: 0.499867] [G loss: 0.272459]\n",
      "[Epoch 17/100] [Batch 227/347] [D loss: 0.499699] [G loss: 0.282738]\n",
      "[Epoch 17/100] [Batch 228/347] [D loss: 0.499687] [G loss: 0.284020]\n",
      "[Epoch 17/100] [Batch 229/347] [D loss: 0.499760] [G loss: 0.279118]\n",
      "[Epoch 17/100] [Batch 230/347] [D loss: 0.499805] [G loss: 0.275213]\n",
      "[Epoch 17/100] [Batch 231/347] [D loss: 0.499758] [G loss: 0.275170]\n",
      "[Epoch 17/100] [Batch 232/347] [D loss: 0.499800] [G loss: 0.271061]\n",
      "[Epoch 17/100] [Batch 233/347] [D loss: 0.499825] [G loss: 0.269115]\n",
      "[Epoch 17/100] [Batch 234/347] [D loss: 0.499822] [G loss: 0.274057]\n",
      "[Epoch 17/100] [Batch 235/347] [D loss: 0.499926] [G loss: 0.262822]\n",
      "[Epoch 17/100] [Batch 236/347] [D loss: 0.500028] [G loss: 0.263675]\n",
      "[Epoch 17/100] [Batch 237/347] [D loss: 0.500103] [G loss: 0.266582]\n",
      "[Epoch 17/100] [Batch 238/347] [D loss: 0.500101] [G loss: 0.270490]\n",
      "[Epoch 17/100] [Batch 239/347] [D loss: 0.500074] [G loss: 0.268360]\n",
      "[Epoch 17/100] [Batch 240/347] [D loss: 0.500066] [G loss: 0.264425]\n",
      "[Epoch 17/100] [Batch 241/347] [D loss: 0.500031] [G loss: 0.258473]\n",
      "[Epoch 17/100] [Batch 242/347] [D loss: 0.500005] [G loss: 0.256399]\n",
      "[Epoch 17/100] [Batch 243/347] [D loss: 0.500052] [G loss: 0.263935]\n",
      "[Epoch 17/100] [Batch 244/347] [D loss: 0.500107] [G loss: 0.272673]\n",
      "[Epoch 17/100] [Batch 245/347] [D loss: 0.500164] [G loss: 0.271350]\n",
      "[Epoch 17/100] [Batch 246/347] [D loss: 0.500011] [G loss: 0.264648]\n",
      "[Epoch 17/100] [Batch 247/347] [D loss: 0.499809] [G loss: 0.269512]\n",
      "[Epoch 17/100] [Batch 248/347] [D loss: 0.499728] [G loss: 0.274816]\n",
      "[Epoch 17/100] [Batch 249/347] [D loss: 0.499689] [G loss: 0.280908]\n",
      "[Epoch 17/100] [Batch 250/347] [D loss: 0.499830] [G loss: 0.272263]\n",
      "[Epoch 17/100] [Batch 251/347] [D loss: 0.500014] [G loss: 0.264759]\n",
      "[Epoch 17/100] [Batch 252/347] [D loss: 0.500085] [G loss: 0.267961]\n",
      "[Epoch 17/100] [Batch 253/347] [D loss: 0.500091] [G loss: 0.268510]\n",
      "[Epoch 17/100] [Batch 254/347] [D loss: 0.500087] [G loss: 0.266867]\n",
      "[Epoch 17/100] [Batch 255/347] [D loss: 0.500040] [G loss: 0.265418]\n",
      "[Epoch 17/100] [Batch 256/347] [D loss: 0.500082] [G loss: 0.270604]\n",
      "[Epoch 17/100] [Batch 257/347] [D loss: 0.500161] [G loss: 0.272476]\n",
      "[Epoch 17/100] [Batch 258/347] [D loss: 0.500071] [G loss: 0.267171]\n",
      "[Epoch 17/100] [Batch 259/347] [D loss: 0.499868] [G loss: 0.271733]\n",
      "[Epoch 17/100] [Batch 260/347] [D loss: 0.499772] [G loss: 0.286083]\n",
      "[Epoch 17/100] [Batch 261/347] [D loss: 0.499846] [G loss: 0.278508]\n",
      "[Epoch 17/100] [Batch 262/347] [D loss: 0.499903] [G loss: 0.263319]\n",
      "[Epoch 17/100] [Batch 263/347] [D loss: 0.499896] [G loss: 0.264177]\n",
      "[Epoch 17/100] [Batch 264/347] [D loss: 0.499826] [G loss: 0.278612]\n",
      "[Epoch 17/100] [Batch 265/347] [D loss: 0.499787] [G loss: 0.283820]\n",
      "[Epoch 17/100] [Batch 266/347] [D loss: 0.499809] [G loss: 0.276642]\n",
      "[Epoch 17/100] [Batch 267/347] [D loss: 0.499844] [G loss: 0.269830]\n",
      "[Epoch 17/100] [Batch 268/347] [D loss: 0.499834] [G loss: 0.276695]\n",
      "[Epoch 17/100] [Batch 269/347] [D loss: 0.499786] [G loss: 0.287753]\n",
      "[Epoch 17/100] [Batch 270/347] [D loss: 0.499790] [G loss: 0.284318]\n",
      "[Epoch 17/100] [Batch 271/347] [D loss: 0.499834] [G loss: 0.272481]\n",
      "[Epoch 17/100] [Batch 272/347] [D loss: 0.499897] [G loss: 0.263853]\n",
      "[Epoch 17/100] [Batch 273/347] [D loss: 0.499875] [G loss: 0.275660]\n",
      "[Epoch 17/100] [Batch 274/347] [D loss: 0.499743] [G loss: 0.309440]\n",
      "[Epoch 17/100] [Batch 275/347] [D loss: 0.499746] [G loss: 0.306401]\n",
      "[Epoch 17/100] [Batch 276/347] [D loss: 0.499861] [G loss: 0.274003]\n",
      "[Epoch 17/100] [Batch 277/347] [D loss: 0.499923] [G loss: 0.259370]\n",
      "[Epoch 17/100] [Batch 278/347] [D loss: 0.499983] [G loss: 0.253290]\n",
      "[Epoch 17/100] [Batch 279/347] [D loss: 0.499991] [G loss: 0.260138]\n",
      "[Epoch 17/100] [Batch 280/347] [D loss: 0.499974] [G loss: 0.263599]\n",
      "[Epoch 17/100] [Batch 281/347] [D loss: 0.499976] [G loss: 0.261820]\n",
      "[Epoch 17/100] [Batch 282/347] [D loss: 0.499969] [G loss: 0.259631]\n",
      "[Epoch 17/100] [Batch 283/347] [D loss: 0.499934] [G loss: 0.260706]\n",
      "[Epoch 17/100] [Batch 284/347] [D loss: 0.499958] [G loss: 0.262326]\n",
      "[Epoch 17/100] [Batch 285/347] [D loss: 0.499981] [G loss: 0.258260]\n",
      "[Epoch 17/100] [Batch 286/347] [D loss: 0.499946] [G loss: 0.251202]\n",
      "[Epoch 17/100] [Batch 287/347] [D loss: 0.499934] [G loss: 0.254605]\n",
      "[Epoch 17/100] [Batch 288/347] [D loss: 0.499736] [G loss: 0.281399]\n",
      "[Epoch 17/100] [Batch 289/347] [D loss: 0.499703] [G loss: 0.285828]\n",
      "[Epoch 17/100] [Batch 290/347] [D loss: 0.499850] [G loss: 0.263281]\n",
      "[Epoch 17/100] [Batch 291/347] [D loss: 0.499820] [G loss: 0.266000]\n",
      "[Epoch 17/100] [Batch 292/347] [D loss: 0.499893] [G loss: 0.257417]\n",
      "[Epoch 17/100] [Batch 293/347] [D loss: 0.500095] [G loss: 0.268858]\n",
      "[Epoch 17/100] [Batch 294/347] [D loss: 0.500180] [G loss: 0.278573]\n",
      "[Epoch 17/100] [Batch 295/347] [D loss: 0.500105] [G loss: 0.276113]\n",
      "[Epoch 17/100] [Batch 296/347] [D loss: 0.500123] [G loss: 0.272042]\n",
      "[Epoch 17/100] [Batch 297/347] [D loss: 0.500184] [G loss: 0.283722]\n",
      "[Epoch 17/100] [Batch 298/347] [D loss: 0.500135] [G loss: 0.278574]\n",
      "[Epoch 17/100] [Batch 299/347] [D loss: 0.500146] [G loss: 0.277237]\n",
      "[Epoch 17/100] [Batch 300/347] [D loss: 0.500112] [G loss: 0.272615]\n",
      "[Epoch 17/100] [Batch 301/347] [D loss: 0.500134] [G loss: 0.273605]\n",
      "[Epoch 17/100] [Batch 302/347] [D loss: 0.500185] [G loss: 0.278715]\n",
      "[Epoch 17/100] [Batch 303/347] [D loss: 0.499992] [G loss: 0.263046]\n",
      "[Epoch 17/100] [Batch 304/347] [D loss: 0.499806] [G loss: 0.266790]\n",
      "[Epoch 17/100] [Batch 305/347] [D loss: 0.499758] [G loss: 0.279540]\n",
      "[Epoch 17/100] [Batch 306/347] [D loss: 0.499747] [G loss: 0.270937]\n",
      "[Epoch 17/100] [Batch 307/347] [D loss: 0.499727] [G loss: 0.283415]\n",
      "[Epoch 17/100] [Batch 308/347] [D loss: 0.499728] [G loss: 0.279460]\n",
      "[Epoch 17/100] [Batch 309/347] [D loss: 0.499886] [G loss: 0.259638]\n",
      "[Epoch 17/100] [Batch 310/347] [D loss: 0.500031] [G loss: 0.275779]\n",
      "[Epoch 17/100] [Batch 311/347] [D loss: 0.500034] [G loss: 0.278581]\n",
      "[Epoch 17/100] [Batch 312/347] [D loss: 0.500029] [G loss: 0.278186]\n",
      "[Epoch 17/100] [Batch 313/347] [D loss: 0.500031] [G loss: 0.277288]\n",
      "[Epoch 17/100] [Batch 314/347] [D loss: 0.500040] [G loss: 0.270825]\n",
      "[Epoch 17/100] [Batch 315/347] [D loss: 0.500043] [G loss: 0.261484]\n",
      "[Epoch 17/100] [Batch 316/347] [D loss: 0.499872] [G loss: 0.259609]\n",
      "[Epoch 17/100] [Batch 317/347] [D loss: 0.499722] [G loss: 0.278185]\n",
      "[Epoch 17/100] [Batch 318/347] [D loss: 0.499901] [G loss: 0.255870]\n",
      "[Epoch 17/100] [Batch 319/347] [D loss: 0.500130] [G loss: 0.283562]\n",
      "[Epoch 17/100] [Batch 320/347] [D loss: 0.500216] [G loss: 0.297227]\n",
      "[Epoch 17/100] [Batch 321/347] [D loss: 0.500159] [G loss: 0.286804]\n",
      "[Epoch 17/100] [Batch 322/347] [D loss: 0.500082] [G loss: 0.273740]\n",
      "[Epoch 17/100] [Batch 323/347] [D loss: 0.500082] [G loss: 0.272927]\n",
      "[Epoch 17/100] [Batch 324/347] [D loss: 0.500109] [G loss: 0.275940]\n",
      "[Epoch 17/100] [Batch 325/347] [D loss: 0.500048] [G loss: 0.265179]\n",
      "[Epoch 17/100] [Batch 326/347] [D loss: 0.499963] [G loss: 0.254233]\n",
      "[Epoch 17/100] [Batch 327/347] [D loss: 0.499963] [G loss: 0.252391]\n",
      "[Epoch 17/100] [Batch 328/347] [D loss: 0.499931] [G loss: 0.251867]\n",
      "[Epoch 17/100] [Batch 329/347] [D loss: 0.499788] [G loss: 0.273836]\n",
      "[Epoch 17/100] [Batch 330/347] [D loss: 0.499664] [G loss: 0.289217]\n",
      "[Epoch 17/100] [Batch 331/347] [D loss: 0.499790] [G loss: 0.270889]\n",
      "[Epoch 17/100] [Batch 332/347] [D loss: 0.499993] [G loss: 0.265601]\n",
      "[Epoch 17/100] [Batch 333/347] [D loss: 0.500047] [G loss: 0.277122]\n",
      "[Epoch 17/100] [Batch 334/347] [D loss: 0.500087] [G loss: 0.278649]\n",
      "[Epoch 17/100] [Batch 335/347] [D loss: 0.500045] [G loss: 0.266772]\n",
      "[Epoch 17/100] [Batch 336/347] [D loss: 0.499958] [G loss: 0.252416]\n",
      "[Epoch 17/100] [Batch 337/347] [D loss: 0.499969] [G loss: 0.258508]\n",
      "[Epoch 17/100] [Batch 338/347] [D loss: 0.500042] [G loss: 0.273180]\n",
      "[Epoch 17/100] [Batch 339/347] [D loss: 0.500077] [G loss: 0.278569]\n",
      "[Epoch 17/100] [Batch 340/347] [D loss: 0.500067] [G loss: 0.278999]\n",
      "[Epoch 17/100] [Batch 341/347] [D loss: 0.500062] [G loss: 0.274257]\n",
      "[Epoch 17/100] [Batch 342/347] [D loss: 0.500014] [G loss: 0.266662]\n",
      "[Epoch 17/100] [Batch 343/347] [D loss: 0.500005] [G loss: 0.271400]\n",
      "[Epoch 17/100] [Batch 344/347] [D loss: 0.499935] [G loss: 0.263243]\n",
      "[Epoch 17/100] [Batch 345/347] [D loss: 0.499745] [G loss: 0.273388]\n",
      "[Epoch 17/100] [Batch 346/347] [D loss: 0.499644] [G loss: 0.291768]\n",
      "[Epoch 17/100] [Batch 347/347] [D loss: 0.499628] [G loss: 0.297884]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 18/100] [Batch 1/347] [D loss: 0.499873] [G loss: 0.263994]\n",
      "[Epoch 18/100] [Batch 2/347] [D loss: 0.499865] [G loss: 0.269124]\n",
      "[Epoch 18/100] [Batch 3/347] [D loss: 0.499914] [G loss: 0.268959]\n",
      "[Epoch 18/100] [Batch 4/347] [D loss: 0.499913] [G loss: 0.270140]\n",
      "[Epoch 18/100] [Batch 5/347] [D loss: 0.499911] [G loss: 0.269358]\n",
      "[Epoch 18/100] [Batch 6/347] [D loss: 0.499925] [G loss: 0.269681]\n",
      "[Epoch 18/100] [Batch 7/347] [D loss: 0.499897] [G loss: 0.269518]\n",
      "[Epoch 18/100] [Batch 8/347] [D loss: 0.499906] [G loss: 0.264811]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 18/100] [Batch 9/347] [D loss: 0.499850] [G loss: 0.263772]\n",
      "[Epoch 18/100] [Batch 10/347] [D loss: 0.499848] [G loss: 0.265356]\n",
      "[Epoch 18/100] [Batch 11/347] [D loss: 0.499922] [G loss: 0.265143]\n",
      "[Epoch 18/100] [Batch 12/347] [D loss: 0.499948] [G loss: 0.265637]\n",
      "[Epoch 18/100] [Batch 13/347] [D loss: 0.499985] [G loss: 0.268896]\n",
      "[Epoch 18/100] [Batch 14/347] [D loss: 0.500028] [G loss: 0.271224]\n",
      "[Epoch 18/100] [Batch 15/347] [D loss: 0.500011] [G loss: 0.267421]\n",
      "[Epoch 18/100] [Batch 16/347] [D loss: 0.499993] [G loss: 0.263348]\n",
      "[Epoch 18/100] [Batch 17/347] [D loss: 0.499954] [G loss: 0.251397]\n",
      "[Epoch 18/100] [Batch 18/347] [D loss: 0.499915] [G loss: 0.256510]\n",
      "[Epoch 18/100] [Batch 19/347] [D loss: 0.499985] [G loss: 0.256700]\n",
      "[Epoch 18/100] [Batch 20/347] [D loss: 0.500044] [G loss: 0.269775]\n",
      "[Epoch 18/100] [Batch 21/347] [D loss: 0.500011] [G loss: 0.266041]\n",
      "[Epoch 18/100] [Batch 22/347] [D loss: 0.499977] [G loss: 0.261053]\n",
      "[Epoch 18/100] [Batch 23/347] [D loss: 0.499953] [G loss: 0.254760]\n",
      "[Epoch 18/100] [Batch 24/347] [D loss: 0.499966] [G loss: 0.253998]\n",
      "[Epoch 18/100] [Batch 25/347] [D loss: 0.499957] [G loss: 0.253350]\n",
      "[Epoch 18/100] [Batch 26/347] [D loss: 0.499850] [G loss: 0.262284]\n",
      "[Epoch 18/100] [Batch 27/347] [D loss: 0.499881] [G loss: 0.268082]\n",
      "[Epoch 18/100] [Batch 28/347] [D loss: 0.499989] [G loss: 0.266385]\n",
      "[Epoch 18/100] [Batch 29/347] [D loss: 0.500052] [G loss: 0.263965]\n",
      "[Epoch 18/100] [Batch 30/347] [D loss: 0.500103] [G loss: 0.270816]\n",
      "[Epoch 18/100] [Batch 31/347] [D loss: 0.500138] [G loss: 0.273329]\n",
      "[Epoch 18/100] [Batch 32/347] [D loss: 0.500100] [G loss: 0.266594]\n",
      "[Epoch 18/100] [Batch 33/347] [D loss: 0.500042] [G loss: 0.262480]\n",
      "[Epoch 18/100] [Batch 34/347] [D loss: 0.500040] [G loss: 0.263533]\n",
      "[Epoch 18/100] [Batch 35/347] [D loss: 0.500031] [G loss: 0.262291]\n",
      "[Epoch 18/100] [Batch 36/347] [D loss: 0.499979] [G loss: 0.253122]\n",
      "[Epoch 18/100] [Batch 37/347] [D loss: 0.499799] [G loss: 0.273643]\n",
      "[Epoch 18/100] [Batch 38/347] [D loss: 0.499665] [G loss: 0.288826]\n",
      "[Epoch 18/100] [Batch 39/347] [D loss: 0.499696] [G loss: 0.279174]\n",
      "[Epoch 18/100] [Batch 40/347] [D loss: 0.499707] [G loss: 0.279805]\n",
      "[Epoch 18/100] [Batch 41/347] [D loss: 0.499686] [G loss: 0.281047]\n",
      "[Epoch 18/100] [Batch 42/347] [D loss: 0.499729] [G loss: 0.273963]\n",
      "[Epoch 18/100] [Batch 43/347] [D loss: 0.499872] [G loss: 0.257577]\n",
      "[Epoch 18/100] [Batch 44/347] [D loss: 0.500026] [G loss: 0.260930]\n",
      "[Epoch 18/100] [Batch 45/347] [D loss: 0.500135] [G loss: 0.278172]\n",
      "[Epoch 18/100] [Batch 46/347] [D loss: 0.500115] [G loss: 0.272814]\n",
      "[Epoch 18/100] [Batch 47/347] [D loss: 0.499912] [G loss: 0.255666]\n",
      "[Epoch 18/100] [Batch 48/347] [D loss: 0.499704] [G loss: 0.288016]\n",
      "[Epoch 18/100] [Batch 49/347] [D loss: 0.499637] [G loss: 0.296541]\n",
      "[Epoch 18/100] [Batch 50/347] [D loss: 0.499598] [G loss: 0.312113]\n",
      "[Epoch 18/100] [Batch 51/347] [D loss: 0.499751] [G loss: 0.296655]\n",
      "[Epoch 18/100] [Batch 52/347] [D loss: 0.499970] [G loss: 0.259850]\n",
      "[Epoch 18/100] [Batch 53/347] [D loss: 0.499931] [G loss: 0.259363]\n",
      "[Epoch 18/100] [Batch 54/347] [D loss: 0.499591] [G loss: 0.312030]\n",
      "[Epoch 18/100] [Batch 55/347] [D loss: 0.499324] [G loss: 0.334511]\n",
      "[Epoch 18/100] [Batch 56/347] [D loss: 0.499382] [G loss: 0.321448]\n",
      "[Epoch 18/100] [Batch 57/347] [D loss: 0.499726] [G loss: 0.287038]\n",
      "[Epoch 18/100] [Batch 58/347] [D loss: 0.499962] [G loss: 0.258566]\n",
      "[Epoch 18/100] [Batch 59/347] [D loss: 0.499888] [G loss: 0.269904]\n",
      "[Epoch 18/100] [Batch 60/347] [D loss: 0.499774] [G loss: 0.288779]\n",
      "[Epoch 18/100] [Batch 61/347] [D loss: 0.499695] [G loss: 0.301506]\n",
      "[Epoch 18/100] [Batch 62/347] [D loss: 0.499497] [G loss: 0.325636]\n",
      "[Epoch 18/100] [Batch 63/347] [D loss: 0.499356] [G loss: 0.327787]\n",
      "[Epoch 18/100] [Batch 64/347] [D loss: 0.499664] [G loss: 0.290849]\n",
      "[Epoch 18/100] [Batch 65/347] [D loss: 0.500065] [G loss: 0.262668]\n",
      "[Epoch 18/100] [Batch 66/347] [D loss: 0.500034] [G loss: 0.265023]\n",
      "[Epoch 18/100] [Batch 67/347] [D loss: 0.499848] [G loss: 0.274966]\n",
      "[Epoch 18/100] [Batch 68/347] [D loss: 0.499728] [G loss: 0.293160]\n",
      "[Epoch 18/100] [Batch 69/347] [D loss: 0.499515] [G loss: 0.312248]\n",
      "[Epoch 18/100] [Batch 70/347] [D loss: 0.499469] [G loss: 0.311030]\n",
      "[Epoch 18/100] [Batch 71/347] [D loss: 0.499524] [G loss: 0.313460]\n",
      "[Epoch 18/100] [Batch 72/347] [D loss: 0.499473] [G loss: 0.315997]\n",
      "[Epoch 18/100] [Batch 73/347] [D loss: 0.499655] [G loss: 0.291337]\n",
      "[Epoch 18/100] [Batch 74/347] [D loss: 0.499846] [G loss: 0.277388]\n",
      "[Epoch 18/100] [Batch 75/347] [D loss: 0.499644] [G loss: 0.307408]\n",
      "[Epoch 18/100] [Batch 76/347] [D loss: 0.499518] [G loss: 0.309506]\n",
      "[Epoch 18/100] [Batch 77/347] [D loss: 0.499783] [G loss: 0.275301]\n",
      "[Epoch 18/100] [Batch 78/347] [D loss: 0.500092] [G loss: 0.269123]\n",
      "[Epoch 18/100] [Batch 79/347] [D loss: 0.500161] [G loss: 0.270693]\n",
      "[Epoch 18/100] [Batch 80/347] [D loss: 0.500116] [G loss: 0.267378]\n",
      "[Epoch 18/100] [Batch 81/347] [D loss: 0.500180] [G loss: 0.272309]\n",
      "[Epoch 18/100] [Batch 82/347] [D loss: 0.500176] [G loss: 0.277964]\n",
      "[Epoch 18/100] [Batch 83/347] [D loss: 0.500129] [G loss: 0.270301]\n",
      "[Epoch 18/100] [Batch 84/347] [D loss: 0.500148] [G loss: 0.276136]\n",
      "[Epoch 18/100] [Batch 85/347] [D loss: 0.500130] [G loss: 0.276980]\n",
      "[Epoch 18/100] [Batch 86/347] [D loss: 0.500095] [G loss: 0.271455]\n",
      "[Epoch 18/100] [Batch 87/347] [D loss: 0.500070] [G loss: 0.269391]\n",
      "[Epoch 18/100] [Batch 88/347] [D loss: 0.500080] [G loss: 0.272832]\n",
      "[Epoch 18/100] [Batch 89/347] [D loss: 0.500092] [G loss: 0.276329]\n",
      "[Epoch 18/100] [Batch 90/347] [D loss: 0.500065] [G loss: 0.272630]\n",
      "[Epoch 18/100] [Batch 91/347] [D loss: 0.500051] [G loss: 0.271242]\n",
      "[Epoch 18/100] [Batch 92/347] [D loss: 0.500053] [G loss: 0.272804]\n",
      "[Epoch 18/100] [Batch 93/347] [D loss: 0.500035] [G loss: 0.270847]\n",
      "[Epoch 18/100] [Batch 94/347] [D loss: 0.500005] [G loss: 0.267376]\n",
      "[Epoch 18/100] [Batch 95/347] [D loss: 0.500015] [G loss: 0.267966]\n",
      "[Epoch 18/100] [Batch 96/347] [D loss: 0.499992] [G loss: 0.263275]\n",
      "[Epoch 18/100] [Batch 97/347] [D loss: 0.499947] [G loss: 0.258237]\n",
      "[Epoch 18/100] [Batch 98/347] [D loss: 0.499965] [G loss: 0.263246]\n",
      "[Epoch 18/100] [Batch 99/347] [D loss: 0.499986] [G loss: 0.266991]\n",
      "[Epoch 18/100] [Batch 100/347] [D loss: 0.499967] [G loss: 0.263337]\n",
      "[Epoch 18/100] [Batch 101/347] [D loss: 0.499926] [G loss: 0.261785]\n",
      "[Epoch 18/100] [Batch 102/347] [D loss: 0.499937] [G loss: 0.262475]\n",
      "[Epoch 18/100] [Batch 103/347] [D loss: 0.499948] [G loss: 0.261744]\n",
      "[Epoch 18/100] [Batch 104/347] [D loss: 0.499893] [G loss: 0.263596]\n",
      "[Epoch 18/100] [Batch 105/347] [D loss: 0.499888] [G loss: 0.264883]\n",
      "[Epoch 18/100] [Batch 106/347] [D loss: 0.499895] [G loss: 0.263573]\n",
      "[Epoch 18/100] [Batch 107/347] [D loss: 0.499875] [G loss: 0.257421]\n",
      "[Epoch 18/100] [Batch 108/347] [D loss: 0.499847] [G loss: 0.274110]\n",
      "[Epoch 18/100] [Batch 109/347] [D loss: 0.499919] [G loss: 0.266987]\n",
      "[Epoch 18/100] [Batch 110/347] [D loss: 0.500010] [G loss: 0.256731]\n",
      "[Epoch 18/100] [Batch 111/347] [D loss: 0.499943] [G loss: 0.261997]\n",
      "[Epoch 18/100] [Batch 112/347] [D loss: 0.499962] [G loss: 0.267196]\n",
      "[Epoch 18/100] [Batch 113/347] [D loss: 0.500121] [G loss: 0.271954]\n",
      "[Epoch 18/100] [Batch 114/347] [D loss: 0.500226] [G loss: 0.292533]\n",
      "[Epoch 18/100] [Batch 115/347] [D loss: 0.500239] [G loss: 0.293616]\n",
      "[Epoch 18/100] [Batch 116/347] [D loss: 0.500215] [G loss: 0.287780]\n",
      "[Epoch 18/100] [Batch 117/347] [D loss: 0.500073] [G loss: 0.261603]\n",
      "[Epoch 18/100] [Batch 118/347] [D loss: 0.499860] [G loss: 0.265209]\n",
      "[Epoch 18/100] [Batch 119/347] [D loss: 0.499817] [G loss: 0.267437]\n",
      "[Epoch 18/100] [Batch 120/347] [D loss: 0.499846] [G loss: 0.266336]\n",
      "[Epoch 18/100] [Batch 121/347] [D loss: 0.499855] [G loss: 0.264658]\n",
      "[Epoch 18/100] [Batch 122/347] [D loss: 0.499925] [G loss: 0.251693]\n",
      "[Epoch 18/100] [Batch 123/347] [D loss: 0.499946] [G loss: 0.251369]\n",
      "[Epoch 18/100] [Batch 124/347] [D loss: 0.499908] [G loss: 0.252771]\n",
      "[Epoch 18/100] [Batch 125/347] [D loss: 0.499989] [G loss: 0.258778]\n",
      "[Epoch 18/100] [Batch 126/347] [D loss: 0.500085] [G loss: 0.271282]\n",
      "[Epoch 18/100] [Batch 127/347] [D loss: 0.500108] [G loss: 0.272507]\n",
      "[Epoch 18/100] [Batch 128/347] [D loss: 0.500063] [G loss: 0.266895]\n",
      "[Epoch 18/100] [Batch 129/347] [D loss: 0.500054] [G loss: 0.261869]\n",
      "[Epoch 18/100] [Batch 130/347] [D loss: 0.500037] [G loss: 0.264688]\n",
      "[Epoch 18/100] [Batch 131/347] [D loss: 0.499925] [G loss: 0.264024]\n",
      "[Epoch 18/100] [Batch 132/347] [D loss: 0.499774] [G loss: 0.288767]\n",
      "[Epoch 18/100] [Batch 133/347] [D loss: 0.499724] [G loss: 0.295530]\n",
      "[Epoch 18/100] [Batch 134/347] [D loss: 0.499626] [G loss: 0.310449]\n",
      "[Epoch 18/100] [Batch 135/347] [D loss: 0.499612] [G loss: 0.319478]\n",
      "[Epoch 18/100] [Batch 136/347] [D loss: 0.499870] [G loss: 0.277514]\n",
      "[Epoch 18/100] [Batch 137/347] [D loss: 0.500007] [G loss: 0.264542]\n",
      "[Epoch 18/100] [Batch 138/347] [D loss: 0.499782] [G loss: 0.282799]\n",
      "[Epoch 18/100] [Batch 139/347] [D loss: 0.499582] [G loss: 0.306803]\n",
      "[Epoch 18/100] [Batch 140/347] [D loss: 0.499505] [G loss: 0.318300]\n",
      "[Epoch 18/100] [Batch 141/347] [D loss: 0.499438] [G loss: 0.325130]\n",
      "[Epoch 18/100] [Batch 142/347] [D loss: 0.499396] [G loss: 0.332781]\n",
      "[Epoch 18/100] [Batch 143/347] [D loss: 0.499225] [G loss: 0.354371]\n",
      "[Epoch 18/100] [Batch 144/347] [D loss: 0.499163] [G loss: 0.356537]\n",
      "[Epoch 18/100] [Batch 145/347] [D loss: 0.499202] [G loss: 0.342186]\n",
      "[Epoch 18/100] [Batch 146/347] [D loss: 0.499267] [G loss: 0.325352]\n",
      "[Epoch 18/100] [Batch 147/347] [D loss: 0.499489] [G loss: 0.297290]\n",
      "[Epoch 18/100] [Batch 148/347] [D loss: 0.499619] [G loss: 0.284906]\n",
      "[Epoch 18/100] [Batch 149/347] [D loss: 0.499520] [G loss: 0.298360]\n",
      "[Epoch 18/100] [Batch 150/347] [D loss: 0.499524] [G loss: 0.298941]\n",
      "[Epoch 18/100] [Batch 151/347] [D loss: 0.499670] [G loss: 0.288212]\n",
      "[Epoch 18/100] [Batch 152/347] [D loss: 0.499631] [G loss: 0.299470]\n",
      "[Epoch 18/100] [Batch 153/347] [D loss: 0.499448] [G loss: 0.320343]\n",
      "[Epoch 18/100] [Batch 154/347] [D loss: 0.499333] [G loss: 0.324696]\n",
      "[Epoch 18/100] [Batch 155/347] [D loss: 0.499412] [G loss: 0.311966]\n",
      "[Epoch 18/100] [Batch 156/347] [D loss: 0.499575] [G loss: 0.295532]\n",
      "[Epoch 18/100] [Batch 157/347] [D loss: 0.499627] [G loss: 0.302051]\n",
      "[Epoch 18/100] [Batch 158/347] [D loss: 0.499414] [G loss: 0.325937]\n",
      "[Epoch 18/100] [Batch 159/347] [D loss: 0.499349] [G loss: 0.323685]\n",
      "[Epoch 18/100] [Batch 160/347] [D loss: 0.499589] [G loss: 0.304020]\n",
      "[Epoch 18/100] [Batch 161/347] [D loss: 0.499733] [G loss: 0.295819]\n",
      "[Epoch 18/100] [Batch 162/347] [D loss: 0.499677] [G loss: 0.301890]\n",
      "[Epoch 18/100] [Batch 163/347] [D loss: 0.499514] [G loss: 0.320882]\n",
      "[Epoch 18/100] [Batch 164/347] [D loss: 0.499355] [G loss: 0.336446]\n",
      "[Epoch 18/100] [Batch 165/347] [D loss: 0.499357] [G loss: 0.327871]\n",
      "[Epoch 18/100] [Batch 166/347] [D loss: 0.499650] [G loss: 0.289816]\n",
      "[Epoch 18/100] [Batch 167/347] [D loss: 0.499986] [G loss: 0.266900]\n",
      "[Epoch 18/100] [Batch 168/347] [D loss: 0.500096] [G loss: 0.277529]\n",
      "[Epoch 18/100] [Batch 169/347] [D loss: 0.500143] [G loss: 0.276189]\n",
      "[Epoch 18/100] [Batch 170/347] [D loss: 0.500182] [G loss: 0.272194]\n",
      "[Epoch 18/100] [Batch 171/347] [D loss: 0.500272] [G loss: 0.281166]\n",
      "[Epoch 18/100] [Batch 172/347] [D loss: 0.500304] [G loss: 0.286036]\n",
      "[Epoch 18/100] [Batch 173/347] [D loss: 0.500209] [G loss: 0.274821]\n",
      "[Epoch 18/100] [Batch 174/347] [D loss: 0.500177] [G loss: 0.272384]\n",
      "[Epoch 18/100] [Batch 175/347] [D loss: 0.500227] [G loss: 0.282363]\n",
      "[Epoch 18/100] [Batch 176/347] [D loss: 0.500332] [G loss: 0.295864]\n",
      "[Epoch 18/100] [Batch 177/347] [D loss: 0.500331] [G loss: 0.296837]\n",
      "[Epoch 18/100] [Batch 178/347] [D loss: 0.500283] [G loss: 0.290953]\n",
      "[Epoch 18/100] [Batch 179/347] [D loss: 0.500228] [G loss: 0.284394]\n",
      "[Epoch 18/100] [Batch 180/347] [D loss: 0.500183] [G loss: 0.278074]\n",
      "[Epoch 18/100] [Batch 181/347] [D loss: 0.500179] [G loss: 0.278574]\n",
      "[Epoch 18/100] [Batch 182/347] [D loss: 0.500130] [G loss: 0.276551]\n",
      "[Epoch 18/100] [Batch 183/347] [D loss: 0.500164] [G loss: 0.280677]\n",
      "[Epoch 18/100] [Batch 184/347] [D loss: 0.500189] [G loss: 0.284667]\n",
      "[Epoch 18/100] [Batch 185/347] [D loss: 0.500178] [G loss: 0.283221]\n",
      "[Epoch 18/100] [Batch 186/347] [D loss: 0.500187] [G loss: 0.283055]\n",
      "[Epoch 18/100] [Batch 187/347] [D loss: 0.500151] [G loss: 0.277766]\n",
      "[Epoch 18/100] [Batch 188/347] [D loss: 0.500115] [G loss: 0.274547]\n",
      "[Epoch 18/100] [Batch 189/347] [D loss: 0.500109] [G loss: 0.273722]\n",
      "[Epoch 18/100] [Batch 190/347] [D loss: 0.499989] [G loss: 0.261811]\n",
      "[Epoch 18/100] [Batch 191/347] [D loss: 0.499854] [G loss: 0.263166]\n",
      "[Epoch 18/100] [Batch 192/347] [D loss: 0.499914] [G loss: 0.253555]\n",
      "[Epoch 18/100] [Batch 193/347] [D loss: 0.500007] [G loss: 0.259926]\n",
      "[Epoch 18/100] [Batch 194/347] [D loss: 0.499926] [G loss: 0.257091]\n",
      "[Epoch 18/100] [Batch 195/347] [D loss: 0.499858] [G loss: 0.265612]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 18/100] [Batch 196/347] [D loss: 0.499823] [G loss: 0.263078]\n",
      "[Epoch 18/100] [Batch 197/347] [D loss: 0.499841] [G loss: 0.258151]\n",
      "[Epoch 18/100] [Batch 198/347] [D loss: 0.499882] [G loss: 0.257198]\n",
      "[Epoch 18/100] [Batch 199/347] [D loss: 0.499881] [G loss: 0.258194]\n",
      "[Epoch 18/100] [Batch 200/347] [D loss: 0.499898] [G loss: 0.252994]\n",
      "[Epoch 18/100] [Batch 201/347] [D loss: 0.499918] [G loss: 0.253036]\n",
      "[Epoch 18/100] [Batch 202/347] [D loss: 0.499834] [G loss: 0.264535]\n",
      "[Epoch 18/100] [Batch 203/347] [D loss: 0.499766] [G loss: 0.273026]\n",
      "[Epoch 18/100] [Batch 204/347] [D loss: 0.499801] [G loss: 0.269336]\n",
      "[Epoch 18/100] [Batch 205/347] [D loss: 0.499848] [G loss: 0.261330]\n",
      "[Epoch 18/100] [Batch 206/347] [D loss: 0.499939] [G loss: 0.251838]\n",
      "[Epoch 18/100] [Batch 207/347] [D loss: 0.500082] [G loss: 0.262603]\n",
      "[Epoch 18/100] [Batch 208/347] [D loss: 0.500052] [G loss: 0.263404]\n",
      "[Epoch 18/100] [Batch 209/347] [D loss: 0.499993] [G loss: 0.257722]\n",
      "[Epoch 18/100] [Batch 210/347] [D loss: 0.500098] [G loss: 0.265306]\n",
      "[Epoch 18/100] [Batch 211/347] [D loss: 0.500079] [G loss: 0.262505]\n",
      "[Epoch 18/100] [Batch 212/347] [D loss: 0.500041] [G loss: 0.261341]\n",
      "[Epoch 18/100] [Batch 213/347] [D loss: 0.500031] [G loss: 0.267073]\n",
      "[Epoch 18/100] [Batch 214/347] [D loss: 0.499882] [G loss: 0.275458]\n",
      "[Epoch 18/100] [Batch 215/347] [D loss: 0.499821] [G loss: 0.283798]\n",
      "[Epoch 18/100] [Batch 216/347] [D loss: 0.499968] [G loss: 0.266446]\n",
      "[Epoch 18/100] [Batch 217/347] [D loss: 0.500069] [G loss: 0.267164]\n",
      "[Epoch 18/100] [Batch 218/347] [D loss: 0.500156] [G loss: 0.273775]\n",
      "[Epoch 18/100] [Batch 219/347] [D loss: 0.500271] [G loss: 0.286038]\n",
      "[Epoch 18/100] [Batch 220/347] [D loss: 0.500402] [G loss: 0.301882]\n",
      "[Epoch 18/100] [Batch 221/347] [D loss: 0.500425] [G loss: 0.303251]\n",
      "[Epoch 18/100] [Batch 222/347] [D loss: 0.500386] [G loss: 0.295233]\n",
      "[Epoch 18/100] [Batch 223/347] [D loss: 0.500377] [G loss: 0.293953]\n",
      "[Epoch 18/100] [Batch 224/347] [D loss: 0.500341] [G loss: 0.289841]\n",
      "[Epoch 18/100] [Batch 225/347] [D loss: 0.500135] [G loss: 0.276172]\n",
      "[Epoch 18/100] [Batch 226/347] [D loss: 0.499817] [G loss: 0.272414]\n",
      "[Epoch 18/100] [Batch 227/347] [D loss: 0.499616] [G loss: 0.282701]\n",
      "[Epoch 18/100] [Batch 228/347] [D loss: 0.499604] [G loss: 0.284477]\n",
      "[Epoch 18/100] [Batch 229/347] [D loss: 0.499690] [G loss: 0.279551]\n",
      "[Epoch 18/100] [Batch 230/347] [D loss: 0.499738] [G loss: 0.275638]\n",
      "[Epoch 18/100] [Batch 231/347] [D loss: 0.499683] [G loss: 0.275609]\n",
      "[Epoch 18/100] [Batch 232/347] [D loss: 0.499736] [G loss: 0.271515]\n",
      "[Epoch 18/100] [Batch 233/347] [D loss: 0.499762] [G loss: 0.269078]\n",
      "[Epoch 18/100] [Batch 234/347] [D loss: 0.499758] [G loss: 0.274036]\n",
      "[Epoch 18/100] [Batch 235/347] [D loss: 0.499884] [G loss: 0.262832]\n",
      "[Epoch 18/100] [Batch 236/347] [D loss: 0.500005] [G loss: 0.263104]\n",
      "[Epoch 18/100] [Batch 237/347] [D loss: 0.500099] [G loss: 0.266497]\n",
      "[Epoch 18/100] [Batch 238/347] [D loss: 0.500097] [G loss: 0.270368]\n",
      "[Epoch 18/100] [Batch 239/347] [D loss: 0.500070] [G loss: 0.268192]\n",
      "[Epoch 18/100] [Batch 240/347] [D loss: 0.500050] [G loss: 0.264232]\n",
      "[Epoch 18/100] [Batch 241/347] [D loss: 0.500011] [G loss: 0.258308]\n",
      "[Epoch 18/100] [Batch 242/347] [D loss: 0.499982] [G loss: 0.256239]\n",
      "[Epoch 18/100] [Batch 243/347] [D loss: 0.500038] [G loss: 0.263793]\n",
      "[Epoch 18/100] [Batch 244/347] [D loss: 0.500102] [G loss: 0.272575]\n",
      "[Epoch 18/100] [Batch 245/347] [D loss: 0.500173] [G loss: 0.271129]\n",
      "[Epoch 18/100] [Batch 246/347] [D loss: 0.499982] [G loss: 0.264036]\n",
      "[Epoch 18/100] [Batch 247/347] [D loss: 0.499744] [G loss: 0.269574]\n",
      "[Epoch 18/100] [Batch 248/347] [D loss: 0.499653] [G loss: 0.275148]\n",
      "[Epoch 18/100] [Batch 249/347] [D loss: 0.499602] [G loss: 0.280875]\n",
      "[Epoch 18/100] [Batch 250/347] [D loss: 0.499770] [G loss: 0.272201]\n",
      "[Epoch 18/100] [Batch 251/347] [D loss: 0.499993] [G loss: 0.264437]\n",
      "[Epoch 18/100] [Batch 252/347] [D loss: 0.500076] [G loss: 0.267677]\n",
      "[Epoch 18/100] [Batch 253/347] [D loss: 0.500087] [G loss: 0.268251]\n",
      "[Epoch 18/100] [Batch 254/347] [D loss: 0.500082] [G loss: 0.266564]\n",
      "[Epoch 18/100] [Batch 255/347] [D loss: 0.500024] [G loss: 0.265167]\n",
      "[Epoch 18/100] [Batch 256/347] [D loss: 0.500072] [G loss: 0.270331]\n",
      "[Epoch 18/100] [Batch 257/347] [D loss: 0.500170] [G loss: 0.272146]\n",
      "[Epoch 18/100] [Batch 258/347] [D loss: 0.500058] [G loss: 0.266994]\n",
      "[Epoch 18/100] [Batch 259/347] [D loss: 0.499815] [G loss: 0.271617]\n",
      "[Epoch 18/100] [Batch 260/347] [D loss: 0.499699] [G loss: 0.285950]\n",
      "[Epoch 18/100] [Batch 261/347] [D loss: 0.499790] [G loss: 0.278337]\n",
      "[Epoch 18/100] [Batch 262/347] [D loss: 0.499859] [G loss: 0.263128]\n",
      "[Epoch 18/100] [Batch 263/347] [D loss: 0.499853] [G loss: 0.263986]\n",
      "[Epoch 18/100] [Batch 264/347] [D loss: 0.499770] [G loss: 0.278429]\n",
      "[Epoch 18/100] [Batch 265/347] [D loss: 0.499720] [G loss: 0.283661]\n",
      "[Epoch 18/100] [Batch 266/347] [D loss: 0.499748] [G loss: 0.276519]\n",
      "[Epoch 18/100] [Batch 267/347] [D loss: 0.499789] [G loss: 0.269719]\n",
      "[Epoch 18/100] [Batch 268/347] [D loss: 0.499769] [G loss: 0.276585]\n",
      "[Epoch 18/100] [Batch 269/347] [D loss: 0.499715] [G loss: 0.287673]\n",
      "[Epoch 18/100] [Batch 270/347] [D loss: 0.499720] [G loss: 0.284233]\n",
      "[Epoch 18/100] [Batch 271/347] [D loss: 0.499781] [G loss: 0.272412]\n",
      "[Epoch 18/100] [Batch 272/347] [D loss: 0.499852] [G loss: 0.263814]\n",
      "[Epoch 18/100] [Batch 273/347] [D loss: 0.499822] [G loss: 0.275664]\n",
      "[Epoch 18/100] [Batch 274/347] [D loss: 0.499648] [G loss: 0.309486]\n",
      "[Epoch 18/100] [Batch 275/347] [D loss: 0.499656] [G loss: 0.306429]\n",
      "[Epoch 18/100] [Batch 276/347] [D loss: 0.499807] [G loss: 0.274065]\n",
      "[Epoch 18/100] [Batch 277/347] [D loss: 0.499888] [G loss: 0.259405]\n",
      "[Epoch 18/100] [Batch 278/347] [D loss: 0.499959] [G loss: 0.253378]\n",
      "[Epoch 18/100] [Batch 279/347] [D loss: 0.499965] [G loss: 0.260243]\n",
      "[Epoch 18/100] [Batch 280/347] [D loss: 0.499943] [G loss: 0.263620]\n",
      "[Epoch 18/100] [Batch 281/347] [D loss: 0.499946] [G loss: 0.261814]\n",
      "[Epoch 18/100] [Batch 282/347] [D loss: 0.499941] [G loss: 0.259623]\n",
      "[Epoch 18/100] [Batch 283/347] [D loss: 0.499896] [G loss: 0.260802]\n",
      "[Epoch 18/100] [Batch 284/347] [D loss: 0.499931] [G loss: 0.262379]\n",
      "[Epoch 18/100] [Batch 285/347] [D loss: 0.499957] [G loss: 0.258337]\n",
      "[Epoch 18/100] [Batch 286/347] [D loss: 0.499910] [G loss: 0.251268]\n",
      "[Epoch 18/100] [Batch 287/347] [D loss: 0.499900] [G loss: 0.254643]\n",
      "[Epoch 18/100] [Batch 288/347] [D loss: 0.499657] [G loss: 0.281438]\n",
      "[Epoch 18/100] [Batch 289/347] [D loss: 0.499619] [G loss: 0.285869]\n",
      "[Epoch 18/100] [Batch 290/347] [D loss: 0.499798] [G loss: 0.263274]\n",
      "[Epoch 18/100] [Batch 291/347] [D loss: 0.499757] [G loss: 0.265961]\n",
      "[Epoch 18/100] [Batch 292/347] [D loss: 0.499846] [G loss: 0.257396]\n",
      "[Epoch 18/100] [Batch 293/347] [D loss: 0.500092] [G loss: 0.268922]\n",
      "[Epoch 18/100] [Batch 294/347] [D loss: 0.500191] [G loss: 0.278604]\n",
      "[Epoch 18/100] [Batch 295/347] [D loss: 0.500100] [G loss: 0.276127]\n",
      "[Epoch 18/100] [Batch 296/347] [D loss: 0.500127] [G loss: 0.272040]\n",
      "[Epoch 18/100] [Batch 297/347] [D loss: 0.500200] [G loss: 0.283229]\n",
      "[Epoch 18/100] [Batch 298/347] [D loss: 0.500144] [G loss: 0.278053]\n",
      "[Epoch 18/100] [Batch 299/347] [D loss: 0.500156] [G loss: 0.276755]\n",
      "[Epoch 18/100] [Batch 300/347] [D loss: 0.500116] [G loss: 0.272126]\n",
      "[Epoch 18/100] [Batch 301/347] [D loss: 0.500139] [G loss: 0.273718]\n",
      "[Epoch 18/100] [Batch 302/347] [D loss: 0.500196] [G loss: 0.278888]\n",
      "[Epoch 18/100] [Batch 303/347] [D loss: 0.499968] [G loss: 0.263236]\n",
      "[Epoch 18/100] [Batch 304/347] [D loss: 0.499743] [G loss: 0.266270]\n",
      "[Epoch 18/100] [Batch 305/347] [D loss: 0.499687] [G loss: 0.278975]\n",
      "[Epoch 18/100] [Batch 306/347] [D loss: 0.499675] [G loss: 0.270924]\n",
      "[Epoch 18/100] [Batch 307/347] [D loss: 0.499649] [G loss: 0.283382]\n",
      "[Epoch 18/100] [Batch 308/347] [D loss: 0.499647] [G loss: 0.279421]\n",
      "[Epoch 18/100] [Batch 309/347] [D loss: 0.499842] [G loss: 0.259003]\n",
      "[Epoch 18/100] [Batch 310/347] [D loss: 0.500019] [G loss: 0.275553]\n",
      "[Epoch 18/100] [Batch 311/347] [D loss: 0.500026] [G loss: 0.278323]\n",
      "[Epoch 18/100] [Batch 312/347] [D loss: 0.500015] [G loss: 0.277920]\n",
      "[Epoch 18/100] [Batch 313/347] [D loss: 0.500027] [G loss: 0.277030]\n",
      "[Epoch 18/100] [Batch 314/347] [D loss: 0.500032] [G loss: 0.270540]\n",
      "[Epoch 18/100] [Batch 315/347] [D loss: 0.500029] [G loss: 0.261190]\n",
      "[Epoch 18/100] [Batch 316/347] [D loss: 0.499828] [G loss: 0.259023]\n",
      "[Epoch 18/100] [Batch 317/347] [D loss: 0.499646] [G loss: 0.277552]\n",
      "[Epoch 18/100] [Batch 318/347] [D loss: 0.499861] [G loss: 0.255219]\n",
      "[Epoch 18/100] [Batch 319/347] [D loss: 0.500144] [G loss: 0.283352]\n",
      "[Epoch 18/100] [Batch 320/347] [D loss: 0.500240] [G loss: 0.297005]\n",
      "[Epoch 18/100] [Batch 321/347] [D loss: 0.500175] [G loss: 0.286553]\n",
      "[Epoch 18/100] [Batch 322/347] [D loss: 0.500080] [G loss: 0.273473]\n",
      "[Epoch 18/100] [Batch 323/347] [D loss: 0.500080] [G loss: 0.272619]\n",
      "[Epoch 18/100] [Batch 324/347] [D loss: 0.500117] [G loss: 0.275621]\n",
      "[Epoch 18/100] [Batch 325/347] [D loss: 0.500041] [G loss: 0.264874]\n",
      "[Epoch 18/100] [Batch 326/347] [D loss: 0.499936] [G loss: 0.254532]\n",
      "[Epoch 18/100] [Batch 327/347] [D loss: 0.499935] [G loss: 0.252715]\n",
      "[Epoch 18/100] [Batch 328/347] [D loss: 0.499897] [G loss: 0.251013]\n",
      "[Epoch 18/100] [Batch 329/347] [D loss: 0.499721] [G loss: 0.273523]\n",
      "[Epoch 18/100] [Batch 330/347] [D loss: 0.499572] [G loss: 0.288876]\n",
      "[Epoch 18/100] [Batch 331/347] [D loss: 0.499726] [G loss: 0.270510]\n",
      "[Epoch 18/100] [Batch 332/347] [D loss: 0.499973] [G loss: 0.265394]\n",
      "[Epoch 18/100] [Batch 333/347] [D loss: 0.500042] [G loss: 0.276900]\n",
      "[Epoch 18/100] [Batch 334/347] [D loss: 0.500090] [G loss: 0.278430]\n",
      "[Epoch 18/100] [Batch 335/347] [D loss: 0.500037] [G loss: 0.266557]\n",
      "[Epoch 18/100] [Batch 336/347] [D loss: 0.499928] [G loss: 0.252680]\n",
      "[Epoch 18/100] [Batch 337/347] [D loss: 0.499944] [G loss: 0.258269]\n",
      "[Epoch 18/100] [Batch 338/347] [D loss: 0.500034] [G loss: 0.272958]\n",
      "[Epoch 18/100] [Batch 339/347] [D loss: 0.500076] [G loss: 0.278407]\n",
      "[Epoch 18/100] [Batch 340/347] [D loss: 0.500070] [G loss: 0.278860]\n",
      "[Epoch 18/100] [Batch 341/347] [D loss: 0.500057] [G loss: 0.274142]\n",
      "[Epoch 18/100] [Batch 342/347] [D loss: 0.499996] [G loss: 0.266583]\n",
      "[Epoch 18/100] [Batch 343/347] [D loss: 0.499989] [G loss: 0.271324]\n",
      "[Epoch 18/100] [Batch 344/347] [D loss: 0.499905] [G loss: 0.262719]\n",
      "[Epoch 18/100] [Batch 345/347] [D loss: 0.499669] [G loss: 0.272847]\n",
      "[Epoch 18/100] [Batch 346/347] [D loss: 0.499543] [G loss: 0.291202]\n",
      "[Epoch 18/100] [Batch 347/347] [D loss: 0.499520] [G loss: 0.297294]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 19/100] [Batch 1/347] [D loss: 0.499826] [G loss: 0.263529]\n",
      "[Epoch 19/100] [Batch 2/347] [D loss: 0.499817] [G loss: 0.268677]\n",
      "[Epoch 19/100] [Batch 3/347] [D loss: 0.499878] [G loss: 0.268520]\n",
      "[Epoch 19/100] [Batch 4/347] [D loss: 0.499875] [G loss: 0.269744]\n",
      "[Epoch 19/100] [Batch 5/347] [D loss: 0.499876] [G loss: 0.268986]\n",
      "[Epoch 19/100] [Batch 6/347] [D loss: 0.499889] [G loss: 0.269319]\n",
      "[Epoch 19/100] [Batch 7/347] [D loss: 0.499859] [G loss: 0.269147]\n",
      "[Epoch 19/100] [Batch 8/347] [D loss: 0.499865] [G loss: 0.264444]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 19/100] [Batch 9/347] [D loss: 0.499798] [G loss: 0.263407]\n",
      "[Epoch 19/100] [Batch 10/347] [D loss: 0.499796] [G loss: 0.265022]\n",
      "[Epoch 19/100] [Batch 11/347] [D loss: 0.499887] [G loss: 0.264802]\n",
      "[Epoch 19/100] [Batch 12/347] [D loss: 0.499919] [G loss: 0.265316]\n",
      "[Epoch 19/100] [Batch 13/347] [D loss: 0.499968] [G loss: 0.268786]\n",
      "[Epoch 19/100] [Batch 14/347] [D loss: 0.500010] [G loss: 0.271115]\n",
      "[Epoch 19/100] [Batch 15/347] [D loss: 0.499992] [G loss: 0.267265]\n",
      "[Epoch 19/100] [Batch 16/347] [D loss: 0.499973] [G loss: 0.263174]\n",
      "[Epoch 19/100] [Batch 17/347] [D loss: 0.499926] [G loss: 0.251243]\n",
      "[Epoch 19/100] [Batch 18/347] [D loss: 0.499878] [G loss: 0.255701]\n",
      "[Epoch 19/100] [Batch 19/347] [D loss: 0.499961] [G loss: 0.256533]\n",
      "[Epoch 19/100] [Batch 20/347] [D loss: 0.500035] [G loss: 0.269624]\n",
      "[Epoch 19/100] [Batch 21/347] [D loss: 0.499992] [G loss: 0.265940]\n",
      "[Epoch 19/100] [Batch 22/347] [D loss: 0.499956] [G loss: 0.260971]\n",
      "[Epoch 19/100] [Batch 23/347] [D loss: 0.499926] [G loss: 0.254690]\n",
      "[Epoch 19/100] [Batch 24/347] [D loss: 0.499936] [G loss: 0.253923]\n",
      "[Epoch 19/100] [Batch 25/347] [D loss: 0.499925] [G loss: 0.253358]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 19/100] [Batch 26/347] [D loss: 0.499796] [G loss: 0.261556]\n",
      "[Epoch 19/100] [Batch 27/347] [D loss: 0.499830] [G loss: 0.267359]\n",
      "[Epoch 19/100] [Batch 28/347] [D loss: 0.499966] [G loss: 0.266036]\n",
      "[Epoch 19/100] [Batch 29/347] [D loss: 0.500042] [G loss: 0.264132]\n",
      "[Epoch 19/100] [Batch 30/347] [D loss: 0.500104] [G loss: 0.271028]\n",
      "[Epoch 19/100] [Batch 31/347] [D loss: 0.500144] [G loss: 0.273560]\n",
      "[Epoch 19/100] [Batch 32/347] [D loss: 0.500101] [G loss: 0.266876]\n",
      "[Epoch 19/100] [Batch 33/347] [D loss: 0.500035] [G loss: 0.262793]\n",
      "[Epoch 19/100] [Batch 34/347] [D loss: 0.500028] [G loss: 0.263848]\n",
      "[Epoch 19/100] [Batch 35/347] [D loss: 0.500021] [G loss: 0.262685]\n",
      "[Epoch 19/100] [Batch 36/347] [D loss: 0.499950] [G loss: 0.253576]\n",
      "[Epoch 19/100] [Batch 37/347] [D loss: 0.499736] [G loss: 0.273169]\n",
      "[Epoch 19/100] [Batch 38/347] [D loss: 0.499573] [G loss: 0.288327]\n",
      "[Epoch 19/100] [Batch 39/347] [D loss: 0.499611] [G loss: 0.278691]\n",
      "[Epoch 19/100] [Batch 40/347] [D loss: 0.499630] [G loss: 0.279748]\n",
      "[Epoch 19/100] [Batch 41/347] [D loss: 0.499601] [G loss: 0.280962]\n",
      "[Epoch 19/100] [Batch 42/347] [D loss: 0.499653] [G loss: 0.273874]\n",
      "[Epoch 19/100] [Batch 43/347] [D loss: 0.499837] [G loss: 0.256945]\n",
      "[Epoch 19/100] [Batch 44/347] [D loss: 0.500013] [G loss: 0.261531]\n",
      "[Epoch 19/100] [Batch 45/347] [D loss: 0.500148] [G loss: 0.278731]\n",
      "[Epoch 19/100] [Batch 46/347] [D loss: 0.500126] [G loss: 0.273342]\n",
      "[Epoch 19/100] [Batch 47/347] [D loss: 0.499877] [G loss: 0.255064]\n",
      "[Epoch 19/100] [Batch 48/347] [D loss: 0.499622] [G loss: 0.287420]\n",
      "[Epoch 19/100] [Batch 49/347] [D loss: 0.499532] [G loss: 0.295939]\n",
      "[Epoch 19/100] [Batch 50/347] [D loss: 0.499484] [G loss: 0.311475]\n",
      "[Epoch 19/100] [Batch 51/347] [D loss: 0.499671] [G loss: 0.295978]\n",
      "[Epoch 19/100] [Batch 52/347] [D loss: 0.499953] [G loss: 0.259822]\n",
      "[Epoch 19/100] [Batch 53/347] [D loss: 0.499897] [G loss: 0.258607]\n",
      "[Epoch 19/100] [Batch 54/347] [D loss: 0.499477] [G loss: 0.311272]\n",
      "[Epoch 19/100] [Batch 55/347] [D loss: 0.499157] [G loss: 0.333772]\n",
      "[Epoch 19/100] [Batch 56/347] [D loss: 0.499232] [G loss: 0.320696]\n",
      "[Epoch 19/100] [Batch 57/347] [D loss: 0.499642] [G loss: 0.286236]\n",
      "[Epoch 19/100] [Batch 58/347] [D loss: 0.499936] [G loss: 0.258487]\n",
      "[Epoch 19/100] [Batch 59/347] [D loss: 0.499843] [G loss: 0.269082]\n",
      "[Epoch 19/100] [Batch 60/347] [D loss: 0.499701] [G loss: 0.288008]\n",
      "[Epoch 19/100] [Batch 61/347] [D loss: 0.499605] [G loss: 0.300744]\n",
      "[Epoch 19/100] [Batch 62/347] [D loss: 0.499364] [G loss: 0.324883]\n",
      "[Epoch 19/100] [Batch 63/347] [D loss: 0.499194] [G loss: 0.327011]\n",
      "[Epoch 19/100] [Batch 64/347] [D loss: 0.499570] [G loss: 0.290093]\n",
      "[Epoch 19/100] [Batch 65/347] [D loss: 0.500059] [G loss: 0.262553]\n",
      "[Epoch 19/100] [Batch 66/347] [D loss: 0.500016] [G loss: 0.264898]\n",
      "[Epoch 19/100] [Batch 67/347] [D loss: 0.499791] [G loss: 0.274243]\n",
      "[Epoch 19/100] [Batch 68/347] [D loss: 0.499642] [G loss: 0.292519]\n",
      "[Epoch 19/100] [Batch 69/347] [D loss: 0.499387] [G loss: 0.311586]\n",
      "[Epoch 19/100] [Batch 70/347] [D loss: 0.499328] [G loss: 0.310432]\n",
      "[Epoch 19/100] [Batch 71/347] [D loss: 0.499394] [G loss: 0.312799]\n",
      "[Epoch 19/100] [Batch 72/347] [D loss: 0.499340] [G loss: 0.315326]\n",
      "[Epoch 19/100] [Batch 73/347] [D loss: 0.499560] [G loss: 0.290639]\n",
      "[Epoch 19/100] [Batch 74/347] [D loss: 0.499793] [G loss: 0.276711]\n",
      "[Epoch 19/100] [Batch 75/347] [D loss: 0.499538] [G loss: 0.306783]\n",
      "[Epoch 19/100] [Batch 76/347] [D loss: 0.499390] [G loss: 0.308941]\n",
      "[Epoch 19/100] [Batch 77/347] [D loss: 0.499711] [G loss: 0.274716]\n",
      "[Epoch 19/100] [Batch 78/347] [D loss: 0.500091] [G loss: 0.268968]\n",
      "[Epoch 19/100] [Batch 79/347] [D loss: 0.500170] [G loss: 0.270578]\n",
      "[Epoch 19/100] [Batch 80/347] [D loss: 0.500117] [G loss: 0.267696]\n",
      "[Epoch 19/100] [Batch 81/347] [D loss: 0.500195] [G loss: 0.272614]\n",
      "[Epoch 19/100] [Batch 82/347] [D loss: 0.500184] [G loss: 0.277805]\n",
      "[Epoch 19/100] [Batch 83/347] [D loss: 0.500135] [G loss: 0.270173]\n",
      "[Epoch 19/100] [Batch 84/347] [D loss: 0.500154] [G loss: 0.276496]\n",
      "[Epoch 19/100] [Batch 85/347] [D loss: 0.500133] [G loss: 0.277359]\n",
      "[Epoch 19/100] [Batch 86/347] [D loss: 0.500093] [G loss: 0.271862]\n",
      "[Epoch 19/100] [Batch 87/347] [D loss: 0.500062] [G loss: 0.269842]\n",
      "[Epoch 19/100] [Batch 88/347] [D loss: 0.500076] [G loss: 0.273319]\n",
      "[Epoch 19/100] [Batch 89/347] [D loss: 0.500091] [G loss: 0.276840]\n",
      "[Epoch 19/100] [Batch 90/347] [D loss: 0.500060] [G loss: 0.273178]\n",
      "[Epoch 19/100] [Batch 91/347] [D loss: 0.500041] [G loss: 0.271839]\n",
      "[Epoch 19/100] [Batch 92/347] [D loss: 0.500045] [G loss: 0.273402]\n",
      "[Epoch 19/100] [Batch 93/347] [D loss: 0.500023] [G loss: 0.271500]\n",
      "[Epoch 19/100] [Batch 94/347] [D loss: 0.499990] [G loss: 0.268040]\n",
      "[Epoch 19/100] [Batch 95/347] [D loss: 0.499998] [G loss: 0.268671]\n",
      "[Epoch 19/100] [Batch 96/347] [D loss: 0.499973] [G loss: 0.264006]\n",
      "[Epoch 19/100] [Batch 97/347] [D loss: 0.499922] [G loss: 0.258992]\n",
      "[Epoch 19/100] [Batch 98/347] [D loss: 0.499939] [G loss: 0.263995]\n",
      "[Epoch 19/100] [Batch 99/347] [D loss: 0.499970] [G loss: 0.267802]\n",
      "[Epoch 19/100] [Batch 100/347] [D loss: 0.499946] [G loss: 0.264171]\n",
      "[Epoch 19/100] [Batch 101/347] [D loss: 0.499899] [G loss: 0.261841]\n",
      "[Epoch 19/100] [Batch 102/347] [D loss: 0.499911] [G loss: 0.262507]\n",
      "[Epoch 19/100] [Batch 103/347] [D loss: 0.499923] [G loss: 0.262020]\n",
      "[Epoch 19/100] [Batch 104/347] [D loss: 0.499852] [G loss: 0.263968]\n",
      "[Epoch 19/100] [Batch 105/347] [D loss: 0.499839] [G loss: 0.265562]\n",
      "[Epoch 19/100] [Batch 106/347] [D loss: 0.499847] [G loss: 0.264524]\n",
      "[Epoch 19/100] [Batch 107/347] [D loss: 0.499817] [G loss: 0.257961]\n",
      "[Epoch 19/100] [Batch 108/347] [D loss: 0.499772] [G loss: 0.274848]\n",
      "[Epoch 19/100] [Batch 109/347] [D loss: 0.499862] [G loss: 0.267867]\n",
      "[Epoch 19/100] [Batch 110/347] [D loss: 0.499971] [G loss: 0.255967]\n",
      "[Epoch 19/100] [Batch 111/347] [D loss: 0.499887] [G loss: 0.261875]\n",
      "[Epoch 19/100] [Batch 112/347] [D loss: 0.499911] [G loss: 0.265629]\n",
      "[Epoch 19/100] [Batch 113/347] [D loss: 0.500109] [G loss: 0.271273]\n",
      "[Epoch 19/100] [Batch 114/347] [D loss: 0.500243] [G loss: 0.291976]\n",
      "[Epoch 19/100] [Batch 115/347] [D loss: 0.500262] [G loss: 0.293191]\n",
      "[Epoch 19/100] [Batch 116/347] [D loss: 0.500233] [G loss: 0.287434]\n",
      "[Epoch 19/100] [Batch 117/347] [D loss: 0.500057] [G loss: 0.260809]\n",
      "[Epoch 19/100] [Batch 118/347] [D loss: 0.499802] [G loss: 0.265395]\n",
      "[Epoch 19/100] [Batch 119/347] [D loss: 0.499748] [G loss: 0.267502]\n",
      "[Epoch 19/100] [Batch 120/347] [D loss: 0.499785] [G loss: 0.266327]\n",
      "[Epoch 19/100] [Batch 121/347] [D loss: 0.499796] [G loss: 0.264538]\n",
      "[Epoch 19/100] [Batch 122/347] [D loss: 0.499886] [G loss: 0.251547]\n",
      "[Epoch 19/100] [Batch 123/347] [D loss: 0.499913] [G loss: 0.251542]\n",
      "[Epoch 19/100] [Batch 124/347] [D loss: 0.499871] [G loss: 0.252448]\n",
      "[Epoch 19/100] [Batch 125/347] [D loss: 0.499973] [G loss: 0.259020]\n",
      "[Epoch 19/100] [Batch 126/347] [D loss: 0.500088] [G loss: 0.271533]\n",
      "[Epoch 19/100] [Batch 127/347] [D loss: 0.500116] [G loss: 0.272831]\n",
      "[Epoch 19/100] [Batch 128/347] [D loss: 0.500061] [G loss: 0.267238]\n",
      "[Epoch 19/100] [Batch 129/347] [D loss: 0.500048] [G loss: 0.262303]\n",
      "[Epoch 19/100] [Batch 130/347] [D loss: 0.500028] [G loss: 0.265669]\n",
      "[Epoch 19/100] [Batch 131/347] [D loss: 0.499891] [G loss: 0.263597]\n",
      "[Epoch 19/100] [Batch 132/347] [D loss: 0.499701] [G loss: 0.288292]\n",
      "[Epoch 19/100] [Batch 133/347] [D loss: 0.499640] [G loss: 0.295044]\n",
      "[Epoch 19/100] [Batch 134/347] [D loss: 0.499519] [G loss: 0.309930]\n",
      "[Epoch 19/100] [Batch 135/347] [D loss: 0.499497] [G loss: 0.318930]\n",
      "[Epoch 19/100] [Batch 136/347] [D loss: 0.499820] [G loss: 0.276945]\n",
      "[Epoch 19/100] [Batch 137/347] [D loss: 0.499993] [G loss: 0.265721]\n",
      "[Epoch 19/100] [Batch 138/347] [D loss: 0.499718] [G loss: 0.282133]\n",
      "[Epoch 19/100] [Batch 139/347] [D loss: 0.499474] [G loss: 0.306187]\n",
      "[Epoch 19/100] [Batch 140/347] [D loss: 0.499382] [G loss: 0.317623]\n",
      "[Epoch 19/100] [Batch 141/347] [D loss: 0.499298] [G loss: 0.324463]\n",
      "[Epoch 19/100] [Batch 142/347] [D loss: 0.499246] [G loss: 0.332035]\n",
      "[Epoch 19/100] [Batch 143/347] [D loss: 0.499042] [G loss: 0.353580]\n",
      "[Epoch 19/100] [Batch 144/347] [D loss: 0.498965] [G loss: 0.355711]\n",
      "[Epoch 19/100] [Batch 145/347] [D loss: 0.499017] [G loss: 0.341258]\n",
      "[Epoch 19/100] [Batch 146/347] [D loss: 0.499098] [G loss: 0.324418]\n",
      "[Epoch 19/100] [Batch 147/347] [D loss: 0.499374] [G loss: 0.296270]\n",
      "[Epoch 19/100] [Batch 148/347] [D loss: 0.499524] [G loss: 0.283924]\n",
      "[Epoch 19/100] [Batch 149/347] [D loss: 0.499410] [G loss: 0.297345]\n",
      "[Epoch 19/100] [Batch 150/347] [D loss: 0.499412] [G loss: 0.297949]\n",
      "[Epoch 19/100] [Batch 151/347] [D loss: 0.499585] [G loss: 0.287213]\n",
      "[Epoch 19/100] [Batch 152/347] [D loss: 0.499535] [G loss: 0.298503]\n",
      "[Epoch 19/100] [Batch 153/347] [D loss: 0.499312] [G loss: 0.319419]\n",
      "[Epoch 19/100] [Batch 154/347] [D loss: 0.499176] [G loss: 0.323703]\n",
      "[Epoch 19/100] [Batch 155/347] [D loss: 0.499277] [G loss: 0.311017]\n",
      "[Epoch 19/100] [Batch 156/347] [D loss: 0.499471] [G loss: 0.294635]\n",
      "[Epoch 19/100] [Batch 157/347] [D loss: 0.499531] [G loss: 0.301098]\n",
      "[Epoch 19/100] [Batch 158/347] [D loss: 0.499269] [G loss: 0.325031]\n",
      "[Epoch 19/100] [Batch 159/347] [D loss: 0.499192] [G loss: 0.322849]\n",
      "[Epoch 19/100] [Batch 160/347] [D loss: 0.499483] [G loss: 0.303141]\n",
      "[Epoch 19/100] [Batch 161/347] [D loss: 0.499652] [G loss: 0.294995]\n",
      "[Epoch 19/100] [Batch 162/347] [D loss: 0.499586] [G loss: 0.301137]\n",
      "[Epoch 19/100] [Batch 163/347] [D loss: 0.499385] [G loss: 0.320158]\n",
      "[Epoch 19/100] [Batch 164/347] [D loss: 0.499189] [G loss: 0.335780]\n",
      "[Epoch 19/100] [Batch 165/347] [D loss: 0.499202] [G loss: 0.327213]\n",
      "[Epoch 19/100] [Batch 166/347] [D loss: 0.499558] [G loss: 0.289137]\n",
      "[Epoch 19/100] [Batch 167/347] [D loss: 0.499962] [G loss: 0.267601]\n",
      "[Epoch 19/100] [Batch 168/347] [D loss: 0.500085] [G loss: 0.278214]\n",
      "[Epoch 19/100] [Batch 169/347] [D loss: 0.500148] [G loss: 0.276908]\n",
      "[Epoch 19/100] [Batch 170/347] [D loss: 0.500202] [G loss: 0.272931]\n",
      "[Epoch 19/100] [Batch 171/347] [D loss: 0.500307] [G loss: 0.281389]\n",
      "[Epoch 19/100] [Batch 172/347] [D loss: 0.500350] [G loss: 0.286286]\n",
      "[Epoch 19/100] [Batch 173/347] [D loss: 0.500235] [G loss: 0.275116]\n",
      "[Epoch 19/100] [Batch 174/347] [D loss: 0.500193] [G loss: 0.272675]\n",
      "[Epoch 19/100] [Batch 175/347] [D loss: 0.500256] [G loss: 0.282683]\n",
      "[Epoch 19/100] [Batch 176/347] [D loss: 0.500378] [G loss: 0.296193]\n",
      "[Epoch 19/100] [Batch 177/347] [D loss: 0.500381] [G loss: 0.297228]\n",
      "[Epoch 19/100] [Batch 178/347] [D loss: 0.500324] [G loss: 0.291381]\n",
      "[Epoch 19/100] [Batch 179/347] [D loss: 0.500258] [G loss: 0.284808]\n",
      "[Epoch 19/100] [Batch 180/347] [D loss: 0.500203] [G loss: 0.278523]\n",
      "[Epoch 19/100] [Batch 181/347] [D loss: 0.500199] [G loss: 0.279092]\n",
      "[Epoch 19/100] [Batch 182/347] [D loss: 0.500147] [G loss: 0.277095]\n",
      "[Epoch 19/100] [Batch 183/347] [D loss: 0.500182] [G loss: 0.281270]\n",
      "[Epoch 19/100] [Batch 184/347] [D loss: 0.500211] [G loss: 0.285241]\n",
      "[Epoch 19/100] [Batch 185/347] [D loss: 0.500204] [G loss: 0.283839]\n",
      "[Epoch 19/100] [Batch 186/347] [D loss: 0.500210] [G loss: 0.283684]\n",
      "[Epoch 19/100] [Batch 187/347] [D loss: 0.500171] [G loss: 0.278459]\n",
      "[Epoch 19/100] [Batch 188/347] [D loss: 0.500128] [G loss: 0.275205]\n",
      "[Epoch 19/100] [Batch 189/347] [D loss: 0.500119] [G loss: 0.274379]\n",
      "[Epoch 19/100] [Batch 190/347] [D loss: 0.499977] [G loss: 0.262531]\n",
      "[Epoch 19/100] [Batch 191/347] [D loss: 0.499816] [G loss: 0.262230]\n",
      "[Epoch 19/100] [Batch 192/347] [D loss: 0.499888] [G loss: 0.252564]\n",
      "[Epoch 19/100] [Batch 193/347] [D loss: 0.500000] [G loss: 0.260679]\n",
      "[Epoch 19/100] [Batch 194/347] [D loss: 0.499901] [G loss: 0.256547]\n",
      "[Epoch 19/100] [Batch 195/347] [D loss: 0.499819] [G loss: 0.264876]\n",
      "[Epoch 19/100] [Batch 196/347] [D loss: 0.499772] [G loss: 0.262672]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 19/100] [Batch 197/347] [D loss: 0.499786] [G loss: 0.258019]\n",
      "[Epoch 19/100] [Batch 198/347] [D loss: 0.499832] [G loss: 0.257642]\n",
      "[Epoch 19/100] [Batch 199/347] [D loss: 0.499829] [G loss: 0.258807]\n",
      "[Epoch 19/100] [Batch 200/347] [D loss: 0.499857] [G loss: 0.253768]\n",
      "[Epoch 19/100] [Batch 201/347] [D loss: 0.499872] [G loss: 0.253752]\n",
      "[Epoch 19/100] [Batch 202/347] [D loss: 0.499766] [G loss: 0.265424]\n",
      "[Epoch 19/100] [Batch 203/347] [D loss: 0.499684] [G loss: 0.274102]\n",
      "[Epoch 19/100] [Batch 204/347] [D loss: 0.499722] [G loss: 0.270552]\n",
      "[Epoch 19/100] [Batch 205/347] [D loss: 0.499778] [G loss: 0.262658]\n",
      "[Epoch 19/100] [Batch 206/347] [D loss: 0.499881] [G loss: 0.250443]\n",
      "[Epoch 19/100] [Batch 207/347] [D loss: 0.500057] [G loss: 0.261307]\n",
      "[Epoch 19/100] [Batch 208/347] [D loss: 0.500024] [G loss: 0.262221]\n",
      "[Epoch 19/100] [Batch 209/347] [D loss: 0.499962] [G loss: 0.256660]\n",
      "[Epoch 19/100] [Batch 210/347] [D loss: 0.500087] [G loss: 0.264568]\n",
      "[Epoch 19/100] [Batch 211/347] [D loss: 0.500063] [G loss: 0.261932]\n",
      "[Epoch 19/100] [Batch 212/347] [D loss: 0.500022] [G loss: 0.260936]\n",
      "[Epoch 19/100] [Batch 213/347] [D loss: 0.500004] [G loss: 0.266794]\n",
      "[Epoch 19/100] [Batch 214/347] [D loss: 0.499818] [G loss: 0.275680]\n",
      "[Epoch 19/100] [Batch 215/347] [D loss: 0.499744] [G loss: 0.283931]\n",
      "[Epoch 19/100] [Batch 216/347] [D loss: 0.499937] [G loss: 0.266517]\n",
      "[Epoch 19/100] [Batch 217/347] [D loss: 0.500060] [G loss: 0.267361]\n",
      "[Epoch 19/100] [Batch 218/347] [D loss: 0.500174] [G loss: 0.273769]\n",
      "[Epoch 19/100] [Batch 219/347] [D loss: 0.500313] [G loss: 0.286104]\n",
      "[Epoch 19/100] [Batch 220/347] [D loss: 0.500475] [G loss: 0.301987]\n",
      "[Epoch 19/100] [Batch 221/347] [D loss: 0.500498] [G loss: 0.303421]\n",
      "[Epoch 19/100] [Batch 222/347] [D loss: 0.500448] [G loss: 0.295467]\n",
      "[Epoch 19/100] [Batch 223/347] [D loss: 0.500440] [G loss: 0.294187]\n",
      "[Epoch 19/100] [Batch 224/347] [D loss: 0.500401] [G loss: 0.290185]\n",
      "[Epoch 19/100] [Batch 225/347] [D loss: 0.500147] [G loss: 0.276994]\n",
      "[Epoch 19/100] [Batch 226/347] [D loss: 0.499760] [G loss: 0.271962]\n",
      "[Epoch 19/100] [Batch 227/347] [D loss: 0.499521] [G loss: 0.282249]\n",
      "[Epoch 19/100] [Batch 228/347] [D loss: 0.499510] [G loss: 0.283540]\n",
      "[Epoch 19/100] [Batch 229/347] [D loss: 0.499618] [G loss: 0.278530]\n",
      "[Epoch 19/100] [Batch 230/347] [D loss: 0.499676] [G loss: 0.274563]\n",
      "[Epoch 19/100] [Batch 231/347] [D loss: 0.499608] [G loss: 0.274488]\n",
      "[Epoch 19/100] [Batch 232/347] [D loss: 0.499672] [G loss: 0.270410]\n",
      "[Epoch 19/100] [Batch 233/347] [D loss: 0.499704] [G loss: 0.268348]\n",
      "[Epoch 19/100] [Batch 234/347] [D loss: 0.499695] [G loss: 0.273316]\n",
      "[Epoch 19/100] [Batch 235/347] [D loss: 0.499849] [G loss: 0.262048]\n",
      "[Epoch 19/100] [Batch 236/347] [D loss: 0.500002] [G loss: 0.264301]\n",
      "[Epoch 19/100] [Batch 237/347] [D loss: 0.500113] [G loss: 0.267260]\n",
      "[Epoch 19/100] [Batch 238/347] [D loss: 0.500110] [G loss: 0.271117]\n",
      "[Epoch 19/100] [Batch 239/347] [D loss: 0.500080] [G loss: 0.268940]\n",
      "[Epoch 19/100] [Batch 240/347] [D loss: 0.500058] [G loss: 0.264983]\n",
      "[Epoch 19/100] [Batch 241/347] [D loss: 0.500006] [G loss: 0.259053]\n",
      "[Epoch 19/100] [Batch 242/347] [D loss: 0.499970] [G loss: 0.257009]\n",
      "[Epoch 19/100] [Batch 243/347] [D loss: 0.500041] [G loss: 0.264595]\n",
      "[Epoch 19/100] [Batch 244/347] [D loss: 0.500117] [G loss: 0.273392]\n",
      "[Epoch 19/100] [Batch 245/347] [D loss: 0.500200] [G loss: 0.271930]\n",
      "[Epoch 19/100] [Batch 246/347] [D loss: 0.499971] [G loss: 0.265311]\n",
      "[Epoch 19/100] [Batch 247/347] [D loss: 0.499686] [G loss: 0.268789]\n",
      "[Epoch 19/100] [Batch 248/347] [D loss: 0.499574] [G loss: 0.273881]\n",
      "[Epoch 19/100] [Batch 249/347] [D loss: 0.499514] [G loss: 0.280047]\n",
      "[Epoch 19/100] [Batch 250/347] [D loss: 0.499717] [G loss: 0.271306]\n",
      "[Epoch 19/100] [Batch 251/347] [D loss: 0.499983] [G loss: 0.265854]\n",
      "[Epoch 19/100] [Batch 252/347] [D loss: 0.500088] [G loss: 0.269068]\n",
      "[Epoch 19/100] [Batch 253/347] [D loss: 0.500094] [G loss: 0.269637]\n",
      "[Epoch 19/100] [Batch 254/347] [D loss: 0.500095] [G loss: 0.267982]\n",
      "[Epoch 19/100] [Batch 255/347] [D loss: 0.500020] [G loss: 0.266496]\n",
      "[Epoch 19/100] [Batch 256/347] [D loss: 0.500079] [G loss: 0.271687]\n",
      "[Epoch 19/100] [Batch 257/347] [D loss: 0.500198] [G loss: 0.273554]\n",
      "[Epoch 19/100] [Batch 258/347] [D loss: 0.500063] [G loss: 0.268393]\n",
      "[Epoch 19/100] [Batch 259/347] [D loss: 0.499767] [G loss: 0.270633]\n",
      "[Epoch 19/100] [Batch 260/347] [D loss: 0.499623] [G loss: 0.284970]\n",
      "[Epoch 19/100] [Batch 261/347] [D loss: 0.499737] [G loss: 0.277333]\n",
      "[Epoch 19/100] [Batch 262/347] [D loss: 0.499823] [G loss: 0.262100]\n",
      "[Epoch 19/100] [Batch 263/347] [D loss: 0.499812] [G loss: 0.262911]\n",
      "[Epoch 19/100] [Batch 264/347] [D loss: 0.499709] [G loss: 0.277313]\n",
      "[Epoch 19/100] [Batch 265/347] [D loss: 0.499649] [G loss: 0.282529]\n",
      "[Epoch 19/100] [Batch 266/347] [D loss: 0.499686] [G loss: 0.275394]\n",
      "[Epoch 19/100] [Batch 267/347] [D loss: 0.499738] [G loss: 0.268537]\n",
      "[Epoch 19/100] [Batch 268/347] [D loss: 0.499716] [G loss: 0.275403]\n",
      "[Epoch 19/100] [Batch 269/347] [D loss: 0.499640] [G loss: 0.286491]\n",
      "[Epoch 19/100] [Batch 270/347] [D loss: 0.499650] [G loss: 0.283041]\n",
      "[Epoch 19/100] [Batch 271/347] [D loss: 0.499723] [G loss: 0.271212]\n",
      "[Epoch 19/100] [Batch 272/347] [D loss: 0.499811] [G loss: 0.262579]\n",
      "[Epoch 19/100] [Batch 273/347] [D loss: 0.499769] [G loss: 0.274425]\n",
      "[Epoch 19/100] [Batch 274/347] [D loss: 0.499531] [G loss: 0.308279]\n",
      "[Epoch 19/100] [Batch 275/347] [D loss: 0.499537] [G loss: 0.305204]\n",
      "[Epoch 19/100] [Batch 276/347] [D loss: 0.499756] [G loss: 0.272809]\n",
      "[Epoch 19/100] [Batch 277/347] [D loss: 0.499854] [G loss: 0.258199]\n",
      "[Epoch 19/100] [Batch 278/347] [D loss: 0.499945] [G loss: 0.254101]\n",
      "[Epoch 19/100] [Batch 279/347] [D loss: 0.499947] [G loss: 0.260938]\n",
      "[Epoch 19/100] [Batch 280/347] [D loss: 0.499918] [G loss: 0.264311]\n",
      "[Epoch 19/100] [Batch 281/347] [D loss: 0.499923] [G loss: 0.262504]\n",
      "[Epoch 19/100] [Batch 282/347] [D loss: 0.499917] [G loss: 0.260325]\n",
      "[Epoch 19/100] [Batch 283/347] [D loss: 0.499860] [G loss: 0.260612]\n",
      "[Epoch 19/100] [Batch 284/347] [D loss: 0.499897] [G loss: 0.262708]\n",
      "[Epoch 19/100] [Batch 285/347] [D loss: 0.499927] [G loss: 0.258390]\n",
      "[Epoch 19/100] [Batch 286/347] [D loss: 0.499872] [G loss: 0.251065]\n",
      "[Epoch 19/100] [Batch 287/347] [D loss: 0.499853] [G loss: 0.254568]\n",
      "[Epoch 19/100] [Batch 288/347] [D loss: 0.499552] [G loss: 0.281568]\n",
      "[Epoch 19/100] [Batch 289/347] [D loss: 0.499503] [G loss: 0.286183]\n",
      "[Epoch 19/100] [Batch 290/347] [D loss: 0.499720] [G loss: 0.263699]\n",
      "[Epoch 19/100] [Batch 291/347] [D loss: 0.499672] [G loss: 0.266558]\n",
      "[Epoch 19/100] [Batch 292/347] [D loss: 0.499775] [G loss: 0.258088]\n",
      "[Epoch 19/100] [Batch 293/347] [D loss: 0.500070] [G loss: 0.267398]\n",
      "[Epoch 19/100] [Batch 294/347] [D loss: 0.500188] [G loss: 0.276946]\n",
      "[Epoch 19/100] [Batch 295/347] [D loss: 0.500071] [G loss: 0.274319]\n",
      "[Epoch 19/100] [Batch 296/347] [D loss: 0.500102] [G loss: 0.270151]\n",
      "[Epoch 19/100] [Batch 297/347] [D loss: 0.500196] [G loss: 0.281894]\n",
      "[Epoch 19/100] [Batch 298/347] [D loss: 0.500126] [G loss: 0.276648]\n",
      "[Epoch 19/100] [Batch 299/347] [D loss: 0.500137] [G loss: 0.275241]\n",
      "[Epoch 19/100] [Batch 300/347] [D loss: 0.500090] [G loss: 0.270590]\n",
      "[Epoch 19/100] [Batch 301/347] [D loss: 0.500117] [G loss: 0.271418]\n",
      "[Epoch 19/100] [Batch 302/347] [D loss: 0.500189] [G loss: 0.276544]\n",
      "[Epoch 19/100] [Batch 303/347] [D loss: 0.499908] [G loss: 0.260827]\n",
      "[Epoch 19/100] [Batch 304/347] [D loss: 0.499639] [G loss: 0.268486]\n",
      "[Epoch 19/100] [Batch 305/347] [D loss: 0.499574] [G loss: 0.281185]\n",
      "[Epoch 19/100] [Batch 306/347] [D loss: 0.499552] [G loss: 0.272377]\n",
      "[Epoch 19/100] [Batch 307/347] [D loss: 0.499513] [G loss: 0.284788]\n",
      "[Epoch 19/100] [Batch 308/347] [D loss: 0.499517] [G loss: 0.280776]\n",
      "[Epoch 19/100] [Batch 309/347] [D loss: 0.499756] [G loss: 0.261126]\n",
      "[Epoch 19/100] [Batch 310/347] [D loss: 0.499978] [G loss: 0.273678]\n",
      "[Epoch 19/100] [Batch 311/347] [D loss: 0.499985] [G loss: 0.276415]\n",
      "[Epoch 19/100] [Batch 312/347] [D loss: 0.499972] [G loss: 0.275983]\n",
      "[Epoch 19/100] [Batch 313/347] [D loss: 0.499985] [G loss: 0.275055]\n",
      "[Epoch 19/100] [Batch 314/347] [D loss: 0.499989] [G loss: 0.268551]\n",
      "[Epoch 19/100] [Batch 315/347] [D loss: 0.499982] [G loss: 0.259234]\n",
      "[Epoch 19/100] [Batch 316/347] [D loss: 0.499740] [G loss: 0.261276]\n",
      "[Epoch 19/100] [Batch 317/347] [D loss: 0.499519] [G loss: 0.279819]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 19/100] [Batch 318/347] [D loss: 0.499781] [G loss: 0.257489]\n",
      "[Epoch 19/100] [Batch 319/347] [D loss: 0.500125] [G loss: 0.281441]\n",
      "[Epoch 19/100] [Batch 320/347] [D loss: 0.500245] [G loss: 0.295087]\n",
      "[Epoch 19/100] [Batch 321/347] [D loss: 0.500162] [G loss: 0.284644]\n",
      "[Epoch 19/100] [Batch 322/347] [D loss: 0.500046] [G loss: 0.271520]\n",
      "[Epoch 19/100] [Batch 323/347] [D loss: 0.500048] [G loss: 0.270677]\n",
      "[Epoch 19/100] [Batch 324/347] [D loss: 0.500092] [G loss: 0.273707]\n",
      "[Epoch 19/100] [Batch 325/347] [D loss: 0.499998] [G loss: 0.263018]\n",
      "[Epoch 19/100] [Batch 326/347] [D loss: 0.499867] [G loss: 0.251903]\n",
      "[Epoch 19/100] [Batch 327/347] [D loss: 0.499865] [G loss: 0.250163]\n",
      "[Epoch 19/100] [Batch 328/347] [D loss: 0.499826] [G loss: 0.253022]\n",
      "[Epoch 19/100] [Batch 329/347] [D loss: 0.499612] [G loss: 0.274509]\n",
      "[Epoch 19/100] [Batch 330/347] [D loss: 0.499433] [G loss: 0.289565]\n",
      "[Epoch 19/100] [Batch 331/347] [D loss: 0.499628] [G loss: 0.270914]\n",
      "[Epoch 19/100] [Batch 332/347] [D loss: 0.499940] [G loss: 0.264870]\n",
      "[Epoch 19/100] [Batch 333/347] [D loss: 0.500026] [G loss: 0.276578]\n",
      "[Epoch 19/100] [Batch 334/347] [D loss: 0.500087] [G loss: 0.278254]\n",
      "[Epoch 19/100] [Batch 335/347] [D loss: 0.500021] [G loss: 0.266506]\n",
      "[Epoch 19/100] [Batch 336/347] [D loss: 0.499890] [G loss: 0.252411]\n",
      "[Epoch 19/100] [Batch 337/347] [D loss: 0.499913] [G loss: 0.258445]\n",
      "[Epoch 19/100] [Batch 338/347] [D loss: 0.500029] [G loss: 0.273290]\n",
      "[Epoch 19/100] [Batch 339/347] [D loss: 0.500081] [G loss: 0.278836]\n",
      "[Epoch 19/100] [Batch 340/347] [D loss: 0.500076] [G loss: 0.279418]\n",
      "[Epoch 19/100] [Batch 341/347] [D loss: 0.500058] [G loss: 0.274781]\n",
      "[Epoch 19/100] [Batch 342/347] [D loss: 0.499984] [G loss: 0.267308]\n",
      "[Epoch 19/100] [Batch 343/347] [D loss: 0.499979] [G loss: 0.272143]\n",
      "[Epoch 19/100] [Batch 344/347] [D loss: 0.499876] [G loss: 0.261784]\n",
      "[Epoch 19/100] [Batch 345/347] [D loss: 0.499581] [G loss: 0.271742]\n",
      "[Epoch 19/100] [Batch 346/347] [D loss: 0.499426] [G loss: 0.290006]\n",
      "[Epoch 19/100] [Batch 347/347] [D loss: 0.499397] [G loss: 0.295991]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 20/100] [Batch 1/347] [D loss: 0.499784] [G loss: 0.262299]\n",
      "[Epoch 20/100] [Batch 2/347] [D loss: 0.499776] [G loss: 0.267396]\n",
      "[Epoch 20/100] [Batch 3/347] [D loss: 0.499852] [G loss: 0.267194]\n",
      "[Epoch 20/100] [Batch 4/347] [D loss: 0.499852] [G loss: 0.268378]\n",
      "[Epoch 20/100] [Batch 5/347] [D loss: 0.499850] [G loss: 0.267674]\n",
      "[Epoch 20/100] [Batch 6/347] [D loss: 0.499865] [G loss: 0.267965]\n",
      "[Epoch 20/100] [Batch 7/347] [D loss: 0.499831] [G loss: 0.267783]\n",
      "[Epoch 20/100] [Batch 8/347] [D loss: 0.499835] [G loss: 0.263092]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 20/100] [Batch 9/347] [D loss: 0.499754] [G loss: 0.262056]\n",
      "[Epoch 20/100] [Batch 10/347] [D loss: 0.499751] [G loss: 0.263666]\n",
      "[Epoch 20/100] [Batch 11/347] [D loss: 0.499863] [G loss: 0.263414]\n",
      "[Epoch 20/100] [Batch 12/347] [D loss: 0.499903] [G loss: 0.265847]\n",
      "[Epoch 20/100] [Batch 13/347] [D loss: 0.499956] [G loss: 0.269865]\n",
      "[Epoch 20/100] [Batch 14/347] [D loss: 0.500006] [G loss: 0.271944]\n",
      "[Epoch 20/100] [Batch 15/347] [D loss: 0.499976] [G loss: 0.267873]\n",
      "[Epoch 20/100] [Batch 16/347] [D loss: 0.499949] [G loss: 0.263567]\n",
      "[Epoch 20/100] [Batch 17/347] [D loss: 0.499888] [G loss: 0.251464]\n",
      "[Epoch 20/100] [Batch 18/347] [D loss: 0.499823] [G loss: 0.255639]\n",
      "[Epoch 20/100] [Batch 19/347] [D loss: 0.499926] [G loss: 0.256462]\n",
      "[Epoch 20/100] [Batch 20/347] [D loss: 0.500019] [G loss: 0.269423]\n",
      "[Epoch 20/100] [Batch 21/347] [D loss: 0.499966] [G loss: 0.265597]\n",
      "[Epoch 20/100] [Batch 22/347] [D loss: 0.499917] [G loss: 0.260525]\n",
      "[Epoch 20/100] [Batch 23/347] [D loss: 0.499876] [G loss: 0.254557]\n",
      "[Epoch 20/100] [Batch 24/347] [D loss: 0.499892] [G loss: 0.253580]\n",
      "[Epoch 20/100] [Batch 25/347] [D loss: 0.499881] [G loss: 0.253364]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 20/100] [Batch 26/347] [D loss: 0.499731] [G loss: 0.261206]\n",
      "[Epoch 20/100] [Batch 27/347] [D loss: 0.499777] [G loss: 0.266585]\n",
      "[Epoch 20/100] [Batch 28/347] [D loss: 0.499947] [G loss: 0.266921]\n",
      "[Epoch 20/100] [Batch 29/347] [D loss: 0.500054] [G loss: 0.265586]\n",
      "[Epoch 20/100] [Batch 30/347] [D loss: 0.500134] [G loss: 0.272768]\n",
      "[Epoch 20/100] [Batch 31/347] [D loss: 0.500186] [G loss: 0.275591]\n",
      "[Epoch 20/100] [Batch 32/347] [D loss: 0.500133] [G loss: 0.269097]\n",
      "[Epoch 20/100] [Batch 33/347] [D loss: 0.500055] [G loss: 0.265254]\n",
      "[Epoch 20/100] [Batch 34/347] [D loss: 0.500056] [G loss: 0.266531]\n",
      "[Epoch 20/100] [Batch 35/347] [D loss: 0.500050] [G loss: 0.265547]\n",
      "[Epoch 20/100] [Batch 36/347] [D loss: 0.499965] [G loss: 0.256622]\n",
      "[Epoch 20/100] [Batch 37/347] [D loss: 0.499701] [G loss: 0.269871]\n",
      "[Epoch 20/100] [Batch 38/347] [D loss: 0.499507] [G loss: 0.284875]\n",
      "[Epoch 20/100] [Batch 39/347] [D loss: 0.499560] [G loss: 0.275068]\n",
      "[Epoch 20/100] [Batch 40/347] [D loss: 0.499587] [G loss: 0.275641]\n",
      "[Epoch 20/100] [Batch 41/347] [D loss: 0.499553] [G loss: 0.276737]\n",
      "[Epoch 20/100] [Batch 42/347] [D loss: 0.499618] [G loss: 0.269516]\n",
      "[Epoch 20/100] [Batch 43/347] [D loss: 0.499841] [G loss: 0.252911]\n",
      "[Epoch 20/100] [Batch 44/347] [D loss: 0.500058] [G loss: 0.265467]\n",
      "[Epoch 20/100] [Batch 45/347] [D loss: 0.500225] [G loss: 0.282767]\n",
      "[Epoch 20/100] [Batch 46/347] [D loss: 0.500195] [G loss: 0.277413]\n",
      "[Epoch 20/100] [Batch 47/347] [D loss: 0.499890] [G loss: 0.252478]\n",
      "[Epoch 20/100] [Batch 48/347] [D loss: 0.499572] [G loss: 0.283573]\n",
      "[Epoch 20/100] [Batch 49/347] [D loss: 0.499461] [G loss: 0.292290]\n",
      "[Epoch 20/100] [Batch 50/347] [D loss: 0.499387] [G loss: 0.308015]\n",
      "[Epoch 20/100] [Batch 51/347] [D loss: 0.499611] [G loss: 0.292651]\n",
      "[Epoch 20/100] [Batch 52/347] [D loss: 0.499967] [G loss: 0.263284]\n",
      "[Epoch 20/100] [Batch 53/347] [D loss: 0.499895] [G loss: 0.257562]\n",
      "[Epoch 20/100] [Batch 54/347] [D loss: 0.499370] [G loss: 0.308737]\n",
      "[Epoch 20/100] [Batch 55/347] [D loss: 0.498981] [G loss: 0.331602]\n",
      "[Epoch 20/100] [Batch 56/347] [D loss: 0.499067] [G loss: 0.318843]\n",
      "[Epoch 20/100] [Batch 57/347] [D loss: 0.499559] [G loss: 0.284695]\n",
      "[Epoch 20/100] [Batch 58/347] [D loss: 0.499912] [G loss: 0.259588]\n",
      "[Epoch 20/100] [Batch 59/347] [D loss: 0.499797] [G loss: 0.268018]\n",
      "[Epoch 20/100] [Batch 60/347] [D loss: 0.499616] [G loss: 0.287183]\n",
      "[Epoch 20/100] [Batch 61/347] [D loss: 0.499495] [G loss: 0.300157]\n",
      "[Epoch 20/100] [Batch 62/347] [D loss: 0.499192] [G loss: 0.324483]\n",
      "[Epoch 20/100] [Batch 63/347] [D loss: 0.498994] [G loss: 0.326759]\n",
      "[Epoch 20/100] [Batch 64/347] [D loss: 0.499445] [G loss: 0.289899]\n",
      "[Epoch 20/100] [Batch 65/347] [D loss: 0.500041] [G loss: 0.261936]\n",
      "[Epoch 20/100] [Batch 66/347] [D loss: 0.499988] [G loss: 0.264112]\n",
      "[Epoch 20/100] [Batch 67/347] [D loss: 0.499705] [G loss: 0.274374]\n",
      "[Epoch 20/100] [Batch 68/347] [D loss: 0.499518] [G loss: 0.292755]\n",
      "[Epoch 20/100] [Batch 69/347] [D loss: 0.499211] [G loss: 0.311959]\n",
      "[Epoch 20/100] [Batch 70/347] [D loss: 0.499148] [G loss: 0.310820]\n",
      "[Epoch 20/100] [Batch 71/347] [D loss: 0.499218] [G loss: 0.313186]\n",
      "[Epoch 20/100] [Batch 72/347] [D loss: 0.499155] [G loss: 0.315742]\n",
      "[Epoch 20/100] [Batch 73/347] [D loss: 0.499424] [G loss: 0.291074]\n",
      "[Epoch 20/100] [Batch 74/347] [D loss: 0.499697] [G loss: 0.277179]\n",
      "[Epoch 20/100] [Batch 75/347] [D loss: 0.499386] [G loss: 0.307283]\n",
      "[Epoch 20/100] [Batch 76/347] [D loss: 0.499211] [G loss: 0.309465]\n",
      "[Epoch 20/100] [Batch 77/347] [D loss: 0.499603] [G loss: 0.275288]\n",
      "[Epoch 20/100] [Batch 78/347] [D loss: 0.500067] [G loss: 0.266885]\n",
      "[Epoch 20/100] [Batch 79/347] [D loss: 0.500165] [G loss: 0.268887]\n",
      "[Epoch 20/100] [Batch 80/347] [D loss: 0.500102] [G loss: 0.266265]\n",
      "[Epoch 20/100] [Batch 81/347] [D loss: 0.500188] [G loss: 0.271139]\n",
      "[Epoch 20/100] [Batch 82/347] [D loss: 0.500173] [G loss: 0.275727]\n",
      "[Epoch 20/100] [Batch 83/347] [D loss: 0.500115] [G loss: 0.268102]\n",
      "[Epoch 20/100] [Batch 84/347] [D loss: 0.500148] [G loss: 0.274865]\n",
      "[Epoch 20/100] [Batch 85/347] [D loss: 0.500122] [G loss: 0.275732]\n",
      "[Epoch 20/100] [Batch 86/347] [D loss: 0.500072] [G loss: 0.270252]\n",
      "[Epoch 20/100] [Batch 87/347] [D loss: 0.500031] [G loss: 0.268217]\n",
      "[Epoch 20/100] [Batch 88/347] [D loss: 0.500054] [G loss: 0.271774]\n",
      "[Epoch 20/100] [Batch 89/347] [D loss: 0.500071] [G loss: 0.275317]\n",
      "[Epoch 20/100] [Batch 90/347] [D loss: 0.500036] [G loss: 0.271642]\n",
      "[Epoch 20/100] [Batch 91/347] [D loss: 0.500014] [G loss: 0.270328]\n",
      "[Epoch 20/100] [Batch 92/347] [D loss: 0.500017] [G loss: 0.271935]\n",
      "[Epoch 20/100] [Batch 93/347] [D loss: 0.499991] [G loss: 0.270030]\n",
      "[Epoch 20/100] [Batch 94/347] [D loss: 0.499951] [G loss: 0.266597]\n",
      "[Epoch 20/100] [Batch 95/347] [D loss: 0.499963] [G loss: 0.267209]\n",
      "[Epoch 20/100] [Batch 96/347] [D loss: 0.499928] [G loss: 0.262576]\n",
      "[Epoch 20/100] [Batch 97/347] [D loss: 0.499864] [G loss: 0.258850]\n",
      "[Epoch 20/100] [Batch 98/347] [D loss: 0.499894] [G loss: 0.262833]\n",
      "[Epoch 20/100] [Batch 99/347] [D loss: 0.499934] [G loss: 0.266900]\n",
      "[Epoch 20/100] [Batch 100/347] [D loss: 0.499909] [G loss: 0.263543]\n",
      "[Epoch 20/100] [Batch 101/347] [D loss: 0.499855] [G loss: 0.261536]\n",
      "[Epoch 20/100] [Batch 102/347] [D loss: 0.499874] [G loss: 0.261965]\n",
      "[Epoch 20/100] [Batch 103/347] [D loss: 0.499891] [G loss: 0.261970]\n",
      "[Epoch 20/100] [Batch 104/347] [D loss: 0.499809] [G loss: 0.262929]\n",
      "[Epoch 20/100] [Batch 105/347] [D loss: 0.499797] [G loss: 0.264351]\n",
      "[Epoch 20/100] [Batch 106/347] [D loss: 0.499805] [G loss: 0.263148]\n",
      "[Epoch 20/100] [Batch 107/347] [D loss: 0.499774] [G loss: 0.256878]\n",
      "[Epoch 20/100] [Batch 108/347] [D loss: 0.499708] [G loss: 0.273651]\n",
      "[Epoch 20/100] [Batch 109/347] [D loss: 0.499813] [G loss: 0.266606]\n",
      "[Epoch 20/100] [Batch 110/347] [D loss: 0.499966] [G loss: 0.256763]\n",
      "[Epoch 20/100] [Batch 111/347] [D loss: 0.499854] [G loss: 0.261686]\n",
      "[Epoch 20/100] [Batch 112/347] [D loss: 0.499881] [G loss: 0.266770]\n",
      "[Epoch 20/100] [Batch 113/347] [D loss: 0.500125] [G loss: 0.271761]\n",
      "[Epoch 20/100] [Batch 114/347] [D loss: 0.500288] [G loss: 0.292284]\n",
      "[Epoch 20/100] [Batch 115/347] [D loss: 0.500310] [G loss: 0.293375]\n",
      "[Epoch 20/100] [Batch 116/347] [D loss: 0.500269] [G loss: 0.287477]\n",
      "[Epoch 20/100] [Batch 117/347] [D loss: 0.500048] [G loss: 0.260954]\n",
      "[Epoch 20/100] [Batch 118/347] [D loss: 0.499736] [G loss: 0.265345]\n",
      "[Epoch 20/100] [Batch 119/347] [D loss: 0.499671] [G loss: 0.267585]\n",
      "[Epoch 20/100] [Batch 120/347] [D loss: 0.499712] [G loss: 0.266466]\n",
      "[Epoch 20/100] [Batch 121/347] [D loss: 0.499723] [G loss: 0.264743]\n",
      "[Epoch 20/100] [Batch 122/347] [D loss: 0.499833] [G loss: 0.251991]\n",
      "[Epoch 20/100] [Batch 123/347] [D loss: 0.499867] [G loss: 0.251133]\n",
      "[Epoch 20/100] [Batch 124/347] [D loss: 0.499814] [G loss: 0.252553]\n",
      "[Epoch 20/100] [Batch 125/347] [D loss: 0.499945] [G loss: 0.258977]\n",
      "[Epoch 20/100] [Batch 126/347] [D loss: 0.500089] [G loss: 0.271678]\n",
      "[Epoch 20/100] [Batch 127/347] [D loss: 0.500128] [G loss: 0.273116]\n",
      "[Epoch 20/100] [Batch 128/347] [D loss: 0.500060] [G loss: 0.267650]\n",
      "[Epoch 20/100] [Batch 129/347] [D loss: 0.500049] [G loss: 0.262776]\n",
      "[Epoch 20/100] [Batch 130/347] [D loss: 0.500023] [G loss: 0.266262]\n",
      "[Epoch 20/100] [Batch 131/347] [D loss: 0.499852] [G loss: 0.264364]\n",
      "[Epoch 20/100] [Batch 132/347] [D loss: 0.499607] [G loss: 0.287403]\n",
      "[Epoch 20/100] [Batch 133/347] [D loss: 0.499526] [G loss: 0.294312]\n",
      "[Epoch 20/100] [Batch 134/347] [D loss: 0.499370] [G loss: 0.309333]\n",
      "[Epoch 20/100] [Batch 135/347] [D loss: 0.499323] [G loss: 0.318432]\n",
      "[Epoch 20/100] [Batch 136/347] [D loss: 0.499737] [G loss: 0.276521]\n",
      "[Epoch 20/100] [Batch 137/347] [D loss: 0.499964] [G loss: 0.265636]\n",
      "[Epoch 20/100] [Batch 138/347] [D loss: 0.499623] [G loss: 0.281987]\n",
      "[Epoch 20/100] [Batch 139/347] [D loss: 0.499322] [G loss: 0.306128]\n",
      "[Epoch 20/100] [Batch 140/347] [D loss: 0.499208] [G loss: 0.317622]\n",
      "[Epoch 20/100] [Batch 141/347] [D loss: 0.499108] [G loss: 0.324532]\n",
      "[Epoch 20/100] [Batch 142/347] [D loss: 0.499040] [G loss: 0.332152]\n",
      "[Epoch 20/100] [Batch 143/347] [D loss: 0.498783] [G loss: 0.353699]\n",
      "[Epoch 20/100] [Batch 144/347] [D loss: 0.498695] [G loss: 0.355903]\n",
      "[Epoch 20/100] [Batch 145/347] [D loss: 0.498766] [G loss: 0.341474]\n",
      "[Epoch 20/100] [Batch 146/347] [D loss: 0.498872] [G loss: 0.324642]\n",
      "[Epoch 20/100] [Batch 147/347] [D loss: 0.499207] [G loss: 0.296532]\n",
      "[Epoch 20/100] [Batch 148/347] [D loss: 0.499395] [G loss: 0.284238]\n",
      "[Epoch 20/100] [Batch 149/347] [D loss: 0.499242] [G loss: 0.297770]\n",
      "[Epoch 20/100] [Batch 150/347] [D loss: 0.499251] [G loss: 0.298435]\n",
      "[Epoch 20/100] [Batch 151/347] [D loss: 0.499456] [G loss: 0.287780]\n",
      "[Epoch 20/100] [Batch 152/347] [D loss: 0.499391] [G loss: 0.299122]\n",
      "[Epoch 20/100] [Batch 153/347] [D loss: 0.499114] [G loss: 0.320095]\n",
      "[Epoch 20/100] [Batch 154/347] [D loss: 0.498952] [G loss: 0.324430]\n",
      "[Epoch 20/100] [Batch 155/347] [D loss: 0.499071] [G loss: 0.311821]\n",
      "[Epoch 20/100] [Batch 156/347] [D loss: 0.499309] [G loss: 0.295435]\n",
      "[Epoch 20/100] [Batch 157/347] [D loss: 0.499370] [G loss: 0.301948]\n",
      "[Epoch 20/100] [Batch 158/347] [D loss: 0.499051] [G loss: 0.325948]\n",
      "[Epoch 20/100] [Batch 159/347] [D loss: 0.498963] [G loss: 0.323770]\n",
      "[Epoch 20/100] [Batch 160/347] [D loss: 0.499309] [G loss: 0.304139]\n",
      "[Epoch 20/100] [Batch 161/347] [D loss: 0.499510] [G loss: 0.296039]\n",
      "[Epoch 20/100] [Batch 162/347] [D loss: 0.499434] [G loss: 0.302154]\n",
      "[Epoch 20/100] [Batch 163/347] [D loss: 0.499183] [G loss: 0.321235]\n",
      "[Epoch 20/100] [Batch 164/347] [D loss: 0.498948] [G loss: 0.336862]\n",
      "[Epoch 20/100] [Batch 165/347] [D loss: 0.498966] [G loss: 0.328312]\n",
      "[Epoch 20/100] [Batch 166/347] [D loss: 0.499410] [G loss: 0.290251]\n",
      "[Epoch 20/100] [Batch 167/347] [D loss: 0.499905] [G loss: 0.266500]\n",
      "[Epoch 20/100] [Batch 168/347] [D loss: 0.500061] [G loss: 0.277078]\n",
      "[Epoch 20/100] [Batch 169/347] [D loss: 0.500134] [G loss: 0.275755]\n",
      "[Epoch 20/100] [Batch 170/347] [D loss: 0.500202] [G loss: 0.271692]\n",
      "[Epoch 20/100] [Batch 171/347] [D loss: 0.500332] [G loss: 0.280002]\n",
      "[Epoch 20/100] [Batch 172/347] [D loss: 0.500387] [G loss: 0.284892]\n",
      "[Epoch 20/100] [Batch 173/347] [D loss: 0.500240] [G loss: 0.273704]\n",
      "[Epoch 20/100] [Batch 174/347] [D loss: 0.500192] [G loss: 0.271291]\n",
      "[Epoch 20/100] [Batch 175/347] [D loss: 0.500274] [G loss: 0.281304]\n",
      "[Epoch 20/100] [Batch 176/347] [D loss: 0.500426] [G loss: 0.294840]\n",
      "[Epoch 20/100] [Batch 177/347] [D loss: 0.500427] [G loss: 0.295904]\n",
      "[Epoch 20/100] [Batch 178/347] [D loss: 0.500357] [G loss: 0.290084]\n",
      "[Epoch 20/100] [Batch 179/347] [D loss: 0.500275] [G loss: 0.283535]\n",
      "[Epoch 20/100] [Batch 180/347] [D loss: 0.500210] [G loss: 0.277274]\n",
      "[Epoch 20/100] [Batch 181/347] [D loss: 0.500203] [G loss: 0.277867]\n",
      "[Epoch 20/100] [Batch 182/347] [D loss: 0.500140] [G loss: 0.275903]\n",
      "[Epoch 20/100] [Batch 183/347] [D loss: 0.500190] [G loss: 0.280121]\n",
      "[Epoch 20/100] [Batch 184/347] [D loss: 0.500222] [G loss: 0.284141]\n",
      "[Epoch 20/100] [Batch 185/347] [D loss: 0.500211] [G loss: 0.282732]\n",
      "[Epoch 20/100] [Batch 186/347] [D loss: 0.500218] [G loss: 0.282626]\n",
      "[Epoch 20/100] [Batch 187/347] [D loss: 0.500171] [G loss: 0.277412]\n",
      "[Epoch 20/100] [Batch 188/347] [D loss: 0.500117] [G loss: 0.274232]\n",
      "[Epoch 20/100] [Batch 189/347] [D loss: 0.500108] [G loss: 0.273410]\n",
      "[Epoch 20/100] [Batch 190/347] [D loss: 0.499933] [G loss: 0.261567]\n",
      "[Epoch 20/100] [Batch 191/347] [D loss: 0.499738] [G loss: 0.263177]\n",
      "[Epoch 20/100] [Batch 192/347] [D loss: 0.499821] [G loss: 0.253492]\n",
      "[Epoch 20/100] [Batch 193/347] [D loss: 0.499963] [G loss: 0.259757]\n",
      "[Epoch 20/100] [Batch 194/347] [D loss: 0.499843] [G loss: 0.256832]\n",
      "[Epoch 20/100] [Batch 195/347] [D loss: 0.499745] [G loss: 0.265298]\n",
      "[Epoch 20/100] [Batch 196/347] [D loss: 0.499696] [G loss: 0.262687]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 20/100] [Batch 197/347] [D loss: 0.499720] [G loss: 0.257746]\n",
      "[Epoch 20/100] [Batch 198/347] [D loss: 0.499776] [G loss: 0.257368]\n",
      "[Epoch 20/100] [Batch 199/347] [D loss: 0.499776] [G loss: 0.258309]\n",
      "[Epoch 20/100] [Batch 200/347] [D loss: 0.499812] [G loss: 0.253081]\n",
      "[Epoch 20/100] [Batch 201/347] [D loss: 0.499834] [G loss: 0.252428]\n",
      "[Epoch 20/100] [Batch 202/347] [D loss: 0.499717] [G loss: 0.263958]\n",
      "[Epoch 20/100] [Batch 203/347] [D loss: 0.499623] [G loss: 0.272464]\n",
      "[Epoch 20/100] [Batch 204/347] [D loss: 0.499667] [G loss: 0.268800]\n",
      "[Epoch 20/100] [Batch 205/347] [D loss: 0.499736] [G loss: 0.260795]\n",
      "[Epoch 20/100] [Batch 206/347] [D loss: 0.499864] [G loss: 0.251311]\n",
      "[Epoch 20/100] [Batch 207/347] [D loss: 0.500073] [G loss: 0.262116]\n",
      "[Epoch 20/100] [Batch 208/347] [D loss: 0.500031] [G loss: 0.262880]\n",
      "[Epoch 20/100] [Batch 209/347] [D loss: 0.499949] [G loss: 0.257188]\n",
      "[Epoch 20/100] [Batch 210/347] [D loss: 0.500100] [G loss: 0.265312]\n",
      "[Epoch 20/100] [Batch 211/347] [D loss: 0.500066] [G loss: 0.262535]\n",
      "[Epoch 20/100] [Batch 212/347] [D loss: 0.500008] [G loss: 0.261448]\n",
      "[Epoch 20/100] [Batch 213/347] [D loss: 0.499982] [G loss: 0.267197]\n",
      "[Epoch 20/100] [Batch 214/347] [D loss: 0.499734] [G loss: 0.275694]\n",
      "[Epoch 20/100] [Batch 215/347] [D loss: 0.499640] [G loss: 0.284033]\n",
      "[Epoch 20/100] [Batch 216/347] [D loss: 0.499896] [G loss: 0.266638]\n",
      "[Epoch 20/100] [Batch 217/347] [D loss: 0.500049] [G loss: 0.267412]\n",
      "[Epoch 20/100] [Batch 218/347] [D loss: 0.500188] [G loss: 0.273545]\n",
      "[Epoch 20/100] [Batch 219/347] [D loss: 0.500359] [G loss: 0.285848]\n",
      "[Epoch 20/100] [Batch 220/347] [D loss: 0.500552] [G loss: 0.301710]\n",
      "[Epoch 20/100] [Batch 221/347] [D loss: 0.500580] [G loss: 0.303084]\n",
      "[Epoch 20/100] [Batch 222/347] [D loss: 0.500519] [G loss: 0.295086]\n",
      "[Epoch 20/100] [Batch 223/347] [D loss: 0.500507] [G loss: 0.293799]\n",
      "[Epoch 20/100] [Batch 224/347] [D loss: 0.500459] [G loss: 0.289717]\n",
      "[Epoch 20/100] [Batch 225/347] [D loss: 0.500142] [G loss: 0.276711]\n",
      "[Epoch 20/100] [Batch 226/347] [D loss: 0.499672] [G loss: 0.272667]\n",
      "[Epoch 20/100] [Batch 227/347] [D loss: 0.499386] [G loss: 0.282894]\n",
      "[Epoch 20/100] [Batch 228/347] [D loss: 0.499378] [G loss: 0.283975]\n",
      "[Epoch 20/100] [Batch 229/347] [D loss: 0.499512] [G loss: 0.278907]\n",
      "[Epoch 20/100] [Batch 230/347] [D loss: 0.499582] [G loss: 0.274884]\n",
      "[Epoch 20/100] [Batch 231/347] [D loss: 0.499502] [G loss: 0.274761]\n",
      "[Epoch 20/100] [Batch 232/347] [D loss: 0.499571] [G loss: 0.270663]\n",
      "[Epoch 20/100] [Batch 233/347] [D loss: 0.499608] [G loss: 0.268711]\n",
      "[Epoch 20/100] [Batch 234/347] [D loss: 0.499597] [G loss: 0.273650]\n",
      "[Epoch 20/100] [Batch 235/347] [D loss: 0.499783] [G loss: 0.262356]\n",
      "[Epoch 20/100] [Batch 236/347] [D loss: 0.499970] [G loss: 0.263535]\n",
      "[Epoch 20/100] [Batch 237/347] [D loss: 0.500108] [G loss: 0.266337]\n",
      "[Epoch 20/100] [Batch 238/347] [D loss: 0.500109] [G loss: 0.270179]\n",
      "[Epoch 20/100] [Batch 239/347] [D loss: 0.500073] [G loss: 0.267991]\n",
      "[Epoch 20/100] [Batch 240/347] [D loss: 0.500045] [G loss: 0.264020]\n",
      "[Epoch 20/100] [Batch 241/347] [D loss: 0.499977] [G loss: 0.258086]\n",
      "[Epoch 20/100] [Batch 242/347] [D loss: 0.499936] [G loss: 0.256069]\n",
      "[Epoch 20/100] [Batch 243/347] [D loss: 0.500021] [G loss: 0.263684]\n",
      "[Epoch 20/100] [Batch 244/347] [D loss: 0.500118] [G loss: 0.272511]\n",
      "[Epoch 20/100] [Batch 245/347] [D loss: 0.500214] [G loss: 0.271187]\n",
      "[Epoch 20/100] [Batch 246/347] [D loss: 0.499926] [G loss: 0.264569]\n",
      "[Epoch 20/100] [Batch 247/347] [D loss: 0.499586] [G loss: 0.269231]\n",
      "[Epoch 20/100] [Batch 248/347] [D loss: 0.499453] [G loss: 0.274453]\n",
      "[Epoch 20/100] [Batch 249/347] [D loss: 0.499381] [G loss: 0.280485]\n",
      "[Epoch 20/100] [Batch 250/347] [D loss: 0.499621] [G loss: 0.271712]\n",
      "[Epoch 20/100] [Batch 251/347] [D loss: 0.499948] [G loss: 0.264982]\n",
      "[Epoch 20/100] [Batch 252/347] [D loss: 0.500076] [G loss: 0.268197]\n",
      "[Epoch 20/100] [Batch 253/347] [D loss: 0.500082] [G loss: 0.268713]\n",
      "[Epoch 20/100] [Batch 254/347] [D loss: 0.500084] [G loss: 0.267044]\n",
      "[Epoch 20/100] [Batch 255/347] [D loss: 0.499984] [G loss: 0.265563]\n",
      "[Epoch 20/100] [Batch 256/347] [D loss: 0.500058] [G loss: 0.270756]\n",
      "[Epoch 20/100] [Batch 257/347] [D loss: 0.500210] [G loss: 0.272637]\n",
      "[Epoch 20/100] [Batch 258/347] [D loss: 0.500041] [G loss: 0.267446]\n",
      "[Epoch 20/100] [Batch 259/347] [D loss: 0.499678] [G loss: 0.271121]\n",
      "[Epoch 20/100] [Batch 260/347] [D loss: 0.499501] [G loss: 0.285438]\n",
      "[Epoch 20/100] [Batch 261/347] [D loss: 0.499639] [G loss: 0.277764]\n",
      "[Epoch 20/100] [Batch 262/347] [D loss: 0.499752] [G loss: 0.262496]\n",
      "[Epoch 20/100] [Batch 263/347] [D loss: 0.499740] [G loss: 0.263286]\n",
      "[Epoch 20/100] [Batch 264/347] [D loss: 0.499603] [G loss: 0.277674]\n",
      "[Epoch 20/100] [Batch 265/347] [D loss: 0.499527] [G loss: 0.282877]\n",
      "[Epoch 20/100] [Batch 266/347] [D loss: 0.499579] [G loss: 0.275727]\n",
      "[Epoch 20/100] [Batch 267/347] [D loss: 0.499642] [G loss: 0.268886]\n",
      "[Epoch 20/100] [Batch 268/347] [D loss: 0.499614] [G loss: 0.275731]\n",
      "[Epoch 20/100] [Batch 269/347] [D loss: 0.499517] [G loss: 0.286816]\n",
      "[Epoch 20/100] [Batch 270/347] [D loss: 0.499529] [G loss: 0.283356]\n",
      "[Epoch 20/100] [Batch 271/347] [D loss: 0.499625] [G loss: 0.271487]\n",
      "[Epoch 20/100] [Batch 272/347] [D loss: 0.499733] [G loss: 0.262837]\n",
      "[Epoch 20/100] [Batch 273/347] [D loss: 0.499671] [G loss: 0.274680]\n",
      "[Epoch 20/100] [Batch 274/347] [D loss: 0.499317] [G loss: 0.308475]\n",
      "[Epoch 20/100] [Batch 275/347] [D loss: 0.499325] [G loss: 0.305438]\n",
      "[Epoch 20/100] [Batch 276/347] [D loss: 0.499659] [G loss: 0.272975]\n",
      "[Epoch 20/100] [Batch 277/347] [D loss: 0.499788] [G loss: 0.258363]\n",
      "[Epoch 20/100] [Batch 278/347] [D loss: 0.499900] [G loss: 0.253118]\n",
      "[Epoch 20/100] [Batch 279/347] [D loss: 0.499901] [G loss: 0.259759]\n",
      "[Epoch 20/100] [Batch 280/347] [D loss: 0.499866] [G loss: 0.263184]\n",
      "[Epoch 20/100] [Batch 281/347] [D loss: 0.499873] [G loss: 0.261444]\n",
      "[Epoch 20/100] [Batch 282/347] [D loss: 0.499864] [G loss: 0.259357]\n",
      "[Epoch 20/100] [Batch 283/347] [D loss: 0.499793] [G loss: 0.259923]\n",
      "[Epoch 20/100] [Batch 284/347] [D loss: 0.499843] [G loss: 0.262243]\n",
      "[Epoch 20/100] [Batch 285/347] [D loss: 0.499894] [G loss: 0.258294]\n",
      "[Epoch 20/100] [Batch 286/347] [D loss: 0.499831] [G loss: 0.251292]\n",
      "[Epoch 20/100] [Batch 287/347] [D loss: 0.499808] [G loss: 0.253877]\n",
      "[Epoch 20/100] [Batch 288/347] [D loss: 0.499439] [G loss: 0.280686]\n",
      "[Epoch 20/100] [Batch 289/347] [D loss: 0.499380] [G loss: 0.285153]\n",
      "[Epoch 20/100] [Batch 290/347] [D loss: 0.499658] [G loss: 0.262514]\n",
      "[Epoch 20/100] [Batch 291/347] [D loss: 0.499600] [G loss: 0.265208]\n",
      "[Epoch 20/100] [Batch 292/347] [D loss: 0.499730] [G loss: 0.256643]\n",
      "[Epoch 20/100] [Batch 293/347] [D loss: 0.500093] [G loss: 0.269431]\n",
      "[Epoch 20/100] [Batch 294/347] [D loss: 0.500234] [G loss: 0.279154]\n",
      "[Epoch 20/100] [Batch 295/347] [D loss: 0.500090] [G loss: 0.276689]\n",
      "[Epoch 20/100] [Batch 296/347] [D loss: 0.500136] [G loss: 0.272660]\n",
      "[Epoch 20/100] [Batch 297/347] [D loss: 0.500263] [G loss: 0.283787]\n",
      "[Epoch 20/100] [Batch 298/347] [D loss: 0.500176] [G loss: 0.278607]\n",
      "[Epoch 20/100] [Batch 299/347] [D loss: 0.500196] [G loss: 0.277348]\n",
      "[Epoch 20/100] [Batch 300/347] [D loss: 0.500131] [G loss: 0.272786]\n",
      "[Epoch 20/100] [Batch 301/347] [D loss: 0.500164] [G loss: 0.274577]\n",
      "[Epoch 20/100] [Batch 302/347] [D loss: 0.500247] [G loss: 0.279837]\n",
      "[Epoch 20/100] [Batch 303/347] [D loss: 0.499902] [G loss: 0.264227]\n",
      "[Epoch 20/100] [Batch 304/347] [D loss: 0.499583] [G loss: 0.265527]\n",
      "[Epoch 20/100] [Batch 305/347] [D loss: 0.499514] [G loss: 0.278113]\n",
      "[Epoch 20/100] [Batch 306/347] [D loss: 0.499483] [G loss: 0.270228]\n",
      "[Epoch 20/100] [Batch 307/347] [D loss: 0.499427] [G loss: 0.282535]\n",
      "[Epoch 20/100] [Batch 308/347] [D loss: 0.499437] [G loss: 0.278443]\n",
      "[Epoch 20/100] [Batch 309/347] [D loss: 0.499732] [G loss: 0.257661]\n",
      "[Epoch 20/100] [Batch 310/347] [D loss: 0.500013] [G loss: 0.276267]\n",
      "[Epoch 20/100] [Batch 311/347] [D loss: 0.500021] [G loss: 0.278976]\n",
      "[Epoch 20/100] [Batch 312/347] [D loss: 0.500006] [G loss: 0.278535]\n",
      "[Epoch 20/100] [Batch 313/347] [D loss: 0.500022] [G loss: 0.277589]\n",
      "[Epoch 20/100] [Batch 314/347] [D loss: 0.500023] [G loss: 0.271085]\n",
      "[Epoch 20/100] [Batch 315/347] [D loss: 0.500005] [G loss: 0.261739]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 20/100] [Batch 316/347] [D loss: 0.499713] [G loss: 0.257577]\n",
      "[Epoch 20/100] [Batch 317/347] [D loss: 0.499452] [G loss: 0.276099]\n",
      "[Epoch 20/100] [Batch 318/347] [D loss: 0.499768] [G loss: 0.253758]\n",
      "[Epoch 20/100] [Batch 319/347] [D loss: 0.500193] [G loss: 0.284066]\n",
      "[Epoch 20/100] [Batch 320/347] [D loss: 0.500341] [G loss: 0.297731]\n",
      "[Epoch 20/100] [Batch 321/347] [D loss: 0.500237] [G loss: 0.287327]\n",
      "[Epoch 20/100] [Batch 322/347] [D loss: 0.500094] [G loss: 0.274220]\n",
      "[Epoch 20/100] [Batch 323/347] [D loss: 0.500097] [G loss: 0.273398]\n",
      "[Epoch 20/100] [Batch 324/347] [D loss: 0.500146] [G loss: 0.276466]\n",
      "[Epoch 20/100] [Batch 325/347] [D loss: 0.500028] [G loss: 0.265777]\n",
      "[Epoch 20/100] [Batch 326/347] [D loss: 0.499870] [G loss: 0.255902]\n",
      "[Epoch 20/100] [Batch 327/347] [D loss: 0.499871] [G loss: 0.254144]\n",
      "[Epoch 20/100] [Batch 328/347] [D loss: 0.499818] [G loss: 0.251740]\n",
      "[Epoch 20/100] [Batch 329/347] [D loss: 0.499544] [G loss: 0.272948]\n",
      "[Epoch 20/100] [Batch 330/347] [D loss: 0.499316] [G loss: 0.288515]\n",
      "[Epoch 20/100] [Batch 331/347] [D loss: 0.499549] [G loss: 0.270295]\n",
      "[Epoch 20/100] [Batch 332/347] [D loss: 0.499925] [G loss: 0.265689]\n",
      "[Epoch 20/100] [Batch 333/347] [D loss: 0.500027] [G loss: 0.277010]\n",
      "[Epoch 20/100] [Batch 334/347] [D loss: 0.500092] [G loss: 0.278328]\n",
      "[Epoch 20/100] [Batch 335/347] [D loss: 0.499999] [G loss: 0.266275]\n",
      "[Epoch 20/100] [Batch 336/347] [D loss: 0.499833] [G loss: 0.252147]\n",
      "[Epoch 20/100] [Batch 337/347] [D loss: 0.499863] [G loss: 0.257612]\n",
      "[Epoch 20/100] [Batch 338/347] [D loss: 0.500002] [G loss: 0.272222]\n",
      "[Epoch 20/100] [Batch 339/347] [D loss: 0.500060] [G loss: 0.277580]\n",
      "[Epoch 20/100] [Batch 340/347] [D loss: 0.500051] [G loss: 0.277991]\n",
      "[Epoch 20/100] [Batch 341/347] [D loss: 0.500028] [G loss: 0.273179]\n",
      "[Epoch 20/100] [Batch 342/347] [D loss: 0.499935] [G loss: 0.265554]\n",
      "[Epoch 20/100] [Batch 343/347] [D loss: 0.499927] [G loss: 0.270284]\n",
      "[Epoch 20/100] [Batch 344/347] [D loss: 0.499796] [G loss: 0.264027]\n",
      "[Epoch 20/100] [Batch 345/347] [D loss: 0.499431] [G loss: 0.273963]\n",
      "[Epoch 20/100] [Batch 346/347] [D loss: 0.499230] [G loss: 0.292286]\n",
      "[Epoch 20/100] [Batch 347/347] [D loss: 0.499185] [G loss: 0.298246]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 21/100] [Batch 1/347] [D loss: 0.499681] [G loss: 0.264744]\n",
      "[Epoch 21/100] [Batch 2/347] [D loss: 0.499674] [G loss: 0.269896]\n",
      "[Epoch 21/100] [Batch 3/347] [D loss: 0.499764] [G loss: 0.269727]\n",
      "[Epoch 21/100] [Batch 4/347] [D loss: 0.499763] [G loss: 0.270943]\n",
      "[Epoch 21/100] [Batch 5/347] [D loss: 0.499761] [G loss: 0.270268]\n",
      "[Epoch 21/100] [Batch 6/347] [D loss: 0.499778] [G loss: 0.270624]\n",
      "[Epoch 21/100] [Batch 7/347] [D loss: 0.499734] [G loss: 0.270522]\n",
      "[Epoch 21/100] [Batch 8/347] [D loss: 0.499738] [G loss: 0.265866]\n",
      "[Epoch 21/100] [Batch 9/347] [D loss: 0.499632] [G loss: 0.264883]\n",
      "[Epoch 21/100] [Batch 10/347] [D loss: 0.499631] [G loss: 0.266540]\n",
      "[Epoch 21/100] [Batch 11/347] [D loss: 0.499772] [G loss: 0.266345]\n",
      "[Epoch 21/100] [Batch 12/347] [D loss: 0.499816] [G loss: 0.266972]\n",
      "[Epoch 21/100] [Batch 13/347] [D loss: 0.499890] [G loss: 0.267323]\n",
      "[Epoch 21/100] [Batch 14/347] [D loss: 0.499954] [G loss: 0.269689]\n",
      "[Epoch 21/100] [Batch 15/347] [D loss: 0.499923] [G loss: 0.265887]\n",
      "[Epoch 21/100] [Batch 16/347] [D loss: 0.499893] [G loss: 0.261827]\n",
      "[Epoch 21/100] [Batch 17/347] [D loss: 0.499811] [G loss: 0.251975]\n",
      "[Epoch 21/100] [Batch 18/347] [D loss: 0.499741] [G loss: 0.257030]\n",
      "[Epoch 21/100] [Batch 19/347] [D loss: 0.499885] [G loss: 0.255879]\n",
      "[Epoch 21/100] [Batch 20/347] [D loss: 0.500002] [G loss: 0.269280]\n",
      "[Epoch 21/100] [Batch 21/347] [D loss: 0.499944] [G loss: 0.265844]\n",
      "[Epoch 21/100] [Batch 22/347] [D loss: 0.499894] [G loss: 0.261061]\n",
      "[Epoch 21/100] [Batch 23/347] [D loss: 0.499848] [G loss: 0.255013]\n",
      "[Epoch 21/100] [Batch 24/347] [D loss: 0.499862] [G loss: 0.254405]\n",
      "[Epoch 21/100] [Batch 25/347] [D loss: 0.499847] [G loss: 0.253970]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 21/100] [Batch 26/347] [D loss: 0.499656] [G loss: 0.261422]\n",
      "[Epoch 21/100] [Batch 27/347] [D loss: 0.499703] [G loss: 0.267058]\n",
      "[Epoch 21/100] [Batch 28/347] [D loss: 0.499903] [G loss: 0.266999]\n",
      "[Epoch 21/100] [Batch 29/347] [D loss: 0.500036] [G loss: 0.265218]\n",
      "[Epoch 21/100] [Batch 30/347] [D loss: 0.500130] [G loss: 0.272166]\n",
      "[Epoch 21/100] [Batch 31/347] [D loss: 0.500188] [G loss: 0.274740]\n",
      "[Epoch 21/100] [Batch 32/347] [D loss: 0.500118] [G loss: 0.268058]\n",
      "[Epoch 21/100] [Batch 33/347] [D loss: 0.500028] [G loss: 0.264030]\n",
      "[Epoch 21/100] [Batch 34/347] [D loss: 0.500020] [G loss: 0.265142]\n",
      "[Epoch 21/100] [Batch 35/347] [D loss: 0.500009] [G loss: 0.264042]\n",
      "[Epoch 21/100] [Batch 36/347] [D loss: 0.499904] [G loss: 0.254973]\n",
      "[Epoch 21/100] [Batch 37/347] [D loss: 0.499576] [G loss: 0.271797]\n",
      "[Epoch 21/100] [Batch 38/347] [D loss: 0.499344] [G loss: 0.286827]\n",
      "[Epoch 21/100] [Batch 39/347] [D loss: 0.499407] [G loss: 0.277019]\n",
      "[Epoch 21/100] [Batch 40/347] [D loss: 0.499450] [G loss: 0.277786]\n",
      "[Epoch 21/100] [Batch 41/347] [D loss: 0.499405] [G loss: 0.278864]\n",
      "[Epoch 21/100] [Batch 42/347] [D loss: 0.499480] [G loss: 0.271656]\n",
      "[Epoch 21/100] [Batch 43/347] [D loss: 0.499750] [G loss: 0.254792]\n",
      "[Epoch 21/100] [Batch 44/347] [D loss: 0.500012] [G loss: 0.263023]\n",
      "[Epoch 21/100] [Batch 45/347] [D loss: 0.500220] [G loss: 0.280260]\n",
      "[Epoch 21/100] [Batch 46/347] [D loss: 0.500180] [G loss: 0.274871]\n",
      "[Epoch 21/100] [Batch 47/347] [D loss: 0.499800] [G loss: 0.253088]\n",
      "[Epoch 21/100] [Batch 48/347] [D loss: 0.499407] [G loss: 0.285506]\n",
      "[Epoch 21/100] [Batch 49/347] [D loss: 0.499274] [G loss: 0.294041]\n",
      "[Epoch 21/100] [Batch 50/347] [D loss: 0.499176] [G loss: 0.309550]\n",
      "[Epoch 21/100] [Batch 51/347] [D loss: 0.499444] [G loss: 0.293992]\n",
      "[Epoch 21/100] [Batch 52/347] [D loss: 0.499918] [G loss: 0.261861]\n",
      "[Epoch 21/100] [Batch 53/347] [D loss: 0.499825] [G loss: 0.256647]\n",
      "[Epoch 21/100] [Batch 54/347] [D loss: 0.499179] [G loss: 0.309379]\n",
      "[Epoch 21/100] [Batch 55/347] [D loss: 0.498723] [G loss: 0.331853]\n",
      "[Epoch 21/100] [Batch 56/347] [D loss: 0.498840] [G loss: 0.318716]\n",
      "[Epoch 21/100] [Batch 57/347] [D loss: 0.499445] [G loss: 0.284183]\n",
      "[Epoch 21/100] [Batch 58/347] [D loss: 0.499893] [G loss: 0.260612]\n",
      "[Epoch 21/100] [Batch 59/347] [D loss: 0.499745] [G loss: 0.266992]\n",
      "[Epoch 21/100] [Batch 60/347] [D loss: 0.499525] [G loss: 0.285970]\n",
      "[Epoch 21/100] [Batch 61/347] [D loss: 0.499376] [G loss: 0.298772]\n",
      "[Epoch 21/100] [Batch 62/347] [D loss: 0.499006] [G loss: 0.322999]\n",
      "[Epoch 21/100] [Batch 63/347] [D loss: 0.498785] [G loss: 0.325084]\n",
      "[Epoch 21/100] [Batch 64/347] [D loss: 0.499342] [G loss: 0.288076]\n",
      "[Epoch 21/100] [Batch 65/347] [D loss: 0.500071] [G loss: 0.264625]\n",
      "[Epoch 21/100] [Batch 66/347] [D loss: 0.499999] [G loss: 0.266948]\n",
      "[Epoch 21/100] [Batch 67/347] [D loss: 0.499653] [G loss: 0.272287]\n",
      "[Epoch 21/100] [Batch 68/347] [D loss: 0.499423] [G loss: 0.290604]\n",
      "[Epoch 21/100] [Batch 69/347] [D loss: 0.499062] [G loss: 0.309808]\n",
      "[Epoch 21/100] [Batch 70/347] [D loss: 0.498991] [G loss: 0.308596]\n",
      "[Epoch 21/100] [Batch 71/347] [D loss: 0.499071] [G loss: 0.310822]\n",
      "[Epoch 21/100] [Batch 72/347] [D loss: 0.498997] [G loss: 0.313257]\n",
      "[Epoch 21/100] [Batch 73/347] [D loss: 0.499334] [G loss: 0.288488]\n",
      "[Epoch 21/100] [Batch 74/347] [D loss: 0.499660] [G loss: 0.274495]\n",
      "[Epoch 21/100] [Batch 75/347] [D loss: 0.499273] [G loss: 0.304564]\n",
      "[Epoch 21/100] [Batch 76/347] [D loss: 0.499077] [G loss: 0.306717]\n",
      "[Epoch 21/100] [Batch 77/347] [D loss: 0.499558] [G loss: 0.272444]\n",
      "[Epoch 21/100] [Batch 78/347] [D loss: 0.500113] [G loss: 0.270565]\n",
      "[Epoch 21/100] [Batch 79/347] [D loss: 0.500240] [G loss: 0.272192]\n",
      "[Epoch 21/100] [Batch 80/347] [D loss: 0.500164] [G loss: 0.269240]\n",
      "[Epoch 21/100] [Batch 81/347] [D loss: 0.500269] [G loss: 0.274169]\n",
      "[Epoch 21/100] [Batch 82/347] [D loss: 0.500243] [G loss: 0.279511]\n",
      "[Epoch 21/100] [Batch 83/347] [D loss: 0.500164] [G loss: 0.271969]\n",
      "[Epoch 21/100] [Batch 84/347] [D loss: 0.500219] [G loss: 0.278238]\n",
      "[Epoch 21/100] [Batch 85/347] [D loss: 0.500193] [G loss: 0.279192]\n",
      "[Epoch 21/100] [Batch 86/347] [D loss: 0.500133] [G loss: 0.273780]\n",
      "[Epoch 21/100] [Batch 87/347] [D loss: 0.500086] [G loss: 0.271814]\n",
      "[Epoch 21/100] [Batch 88/347] [D loss: 0.500111] [G loss: 0.275378]\n",
      "[Epoch 21/100] [Batch 89/347] [D loss: 0.500133] [G loss: 0.278925]\n",
      "[Epoch 21/100] [Batch 90/347] [D loss: 0.500091] [G loss: 0.275255]\n",
      "[Epoch 21/100] [Batch 91/347] [D loss: 0.500065] [G loss: 0.273896]\n",
      "[Epoch 21/100] [Batch 92/347] [D loss: 0.500070] [G loss: 0.275478]\n",
      "[Epoch 21/100] [Batch 93/347] [D loss: 0.500040] [G loss: 0.273510]\n",
      "[Epoch 21/100] [Batch 94/347] [D loss: 0.499991] [G loss: 0.269968]\n",
      "[Epoch 21/100] [Batch 95/347] [D loss: 0.500002] [G loss: 0.270526]\n",
      "[Epoch 21/100] [Batch 96/347] [D loss: 0.499957] [G loss: 0.265818]\n",
      "[Epoch 21/100] [Batch 97/347] [D loss: 0.499887] [G loss: 0.260694]\n",
      "[Epoch 21/100] [Batch 98/347] [D loss: 0.499918] [G loss: 0.265606]\n",
      "[Epoch 21/100] [Batch 99/347] [D loss: 0.499960] [G loss: 0.269367]\n",
      "[Epoch 21/100] [Batch 100/347] [D loss: 0.499926] [G loss: 0.265708]\n",
      "[Epoch 21/100] [Batch 101/347] [D loss: 0.499857] [G loss: 0.260475]\n",
      "[Epoch 21/100] [Batch 102/347] [D loss: 0.499865] [G loss: 0.261984]\n",
      "[Epoch 21/100] [Batch 103/347] [D loss: 0.499878] [G loss: 0.262610]\n",
      "[Epoch 21/100] [Batch 104/347] [D loss: 0.499760] [G loss: 0.262089]\n",
      "[Epoch 21/100] [Batch 105/347] [D loss: 0.499739] [G loss: 0.264187]\n",
      "[Epoch 21/100] [Batch 106/347] [D loss: 0.499737] [G loss: 0.263602]\n",
      "[Epoch 21/100] [Batch 107/347] [D loss: 0.499680] [G loss: 0.257271]\n",
      "[Epoch 21/100] [Batch 108/347] [D loss: 0.499571] [G loss: 0.274443]\n",
      "[Epoch 21/100] [Batch 109/347] [D loss: 0.499693] [G loss: 0.267782]\n",
      "[Epoch 21/100] [Batch 110/347] [D loss: 0.499888] [G loss: 0.254009]\n",
      "[Epoch 21/100] [Batch 111/347] [D loss: 0.499732] [G loss: 0.262390]\n",
      "[Epoch 21/100] [Batch 112/347] [D loss: 0.499760] [G loss: 0.262744]\n",
      "[Epoch 21/100] [Batch 113/347] [D loss: 0.500076] [G loss: 0.268832]\n",
      "[Epoch 21/100] [Batch 114/347] [D loss: 0.500282] [G loss: 0.289436]\n",
      "[Epoch 21/100] [Batch 115/347] [D loss: 0.500306] [G loss: 0.290576]\n",
      "[Epoch 21/100] [Batch 116/347] [D loss: 0.500250] [G loss: 0.284799]\n",
      "[Epoch 21/100] [Batch 117/347] [D loss: 0.499978] [G loss: 0.258099]\n",
      "[Epoch 21/100] [Batch 118/347] [D loss: 0.499601] [G loss: 0.267693]\n",
      "[Epoch 21/100] [Batch 119/347] [D loss: 0.499524] [G loss: 0.269931]\n",
      "[Epoch 21/100] [Batch 120/347] [D loss: 0.499578] [G loss: 0.268825]\n",
      "[Epoch 21/100] [Batch 121/347] [D loss: 0.499594] [G loss: 0.267100]\n",
      "[Epoch 21/100] [Batch 122/347] [D loss: 0.499733] [G loss: 0.255011]\n",
      "[Epoch 21/100] [Batch 123/347] [D loss: 0.499772] [G loss: 0.254072]\n",
      "[Epoch 21/100] [Batch 124/347] [D loss: 0.499714] [G loss: 0.254928]\n",
      "[Epoch 21/100] [Batch 125/347] [D loss: 0.499868] [G loss: 0.256543]\n",
      "[Epoch 21/100] [Batch 126/347] [D loss: 0.500046] [G loss: 0.269206]\n",
      "[Epoch 21/100] [Batch 127/347] [D loss: 0.500088] [G loss: 0.270609]\n",
      "[Epoch 21/100] [Batch 128/347] [D loss: 0.500007] [G loss: 0.265161]\n",
      "[Epoch 21/100] [Batch 129/347] [D loss: 0.499995] [G loss: 0.260240]\n",
      "[Epoch 21/100] [Batch 130/347] [D loss: 0.499956] [G loss: 0.263684]\n",
      "[Epoch 21/100] [Batch 131/347] [D loss: 0.499741] [G loss: 0.264775]\n",
      "[Epoch 21/100] [Batch 132/347] [D loss: 0.499424] [G loss: 0.289276]\n",
      "[Epoch 21/100] [Batch 133/347] [D loss: 0.499329] [G loss: 0.295836]\n",
      "[Epoch 21/100] [Batch 134/347] [D loss: 0.499142] [G loss: 0.310538]\n",
      "[Epoch 21/100] [Batch 135/347] [D loss: 0.499061] [G loss: 0.319355]\n",
      "[Epoch 21/100] [Batch 136/347] [D loss: 0.499593] [G loss: 0.277146]\n",
      "[Epoch 21/100] [Batch 137/347] [D loss: 0.499915] [G loss: 0.264740]\n",
      "[Epoch 21/100] [Batch 138/347] [D loss: 0.499496] [G loss: 0.282117]\n",
      "[Epoch 21/100] [Batch 139/347] [D loss: 0.499130] [G loss: 0.306084]\n",
      "[Epoch 21/100] [Batch 140/347] [D loss: 0.498989] [G loss: 0.317426]\n",
      "[Epoch 21/100] [Batch 141/347] [D loss: 0.498870] [G loss: 0.324162]\n",
      "[Epoch 21/100] [Batch 142/347] [D loss: 0.498789] [G loss: 0.331604]\n",
      "[Epoch 21/100] [Batch 143/347] [D loss: 0.498465] [G loss: 0.353028]\n",
      "[Epoch 21/100] [Batch 144/347] [D loss: 0.498372] [G loss: 0.355066]\n",
      "[Epoch 21/100] [Batch 145/347] [D loss: 0.498470] [G loss: 0.340568]\n",
      "[Epoch 21/100] [Batch 146/347] [D loss: 0.498611] [G loss: 0.323614]\n",
      "[Epoch 21/100] [Batch 147/347] [D loss: 0.499025] [G loss: 0.295484]\n",
      "[Epoch 21/100] [Batch 148/347] [D loss: 0.499249] [G loss: 0.283109]\n",
      "[Epoch 21/100] [Batch 149/347] [D loss: 0.499066] [G loss: 0.296671]\n",
      "[Epoch 21/100] [Batch 150/347] [D loss: 0.499081] [G loss: 0.297366]\n",
      "[Epoch 21/100] [Batch 151/347] [D loss: 0.499323] [G loss: 0.286775]\n",
      "[Epoch 21/100] [Batch 152/347] [D loss: 0.499233] [G loss: 0.298217]\n",
      "[Epoch 21/100] [Batch 153/347] [D loss: 0.498897] [G loss: 0.319248]\n",
      "[Epoch 21/100] [Batch 154/347] [D loss: 0.498704] [G loss: 0.323632]\n",
      "[Epoch 21/100] [Batch 155/347] [D loss: 0.498856] [G loss: 0.311093]\n",
      "[Epoch 21/100] [Batch 156/347] [D loss: 0.499154] [G loss: 0.294777]\n",
      "[Epoch 21/100] [Batch 157/347] [D loss: 0.499210] [G loss: 0.301359]\n",
      "[Epoch 21/100] [Batch 158/347] [D loss: 0.498811] [G loss: 0.325422]\n",
      "[Epoch 21/100] [Batch 159/347] [D loss: 0.498726] [G loss: 0.323363]\n",
      "[Epoch 21/100] [Batch 160/347] [D loss: 0.499125] [G loss: 0.303743]\n",
      "[Epoch 21/100] [Batch 161/347] [D loss: 0.499361] [G loss: 0.295718]\n",
      "[Epoch 21/100] [Batch 162/347] [D loss: 0.499280] [G loss: 0.301940]\n",
      "[Epoch 21/100] [Batch 163/347] [D loss: 0.498975] [G loss: 0.321053]\n",
      "[Epoch 21/100] [Batch 164/347] [D loss: 0.498695] [G loss: 0.336724]\n",
      "[Epoch 21/100] [Batch 165/347] [D loss: 0.498725] [G loss: 0.328206]\n",
      "[Epoch 21/100] [Batch 166/347] [D loss: 0.499271] [G loss: 0.290154]\n",
      "[Epoch 21/100] [Batch 167/347] [D loss: 0.499868] [G loss: 0.268117]\n",
      "[Epoch 21/100] [Batch 168/347] [D loss: 0.500057] [G loss: 0.278762]\n",
      "[Epoch 21/100] [Batch 169/347] [D loss: 0.500150] [G loss: 0.277380]\n",
      "[Epoch 21/100] [Batch 170/347] [D loss: 0.500234] [G loss: 0.273330]\n",
      "[Epoch 21/100] [Batch 171/347] [D loss: 0.500396] [G loss: 0.280261]\n",
      "[Epoch 21/100] [Batch 172/347] [D loss: 0.500462] [G loss: 0.285113]\n",
      "[Epoch 21/100] [Batch 173/347] [D loss: 0.500286] [G loss: 0.273935]\n",
      "[Epoch 21/100] [Batch 174/347] [D loss: 0.500230] [G loss: 0.271529]\n",
      "[Epoch 21/100] [Batch 175/347] [D loss: 0.500329] [G loss: 0.281555]\n",
      "[Epoch 21/100] [Batch 176/347] [D loss: 0.500517] [G loss: 0.295118]\n",
      "[Epoch 21/100] [Batch 177/347] [D loss: 0.500519] [G loss: 0.296170]\n",
      "[Epoch 21/100] [Batch 178/347] [D loss: 0.500434] [G loss: 0.290309]\n",
      "[Epoch 21/100] [Batch 179/347] [D loss: 0.500336] [G loss: 0.283783]\n",
      "[Epoch 21/100] [Batch 180/347] [D loss: 0.500253] [G loss: 0.277510]\n",
      "[Epoch 21/100] [Batch 181/347] [D loss: 0.500252] [G loss: 0.278093]\n",
      "[Epoch 21/100] [Batch 182/347] [D loss: 0.500174] [G loss: 0.276104]\n",
      "[Epoch 21/100] [Batch 183/347] [D loss: 0.500237] [G loss: 0.280267]\n",
      "[Epoch 21/100] [Batch 184/347] [D loss: 0.500277] [G loss: 0.284276]\n",
      "[Epoch 21/100] [Batch 185/347] [D loss: 0.500261] [G loss: 0.282863]\n",
      "[Epoch 21/100] [Batch 186/347] [D loss: 0.500277] [G loss: 0.282702]\n",
      "[Epoch 21/100] [Batch 187/347] [D loss: 0.500215] [G loss: 0.277436]\n",
      "[Epoch 21/100] [Batch 188/347] [D loss: 0.500151] [G loss: 0.274203]\n",
      "[Epoch 21/100] [Batch 189/347] [D loss: 0.500137] [G loss: 0.273373]\n",
      "[Epoch 21/100] [Batch 190/347] [D loss: 0.499927] [G loss: 0.261501]\n",
      "[Epoch 21/100] [Batch 191/347] [D loss: 0.499690] [G loss: 0.260736]\n",
      "[Epoch 21/100] [Batch 192/347] [D loss: 0.499793] [G loss: 0.250970]\n",
      "[Epoch 21/100] [Batch 193/347] [D loss: 0.499962] [G loss: 0.259652]\n",
      "[Epoch 21/100] [Batch 194/347] [D loss: 0.499825] [G loss: 0.255576]\n",
      "[Epoch 21/100] [Batch 195/347] [D loss: 0.499695] [G loss: 0.263050]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 21/100] [Batch 196/347] [D loss: 0.499632] [G loss: 0.260770]\n",
      "[Epoch 21/100] [Batch 197/347] [D loss: 0.499652] [G loss: 0.256946]\n",
      "[Epoch 21/100] [Batch 198/347] [D loss: 0.499711] [G loss: 0.257214]\n",
      "[Epoch 21/100] [Batch 199/347] [D loss: 0.499706] [G loss: 0.258354]\n",
      "[Epoch 21/100] [Batch 200/347] [D loss: 0.499752] [G loss: 0.253296]\n",
      "[Epoch 21/100] [Batch 201/347] [D loss: 0.499772] [G loss: 0.252033]\n",
      "[Epoch 21/100] [Batch 202/347] [D loss: 0.499625] [G loss: 0.263818]\n",
      "[Epoch 21/100] [Batch 203/347] [D loss: 0.499516] [G loss: 0.272544]\n",
      "[Epoch 21/100] [Batch 204/347] [D loss: 0.499570] [G loss: 0.269100]\n",
      "[Epoch 21/100] [Batch 205/347] [D loss: 0.499647] [G loss: 0.261317]\n",
      "[Epoch 21/100] [Batch 206/347] [D loss: 0.499795] [G loss: 0.249561]\n",
      "[Epoch 21/100] [Batch 207/347] [D loss: 0.500038] [G loss: 0.260360]\n",
      "[Epoch 21/100] [Batch 208/347] [D loss: 0.499991] [G loss: 0.261125]\n",
      "[Epoch 21/100] [Batch 209/347] [D loss: 0.499891] [G loss: 0.255391]\n",
      "[Epoch 21/100] [Batch 210/347] [D loss: 0.500064] [G loss: 0.263790]\n",
      "[Epoch 21/100] [Batch 211/347] [D loss: 0.500025] [G loss: 0.260989]\n",
      "[Epoch 21/100] [Batch 212/347] [D loss: 0.499950] [G loss: 0.259879]\n",
      "[Epoch 21/100] [Batch 213/347] [D loss: 0.499908] [G loss: 0.265643]\n",
      "[Epoch 21/100] [Batch 214/347] [D loss: 0.499582] [G loss: 0.277727]\n",
      "[Epoch 21/100] [Batch 215/347] [D loss: 0.499467] [G loss: 0.286088]\n",
      "[Epoch 21/100] [Batch 216/347] [D loss: 0.499806] [G loss: 0.265006]\n",
      "[Epoch 21/100] [Batch 217/347] [D loss: 0.499999] [G loss: 0.265750]\n",
      "[Epoch 21/100] [Batch 218/347] [D loss: 0.500170] [G loss: 0.271741]\n",
      "[Epoch 21/100] [Batch 219/347] [D loss: 0.500373] [G loss: 0.284011]\n",
      "[Epoch 21/100] [Batch 220/347] [D loss: 0.500609] [G loss: 0.299827]\n",
      "[Epoch 21/100] [Batch 221/347] [D loss: 0.500645] [G loss: 0.301209]\n",
      "[Epoch 21/100] [Batch 222/347] [D loss: 0.500565] [G loss: 0.293166]\n",
      "[Epoch 21/100] [Batch 223/347] [D loss: 0.500552] [G loss: 0.291847]\n",
      "[Epoch 21/100] [Batch 224/347] [D loss: 0.500489] [G loss: 0.287730]\n",
      "[Epoch 21/100] [Batch 225/347] [D loss: 0.500106] [G loss: 0.274780]\n",
      "[Epoch 21/100] [Batch 226/347] [D loss: 0.499532] [G loss: 0.274762]\n",
      "[Epoch 21/100] [Batch 227/347] [D loss: 0.499198] [G loss: 0.284890]\n",
      "[Epoch 21/100] [Batch 228/347] [D loss: 0.499191] [G loss: 0.285868]\n",
      "[Epoch 21/100] [Batch 229/347] [D loss: 0.499354] [G loss: 0.280689]\n",
      "[Epoch 21/100] [Batch 230/347] [D loss: 0.499440] [G loss: 0.276578]\n",
      "[Epoch 21/100] [Batch 231/347] [D loss: 0.499345] [G loss: 0.276354]\n",
      "[Epoch 21/100] [Batch 232/347] [D loss: 0.499427] [G loss: 0.272164]\n",
      "[Epoch 21/100] [Batch 233/347] [D loss: 0.499465] [G loss: 0.270143]\n",
      "[Epoch 21/100] [Batch 234/347] [D loss: 0.499448] [G loss: 0.275004]\n",
      "[Epoch 21/100] [Batch 235/347] [D loss: 0.499668] [G loss: 0.263683]\n",
      "[Epoch 21/100] [Batch 236/347] [D loss: 0.499902] [G loss: 0.260925]\n",
      "[Epoch 21/100] [Batch 237/347] [D loss: 0.500070] [G loss: 0.263741]\n",
      "[Epoch 21/100] [Batch 238/347] [D loss: 0.500078] [G loss: 0.267557]\n",
      "[Epoch 21/100] [Batch 239/347] [D loss: 0.500033] [G loss: 0.265344]\n",
      "[Epoch 21/100] [Batch 240/347] [D loss: 0.499995] [G loss: 0.261413]\n",
      "[Epoch 21/100] [Batch 241/347] [D loss: 0.499914] [G loss: 0.255526]\n",
      "[Epoch 21/100] [Batch 242/347] [D loss: 0.499865] [G loss: 0.253555]\n",
      "[Epoch 21/100] [Batch 243/347] [D loss: 0.499968] [G loss: 0.261251]\n",
      "[Epoch 21/100] [Batch 244/347] [D loss: 0.500089] [G loss: 0.270174]\n",
      "[Epoch 21/100] [Batch 245/347] [D loss: 0.500201] [G loss: 0.268895]\n",
      "[Epoch 21/100] [Batch 246/347] [D loss: 0.499844] [G loss: 0.262316]\n",
      "[Epoch 21/100] [Batch 247/347] [D loss: 0.499438] [G loss: 0.270935]\n",
      "[Epoch 21/100] [Batch 248/347] [D loss: 0.499277] [G loss: 0.276207]\n",
      "[Epoch 21/100] [Batch 249/347] [D loss: 0.499186] [G loss: 0.282175]\n",
      "[Epoch 21/100] [Batch 250/347] [D loss: 0.499474] [G loss: 0.273402]\n",
      "[Epoch 21/100] [Batch 251/347] [D loss: 0.499876] [G loss: 0.263035]\n",
      "[Epoch 21/100] [Batch 252/347] [D loss: 0.500027] [G loss: 0.266253]\n",
      "[Epoch 21/100] [Batch 253/347] [D loss: 0.500037] [G loss: 0.266769]\n",
      "[Epoch 21/100] [Batch 254/347] [D loss: 0.500042] [G loss: 0.265098]\n",
      "[Epoch 21/100] [Batch 255/347] [D loss: 0.499918] [G loss: 0.263605]\n",
      "[Epoch 21/100] [Batch 256/347] [D loss: 0.500002] [G loss: 0.268790]\n",
      "[Epoch 21/100] [Batch 257/347] [D loss: 0.500193] [G loss: 0.270685]\n",
      "[Epoch 21/100] [Batch 258/347] [D loss: 0.499984] [G loss: 0.265519]\n",
      "[Epoch 21/100] [Batch 259/347] [D loss: 0.499538] [G loss: 0.272799]\n",
      "[Epoch 21/100] [Batch 260/347] [D loss: 0.499320] [G loss: 0.287082]\n",
      "[Epoch 21/100] [Batch 261/347] [D loss: 0.499487] [G loss: 0.279352]\n",
      "[Epoch 21/100] [Batch 262/347] [D loss: 0.499634] [G loss: 0.264035]\n",
      "[Epoch 21/100] [Batch 263/347] [D loss: 0.499618] [G loss: 0.264753]\n",
      "[Epoch 21/100] [Batch 264/347] [D loss: 0.499440] [G loss: 0.279108]\n",
      "[Epoch 21/100] [Batch 265/347] [D loss: 0.499349] [G loss: 0.284264]\n",
      "[Epoch 21/100] [Batch 266/347] [D loss: 0.499415] [G loss: 0.277069]\n",
      "[Epoch 21/100] [Batch 267/347] [D loss: 0.499500] [G loss: 0.270152]\n",
      "[Epoch 21/100] [Batch 268/347] [D loss: 0.499456] [G loss: 0.276951]\n",
      "[Epoch 21/100] [Batch 269/347] [D loss: 0.499332] [G loss: 0.288003]\n",
      "[Epoch 21/100] [Batch 270/347] [D loss: 0.499353] [G loss: 0.284525]\n",
      "[Epoch 21/100] [Batch 271/347] [D loss: 0.499480] [G loss: 0.272652]\n",
      "[Epoch 21/100] [Batch 272/347] [D loss: 0.499611] [G loss: 0.263976]\n",
      "[Epoch 21/100] [Batch 273/347] [D loss: 0.499511] [G loss: 0.275803]\n",
      "[Epoch 21/100] [Batch 274/347] [D loss: 0.498935] [G loss: 0.309642]\n",
      "[Epoch 21/100] [Batch 275/347] [D loss: 0.498960] [G loss: 0.306525]\n",
      "[Epoch 21/100] [Batch 276/347] [D loss: 0.499507] [G loss: 0.274095]\n",
      "[Epoch 21/100] [Batch 277/347] [D loss: 0.499673] [G loss: 0.259503]\n",
      "[Epoch 21/100] [Batch 278/347] [D loss: 0.499822] [G loss: 0.250633]\n",
      "[Epoch 21/100] [Batch 279/347] [D loss: 0.499818] [G loss: 0.257377]\n",
      "[Epoch 21/100] [Batch 280/347] [D loss: 0.499769] [G loss: 0.260846]\n",
      "[Epoch 21/100] [Batch 281/347] [D loss: 0.499776] [G loss: 0.259109]\n",
      "[Epoch 21/100] [Batch 282/347] [D loss: 0.499772] [G loss: 0.257041]\n",
      "[Epoch 21/100] [Batch 283/347] [D loss: 0.499677] [G loss: 0.261316]\n",
      "[Epoch 21/100] [Batch 284/347] [D loss: 0.499736] [G loss: 0.260058]\n",
      "[Epoch 21/100] [Batch 285/347] [D loss: 0.499800] [G loss: 0.256167]\n",
      "[Epoch 21/100] [Batch 286/347] [D loss: 0.499732] [G loss: 0.251512]\n",
      "[Epoch 21/100] [Batch 287/347] [D loss: 0.499703] [G loss: 0.255136]\n",
      "[Epoch 21/100] [Batch 288/347] [D loss: 0.499253] [G loss: 0.281704]\n",
      "[Epoch 21/100] [Batch 289/347] [D loss: 0.499185] [G loss: 0.285936]\n",
      "[Epoch 21/100] [Batch 290/347] [D loss: 0.499539] [G loss: 0.263048]\n",
      "[Epoch 21/100] [Batch 291/347] [D loss: 0.499474] [G loss: 0.265545]\n",
      "[Epoch 21/100] [Batch 292/347] [D loss: 0.499637] [G loss: 0.256837]\n",
      "[Epoch 21/100] [Batch 293/347] [D loss: 0.500083] [G loss: 0.269395]\n",
      "[Epoch 21/100] [Batch 294/347] [D loss: 0.500256] [G loss: 0.279257]\n",
      "[Epoch 21/100] [Batch 295/347] [D loss: 0.500071] [G loss: 0.276955]\n",
      "[Epoch 21/100] [Batch 296/347] [D loss: 0.500135] [G loss: 0.273046]\n",
      "[Epoch 21/100] [Batch 297/347] [D loss: 0.500308] [G loss: 0.283702]\n",
      "[Epoch 21/100] [Batch 298/347] [D loss: 0.500213] [G loss: 0.278638]\n",
      "[Epoch 21/100] [Batch 299/347] [D loss: 0.500228] [G loss: 0.277474]\n",
      "[Epoch 21/100] [Batch 300/347] [D loss: 0.500150] [G loss: 0.273035]\n",
      "[Epoch 21/100] [Batch 301/347] [D loss: 0.500182] [G loss: 0.275623]\n",
      "[Epoch 21/100] [Batch 302/347] [D loss: 0.500286] [G loss: 0.280981]\n",
      "[Epoch 21/100] [Batch 303/347] [D loss: 0.499866] [G loss: 0.265440]\n",
      "[Epoch 21/100] [Batch 304/347] [D loss: 0.499491] [G loss: 0.263861]\n",
      "[Epoch 21/100] [Batch 305/347] [D loss: 0.499407] [G loss: 0.276372]\n",
      "[Epoch 21/100] [Batch 306/347] [D loss: 0.499365] [G loss: 0.269224]\n",
      "[Epoch 21/100] [Batch 307/347] [D loss: 0.499284] [G loss: 0.281465]\n",
      "[Epoch 21/100] [Batch 308/347] [D loss: 0.499301] [G loss: 0.277286]\n",
      "[Epoch 21/100] [Batch 309/347] [D loss: 0.499686] [G loss: 0.255578]\n",
      "[Epoch 21/100] [Batch 310/347] [D loss: 0.500029] [G loss: 0.277054]\n",
      "[Epoch 21/100] [Batch 311/347] [D loss: 0.500045] [G loss: 0.279773]\n",
      "[Epoch 21/100] [Batch 312/347] [D loss: 0.500027] [G loss: 0.279335]\n",
      "[Epoch 21/100] [Batch 313/347] [D loss: 0.500044] [G loss: 0.278410]\n",
      "[Epoch 21/100] [Batch 314/347] [D loss: 0.500041] [G loss: 0.271931]\n",
      "[Epoch 21/100] [Batch 315/347] [D loss: 0.500008] [G loss: 0.262621]\n",
      "[Epoch 21/100] [Batch 316/347] [D loss: 0.499653] [G loss: 0.255363]\n",
      "[Epoch 21/100] [Batch 317/347] [D loss: 0.499346] [G loss: 0.273890]\n",
      "[Epoch 21/100] [Batch 318/347] [D loss: 0.499725] [G loss: 0.252002]\n",
      "[Epoch 21/100] [Batch 319/347] [D loss: 0.500243] [G loss: 0.284803]\n",
      "[Epoch 21/100] [Batch 320/347] [D loss: 0.500417] [G loss: 0.298220]\n",
      "[Epoch 21/100] [Batch 321/347] [D loss: 0.500283] [G loss: 0.287612]\n",
      "[Epoch 21/100] [Batch 322/347] [D loss: 0.500104] [G loss: 0.274327]\n",
      "[Epoch 21/100] [Batch 323/347] [D loss: 0.500100] [G loss: 0.273300]\n",
      "[Epoch 21/100] [Batch 324/347] [D loss: 0.500160] [G loss: 0.276188]\n",
      "[Epoch 21/100] [Batch 325/347] [D loss: 0.500009] [G loss: 0.265377]\n",
      "[Epoch 21/100] [Batch 326/347] [D loss: 0.499810] [G loss: 0.255905]\n",
      "[Epoch 21/100] [Batch 327/347] [D loss: 0.499804] [G loss: 0.253969]\n",
      "[Epoch 21/100] [Batch 328/347] [D loss: 0.499740] [G loss: 0.250993]\n",
      "[Epoch 21/100] [Batch 329/347] [D loss: 0.499399] [G loss: 0.273446]\n",
      "[Epoch 21/100] [Batch 330/347] [D loss: 0.499115] [G loss: 0.288989]\n",
      "[Epoch 21/100] [Batch 331/347] [D loss: 0.499404] [G loss: 0.270830]\n",
      "[Epoch 21/100] [Batch 332/347] [D loss: 0.499873] [G loss: 0.264565]\n",
      "[Epoch 21/100] [Batch 333/347] [D loss: 0.500001] [G loss: 0.275818]\n",
      "[Epoch 21/100] [Batch 334/347] [D loss: 0.500077] [G loss: 0.277061]\n",
      "[Epoch 21/100] [Batch 335/347] [D loss: 0.499956] [G loss: 0.264905]\n",
      "[Epoch 21/100] [Batch 336/347] [D loss: 0.499747] [G loss: 0.251026]\n",
      "[Epoch 21/100] [Batch 337/347] [D loss: 0.499787] [G loss: 0.256165]\n",
      "[Epoch 21/100] [Batch 338/347] [D loss: 0.499963] [G loss: 0.270744]\n",
      "[Epoch 21/100] [Batch 339/347] [D loss: 0.500035] [G loss: 0.276109]\n",
      "[Epoch 21/100] [Batch 340/347] [D loss: 0.500024] [G loss: 0.276487]\n",
      "[Epoch 21/100] [Batch 341/347] [D loss: 0.499993] [G loss: 0.271702]\n",
      "[Epoch 21/100] [Batch 342/347] [D loss: 0.499877] [G loss: 0.264047]\n",
      "[Epoch 21/100] [Batch 343/347] [D loss: 0.499872] [G loss: 0.268784]\n",
      "[Epoch 21/100] [Batch 344/347] [D loss: 0.499708] [G loss: 0.264556]\n",
      "[Epoch 21/100] [Batch 345/347] [D loss: 0.499251] [G loss: 0.274775]\n",
      "[Epoch 21/100] [Batch 346/347] [D loss: 0.498992] [G loss: 0.293077]\n",
      "[Epoch 21/100] [Batch 347/347] [D loss: 0.498916] [G loss: 0.299055]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 22/100] [Batch 1/347] [D loss: 0.499564] [G loss: 0.265274]\n",
      "[Epoch 22/100] [Batch 2/347] [D loss: 0.499559] [G loss: 0.270414]\n",
      "[Epoch 22/100] [Batch 3/347] [D loss: 0.499673] [G loss: 0.270251]\n",
      "[Epoch 22/100] [Batch 4/347] [D loss: 0.499671] [G loss: 0.271482]\n",
      "[Epoch 22/100] [Batch 5/347] [D loss: 0.499667] [G loss: 0.270807]\n",
      "[Epoch 22/100] [Batch 6/347] [D loss: 0.499693] [G loss: 0.271156]\n",
      "[Epoch 22/100] [Batch 7/347] [D loss: 0.499636] [G loss: 0.271047]\n",
      "[Epoch 22/100] [Batch 8/347] [D loss: 0.499636] [G loss: 0.266405]\n",
      "[Epoch 22/100] [Batch 9/347] [D loss: 0.499503] [G loss: 0.265440]\n",
      "[Epoch 22/100] [Batch 10/347] [D loss: 0.499501] [G loss: 0.267112]\n",
      "[Epoch 22/100] [Batch 11/347] [D loss: 0.499681] [G loss: 0.266954]\n",
      "[Epoch 22/100] [Batch 12/347] [D loss: 0.499741] [G loss: 0.267524]\n",
      "[Epoch 22/100] [Batch 13/347] [D loss: 0.499832] [G loss: 0.265706]\n",
      "[Epoch 22/100] [Batch 14/347] [D loss: 0.499907] [G loss: 0.268063]\n",
      "[Epoch 22/100] [Batch 15/347] [D loss: 0.499864] [G loss: 0.264204]\n",
      "[Epoch 22/100] [Batch 16/347] [D loss: 0.499827] [G loss: 0.260139]\n",
      "[Epoch 22/100] [Batch 17/347] [D loss: 0.499718] [G loss: 0.252617]\n",
      "[Epoch 22/100] [Batch 18/347] [D loss: 0.499631] [G loss: 0.257798]\n",
      "[Epoch 22/100] [Batch 19/347] [D loss: 0.499807] [G loss: 0.254214]\n",
      "[Epoch 22/100] [Batch 20/347] [D loss: 0.499963] [G loss: 0.267609]\n",
      "[Epoch 22/100] [Batch 21/347] [D loss: 0.499890] [G loss: 0.264152]\n",
      "[Epoch 22/100] [Batch 22/347] [D loss: 0.499826] [G loss: 0.259379]\n",
      "[Epoch 22/100] [Batch 23/347] [D loss: 0.499771] [G loss: 0.254484]\n",
      "[Epoch 22/100] [Batch 24/347] [D loss: 0.499789] [G loss: 0.253015]\n",
      "[Epoch 22/100] [Batch 25/347] [D loss: 0.499779] [G loss: 0.252900]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 22/100] [Batch 26/347] [D loss: 0.499549] [G loss: 0.261290]\n",
      "[Epoch 22/100] [Batch 27/347] [D loss: 0.499594] [G loss: 0.266721]\n",
      "[Epoch 22/100] [Batch 28/347] [D loss: 0.499846] [G loss: 0.267015]\n",
      "[Epoch 22/100] [Batch 29/347] [D loss: 0.500029] [G loss: 0.265046]\n",
      "[Epoch 22/100] [Batch 30/347] [D loss: 0.500149] [G loss: 0.272173]\n",
      "[Epoch 22/100] [Batch 31/347] [D loss: 0.500218] [G loss: 0.274933]\n",
      "[Epoch 22/100] [Batch 32/347] [D loss: 0.500135] [G loss: 0.268362]\n",
      "[Epoch 22/100] [Batch 33/347] [D loss: 0.500026] [G loss: 0.264464]\n",
      "[Epoch 22/100] [Batch 34/347] [D loss: 0.500031] [G loss: 0.265731]\n",
      "[Epoch 22/100] [Batch 35/347] [D loss: 0.500019] [G loss: 0.264762]\n",
      "[Epoch 22/100] [Batch 36/347] [D loss: 0.499886] [G loss: 0.255853]\n",
      "[Epoch 22/100] [Batch 37/347] [D loss: 0.499478] [G loss: 0.270377]\n",
      "[Epoch 22/100] [Batch 38/347] [D loss: 0.499193] [G loss: 0.285370]\n",
      "[Epoch 22/100] [Batch 39/347] [D loss: 0.499287] [G loss: 0.275479]\n",
      "[Epoch 22/100] [Batch 40/347] [D loss: 0.499341] [G loss: 0.275509]\n",
      "[Epoch 22/100] [Batch 41/347] [D loss: 0.499289] [G loss: 0.276544]\n",
      "[Epoch 22/100] [Batch 42/347] [D loss: 0.499385] [G loss: 0.269278]\n",
      "[Epoch 22/100] [Batch 43/347] [D loss: 0.499711] [G loss: 0.253067]\n",
      "[Epoch 22/100] [Batch 44/347] [D loss: 0.500041] [G loss: 0.264514]\n",
      "[Epoch 22/100] [Batch 45/347] [D loss: 0.500295] [G loss: 0.281751]\n",
      "[Epoch 22/100] [Batch 46/347] [D loss: 0.500240] [G loss: 0.276353]\n",
      "[Epoch 22/100] [Batch 47/347] [D loss: 0.499772] [G loss: 0.251788]\n",
      "[Epoch 22/100] [Batch 48/347] [D loss: 0.499274] [G loss: 0.283906]\n",
      "[Epoch 22/100] [Batch 49/347] [D loss: 0.499100] [G loss: 0.292608]\n",
      "[Epoch 22/100] [Batch 50/347] [D loss: 0.498947] [G loss: 0.308266]\n",
      "[Epoch 22/100] [Batch 51/347] [D loss: 0.499269] [G loss: 0.292819]\n",
      "[Epoch 22/100] [Batch 52/347] [D loss: 0.499884] [G loss: 0.262678]\n",
      "[Epoch 22/100] [Batch 53/347] [D loss: 0.499768] [G loss: 0.256935]\n",
      "[Epoch 22/100] [Batch 54/347] [D loss: 0.498946] [G loss: 0.308819]\n",
      "[Epoch 22/100] [Batch 55/347] [D loss: 0.498380] [G loss: 0.331701]\n",
      "[Epoch 22/100] [Batch 56/347] [D loss: 0.498522] [G loss: 0.318849]\n",
      "[Epoch 22/100] [Batch 57/347] [D loss: 0.499251] [G loss: 0.284586]\n",
      "[Epoch 22/100] [Batch 58/347] [D loss: 0.499807] [G loss: 0.258944]\n",
      "[Epoch 22/100] [Batch 59/347] [D loss: 0.499616] [G loss: 0.267831]\n",
      "[Epoch 22/100] [Batch 60/347] [D loss: 0.499330] [G loss: 0.287063]\n",
      "[Epoch 22/100] [Batch 61/347] [D loss: 0.499137] [G loss: 0.300097]\n",
      "[Epoch 22/100] [Batch 62/347] [D loss: 0.498671] [G loss: 0.324506]\n",
      "[Epoch 22/100] [Batch 63/347] [D loss: 0.498406] [G loss: 0.326716]\n",
      "[Epoch 22/100] [Batch 64/347] [D loss: 0.499089] [G loss: 0.289782]\n",
      "[Epoch 22/100] [Batch 65/347] [D loss: 0.500002] [G loss: 0.261196]\n",
      "[Epoch 22/100] [Batch 66/347] [D loss: 0.499896] [G loss: 0.263343]\n",
      "[Epoch 22/100] [Batch 67/347] [D loss: 0.499455] [G loss: 0.274410]\n",
      "[Epoch 22/100] [Batch 68/347] [D loss: 0.499167] [G loss: 0.292848]\n",
      "[Epoch 22/100] [Batch 69/347] [D loss: 0.498724] [G loss: 0.312128]\n",
      "[Epoch 22/100] [Batch 70/347] [D loss: 0.498645] [G loss: 0.310959]\n",
      "[Epoch 22/100] [Batch 71/347] [D loss: 0.498733] [G loss: 0.313287]\n",
      "[Epoch 22/100] [Batch 72/347] [D loss: 0.498639] [G loss: 0.315830]\n",
      "[Epoch 22/100] [Batch 73/347] [D loss: 0.499060] [G loss: 0.291131]\n",
      "[Epoch 22/100] [Batch 74/347] [D loss: 0.499457] [G loss: 0.277201]\n",
      "[Epoch 22/100] [Batch 75/347] [D loss: 0.498964] [G loss: 0.307372]\n",
      "[Epoch 22/100] [Batch 76/347] [D loss: 0.498734] [G loss: 0.309641]\n",
      "[Epoch 22/100] [Batch 77/347] [D loss: 0.499334] [G loss: 0.275476]\n",
      "[Epoch 22/100] [Batch 78/347] [D loss: 0.500023] [G loss: 0.266172]\n",
      "[Epoch 22/100] [Batch 79/347] [D loss: 0.500187] [G loss: 0.267745]\n",
      "[Epoch 22/100] [Batch 80/347] [D loss: 0.500089] [G loss: 0.265024]\n",
      "[Epoch 22/100] [Batch 81/347] [D loss: 0.500212] [G loss: 0.269875]\n",
      "[Epoch 22/100] [Batch 82/347] [D loss: 0.500175] [G loss: 0.274839]\n",
      "[Epoch 22/100] [Batch 83/347] [D loss: 0.500090] [G loss: 0.267239]\n",
      "[Epoch 22/100] [Batch 84/347] [D loss: 0.500158] [G loss: 0.273753]\n",
      "[Epoch 22/100] [Batch 85/347] [D loss: 0.500127] [G loss: 0.274678]\n",
      "[Epoch 22/100] [Batch 86/347] [D loss: 0.500052] [G loss: 0.269264]\n",
      "[Epoch 22/100] [Batch 87/347] [D loss: 0.499996] [G loss: 0.267343]\n",
      "[Epoch 22/100] [Batch 88/347] [D loss: 0.500027] [G loss: 0.270905]\n",
      "[Epoch 22/100] [Batch 89/347] [D loss: 0.500058] [G loss: 0.274508]\n",
      "[Epoch 22/100] [Batch 90/347] [D loss: 0.500004] [G loss: 0.270878]\n",
      "[Epoch 22/100] [Batch 91/347] [D loss: 0.499969] [G loss: 0.269576]\n",
      "[Epoch 22/100] [Batch 92/347] [D loss: 0.499979] [G loss: 0.271220]\n",
      "[Epoch 22/100] [Batch 93/347] [D loss: 0.499940] [G loss: 0.269345]\n",
      "[Epoch 22/100] [Batch 94/347] [D loss: 0.499886] [G loss: 0.265931]\n",
      "[Epoch 22/100] [Batch 95/347] [D loss: 0.499899] [G loss: 0.266566]\n",
      "[Epoch 22/100] [Batch 96/347] [D loss: 0.499843] [G loss: 0.261966]\n",
      "[Epoch 22/100] [Batch 97/347] [D loss: 0.499751] [G loss: 0.259102]\n",
      "[Epoch 22/100] [Batch 98/347] [D loss: 0.499802] [G loss: 0.262280]\n",
      "[Epoch 22/100] [Batch 99/347] [D loss: 0.499861] [G loss: 0.266354]\n",
      "[Epoch 22/100] [Batch 100/347] [D loss: 0.499827] [G loss: 0.263011]\n",
      "[Epoch 22/100] [Batch 101/347] [D loss: 0.499749] [G loss: 0.261583]\n",
      "[Epoch 22/100] [Batch 102/347] [D loss: 0.499774] [G loss: 0.261953]\n",
      "[Epoch 22/100] [Batch 103/347] [D loss: 0.499800] [G loss: 0.261512]\n",
      "[Epoch 22/100] [Batch 104/347] [D loss: 0.499675] [G loss: 0.262886]\n",
      "[Epoch 22/100] [Batch 105/347] [D loss: 0.499663] [G loss: 0.264308]\n",
      "[Epoch 22/100] [Batch 106/347] [D loss: 0.499673] [G loss: 0.263081]\n",
      "[Epoch 22/100] [Batch 107/347] [D loss: 0.499603] [G loss: 0.256724]\n",
      "[Epoch 22/100] [Batch 108/347] [D loss: 0.499449] [G loss: 0.273450]\n",
      "[Epoch 22/100] [Batch 109/347] [D loss: 0.499603] [G loss: 0.266389]\n",
      "[Epoch 22/100] [Batch 110/347] [D loss: 0.499895] [G loss: 0.256387]\n",
      "[Epoch 22/100] [Batch 111/347] [D loss: 0.499691] [G loss: 0.261179]\n",
      "[Epoch 22/100] [Batch 112/347] [D loss: 0.499720] [G loss: 0.266269]\n",
      "[Epoch 22/100] [Batch 113/347] [D loss: 0.500139] [G loss: 0.271410]\n",
      "[Epoch 22/100] [Batch 114/347] [D loss: 0.500395] [G loss: 0.291915]\n",
      "[Epoch 22/100] [Batch 115/347] [D loss: 0.500426] [G loss: 0.293010]\n",
      "[Epoch 22/100] [Batch 116/347] [D loss: 0.500360] [G loss: 0.287152]\n",
      "[Epoch 22/100] [Batch 117/347] [D loss: 0.500015] [G loss: 0.260586]\n",
      "[Epoch 22/100] [Batch 118/347] [D loss: 0.499537] [G loss: 0.265320]\n",
      "[Epoch 22/100] [Batch 119/347] [D loss: 0.499445] [G loss: 0.267499]\n",
      "[Epoch 22/100] [Batch 120/347] [D loss: 0.499509] [G loss: 0.266308]\n",
      "[Epoch 22/100] [Batch 121/347] [D loss: 0.499529] [G loss: 0.264550]\n",
      "[Epoch 22/100] [Batch 122/347] [D loss: 0.499706] [G loss: 0.251860]\n",
      "[Epoch 22/100] [Batch 123/347] [D loss: 0.499757] [G loss: 0.251151]\n",
      "[Epoch 22/100] [Batch 124/347] [D loss: 0.499678] [G loss: 0.252609]\n",
      "[Epoch 22/100] [Batch 125/347] [D loss: 0.499863] [G loss: 0.258448]\n",
      "[Epoch 22/100] [Batch 126/347] [D loss: 0.500075] [G loss: 0.270908]\n",
      "[Epoch 22/100] [Batch 127/347] [D loss: 0.500121] [G loss: 0.272131]\n",
      "[Epoch 22/100] [Batch 128/347] [D loss: 0.500015] [G loss: 0.266510]\n",
      "[Epoch 22/100] [Batch 129/347] [D loss: 0.499992] [G loss: 0.261467]\n",
      "[Epoch 22/100] [Batch 130/347] [D loss: 0.499928] [G loss: 0.264375]\n",
      "[Epoch 22/100] [Batch 131/347] [D loss: 0.499640] [G loss: 0.264001]\n",
      "[Epoch 22/100] [Batch 132/347] [D loss: 0.499214] [G loss: 0.288628]\n",
      "[Epoch 22/100] [Batch 133/347] [D loss: 0.499089] [G loss: 0.295269]\n",
      "[Epoch 22/100] [Batch 134/347] [D loss: 0.498834] [G loss: 0.310036]\n",
      "[Epoch 22/100] [Batch 135/347] [D loss: 0.498691] [G loss: 0.318899]\n",
      "[Epoch 22/100] [Batch 136/347] [D loss: 0.499391] [G loss: 0.276735]\n",
      "[Epoch 22/100] [Batch 137/347] [D loss: 0.499847] [G loss: 0.264286]\n",
      "[Epoch 22/100] [Batch 138/347] [D loss: 0.499321] [G loss: 0.281795]\n",
      "[Epoch 22/100] [Batch 139/347] [D loss: 0.498868] [G loss: 0.305774]\n",
      "[Epoch 22/100] [Batch 140/347] [D loss: 0.498687] [G loss: 0.317180]\n",
      "[Epoch 22/100] [Batch 141/347] [D loss: 0.498546] [G loss: 0.323970]\n",
      "[Epoch 22/100] [Batch 142/347] [D loss: 0.498439] [G loss: 0.331440]\n",
      "[Epoch 22/100] [Batch 143/347] [D loss: 0.498034] [G loss: 0.352810]\n",
      "[Epoch 22/100] [Batch 144/347] [D loss: 0.497920] [G loss: 0.354853]\n",
      "[Epoch 22/100] [Batch 145/347] [D loss: 0.498057] [G loss: 0.340339]\n",
      "[Epoch 22/100] [Batch 146/347] [D loss: 0.498247] [G loss: 0.323463]\n",
      "[Epoch 22/100] [Batch 147/347] [D loss: 0.498759] [G loss: 0.295324]\n",
      "[Epoch 22/100] [Batch 148/347] [D loss: 0.499037] [G loss: 0.282948]\n",
      "[Epoch 22/100] [Batch 149/347] [D loss: 0.498807] [G loss: 0.296535]\n",
      "[Epoch 22/100] [Batch 150/347] [D loss: 0.498823] [G loss: 0.297276]\n",
      "[Epoch 22/100] [Batch 151/347] [D loss: 0.499120] [G loss: 0.286715]\n",
      "[Epoch 22/100] [Batch 152/347] [D loss: 0.498994] [G loss: 0.298169]\n",
      "[Epoch 22/100] [Batch 153/347] [D loss: 0.498581] [G loss: 0.319205]\n",
      "[Epoch 22/100] [Batch 154/347] [D loss: 0.498355] [G loss: 0.323634]\n",
      "[Epoch 22/100] [Batch 155/347] [D loss: 0.498549] [G loss: 0.311009]\n",
      "[Epoch 22/100] [Batch 156/347] [D loss: 0.498909] [G loss: 0.294679]\n",
      "[Epoch 22/100] [Batch 157/347] [D loss: 0.498960] [G loss: 0.301254]\n",
      "[Epoch 22/100] [Batch 158/347] [D loss: 0.498474] [G loss: 0.325276]\n",
      "[Epoch 22/100] [Batch 159/347] [D loss: 0.498374] [G loss: 0.323175]\n",
      "[Epoch 22/100] [Batch 160/347] [D loss: 0.498857] [G loss: 0.303575]\n",
      "[Epoch 22/100] [Batch 161/347] [D loss: 0.499136] [G loss: 0.295490]\n",
      "[Epoch 22/100] [Batch 162/347] [D loss: 0.499039] [G loss: 0.301679]\n",
      "[Epoch 22/100] [Batch 163/347] [D loss: 0.498658] [G loss: 0.320767]\n",
      "[Epoch 22/100] [Batch 164/347] [D loss: 0.498304] [G loss: 0.336473]\n",
      "[Epoch 22/100] [Batch 165/347] [D loss: 0.498362] [G loss: 0.327915]\n",
      "[Epoch 22/100] [Batch 166/347] [D loss: 0.499038] [G loss: 0.289830]\n",
      "[Epoch 22/100] [Batch 167/347] [D loss: 0.499764] [G loss: 0.265876]\n",
      "[Epoch 22/100] [Batch 168/347] [D loss: 0.499993] [G loss: 0.276472]\n",
      "[Epoch 22/100] [Batch 169/347] [D loss: 0.500110] [G loss: 0.275077]\n",
      "[Epoch 22/100] [Batch 170/347] [D loss: 0.500223] [G loss: 0.271040]\n",
      "[Epoch 22/100] [Batch 171/347] [D loss: 0.500419] [G loss: 0.279293]\n",
      "[Epoch 22/100] [Batch 172/347] [D loss: 0.500507] [G loss: 0.284187]\n",
      "[Epoch 22/100] [Batch 173/347] [D loss: 0.500289] [G loss: 0.273034]\n",
      "[Epoch 22/100] [Batch 174/347] [D loss: 0.500217] [G loss: 0.270656]\n",
      "[Epoch 22/100] [Batch 175/347] [D loss: 0.500346] [G loss: 0.280730]\n",
      "[Epoch 22/100] [Batch 176/347] [D loss: 0.500574] [G loss: 0.294290]\n",
      "[Epoch 22/100] [Batch 177/347] [D loss: 0.500580] [G loss: 0.295437]\n",
      "[Epoch 22/100] [Batch 178/347] [D loss: 0.500475] [G loss: 0.289653]\n",
      "[Epoch 22/100] [Batch 179/347] [D loss: 0.500355] [G loss: 0.283168]\n",
      "[Epoch 22/100] [Batch 180/347] [D loss: 0.500253] [G loss: 0.276918]\n",
      "[Epoch 22/100] [Batch 181/347] [D loss: 0.500250] [G loss: 0.277548]\n",
      "[Epoch 22/100] [Batch 182/347] [D loss: 0.500162] [G loss: 0.275605]\n",
      "[Epoch 22/100] [Batch 183/347] [D loss: 0.500235] [G loss: 0.279818]\n",
      "[Epoch 22/100] [Batch 184/347] [D loss: 0.500285] [G loss: 0.283909]\n",
      "[Epoch 22/100] [Batch 185/347] [D loss: 0.500273] [G loss: 0.282511]\n",
      "[Epoch 22/100] [Batch 186/347] [D loss: 0.500288] [G loss: 0.282401]\n",
      "[Epoch 22/100] [Batch 187/347] [D loss: 0.500215] [G loss: 0.277227]\n",
      "[Epoch 22/100] [Batch 188/347] [D loss: 0.500133] [G loss: 0.274023]\n",
      "[Epoch 22/100] [Batch 189/347] [D loss: 0.500119] [G loss: 0.273253]\n",
      "[Epoch 22/100] [Batch 190/347] [D loss: 0.499859] [G loss: 0.261437]\n",
      "[Epoch 22/100] [Batch 191/347] [D loss: 0.499575] [G loss: 0.262391]\n",
      "[Epoch 22/100] [Batch 192/347] [D loss: 0.499695] [G loss: 0.252593]\n",
      "[Epoch 22/100] [Batch 193/347] [D loss: 0.499907] [G loss: 0.259761]\n",
      "[Epoch 22/100] [Batch 194/347] [D loss: 0.499740] [G loss: 0.255863]\n",
      "[Epoch 22/100] [Batch 195/347] [D loss: 0.499594] [G loss: 0.264276]\n",
      "[Epoch 22/100] [Batch 196/347] [D loss: 0.499520] [G loss: 0.261640]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 22/100] [Batch 197/347] [D loss: 0.499549] [G loss: 0.256679]\n",
      "[Epoch 22/100] [Batch 198/347] [D loss: 0.499624] [G loss: 0.256442]\n",
      "[Epoch 22/100] [Batch 199/347] [D loss: 0.499624] [G loss: 0.257376]\n",
      "[Epoch 22/100] [Batch 200/347] [D loss: 0.499688] [G loss: 0.252158]\n",
      "[Epoch 22/100] [Batch 201/347] [D loss: 0.499718] [G loss: 0.251440]\n",
      "[Epoch 22/100] [Batch 202/347] [D loss: 0.499549] [G loss: 0.262957]\n",
      "[Epoch 22/100] [Batch 203/347] [D loss: 0.499422] [G loss: 0.271503]\n",
      "[Epoch 22/100] [Batch 204/347] [D loss: 0.499490] [G loss: 0.267871]\n",
      "[Epoch 22/100] [Batch 205/347] [D loss: 0.499584] [G loss: 0.259945]\n",
      "[Epoch 22/100] [Batch 206/347] [D loss: 0.499767] [G loss: 0.251575]\n",
      "[Epoch 22/100] [Batch 207/347] [D loss: 0.500061] [G loss: 0.262458]\n",
      "[Epoch 22/100] [Batch 208/347] [D loss: 0.500010] [G loss: 0.263248]\n",
      "[Epoch 22/100] [Batch 209/347] [D loss: 0.499890] [G loss: 0.257531]\n",
      "[Epoch 22/100] [Batch 210/347] [D loss: 0.500098] [G loss: 0.265699]\n",
      "[Epoch 22/100] [Batch 211/347] [D loss: 0.500052] [G loss: 0.262949]\n",
      "[Epoch 22/100] [Batch 212/347] [D loss: 0.499958] [G loss: 0.261880]\n",
      "[Epoch 22/100] [Batch 213/347] [D loss: 0.499897] [G loss: 0.267734]\n",
      "[Epoch 22/100] [Batch 214/347] [D loss: 0.499454] [G loss: 0.275173]\n",
      "[Epoch 22/100] [Batch 215/347] [D loss: 0.499312] [G loss: 0.283501]\n",
      "[Epoch 22/100] [Batch 216/347] [D loss: 0.499777] [G loss: 0.267221]\n",
      "[Epoch 22/100] [Batch 217/347] [D loss: 0.500027] [G loss: 0.268011]\n",
      "[Epoch 22/100] [Batch 218/347] [D loss: 0.500245] [G loss: 0.274100]\n",
      "[Epoch 22/100] [Batch 219/347] [D loss: 0.500492] [G loss: 0.286418]\n",
      "[Epoch 22/100] [Batch 220/347] [D loss: 0.500777] [G loss: 0.302264]\n",
      "[Epoch 22/100] [Batch 221/347] [D loss: 0.500822] [G loss: 0.303655]\n",
      "[Epoch 22/100] [Batch 222/347] [D loss: 0.500723] [G loss: 0.295622]\n",
      "[Epoch 22/100] [Batch 223/347] [D loss: 0.500699] [G loss: 0.294310]\n",
      "[Epoch 22/100] [Batch 224/347] [D loss: 0.500624] [G loss: 0.290208]\n",
      "[Epoch 22/100] [Batch 225/347] [D loss: 0.500152] [G loss: 0.277422]\n",
      "[Epoch 22/100] [Batch 226/347] [D loss: 0.499457] [G loss: 0.271900]\n",
      "[Epoch 22/100] [Batch 227/347] [D loss: 0.499058] [G loss: 0.282010]\n",
      "[Epoch 22/100] [Batch 228/347] [D loss: 0.499061] [G loss: 0.282852]\n",
      "[Epoch 22/100] [Batch 229/347] [D loss: 0.499259] [G loss: 0.277665]\n",
      "[Epoch 22/100] [Batch 230/347] [D loss: 0.499368] [G loss: 0.273529]\n",
      "[Epoch 22/100] [Batch 231/347] [D loss: 0.499252] [G loss: 0.273318]\n",
      "[Epoch 22/100] [Batch 232/347] [D loss: 0.499351] [G loss: 0.269126]\n",
      "[Epoch 22/100] [Batch 233/347] [D loss: 0.499391] [G loss: 0.267210]\n",
      "[Epoch 22/100] [Batch 234/347] [D loss: 0.499365] [G loss: 0.272143]\n",
      "[Epoch 22/100] [Batch 235/347] [D loss: 0.499631] [G loss: 0.260809]\n",
      "[Epoch 22/100] [Batch 236/347] [D loss: 0.499916] [G loss: 0.264086]\n",
      "[Epoch 22/100] [Batch 237/347] [D loss: 0.500130] [G loss: 0.266769]\n",
      "[Epoch 22/100] [Batch 238/347] [D loss: 0.500142] [G loss: 0.270580]\n",
      "[Epoch 22/100] [Batch 239/347] [D loss: 0.500089] [G loss: 0.268367]\n",
      "[Epoch 22/100] [Batch 240/347] [D loss: 0.500043] [G loss: 0.264441]\n",
      "[Epoch 22/100] [Batch 241/347] [D loss: 0.499943] [G loss: 0.258573]\n",
      "[Epoch 22/100] [Batch 242/347] [D loss: 0.499885] [G loss: 0.256633]\n",
      "[Epoch 22/100] [Batch 243/347] [D loss: 0.500010] [G loss: 0.264351]\n",
      "[Epoch 22/100] [Batch 244/347] [D loss: 0.500160] [G loss: 0.273261]\n",
      "[Epoch 22/100] [Batch 245/347] [D loss: 0.500285] [G loss: 0.272142]\n",
      "[Epoch 22/100] [Batch 246/347] [D loss: 0.499845] [G loss: 0.265590]\n",
      "[Epoch 22/100] [Batch 247/347] [D loss: 0.499361] [G loss: 0.268038]\n",
      "[Epoch 22/100] [Batch 248/347] [D loss: 0.499179] [G loss: 0.273072]\n",
      "[Epoch 22/100] [Batch 249/347] [D loss: 0.499067] [G loss: 0.279198]\n",
      "[Epoch 22/100] [Batch 250/347] [D loss: 0.499405] [G loss: 0.270406]\n",
      "[Epoch 22/100] [Batch 251/347] [D loss: 0.499890] [G loss: 0.266352]\n",
      "[Epoch 22/100] [Batch 252/347] [D loss: 0.500076] [G loss: 0.269552]\n",
      "[Epoch 22/100] [Batch 253/347] [D loss: 0.500085] [G loss: 0.270092]\n",
      "[Epoch 22/100] [Batch 254/347] [D loss: 0.500095] [G loss: 0.268376]\n",
      "[Epoch 22/100] [Batch 255/347] [D loss: 0.499931] [G loss: 0.266870]\n",
      "[Epoch 22/100] [Batch 256/347] [D loss: 0.500033] [G loss: 0.272075]\n",
      "[Epoch 22/100] [Batch 257/347] [D loss: 0.500275] [G loss: 0.273980]\n",
      "[Epoch 22/100] [Batch 258/347] [D loss: 0.500016] [G loss: 0.268854]\n",
      "[Epoch 22/100] [Batch 259/347] [D loss: 0.499479] [G loss: 0.269573]\n",
      "[Epoch 22/100] [Batch 260/347] [D loss: 0.499209] [G loss: 0.283818]\n",
      "[Epoch 22/100] [Batch 261/347] [D loss: 0.499406] [G loss: 0.276065]\n",
      "[Epoch 22/100] [Batch 262/347] [D loss: 0.499603] [G loss: 0.260738]\n",
      "[Epoch 22/100] [Batch 263/347] [D loss: 0.499585] [G loss: 0.261437]\n",
      "[Epoch 22/100] [Batch 264/347] [D loss: 0.499354] [G loss: 0.275767]\n",
      "[Epoch 22/100] [Batch 265/347] [D loss: 0.499243] [G loss: 0.280931]\n",
      "[Epoch 22/100] [Batch 266/347] [D loss: 0.499330] [G loss: 0.273722]\n",
      "[Epoch 22/100] [Batch 267/347] [D loss: 0.499440] [G loss: 0.266819]\n",
      "[Epoch 22/100] [Batch 268/347] [D loss: 0.499379] [G loss: 0.273608]\n",
      "[Epoch 22/100] [Batch 269/347] [D loss: 0.499220] [G loss: 0.284643]\n",
      "[Epoch 22/100] [Batch 270/347] [D loss: 0.499256] [G loss: 0.281179]\n",
      "[Epoch 22/100] [Batch 271/347] [D loss: 0.499414] [G loss: 0.269312]\n",
      "[Epoch 22/100] [Batch 272/347] [D loss: 0.499583] [G loss: 0.260652]\n",
      "[Epoch 22/100] [Batch 273/347] [D loss: 0.499425] [G loss: 0.272474]\n",
      "[Epoch 22/100] [Batch 274/347] [D loss: 0.498478] [G loss: 0.306283]\n",
      "[Epoch 22/100] [Batch 275/347] [D loss: 0.498516] [G loss: 0.303158]\n",
      "[Epoch 22/100] [Batch 276/347] [D loss: 0.499438] [G loss: 0.270633]\n",
      "[Epoch 22/100] [Batch 277/347] [D loss: 0.499657] [G loss: 0.255946]\n",
      "[Epoch 22/100] [Batch 278/347] [D loss: 0.499844] [G loss: 0.253657]\n",
      "[Epoch 22/100] [Batch 279/347] [D loss: 0.499823] [G loss: 0.260483]\n",
      "[Epoch 22/100] [Batch 280/347] [D loss: 0.499765] [G loss: 0.263880]\n",
      "[Epoch 22/100] [Batch 281/347] [D loss: 0.499771] [G loss: 0.262108]\n",
      "[Epoch 22/100] [Batch 282/347] [D loss: 0.499767] [G loss: 0.260039]\n",
      "[Epoch 22/100] [Batch 283/347] [D loss: 0.499651] [G loss: 0.260433]\n",
      "[Epoch 22/100] [Batch 284/347] [D loss: 0.499711] [G loss: 0.262690]\n",
      "[Epoch 22/100] [Batch 285/347] [D loss: 0.499791] [G loss: 0.258488]\n",
      "[Epoch 22/100] [Batch 286/347] [D loss: 0.499708] [G loss: 0.251283]\n",
      "[Epoch 22/100] [Batch 287/347] [D loss: 0.499652] [G loss: 0.252876]\n",
      "[Epoch 22/100] [Batch 288/347] [D loss: 0.499088] [G loss: 0.279927]\n",
      "[Epoch 22/100] [Batch 289/347] [D loss: 0.498994] [G loss: 0.284591]\n",
      "[Epoch 22/100] [Batch 290/347] [D loss: 0.499418] [G loss: 0.262063]\n",
      "[Epoch 22/100] [Batch 291/347] [D loss: 0.499332] [G loss: 0.264875]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 22/100] [Batch 292/347] [D loss: 0.499521] [G loss: 0.256433]\n",
      "[Epoch 22/100] [Batch 293/347] [D loss: 0.500047] [G loss: 0.268375]\n",
      "[Epoch 22/100] [Batch 294/347] [D loss: 0.500236] [G loss: 0.277934]\n",
      "[Epoch 22/100] [Batch 295/347] [D loss: 0.499988] [G loss: 0.275340]\n",
      "[Epoch 22/100] [Batch 296/347] [D loss: 0.500070] [G loss: 0.271178]\n",
      "[Epoch 22/100] [Batch 297/347] [D loss: 0.500305] [G loss: 0.282868]\n",
      "[Epoch 22/100] [Batch 298/347] [D loss: 0.500185] [G loss: 0.277650]\n",
      "[Epoch 22/100] [Batch 299/347] [D loss: 0.500196] [G loss: 0.276338]\n",
      "[Epoch 22/100] [Batch 300/347] [D loss: 0.500092] [G loss: 0.271769]\n",
      "[Epoch 22/100] [Batch 301/347] [D loss: 0.500120] [G loss: 0.272876]\n",
      "[Epoch 22/100] [Batch 302/347] [D loss: 0.500247] [G loss: 0.278141]\n",
      "[Epoch 22/100] [Batch 303/347] [D loss: 0.499733] [G loss: 0.262542]\n",
      "[Epoch 22/100] [Batch 304/347] [D loss: 0.499291] [G loss: 0.266843]\n",
      "[Epoch 22/100] [Batch 305/347] [D loss: 0.499197] [G loss: 0.279430]\n",
      "[Epoch 22/100] [Batch 306/347] [D loss: 0.499129] [G loss: 0.270775]\n",
      "[Epoch 22/100] [Batch 307/347] [D loss: 0.499014] [G loss: 0.282980]\n",
      "[Epoch 22/100] [Batch 308/347] [D loss: 0.499044] [G loss: 0.278787]\n",
      "[Epoch 22/100] [Batch 309/347] [D loss: 0.499521] [G loss: 0.258676]\n",
      "[Epoch 22/100] [Batch 310/347] [D loss: 0.499953] [G loss: 0.275098]\n",
      "[Epoch 22/100] [Batch 311/347] [D loss: 0.499971] [G loss: 0.277738]\n",
      "[Epoch 22/100] [Batch 312/347] [D loss: 0.499951] [G loss: 0.277239]\n",
      "[Epoch 22/100] [Batch 313/347] [D loss: 0.499968] [G loss: 0.276287]\n",
      "[Epoch 22/100] [Batch 314/347] [D loss: 0.499951] [G loss: 0.269739]\n",
      "[Epoch 22/100] [Batch 315/347] [D loss: 0.499896] [G loss: 0.260421]\n",
      "[Epoch 22/100] [Batch 316/347] [D loss: 0.499473] [G loss: 0.258666]\n",
      "[Epoch 22/100] [Batch 317/347] [D loss: 0.499107] [G loss: 0.277195]\n",
      "[Epoch 22/100] [Batch 318/347] [D loss: 0.499566] [G loss: 0.254809]\n",
      "[Epoch 22/100] [Batch 319/347] [D loss: 0.500205] [G loss: 0.282931]\n",
      "[Epoch 22/100] [Batch 320/347] [D loss: 0.500430] [G loss: 0.296627]\n",
      "[Epoch 22/100] [Batch 321/347] [D loss: 0.500271] [G loss: 0.286249]\n",
      "[Epoch 22/100] [Batch 322/347] [D loss: 0.500051] [G loss: 0.273138]\n",
      "[Epoch 22/100] [Batch 323/347] [D loss: 0.500050] [G loss: 0.272306]\n",
      "[Epoch 22/100] [Batch 324/347] [D loss: 0.500127] [G loss: 0.275346]\n",
      "[Epoch 22/100] [Batch 325/347] [D loss: 0.499947] [G loss: 0.264766]\n",
      "[Epoch 22/100] [Batch 326/347] [D loss: 0.499707] [G loss: 0.254216]\n",
      "[Epoch 22/100] [Batch 327/347] [D loss: 0.499705] [G loss: 0.252503]\n",
      "[Epoch 22/100] [Batch 328/347] [D loss: 0.499631] [G loss: 0.250875]\n",
      "[Epoch 22/100] [Batch 329/347] [D loss: 0.499215] [G loss: 0.272982]\n",
      "[Epoch 22/100] [Batch 330/347] [D loss: 0.498883] [G loss: 0.288200]\n",
      "[Epoch 22/100] [Batch 331/347] [D loss: 0.499248] [G loss: 0.269654]\n",
      "[Epoch 22/100] [Batch 332/347] [D loss: 0.499844] [G loss: 0.265873]\n",
      "[Epoch 22/100] [Batch 333/347] [D loss: 0.500015] [G loss: 0.277414]\n",
      "[Epoch 22/100] [Batch 334/347] [D loss: 0.500107] [G loss: 0.278873]\n",
      "[Epoch 22/100] [Batch 335/347] [D loss: 0.499962] [G loss: 0.266951]\n",
      "[Epoch 22/100] [Batch 336/347] [D loss: 0.499707] [G loss: 0.252665]\n",
      "[Epoch 22/100] [Batch 337/347] [D loss: 0.499769] [G loss: 0.258565]\n",
      "[Epoch 22/100] [Batch 338/347] [D loss: 0.499993] [G loss: 0.273343]\n",
      "[Epoch 22/100] [Batch 339/347] [D loss: 0.500086] [G loss: 0.278864]\n",
      "[Epoch 22/100] [Batch 340/347] [D loss: 0.500076] [G loss: 0.279422]\n",
      "[Epoch 22/100] [Batch 341/347] [D loss: 0.500041] [G loss: 0.274741]\n",
      "[Epoch 22/100] [Batch 342/347] [D loss: 0.499900] [G loss: 0.267228]\n",
      "[Epoch 22/100] [Batch 343/347] [D loss: 0.499902] [G loss: 0.272071]\n",
      "[Epoch 22/100] [Batch 344/347] [D loss: 0.499696] [G loss: 0.261588]\n",
      "[Epoch 22/100] [Batch 345/347] [D loss: 0.499135] [G loss: 0.271488]\n",
      "[Epoch 22/100] [Batch 346/347] [D loss: 0.498809] [G loss: 0.289674]\n",
      "[Epoch 22/100] [Batch 347/347] [D loss: 0.498692] [G loss: 0.295518]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 23/100] [Batch 1/347] [D loss: 0.499540] [G loss: 0.261840]\n",
      "[Epoch 23/100] [Batch 2/347] [D loss: 0.499538] [G loss: 0.266871]\n",
      "[Epoch 23/100] [Batch 3/347] [D loss: 0.499680] [G loss: 0.266631]\n",
      "[Epoch 23/100] [Batch 4/347] [D loss: 0.499681] [G loss: 0.267806]\n",
      "[Epoch 23/100] [Batch 5/347] [D loss: 0.499675] [G loss: 0.267071]\n",
      "[Epoch 23/100] [Batch 6/347] [D loss: 0.499706] [G loss: 0.267427]\n",
      "[Epoch 23/100] [Batch 7/347] [D loss: 0.499638] [G loss: 0.267271]\n",
      "[Epoch 23/100] [Batch 8/347] [D loss: 0.499636] [G loss: 0.262667]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 23/100] [Batch 9/347] [D loss: 0.499471] [G loss: 0.261673]\n",
      "[Epoch 23/100] [Batch 10/347] [D loss: 0.499473] [G loss: 0.263363]\n",
      "[Epoch 23/100] [Batch 11/347] [D loss: 0.499694] [G loss: 0.263208]\n",
      "[Epoch 23/100] [Batch 12/347] [D loss: 0.499766] [G loss: 0.265255]\n",
      "[Epoch 23/100] [Batch 13/347] [D loss: 0.499869] [G loss: 0.269344]\n",
      "[Epoch 23/100] [Batch 14/347] [D loss: 0.499948] [G loss: 0.271463]\n",
      "[Epoch 23/100] [Batch 15/347] [D loss: 0.499892] [G loss: 0.267395]\n",
      "[Epoch 23/100] [Batch 16/347] [D loss: 0.499837] [G loss: 0.263159]\n",
      "[Epoch 23/100] [Batch 17/347] [D loss: 0.499693] [G loss: 0.251127]\n",
      "[Epoch 23/100] [Batch 18/347] [D loss: 0.499572] [G loss: 0.255653]\n",
      "[Epoch 23/100] [Batch 19/347] [D loss: 0.499778] [G loss: 0.256274]\n",
      "[Epoch 23/100] [Batch 20/347] [D loss: 0.499958] [G loss: 0.269303]\n",
      "[Epoch 23/100] [Batch 21/347] [D loss: 0.499868] [G loss: 0.265532]\n",
      "[Epoch 23/100] [Batch 22/347] [D loss: 0.499783] [G loss: 0.260498]\n",
      "[Epoch 23/100] [Batch 23/347] [D loss: 0.499702] [G loss: 0.255020]\n",
      "[Epoch 23/100] [Batch 24/347] [D loss: 0.499717] [G loss: 0.253585]\n",
      "[Epoch 23/100] [Batch 25/347] [D loss: 0.499696] [G loss: 0.253755]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 23/100] [Batch 26/347] [D loss: 0.499417] [G loss: 0.261058]\n",
      "[Epoch 23/100] [Batch 27/347] [D loss: 0.499457] [G loss: 0.266339]\n",
      "[Epoch 23/100] [Batch 28/347] [D loss: 0.499760] [G loss: 0.266374]\n",
      "[Epoch 23/100] [Batch 29/347] [D loss: 0.500008] [G loss: 0.265514]\n",
      "[Epoch 23/100] [Batch 30/347] [D loss: 0.500152] [G loss: 0.272661]\n",
      "[Epoch 23/100] [Batch 31/347] [D loss: 0.500232] [G loss: 0.275436]\n",
      "[Epoch 23/100] [Batch 32/347] [D loss: 0.500127] [G loss: 0.268896]\n",
      "[Epoch 23/100] [Batch 33/347] [D loss: 0.500004] [G loss: 0.264984]\n",
      "[Epoch 23/100] [Batch 34/347] [D loss: 0.500016] [G loss: 0.266291]\n",
      "[Epoch 23/100] [Batch 35/347] [D loss: 0.499999] [G loss: 0.265379]\n",
      "[Epoch 23/100] [Batch 36/347] [D loss: 0.499837] [G loss: 0.256518]\n",
      "[Epoch 23/100] [Batch 37/347] [D loss: 0.499339] [G loss: 0.269195]\n",
      "[Epoch 23/100] [Batch 38/347] [D loss: 0.499000] [G loss: 0.284157]\n",
      "[Epoch 23/100] [Batch 39/347] [D loss: 0.499124] [G loss: 0.274209]\n",
      "[Epoch 23/100] [Batch 40/347] [D loss: 0.499200] [G loss: 0.275130]\n",
      "[Epoch 23/100] [Batch 41/347] [D loss: 0.499140] [G loss: 0.276118]\n",
      "[Epoch 23/100] [Batch 42/347] [D loss: 0.499256] [G loss: 0.268782]\n",
      "[Epoch 23/100] [Batch 43/347] [D loss: 0.499639] [G loss: 0.251613]\n",
      "[Epoch 23/100] [Batch 44/347] [D loss: 0.500038] [G loss: 0.265454]\n",
      "[Epoch 23/100] [Batch 45/347] [D loss: 0.500349] [G loss: 0.282697]\n",
      "[Epoch 23/100] [Batch 46/347] [D loss: 0.500279] [G loss: 0.277319]\n",
      "[Epoch 23/100] [Batch 47/347] [D loss: 0.499714] [G loss: 0.251877]\n",
      "[Epoch 23/100] [Batch 48/347] [D loss: 0.499098] [G loss: 0.282558]\n",
      "[Epoch 23/100] [Batch 49/347] [D loss: 0.498880] [G loss: 0.291260]\n",
      "[Epoch 23/100] [Batch 50/347] [D loss: 0.498665] [G loss: 0.306894]\n",
      "[Epoch 23/100] [Batch 51/347] [D loss: 0.499038] [G loss: 0.291427]\n",
      "[Epoch 23/100] [Batch 52/347] [D loss: 0.499838] [G loss: 0.262919]\n",
      "[Epoch 23/100] [Batch 53/347] [D loss: 0.499697] [G loss: 0.257188]\n",
      "[Epoch 23/100] [Batch 54/347] [D loss: 0.498679] [G loss: 0.307400]\n",
      "[Epoch 23/100] [Batch 55/347] [D loss: 0.498017] [G loss: 0.330245]\n",
      "[Epoch 23/100] [Batch 56/347] [D loss: 0.498194] [G loss: 0.317366]\n",
      "[Epoch 23/100] [Batch 57/347] [D loss: 0.499065] [G loss: 0.283016]\n",
      "[Epoch 23/100] [Batch 58/347] [D loss: 0.499750] [G loss: 0.259166]\n",
      "[Epoch 23/100] [Batch 59/347] [D loss: 0.499503] [G loss: 0.266214]\n",
      "[Epoch 23/100] [Batch 60/347] [D loss: 0.499153] [G loss: 0.285440]\n",
      "[Epoch 23/100] [Batch 61/347] [D loss: 0.498912] [G loss: 0.298477]\n",
      "[Epoch 23/100] [Batch 62/347] [D loss: 0.498351] [G loss: 0.322860]\n",
      "[Epoch 23/100] [Batch 63/347] [D loss: 0.498054] [G loss: 0.325052]\n",
      "[Epoch 23/100] [Batch 64/347] [D loss: 0.498884] [G loss: 0.288078]\n",
      "[Epoch 23/100] [Batch 65/347] [D loss: 0.499990] [G loss: 0.261372]\n",
      "[Epoch 23/100] [Batch 66/347] [D loss: 0.499849] [G loss: 0.263550]\n",
      "[Epoch 23/100] [Batch 67/347] [D loss: 0.499298] [G loss: 0.272682]\n",
      "[Epoch 23/100] [Batch 68/347] [D loss: 0.498941] [G loss: 0.291146]\n",
      "[Epoch 23/100] [Batch 69/347] [D loss: 0.498435] [G loss: 0.310456]\n",
      "[Epoch 23/100] [Batch 70/347] [D loss: 0.498347] [G loss: 0.309315]\n",
      "[Epoch 23/100] [Batch 71/347] [D loss: 0.498440] [G loss: 0.311600]\n",
      "[Epoch 23/100] [Batch 72/347] [D loss: 0.498334] [G loss: 0.314085]\n",
      "[Epoch 23/100] [Batch 73/347] [D loss: 0.498846] [G loss: 0.289361]\n",
      "[Epoch 23/100] [Batch 74/347] [D loss: 0.499309] [G loss: 0.275441]\n",
      "[Epoch 23/100] [Batch 75/347] [D loss: 0.498702] [G loss: 0.305651]\n",
      "[Epoch 23/100] [Batch 76/347] [D loss: 0.498455] [G loss: 0.307945]\n",
      "[Epoch 23/100] [Batch 77/347] [D loss: 0.499190] [G loss: 0.273773]\n",
      "[Epoch 23/100] [Batch 78/347] [D loss: 0.500009] [G loss: 0.266433]\n",
      "[Epoch 23/100] [Batch 79/347] [D loss: 0.500214] [G loss: 0.268841]\n",
      "[Epoch 23/100] [Batch 80/347] [D loss: 0.500100] [G loss: 0.266300]\n",
      "[Epoch 23/100] [Batch 81/347] [D loss: 0.500246] [G loss: 0.271158]\n",
      "[Epoch 23/100] [Batch 82/347] [D loss: 0.500189] [G loss: 0.275427]\n",
      "[Epoch 23/100] [Batch 83/347] [D loss: 0.500095] [G loss: 0.267914]\n",
      "[Epoch 23/100] [Batch 84/347] [D loss: 0.500186] [G loss: 0.275155]\n",
      "[Epoch 23/100] [Batch 85/347] [D loss: 0.500157] [G loss: 0.276159]\n",
      "[Epoch 23/100] [Batch 86/347] [D loss: 0.500067] [G loss: 0.270787]\n",
      "[Epoch 23/100] [Batch 87/347] [D loss: 0.499998] [G loss: 0.268939]\n",
      "[Epoch 23/100] [Batch 88/347] [D loss: 0.500045] [G loss: 0.272559]\n",
      "[Epoch 23/100] [Batch 89/347] [D loss: 0.500081] [G loss: 0.276131]\n",
      "[Epoch 23/100] [Batch 90/347] [D loss: 0.500016] [G loss: 0.272568]\n",
      "[Epoch 23/100] [Batch 91/347] [D loss: 0.499978] [G loss: 0.271312]\n",
      "[Epoch 23/100] [Batch 92/347] [D loss: 0.499993] [G loss: 0.272964]\n",
      "[Epoch 23/100] [Batch 93/347] [D loss: 0.499946] [G loss: 0.271094]\n",
      "[Epoch 23/100] [Batch 94/347] [D loss: 0.499876] [G loss: 0.267642]\n",
      "[Epoch 23/100] [Batch 95/347] [D loss: 0.499895] [G loss: 0.268312]\n",
      "[Epoch 23/100] [Batch 96/347] [D loss: 0.499827] [G loss: 0.263683]\n",
      "[Epoch 23/100] [Batch 97/347] [D loss: 0.499716] [G loss: 0.258645]\n",
      "[Epoch 23/100] [Batch 98/347] [D loss: 0.499775] [G loss: 0.263662]\n",
      "[Epoch 23/100] [Batch 99/347] [D loss: 0.499838] [G loss: 0.267450]\n",
      "[Epoch 23/100] [Batch 100/347] [D loss: 0.499789] [G loss: 0.263873]\n",
      "[Epoch 23/100] [Batch 101/347] [D loss: 0.499688] [G loss: 0.261440]\n",
      "[Epoch 23/100] [Batch 102/347] [D loss: 0.499718] [G loss: 0.261962]\n",
      "[Epoch 23/100] [Batch 103/347] [D loss: 0.499744] [G loss: 0.261685]\n",
      "[Epoch 23/100] [Batch 104/347] [D loss: 0.499592] [G loss: 0.263174]\n",
      "[Epoch 23/100] [Batch 105/347] [D loss: 0.499572] [G loss: 0.264688]\n",
      "[Epoch 23/100] [Batch 106/347] [D loss: 0.499581] [G loss: 0.263564]\n",
      "[Epoch 23/100] [Batch 107/347] [D loss: 0.499483] [G loss: 0.256831]\n",
      "[Epoch 23/100] [Batch 108/347] [D loss: 0.499237] [G loss: 0.273632]\n",
      "[Epoch 23/100] [Batch 109/347] [D loss: 0.499415] [G loss: 0.266607]\n",
      "[Epoch 23/100] [Batch 110/347] [D loss: 0.499818] [G loss: 0.255590]\n",
      "[Epoch 23/100] [Batch 111/347] [D loss: 0.499535] [G loss: 0.260620]\n",
      "[Epoch 23/100] [Batch 112/347] [D loss: 0.499576] [G loss: 0.265044]\n",
      "[Epoch 23/100] [Batch 113/347] [D loss: 0.500117] [G loss: 0.270886]\n",
      "[Epoch 23/100] [Batch 114/347] [D loss: 0.500446] [G loss: 0.291618]\n",
      "[Epoch 23/100] [Batch 115/347] [D loss: 0.500489] [G loss: 0.292896]\n",
      "[Epoch 23/100] [Batch 116/347] [D loss: 0.500412] [G loss: 0.287249]\n",
      "[Epoch 23/100] [Batch 117/347] [D loss: 0.499985] [G loss: 0.260702]\n",
      "[Epoch 23/100] [Batch 118/347] [D loss: 0.499411] [G loss: 0.264687]\n",
      "[Epoch 23/100] [Batch 119/347] [D loss: 0.499314] [G loss: 0.266795]\n",
      "[Epoch 23/100] [Batch 120/347] [D loss: 0.499389] [G loss: 0.265561]\n",
      "[Epoch 23/100] [Batch 121/347] [D loss: 0.499417] [G loss: 0.263740]\n",
      "[Epoch 23/100] [Batch 122/347] [D loss: 0.499642] [G loss: 0.250841]\n",
      "[Epoch 23/100] [Batch 123/347] [D loss: 0.499710] [G loss: 0.252262]\n",
      "[Epoch 23/100] [Batch 124/347] [D loss: 0.499618] [G loss: 0.251635]\n",
      "[Epoch 23/100] [Batch 125/347] [D loss: 0.499842] [G loss: 0.259683]\n",
      "[Epoch 23/100] [Batch 126/347] [D loss: 0.500096] [G loss: 0.272194]\n",
      "[Epoch 23/100] [Batch 127/347] [D loss: 0.500149] [G loss: 0.273473]\n",
      "[Epoch 23/100] [Batch 128/347] [D loss: 0.500026] [G loss: 0.267890]\n",
      "[Epoch 23/100] [Batch 129/347] [D loss: 0.499993] [G loss: 0.262892]\n",
      "[Epoch 23/100] [Batch 130/347] [D loss: 0.499907] [G loss: 0.266362]\n",
      "[Epoch 23/100] [Batch 131/347] [D loss: 0.499538] [G loss: 0.264369]\n",
      "[Epoch 23/100] [Batch 132/347] [D loss: 0.498966] [G loss: 0.287573]\n",
      "[Epoch 23/100] [Batch 133/347] [D loss: 0.498799] [G loss: 0.294370]\n",
      "[Epoch 23/100] [Batch 134/347] [D loss: 0.498478] [G loss: 0.309240]\n",
      "[Epoch 23/100] [Batch 135/347] [D loss: 0.498217] [G loss: 0.318132]\n",
      "[Epoch 23/100] [Batch 136/347] [D loss: 0.499103] [G loss: 0.275974]\n",
      "[Epoch 23/100] [Batch 137/347] [D loss: 0.499770] [G loss: 0.264451]\n",
      "[Epoch 23/100] [Batch 138/347] [D loss: 0.499122] [G loss: 0.281132]\n",
      "[Epoch 23/100] [Batch 139/347] [D loss: 0.498578] [G loss: 0.305145]\n",
      "[Epoch 23/100] [Batch 140/347] [D loss: 0.498355] [G loss: 0.316549]\n",
      "[Epoch 23/100] [Batch 141/347] [D loss: 0.498186] [G loss: 0.323346]\n",
      "[Epoch 23/100] [Batch 142/347] [D loss: 0.498048] [G loss: 0.330795]\n",
      "[Epoch 23/100] [Batch 143/347] [D loss: 0.497546] [G loss: 0.352233]\n",
      "[Epoch 23/100] [Batch 144/347] [D loss: 0.497423] [G loss: 0.354276]\n",
      "[Epoch 23/100] [Batch 145/347] [D loss: 0.497609] [G loss: 0.339732]\n",
      "[Epoch 23/100] [Batch 146/347] [D loss: 0.497846] [G loss: 0.322846]\n",
      "[Epoch 23/100] [Batch 147/347] [D loss: 0.498474] [G loss: 0.294731]\n",
      "[Epoch 23/100] [Batch 148/347] [D loss: 0.498797] [G loss: 0.282514]\n",
      "[Epoch 23/100] [Batch 149/347] [D loss: 0.498517] [G loss: 0.296187]\n",
      "[Epoch 23/100] [Batch 150/347] [D loss: 0.498535] [G loss: 0.297070]\n",
      "[Epoch 23/100] [Batch 151/347] [D loss: 0.498885] [G loss: 0.286605]\n",
      "[Epoch 23/100] [Batch 152/347] [D loss: 0.498714] [G loss: 0.298216]\n",
      "[Epoch 23/100] [Batch 153/347] [D loss: 0.498208] [G loss: 0.319389]\n",
      "[Epoch 23/100] [Batch 154/347] [D loss: 0.497954] [G loss: 0.323892]\n",
      "[Epoch 23/100] [Batch 155/347] [D loss: 0.498190] [G loss: 0.311420]\n",
      "[Epoch 23/100] [Batch 156/347] [D loss: 0.498620] [G loss: 0.295202]\n",
      "[Epoch 23/100] [Batch 157/347] [D loss: 0.498656] [G loss: 0.301836]\n",
      "[Epoch 23/100] [Batch 158/347] [D loss: 0.498065] [G loss: 0.325990]\n",
      "[Epoch 23/100] [Batch 159/347] [D loss: 0.497964] [G loss: 0.323989]\n",
      "[Epoch 23/100] [Batch 160/347] [D loss: 0.498518] [G loss: 0.304408]\n",
      "[Epoch 23/100] [Batch 161/347] [D loss: 0.498835] [G loss: 0.296391]\n",
      "[Epoch 23/100] [Batch 162/347] [D loss: 0.498732] [G loss: 0.302659]\n",
      "[Epoch 23/100] [Batch 163/347] [D loss: 0.498270] [G loss: 0.321783]\n",
      "[Epoch 23/100] [Batch 164/347] [D loss: 0.497844] [G loss: 0.337508]\n",
      "[Epoch 23/100] [Batch 165/347] [D loss: 0.497931] [G loss: 0.328972]\n",
      "[Epoch 23/100] [Batch 166/347] [D loss: 0.498758] [G loss: 0.290858]\n",
      "[Epoch 23/100] [Batch 167/347] [D loss: 0.499622] [G loss: 0.264721]\n",
      "[Epoch 23/100] [Batch 168/347] [D loss: 0.499884] [G loss: 0.275260]\n",
      "[Epoch 23/100] [Batch 169/347] [D loss: 0.500037] [G loss: 0.273836]\n",
      "[Epoch 23/100] [Batch 170/347] [D loss: 0.500188] [G loss: 0.269806]\n",
      "[Epoch 23/100] [Batch 171/347] [D loss: 0.500427] [G loss: 0.277721]\n",
      "[Epoch 23/100] [Batch 172/347] [D loss: 0.500528] [G loss: 0.282614]\n",
      "[Epoch 23/100] [Batch 173/347] [D loss: 0.500270] [G loss: 0.271513]\n",
      "[Epoch 23/100] [Batch 174/347] [D loss: 0.500183] [G loss: 0.269181]\n",
      "[Epoch 23/100] [Batch 175/347] [D loss: 0.500345] [G loss: 0.279315]\n",
      "[Epoch 23/100] [Batch 176/347] [D loss: 0.500621] [G loss: 0.292975]\n",
      "[Epoch 23/100] [Batch 177/347] [D loss: 0.500624] [G loss: 0.294158]\n",
      "[Epoch 23/100] [Batch 178/347] [D loss: 0.500496] [G loss: 0.288389]\n",
      "[Epoch 23/100] [Batch 179/347] [D loss: 0.500353] [G loss: 0.281957]\n",
      "[Epoch 23/100] [Batch 180/347] [D loss: 0.500236] [G loss: 0.275758]\n",
      "[Epoch 23/100] [Batch 181/347] [D loss: 0.500232] [G loss: 0.276453]\n",
      "[Epoch 23/100] [Batch 182/347] [D loss: 0.500131] [G loss: 0.274540]\n",
      "[Epoch 23/100] [Batch 183/347] [D loss: 0.500221] [G loss: 0.278760]\n",
      "[Epoch 23/100] [Batch 184/347] [D loss: 0.500284] [G loss: 0.282854]\n",
      "[Epoch 23/100] [Batch 185/347] [D loss: 0.500267] [G loss: 0.281501]\n",
      "[Epoch 23/100] [Batch 186/347] [D loss: 0.500285] [G loss: 0.281369]\n",
      "[Epoch 23/100] [Batch 187/347] [D loss: 0.500196] [G loss: 0.276107]\n",
      "[Epoch 23/100] [Batch 188/347] [D loss: 0.500102] [G loss: 0.272885]\n",
      "[Epoch 23/100] [Batch 189/347] [D loss: 0.500085] [G loss: 0.272119]\n",
      "[Epoch 23/100] [Batch 190/347] [D loss: 0.499776] [G loss: 0.260208]\n",
      "[Epoch 23/100] [Batch 191/347] [D loss: 0.499436] [G loss: 0.263020]\n",
      "[Epoch 23/100] [Batch 192/347] [D loss: 0.499578] [G loss: 0.253134]\n",
      "[Epoch 23/100] [Batch 193/347] [D loss: 0.499831] [G loss: 0.258467]\n",
      "[Epoch 23/100] [Batch 194/347] [D loss: 0.499644] [G loss: 0.256235]\n",
      "[Epoch 23/100] [Batch 195/347] [D loss: 0.499462] [G loss: 0.264610]\n",
      "[Epoch 23/100] [Batch 196/347] [D loss: 0.499366] [G loss: 0.261922]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 23/100] [Batch 197/347] [D loss: 0.499406] [G loss: 0.256923]\n",
      "[Epoch 23/100] [Batch 198/347] [D loss: 0.499484] [G loss: 0.256908]\n",
      "[Epoch 23/100] [Batch 199/347] [D loss: 0.499488] [G loss: 0.257811]\n",
      "[Epoch 23/100] [Batch 200/347] [D loss: 0.499573] [G loss: 0.252547]\n",
      "[Epoch 23/100] [Batch 201/347] [D loss: 0.499612] [G loss: 0.251582]\n",
      "[Epoch 23/100] [Batch 202/347] [D loss: 0.499417] [G loss: 0.263159]\n",
      "[Epoch 23/100] [Batch 203/347] [D loss: 0.499267] [G loss: 0.271715]\n",
      "[Epoch 23/100] [Batch 204/347] [D loss: 0.499347] [G loss: 0.268074]\n",
      "[Epoch 23/100] [Batch 205/347] [D loss: 0.499456] [G loss: 0.260191]\n",
      "[Epoch 23/100] [Batch 206/347] [D loss: 0.499671] [G loss: 0.250238]\n",
      "[Epoch 23/100] [Batch 207/347] [D loss: 0.500014] [G loss: 0.261183]\n",
      "[Epoch 23/100] [Batch 208/347] [D loss: 0.499959] [G loss: 0.262047]\n",
      "[Epoch 23/100] [Batch 209/347] [D loss: 0.499818] [G loss: 0.256396]\n",
      "[Epoch 23/100] [Batch 210/347] [D loss: 0.500057] [G loss: 0.264865]\n",
      "[Epoch 23/100] [Batch 211/347] [D loss: 0.500006] [G loss: 0.262214]\n",
      "[Epoch 23/100] [Batch 212/347] [D loss: 0.499883] [G loss: 0.261233]\n",
      "[Epoch 23/100] [Batch 213/347] [D loss: 0.499791] [G loss: 0.267171]\n",
      "[Epoch 23/100] [Batch 214/347] [D loss: 0.499198] [G loss: 0.276271]\n",
      "[Epoch 23/100] [Batch 215/347] [D loss: 0.499021] [G loss: 0.284599]\n",
      "[Epoch 23/100] [Batch 216/347] [D loss: 0.499659] [G loss: 0.266782]\n",
      "[Epoch 23/100] [Batch 217/347] [D loss: 0.499973] [G loss: 0.267572]\n",
      "[Epoch 23/100] [Batch 218/347] [D loss: 0.500238] [G loss: 0.273495]\n",
      "[Epoch 23/100] [Batch 219/347] [D loss: 0.500537] [G loss: 0.285816]\n",
      "[Epoch 23/100] [Batch 220/347] [D loss: 0.500874] [G loss: 0.301653]\n",
      "[Epoch 23/100] [Batch 221/347] [D loss: 0.500922] [G loss: 0.303046]\n",
      "[Epoch 23/100] [Batch 222/347] [D loss: 0.500800] [G loss: 0.295040]\n",
      "[Epoch 23/100] [Batch 223/347] [D loss: 0.500768] [G loss: 0.293760]\n",
      "[Epoch 23/100] [Batch 224/347] [D loss: 0.500682] [G loss: 0.289728]\n",
      "[Epoch 23/100] [Batch 225/347] [D loss: 0.500114] [G loss: 0.277175]\n",
      "[Epoch 23/100] [Batch 226/347] [D loss: 0.499288] [G loss: 0.273034]\n",
      "[Epoch 23/100] [Batch 227/347] [D loss: 0.498837] [G loss: 0.283062]\n",
      "[Epoch 23/100] [Batch 228/347] [D loss: 0.498843] [G loss: 0.283535]\n",
      "[Epoch 23/100] [Batch 229/347] [D loss: 0.499086] [G loss: 0.278215]\n",
      "[Epoch 23/100] [Batch 230/347] [D loss: 0.499210] [G loss: 0.273931]\n",
      "[Epoch 23/100] [Batch 231/347] [D loss: 0.499076] [G loss: 0.273580]\n",
      "[Epoch 23/100] [Batch 232/347] [D loss: 0.499185] [G loss: 0.269254]\n",
      "[Epoch 23/100] [Batch 233/347] [D loss: 0.499228] [G loss: 0.267411]\n",
      "[Epoch 23/100] [Batch 234/347] [D loss: 0.499189] [G loss: 0.272195]\n",
      "[Epoch 23/100] [Batch 235/347] [D loss: 0.499497] [G loss: 0.260804]\n",
      "[Epoch 23/100] [Batch 236/347] [D loss: 0.499843] [G loss: 0.262967]\n",
      "[Epoch 23/100] [Batch 237/347] [D loss: 0.500105] [G loss: 0.265359]\n",
      "[Epoch 23/100] [Batch 238/347] [D loss: 0.500131] [G loss: 0.269145]\n",
      "[Epoch 23/100] [Batch 239/347] [D loss: 0.500068] [G loss: 0.266946]\n",
      "[Epoch 23/100] [Batch 240/347] [D loss: 0.500007] [G loss: 0.263043]\n",
      "[Epoch 23/100] [Batch 241/347] [D loss: 0.499888] [G loss: 0.257235]\n",
      "[Epoch 23/100] [Batch 242/347] [D loss: 0.499821] [G loss: 0.255385]\n",
      "[Epoch 23/100] [Batch 243/347] [D loss: 0.499972] [G loss: 0.263224]\n",
      "[Epoch 23/100] [Batch 244/347] [D loss: 0.500156] [G loss: 0.272306]\n",
      "[Epoch 23/100] [Batch 245/347] [D loss: 0.500290] [G loss: 0.271537]\n",
      "[Epoch 23/100] [Batch 246/347] [D loss: 0.499754] [G loss: 0.265088]\n",
      "[Epoch 23/100] [Batch 247/347] [D loss: 0.499193] [G loss: 0.268551]\n",
      "[Epoch 23/100] [Batch 248/347] [D loss: 0.498978] [G loss: 0.273461]\n",
      "[Epoch 23/100] [Batch 249/347] [D loss: 0.498848] [G loss: 0.279819]\n",
      "[Epoch 23/100] [Batch 250/347] [D loss: 0.499237] [G loss: 0.271020]\n",
      "[Epoch 23/100] [Batch 251/347] [D loss: 0.499816] [G loss: 0.266224]\n",
      "[Epoch 23/100] [Batch 252/347] [D loss: 0.500035] [G loss: 0.269435]\n",
      "[Epoch 23/100] [Batch 253/347] [D loss: 0.500048] [G loss: 0.269954]\n",
      "[Epoch 23/100] [Batch 254/347] [D loss: 0.500067] [G loss: 0.268270]\n",
      "[Epoch 23/100] [Batch 255/347] [D loss: 0.499857] [G loss: 0.266779]\n",
      "[Epoch 23/100] [Batch 256/347] [D loss: 0.499974] [G loss: 0.271974]\n",
      "[Epoch 23/100] [Batch 257/347] [D loss: 0.500271] [G loss: 0.273877]\n",
      "[Epoch 23/100] [Batch 258/347] [D loss: 0.499960] [G loss: 0.268764]\n",
      "[Epoch 23/100] [Batch 259/347] [D loss: 0.499316] [G loss: 0.270087]\n",
      "[Epoch 23/100] [Batch 260/347] [D loss: 0.498991] [G loss: 0.284267]\n",
      "[Epoch 23/100] [Batch 261/347] [D loss: 0.499223] [G loss: 0.276439]\n",
      "[Epoch 23/100] [Batch 262/347] [D loss: 0.499475] [G loss: 0.261025]\n",
      "[Epoch 23/100] [Batch 263/347] [D loss: 0.499452] [G loss: 0.261636]\n",
      "[Epoch 23/100] [Batch 264/347] [D loss: 0.499156] [G loss: 0.275878]\n",
      "[Epoch 23/100] [Batch 265/347] [D loss: 0.499025] [G loss: 0.280964]\n",
      "[Epoch 23/100] [Batch 266/347] [D loss: 0.499146] [G loss: 0.273642]\n",
      "[Epoch 23/100] [Batch 267/347] [D loss: 0.499275] [G loss: 0.266688]\n",
      "[Epoch 23/100] [Batch 268/347] [D loss: 0.499192] [G loss: 0.273397]\n",
      "[Epoch 23/100] [Batch 269/347] [D loss: 0.498994] [G loss: 0.284373]\n",
      "[Epoch 23/100] [Batch 270/347] [D loss: 0.499046] [G loss: 0.280904]\n",
      "[Epoch 23/100] [Batch 271/347] [D loss: 0.499251] [G loss: 0.268960]\n",
      "[Epoch 23/100] [Batch 272/347] [D loss: 0.499446] [G loss: 0.260326]\n",
      "[Epoch 23/100] [Batch 273/347] [D loss: 0.499200] [G loss: 0.272159]\n",
      "[Epoch 23/100] [Batch 274/347] [D loss: 0.497519] [G loss: 0.305922]\n",
      "[Epoch 23/100] [Batch 275/347] [D loss: 0.497587] [G loss: 0.302601]\n",
      "[Epoch 23/100] [Batch 276/347] [D loss: 0.499252] [G loss: 0.270002]\n",
      "[Epoch 23/100] [Batch 277/347] [D loss: 0.499542] [G loss: 0.255290]\n",
      "[Epoch 23/100] [Batch 278/347] [D loss: 0.499781] [G loss: 0.252530]\n",
      "[Epoch 23/100] [Batch 279/347] [D loss: 0.499749] [G loss: 0.259365]\n",
      "[Epoch 23/100] [Batch 280/347] [D loss: 0.499669] [G loss: 0.262792]\n",
      "[Epoch 23/100] [Batch 281/347] [D loss: 0.499676] [G loss: 0.261120]\n",
      "[Epoch 23/100] [Batch 282/347] [D loss: 0.499674] [G loss: 0.259149]\n",
      "[Epoch 23/100] [Batch 283/347] [D loss: 0.499527] [G loss: 0.259712]\n",
      "[Epoch 23/100] [Batch 284/347] [D loss: 0.499598] [G loss: 0.262125]\n",
      "[Epoch 23/100] [Batch 285/347] [D loss: 0.499707] [G loss: 0.258128]\n",
      "[Epoch 23/100] [Batch 286/347] [D loss: 0.499613] [G loss: 0.251106]\n",
      "[Epoch 23/100] [Batch 287/347] [D loss: 0.499539] [G loss: 0.253218]\n",
      "[Epoch 23/100] [Batch 288/347] [D loss: 0.498860] [G loss: 0.280358]\n",
      "[Epoch 23/100] [Batch 289/347] [D loss: 0.498748] [G loss: 0.285095]\n",
      "[Epoch 23/100] [Batch 290/347] [D loss: 0.499270] [G loss: 0.262612]\n",
      "[Epoch 23/100] [Batch 291/347] [D loss: 0.499164] [G loss: 0.265480]\n",
      "[Epoch 23/100] [Batch 292/347] [D loss: 0.499384] [G loss: 0.257056]\n",
      "[Epoch 23/100] [Batch 293/347] [D loss: 0.500008] [G loss: 0.268859]\n",
      "[Epoch 23/100] [Batch 294/347] [D loss: 0.500219] [G loss: 0.278404]\n",
      "[Epoch 23/100] [Batch 295/347] [D loss: 0.499895] [G loss: 0.275766]\n",
      "[Epoch 23/100] [Batch 296/347] [D loss: 0.500005] [G loss: 0.271597]\n",
      "[Epoch 23/100] [Batch 297/347] [D loss: 0.500323] [G loss: 0.282591]\n",
      "[Epoch 23/100] [Batch 298/347] [D loss: 0.500189] [G loss: 0.277339]\n",
      "[Epoch 23/100] [Batch 299/347] [D loss: 0.500195] [G loss: 0.275989]\n",
      "[Epoch 23/100] [Batch 300/347] [D loss: 0.500065] [G loss: 0.271452]\n",
      "[Epoch 23/100] [Batch 301/347] [D loss: 0.500087] [G loss: 0.273266]\n",
      "[Epoch 23/100] [Batch 302/347] [D loss: 0.500234] [G loss: 0.278508]\n",
      "[Epoch 23/100] [Batch 303/347] [D loss: 0.499617] [G loss: 0.262853]\n",
      "[Epoch 23/100] [Batch 304/347] [D loss: 0.499119] [G loss: 0.266377]\n",
      "[Epoch 23/100] [Batch 305/347] [D loss: 0.499023] [G loss: 0.278883]\n",
      "[Epoch 23/100] [Batch 306/347] [D loss: 0.498915] [G loss: 0.270897]\n",
      "[Epoch 23/100] [Batch 307/347] [D loss: 0.498753] [G loss: 0.282984]\n",
      "[Epoch 23/100] [Batch 308/347] [D loss: 0.498808] [G loss: 0.278659]\n",
      "[Epoch 23/100] [Batch 309/347] [D loss: 0.499394] [G loss: 0.257712]\n",
      "[Epoch 23/100] [Batch 310/347] [D loss: 0.499928] [G loss: 0.274328]\n",
      "[Epoch 23/100] [Batch 311/347] [D loss: 0.499953] [G loss: 0.276895]\n",
      "[Epoch 23/100] [Batch 312/347] [D loss: 0.499925] [G loss: 0.276351]\n",
      "[Epoch 23/100] [Batch 313/347] [D loss: 0.499942] [G loss: 0.275378]\n",
      "[Epoch 23/100] [Batch 314/347] [D loss: 0.499914] [G loss: 0.268837]\n",
      "[Epoch 23/100] [Batch 315/347] [D loss: 0.499830] [G loss: 0.259577]\n",
      "[Epoch 23/100] [Batch 316/347] [D loss: 0.499334] [G loss: 0.257590]\n",
      "[Epoch 23/100] [Batch 317/347] [D loss: 0.498919] [G loss: 0.276155]\n",
      "[Epoch 23/100] [Batch 318/347] [D loss: 0.499451] [G loss: 0.253818]\n",
      "[Epoch 23/100] [Batch 319/347] [D loss: 0.500221] [G loss: 0.282265]\n",
      "[Epoch 23/100] [Batch 320/347] [D loss: 0.500490] [G loss: 0.296042]\n",
      "[Epoch 23/100] [Batch 321/347] [D loss: 0.500297] [G loss: 0.285767]\n",
      "[Epoch 23/100] [Batch 322/347] [D loss: 0.500034] [G loss: 0.272704]\n",
      "[Epoch 23/100] [Batch 323/347] [D loss: 0.500033] [G loss: 0.271906]\n",
      "[Epoch 23/100] [Batch 324/347] [D loss: 0.500121] [G loss: 0.275079]\n",
      "[Epoch 23/100] [Batch 325/347] [D loss: 0.499897] [G loss: 0.264571]\n",
      "[Epoch 23/100] [Batch 326/347] [D loss: 0.499607] [G loss: 0.254835]\n",
      "[Epoch 23/100] [Batch 327/347] [D loss: 0.499603] [G loss: 0.253157]\n",
      "[Epoch 23/100] [Batch 328/347] [D loss: 0.499530] [G loss: 0.250838]\n",
      "[Epoch 23/100] [Batch 329/347] [D loss: 0.499012] [G loss: 0.273386]\n",
      "[Epoch 23/100] [Batch 330/347] [D loss: 0.498605] [G loss: 0.288798]\n",
      "[Epoch 23/100] [Batch 331/347] [D loss: 0.499043] [G loss: 0.270431]\n",
      "[Epoch 23/100] [Batch 332/347] [D loss: 0.499765] [G loss: 0.264856]\n",
      "[Epoch 23/100] [Batch 333/347] [D loss: 0.499966] [G loss: 0.276142]\n",
      "[Epoch 23/100] [Batch 334/347] [D loss: 0.500064] [G loss: 0.277416]\n",
      "[Epoch 23/100] [Batch 335/347] [D loss: 0.499873] [G loss: 0.265306]\n",
      "[Epoch 23/100] [Batch 336/347] [D loss: 0.499566] [G loss: 0.251189]\n",
      "[Epoch 23/100] [Batch 337/347] [D loss: 0.499643] [G loss: 0.256574]\n",
      "[Epoch 23/100] [Batch 338/347] [D loss: 0.499912] [G loss: 0.271257]\n",
      "[Epoch 23/100] [Batch 339/347] [D loss: 0.500022] [G loss: 0.276666]\n",
      "[Epoch 23/100] [Batch 340/347] [D loss: 0.500013] [G loss: 0.277124]\n",
      "[Epoch 23/100] [Batch 341/347] [D loss: 0.499962] [G loss: 0.272384]\n",
      "[Epoch 23/100] [Batch 342/347] [D loss: 0.499790] [G loss: 0.264763]\n",
      "[Epoch 23/100] [Batch 343/347] [D loss: 0.499800] [G loss: 0.269561]\n",
      "[Epoch 23/100] [Batch 344/347] [D loss: 0.499539] [G loss: 0.263233]\n",
      "[Epoch 23/100] [Batch 345/347] [D loss: 0.498853] [G loss: 0.273321]\n",
      "[Epoch 23/100] [Batch 346/347] [D loss: 0.498427] [G loss: 0.291520]\n",
      "[Epoch 23/100] [Batch 347/347] [D loss: 0.498234] [G loss: 0.297348]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 24/100] [Batch 1/347] [D loss: 0.499353] [G loss: 0.263552]\n",
      "[Epoch 24/100] [Batch 2/347] [D loss: 0.499350] [G loss: 0.268612]\n",
      "[Epoch 24/100] [Batch 3/347] [D loss: 0.499530] [G loss: 0.268359]\n",
      "[Epoch 24/100] [Batch 4/347] [D loss: 0.499531] [G loss: 0.269567]\n",
      "[Epoch 24/100] [Batch 5/347] [D loss: 0.499523] [G loss: 0.268890]\n",
      "[Epoch 24/100] [Batch 6/347] [D loss: 0.499564] [G loss: 0.269246]\n",
      "[Epoch 24/100] [Batch 7/347] [D loss: 0.499479] [G loss: 0.269136]\n",
      "[Epoch 24/100] [Batch 8/347] [D loss: 0.499467] [G loss: 0.264575]\n",
      "[Epoch 24/100] [Batch 9/347] [D loss: 0.499261] [G loss: 0.263672]\n",
      "[Epoch 24/100] [Batch 10/347] [D loss: 0.499268] [G loss: 0.265411]\n",
      "[Epoch 24/100] [Batch 11/347] [D loss: 0.499543] [G loss: 0.265238]\n",
      "[Epoch 24/100] [Batch 12/347] [D loss: 0.499631] [G loss: 0.266004]\n",
      "[Epoch 24/100] [Batch 13/347] [D loss: 0.499762] [G loss: 0.266897]\n",
      "[Epoch 24/100] [Batch 14/347] [D loss: 0.499869] [G loss: 0.269324]\n",
      "[Epoch 24/100] [Batch 15/347] [D loss: 0.499804] [G loss: 0.265545]\n",
      "[Epoch 24/100] [Batch 16/347] [D loss: 0.499737] [G loss: 0.261514]\n",
      "[Epoch 24/100] [Batch 17/347] [D loss: 0.499556] [G loss: 0.251469]\n",
      "[Epoch 24/100] [Batch 18/347] [D loss: 0.499428] [G loss: 0.256412]\n",
      "[Epoch 24/100] [Batch 19/347] [D loss: 0.499701] [G loss: 0.255716]\n",
      "[Epoch 24/100] [Batch 20/347] [D loss: 0.499934] [G loss: 0.269151]\n",
      "[Epoch 24/100] [Batch 21/347] [D loss: 0.499838] [G loss: 0.265719]\n",
      "[Epoch 24/100] [Batch 22/347] [D loss: 0.499744] [G loss: 0.260982]\n",
      "[Epoch 24/100] [Batch 23/347] [D loss: 0.499653] [G loss: 0.254943]\n",
      "[Epoch 24/100] [Batch 24/347] [D loss: 0.499669] [G loss: 0.254346]\n",
      "[Epoch 24/100] [Batch 25/347] [D loss: 0.499639] [G loss: 0.253980]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 24/100] [Batch 26/347] [D loss: 0.499291] [G loss: 0.260575]\n",
      "[Epoch 24/100] [Batch 27/347] [D loss: 0.499302] [G loss: 0.266146]\n",
      "[Epoch 24/100] [Batch 28/347] [D loss: 0.499650] [G loss: 0.266780]\n",
      "[Epoch 24/100] [Batch 29/347] [D loss: 0.499974] [G loss: 0.265235]\n",
      "[Epoch 24/100] [Batch 30/347] [D loss: 0.500139] [G loss: 0.272181]\n",
      "[Epoch 24/100] [Batch 31/347] [D loss: 0.500222] [G loss: 0.274765]\n",
      "[Epoch 24/100] [Batch 32/347] [D loss: 0.500087] [G loss: 0.268015]\n",
      "[Epoch 24/100] [Batch 33/347] [D loss: 0.499945] [G loss: 0.263965]\n",
      "[Epoch 24/100] [Batch 34/347] [D loss: 0.499956] [G loss: 0.265170]\n",
      "[Epoch 24/100] [Batch 35/347] [D loss: 0.499933] [G loss: 0.264071]\n",
      "[Epoch 24/100] [Batch 36/347] [D loss: 0.499734] [G loss: 0.255106]\n",
      "[Epoch 24/100] [Batch 37/347] [D loss: 0.499123] [G loss: 0.270381]\n",
      "[Epoch 24/100] [Batch 38/347] [D loss: 0.498715] [G loss: 0.285328]\n",
      "[Epoch 24/100] [Batch 39/347] [D loss: 0.498876] [G loss: 0.275423]\n",
      "[Epoch 24/100] [Batch 40/347] [D loss: 0.498978] [G loss: 0.276338]\n",
      "[Epoch 24/100] [Batch 41/347] [D loss: 0.498904] [G loss: 0.277352]\n",
      "[Epoch 24/100] [Batch 42/347] [D loss: 0.499038] [G loss: 0.270026]\n",
      "[Epoch 24/100] [Batch 43/347] [D loss: 0.499493] [G loss: 0.252924]\n",
      "[Epoch 24/100] [Batch 44/347] [D loss: 0.499967] [G loss: 0.263478]\n",
      "[Epoch 24/100] [Batch 45/347] [D loss: 0.500343] [G loss: 0.280674]\n",
      "[Epoch 24/100] [Batch 46/347] [D loss: 0.500250] [G loss: 0.275254]\n",
      "[Epoch 24/100] [Batch 47/347] [D loss: 0.499563] [G loss: 0.251398]\n",
      "[Epoch 24/100] [Batch 48/347] [D loss: 0.498817] [G loss: 0.283859]\n",
      "[Epoch 24/100] [Batch 49/347] [D loss: 0.498563] [G loss: 0.292330]\n",
      "[Epoch 24/100] [Batch 50/347] [D loss: 0.498257] [G loss: 0.307747]\n",
      "[Epoch 24/100] [Batch 51/347] [D loss: 0.498696] [G loss: 0.292047]\n",
      "[Epoch 24/100] [Batch 52/347] [D loss: 0.499735] [G loss: 0.262110]\n",
      "[Epoch 24/100] [Batch 53/347] [D loss: 0.499567] [G loss: 0.256554]\n",
      "[Epoch 24/100] [Batch 54/347] [D loss: 0.498324] [G loss: 0.307541]\n",
      "[Epoch 24/100] [Batch 55/347] [D loss: 0.497559] [G loss: 0.330279]\n",
      "[Epoch 24/100] [Batch 56/347] [D loss: 0.497787] [G loss: 0.317266]\n",
      "[Epoch 24/100] [Batch 57/347] [D loss: 0.498819] [G loss: 0.282809]\n",
      "[Epoch 24/100] [Batch 58/347] [D loss: 0.499661] [G loss: 0.259238]\n",
      "[Epoch 24/100] [Batch 59/347] [D loss: 0.499353] [G loss: 0.265779]\n",
      "[Epoch 24/100] [Batch 60/347] [D loss: 0.498920] [G loss: 0.284951]\n",
      "[Epoch 24/100] [Batch 61/347] [D loss: 0.498628] [G loss: 0.297959]\n",
      "[Epoch 24/100] [Batch 62/347] [D loss: 0.497952] [G loss: 0.322329]\n",
      "[Epoch 24/100] [Batch 63/347] [D loss: 0.497629] [G loss: 0.324497]\n",
      "[Epoch 24/100] [Batch 64/347] [D loss: 0.498625] [G loss: 0.287418]\n",
      "[Epoch 24/100] [Batch 65/347] [D loss: 0.499967] [G loss: 0.262000]\n",
      "[Epoch 24/100] [Batch 66/347] [D loss: 0.499765] [G loss: 0.264250]\n",
      "[Epoch 24/100] [Batch 67/347] [D loss: 0.499086] [G loss: 0.272001]\n",
      "[Epoch 24/100] [Batch 68/347] [D loss: 0.498653] [G loss: 0.290482]\n",
      "[Epoch 24/100] [Batch 69/347] [D loss: 0.498079] [G loss: 0.309805]\n",
      "[Epoch 24/100] [Batch 70/347] [D loss: 0.497996] [G loss: 0.308674]\n",
      "[Epoch 24/100] [Batch 71/347] [D loss: 0.498083] [G loss: 0.310886]\n",
      "[Epoch 24/100] [Batch 72/347] [D loss: 0.497966] [G loss: 0.313356]\n",
      "[Epoch 24/100] [Batch 73/347] [D loss: 0.498597] [G loss: 0.288619]\n",
      "[Epoch 24/100] [Batch 74/347] [D loss: 0.499124] [G loss: 0.274703]\n",
      "[Epoch 24/100] [Batch 75/347] [D loss: 0.498393] [G loss: 0.304863]\n",
      "[Epoch 24/100] [Batch 76/347] [D loss: 0.498132] [G loss: 0.307136]\n",
      "[Epoch 24/100] [Batch 77/347] [D loss: 0.499016] [G loss: 0.272940]\n",
      "[Epoch 24/100] [Batch 78/347] [D loss: 0.499989] [G loss: 0.267414]\n",
      "[Epoch 24/100] [Batch 79/347] [D loss: 0.500248] [G loss: 0.269228]\n",
      "[Epoch 24/100] [Batch 80/347] [D loss: 0.500114] [G loss: 0.266665]\n",
      "[Epoch 24/100] [Batch 81/347] [D loss: 0.500284] [G loss: 0.271545]\n",
      "[Epoch 24/100] [Batch 82/347] [D loss: 0.500201] [G loss: 0.276527]\n",
      "[Epoch 24/100] [Batch 83/347] [D loss: 0.500089] [G loss: 0.269054]\n",
      "[Epoch 24/100] [Batch 84/347] [D loss: 0.500228] [G loss: 0.275674]\n",
      "[Epoch 24/100] [Batch 85/347] [D loss: 0.500197] [G loss: 0.276723]\n",
      "[Epoch 24/100] [Batch 86/347] [D loss: 0.500081] [G loss: 0.271415]\n",
      "[Epoch 24/100] [Batch 87/347] [D loss: 0.500006] [G loss: 0.269602]\n",
      "[Epoch 24/100] [Batch 88/347] [D loss: 0.500059] [G loss: 0.273286]\n",
      "[Epoch 24/100] [Batch 89/347] [D loss: 0.500108] [G loss: 0.276953]\n",
      "[Epoch 24/100] [Batch 90/347] [D loss: 0.500029] [G loss: 0.273378]\n",
      "[Epoch 24/100] [Batch 91/347] [D loss: 0.499987] [G loss: 0.272160]\n",
      "[Epoch 24/100] [Batch 92/347] [D loss: 0.500007] [G loss: 0.273824]\n",
      "[Epoch 24/100] [Batch 93/347] [D loss: 0.499948] [G loss: 0.271979]\n",
      "[Epoch 24/100] [Batch 94/347] [D loss: 0.499870] [G loss: 0.268542]\n",
      "[Epoch 24/100] [Batch 95/347] [D loss: 0.499891] [G loss: 0.269177]\n",
      "[Epoch 24/100] [Batch 96/347] [D loss: 0.499808] [G loss: 0.264527]\n",
      "[Epoch 24/100] [Batch 97/347] [D loss: 0.499677] [G loss: 0.259487]\n",
      "[Epoch 24/100] [Batch 98/347] [D loss: 0.499748] [G loss: 0.264456]\n",
      "[Epoch 24/100] [Batch 99/347] [D loss: 0.499833] [G loss: 0.268263]\n",
      "[Epoch 24/100] [Batch 100/347] [D loss: 0.499767] [G loss: 0.264636]\n",
      "[Epoch 24/100] [Batch 101/347] [D loss: 0.499650] [G loss: 0.259568]\n",
      "[Epoch 24/100] [Batch 102/347] [D loss: 0.499687] [G loss: 0.261243]\n",
      "[Epoch 24/100] [Batch 103/347] [D loss: 0.499710] [G loss: 0.262147]\n",
      "[Epoch 24/100] [Batch 104/347] [D loss: 0.499516] [G loss: 0.261799]\n",
      "[Epoch 24/100] [Batch 105/347] [D loss: 0.499491] [G loss: 0.263548]\n",
      "[Epoch 24/100] [Batch 106/347] [D loss: 0.499490] [G loss: 0.262626]\n",
      "[Epoch 24/100] [Batch 107/347] [D loss: 0.499348] [G loss: 0.256605]\n",
      "[Epoch 24/100] [Batch 108/347] [D loss: 0.498974] [G loss: 0.273523]\n",
      "[Epoch 24/100] [Batch 109/347] [D loss: 0.499174] [G loss: 0.266589]\n",
      "[Epoch 24/100] [Batch 110/347] [D loss: 0.499738] [G loss: 0.254554]\n",
      "[Epoch 24/100] [Batch 111/347] [D loss: 0.499344] [G loss: 0.260724]\n",
      "[Epoch 24/100] [Batch 112/347] [D loss: 0.499377] [G loss: 0.264046]\n",
      "[Epoch 24/100] [Batch 113/347] [D loss: 0.500076] [G loss: 0.269445]\n",
      "[Epoch 24/100] [Batch 114/347] [D loss: 0.500484] [G loss: 0.290097]\n",
      "[Epoch 24/100] [Batch 115/347] [D loss: 0.500531] [G loss: 0.291333]\n",
      "[Epoch 24/100] [Batch 116/347] [D loss: 0.500429] [G loss: 0.285655]\n",
      "[Epoch 24/100] [Batch 117/347] [D loss: 0.499905] [G loss: 0.259188]\n",
      "[Epoch 24/100] [Batch 118/347] [D loss: 0.499213] [G loss: 0.265530]\n",
      "[Epoch 24/100] [Batch 119/347] [D loss: 0.499102] [G loss: 0.267686]\n",
      "[Epoch 24/100] [Batch 120/347] [D loss: 0.499180] [G loss: 0.266497]\n",
      "[Epoch 24/100] [Batch 121/347] [D loss: 0.499211] [G loss: 0.264704]\n",
      "[Epoch 24/100] [Batch 122/347] [D loss: 0.499497] [G loss: 0.251983]\n",
      "[Epoch 24/100] [Batch 123/347] [D loss: 0.499578] [G loss: 0.251074]\n",
      "[Epoch 24/100] [Batch 124/347] [D loss: 0.499476] [G loss: 0.252410]\n",
      "[Epoch 24/100] [Batch 125/347] [D loss: 0.499756] [G loss: 0.258580]\n",
      "[Epoch 24/100] [Batch 126/347] [D loss: 0.500063] [G loss: 0.271294]\n",
      "[Epoch 24/100] [Batch 127/347] [D loss: 0.500128] [G loss: 0.272730]\n",
      "[Epoch 24/100] [Batch 128/347] [D loss: 0.499988] [G loss: 0.267339]\n",
      "[Epoch 24/100] [Batch 129/347] [D loss: 0.499948] [G loss: 0.262492]\n",
      "[Epoch 24/100] [Batch 130/347] [D loss: 0.499830] [G loss: 0.266011]\n",
      "[Epoch 24/100] [Batch 131/347] [D loss: 0.499353] [G loss: 0.264185]\n",
      "[Epoch 24/100] [Batch 132/347] [D loss: 0.498582] [G loss: 0.287092]\n",
      "[Epoch 24/100] [Batch 133/347] [D loss: 0.498377] [G loss: 0.293741]\n",
      "[Epoch 24/100] [Batch 134/347] [D loss: 0.497973] [G loss: 0.308420]\n",
      "[Epoch 24/100] [Batch 135/347] [D loss: 0.497529] [G loss: 0.317097]\n",
      "[Epoch 24/100] [Batch 136/347] [D loss: 0.498679] [G loss: 0.274724]\n",
      "[Epoch 24/100] [Batch 137/347] [D loss: 0.499673] [G loss: 0.264509]\n",
      "[Epoch 24/100] [Batch 138/347] [D loss: 0.498899] [G loss: 0.279590]\n",
      "[Epoch 24/100] [Batch 139/347] [D loss: 0.498245] [G loss: 0.303500]\n",
      "[Epoch 24/100] [Batch 140/347] [D loss: 0.497975] [G loss: 0.314814]\n",
      "[Epoch 24/100] [Batch 141/347] [D loss: 0.497780] [G loss: 0.321517]\n",
      "[Epoch 24/100] [Batch 142/347] [D loss: 0.497610] [G loss: 0.328900]\n",
      "[Epoch 24/100] [Batch 143/347] [D loss: 0.496995] [G loss: 0.350220]\n",
      "[Epoch 24/100] [Batch 144/347] [D loss: 0.496862] [G loss: 0.352265]\n",
      "[Epoch 24/100] [Batch 145/347] [D loss: 0.497113] [G loss: 0.337706]\n",
      "[Epoch 24/100] [Batch 146/347] [D loss: 0.497417] [G loss: 0.320839]\n",
      "[Epoch 24/100] [Batch 147/347] [D loss: 0.498183] [G loss: 0.292715]\n",
      "[Epoch 24/100] [Batch 148/347] [D loss: 0.498571] [G loss: 0.280541]\n",
      "[Epoch 24/100] [Batch 149/347] [D loss: 0.498227] [G loss: 0.294317]\n",
      "[Epoch 24/100] [Batch 150/347] [D loss: 0.498248] [G loss: 0.295258]\n",
      "[Epoch 24/100] [Batch 151/347] [D loss: 0.498656] [G loss: 0.284885]\n",
      "[Epoch 24/100] [Batch 152/347] [D loss: 0.498432] [G loss: 0.296593]\n",
      "[Epoch 24/100] [Batch 153/347] [D loss: 0.497819] [G loss: 0.317846]\n",
      "[Epoch 24/100] [Batch 154/347] [D loss: 0.497528] [G loss: 0.322398]\n",
      "[Epoch 24/100] [Batch 155/347] [D loss: 0.497823] [G loss: 0.309979]\n",
      "[Epoch 24/100] [Batch 156/347] [D loss: 0.498345] [G loss: 0.293812]\n",
      "[Epoch 24/100] [Batch 157/347] [D loss: 0.498349] [G loss: 0.300476]\n",
      "[Epoch 24/100] [Batch 158/347] [D loss: 0.497638] [G loss: 0.324666]\n",
      "[Epoch 24/100] [Batch 159/347] [D loss: 0.497545] [G loss: 0.322680]\n",
      "[Epoch 24/100] [Batch 160/347] [D loss: 0.498181] [G loss: 0.303101]\n",
      "[Epoch 24/100] [Batch 161/347] [D loss: 0.498532] [G loss: 0.295094]\n",
      "[Epoch 24/100] [Batch 162/347] [D loss: 0.498430] [G loss: 0.301366]\n",
      "[Epoch 24/100] [Batch 163/347] [D loss: 0.497876] [G loss: 0.320413]\n",
      "[Epoch 24/100] [Batch 164/347] [D loss: 0.497367] [G loss: 0.336144]\n",
      "[Epoch 24/100] [Batch 165/347] [D loss: 0.497491] [G loss: 0.327601]\n",
      "[Epoch 24/100] [Batch 166/347] [D loss: 0.498504] [G loss: 0.289385]\n",
      "[Epoch 24/100] [Batch 167/347] [D loss: 0.499522] [G loss: 0.265660]\n",
      "[Epoch 24/100] [Batch 168/347] [D loss: 0.499829] [G loss: 0.276167]\n",
      "[Epoch 24/100] [Batch 169/347] [D loss: 0.500035] [G loss: 0.274756]\n",
      "[Epoch 24/100] [Batch 170/347] [D loss: 0.500230] [G loss: 0.270681]\n",
      "[Epoch 24/100] [Batch 171/347] [D loss: 0.500518] [G loss: 0.278643]\n",
      "[Epoch 24/100] [Batch 172/347] [D loss: 0.500637] [G loss: 0.283548]\n",
      "[Epoch 24/100] [Batch 173/347] [D loss: 0.500327] [G loss: 0.272500]\n",
      "[Epoch 24/100] [Batch 174/347] [D loss: 0.500223] [G loss: 0.270195]\n",
      "[Epoch 24/100] [Batch 175/347] [D loss: 0.500422] [G loss: 0.280416]\n",
      "[Epoch 24/100] [Batch 176/347] [D loss: 0.500753] [G loss: 0.294161]\n",
      "[Epoch 24/100] [Batch 177/347] [D loss: 0.500757] [G loss: 0.295422]\n",
      "[Epoch 24/100] [Batch 178/347] [D loss: 0.500600] [G loss: 0.289751]\n",
      "[Epoch 24/100] [Batch 179/347] [D loss: 0.500435] [G loss: 0.283325]\n",
      "[Epoch 24/100] [Batch 180/347] [D loss: 0.500294] [G loss: 0.277152]\n",
      "[Epoch 24/100] [Batch 181/347] [D loss: 0.500288] [G loss: 0.277887]\n",
      "[Epoch 24/100] [Batch 182/347] [D loss: 0.500172] [G loss: 0.276035]\n",
      "[Epoch 24/100] [Batch 183/347] [D loss: 0.500281] [G loss: 0.280312]\n",
      "[Epoch 24/100] [Batch 184/347] [D loss: 0.500359] [G loss: 0.284379]\n",
      "[Epoch 24/100] [Batch 185/347] [D loss: 0.500331] [G loss: 0.283005]\n",
      "[Epoch 24/100] [Batch 186/347] [D loss: 0.500355] [G loss: 0.282905]\n",
      "[Epoch 24/100] [Batch 187/347] [D loss: 0.500250] [G loss: 0.277653]\n",
      "[Epoch 24/100] [Batch 188/347] [D loss: 0.500138] [G loss: 0.274398]\n",
      "[Epoch 24/100] [Batch 189/347] [D loss: 0.500119] [G loss: 0.273622]\n",
      "[Epoch 24/100] [Batch 190/347] [D loss: 0.499758] [G loss: 0.261767]\n",
      "[Epoch 24/100] [Batch 191/347] [D loss: 0.499360] [G loss: 0.261533]\n",
      "[Epoch 24/100] [Batch 192/347] [D loss: 0.499520] [G loss: 0.251568]\n",
      "[Epoch 24/100] [Batch 193/347] [D loss: 0.499817] [G loss: 0.259894]\n",
      "[Epoch 24/100] [Batch 194/347] [D loss: 0.499607] [G loss: 0.255769]\n",
      "[Epoch 24/100] [Batch 195/347] [D loss: 0.499380] [G loss: 0.263140]\n",
      "[Epoch 24/100] [Batch 196/347] [D loss: 0.499265] [G loss: 0.260733]\n",
      "[Epoch 24/100] [Batch 197/347] [D loss: 0.499293] [G loss: 0.255975]\n",
      "[Epoch 24/100] [Batch 198/347] [D loss: 0.499366] [G loss: 0.256066]\n",
      "[Epoch 24/100] [Batch 199/347] [D loss: 0.499364] [G loss: 0.257103]\n",
      "[Epoch 24/100] [Batch 200/347] [D loss: 0.499467] [G loss: 0.251996]\n",
      "[Epoch 24/100] [Batch 201/347] [D loss: 0.499507] [G loss: 0.251346]\n",
      "[Epoch 24/100] [Batch 202/347] [D loss: 0.499281] [G loss: 0.263044]\n",
      "[Epoch 24/100] [Batch 203/347] [D loss: 0.499110] [G loss: 0.271794]\n",
      "[Epoch 24/100] [Batch 204/347] [D loss: 0.499195] [G loss: 0.268300]\n",
      "[Epoch 24/100] [Batch 205/347] [D loss: 0.499320] [G loss: 0.260532]\n",
      "[Epoch 24/100] [Batch 206/347] [D loss: 0.499565] [G loss: 0.249515]\n",
      "[Epoch 24/100] [Batch 207/347] [D loss: 0.499957] [G loss: 0.260424]\n",
      "[Epoch 24/100] [Batch 208/347] [D loss: 0.499893] [G loss: 0.261234]\n",
      "[Epoch 24/100] [Batch 209/347] [D loss: 0.499721] [G loss: 0.255555]\n",
      "[Epoch 24/100] [Batch 210/347] [D loss: 0.500003] [G loss: 0.263657]\n",
      "[Epoch 24/100] [Batch 211/347] [D loss: 0.499930] [G loss: 0.260969]\n",
      "[Epoch 24/100] [Batch 212/347] [D loss: 0.499773] [G loss: 0.259942]\n",
      "[Epoch 24/100] [Batch 213/347] [D loss: 0.499639] [G loss: 0.265860]\n",
      "[Epoch 24/100] [Batch 214/347] [D loss: 0.498838] [G loss: 0.277097]\n",
      "[Epoch 24/100] [Batch 215/347] [D loss: 0.498632] [G loss: 0.285404]\n",
      "[Epoch 24/100] [Batch 216/347] [D loss: 0.499497] [G loss: 0.265281]\n",
      "[Epoch 24/100] [Batch 217/347] [D loss: 0.499882] [G loss: 0.266037]\n",
      "[Epoch 24/100] [Batch 218/347] [D loss: 0.500210] [G loss: 0.272311]\n",
      "[Epoch 24/100] [Batch 219/347] [D loss: 0.500560] [G loss: 0.284594]\n",
      "[Epoch 24/100] [Batch 220/347] [D loss: 0.500958] [G loss: 0.300378]\n",
      "[Epoch 24/100] [Batch 221/347] [D loss: 0.501010] [G loss: 0.301725]\n",
      "[Epoch 24/100] [Batch 222/347] [D loss: 0.500863] [G loss: 0.293685]\n",
      "[Epoch 24/100] [Batch 223/347] [D loss: 0.500822] [G loss: 0.292419]\n",
      "[Epoch 24/100] [Batch 224/347] [D loss: 0.500713] [G loss: 0.288408]\n",
      "[Epoch 24/100] [Batch 225/347] [D loss: 0.500026] [G loss: 0.275460]\n",
      "[Epoch 24/100] [Batch 226/347] [D loss: 0.499057] [G loss: 0.273815]\n",
      "[Epoch 24/100] [Batch 227/347] [D loss: 0.498540] [G loss: 0.283846]\n",
      "[Epoch 24/100] [Batch 228/347] [D loss: 0.498559] [G loss: 0.284679]\n",
      "[Epoch 24/100] [Batch 229/347] [D loss: 0.498853] [G loss: 0.279316]\n",
      "[Epoch 24/100] [Batch 230/347] [D loss: 0.498998] [G loss: 0.274981]\n",
      "[Epoch 24/100] [Batch 231/347] [D loss: 0.498841] [G loss: 0.274596]\n",
      "[Epoch 24/100] [Batch 232/347] [D loss: 0.498967] [G loss: 0.270263]\n",
      "[Epoch 24/100] [Batch 233/347] [D loss: 0.499011] [G loss: 0.267981]\n",
      "[Epoch 24/100] [Batch 234/347] [D loss: 0.498953] [G loss: 0.272784]\n",
      "[Epoch 24/100] [Batch 235/347] [D loss: 0.499313] [G loss: 0.261344]\n",
      "[Epoch 24/100] [Batch 236/347] [D loss: 0.499729] [G loss: 0.261250]\n",
      "[Epoch 24/100] [Batch 237/347] [D loss: 0.500047] [G loss: 0.264087]\n",
      "[Epoch 24/100] [Batch 238/347] [D loss: 0.500089] [G loss: 0.267907]\n",
      "[Epoch 24/100] [Batch 239/347] [D loss: 0.500012] [G loss: 0.265729]\n",
      "[Epoch 24/100] [Batch 240/347] [D loss: 0.499933] [G loss: 0.261847]\n",
      "[Epoch 24/100] [Batch 241/347] [D loss: 0.499793] [G loss: 0.256087]\n",
      "[Epoch 24/100] [Batch 242/347] [D loss: 0.499716] [G loss: 0.254312]\n",
      "[Epoch 24/100] [Batch 243/347] [D loss: 0.499898] [G loss: 0.262206]\n",
      "[Epoch 24/100] [Batch 244/347] [D loss: 0.500117] [G loss: 0.271333]\n",
      "[Epoch 24/100] [Batch 245/347] [D loss: 0.500258] [G loss: 0.270203]\n",
      "[Epoch 24/100] [Batch 246/347] [D loss: 0.499619] [G loss: 0.263877]\n",
      "[Epoch 24/100] [Batch 247/347] [D loss: 0.498968] [G loss: 0.269486]\n",
      "[Epoch 24/100] [Batch 248/347] [D loss: 0.498725] [G loss: 0.274579]\n",
      "[Epoch 24/100] [Batch 249/347] [D loss: 0.498572] [G loss: 0.280695]\n",
      "[Epoch 24/100] [Batch 250/347] [D loss: 0.499019] [G loss: 0.271825]\n",
      "[Epoch 24/100] [Batch 251/347] [D loss: 0.499712] [G loss: 0.265249]\n",
      "[Epoch 24/100] [Batch 252/347] [D loss: 0.499965] [G loss: 0.268449]\n",
      "[Epoch 24/100] [Batch 253/347] [D loss: 0.499977] [G loss: 0.268969]\n",
      "[Epoch 24/100] [Batch 254/347] [D loss: 0.500010] [G loss: 0.267266]\n",
      "[Epoch 24/100] [Batch 255/347] [D loss: 0.499743] [G loss: 0.265721]\n",
      "[Epoch 24/100] [Batch 256/347] [D loss: 0.499878] [G loss: 0.270948]\n",
      "[Epoch 24/100] [Batch 257/347] [D loss: 0.500253] [G loss: 0.272913]\n",
      "[Epoch 24/100] [Batch 258/347] [D loss: 0.499867] [G loss: 0.267813]\n",
      "[Epoch 24/100] [Batch 259/347] [D loss: 0.499100] [G loss: 0.270647]\n",
      "[Epoch 24/100] [Batch 260/347] [D loss: 0.498702] [G loss: 0.284815]\n",
      "[Epoch 24/100] [Batch 261/347] [D loss: 0.498976] [G loss: 0.276941]\n",
      "[Epoch 24/100] [Batch 262/347] [D loss: 0.499307] [G loss: 0.261485]\n",
      "[Epoch 24/100] [Batch 263/347] [D loss: 0.499275] [G loss: 0.262080]\n",
      "[Epoch 24/100] [Batch 264/347] [D loss: 0.498895] [G loss: 0.276293]\n",
      "[Epoch 24/100] [Batch 265/347] [D loss: 0.498739] [G loss: 0.281387]\n",
      "[Epoch 24/100] [Batch 266/347] [D loss: 0.498896] [G loss: 0.274080]\n",
      "[Epoch 24/100] [Batch 267/347] [D loss: 0.499065] [G loss: 0.267092]\n",
      "[Epoch 24/100] [Batch 268/347] [D loss: 0.498946] [G loss: 0.273805]\n",
      "[Epoch 24/100] [Batch 269/347] [D loss: 0.498695] [G loss: 0.284788]\n",
      "[Epoch 24/100] [Batch 270/347] [D loss: 0.498773] [G loss: 0.281330]\n",
      "[Epoch 24/100] [Batch 271/347] [D loss: 0.499032] [G loss: 0.269434]\n",
      "[Epoch 24/100] [Batch 272/347] [D loss: 0.499272] [G loss: 0.260771]\n",
      "[Epoch 24/100] [Batch 273/347] [D loss: 0.498871] [G loss: 0.272616]\n",
      "[Epoch 24/100] [Batch 274/347] [D loss: 0.495753] [G loss: 0.306217]\n",
      "[Epoch 24/100] [Batch 275/347] [D loss: 0.495831] [G loss: 0.302669]\n",
      "[Epoch 24/100] [Batch 276/347] [D loss: 0.499007] [G loss: 0.269786]\n",
      "[Epoch 24/100] [Batch 277/347] [D loss: 0.499396] [G loss: 0.254905]\n",
      "[Epoch 24/100] [Batch 278/347] [D loss: 0.499692] [G loss: 0.250817]\n",
      "[Epoch 24/100] [Batch 279/347] [D loss: 0.499646] [G loss: 0.257599]\n",
      "[Epoch 24/100] [Batch 280/347] [D loss: 0.499543] [G loss: 0.261030]\n",
      "[Epoch 24/100] [Batch 281/347] [D loss: 0.499555] [G loss: 0.259407]\n",
      "[Epoch 24/100] [Batch 282/347] [D loss: 0.499554] [G loss: 0.257550]\n",
      "[Epoch 24/100] [Batch 283/347] [D loss: 0.499368] [G loss: 0.258237]\n",
      "[Epoch 24/100] [Batch 284/347] [D loss: 0.499447] [G loss: 0.260796]\n",
      "[Epoch 24/100] [Batch 285/347] [D loss: 0.499590] [G loss: 0.256977]\n",
      "[Epoch 24/100] [Batch 286/347] [D loss: 0.499487] [G loss: 0.250155]\n",
      "[Epoch 24/100] [Batch 287/347] [D loss: 0.499388] [G loss: 0.253570]\n",
      "[Epoch 24/100] [Batch 288/347] [D loss: 0.498568] [G loss: 0.280820]\n",
      "[Epoch 24/100] [Batch 289/347] [D loss: 0.498442] [G loss: 0.285710]\n",
      "[Epoch 24/100] [Batch 290/347] [D loss: 0.499075] [G loss: 0.263317]\n",
      "[Epoch 24/100] [Batch 291/347] [D loss: 0.498949] [G loss: 0.266302]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 24/100] [Batch 292/347] [D loss: 0.499207] [G loss: 0.257965]\n",
      "[Epoch 24/100] [Batch 293/347] [D loss: 0.499943] [G loss: 0.268845]\n",
      "[Epoch 24/100] [Batch 294/347] [D loss: 0.500175] [G loss: 0.278441]\n",
      "[Epoch 24/100] [Batch 295/347] [D loss: 0.499738] [G loss: 0.275838]\n",
      "[Epoch 24/100] [Batch 296/347] [D loss: 0.499884] [G loss: 0.271652]\n",
      "[Epoch 24/100] [Batch 297/347] [D loss: 0.500323] [G loss: 0.281984]\n",
      "[Epoch 24/100] [Batch 298/347] [D loss: 0.500175] [G loss: 0.276704]\n",
      "[Epoch 24/100] [Batch 299/347] [D loss: 0.500172] [G loss: 0.275369]\n",
      "[Epoch 24/100] [Batch 300/347] [D loss: 0.500020] [G loss: 0.270818]\n",
      "[Epoch 24/100] [Batch 301/347] [D loss: 0.500023] [G loss: 0.273307]\n",
      "[Epoch 24/100] [Batch 302/347] [D loss: 0.500197] [G loss: 0.278541]\n",
      "[Epoch 24/100] [Batch 303/347] [D loss: 0.499473] [G loss: 0.262853]\n",
      "[Epoch 24/100] [Batch 304/347] [D loss: 0.498901] [G loss: 0.266399]\n",
      "[Epoch 24/100] [Batch 305/347] [D loss: 0.498801] [G loss: 0.278767]\n",
      "[Epoch 24/100] [Batch 306/347] [D loss: 0.498639] [G loss: 0.271385]\n",
      "[Epoch 24/100] [Batch 307/347] [D loss: 0.498412] [G loss: 0.283392]\n",
      "[Epoch 24/100] [Batch 308/347] [D loss: 0.498501] [G loss: 0.278952]\n",
      "[Epoch 24/100] [Batch 309/347] [D loss: 0.499237] [G loss: 0.257179]\n",
      "[Epoch 24/100] [Batch 310/347] [D loss: 0.499886] [G loss: 0.273273]\n",
      "[Epoch 24/100] [Batch 311/347] [D loss: 0.499915] [G loss: 0.275805]\n",
      "[Epoch 24/100] [Batch 312/347] [D loss: 0.499887] [G loss: 0.275234]\n",
      "[Epoch 24/100] [Batch 313/347] [D loss: 0.499902] [G loss: 0.274248]\n",
      "[Epoch 24/100] [Batch 314/347] [D loss: 0.499851] [G loss: 0.267724]\n",
      "[Epoch 24/100] [Batch 315/347] [D loss: 0.499730] [G loss: 0.258498]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 24/100] [Batch 316/347] [D loss: 0.499157] [G loss: 0.256976]\n",
      "[Epoch 24/100] [Batch 317/347] [D loss: 0.498679] [G loss: 0.275586]\n",
      "[Epoch 24/100] [Batch 318/347] [D loss: 0.499309] [G loss: 0.253232]\n",
      "[Epoch 24/100] [Batch 319/347] [D loss: 0.500229] [G loss: 0.281458]\n",
      "[Epoch 24/100] [Batch 320/347] [D loss: 0.500547] [G loss: 0.295295]\n",
      "[Epoch 24/100] [Batch 321/347] [D loss: 0.500313] [G loss: 0.285053]\n",
      "[Epoch 24/100] [Batch 322/347] [D loss: 0.499997] [G loss: 0.272049]\n",
      "[Epoch 24/100] [Batch 323/347] [D loss: 0.499989] [G loss: 0.271253]\n",
      "[Epoch 24/100] [Batch 324/347] [D loss: 0.500094] [G loss: 0.274514]\n",
      "[Epoch 24/100] [Batch 325/347] [D loss: 0.499820] [G loss: 0.264032]\n",
      "[Epoch 24/100] [Batch 326/347] [D loss: 0.499473] [G loss: 0.255111]\n",
      "[Epoch 24/100] [Batch 327/347] [D loss: 0.499472] [G loss: 0.253523]\n",
      "[Epoch 24/100] [Batch 328/347] [D loss: 0.499394] [G loss: 0.250437]\n",
      "[Epoch 24/100] [Batch 329/347] [D loss: 0.498754] [G loss: 0.273821]\n",
      "[Epoch 24/100] [Batch 330/347] [D loss: 0.498273] [G loss: 0.289191]\n",
      "[Epoch 24/100] [Batch 331/347] [D loss: 0.498809] [G loss: 0.270721]\n",
      "[Epoch 24/100] [Batch 332/347] [D loss: 0.499689] [G loss: 0.264437]\n",
      "[Epoch 24/100] [Batch 333/347] [D loss: 0.499939] [G loss: 0.275746]\n",
      "[Epoch 24/100] [Batch 334/347] [D loss: 0.500046] [G loss: 0.277000]\n",
      "[Epoch 24/100] [Batch 335/347] [D loss: 0.499807] [G loss: 0.264847]\n",
      "[Epoch 24/100] [Batch 336/347] [D loss: 0.499436] [G loss: 0.251447]\n",
      "[Epoch 24/100] [Batch 337/347] [D loss: 0.499539] [G loss: 0.256072]\n",
      "[Epoch 24/100] [Batch 338/347] [D loss: 0.499873] [G loss: 0.270803]\n",
      "[Epoch 24/100] [Batch 339/347] [D loss: 0.500004] [G loss: 0.276263]\n",
      "[Epoch 24/100] [Batch 340/347] [D loss: 0.499995] [G loss: 0.276743]\n",
      "[Epoch 24/100] [Batch 341/347] [D loss: 0.499924] [G loss: 0.271988]\n",
      "[Epoch 24/100] [Batch 342/347] [D loss: 0.499722] [G loss: 0.264454]\n",
      "[Epoch 24/100] [Batch 343/347] [D loss: 0.499742] [G loss: 0.269263]\n",
      "[Epoch 24/100] [Batch 344/347] [D loss: 0.499420] [G loss: 0.262540]\n",
      "[Epoch 24/100] [Batch 345/347] [D loss: 0.498595] [G loss: 0.273413]\n",
      "[Epoch 24/100] [Batch 346/347] [D loss: 0.498044] [G loss: 0.291514]\n",
      "[Epoch 24/100] [Batch 347/347] [D loss: 0.497733] [G loss: 0.297237]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 25/100] [Batch 1/347] [D loss: 0.499210] [G loss: 0.262592]\n",
      "[Epoch 25/100] [Batch 2/347] [D loss: 0.499217] [G loss: 0.267608]\n",
      "[Epoch 25/100] [Batch 3/347] [D loss: 0.499437] [G loss: 0.267302]\n",
      "[Epoch 25/100] [Batch 4/347] [D loss: 0.499436] [G loss: 0.268489]\n",
      "[Epoch 25/100] [Batch 5/347] [D loss: 0.499426] [G loss: 0.267821]\n",
      "[Epoch 25/100] [Batch 6/347] [D loss: 0.499479] [G loss: 0.268226]\n",
      "[Epoch 25/100] [Batch 7/347] [D loss: 0.499376] [G loss: 0.268143]\n",
      "[Epoch 25/100] [Batch 8/347] [D loss: 0.499352] [G loss: 0.263620]\n",
      "[Epoch 25/100] [Batch 9/347] [D loss: 0.499100] [G loss: 0.262756]\n",
      "[Epoch 25/100] [Batch 10/347] [D loss: 0.499111] [G loss: 0.264537]\n",
      "[Epoch 25/100] [Batch 11/347] [D loss: 0.499447] [G loss: 0.264432]\n",
      "[Epoch 25/100] [Batch 12/347] [D loss: 0.499553] [G loss: 0.265164]\n",
      "[Epoch 25/100] [Batch 13/347] [D loss: 0.499709] [G loss: 0.266699]\n",
      "[Epoch 25/100] [Batch 14/347] [D loss: 0.499831] [G loss: 0.269149]\n",
      "[Epoch 25/100] [Batch 15/347] [D loss: 0.499752] [G loss: 0.265387]\n",
      "[Epoch 25/100] [Batch 16/347] [D loss: 0.499677] [G loss: 0.261397]\n",
      "[Epoch 25/100] [Batch 17/347] [D loss: 0.499444] [G loss: 0.250833]\n",
      "[Epoch 25/100] [Batch 18/347] [D loss: 0.499287] [G loss: 0.256391]\n",
      "[Epoch 25/100] [Batch 19/347] [D loss: 0.499621] [G loss: 0.255649]\n",
      "[Epoch 25/100] [Batch 20/347] [D loss: 0.499907] [G loss: 0.269092]\n",
      "[Epoch 25/100] [Batch 21/347] [D loss: 0.499795] [G loss: 0.265651]\n",
      "[Epoch 25/100] [Batch 22/347] [D loss: 0.499685] [G loss: 0.260916]\n",
      "[Epoch 25/100] [Batch 23/347] [D loss: 0.499568] [G loss: 0.254870]\n",
      "[Epoch 25/100] [Batch 24/347] [D loss: 0.499579] [G loss: 0.254274]\n",
      "[Epoch 25/100] [Batch 25/347] [D loss: 0.499547] [G loss: 0.253925]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 25/100] [Batch 26/347] [D loss: 0.499126] [G loss: 0.260478]\n",
      "[Epoch 25/100] [Batch 27/347] [D loss: 0.499095] [G loss: 0.265997]\n",
      "[Epoch 25/100] [Batch 28/347] [D loss: 0.499510] [G loss: 0.267260]\n",
      "[Epoch 25/100] [Batch 29/347] [D loss: 0.499946] [G loss: 0.265090]\n",
      "[Epoch 25/100] [Batch 30/347] [D loss: 0.500136] [G loss: 0.272025]\n",
      "[Epoch 25/100] [Batch 31/347] [D loss: 0.500224] [G loss: 0.274584]\n",
      "[Epoch 25/100] [Batch 32/347] [D loss: 0.500051] [G loss: 0.267826]\n",
      "[Epoch 25/100] [Batch 33/347] [D loss: 0.499895] [G loss: 0.263773]\n",
      "[Epoch 25/100] [Batch 34/347] [D loss: 0.499917] [G loss: 0.264971]\n",
      "[Epoch 25/100] [Batch 35/347] [D loss: 0.499892] [G loss: 0.263915]\n",
      "[Epoch 25/100] [Batch 36/347] [D loss: 0.499653] [G loss: 0.254987]\n",
      "[Epoch 25/100] [Batch 37/347] [D loss: 0.498920] [G loss: 0.270039]\n",
      "[Epoch 25/100] [Batch 38/347] [D loss: 0.498443] [G loss: 0.284958]\n",
      "[Epoch 25/100] [Batch 39/347] [D loss: 0.498645] [G loss: 0.274981]\n",
      "[Epoch 25/100] [Batch 40/347] [D loss: 0.498783] [G loss: 0.275216]\n",
      "[Epoch 25/100] [Batch 41/347] [D loss: 0.498696] [G loss: 0.276211]\n",
      "[Epoch 25/100] [Batch 42/347] [D loss: 0.498857] [G loss: 0.268890]\n",
      "[Epoch 25/100] [Batch 43/347] [D loss: 0.499384] [G loss: 0.252330]\n",
      "[Epoch 25/100] [Batch 44/347] [D loss: 0.499949] [G loss: 0.263435]\n",
      "[Epoch 25/100] [Batch 45/347] [D loss: 0.500399] [G loss: 0.280638]\n",
      "[Epoch 25/100] [Batch 46/347] [D loss: 0.500277] [G loss: 0.275222]\n",
      "[Epoch 25/100] [Batch 47/347] [D loss: 0.499460] [G loss: 0.250936]\n",
      "[Epoch 25/100] [Batch 48/347] [D loss: 0.498552] [G loss: 0.283443]\n",
      "[Epoch 25/100] [Batch 49/347] [D loss: 0.498243] [G loss: 0.291913]\n",
      "[Epoch 25/100] [Batch 50/347] [D loss: 0.497810] [G loss: 0.307294]\n",
      "[Epoch 25/100] [Batch 51/347] [D loss: 0.498303] [G loss: 0.291548]\n",
      "[Epoch 25/100] [Batch 52/347] [D loss: 0.499642] [G loss: 0.262739]\n",
      "[Epoch 25/100] [Batch 53/347] [D loss: 0.499447] [G loss: 0.257145]\n",
      "[Epoch 25/100] [Batch 54/347] [D loss: 0.497940] [G loss: 0.306954]\n",
      "[Epoch 25/100] [Batch 55/347] [D loss: 0.497047] [G loss: 0.329665]\n",
      "[Epoch 25/100] [Batch 56/347] [D loss: 0.497336] [G loss: 0.316600]\n",
      "[Epoch 25/100] [Batch 57/347] [D loss: 0.498550] [G loss: 0.282067]\n",
      "[Epoch 25/100] [Batch 58/347] [D loss: 0.499568] [G loss: 0.259811]\n",
      "[Epoch 25/100] [Batch 59/347] [D loss: 0.499182] [G loss: 0.265011]\n",
      "[Epoch 25/100] [Batch 60/347] [D loss: 0.498646] [G loss: 0.284285]\n",
      "[Epoch 25/100] [Batch 61/347] [D loss: 0.498292] [G loss: 0.297307]\n",
      "[Epoch 25/100] [Batch 62/347] [D loss: 0.497482] [G loss: 0.321715]\n",
      "[Epoch 25/100] [Batch 63/347] [D loss: 0.497140] [G loss: 0.323855]\n",
      "[Epoch 25/100] [Batch 64/347] [D loss: 0.498338] [G loss: 0.286776]\n",
      "[Epoch 25/100] [Batch 65/347] [D loss: 0.499943] [G loss: 0.262681]\n",
      "[Epoch 25/100] [Batch 66/347] [D loss: 0.499664] [G loss: 0.264963]\n",
      "[Epoch 25/100] [Batch 67/347] [D loss: 0.498797] [G loss: 0.271397]\n",
      "[Epoch 25/100] [Batch 68/347] [D loss: 0.498296] [G loss: 0.289926]\n",
      "[Epoch 25/100] [Batch 69/347] [D loss: 0.497667] [G loss: 0.309267]\n",
      "[Epoch 25/100] [Batch 70/347] [D loss: 0.497585] [G loss: 0.308088]\n",
      "[Epoch 25/100] [Batch 71/347] [D loss: 0.497673] [G loss: 0.310225]\n",
      "[Epoch 25/100] [Batch 72/347] [D loss: 0.497531] [G loss: 0.312648]\n",
      "[Epoch 25/100] [Batch 73/347] [D loss: 0.498296] [G loss: 0.287891]\n",
      "[Epoch 25/100] [Batch 74/347] [D loss: 0.498900] [G loss: 0.273921]\n",
      "[Epoch 25/100] [Batch 75/347] [D loss: 0.498016] [G loss: 0.304135]\n",
      "[Epoch 25/100] [Batch 76/347] [D loss: 0.497748] [G loss: 0.306407]\n",
      "[Epoch 25/100] [Batch 77/347] [D loss: 0.498807] [G loss: 0.272221]\n",
      "[Epoch 25/100] [Batch 78/347] [D loss: 0.499962] [G loss: 0.268038]\n",
      "[Epoch 25/100] [Batch 79/347] [D loss: 0.500282] [G loss: 0.269662]\n",
      "[Epoch 25/100] [Batch 80/347] [D loss: 0.500127] [G loss: 0.266715]\n",
      "[Epoch 25/100] [Batch 81/347] [D loss: 0.500315] [G loss: 0.271619]\n",
      "[Epoch 25/100] [Batch 82/347] [D loss: 0.500193] [G loss: 0.277100]\n",
      "[Epoch 25/100] [Batch 83/347] [D loss: 0.500071] [G loss: 0.269633]\n",
      "[Epoch 25/100] [Batch 84/347] [D loss: 0.500258] [G loss: 0.275913]\n",
      "[Epoch 25/100] [Batch 85/347] [D loss: 0.500222] [G loss: 0.277053]\n",
      "[Epoch 25/100] [Batch 86/347] [D loss: 0.500088] [G loss: 0.271804]\n",
      "[Epoch 25/100] [Batch 87/347] [D loss: 0.500001] [G loss: 0.270055]\n",
      "[Epoch 25/100] [Batch 88/347] [D loss: 0.500066] [G loss: 0.273786]\n",
      "[Epoch 25/100] [Batch 89/347] [D loss: 0.500127] [G loss: 0.277504]\n",
      "[Epoch 25/100] [Batch 90/347] [D loss: 0.500033] [G loss: 0.274006]\n",
      "[Epoch 25/100] [Batch 91/347] [D loss: 0.499987] [G loss: 0.272796]\n",
      "[Epoch 25/100] [Batch 92/347] [D loss: 0.500009] [G loss: 0.274451]\n",
      "[Epoch 25/100] [Batch 93/347] [D loss: 0.499937] [G loss: 0.272587]\n",
      "[Epoch 25/100] [Batch 94/347] [D loss: 0.499848] [G loss: 0.269170]\n",
      "[Epoch 25/100] [Batch 95/347] [D loss: 0.499874] [G loss: 0.269814]\n",
      "[Epoch 25/100] [Batch 96/347] [D loss: 0.499771] [G loss: 0.265148]\n",
      "[Epoch 25/100] [Batch 97/347] [D loss: 0.499616] [G loss: 0.260082]\n",
      "[Epoch 25/100] [Batch 98/347] [D loss: 0.499711] [G loss: 0.265039]\n",
      "[Epoch 25/100] [Batch 99/347] [D loss: 0.499807] [G loss: 0.268854]\n",
      "[Epoch 25/100] [Batch 100/347] [D loss: 0.499728] [G loss: 0.265183]\n",
      "[Epoch 25/100] [Batch 101/347] [D loss: 0.499592] [G loss: 0.259977]\n",
      "[Epoch 25/100] [Batch 102/347] [D loss: 0.499626] [G loss: 0.261499]\n",
      "[Epoch 25/100] [Batch 103/347] [D loss: 0.499642] [G loss: 0.262121]\n",
      "[Epoch 25/100] [Batch 104/347] [D loss: 0.499405] [G loss: 0.261678]\n",
      "[Epoch 25/100] [Batch 105/347] [D loss: 0.499369] [G loss: 0.263678]\n",
      "[Epoch 25/100] [Batch 106/347] [D loss: 0.499362] [G loss: 0.262948]\n",
      "[Epoch 25/100] [Batch 107/347] [D loss: 0.499163] [G loss: 0.256876]\n",
      "[Epoch 25/100] [Batch 108/347] [D loss: 0.498599] [G loss: 0.273881]\n",
      "[Epoch 25/100] [Batch 109/347] [D loss: 0.498821] [G loss: 0.267011]\n",
      "[Epoch 25/100] [Batch 110/347] [D loss: 0.499611] [G loss: 0.253367]\n",
      "[Epoch 25/100] [Batch 111/347] [D loss: 0.499056] [G loss: 0.261321]\n",
      "[Epoch 25/100] [Batch 112/347] [D loss: 0.499078] [G loss: 0.262209]\n",
      "[Epoch 25/100] [Batch 113/347] [D loss: 0.499981] [G loss: 0.267919]\n",
      "[Epoch 25/100] [Batch 114/347] [D loss: 0.500493] [G loss: 0.288486]\n",
      "[Epoch 25/100] [Batch 115/347] [D loss: 0.500544] [G loss: 0.289683]\n",
      "[Epoch 25/100] [Batch 116/347] [D loss: 0.500417] [G loss: 0.283967]\n",
      "[Epoch 25/100] [Batch 117/347] [D loss: 0.499778] [G loss: 0.257414]\n",
      "[Epoch 25/100] [Batch 118/347] [D loss: 0.498951] [G loss: 0.266739]\n",
      "[Epoch 25/100] [Batch 119/347] [D loss: 0.498818] [G loss: 0.268965]\n",
      "[Epoch 25/100] [Batch 120/347] [D loss: 0.498899] [G loss: 0.267798]\n",
      "[Epoch 25/100] [Batch 121/347] [D loss: 0.498941] [G loss: 0.266029]\n",
      "[Epoch 25/100] [Batch 122/347] [D loss: 0.499304] [G loss: 0.253546]\n",
      "[Epoch 25/100] [Batch 123/347] [D loss: 0.499407] [G loss: 0.252622]\n",
      "[Epoch 25/100] [Batch 124/347] [D loss: 0.499287] [G loss: 0.253787]\n",
      "[Epoch 25/100] [Batch 125/347] [D loss: 0.499622] [G loss: 0.256756]\n",
      "[Epoch 25/100] [Batch 126/347] [D loss: 0.499976] [G loss: 0.269453]\n",
      "[Epoch 25/100] [Batch 127/347] [D loss: 0.500048] [G loss: 0.270923]\n",
      "[Epoch 25/100] [Batch 128/347] [D loss: 0.499887] [G loss: 0.265524]\n",
      "[Epoch 25/100] [Batch 129/347] [D loss: 0.499826] [G loss: 0.260676]\n",
      "[Epoch 25/100] [Batch 130/347] [D loss: 0.499669] [G loss: 0.264206]\n",
      "[Epoch 25/100] [Batch 131/347] [D loss: 0.499031] [G loss: 0.263985]\n",
      "[Epoch 25/100] [Batch 132/347] [D loss: 0.497985] [G loss: 0.288350]\n",
      "[Epoch 25/100] [Batch 133/347] [D loss: 0.497752] [G loss: 0.294661]\n",
      "[Epoch 25/100] [Batch 134/347] [D loss: 0.497245] [G loss: 0.309015]\n",
      "[Epoch 25/100] [Batch 135/347] [D loss: 0.496492] [G loss: 0.317326]\n",
      "[Epoch 25/100] [Batch 136/347] [D loss: 0.497971] [G loss: 0.274594]\n",
      "[Epoch 25/100] [Batch 137/347] [D loss: 0.499521] [G loss: 0.263770]\n",
      "[Epoch 25/100] [Batch 138/347] [D loss: 0.498609] [G loss: 0.278929]\n",
      "[Epoch 25/100] [Batch 139/347] [D loss: 0.497829] [G loss: 0.302642]\n",
      "[Epoch 25/100] [Batch 140/347] [D loss: 0.497507] [G loss: 0.313796]\n",
      "[Epoch 25/100] [Batch 141/347] [D loss: 0.497288] [G loss: 0.320395]\n",
      "[Epoch 25/100] [Batch 142/347] [D loss: 0.497087] [G loss: 0.327665]\n",
      "[Epoch 25/100] [Batch 143/347] [D loss: 0.496334] [G loss: 0.348936]\n",
      "[Epoch 25/100] [Batch 144/347] [D loss: 0.496197] [G loss: 0.350891]\n",
      "[Epoch 25/100] [Batch 145/347] [D loss: 0.496536] [G loss: 0.336327]\n",
      "[Epoch 25/100] [Batch 146/347] [D loss: 0.496926] [G loss: 0.319485]\n",
      "[Epoch 25/100] [Batch 147/347] [D loss: 0.497850] [G loss: 0.291409]\n",
      "[Epoch 25/100] [Batch 148/347] [D loss: 0.498303] [G loss: 0.279259]\n",
      "[Epoch 25/100] [Batch 149/347] [D loss: 0.497890] [G loss: 0.293101]\n",
      "[Epoch 25/100] [Batch 150/347] [D loss: 0.497926] [G loss: 0.294134]\n",
      "[Epoch 25/100] [Batch 151/347] [D loss: 0.498390] [G loss: 0.283856]\n",
      "[Epoch 25/100] [Batch 152/347] [D loss: 0.498095] [G loss: 0.295628]\n",
      "[Epoch 25/100] [Batch 153/347] [D loss: 0.497367] [G loss: 0.316953]\n",
      "[Epoch 25/100] [Batch 154/347] [D loss: 0.497045] [G loss: 0.321553]\n",
      "[Epoch 25/100] [Batch 155/347] [D loss: 0.497406] [G loss: 0.309169]\n",
      "[Epoch 25/100] [Batch 156/347] [D loss: 0.498030] [G loss: 0.292988]\n",
      "[Epoch 25/100] [Batch 157/347] [D loss: 0.497993] [G loss: 0.299644]\n",
      "[Epoch 25/100] [Batch 158/347] [D loss: 0.497140] [G loss: 0.323820]\n",
      "[Epoch 25/100] [Batch 159/347] [D loss: 0.497060] [G loss: 0.321796]\n",
      "[Epoch 25/100] [Batch 160/347] [D loss: 0.497773] [G loss: 0.302204]\n",
      "[Epoch 25/100] [Batch 161/347] [D loss: 0.498164] [G loss: 0.294120]\n",
      "[Epoch 25/100] [Batch 162/347] [D loss: 0.498072] [G loss: 0.300301]\n",
      "[Epoch 25/100] [Batch 163/347] [D loss: 0.497401] [G loss: 0.319351]\n",
      "[Epoch 25/100] [Batch 164/347] [D loss: 0.496795] [G loss: 0.334979]\n",
      "[Epoch 25/100] [Batch 165/347] [D loss: 0.496967] [G loss: 0.326338]\n",
      "[Epoch 25/100] [Batch 166/347] [D loss: 0.498200] [G loss: 0.288077]\n",
      "[Epoch 25/100] [Batch 167/347] [D loss: 0.499387] [G loss: 0.266834]\n",
      "[Epoch 25/100] [Batch 168/347] [D loss: 0.499744] [G loss: 0.277332]\n",
      "[Epoch 25/100] [Batch 169/347] [D loss: 0.500014] [G loss: 0.275850]\n",
      "[Epoch 25/100] [Batch 170/347] [D loss: 0.500274] [G loss: 0.271767]\n",
      "[Epoch 25/100] [Batch 171/347] [D loss: 0.500620] [G loss: 0.278909]\n",
      "[Epoch 25/100] [Batch 172/347] [D loss: 0.500771] [G loss: 0.283893]\n",
      "[Epoch 25/100] [Batch 173/347] [D loss: 0.500397] [G loss: 0.272897]\n",
      "[Epoch 25/100] [Batch 174/347] [D loss: 0.500274] [G loss: 0.270671]\n",
      "[Epoch 25/100] [Batch 175/347] [D loss: 0.500520] [G loss: 0.280963]\n",
      "[Epoch 25/100] [Batch 176/347] [D loss: 0.500920] [G loss: 0.294811]\n",
      "[Epoch 25/100] [Batch 177/347] [D loss: 0.500924] [G loss: 0.296170]\n",
      "[Epoch 25/100] [Batch 178/347] [D loss: 0.500741] [G loss: 0.290569]\n",
      "[Epoch 25/100] [Batch 179/347] [D loss: 0.500542] [G loss: 0.284231]\n",
      "[Epoch 25/100] [Batch 180/347] [D loss: 0.500374] [G loss: 0.278153]\n",
      "[Epoch 25/100] [Batch 181/347] [D loss: 0.500368] [G loss: 0.278929]\n",
      "[Epoch 25/100] [Batch 182/347] [D loss: 0.500238] [G loss: 0.277150]\n",
      "[Epoch 25/100] [Batch 183/347] [D loss: 0.500367] [G loss: 0.281433]\n",
      "[Epoch 25/100] [Batch 184/347] [D loss: 0.500465] [G loss: 0.285577]\n",
      "[Epoch 25/100] [Batch 185/347] [D loss: 0.500432] [G loss: 0.284201]\n",
      "[Epoch 25/100] [Batch 186/347] [D loss: 0.500463] [G loss: 0.284131]\n",
      "[Epoch 25/100] [Batch 187/347] [D loss: 0.500335] [G loss: 0.278871]\n",
      "[Epoch 25/100] [Batch 188/347] [D loss: 0.500205] [G loss: 0.275627]\n",
      "[Epoch 25/100] [Batch 189/347] [D loss: 0.500177] [G loss: 0.274809]\n",
      "[Epoch 25/100] [Batch 190/347] [D loss: 0.499749] [G loss: 0.262916]\n",
      "[Epoch 25/100] [Batch 191/347] [D loss: 0.499281] [G loss: 0.259381]\n",
      "[Epoch 25/100] [Batch 192/347] [D loss: 0.499469] [G loss: 0.252142]\n",
      "[Epoch 25/100] [Batch 193/347] [D loss: 0.499803] [G loss: 0.260789]\n",
      "[Epoch 25/100] [Batch 194/347] [D loss: 0.499557] [G loss: 0.256359]\n",
      "[Epoch 25/100] [Batch 195/347] [D loss: 0.499280] [G loss: 0.261654]\n",
      "[Epoch 25/100] [Batch 196/347] [D loss: 0.499131] [G loss: 0.259442]\n",
      "[Epoch 25/100] [Batch 197/347] [D loss: 0.499154] [G loss: 0.255514]\n",
      "[Epoch 25/100] [Batch 198/347] [D loss: 0.499221] [G loss: 0.255808]\n",
      "[Epoch 25/100] [Batch 199/347] [D loss: 0.499209] [G loss: 0.256931]\n",
      "[Epoch 25/100] [Batch 200/347] [D loss: 0.499338] [G loss: 0.251932]\n",
      "[Epoch 25/100] [Batch 201/347] [D loss: 0.499379] [G loss: 0.251034]\n",
      "[Epoch 25/100] [Batch 202/347] [D loss: 0.499116] [G loss: 0.262948]\n",
      "[Epoch 25/100] [Batch 203/347] [D loss: 0.498911] [G loss: 0.271822]\n",
      "[Epoch 25/100] [Batch 204/347] [D loss: 0.499010] [G loss: 0.268478]\n",
      "[Epoch 25/100] [Batch 205/347] [D loss: 0.499148] [G loss: 0.260823]\n",
      "[Epoch 25/100] [Batch 206/347] [D loss: 0.499430] [G loss: 0.248890]\n",
      "[Epoch 25/100] [Batch 207/347] [D loss: 0.499897] [G loss: 0.259717]\n",
      "[Epoch 25/100] [Batch 208/347] [D loss: 0.499835] [G loss: 0.260730]\n",
      "[Epoch 25/100] [Batch 209/347] [D loss: 0.499638] [G loss: 0.255257]\n",
      "[Epoch 25/100] [Batch 210/347] [D loss: 0.499965] [G loss: 0.263606]\n",
      "[Epoch 25/100] [Batch 211/347] [D loss: 0.499893] [G loss: 0.261112]\n",
      "[Epoch 25/100] [Batch 212/347] [D loss: 0.499696] [G loss: 0.260265]\n",
      "[Epoch 25/100] [Batch 213/347] [D loss: 0.499504] [G loss: 0.266354]\n",
      "[Epoch 25/100] [Batch 214/347] [D loss: 0.498397] [G loss: 0.276473]\n",
      "[Epoch 25/100] [Batch 215/347] [D loss: 0.498157] [G loss: 0.284625]\n",
      "[Epoch 25/100] [Batch 216/347] [D loss: 0.499366] [G loss: 0.266046]\n",
      "[Epoch 25/100] [Batch 217/347] [D loss: 0.499854] [G loss: 0.266862]\n",
      "[Epoch 25/100] [Batch 218/347] [D loss: 0.500256] [G loss: 0.273094]\n",
      "[Epoch 25/100] [Batch 219/347] [D loss: 0.500667] [G loss: 0.285448]\n",
      "[Epoch 25/100] [Batch 220/347] [D loss: 0.501141] [G loss: 0.301324]\n",
      "[Epoch 25/100] [Batch 221/347] [D loss: 0.501198] [G loss: 0.302698]\n",
      "[Epoch 25/100] [Batch 222/347] [D loss: 0.501015] [G loss: 0.294788]\n",
      "[Epoch 25/100] [Batch 223/347] [D loss: 0.500970] [G loss: 0.293617]\n",
      "[Epoch 25/100] [Batch 224/347] [D loss: 0.500848] [G loss: 0.289648]\n",
      "[Epoch 25/100] [Batch 225/347] [D loss: 0.500026] [G loss: 0.277002]\n",
      "[Epoch 25/100] [Batch 226/347] [D loss: 0.498884] [G loss: 0.272603]\n",
      "[Epoch 25/100] [Batch 227/347] [D loss: 0.498302] [G loss: 0.282512]\n",
      "[Epoch 25/100] [Batch 228/347] [D loss: 0.498337] [G loss: 0.283043]\n",
      "[Epoch 25/100] [Batch 229/347] [D loss: 0.498686] [G loss: 0.277564]\n",
      "[Epoch 25/100] [Batch 230/347] [D loss: 0.498863] [G loss: 0.273148]\n",
      "[Epoch 25/100] [Batch 231/347] [D loss: 0.498680] [G loss: 0.272701]\n",
      "[Epoch 25/100] [Batch 232/347] [D loss: 0.498824] [G loss: 0.268322]\n",
      "[Epoch 25/100] [Batch 233/347] [D loss: 0.498867] [G loss: 0.266175]\n",
      "[Epoch 25/100] [Batch 234/347] [D loss: 0.498791] [G loss: 0.270957]\n",
      "[Epoch 25/100] [Batch 235/347] [D loss: 0.499207] [G loss: 0.259464]\n",
      "[Epoch 25/100] [Batch 236/347] [D loss: 0.499703] [G loss: 0.262972]\n",
      "[Epoch 25/100] [Batch 237/347] [D loss: 0.500087] [G loss: 0.265599]\n",
      "[Epoch 25/100] [Batch 238/347] [D loss: 0.500144] [G loss: 0.269436]\n",
      "[Epoch 25/100] [Batch 239/347] [D loss: 0.500054] [G loss: 0.267252]\n",
      "[Epoch 25/100] [Batch 240/347] [D loss: 0.499957] [G loss: 0.263434]\n",
      "[Epoch 25/100] [Batch 241/347] [D loss: 0.499789] [G loss: 0.257731]\n",
      "[Epoch 25/100] [Batch 242/347] [D loss: 0.499703] [G loss: 0.256015]\n",
      "[Epoch 25/100] [Batch 243/347] [D loss: 0.499920] [G loss: 0.263997]\n",
      "[Epoch 25/100] [Batch 244/347] [D loss: 0.500186] [G loss: 0.273173]\n",
      "[Epoch 25/100] [Batch 245/347] [D loss: 0.500330] [G loss: 0.272308]\n",
      "[Epoch 25/100] [Batch 246/347] [D loss: 0.499572] [G loss: 0.265972]\n",
      "[Epoch 25/100] [Batch 247/347] [D loss: 0.498827] [G loss: 0.267845]\n",
      "[Epoch 25/100] [Batch 248/347] [D loss: 0.498552] [G loss: 0.272876]\n",
      "[Epoch 25/100] [Batch 249/347] [D loss: 0.498367] [G loss: 0.278958]\n",
      "[Epoch 25/100] [Batch 250/347] [D loss: 0.498875] [G loss: 0.270040]\n",
      "[Epoch 25/100] [Batch 251/347] [D loss: 0.499686] [G loss: 0.267224]\n",
      "[Epoch 25/100] [Batch 252/347] [D loss: 0.499978] [G loss: 0.270396]\n",
      "[Epoch 25/100] [Batch 253/347] [D loss: 0.499997] [G loss: 0.270848]\n",
      "[Epoch 25/100] [Batch 254/347] [D loss: 0.500040] [G loss: 0.269097]\n",
      "[Epoch 25/100] [Batch 255/347] [D loss: 0.499699] [G loss: 0.267488]\n",
      "[Epoch 25/100] [Batch 256/347] [D loss: 0.499855] [G loss: 0.272663]\n",
      "[Epoch 25/100] [Batch 257/347] [D loss: 0.500315] [G loss: 0.274620]\n",
      "[Epoch 25/100] [Batch 258/347] [D loss: 0.499853] [G loss: 0.269503]\n",
      "[Epoch 25/100] [Batch 259/347] [D loss: 0.498943] [G loss: 0.268488]\n",
      "[Epoch 25/100] [Batch 260/347] [D loss: 0.498458] [G loss: 0.282583]\n",
      "[Epoch 25/100] [Batch 261/347] [D loss: 0.498772] [G loss: 0.274680]\n",
      "[Epoch 25/100] [Batch 262/347] [D loss: 0.499201] [G loss: 0.259160]\n",
      "[Epoch 25/100] [Batch 263/347] [D loss: 0.499160] [G loss: 0.259702]\n",
      "[Epoch 25/100] [Batch 264/347] [D loss: 0.498679] [G loss: 0.273856]\n",
      "[Epoch 25/100] [Batch 265/347] [D loss: 0.498492] [G loss: 0.278918]\n",
      "[Epoch 25/100] [Batch 266/347] [D loss: 0.498700] [G loss: 0.271597]\n",
      "[Epoch 25/100] [Batch 267/347] [D loss: 0.498908] [G loss: 0.264574]\n",
      "[Epoch 25/100] [Batch 268/347] [D loss: 0.498743] [G loss: 0.271269]\n",
      "[Epoch 25/100] [Batch 269/347] [D loss: 0.498425] [G loss: 0.282230]\n",
      "[Epoch 25/100] [Batch 270/347] [D loss: 0.498546] [G loss: 0.278680]\n",
      "[Epoch 25/100] [Batch 271/347] [D loss: 0.498875] [G loss: 0.266785]\n",
      "[Epoch 25/100] [Batch 272/347] [D loss: 0.499158] [G loss: 0.258177]\n",
      "[Epoch 25/100] [Batch 273/347] [D loss: 0.498490] [G loss: 0.270020]\n",
      "[Epoch 25/100] [Batch 274/347] [D loss: 0.492753] [G loss: 0.303380]\n",
      "[Epoch 25/100] [Batch 275/347] [D loss: 0.492837] [G loss: 0.299472]\n",
      "[Epoch 25/100] [Batch 276/347] [D loss: 0.498789] [G loss: 0.266307]\n",
      "[Epoch 25/100] [Batch 277/347] [D loss: 0.499316] [G loss: 0.253378]\n",
      "[Epoch 25/100] [Batch 278/347] [D loss: 0.499688] [G loss: 0.250668]\n",
      "[Epoch 25/100] [Batch 279/347] [D loss: 0.499602] [G loss: 0.257104]\n",
      "[Epoch 25/100] [Batch 280/347] [D loss: 0.499457] [G loss: 0.260255]\n",
      "[Epoch 25/100] [Batch 281/347] [D loss: 0.499468] [G loss: 0.258456]\n",
      "[Epoch 25/100] [Batch 282/347] [D loss: 0.499458] [G loss: 0.256486]\n",
      "[Epoch 25/100] [Batch 283/347] [D loss: 0.499212] [G loss: 0.257143]\n",
      "[Epoch 25/100] [Batch 284/347] [D loss: 0.499291] [G loss: 0.259739]\n",
      "[Epoch 25/100] [Batch 285/347] [D loss: 0.499478] [G loss: 0.255978]\n",
      "[Epoch 25/100] [Batch 286/347] [D loss: 0.499367] [G loss: 0.249238]\n",
      "[Epoch 25/100] [Batch 287/347] [D loss: 0.499233] [G loss: 0.252487]\n",
      "[Epoch 25/100] [Batch 288/347] [D loss: 0.498248] [G loss: 0.280050]\n",
      "[Epoch 25/100] [Batch 289/347] [D loss: 0.498093] [G loss: 0.285188]\n",
      "[Epoch 25/100] [Batch 290/347] [D loss: 0.498858] [G loss: 0.262994]\n",
      "[Epoch 25/100] [Batch 291/347] [D loss: 0.498704] [G loss: 0.266137]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 25/100] [Batch 292/347] [D loss: 0.499001] [G loss: 0.257945]\n",
      "[Epoch 25/100] [Batch 293/347] [D loss: 0.499853] [G loss: 0.268474]\n",
      "[Epoch 25/100] [Batch 294/347] [D loss: 0.500106] [G loss: 0.278066]\n",
      "[Epoch 25/100] [Batch 295/347] [D loss: 0.499501] [G loss: 0.275420]\n",
      "[Epoch 25/100] [Batch 296/347] [D loss: 0.499681] [G loss: 0.271180]\n",
      "[Epoch 25/100] [Batch 297/347] [D loss: 0.500303] [G loss: 0.282463]\n",
      "[Epoch 25/100] [Batch 298/347] [D loss: 0.500151] [G loss: 0.277127]\n",
      "[Epoch 25/100] [Batch 299/347] [D loss: 0.500136] [G loss: 0.275717]\n",
      "[Epoch 25/100] [Batch 300/347] [D loss: 0.499940] [G loss: 0.271097]\n",
      "[Epoch 25/100] [Batch 301/347] [D loss: 0.499927] [G loss: 0.272438]\n",
      "[Epoch 25/100] [Batch 302/347] [D loss: 0.500130] [G loss: 0.277581]\n",
      "[Epoch 25/100] [Batch 303/347] [D loss: 0.499274] [G loss: 0.261811]\n",
      "[Epoch 25/100] [Batch 304/347] [D loss: 0.498633] [G loss: 0.267478]\n",
      "[Epoch 25/100] [Batch 305/347] [D loss: 0.498528] [G loss: 0.279724]\n",
      "[Epoch 25/100] [Batch 306/347] [D loss: 0.498287] [G loss: 0.271201]\n",
      "[Epoch 25/100] [Batch 307/347] [D loss: 0.497964] [G loss: 0.283040]\n",
      "[Epoch 25/100] [Batch 308/347] [D loss: 0.498105] [G loss: 0.278446]\n",
      "[Epoch 25/100] [Batch 309/347] [D loss: 0.499027] [G loss: 0.257634]\n",
      "[Epoch 25/100] [Batch 310/347] [D loss: 0.499821] [G loss: 0.272681]\n",
      "[Epoch 25/100] [Batch 311/347] [D loss: 0.499857] [G loss: 0.275126]\n",
      "[Epoch 25/100] [Batch 312/347] [D loss: 0.499824] [G loss: 0.274508]\n",
      "[Epoch 25/100] [Batch 313/347] [D loss: 0.499837] [G loss: 0.273505]\n",
      "[Epoch 25/100] [Batch 314/347] [D loss: 0.499761] [G loss: 0.266939]\n",
      "[Epoch 25/100] [Batch 315/347] [D loss: 0.499587] [G loss: 0.257772]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 25/100] [Batch 316/347] [D loss: 0.498923] [G loss: 0.257434]\n",
      "[Epoch 25/100] [Batch 317/347] [D loss: 0.498387] [G loss: 0.276039]\n",
      "[Epoch 25/100] [Batch 318/347] [D loss: 0.499115] [G loss: 0.253714]\n",
      "[Epoch 25/100] [Batch 319/347] [D loss: 0.500213] [G loss: 0.280957]\n",
      "[Epoch 25/100] [Batch 320/347] [D loss: 0.500594] [G loss: 0.294864]\n",
      "[Epoch 25/100] [Batch 321/347] [D loss: 0.500307] [G loss: 0.284706]\n",
      "[Epoch 25/100] [Batch 322/347] [D loss: 0.499928] [G loss: 0.271741]\n",
      "[Epoch 25/100] [Batch 323/347] [D loss: 0.499916] [G loss: 0.271020]\n",
      "[Epoch 25/100] [Batch 324/347] [D loss: 0.500037] [G loss: 0.274350]\n",
      "[Epoch 25/100] [Batch 325/347] [D loss: 0.499697] [G loss: 0.263947]\n",
      "[Epoch 25/100] [Batch 326/347] [D loss: 0.499283] [G loss: 0.254120]\n",
      "[Epoch 25/100] [Batch 327/347] [D loss: 0.499279] [G loss: 0.252545]\n",
      "[Epoch 25/100] [Batch 328/347] [D loss: 0.499207] [G loss: 0.250985]\n",
      "[Epoch 25/100] [Batch 329/347] [D loss: 0.498437] [G loss: 0.273506]\n",
      "[Epoch 25/100] [Batch 330/347] [D loss: 0.497876] [G loss: 0.288556]\n",
      "[Epoch 25/100] [Batch 331/347] [D loss: 0.498536] [G loss: 0.269826]\n",
      "[Epoch 25/100] [Batch 332/347] [D loss: 0.499626] [G loss: 0.265495]\n",
      "[Epoch 25/100] [Batch 333/347] [D loss: 0.499938] [G loss: 0.276972]\n",
      "[Epoch 25/100] [Batch 334/347] [D loss: 0.500064] [G loss: 0.278371]\n",
      "[Epoch 25/100] [Batch 335/347] [D loss: 0.499768] [G loss: 0.266346]\n",
      "[Epoch 25/100] [Batch 336/347] [D loss: 0.499325] [G loss: 0.252492]\n",
      "[Epoch 25/100] [Batch 337/347] [D loss: 0.499468] [G loss: 0.257772]\n",
      "[Epoch 25/100] [Batch 338/347] [D loss: 0.499881] [G loss: 0.272602]\n",
      "[Epoch 25/100] [Batch 339/347] [D loss: 0.500043] [G loss: 0.278161]\n",
      "[Epoch 25/100] [Batch 340/347] [D loss: 0.500040] [G loss: 0.278754]\n",
      "[Epoch 25/100] [Batch 341/347] [D loss: 0.499954] [G loss: 0.274127]\n",
      "[Epoch 25/100] [Batch 342/347] [D loss: 0.499717] [G loss: 0.266652]\n",
      "[Epoch 25/100] [Batch 343/347] [D loss: 0.499756] [G loss: 0.271541]\n",
      "[Epoch 25/100] [Batch 344/347] [D loss: 0.499363] [G loss: 0.260209]\n",
      "[Epoch 25/100] [Batch 345/347] [D loss: 0.498367] [G loss: 0.270744]\n",
      "[Epoch 25/100] [Batch 346/347] [D loss: 0.497651] [G loss: 0.288827]\n",
      "[Epoch 25/100] [Batch 347/347] [D loss: 0.497130] [G loss: 0.294475]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 26/100] [Batch 1/347] [D loss: 0.499135] [G loss: 0.259995]\n",
      "[Epoch 26/100] [Batch 2/347] [D loss: 0.499150] [G loss: 0.264939]\n",
      "[Epoch 26/100] [Batch 3/347] [D loss: 0.499421] [G loss: 0.264588]\n",
      "[Epoch 26/100] [Batch 4/347] [D loss: 0.499427] [G loss: 0.265704]\n",
      "[Epoch 26/100] [Batch 5/347] [D loss: 0.499415] [G loss: 0.265038]\n",
      "[Epoch 26/100] [Batch 6/347] [D loss: 0.499476] [G loss: 0.265413]\n",
      "[Epoch 26/100] [Batch 7/347] [D loss: 0.499359] [G loss: 0.265337]\n",
      "[Epoch 26/100] [Batch 8/347] [D loss: 0.499312] [G loss: 0.260816]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 26/100] [Batch 9/347] [D loss: 0.499017] [G loss: 0.259961]\n",
      "[Epoch 26/100] [Batch 10/347] [D loss: 0.499030] [G loss: 0.261709]\n",
      "[Epoch 26/100] [Batch 11/347] [D loss: 0.499440] [G loss: 0.261641]\n",
      "[Epoch 26/100] [Batch 12/347] [D loss: 0.499569] [G loss: 0.265257]\n",
      "[Epoch 26/100] [Batch 13/347] [D loss: 0.499743] [G loss: 0.269419]\n",
      "[Epoch 26/100] [Batch 14/347] [D loss: 0.499866] [G loss: 0.271659]\n",
      "[Epoch 26/100] [Batch 15/347] [D loss: 0.499759] [G loss: 0.267679]\n",
      "[Epoch 26/100] [Batch 16/347] [D loss: 0.499653] [G loss: 0.263512]\n",
      "[Epoch 26/100] [Batch 17/347] [D loss: 0.499360] [G loss: 0.251583]\n",
      "[Epoch 26/100] [Batch 18/347] [D loss: 0.499149] [G loss: 0.255131]\n",
      "[Epoch 26/100] [Batch 19/347] [D loss: 0.499533] [G loss: 0.256840]\n",
      "[Epoch 26/100] [Batch 20/347] [D loss: 0.499866] [G loss: 0.269944]\n",
      "[Epoch 26/100] [Batch 21/347] [D loss: 0.499726] [G loss: 0.266192]\n",
      "[Epoch 26/100] [Batch 22/347] [D loss: 0.499578] [G loss: 0.261149]\n",
      "[Epoch 26/100] [Batch 23/347] [D loss: 0.499421] [G loss: 0.254822]\n",
      "[Epoch 26/100] [Batch 24/347] [D loss: 0.499424] [G loss: 0.254008]\n",
      "[Epoch 26/100] [Batch 25/347] [D loss: 0.499376] [G loss: 0.253404]\n",
      "[Epoch 26/100] [Batch 26/347] [D loss: 0.498859] [G loss: 0.261202]\n",
      "[Epoch 26/100] [Batch 27/347] [D loss: 0.498748] [G loss: 0.266820]\n",
      "[Epoch 26/100] [Batch 28/347] [D loss: 0.499219] [G loss: 0.264975]\n",
      "[Epoch 26/100] [Batch 29/347] [D loss: 0.499814] [G loss: 0.263738]\n",
      "[Epoch 26/100] [Batch 30/347] [D loss: 0.500030] [G loss: 0.270523]\n",
      "[Epoch 26/100] [Batch 31/347] [D loss: 0.500109] [G loss: 0.272943]\n",
      "[Epoch 26/100] [Batch 32/347] [D loss: 0.499892] [G loss: 0.266032]\n",
      "[Epoch 26/100] [Batch 33/347] [D loss: 0.499715] [G loss: 0.261860]\n",
      "[Epoch 26/100] [Batch 34/347] [D loss: 0.499756] [G loss: 0.262989]\n",
      "[Epoch 26/100] [Batch 35/347] [D loss: 0.499718] [G loss: 0.261893]\n",
      "[Epoch 26/100] [Batch 36/347] [D loss: 0.499434] [G loss: 0.252873]\n",
      "[Epoch 26/100] [Batch 37/347] [D loss: 0.498546] [G loss: 0.271442]\n",
      "[Epoch 26/100] [Batch 38/347] [D loss: 0.497976] [G loss: 0.286402]\n",
      "[Epoch 26/100] [Batch 39/347] [D loss: 0.498242] [G loss: 0.276454]\n",
      "[Epoch 26/100] [Batch 40/347] [D loss: 0.498420] [G loss: 0.277987]\n",
      "[Epoch 26/100] [Batch 41/347] [D loss: 0.498320] [G loss: 0.278981]\n",
      "[Epoch 26/100] [Batch 42/347] [D loss: 0.498507] [G loss: 0.271673]\n",
      "[Epoch 26/100] [Batch 43/347] [D loss: 0.499114] [G loss: 0.253929]\n",
      "[Epoch 26/100] [Batch 44/347] [D loss: 0.499785] [G loss: 0.261125]\n",
      "[Epoch 26/100] [Batch 45/347] [D loss: 0.500326] [G loss: 0.278303]\n",
      "[Epoch 26/100] [Batch 46/347] [D loss: 0.500173] [G loss: 0.272879]\n",
      "[Epoch 26/100] [Batch 47/347] [D loss: 0.499200] [G loss: 0.252665]\n",
      "[Epoch 26/100] [Batch 48/347] [D loss: 0.498091] [G loss: 0.285207]\n",
      "[Epoch 26/100] [Batch 49/347] [D loss: 0.497715] [G loss: 0.293702]\n",
      "[Epoch 26/100] [Batch 50/347] [D loss: 0.497097] [G loss: 0.309034]\n",
      "[Epoch 26/100] [Batch 51/347] [D loss: 0.497637] [G loss: 0.293252]\n",
      "[Epoch 26/100] [Batch 52/347] [D loss: 0.499382] [G loss: 0.259500]\n",
      "[Epoch 26/100] [Batch 53/347] [D loss: 0.499164] [G loss: 0.255614]\n",
      "[Epoch 26/100] [Batch 54/347] [D loss: 0.497338] [G loss: 0.308368]\n",
      "[Epoch 26/100] [Batch 55/347] [D loss: 0.496316] [G loss: 0.330823]\n",
      "[Epoch 26/100] [Batch 56/347] [D loss: 0.496681] [G loss: 0.317511]\n",
      "[Epoch 26/100] [Batch 57/347] [D loss: 0.498129] [G loss: 0.282754]\n",
      "[Epoch 26/100] [Batch 58/347] [D loss: 0.499365] [G loss: 0.257977]\n",
      "[Epoch 26/100] [Batch 59/347] [D loss: 0.498877] [G loss: 0.265341]\n",
      "[Epoch 26/100] [Batch 60/347] [D loss: 0.498227] [G loss: 0.284465]\n",
      "[Epoch 26/100] [Batch 61/347] [D loss: 0.497796] [G loss: 0.297438]\n",
      "[Epoch 26/100] [Batch 62/347] [D loss: 0.496844] [G loss: 0.321733]\n",
      "[Epoch 26/100] [Batch 63/347] [D loss: 0.496487] [G loss: 0.323774]\n",
      "[Epoch 26/100] [Batch 64/347] [D loss: 0.497927] [G loss: 0.286605]\n",
      "[Epoch 26/100] [Batch 65/347] [D loss: 0.499868] [G loss: 0.262000]\n",
      "[Epoch 26/100] [Batch 66/347] [D loss: 0.499470] [G loss: 0.264363]\n",
      "[Epoch 26/100] [Batch 67/347] [D loss: 0.498361] [G loss: 0.271024]\n",
      "[Epoch 26/100] [Batch 68/347] [D loss: 0.497768] [G loss: 0.289505]\n",
      "[Epoch 26/100] [Batch 69/347] [D loss: 0.497130] [G loss: 0.308855]\n",
      "[Epoch 26/100] [Batch 70/347] [D loss: 0.497050] [G loss: 0.307628]\n",
      "[Epoch 26/100] [Batch 71/347] [D loss: 0.497126] [G loss: 0.309673]\n",
      "[Epoch 26/100] [Batch 72/347] [D loss: 0.496971] [G loss: 0.311989]\n",
      "[Epoch 26/100] [Batch 73/347] [D loss: 0.497895] [G loss: 0.287176]\n",
      "[Epoch 26/100] [Batch 74/347] [D loss: 0.498580] [G loss: 0.273181]\n",
      "[Epoch 26/100] [Batch 75/347] [D loss: 0.497525] [G loss: 0.303352]\n",
      "[Epoch 26/100] [Batch 76/347] [D loss: 0.497249] [G loss: 0.305635]\n",
      "[Epoch 26/100] [Batch 77/347] [D loss: 0.498534] [G loss: 0.271402]\n",
      "[Epoch 26/100] [Batch 78/347] [D loss: 0.499902] [G loss: 0.268108]\n",
      "[Epoch 26/100] [Batch 79/347] [D loss: 0.500310] [G loss: 0.269778]\n",
      "[Epoch 26/100] [Batch 80/347] [D loss: 0.500131] [G loss: 0.266958]\n",
      "[Epoch 26/100] [Batch 81/347] [D loss: 0.500344] [G loss: 0.271880]\n",
      "[Epoch 26/100] [Batch 82/347] [D loss: 0.500181] [G loss: 0.277348]\n",
      "[Epoch 26/100] [Batch 83/347] [D loss: 0.500039] [G loss: 0.269940]\n",
      "[Epoch 26/100] [Batch 84/347] [D loss: 0.500290] [G loss: 0.276296]\n",
      "[Epoch 26/100] [Batch 85/347] [D loss: 0.500260] [G loss: 0.277501]\n",
      "[Epoch 26/100] [Batch 86/347] [D loss: 0.500092] [G loss: 0.272332]\n",
      "[Epoch 26/100] [Batch 87/347] [D loss: 0.499998] [G loss: 0.270665]\n",
      "[Epoch 26/100] [Batch 88/347] [D loss: 0.500078] [G loss: 0.274454]\n",
      "[Epoch 26/100] [Batch 89/347] [D loss: 0.500155] [G loss: 0.278217]\n",
      "[Epoch 26/100] [Batch 90/347] [D loss: 0.500044] [G loss: 0.274791]\n",
      "[Epoch 26/100] [Batch 91/347] [D loss: 0.499990] [G loss: 0.273571]\n",
      "[Epoch 26/100] [Batch 92/347] [D loss: 0.500017] [G loss: 0.275254]\n",
      "[Epoch 26/100] [Batch 93/347] [D loss: 0.499933] [G loss: 0.273449]\n",
      "[Epoch 26/100] [Batch 94/347] [D loss: 0.499825] [G loss: 0.270042]\n",
      "[Epoch 26/100] [Batch 95/347] [D loss: 0.499854] [G loss: 0.270712]\n",
      "[Epoch 26/100] [Batch 96/347] [D loss: 0.499728] [G loss: 0.266038]\n",
      "[Epoch 26/100] [Batch 97/347] [D loss: 0.499548] [G loss: 0.261013]\n",
      "[Epoch 26/100] [Batch 98/347] [D loss: 0.499662] [G loss: 0.265979]\n",
      "[Epoch 26/100] [Batch 99/347] [D loss: 0.499782] [G loss: 0.269765]\n",
      "[Epoch 26/100] [Batch 100/347] [D loss: 0.499686] [G loss: 0.266097]\n",
      "[Epoch 26/100] [Batch 101/347] [D loss: 0.499525] [G loss: 0.260936]\n",
      "[Epoch 26/100] [Batch 102/347] [D loss: 0.499569] [G loss: 0.262431]\n",
      "[Epoch 26/100] [Batch 103/347] [D loss: 0.499590] [G loss: 0.263057]\n",
      "[Epoch 26/100] [Batch 104/347] [D loss: 0.499308] [G loss: 0.260510]\n",
      "[Epoch 26/100] [Batch 105/347] [D loss: 0.499267] [G loss: 0.262454]\n",
      "[Epoch 26/100] [Batch 106/347] [D loss: 0.499258] [G loss: 0.261694]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 26/100] [Batch 107/347] [D loss: 0.498990] [G loss: 0.255676]\n",
      "[Epoch 26/100] [Batch 108/347] [D loss: 0.498132] [G loss: 0.272618]\n",
      "[Epoch 26/100] [Batch 109/347] [D loss: 0.498382] [G loss: 0.265674]\n",
      "[Epoch 26/100] [Batch 110/347] [D loss: 0.499530] [G loss: 0.254112]\n",
      "[Epoch 26/100] [Batch 111/347] [D loss: 0.498735] [G loss: 0.259858]\n",
      "[Epoch 26/100] [Batch 112/347] [D loss: 0.498729] [G loss: 0.262964]\n",
      "[Epoch 26/100] [Batch 113/347] [D loss: 0.499939] [G loss: 0.268515]\n",
      "[Epoch 26/100] [Batch 114/347] [D loss: 0.500602] [G loss: 0.289092]\n",
      "[Epoch 26/100] [Batch 115/347] [D loss: 0.500660] [G loss: 0.290309]\n",
      "[Epoch 26/100] [Batch 116/347] [D loss: 0.500512] [G loss: 0.284638]\n",
      "[Epoch 26/100] [Batch 117/347] [D loss: 0.499730] [G loss: 0.258094]\n",
      "[Epoch 26/100] [Batch 118/347] [D loss: 0.498731] [G loss: 0.265297]\n",
      "[Epoch 26/100] [Batch 119/347] [D loss: 0.498582] [G loss: 0.267572]\n",
      "[Epoch 26/100] [Batch 120/347] [D loss: 0.498649] [G loss: 0.266403]\n",
      "[Epoch 26/100] [Batch 121/347] [D loss: 0.498705] [G loss: 0.264626]\n",
      "[Epoch 26/100] [Batch 122/347] [D loss: 0.499172] [G loss: 0.251975]\n",
      "[Epoch 26/100] [Batch 123/347] [D loss: 0.499305] [G loss: 0.251079]\n",
      "[Epoch 26/100] [Batch 124/347] [D loss: 0.499166] [G loss: 0.252461]\n",
      "[Epoch 26/100] [Batch 125/347] [D loss: 0.499567] [G loss: 0.257888]\n",
      "[Epoch 26/100] [Batch 126/347] [D loss: 0.499990] [G loss: 0.270621]\n",
      "[Epoch 26/100] [Batch 127/347] [D loss: 0.500062] [G loss: 0.272098]\n",
      "[Epoch 26/100] [Batch 128/347] [D loss: 0.499873] [G loss: 0.266710]\n",
      "[Epoch 26/100] [Batch 129/347] [D loss: 0.499788] [G loss: 0.261951]\n",
      "[Epoch 26/100] [Batch 130/347] [D loss: 0.499573] [G loss: 0.265571]\n",
      "[Epoch 26/100] [Batch 131/347] [D loss: 0.498684] [G loss: 0.263689]\n",
      "[Epoch 26/100] [Batch 132/347] [D loss: 0.497179] [G loss: 0.287331]\n",
      "[Epoch 26/100] [Batch 133/347] [D loss: 0.496919] [G loss: 0.293773]\n",
      "[Epoch 26/100] [Batch 134/347] [D loss: 0.496220] [G loss: 0.308158]\n",
      "[Epoch 26/100] [Batch 135/347] [D loss: 0.494904] [G loss: 0.316466]\n",
      "[Epoch 26/100] [Batch 136/347] [D loss: 0.496793] [G loss: 0.273602]\n",
      "[Epoch 26/100] [Batch 137/347] [D loss: 0.499292] [G loss: 0.262419]\n",
      "[Epoch 26/100] [Batch 138/347] [D loss: 0.498207] [G loss: 0.277823]\n",
      "[Epoch 26/100] [Batch 139/347] [D loss: 0.497258] [G loss: 0.301538]\n",
      "[Epoch 26/100] [Batch 140/347] [D loss: 0.496859] [G loss: 0.312714]\n",
      "[Epoch 26/100] [Batch 141/347] [D loss: 0.496602] [G loss: 0.319345]\n",
      "[Epoch 26/100] [Batch 142/347] [D loss: 0.496350] [G loss: 0.326657]\n",
      "[Epoch 26/100] [Batch 143/347] [D loss: 0.495420] [G loss: 0.347942]\n",
      "[Epoch 26/100] [Batch 144/347] [D loss: 0.495271] [G loss: 0.350017]\n",
      "[Epoch 26/100] [Batch 145/347] [D loss: 0.495716] [G loss: 0.335525]\n",
      "[Epoch 26/100] [Batch 146/347] [D loss: 0.496206] [G loss: 0.318791]\n",
      "[Epoch 26/100] [Batch 147/347] [D loss: 0.497323] [G loss: 0.290831]\n",
      "[Epoch 26/100] [Batch 148/347] [D loss: 0.497858] [G loss: 0.278861]\n",
      "[Epoch 26/100] [Batch 149/347] [D loss: 0.497357] [G loss: 0.292926]\n",
      "[Epoch 26/100] [Batch 150/347] [D loss: 0.497390] [G loss: 0.294166]\n",
      "[Epoch 26/100] [Batch 151/347] [D loss: 0.497920] [G loss: 0.284056]\n",
      "[Epoch 26/100] [Batch 152/347] [D loss: 0.497532] [G loss: 0.296023]\n",
      "[Epoch 26/100] [Batch 153/347] [D loss: 0.496646] [G loss: 0.317483]\n",
      "[Epoch 26/100] [Batch 154/347] [D loss: 0.496279] [G loss: 0.322218]\n",
      "[Epoch 26/100] [Batch 155/347] [D loss: 0.496725] [G loss: 0.309934]\n",
      "[Epoch 26/100] [Batch 156/347] [D loss: 0.497482] [G loss: 0.293836]\n",
      "[Epoch 26/100] [Batch 157/347] [D loss: 0.497383] [G loss: 0.300548]\n",
      "[Epoch 26/100] [Batch 158/347] [D loss: 0.496350] [G loss: 0.324753]\n",
      "[Epoch 26/100] [Batch 159/347] [D loss: 0.496276] [G loss: 0.322782]\n",
      "[Epoch 26/100] [Batch 160/347] [D loss: 0.497077] [G loss: 0.303175]\n",
      "[Epoch 26/100] [Batch 161/347] [D loss: 0.497512] [G loss: 0.295086]\n",
      "[Epoch 26/100] [Batch 162/347] [D loss: 0.497433] [G loss: 0.301294]\n",
      "[Epoch 26/100] [Batch 163/347] [D loss: 0.496634] [G loss: 0.320236]\n",
      "[Epoch 26/100] [Batch 164/347] [D loss: 0.495899] [G loss: 0.335897]\n",
      "[Epoch 26/100] [Batch 165/347] [D loss: 0.496125] [G loss: 0.327240]\n",
      "[Epoch 26/100] [Batch 166/347] [D loss: 0.497647] [G loss: 0.288895]\n",
      "[Epoch 26/100] [Batch 167/347] [D loss: 0.499037] [G loss: 0.264112]\n",
      "[Epoch 26/100] [Batch 168/347] [D loss: 0.499444] [G loss: 0.274577]\n",
      "[Epoch 26/100] [Batch 169/347] [D loss: 0.499819] [G loss: 0.273042]\n",
      "[Epoch 26/100] [Batch 170/347] [D loss: 0.500175] [G loss: 0.268942]\n",
      "[Epoch 26/100] [Batch 171/347] [D loss: 0.500599] [G loss: 0.277170]\n",
      "[Epoch 26/100] [Batch 172/347] [D loss: 0.500775] [G loss: 0.282133]\n",
      "[Epoch 26/100] [Batch 173/347] [D loss: 0.500319] [G loss: 0.271159]\n",
      "[Epoch 26/100] [Batch 174/347] [D loss: 0.500175] [G loss: 0.268986]\n",
      "[Epoch 26/100] [Batch 175/347] [D loss: 0.500484] [G loss: 0.279336]\n",
      "[Epoch 26/100] [Batch 176/347] [D loss: 0.500967] [G loss: 0.293208]\n",
      "[Epoch 26/100] [Batch 177/347] [D loss: 0.500971] [G loss: 0.294628]\n",
      "[Epoch 26/100] [Batch 178/347] [D loss: 0.500749] [G loss: 0.289090]\n",
      "[Epoch 26/100] [Batch 179/347] [D loss: 0.500511] [G loss: 0.282824]\n",
      "[Epoch 26/100] [Batch 180/347] [D loss: 0.500312] [G loss: 0.276769]\n",
      "[Epoch 26/100] [Batch 181/347] [D loss: 0.500303] [G loss: 0.277612]\n",
      "[Epoch 26/100] [Batch 182/347] [D loss: 0.500155] [G loss: 0.275905]\n",
      "[Epoch 26/100] [Batch 183/347] [D loss: 0.500310] [G loss: 0.280254]\n",
      "[Epoch 26/100] [Batch 184/347] [D loss: 0.500432] [G loss: 0.284437]\n",
      "[Epoch 26/100] [Batch 185/347] [D loss: 0.500397] [G loss: 0.283113]\n",
      "[Epoch 26/100] [Batch 186/347] [D loss: 0.500428] [G loss: 0.283026]\n",
      "[Epoch 26/100] [Batch 187/347] [D loss: 0.500278] [G loss: 0.277825]\n",
      "[Epoch 26/100] [Batch 188/347] [D loss: 0.500122] [G loss: 0.274572]\n",
      "[Epoch 26/100] [Batch 189/347] [D loss: 0.500088] [G loss: 0.273801]\n",
      "[Epoch 26/100] [Batch 190/347] [D loss: 0.499579] [G loss: 0.261929]\n",
      "[Epoch 26/100] [Batch 191/347] [D loss: 0.499025] [G loss: 0.261449]\n",
      "[Epoch 26/100] [Batch 192/347] [D loss: 0.499236] [G loss: 0.251345]\n",
      "[Epoch 26/100] [Batch 193/347] [D loss: 0.499655] [G loss: 0.260039]\n",
      "[Epoch 26/100] [Batch 194/347] [D loss: 0.499386] [G loss: 0.255862]\n",
      "[Epoch 26/100] [Batch 195/347] [D loss: 0.499068] [G loss: 0.262567]\n",
      "[Epoch 26/100] [Batch 196/347] [D loss: 0.498900] [G loss: 0.260034]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 26/100] [Batch 197/347] [D loss: 0.498930] [G loss: 0.255189]\n",
      "[Epoch 26/100] [Batch 198/347] [D loss: 0.499003] [G loss: 0.255117]\n",
      "[Epoch 26/100] [Batch 199/347] [D loss: 0.498997] [G loss: 0.256074]\n",
      "[Epoch 26/100] [Batch 200/347] [D loss: 0.499171] [G loss: 0.250930]\n",
      "[Epoch 26/100] [Batch 201/347] [D loss: 0.499233] [G loss: 0.250369]\n",
      "[Epoch 26/100] [Batch 202/347] [D loss: 0.498940] [G loss: 0.262078]\n",
      "[Epoch 26/100] [Batch 203/347] [D loss: 0.498714] [G loss: 0.270846]\n",
      "[Epoch 26/100] [Batch 204/347] [D loss: 0.498832] [G loss: 0.267366]\n",
      "[Epoch 26/100] [Batch 205/347] [D loss: 0.499001] [G loss: 0.259613]\n",
      "[Epoch 26/100] [Batch 206/347] [D loss: 0.499335] [G loss: 0.249667]\n",
      "[Epoch 26/100] [Batch 207/347] [D loss: 0.499865] [G loss: 0.260582]\n",
      "[Epoch 26/100] [Batch 208/347] [D loss: 0.499799] [G loss: 0.261445]\n",
      "[Epoch 26/100] [Batch 209/347] [D loss: 0.499549] [G loss: 0.255806]\n",
      "[Epoch 26/100] [Batch 210/347] [D loss: 0.499919] [G loss: 0.263869]\n",
      "[Epoch 26/100] [Batch 211/347] [D loss: 0.499835] [G loss: 0.261266]\n",
      "[Epoch 26/100] [Batch 212/347] [D loss: 0.499562] [G loss: 0.260312]\n",
      "[Epoch 26/100] [Batch 213/347] [D loss: 0.499270] [G loss: 0.266311]\n",
      "[Epoch 26/100] [Batch 214/347] [D loss: 0.497672] [G loss: 0.276394]\n",
      "[Epoch 26/100] [Batch 215/347] [D loss: 0.497385] [G loss: 0.284539]\n",
      "[Epoch 26/100] [Batch 216/347] [D loss: 0.499137] [G loss: 0.265604]\n",
      "[Epoch 26/100] [Batch 217/347] [D loss: 0.499749] [G loss: 0.266312]\n",
      "[Epoch 26/100] [Batch 218/347] [D loss: 0.500250] [G loss: 0.272605]\n",
      "[Epoch 26/100] [Batch 219/347] [D loss: 0.500737] [G loss: 0.284875]\n",
      "[Epoch 26/100] [Batch 220/347] [D loss: 0.501292] [G loss: 0.300617]\n",
      "[Epoch 26/100] [Batch 221/347] [D loss: 0.501358] [G loss: 0.301956]\n",
      "[Epoch 26/100] [Batch 222/347] [D loss: 0.501123] [G loss: 0.293962]\n",
      "[Epoch 26/100] [Batch 223/347] [D loss: 0.501061] [G loss: 0.292747]\n",
      "[Epoch 26/100] [Batch 224/347] [D loss: 0.500916] [G loss: 0.288821]\n",
      "[Epoch 26/100] [Batch 225/347] [D loss: 0.499914] [G loss: 0.275996]\n",
      "[Epoch 26/100] [Batch 226/347] [D loss: 0.498562] [G loss: 0.272699]\n",
      "[Epoch 26/100] [Batch 227/347] [D loss: 0.497896] [G loss: 0.282641]\n",
      "[Epoch 26/100] [Batch 228/347] [D loss: 0.497949] [G loss: 0.283327]\n",
      "[Epoch 26/100] [Batch 229/347] [D loss: 0.498373] [G loss: 0.277853]\n",
      "[Epoch 26/100] [Batch 230/347] [D loss: 0.498582] [G loss: 0.273422]\n",
      "[Epoch 26/100] [Batch 231/347] [D loss: 0.498362] [G loss: 0.272980]\n",
      "[Epoch 26/100] [Batch 232/347] [D loss: 0.498530] [G loss: 0.268608]\n",
      "[Epoch 26/100] [Batch 233/347] [D loss: 0.498570] [G loss: 0.266326]\n",
      "[Epoch 26/100] [Batch 234/347] [D loss: 0.498464] [G loss: 0.271123]\n",
      "[Epoch 26/100] [Batch 235/347] [D loss: 0.498942] [G loss: 0.259665]\n",
      "[Epoch 26/100] [Batch 236/347] [D loss: 0.499544] [G loss: 0.262173]\n",
      "[Epoch 26/100] [Batch 237/347] [D loss: 0.500018] [G loss: 0.264965]\n",
      "[Epoch 26/100] [Batch 238/347] [D loss: 0.500106] [G loss: 0.268811]\n",
      "[Epoch 26/100] [Batch 239/347] [D loss: 0.499996] [G loss: 0.266632]\n",
      "[Epoch 26/100] [Batch 240/347] [D loss: 0.499875] [G loss: 0.262826]\n",
      "[Epoch 26/100] [Batch 241/347] [D loss: 0.499671] [G loss: 0.257167]\n",
      "[Epoch 26/100] [Batch 242/347] [D loss: 0.499576] [G loss: 0.255443]\n",
      "[Epoch 26/100] [Batch 243/347] [D loss: 0.499838] [G loss: 0.263431]\n",
      "[Epoch 26/100] [Batch 244/347] [D loss: 0.500164] [G loss: 0.272638]\n",
      "[Epoch 26/100] [Batch 245/347] [D loss: 0.500309] [G loss: 0.271664]\n",
      "[Epoch 26/100] [Batch 246/347] [D loss: 0.499391] [G loss: 0.265342]\n",
      "[Epoch 26/100] [Batch 247/347] [D loss: 0.498521] [G loss: 0.268146]\n",
      "[Epoch 26/100] [Batch 248/347] [D loss: 0.498201] [G loss: 0.273242]\n",
      "[Epoch 26/100] [Batch 249/347] [D loss: 0.497982] [G loss: 0.279129]\n",
      "[Epoch 26/100] [Batch 250/347] [D loss: 0.498568] [G loss: 0.270157]\n",
      "[Epoch 26/100] [Batch 251/347] [D loss: 0.499535] [G loss: 0.266603]\n",
      "[Epoch 26/100] [Batch 252/347] [D loss: 0.499881] [G loss: 0.269756]\n",
      "[Epoch 26/100] [Batch 253/347] [D loss: 0.499903] [G loss: 0.270183]\n",
      "[Epoch 26/100] [Batch 254/347] [D loss: 0.499970] [G loss: 0.268421]\n",
      "[Epoch 26/100] [Batch 255/347] [D loss: 0.499531] [G loss: 0.266833]\n",
      "[Epoch 26/100] [Batch 256/347] [D loss: 0.499712] [G loss: 0.271991]\n",
      "[Epoch 26/100] [Batch 257/347] [D loss: 0.500287] [G loss: 0.273948]\n",
      "[Epoch 26/100] [Batch 258/347] [D loss: 0.499721] [G loss: 0.268880]\n",
      "[Epoch 26/100] [Batch 259/347] [D loss: 0.498615] [G loss: 0.268464]\n",
      "[Epoch 26/100] [Batch 260/347] [D loss: 0.497999] [G loss: 0.282571]\n",
      "[Epoch 26/100] [Batch 261/347] [D loss: 0.498375] [G loss: 0.274597]\n",
      "[Epoch 26/100] [Batch 262/347] [D loss: 0.498946] [G loss: 0.259050]\n",
      "[Epoch 26/100] [Batch 263/347] [D loss: 0.498890] [G loss: 0.259571]\n",
      "[Epoch 26/100] [Batch 264/347] [D loss: 0.498271] [G loss: 0.273741]\n",
      "[Epoch 26/100] [Batch 265/347] [D loss: 0.498043] [G loss: 0.278778]\n",
      "[Epoch 26/100] [Batch 266/347] [D loss: 0.498322] [G loss: 0.271435]\n",
      "[Epoch 26/100] [Batch 267/347] [D loss: 0.498591] [G loss: 0.264432]\n",
      "[Epoch 26/100] [Batch 268/347] [D loss: 0.498349] [G loss: 0.271140]\n",
      "[Epoch 26/100] [Batch 269/347] [D loss: 0.497946] [G loss: 0.282071]\n",
      "[Epoch 26/100] [Batch 270/347] [D loss: 0.498122] [G loss: 0.278547]\n",
      "[Epoch 26/100] [Batch 271/347] [D loss: 0.498546] [G loss: 0.266656]\n",
      "[Epoch 26/100] [Batch 272/347] [D loss: 0.498902] [G loss: 0.257998]\n",
      "[Epoch 26/100] [Batch 273/347] [D loss: 0.497741] [G loss: 0.269831]\n",
      "[Epoch 26/100] [Batch 274/347] [D loss: 0.487350] [G loss: 0.302971]\n",
      "[Epoch 26/100] [Batch 275/347] [D loss: 0.487475] [G loss: 0.298730]\n",
      "[Epoch 26/100] [Batch 276/347] [D loss: 0.498341] [G loss: 0.265270]\n",
      "[Epoch 26/100] [Batch 277/347] [D loss: 0.499095] [G loss: 0.251852]\n",
      "[Epoch 26/100] [Batch 278/347] [D loss: 0.499582] [G loss: 0.248935]\n",
      "[Epoch 26/100] [Batch 279/347] [D loss: 0.499457] [G loss: 0.255275]\n",
      "[Epoch 26/100] [Batch 280/347] [D loss: 0.499271] [G loss: 0.258376]\n",
      "[Epoch 26/100] [Batch 281/347] [D loss: 0.499295] [G loss: 0.256581]\n",
      "[Epoch 26/100] [Batch 282/347] [D loss: 0.499292] [G loss: 0.254652]\n",
      "[Epoch 26/100] [Batch 283/347] [D loss: 0.498965] [G loss: 0.255395]\n",
      "[Epoch 26/100] [Batch 284/347] [D loss: 0.499049] [G loss: 0.258116]\n",
      "[Epoch 26/100] [Batch 285/347] [D loss: 0.499310] [G loss: 0.254493]\n",
      "[Epoch 26/100] [Batch 286/347] [D loss: 0.499193] [G loss: 0.247925]\n",
      "[Epoch 26/100] [Batch 287/347] [D loss: 0.499018] [G loss: 0.251432]\n",
      "[Epoch 26/100] [Batch 288/347] [D loss: 0.497819] [G loss: 0.279134]\n",
      "[Epoch 26/100] [Batch 289/347] [D loss: 0.497636] [G loss: 0.284403]\n",
      "[Epoch 26/100] [Batch 290/347] [D loss: 0.498572] [G loss: 0.262316]\n",
      "[Epoch 26/100] [Batch 291/347] [D loss: 0.498382] [G loss: 0.265600]\n",
      "[Epoch 26/100] [Batch 292/347] [D loss: 0.498736] [G loss: 0.257550]\n",
      "[Epoch 26/100] [Batch 293/347] [D loss: 0.499755] [G loss: 0.268354]\n",
      "[Epoch 26/100] [Batch 294/347] [D loss: 0.500030] [G loss: 0.278034]\n",
      "[Epoch 26/100] [Batch 295/347] [D loss: 0.499123] [G loss: 0.275454]\n",
      "[Epoch 26/100] [Batch 296/347] [D loss: 0.499355] [G loss: 0.271278]\n",
      "[Epoch 26/100] [Batch 297/347] [D loss: 0.500291] [G loss: 0.282519]\n",
      "[Epoch 26/100] [Batch 298/347] [D loss: 0.500147] [G loss: 0.277195]\n",
      "[Epoch 26/100] [Batch 299/347] [D loss: 0.500113] [G loss: 0.275829]\n",
      "[Epoch 26/100] [Batch 300/347] [D loss: 0.499869] [G loss: 0.271254]\n",
      "[Epoch 26/100] [Batch 301/347] [D loss: 0.499826] [G loss: 0.272750]\n",
      "[Epoch 26/100] [Batch 302/347] [D loss: 0.500070] [G loss: 0.277916]\n",
      "[Epoch 26/100] [Batch 303/347] [D loss: 0.499040] [G loss: 0.262192]\n",
      "[Epoch 26/100] [Batch 304/347] [D loss: 0.498308] [G loss: 0.267266]\n",
      "[Epoch 26/100] [Batch 305/347] [D loss: 0.498203] [G loss: 0.279483]\n",
      "[Epoch 26/100] [Batch 306/347] [D loss: 0.497825] [G loss: 0.271077]\n",
      "[Epoch 26/100] [Batch 307/347] [D loss: 0.497346] [G loss: 0.282843]\n",
      "[Epoch 26/100] [Batch 308/347] [D loss: 0.497584] [G loss: 0.278216]\n",
      "[Epoch 26/100] [Batch 309/347] [D loss: 0.498794] [G loss: 0.257213]\n",
      "[Epoch 26/100] [Batch 310/347] [D loss: 0.499777] [G loss: 0.273037]\n",
      "[Epoch 26/100] [Batch 311/347] [D loss: 0.499823] [G loss: 0.275461]\n",
      "[Epoch 26/100] [Batch 312/347] [D loss: 0.499784] [G loss: 0.274823]\n",
      "[Epoch 26/100] [Batch 313/347] [D loss: 0.499793] [G loss: 0.273783]\n",
      "[Epoch 26/100] [Batch 314/347] [D loss: 0.499679] [G loss: 0.267206]\n",
      "[Epoch 26/100] [Batch 315/347] [D loss: 0.499431] [G loss: 0.257998]\n",
      "[Epoch 26/100] [Batch 316/347] [D loss: 0.498654] [G loss: 0.256780]\n",
      "[Epoch 26/100] [Batch 317/347] [D loss: 0.498036] [G loss: 0.275366]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 26/100] [Batch 318/347] [D loss: 0.498907] [G loss: 0.252996]\n",
      "[Epoch 26/100] [Batch 319/347] [D loss: 0.500239] [G loss: 0.281191]\n",
      "[Epoch 26/100] [Batch 320/347] [D loss: 0.500707] [G loss: 0.295074]\n",
      "[Epoch 26/100] [Batch 321/347] [D loss: 0.500353] [G loss: 0.284875]\n",
      "[Epoch 26/100] [Batch 322/347] [D loss: 0.499884] [G loss: 0.271868]\n",
      "[Epoch 26/100] [Batch 323/347] [D loss: 0.499863] [G loss: 0.271135]\n",
      "[Epoch 26/100] [Batch 324/347] [D loss: 0.500011] [G loss: 0.274465]\n",
      "[Epoch 26/100] [Batch 325/347] [D loss: 0.499572] [G loss: 0.264083]\n",
      "[Epoch 26/100] [Batch 326/347] [D loss: 0.499055] [G loss: 0.254481]\n",
      "[Epoch 26/100] [Batch 327/347] [D loss: 0.499065] [G loss: 0.252957]\n",
      "[Epoch 26/100] [Batch 328/347] [D loss: 0.499001] [G loss: 0.250700]\n",
      "[Epoch 26/100] [Batch 329/347] [D loss: 0.498013] [G loss: 0.273001]\n",
      "[Epoch 26/100] [Batch 330/347] [D loss: 0.497315] [G loss: 0.288296]\n",
      "[Epoch 26/100] [Batch 331/347] [D loss: 0.498132] [G loss: 0.269802]\n",
      "[Epoch 26/100] [Batch 332/347] [D loss: 0.499485] [G loss: 0.264984]\n",
      "[Epoch 26/100] [Batch 333/347] [D loss: 0.499864] [G loss: 0.276336]\n",
      "[Epoch 26/100] [Batch 334/347] [D loss: 0.499999] [G loss: 0.277615]\n",
      "[Epoch 26/100] [Batch 335/347] [D loss: 0.499608] [G loss: 0.265510]\n",
      "[Epoch 26/100] [Batch 336/347] [D loss: 0.499058] [G loss: 0.251422]\n",
      "[Epoch 26/100] [Batch 337/347] [D loss: 0.499238] [G loss: 0.256731]\n",
      "[Epoch 26/100] [Batch 338/347] [D loss: 0.499752] [G loss: 0.271490]\n",
      "[Epoch 26/100] [Batch 339/347] [D loss: 0.499947] [G loss: 0.276975]\n",
      "[Epoch 26/100] [Batch 340/347] [D loss: 0.499945] [G loss: 0.277534]\n",
      "[Epoch 26/100] [Batch 341/347] [D loss: 0.499826] [G loss: 0.272843]\n",
      "[Epoch 26/100] [Batch 342/347] [D loss: 0.499528] [G loss: 0.265288]\n",
      "[Epoch 26/100] [Batch 343/347] [D loss: 0.499587] [G loss: 0.270104]\n",
      "[Epoch 26/100] [Batch 344/347] [D loss: 0.499099] [G loss: 0.262005]\n",
      "[Epoch 26/100] [Batch 345/347] [D loss: 0.497851] [G loss: 0.272301]\n",
      "[Epoch 26/100] [Batch 346/347] [D loss: 0.496855] [G loss: 0.290363]\n",
      "[Epoch 26/100] [Batch 347/347] [D loss: 0.495933] [G loss: 0.295962]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 27/100] [Batch 1/347] [D loss: 0.498827] [G loss: 0.261744]\n",
      "[Epoch 27/100] [Batch 2/347] [D loss: 0.498851] [G loss: 0.266651]\n",
      "[Epoch 27/100] [Batch 3/347] [D loss: 0.499189] [G loss: 0.266297]\n",
      "[Epoch 27/100] [Batch 4/347] [D loss: 0.499195] [G loss: 0.267425]\n",
      "[Epoch 27/100] [Batch 5/347] [D loss: 0.499179] [G loss: 0.266734]\n",
      "[Epoch 27/100] [Batch 6/347] [D loss: 0.499253] [G loss: 0.267127]\n",
      "[Epoch 27/100] [Batch 7/347] [D loss: 0.499106] [G loss: 0.267087]\n",
      "[Epoch 27/100] [Batch 8/347] [D loss: 0.499041] [G loss: 0.262546]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 27/100] [Batch 9/347] [D loss: 0.498668] [G loss: 0.261695]\n",
      "[Epoch 27/100] [Batch 10/347] [D loss: 0.498690] [G loss: 0.263510]\n",
      "[Epoch 27/100] [Batch 11/347] [D loss: 0.499200] [G loss: 0.263438]\n",
      "[Epoch 27/100] [Batch 12/347] [D loss: 0.499366] [G loss: 0.264189]\n",
      "[Epoch 27/100] [Batch 13/347] [D loss: 0.499588] [G loss: 0.267727]\n",
      "[Epoch 27/100] [Batch 14/347] [D loss: 0.499751] [G loss: 0.270207]\n",
      "[Epoch 27/100] [Batch 15/347] [D loss: 0.499627] [G loss: 0.266445]\n",
      "[Epoch 27/100] [Batch 16/347] [D loss: 0.499506] [G loss: 0.262478]\n",
      "[Epoch 27/100] [Batch 17/347] [D loss: 0.499138] [G loss: 0.250738]\n",
      "[Epoch 27/100] [Batch 18/347] [D loss: 0.498885] [G loss: 0.255354]\n",
      "[Epoch 27/100] [Batch 19/347] [D loss: 0.499375] [G loss: 0.256354]\n",
      "[Epoch 27/100] [Batch 20/347] [D loss: 0.499806] [G loss: 0.269655]\n",
      "[Epoch 27/100] [Batch 21/347] [D loss: 0.499646] [G loss: 0.266046]\n",
      "[Epoch 27/100] [Batch 22/347] [D loss: 0.499472] [G loss: 0.261169]\n",
      "[Epoch 27/100] [Batch 23/347] [D loss: 0.499275] [G loss: 0.254973]\n",
      "[Epoch 27/100] [Batch 24/347] [D loss: 0.499273] [G loss: 0.254231]\n",
      "[Epoch 27/100] [Batch 25/347] [D loss: 0.499226] [G loss: 0.253749]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 27/100] [Batch 26/347] [D loss: 0.498573] [G loss: 0.260650]\n",
      "[Epoch 27/100] [Batch 27/347] [D loss: 0.498327] [G loss: 0.266189]\n",
      "[Epoch 27/100] [Batch 28/347] [D loss: 0.498903] [G loss: 0.265759]\n",
      "[Epoch 27/100] [Batch 29/347] [D loss: 0.499767] [G loss: 0.264426]\n",
      "[Epoch 27/100] [Batch 30/347] [D loss: 0.500020] [G loss: 0.271262]\n",
      "[Epoch 27/100] [Batch 31/347] [D loss: 0.500095] [G loss: 0.273744]\n",
      "[Epoch 27/100] [Batch 32/347] [D loss: 0.499800] [G loss: 0.266838]\n",
      "[Epoch 27/100] [Batch 33/347] [D loss: 0.499617] [G loss: 0.262678]\n",
      "[Epoch 27/100] [Batch 34/347] [D loss: 0.499698] [G loss: 0.263848]\n",
      "[Epoch 27/100] [Batch 35/347] [D loss: 0.499657] [G loss: 0.262786]\n",
      "[Epoch 27/100] [Batch 36/347] [D loss: 0.499311] [G loss: 0.253825]\n",
      "[Epoch 27/100] [Batch 37/347] [D loss: 0.498209] [G loss: 0.270259]\n",
      "[Epoch 27/100] [Batch 38/347] [D loss: 0.497523] [G loss: 0.285148]\n",
      "[Epoch 27/100] [Batch 39/347] [D loss: 0.497872] [G loss: 0.275135]\n",
      "[Epoch 27/100] [Batch 40/347] [D loss: 0.498127] [G loss: 0.276326]\n",
      "[Epoch 27/100] [Batch 41/347] [D loss: 0.498011] [G loss: 0.277282]\n",
      "[Epoch 27/100] [Batch 42/347] [D loss: 0.498231] [G loss: 0.269908]\n",
      "[Epoch 27/100] [Batch 43/347] [D loss: 0.498950] [G loss: 0.252363]\n",
      "[Epoch 27/100] [Batch 44/347] [D loss: 0.499762] [G loss: 0.262365]\n",
      "[Epoch 27/100] [Batch 45/347] [D loss: 0.500426] [G loss: 0.279556]\n",
      "[Epoch 27/100] [Batch 46/347] [D loss: 0.500240] [G loss: 0.274158]\n",
      "[Epoch 27/100] [Batch 47/347] [D loss: 0.499048] [G loss: 0.251248]\n",
      "[Epoch 27/100] [Batch 48/347] [D loss: 0.497658] [G loss: 0.283815]\n",
      "[Epoch 27/100] [Batch 49/347] [D loss: 0.497189] [G loss: 0.292270]\n",
      "[Epoch 27/100] [Batch 50/347] [D loss: 0.496278] [G loss: 0.307546]\n",
      "[Epoch 27/100] [Batch 51/347] [D loss: 0.496863] [G loss: 0.291712]\n",
      "[Epoch 27/100] [Batch 52/347] [D loss: 0.499183] [G loss: 0.260795]\n",
      "[Epoch 27/100] [Batch 53/347] [D loss: 0.498969] [G loss: 0.255204]\n",
      "[Epoch 27/100] [Batch 54/347] [D loss: 0.496686] [G loss: 0.307052]\n",
      "[Epoch 27/100] [Batch 55/347] [D loss: 0.495461] [G loss: 0.329765]\n",
      "[Epoch 27/100] [Batch 56/347] [D loss: 0.495908] [G loss: 0.316612]\n",
      "[Epoch 27/100] [Batch 57/347] [D loss: 0.497628] [G loss: 0.281993]\n",
      "[Epoch 27/100] [Batch 58/347] [D loss: 0.499142] [G loss: 0.257879]\n",
      "[Epoch 27/100] [Batch 59/347] [D loss: 0.498500] [G loss: 0.264842]\n",
      "[Epoch 27/100] [Batch 60/347] [D loss: 0.497662] [G loss: 0.284091]\n",
      "[Epoch 27/100] [Batch 61/347] [D loss: 0.497123] [G loss: 0.297195]\n",
      "[Epoch 27/100] [Batch 62/347] [D loss: 0.495969] [G loss: 0.321584]\n",
      "[Epoch 27/100] [Batch 63/347] [D loss: 0.495598] [G loss: 0.323648]\n",
      "[Epoch 27/100] [Batch 64/347] [D loss: 0.497358] [G loss: 0.286474]\n",
      "[Epoch 27/100] [Batch 65/347] [D loss: 0.499736] [G loss: 0.260675]\n",
      "[Epoch 27/100] [Batch 66/347] [D loss: 0.499130] [G loss: 0.262934]\n",
      "[Epoch 27/100] [Batch 67/347] [D loss: 0.497607] [G loss: 0.271052]\n",
      "[Epoch 27/100] [Batch 68/347] [D loss: 0.496926] [G loss: 0.289562]\n",
      "[Epoch 27/100] [Batch 69/347] [D loss: 0.496333] [G loss: 0.308963]\n",
      "[Epoch 27/100] [Batch 70/347] [D loss: 0.496256] [G loss: 0.307708]\n",
      "[Epoch 27/100] [Batch 71/347] [D loss: 0.496307] [G loss: 0.309679]\n",
      "[Epoch 27/100] [Batch 72/347] [D loss: 0.496123] [G loss: 0.312014]\n",
      "[Epoch 27/100] [Batch 73/347] [D loss: 0.497261] [G loss: 0.287166]\n",
      "[Epoch 27/100] [Batch 74/347] [D loss: 0.498036] [G loss: 0.273140]\n",
      "[Epoch 27/100] [Batch 75/347] [D loss: 0.496748] [G loss: 0.303401]\n",
      "[Epoch 27/100] [Batch 76/347] [D loss: 0.496477] [G loss: 0.305745]\n",
      "[Epoch 27/100] [Batch 77/347] [D loss: 0.498051] [G loss: 0.271497]\n",
      "[Epoch 27/100] [Batch 78/347] [D loss: 0.499712] [G loss: 0.265830]\n",
      "[Epoch 27/100] [Batch 79/347] [D loss: 0.500241] [G loss: 0.268034]\n",
      "[Epoch 27/100] [Batch 80/347] [D loss: 0.500034] [G loss: 0.265588]\n",
      "[Epoch 27/100] [Batch 81/347] [D loss: 0.500282] [G loss: 0.270508]\n",
      "[Epoch 27/100] [Batch 82/347] [D loss: 0.500046] [G loss: 0.275310]\n",
      "[Epoch 27/100] [Batch 83/347] [D loss: 0.499885] [G loss: 0.267998]\n",
      "[Epoch 27/100] [Batch 84/347] [D loss: 0.500237] [G loss: 0.274989]\n",
      "[Epoch 27/100] [Batch 85/347] [D loss: 0.500218] [G loss: 0.276245]\n",
      "[Epoch 27/100] [Batch 86/347] [D loss: 0.500011] [G loss: 0.271060]\n",
      "[Epoch 27/100] [Batch 87/347] [D loss: 0.499893] [G loss: 0.269414]\n",
      "[Epoch 27/100] [Batch 88/347] [D loss: 0.499999] [G loss: 0.273199]\n",
      "[Epoch 27/100] [Batch 89/347] [D loss: 0.500096] [G loss: 0.276980]\n",
      "[Epoch 27/100] [Batch 90/347] [D loss: 0.499959] [G loss: 0.273535]\n",
      "[Epoch 27/100] [Batch 91/347] [D loss: 0.499896] [G loss: 0.272369]\n",
      "[Epoch 27/100] [Batch 92/347] [D loss: 0.499932] [G loss: 0.274094]\n",
      "[Epoch 27/100] [Batch 93/347] [D loss: 0.499832] [G loss: 0.272284]\n",
      "[Epoch 27/100] [Batch 94/347] [D loss: 0.499698] [G loss: 0.268889]\n",
      "[Epoch 27/100] [Batch 95/347] [D loss: 0.499736] [G loss: 0.269568]\n",
      "[Epoch 27/100] [Batch 96/347] [D loss: 0.499574] [G loss: 0.264934]\n",
      "[Epoch 27/100] [Batch 97/347] [D loss: 0.499352] [G loss: 0.259895]\n",
      "[Epoch 27/100] [Batch 98/347] [D loss: 0.499506] [G loss: 0.264888]\n",
      "[Epoch 27/100] [Batch 99/347] [D loss: 0.499661] [G loss: 0.268703]\n",
      "[Epoch 27/100] [Batch 100/347] [D loss: 0.499535] [G loss: 0.265084]\n",
      "[Epoch 27/100] [Batch 101/347] [D loss: 0.499341] [G loss: 0.259942]\n",
      "[Epoch 27/100] [Batch 102/347] [D loss: 0.499404] [G loss: 0.261493]\n",
      "[Epoch 27/100] [Batch 103/347] [D loss: 0.499428] [G loss: 0.262166]\n",
      "[Epoch 27/100] [Batch 104/347] [D loss: 0.499081] [G loss: 0.261123]\n",
      "[Epoch 27/100] [Batch 105/347] [D loss: 0.499037] [G loss: 0.263020]\n",
      "[Epoch 27/100] [Batch 106/347] [D loss: 0.499021] [G loss: 0.262251]\n",
      "[Epoch 27/100] [Batch 107/347] [D loss: 0.498635] [G loss: 0.256140]\n",
      "[Epoch 27/100] [Batch 108/347] [D loss: 0.497255] [G loss: 0.273040]\n",
      "[Epoch 27/100] [Batch 109/347] [D loss: 0.497537] [G loss: 0.266051]\n",
      "[Epoch 27/100] [Batch 110/347] [D loss: 0.499313] [G loss: 0.253344]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 27/100] [Batch 111/347] [D loss: 0.498083] [G loss: 0.260125]\n",
      "[Epoch 27/100] [Batch 112/347] [D loss: 0.498025] [G loss: 0.262002]\n",
      "[Epoch 27/100] [Batch 113/347] [D loss: 0.499748] [G loss: 0.267595]\n",
      "[Epoch 27/100] [Batch 114/347] [D loss: 0.500675] [G loss: 0.288127]\n",
      "[Epoch 27/100] [Batch 115/347] [D loss: 0.500738] [G loss: 0.289319]\n",
      "[Epoch 27/100] [Batch 116/347] [D loss: 0.500557] [G loss: 0.283639]\n",
      "[Epoch 27/100] [Batch 117/347] [D loss: 0.499564] [G loss: 0.257126]\n",
      "[Epoch 27/100] [Batch 118/347] [D loss: 0.498312] [G loss: 0.265303]\n",
      "[Epoch 27/100] [Batch 119/347] [D loss: 0.498134] [G loss: 0.267541]\n",
      "[Epoch 27/100] [Batch 120/347] [D loss: 0.498169] [G loss: 0.266303]\n",
      "[Epoch 27/100] [Batch 121/347] [D loss: 0.498242] [G loss: 0.264504]\n",
      "[Epoch 27/100] [Batch 122/347] [D loss: 0.498891] [G loss: 0.251868]\n",
      "[Epoch 27/100] [Batch 123/347] [D loss: 0.499081] [G loss: 0.250978]\n",
      "[Epoch 27/100] [Batch 124/347] [D loss: 0.498903] [G loss: 0.252370]\n",
      "[Epoch 27/100] [Batch 125/347] [D loss: 0.499401] [G loss: 0.257147]\n",
      "[Epoch 27/100] [Batch 126/347] [D loss: 0.499918] [G loss: 0.269942]\n",
      "[Epoch 27/100] [Batch 127/347] [D loss: 0.499997] [G loss: 0.271456]\n",
      "[Epoch 27/100] [Batch 128/347] [D loss: 0.499767] [G loss: 0.266149]\n",
      "[Epoch 27/100] [Batch 129/347] [D loss: 0.499633] [G loss: 0.261429]\n",
      "[Epoch 27/100] [Batch 130/347] [D loss: 0.499335] [G loss: 0.265098]\n",
      "[Epoch 27/100] [Batch 131/347] [D loss: 0.497980] [G loss: 0.263259]\n",
      "[Epoch 27/100] [Batch 132/347] [D loss: 0.495685] [G loss: 0.287447]\n",
      "[Epoch 27/100] [Batch 133/347] [D loss: 0.495465] [G loss: 0.293739]\n",
      "[Epoch 27/100] [Batch 134/347] [D loss: 0.494437] [G loss: 0.307965]\n",
      "[Epoch 27/100] [Batch 135/347] [D loss: 0.492099] [G loss: 0.316009]\n",
      "[Epoch 27/100] [Batch 136/347] [D loss: 0.494555] [G loss: 0.272828]\n",
      "[Epoch 27/100] [Batch 137/347] [D loss: 0.498934] [G loss: 0.261151]\n",
      "[Epoch 27/100] [Batch 138/347] [D loss: 0.497642] [G loss: 0.276666]\n",
      "[Epoch 27/100] [Batch 139/347] [D loss: 0.496445] [G loss: 0.300313]\n",
      "[Epoch 27/100] [Batch 140/347] [D loss: 0.495935] [G loss: 0.311449]\n",
      "[Epoch 27/100] [Batch 141/347] [D loss: 0.495642] [G loss: 0.318043]\n",
      "[Epoch 27/100] [Batch 142/347] [D loss: 0.495321] [G loss: 0.325369]\n",
      "[Epoch 27/100] [Batch 143/347] [D loss: 0.494135] [G loss: 0.346725]\n",
      "[Epoch 27/100] [Batch 144/347] [D loss: 0.493969] [G loss: 0.348931]\n",
      "[Epoch 27/100] [Batch 145/347] [D loss: 0.494581] [G loss: 0.334615]\n",
      "[Epoch 27/100] [Batch 146/347] [D loss: 0.495225] [G loss: 0.318048]\n",
      "[Epoch 27/100] [Batch 147/347] [D loss: 0.496629] [G loss: 0.290283]\n",
      "[Epoch 27/100] [Batch 148/347] [D loss: 0.497266] [G loss: 0.278493]\n",
      "[Epoch 27/100] [Batch 149/347] [D loss: 0.496638] [G loss: 0.292824]\n",
      "[Epoch 27/100] [Batch 150/347] [D loss: 0.496684] [G loss: 0.294272]\n",
      "[Epoch 27/100] [Batch 151/347] [D loss: 0.497312] [G loss: 0.284317]\n",
      "[Epoch 27/100] [Batch 152/347] [D loss: 0.496777] [G loss: 0.296450]\n",
      "[Epoch 27/100] [Batch 153/347] [D loss: 0.495672] [G loss: 0.318013]\n",
      "[Epoch 27/100] [Batch 154/347] [D loss: 0.495255] [G loss: 0.322786]\n",
      "[Epoch 27/100] [Batch 155/347] [D loss: 0.495825] [G loss: 0.310501]\n",
      "[Epoch 27/100] [Batch 156/347] [D loss: 0.496781] [G loss: 0.294339]\n",
      "[Epoch 27/100] [Batch 157/347] [D loss: 0.496584] [G loss: 0.300991]\n",
      "[Epoch 27/100] [Batch 158/347] [D loss: 0.495289] [G loss: 0.325085]\n",
      "[Epoch 27/100] [Batch 159/347] [D loss: 0.495232] [G loss: 0.322981]\n",
      "[Epoch 27/100] [Batch 160/347] [D loss: 0.496123] [G loss: 0.303178]\n",
      "[Epoch 27/100] [Batch 161/347] [D loss: 0.496611] [G loss: 0.294891]\n",
      "[Epoch 27/100] [Batch 162/347] [D loss: 0.496586] [G loss: 0.300870]\n",
      "[Epoch 27/100] [Batch 163/347] [D loss: 0.495596] [G loss: 0.319680]\n",
      "[Epoch 27/100] [Batch 164/347] [D loss: 0.494671] [G loss: 0.335131]\n",
      "[Epoch 27/100] [Batch 165/347] [D loss: 0.494980] [G loss: 0.326246]\n",
      "[Epoch 27/100] [Batch 166/347] [D loss: 0.496928] [G loss: 0.287772]\n",
      "[Epoch 27/100] [Batch 167/347] [D loss: 0.498594] [G loss: 0.262969]\n",
      "[Epoch 27/100] [Batch 168/347] [D loss: 0.499067] [G loss: 0.273382]\n",
      "[Epoch 27/100] [Batch 169/347] [D loss: 0.499642] [G loss: 0.271876]\n",
      "[Epoch 27/100] [Batch 170/347] [D loss: 0.500156] [G loss: 0.267830]\n",
      "[Epoch 27/100] [Batch 171/347] [D loss: 0.500701] [G loss: 0.276049]\n",
      "[Epoch 27/100] [Batch 172/347] [D loss: 0.500930] [G loss: 0.281144]\n",
      "[Epoch 27/100] [Batch 173/347] [D loss: 0.500341] [G loss: 0.270348]\n",
      "[Epoch 27/100] [Batch 174/347] [D loss: 0.500158] [G loss: 0.268372]\n",
      "[Epoch 27/100] [Batch 175/347] [D loss: 0.500570] [G loss: 0.278932]\n",
      "[Epoch 27/100] [Batch 176/347] [D loss: 0.501180] [G loss: 0.293017]\n",
      "[Epoch 27/100] [Batch 177/347] [D loss: 0.501193] [G loss: 0.294647]\n",
      "[Epoch 27/100] [Batch 178/347] [D loss: 0.500912] [G loss: 0.289281]\n",
      "[Epoch 27/100] [Batch 179/347] [D loss: 0.500614] [G loss: 0.283173]\n",
      "[Epoch 27/100] [Batch 180/347] [D loss: 0.500363] [G loss: 0.277230]\n",
      "[Epoch 27/100] [Batch 181/347] [D loss: 0.500359] [G loss: 0.278115]\n",
      "[Epoch 27/100] [Batch 182/347] [D loss: 0.500184] [G loss: 0.276444]\n",
      "[Epoch 27/100] [Batch 183/347] [D loss: 0.500370] [G loss: 0.280823]\n",
      "[Epoch 27/100] [Batch 184/347] [D loss: 0.500530] [G loss: 0.285035]\n",
      "[Epoch 27/100] [Batch 185/347] [D loss: 0.500488] [G loss: 0.283675]\n",
      "[Epoch 27/100] [Batch 186/347] [D loss: 0.500523] [G loss: 0.283562]\n",
      "[Epoch 27/100] [Batch 187/347] [D loss: 0.500329] [G loss: 0.278355]\n",
      "[Epoch 27/100] [Batch 188/347] [D loss: 0.500138] [G loss: 0.275019]\n",
      "[Epoch 27/100] [Batch 189/347] [D loss: 0.500091] [G loss: 0.274192]\n",
      "[Epoch 27/100] [Batch 190/347] [D loss: 0.499465] [G loss: 0.262278]\n",
      "[Epoch 27/100] [Batch 191/347] [D loss: 0.498778] [G loss: 0.260862]\n",
      "[Epoch 27/100] [Batch 192/347] [D loss: 0.499018] [G loss: 0.251378]\n",
      "[Epoch 27/100] [Batch 193/347] [D loss: 0.499525] [G loss: 0.259996]\n",
      "[Epoch 27/100] [Batch 194/347] [D loss: 0.499203] [G loss: 0.255542]\n",
      "[Epoch 27/100] [Batch 195/347] [D loss: 0.498796] [G loss: 0.262476]\n",
      "[Epoch 27/100] [Batch 196/347] [D loss: 0.498576] [G loss: 0.260089]\n",
      "[Epoch 27/100] [Batch 197/347] [D loss: 0.498582] [G loss: 0.255435]\n",
      "[Epoch 27/100] [Batch 198/347] [D loss: 0.498633] [G loss: 0.255442]\n",
      "[Epoch 27/100] [Batch 199/347] [D loss: 0.498614] [G loss: 0.256493]\n",
      "[Epoch 27/100] [Batch 200/347] [D loss: 0.498854] [G loss: 0.251474]\n",
      "[Epoch 27/100] [Batch 201/347] [D loss: 0.498930] [G loss: 0.251126]\n",
      "[Epoch 27/100] [Batch 202/347] [D loss: 0.498587] [G loss: 0.262977]\n",
      "[Epoch 27/100] [Batch 203/347] [D loss: 0.498316] [G loss: 0.271863]\n",
      "[Epoch 27/100] [Batch 204/347] [D loss: 0.498448] [G loss: 0.268509]\n",
      "[Epoch 27/100] [Batch 205/347] [D loss: 0.498643] [G loss: 0.260863]\n",
      "[Epoch 27/100] [Batch 206/347] [D loss: 0.499043] [G loss: 0.248911]\n",
      "[Epoch 27/100] [Batch 207/347] [D loss: 0.499701] [G loss: 0.259186]\n",
      "[Epoch 27/100] [Batch 208/347] [D loss: 0.499648] [G loss: 0.260312]\n",
      "[Epoch 27/100] [Batch 209/347] [D loss: 0.499339] [G loss: 0.254888]\n",
      "[Epoch 27/100] [Batch 210/347] [D loss: 0.499791] [G loss: 0.263165]\n",
      "[Epoch 27/100] [Batch 211/347] [D loss: 0.499701] [G loss: 0.260774]\n",
      "[Epoch 27/100] [Batch 212/347] [D loss: 0.499320] [G loss: 0.260053]\n",
      "[Epoch 27/100] [Batch 213/347] [D loss: 0.498843] [G loss: 0.266241]\n",
      "[Epoch 27/100] [Batch 214/347] [D loss: 0.496306] [G loss: 0.276634]\n",
      "[Epoch 27/100] [Batch 215/347] [D loss: 0.495975] [G loss: 0.284578]\n",
      "[Epoch 27/100] [Batch 216/347] [D loss: 0.498790] [G loss: 0.265626]\n",
      "[Epoch 27/100] [Batch 217/347] [D loss: 0.499614] [G loss: 0.266299]\n",
      "[Epoch 27/100] [Batch 218/347] [D loss: 0.500272] [G loss: 0.272468]\n",
      "[Epoch 27/100] [Batch 219/347] [D loss: 0.500870] [G loss: 0.284767]\n",
      "[Epoch 27/100] [Batch 220/347] [D loss: 0.501562] [G loss: 0.300608]\n",
      "[Epoch 27/100] [Batch 221/347] [D loss: 0.501641] [G loss: 0.301965]\n",
      "[Epoch 27/100] [Batch 222/347] [D loss: 0.501335] [G loss: 0.294036]\n",
      "[Epoch 27/100] [Batch 223/347] [D loss: 0.501255] [G loss: 0.292934]\n",
      "[Epoch 27/100] [Batch 224/347] [D loss: 0.501078] [G loss: 0.289104]\n",
      "[Epoch 27/100] [Batch 225/347] [D loss: 0.499820] [G loss: 0.276646]\n",
      "[Epoch 27/100] [Batch 226/347] [D loss: 0.498157] [G loss: 0.271911]\n",
      "[Epoch 27/100] [Batch 227/347] [D loss: 0.497385] [G loss: 0.281804]\n",
      "[Epoch 27/100] [Batch 228/347] [D loss: 0.497475] [G loss: 0.282129]\n",
      "[Epoch 27/100] [Batch 229/347] [D loss: 0.498011] [G loss: 0.276555]\n",
      "[Epoch 27/100] [Batch 230/347] [D loss: 0.498274] [G loss: 0.272027]\n",
      "[Epoch 27/100] [Batch 231/347] [D loss: 0.498005] [G loss: 0.271515]\n",
      "[Epoch 27/100] [Batch 232/347] [D loss: 0.498202] [G loss: 0.267108]\n",
      "[Epoch 27/100] [Batch 233/347] [D loss: 0.498233] [G loss: 0.265090]\n",
      "[Epoch 27/100] [Batch 234/347] [D loss: 0.498076] [G loss: 0.269888]\n",
      "[Epoch 27/100] [Batch 235/347] [D loss: 0.498651] [G loss: 0.258401]\n",
      "[Epoch 27/100] [Batch 236/347] [D loss: 0.499410] [G loss: 0.263325]\n",
      "[Epoch 27/100] [Batch 237/347] [D loss: 0.500015] [G loss: 0.265936]\n",
      "[Epoch 27/100] [Batch 238/347] [D loss: 0.500151] [G loss: 0.269864]\n",
      "[Epoch 27/100] [Batch 239/347] [D loss: 0.500008] [G loss: 0.267804]\n",
      "[Epoch 27/100] [Batch 240/347] [D loss: 0.499848] [G loss: 0.264074]\n",
      "[Epoch 27/100] [Batch 241/347] [D loss: 0.499591] [G loss: 0.258482]\n",
      "[Epoch 27/100] [Batch 242/347] [D loss: 0.499483] [G loss: 0.256877]\n",
      "[Epoch 27/100] [Batch 243/347] [D loss: 0.499823] [G loss: 0.264962]\n",
      "[Epoch 27/100] [Batch 244/347] [D loss: 0.500225] [G loss: 0.274249]\n",
      "[Epoch 27/100] [Batch 245/347] [D loss: 0.500371] [G loss: 0.273672]\n",
      "[Epoch 27/100] [Batch 246/347] [D loss: 0.499221] [G loss: 0.267353]\n",
      "[Epoch 27/100] [Batch 247/347] [D loss: 0.498191] [G loss: 0.267378]\n",
      "[Epoch 27/100] [Batch 248/347] [D loss: 0.497813] [G loss: 0.271998]\n",
      "[Epoch 27/100] [Batch 249/347] [D loss: 0.497536] [G loss: 0.278113]\n",
      "[Epoch 27/100] [Batch 250/347] [D loss: 0.498230] [G loss: 0.268953]\n",
      "[Epoch 27/100] [Batch 251/347] [D loss: 0.499414] [G loss: 0.268347]\n",
      "[Epoch 27/100] [Batch 252/347] [D loss: 0.499836] [G loss: 0.271395]\n",
      "[Epoch 27/100] [Batch 253/347] [D loss: 0.499867] [G loss: 0.271741]\n",
      "[Epoch 27/100] [Batch 254/347] [D loss: 0.499966] [G loss: 0.269910]\n",
      "[Epoch 27/100] [Batch 255/347] [D loss: 0.499373] [G loss: 0.268275]\n",
      "[Epoch 27/100] [Batch 256/347] [D loss: 0.499592] [G loss: 0.273404]\n",
      "[Epoch 27/100] [Batch 257/347] [D loss: 0.500339] [G loss: 0.275422]\n",
      "[Epoch 27/100] [Batch 258/347] [D loss: 0.499620] [G loss: 0.270375]\n",
      "[Epoch 27/100] [Batch 259/347] [D loss: 0.498226] [G loss: 0.266653]\n",
      "[Epoch 27/100] [Batch 260/347] [D loss: 0.497404] [G loss: 0.280735]\n",
      "[Epoch 27/100] [Batch 261/347] [D loss: 0.497864] [G loss: 0.272695]\n",
      "[Epoch 27/100] [Batch 262/347] [D loss: 0.498672] [G loss: 0.257118]\n",
      "[Epoch 27/100] [Batch 263/347] [D loss: 0.498588] [G loss: 0.257607]\n",
      "[Epoch 27/100] [Batch 264/347] [D loss: 0.497743] [G loss: 0.271766]\n",
      "[Epoch 27/100] [Batch 265/347] [D loss: 0.497456] [G loss: 0.276812]\n",
      "[Epoch 27/100] [Batch 266/347] [D loss: 0.497856] [G loss: 0.269452]\n",
      "[Epoch 27/100] [Batch 267/347] [D loss: 0.498212] [G loss: 0.262404]\n",
      "[Epoch 27/100] [Batch 268/347] [D loss: 0.497838] [G loss: 0.269087]\n",
      "[Epoch 27/100] [Batch 269/347] [D loss: 0.497297] [G loss: 0.280003]\n",
      "[Epoch 27/100] [Batch 270/347] [D loss: 0.497580] [G loss: 0.276473]\n",
      "[Epoch 27/100] [Batch 271/347] [D loss: 0.498163] [G loss: 0.264558]\n",
      "[Epoch 27/100] [Batch 272/347] [D loss: 0.498619] [G loss: 0.255934]\n",
      "[Epoch 27/100] [Batch 273/347] [D loss: 0.496541] [G loss: 0.267678]\n",
      "[Epoch 27/100] [Batch 274/347] [D loss: 0.477637] [G loss: 0.300520]\n",
      "[Epoch 27/100] [Batch 275/347] [D loss: 0.477813] [G loss: 0.295741]\n",
      "[Epoch 27/100] [Batch 276/347] [D loss: 0.497709] [G loss: 0.261878]\n",
      "[Epoch 27/100] [Batch 277/347] [D loss: 0.498851] [G loss: 0.252103]\n",
      "[Epoch 27/100] [Batch 278/347] [D loss: 0.499526] [G loss: 0.249097]\n",
      "[Epoch 27/100] [Batch 279/347] [D loss: 0.499333] [G loss: 0.255474]\n",
      "[Epoch 27/100] [Batch 280/347] [D loss: 0.499075] [G loss: 0.258706]\n",
      "[Epoch 27/100] [Batch 281/347] [D loss: 0.499120] [G loss: 0.257107]\n",
      "[Epoch 27/100] [Batch 282/347] [D loss: 0.499130] [G loss: 0.255469]\n",
      "[Epoch 27/100] [Batch 283/347] [D loss: 0.498691] [G loss: 0.256515]\n",
      "[Epoch 27/100] [Batch 284/347] [D loss: 0.498778] [G loss: 0.259590]\n",
      "[Epoch 27/100] [Batch 285/347] [D loss: 0.499166] [G loss: 0.256264]\n",
      "[Epoch 27/100] [Batch 286/347] [D loss: 0.499051] [G loss: 0.249975]\n",
      "[Epoch 27/100] [Batch 287/347] [D loss: 0.498844] [G loss: 0.250032]\n",
      "[Epoch 27/100] [Batch 288/347] [D loss: 0.497330] [G loss: 0.277609]\n",
      "[Epoch 27/100] [Batch 289/347] [D loss: 0.497096] [G loss: 0.283229]\n",
      "[Epoch 27/100] [Batch 290/347] [D loss: 0.498265] [G loss: 0.261364]\n",
      "[Epoch 27/100] [Batch 291/347] [D loss: 0.498004] [G loss: 0.264858]\n",
      "[Epoch 27/100] [Batch 292/347] [D loss: 0.498429] [G loss: 0.256953]\n",
      "[Epoch 27/100] [Batch 293/347] [D loss: 0.499651] [G loss: 0.269686]\n",
      "[Epoch 27/100] [Batch 294/347] [D loss: 0.499941] [G loss: 0.279136]\n",
      "[Epoch 27/100] [Batch 295/347] [D loss: 0.498495] [G loss: 0.276273]\n",
      "[Epoch 27/100] [Batch 296/347] [D loss: 0.498772] [G loss: 0.271768]\n",
      "[Epoch 27/100] [Batch 297/347] [D loss: 0.500259] [G loss: 0.282491]\n",
      "[Epoch 27/100] [Batch 298/347] [D loss: 0.500142] [G loss: 0.276946]\n",
      "[Epoch 27/100] [Batch 299/347] [D loss: 0.500066] [G loss: 0.275372]\n",
      "[Epoch 27/100] [Batch 300/347] [D loss: 0.499746] [G loss: 0.270641]\n",
      "[Epoch 27/100] [Batch 301/347] [D loss: 0.499653] [G loss: 0.272218]\n",
      "[Epoch 27/100] [Batch 302/347] [D loss: 0.499955] [G loss: 0.277289]\n",
      "[Epoch 27/100] [Batch 303/347] [D loss: 0.498664] [G loss: 0.261512]\n",
      "[Epoch 27/100] [Batch 304/347] [D loss: 0.497792] [G loss: 0.266363]\n",
      "[Epoch 27/100] [Batch 305/347] [D loss: 0.497691] [G loss: 0.278640]\n",
      "[Epoch 27/100] [Batch 306/347] [D loss: 0.497061] [G loss: 0.270430]\n",
      "[Epoch 27/100] [Batch 307/347] [D loss: 0.496295] [G loss: 0.282229]\n",
      "[Epoch 27/100] [Batch 308/347] [D loss: 0.496703] [G loss: 0.277678]\n",
      "[Epoch 27/100] [Batch 309/347] [D loss: 0.498404] [G loss: 0.256680]\n",
      "[Epoch 27/100] [Batch 310/347] [D loss: 0.499679] [G loss: 0.272629]\n",
      "[Epoch 27/100] [Batch 311/347] [D loss: 0.499744] [G loss: 0.275167]\n",
      "[Epoch 27/100] [Batch 312/347] [D loss: 0.499688] [G loss: 0.274686]\n",
      "[Epoch 27/100] [Batch 313/347] [D loss: 0.499688] [G loss: 0.273793]\n",
      "[Epoch 27/100] [Batch 314/347] [D loss: 0.499505] [G loss: 0.267384]\n",
      "[Epoch 27/100] [Batch 315/347] [D loss: 0.499135] [G loss: 0.258312]\n",
      "[Epoch 27/100] [Batch 316/347] [D loss: 0.498207] [G loss: 0.257277]\n",
      "[Epoch 27/100] [Batch 317/347] [D loss: 0.497470] [G loss: 0.275915]\n",
      "[Epoch 27/100] [Batch 318/347] [D loss: 0.498540] [G loss: 0.253588]\n",
      "[Epoch 27/100] [Batch 319/347] [D loss: 0.500216] [G loss: 0.281761]\n",
      "[Epoch 27/100] [Batch 320/347] [D loss: 0.500828] [G loss: 0.295632]\n",
      "[Epoch 27/100] [Batch 321/347] [D loss: 0.500370] [G loss: 0.285454]\n",
      "[Epoch 27/100] [Batch 322/347] [D loss: 0.499765] [G loss: 0.272443]\n",
      "[Epoch 27/100] [Batch 323/347] [D loss: 0.499729] [G loss: 0.271663]\n",
      "[Epoch 27/100] [Batch 324/347] [D loss: 0.499911] [G loss: 0.274934]\n",
      "[Epoch 27/100] [Batch 325/347] [D loss: 0.499318] [G loss: 0.264532]\n",
      "[Epoch 27/100] [Batch 326/347] [D loss: 0.498646] [G loss: 0.255109]\n",
      "[Epoch 27/100] [Batch 327/347] [D loss: 0.498685] [G loss: 0.253527]\n",
      "[Epoch 27/100] [Batch 328/347] [D loss: 0.498648] [G loss: 0.250963]\n",
      "[Epoch 27/100] [Batch 329/347] [D loss: 0.497334] [G loss: 0.273163]\n",
      "[Epoch 27/100] [Batch 330/347] [D loss: 0.496439] [G loss: 0.288295]\n",
      "[Epoch 27/100] [Batch 331/347] [D loss: 0.497513] [G loss: 0.269580]\n",
      "[Epoch 27/100] [Batch 332/347] [D loss: 0.499303] [G loss: 0.264809]\n",
      "[Epoch 27/100] [Batch 333/347] [D loss: 0.499805] [G loss: 0.276103]\n",
      "[Epoch 27/100] [Batch 334/347] [D loss: 0.499949] [G loss: 0.277352]\n",
      "[Epoch 27/100] [Batch 335/347] [D loss: 0.499424] [G loss: 0.265173]\n",
      "[Epoch 27/100] [Batch 336/347] [D loss: 0.498704] [G loss: 0.251341]\n",
      "[Epoch 27/100] [Batch 337/347] [D loss: 0.498957] [G loss: 0.256332]\n",
      "[Epoch 27/100] [Batch 338/347] [D loss: 0.499641] [G loss: 0.271144]\n",
      "[Epoch 27/100] [Batch 339/347] [D loss: 0.499900] [G loss: 0.276684]\n",
      "[Epoch 27/100] [Batch 340/347] [D loss: 0.499907] [G loss: 0.277269]\n",
      "[Epoch 27/100] [Batch 341/347] [D loss: 0.499736] [G loss: 0.272602]\n",
      "[Epoch 27/100] [Batch 342/347] [D loss: 0.499351] [G loss: 0.265119]\n",
      "[Epoch 27/100] [Batch 343/347] [D loss: 0.499460] [G loss: 0.269976]\n",
      "[Epoch 27/100] [Batch 344/347] [D loss: 0.498805] [G loss: 0.261027]\n",
      "[Epoch 27/100] [Batch 345/347] [D loss: 0.497176] [G loss: 0.271636]\n",
      "[Epoch 27/100] [Batch 346/347] [D loss: 0.495641] [G loss: 0.289582]\n",
      "[Epoch 27/100] [Batch 347/347] [D loss: 0.493822] [G loss: 0.294967]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 28/100] [Batch 1/347] [D loss: 0.498485] [G loss: 0.260241]\n",
      "[Epoch 28/100] [Batch 2/347] [D loss: 0.498530] [G loss: 0.265063]\n",
      "[Epoch 28/100] [Batch 3/347] [D loss: 0.498978] [G loss: 0.264654]\n",
      "[Epoch 28/100] [Batch 4/347] [D loss: 0.498994] [G loss: 0.265783]\n",
      "[Epoch 28/100] [Batch 5/347] [D loss: 0.498972] [G loss: 0.265154]\n",
      "[Epoch 28/100] [Batch 6/347] [D loss: 0.499068] [G loss: 0.265574]\n",
      "[Epoch 28/100] [Batch 7/347] [D loss: 0.498877] [G loss: 0.265682]\n",
      "[Epoch 28/100] [Batch 8/347] [D loss: 0.498766] [G loss: 0.261250]\n",
      "[Epoch 28/100] [Batch 9/347] [D loss: 0.498279] [G loss: 0.260464]\n",
      "[Epoch 28/100] [Batch 10/347] [D loss: 0.498311] [G loss: 0.262420]\n",
      "[Epoch 28/100] [Batch 11/347] [D loss: 0.498993] [G loss: 0.262466]\n",
      "[Epoch 28/100] [Batch 12/347] [D loss: 0.499208] [G loss: 0.263803]\n",
      "[Epoch 28/100] [Batch 13/347] [D loss: 0.499465] [G loss: 0.268067]\n",
      "[Epoch 28/100] [Batch 14/347] [D loss: 0.499654] [G loss: 0.270411]\n",
      "[Epoch 28/100] [Batch 15/347] [D loss: 0.499470] [G loss: 0.266538]\n",
      "[Epoch 28/100] [Batch 16/347] [D loss: 0.499292] [G loss: 0.262448]\n",
      "[Epoch 28/100] [Batch 17/347] [D loss: 0.498783] [G loss: 0.250985]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 28/100] [Batch 18/347] [D loss: 0.498457] [G loss: 0.256182]\n",
      "[Epoch 28/100] [Batch 19/347] [D loss: 0.499110] [G loss: 0.256412]\n",
      "[Epoch 28/100] [Batch 20/347] [D loss: 0.499697] [G loss: 0.269731]\n",
      "[Epoch 28/100] [Batch 21/347] [D loss: 0.499508] [G loss: 0.266167]\n",
      "[Epoch 28/100] [Batch 22/347] [D loss: 0.499289] [G loss: 0.261286]\n",
      "[Epoch 28/100] [Batch 23/347] [D loss: 0.499015] [G loss: 0.255125]\n",
      "[Epoch 28/100] [Batch 24/347] [D loss: 0.499011] [G loss: 0.254378]\n",
      "[Epoch 28/100] [Batch 25/347] [D loss: 0.498966] [G loss: 0.253883]\n",
      "[Epoch 28/100] [Batch 26/347] [D loss: 0.498088] [G loss: 0.260240]\n",
      "[Epoch 28/100] [Batch 27/347] [D loss: 0.497541] [G loss: 0.265621]\n",
      "[Epoch 28/100] [Batch 28/347] [D loss: 0.498265] [G loss: 0.266076]\n",
      "[Epoch 28/100] [Batch 29/347] [D loss: 0.499656] [G loss: 0.264442]\n",
      "[Epoch 28/100] [Batch 30/347] [D loss: 0.499959] [G loss: 0.271292]\n",
      "[Epoch 28/100] [Batch 31/347] [D loss: 0.500015] [G loss: 0.273775]\n",
      "[Epoch 28/100] [Batch 32/347] [D loss: 0.499582] [G loss: 0.266924]\n",
      "[Epoch 28/100] [Batch 33/347] [D loss: 0.499390] [G loss: 0.262809]\n",
      "[Epoch 28/100] [Batch 34/347] [D loss: 0.499564] [G loss: 0.264048]\n",
      "[Epoch 28/100] [Batch 35/347] [D loss: 0.499512] [G loss: 0.263100]\n",
      "[Epoch 28/100] [Batch 36/347] [D loss: 0.499081] [G loss: 0.254222]\n",
      "[Epoch 28/100] [Batch 37/347] [D loss: 0.497642] [G loss: 0.269224]\n",
      "[Epoch 28/100] [Batch 38/347] [D loss: 0.496765] [G loss: 0.284129]\n",
      "[Epoch 28/100] [Batch 39/347] [D loss: 0.497268] [G loss: 0.274045]\n",
      "[Epoch 28/100] [Batch 40/347] [D loss: 0.497649] [G loss: 0.274828]\n",
      "[Epoch 28/100] [Batch 41/347] [D loss: 0.497507] [G loss: 0.275736]\n",
      "[Epoch 28/100] [Batch 42/347] [D loss: 0.497785] [G loss: 0.268322]\n",
      "[Epoch 28/100] [Batch 43/347] [D loss: 0.498669] [G loss: 0.251116]\n",
      "[Epoch 28/100] [Batch 44/347] [D loss: 0.499689] [G loss: 0.263203]\n",
      "[Epoch 28/100] [Batch 45/347] [D loss: 0.500551] [G loss: 0.280430]\n",
      "[Epoch 28/100] [Batch 46/347] [D loss: 0.500305] [G loss: 0.275087]\n",
      "[Epoch 28/100] [Batch 47/347] [D loss: 0.498780] [G loss: 0.250172]\n",
      "[Epoch 28/100] [Batch 48/347] [D loss: 0.496944] [G loss: 0.282743]\n",
      "[Epoch 28/100] [Batch 49/347] [D loss: 0.496351] [G loss: 0.291160]\n",
      "[Epoch 28/100] [Batch 50/347] [D loss: 0.494893] [G loss: 0.306326]\n",
      "[Epoch 28/100] [Batch 51/347] [D loss: 0.495511] [G loss: 0.290309]\n",
      "[Epoch 28/100] [Batch 52/347] [D loss: 0.498808] [G loss: 0.261977]\n",
      "[Epoch 28/100] [Batch 53/347] [D loss: 0.498645] [G loss: 0.256303]\n",
      "[Epoch 28/100] [Batch 54/347] [D loss: 0.495656] [G loss: 0.305214]\n",
      "[Epoch 28/100] [Batch 55/347] [D loss: 0.494142] [G loss: 0.327840]\n",
      "[Epoch 28/100] [Batch 56/347] [D loss: 0.494731] [G loss: 0.314573]\n",
      "[Epoch 28/100] [Batch 57/347] [D loss: 0.496898] [G loss: 0.279826]\n",
      "[Epoch 28/100] [Batch 58/347] [D loss: 0.498855] [G loss: 0.258743]\n",
      "[Epoch 28/100] [Batch 59/347] [D loss: 0.497951] [G loss: 0.262613]\n",
      "[Epoch 28/100] [Batch 60/347] [D loss: 0.496828] [G loss: 0.281936]\n",
      "[Epoch 28/100] [Batch 61/347] [D loss: 0.496125] [G loss: 0.295104]\n",
      "[Epoch 28/100] [Batch 62/347] [D loss: 0.494676] [G loss: 0.319563]\n",
      "[Epoch 28/100] [Batch 63/347] [D loss: 0.494315] [G loss: 0.321710]\n",
      "[Epoch 28/100] [Batch 64/347] [D loss: 0.496587] [G loss: 0.284518]\n",
      "[Epoch 28/100] [Batch 65/347] [D loss: 0.499652] [G loss: 0.262115]\n",
      "[Epoch 28/100] [Batch 66/347] [D loss: 0.498633] [G loss: 0.264502]\n",
      "[Epoch 28/100] [Batch 67/347] [D loss: 0.496309] [G loss: 0.269377]\n",
      "[Epoch 28/100] [Batch 68/347] [D loss: 0.495565] [G loss: 0.287994]\n",
      "[Epoch 28/100] [Batch 69/347] [D loss: 0.495230] [G loss: 0.307419]\n",
      "[Epoch 28/100] [Batch 70/347] [D loss: 0.495172] [G loss: 0.306203]\n",
      "[Epoch 28/100] [Batch 71/347] [D loss: 0.495178] [G loss: 0.308138]\n",
      "[Epoch 28/100] [Batch 72/347] [D loss: 0.494945] [G loss: 0.310425]\n",
      "[Epoch 28/100] [Batch 73/347] [D loss: 0.496415] [G loss: 0.285557]\n",
      "[Epoch 28/100] [Batch 74/347] [D loss: 0.497309] [G loss: 0.271496]\n",
      "[Epoch 28/100] [Batch 75/347] [D loss: 0.495694] [G loss: 0.301738]\n",
      "[Epoch 28/100] [Batch 76/347] [D loss: 0.495450] [G loss: 0.304048]\n",
      "[Epoch 28/100] [Batch 77/347] [D loss: 0.497482] [G loss: 0.269786]\n",
      "[Epoch 28/100] [Batch 78/347] [D loss: 0.499586] [G loss: 0.267733]\n",
      "[Epoch 28/100] [Batch 79/347] [D loss: 0.500325] [G loss: 0.269597]\n",
      "[Epoch 28/100] [Batch 80/347] [D loss: 0.500089] [G loss: 0.267179]\n",
      "[Epoch 28/100] [Batch 81/347] [D loss: 0.500382] [G loss: 0.272155]\n",
      "[Epoch 28/100] [Batch 82/347] [D loss: 0.500021] [G loss: 0.277443]\n",
      "[Epoch 28/100] [Batch 83/347] [D loss: 0.499832] [G loss: 0.270179]\n",
      "[Epoch 28/100] [Batch 84/347] [D loss: 0.500348] [G loss: 0.276820]\n",
      "[Epoch 28/100] [Batch 85/347] [D loss: 0.500337] [G loss: 0.278122]\n",
      "[Epoch 28/100] [Batch 86/347] [D loss: 0.500075] [G loss: 0.273005]\n",
      "[Epoch 28/100] [Batch 87/347] [D loss: 0.499929] [G loss: 0.271411]\n",
      "[Epoch 28/100] [Batch 88/347] [D loss: 0.500071] [G loss: 0.275312]\n",
      "[Epoch 28/100] [Batch 89/347] [D loss: 0.500214] [G loss: 0.279118]\n",
      "[Epoch 28/100] [Batch 90/347] [D loss: 0.500034] [G loss: 0.275707]\n",
      "[Epoch 28/100] [Batch 91/347] [D loss: 0.499952] [G loss: 0.274548]\n",
      "[Epoch 28/100] [Batch 92/347] [D loss: 0.500010] [G loss: 0.276283]\n",
      "[Epoch 28/100] [Batch 93/347] [D loss: 0.499880] [G loss: 0.274433]\n",
      "[Epoch 28/100] [Batch 94/347] [D loss: 0.499713] [G loss: 0.271055]\n",
      "[Epoch 28/100] [Batch 95/347] [D loss: 0.499754] [G loss: 0.271686]\n",
      "[Epoch 28/100] [Batch 96/347] [D loss: 0.499546] [G loss: 0.267031]\n",
      "[Epoch 28/100] [Batch 97/347] [D loss: 0.499268] [G loss: 0.261950]\n",
      "[Epoch 28/100] [Batch 98/347] [D loss: 0.499476] [G loss: 0.266898]\n",
      "[Epoch 28/100] [Batch 99/347] [D loss: 0.499675] [G loss: 0.270664]\n",
      "[Epoch 28/100] [Batch 100/347] [D loss: 0.499510] [G loss: 0.267008]\n",
      "[Epoch 28/100] [Batch 101/347] [D loss: 0.499266] [G loss: 0.261812]\n",
      "[Epoch 28/100] [Batch 102/347] [D loss: 0.499353] [G loss: 0.263331]\n",
      "[Epoch 28/100] [Batch 103/347] [D loss: 0.499385] [G loss: 0.263974]\n",
      "[Epoch 28/100] [Batch 104/347] [D loss: 0.498942] [G loss: 0.257937]\n",
      "[Epoch 28/100] [Batch 105/347] [D loss: 0.498891] [G loss: 0.259873]\n",
      "[Epoch 28/100] [Batch 106/347] [D loss: 0.498874] [G loss: 0.259045]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 28/100] [Batch 107/347] [D loss: 0.498273] [G loss: 0.253572]\n",
      "[Epoch 28/100] [Batch 108/347] [D loss: 0.495824] [G loss: 0.270253]\n",
      "[Epoch 28/100] [Batch 109/347] [D loss: 0.496128] [G loss: 0.265076]\n",
      "[Epoch 28/100] [Batch 110/347] [D loss: 0.499150] [G loss: 0.254134]\n",
      "[Epoch 28/100] [Batch 111/347] [D loss: 0.496931] [G loss: 0.257952]\n",
      "[Epoch 28/100] [Batch 112/347] [D loss: 0.496657] [G loss: 0.261928]\n",
      "[Epoch 28/100] [Batch 113/347] [D loss: 0.499406] [G loss: 0.266311]\n",
      "[Epoch 28/100] [Batch 114/347] [D loss: 0.500866] [G loss: 0.286346]\n",
      "[Epoch 28/100] [Batch 115/347] [D loss: 0.500918] [G loss: 0.287244]\n",
      "[Epoch 28/100] [Batch 116/347] [D loss: 0.500646] [G loss: 0.281427]\n",
      "[Epoch 28/100] [Batch 117/347] [D loss: 0.499290] [G loss: 0.254838]\n",
      "[Epoch 28/100] [Batch 118/347] [D loss: 0.497565] [G loss: 0.264451]\n",
      "[Epoch 28/100] [Batch 119/347] [D loss: 0.497299] [G loss: 0.267223]\n",
      "[Epoch 28/100] [Batch 120/347] [D loss: 0.497112] [G loss: 0.266716]\n",
      "[Epoch 28/100] [Batch 121/347] [D loss: 0.497121] [G loss: 0.265858]\n",
      "[Epoch 28/100] [Batch 122/347] [D loss: 0.498183] [G loss: 0.254017]\n",
      "[Epoch 28/100] [Batch 123/347] [D loss: 0.498599] [G loss: 0.253543]\n",
      "[Epoch 28/100] [Batch 124/347] [D loss: 0.498422] [G loss: 0.255020]\n",
      "[Epoch 28/100] [Batch 125/347] [D loss: 0.499059] [G loss: 0.256507]\n",
      "[Epoch 28/100] [Batch 126/347] [D loss: 0.499699] [G loss: 0.269142]\n",
      "[Epoch 28/100] [Batch 127/347] [D loss: 0.499780] [G loss: 0.270503]\n",
      "[Epoch 28/100] [Batch 128/347] [D loss: 0.499485] [G loss: 0.264979]\n",
      "[Epoch 28/100] [Batch 129/347] [D loss: 0.499257] [G loss: 0.260042]\n",
      "[Epoch 28/100] [Batch 130/347] [D loss: 0.498820] [G loss: 0.263424]\n",
      "[Epoch 28/100] [Batch 131/347] [D loss: 0.496545] [G loss: 0.265448]\n",
      "[Epoch 28/100] [Batch 132/347] [D loss: 0.492715] [G loss: 0.289440]\n",
      "[Epoch 28/100] [Batch 133/347] [D loss: 0.492693] [G loss: 0.295220]\n",
      "[Epoch 28/100] [Batch 134/347] [D loss: 0.491092] [G loss: 0.308936]\n",
      "[Epoch 28/100] [Batch 135/347] [D loss: 0.486899] [G loss: 0.316470]\n",
      "[Epoch 28/100] [Batch 136/347] [D loss: 0.489921] [G loss: 0.272778]\n",
      "[Epoch 28/100] [Batch 137/347] [D loss: 0.498210] [G loss: 0.259091]\n",
      "[Epoch 28/100] [Batch 138/347] [D loss: 0.496716] [G loss: 0.275929]\n",
      "[Epoch 28/100] [Batch 139/347] [D loss: 0.495152] [G loss: 0.299376]\n",
      "[Epoch 28/100] [Batch 140/347] [D loss: 0.494482] [G loss: 0.310428]\n",
      "[Epoch 28/100] [Batch 141/347] [D loss: 0.494134] [G loss: 0.317012]\n",
      "[Epoch 28/100] [Batch 142/347] [D loss: 0.493720] [G loss: 0.324321]\n",
      "[Epoch 28/100] [Batch 143/347] [D loss: 0.492149] [G loss: 0.345716]\n",
      "[Epoch 28/100] [Batch 144/347] [D loss: 0.491976] [G loss: 0.347985]\n",
      "[Epoch 28/100] [Batch 145/347] [D loss: 0.492844] [G loss: 0.333725]\n",
      "[Epoch 28/100] [Batch 146/347] [D loss: 0.493723] [G loss: 0.317291]\n",
      "[Epoch 28/100] [Batch 147/347] [D loss: 0.495547] [G loss: 0.289646]\n",
      "[Epoch 28/100] [Batch 148/347] [D loss: 0.496368] [G loss: 0.278004]\n",
      "[Epoch 28/100] [Batch 149/347] [D loss: 0.495553] [G loss: 0.292452]\n",
      "[Epoch 28/100] [Batch 150/347] [D loss: 0.495617] [G loss: 0.294028]\n",
      "[Epoch 28/100] [Batch 151/347] [D loss: 0.496385] [G loss: 0.284198]\n",
      "[Epoch 28/100] [Batch 152/347] [D loss: 0.495631] [G loss: 0.296378]\n",
      "[Epoch 28/100] [Batch 153/347] [D loss: 0.494188] [G loss: 0.317936]\n",
      "[Epoch 28/100] [Batch 154/347] [D loss: 0.493691] [G loss: 0.322640]\n",
      "[Epoch 28/100] [Batch 155/347] [D loss: 0.494474] [G loss: 0.310259]\n",
      "[Epoch 28/100] [Batch 156/347] [D loss: 0.495728] [G loss: 0.293948]\n",
      "[Epoch 28/100] [Batch 157/347] [D loss: 0.495373] [G loss: 0.300462]\n",
      "[Epoch 28/100] [Batch 158/347] [D loss: 0.493676] [G loss: 0.324403]\n",
      "[Epoch 28/100] [Batch 159/347] [D loss: 0.493643] [G loss: 0.322116]\n",
      "[Epoch 28/100] [Batch 160/347] [D loss: 0.494646] [G loss: 0.302183]\n",
      "[Epoch 28/100] [Batch 161/347] [D loss: 0.495208] [G loss: 0.293733]\n",
      "[Epoch 28/100] [Batch 162/347] [D loss: 0.495288] [G loss: 0.299569]\n",
      "[Epoch 28/100] [Batch 163/347] [D loss: 0.494020] [G loss: 0.318249]\n",
      "[Epoch 28/100] [Batch 164/347] [D loss: 0.492820] [G loss: 0.333662]\n",
      "[Epoch 28/100] [Batch 165/347] [D loss: 0.493241] [G loss: 0.324757]\n",
      "[Epoch 28/100] [Batch 166/347] [D loss: 0.495837] [G loss: 0.286233]\n",
      "[Epoch 28/100] [Batch 167/347] [D loss: 0.497885] [G loss: 0.263238]\n",
      "[Epoch 28/100] [Batch 168/347] [D loss: 0.498427] [G loss: 0.273718]\n",
      "[Epoch 28/100] [Batch 169/347] [D loss: 0.499373] [G loss: 0.272296]\n",
      "[Epoch 28/100] [Batch 170/347] [D loss: 0.500178] [G loss: 0.268388]\n",
      "[Epoch 28/100] [Batch 171/347] [D loss: 0.500913] [G loss: 0.275721]\n",
      "[Epoch 28/100] [Batch 172/347] [D loss: 0.501204] [G loss: 0.281031]\n",
      "[Epoch 28/100] [Batch 173/347] [D loss: 0.500399] [G loss: 0.270461]\n",
      "[Epoch 28/100] [Batch 174/347] [D loss: 0.500166] [G loss: 0.268696]\n",
      "[Epoch 28/100] [Batch 175/347] [D loss: 0.500754] [G loss: 0.279460]\n",
      "[Epoch 28/100] [Batch 176/347] [D loss: 0.501569] [G loss: 0.293785]\n",
      "[Epoch 28/100] [Batch 177/347] [D loss: 0.501588] [G loss: 0.295566]\n",
      "[Epoch 28/100] [Batch 178/347] [D loss: 0.501218] [G loss: 0.290324]\n",
      "[Epoch 28/100] [Batch 179/347] [D loss: 0.500832] [G loss: 0.284332]\n",
      "[Epoch 28/100] [Batch 180/347] [D loss: 0.500502] [G loss: 0.278415]\n",
      "[Epoch 28/100] [Batch 181/347] [D loss: 0.500499] [G loss: 0.279363]\n",
      "[Epoch 28/100] [Batch 182/347] [D loss: 0.500288] [G loss: 0.277703]\n",
      "[Epoch 28/100] [Batch 183/347] [D loss: 0.500539] [G loss: 0.282077]\n",
      "[Epoch 28/100] [Batch 184/347] [D loss: 0.500752] [G loss: 0.286229]\n",
      "[Epoch 28/100] [Batch 185/347] [D loss: 0.500680] [G loss: 0.284771]\n",
      "[Epoch 28/100] [Batch 186/347] [D loss: 0.500729] [G loss: 0.284615]\n",
      "[Epoch 28/100] [Batch 187/347] [D loss: 0.500474] [G loss: 0.279300]\n",
      "[Epoch 28/100] [Batch 188/347] [D loss: 0.500233] [G loss: 0.275925]\n",
      "[Epoch 28/100] [Batch 189/347] [D loss: 0.500168] [G loss: 0.275011]\n",
      "[Epoch 28/100] [Batch 190/347] [D loss: 0.499360] [G loss: 0.263024]\n",
      "[Epoch 28/100] [Batch 191/347] [D loss: 0.498473] [G loss: 0.258318]\n",
      "[Epoch 28/100] [Batch 192/347] [D loss: 0.498762] [G loss: 0.252316]\n",
      "[Epoch 28/100] [Batch 193/347] [D loss: 0.499416] [G loss: 0.260654]\n",
      "[Epoch 28/100] [Batch 194/347] [D loss: 0.499037] [G loss: 0.256214]\n",
      "[Epoch 28/100] [Batch 195/347] [D loss: 0.498519] [G loss: 0.259677]\n",
      "[Epoch 28/100] [Batch 196/347] [D loss: 0.498229] [G loss: 0.257319]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 28/100] [Batch 197/347] [D loss: 0.498216] [G loss: 0.253395]\n",
      "[Epoch 28/100] [Batch 198/347] [D loss: 0.498227] [G loss: 0.253531]\n",
      "[Epoch 28/100] [Batch 199/347] [D loss: 0.498207] [G loss: 0.254575]\n",
      "[Epoch 28/100] [Batch 200/347] [D loss: 0.498559] [G loss: 0.249545]\n",
      "[Epoch 28/100] [Batch 201/347] [D loss: 0.498665] [G loss: 0.248733]\n",
      "[Epoch 28/100] [Batch 202/347] [D loss: 0.498246] [G loss: 0.260712]\n",
      "[Epoch 28/100] [Batch 203/347] [D loss: 0.497922] [G loss: 0.269684]\n",
      "[Epoch 28/100] [Batch 204/347] [D loss: 0.498087] [G loss: 0.266429]\n",
      "[Epoch 28/100] [Batch 205/347] [D loss: 0.498333] [G loss: 0.258895]\n",
      "[Epoch 28/100] [Batch 206/347] [D loss: 0.498826] [G loss: 0.249536]\n",
      "[Epoch 28/100] [Batch 207/347] [D loss: 0.499628] [G loss: 0.260574]\n",
      "[Epoch 28/100] [Batch 208/347] [D loss: 0.499553] [G loss: 0.261541]\n",
      "[Epoch 28/100] [Batch 209/347] [D loss: 0.499138] [G loss: 0.255984]\n",
      "[Epoch 28/100] [Batch 210/347] [D loss: 0.499681] [G loss: 0.263970]\n",
      "[Epoch 28/100] [Batch 211/347] [D loss: 0.499561] [G loss: 0.261432]\n",
      "[Epoch 28/100] [Batch 212/347] [D loss: 0.498971] [G loss: 0.260522]\n",
      "[Epoch 28/100] [Batch 213/347] [D loss: 0.498120] [G loss: 0.266539]\n",
      "[Epoch 28/100] [Batch 214/347] [D loss: 0.493814] [G loss: 0.276508]\n",
      "[Epoch 28/100] [Batch 215/347] [D loss: 0.493439] [G loss: 0.284308]\n",
      "[Epoch 28/100] [Batch 216/347] [D loss: 0.498227] [G loss: 0.264939]\n",
      "[Epoch 28/100] [Batch 217/347] [D loss: 0.499365] [G loss: 0.265392]\n",
      "[Epoch 28/100] [Batch 218/347] [D loss: 0.500255] [G loss: 0.271806]\n",
      "[Epoch 28/100] [Batch 219/347] [D loss: 0.501018] [G loss: 0.283908]\n",
      "[Epoch 28/100] [Batch 220/347] [D loss: 0.501911] [G loss: 0.299585]\n",
      "[Epoch 28/100] [Batch 221/347] [D loss: 0.502000] [G loss: 0.300839]\n",
      "[Epoch 28/100] [Batch 222/347] [D loss: 0.501571] [G loss: 0.292821]\n",
      "[Epoch 28/100] [Batch 223/347] [D loss: 0.501453] [G loss: 0.291687]\n",
      "[Epoch 28/100] [Batch 224/347] [D loss: 0.501224] [G loss: 0.287814]\n",
      "[Epoch 28/100] [Batch 225/347] [D loss: 0.499550] [G loss: 0.274822]\n",
      "[Epoch 28/100] [Batch 226/347] [D loss: 0.497416] [G loss: 0.271273]\n",
      "[Epoch 28/100] [Batch 227/347] [D loss: 0.496479] [G loss: 0.281230]\n",
      "[Epoch 28/100] [Batch 228/347] [D loss: 0.496622] [G loss: 0.282210]\n",
      "[Epoch 28/100] [Batch 229/347] [D loss: 0.497334] [G loss: 0.276720]\n",
      "[Epoch 28/100] [Batch 230/347] [D loss: 0.497672] [G loss: 0.272284]\n",
      "[Epoch 28/100] [Batch 231/347] [D loss: 0.497322] [G loss: 0.271882]\n",
      "[Epoch 28/100] [Batch 232/347] [D loss: 0.497565] [G loss: 0.267627]\n",
      "[Epoch 28/100] [Batch 233/347] [D loss: 0.497580] [G loss: 0.265050]\n",
      "[Epoch 28/100] [Batch 234/347] [D loss: 0.497351] [G loss: 0.269961]\n",
      "[Epoch 28/100] [Batch 235/347] [D loss: 0.498067] [G loss: 0.258563]\n",
      "[Epoch 28/100] [Batch 236/347] [D loss: 0.499066] [G loss: 0.262676]\n",
      "[Epoch 28/100] [Batch 237/347] [D loss: 0.499871] [G loss: 0.265859]\n",
      "[Epoch 28/100] [Batch 238/347] [D loss: 0.500076] [G loss: 0.269823]\n",
      "[Epoch 28/100] [Batch 239/347] [D loss: 0.499894] [G loss: 0.267724]\n",
      "[Epoch 28/100] [Batch 240/347] [D loss: 0.499670] [G loss: 0.264009]\n",
      "[Epoch 28/100] [Batch 241/347] [D loss: 0.499335] [G loss: 0.258424]\n",
      "[Epoch 28/100] [Batch 242/347] [D loss: 0.499210] [G loss: 0.256796]\n",
      "[Epoch 28/100] [Batch 243/347] [D loss: 0.499665] [G loss: 0.264882]\n",
      "[Epoch 28/100] [Batch 244/347] [D loss: 0.500196] [G loss: 0.274162]\n",
      "[Epoch 28/100] [Batch 245/347] [D loss: 0.500326] [G loss: 0.273115]\n",
      "[Epoch 28/100] [Batch 246/347] [D loss: 0.498832] [G loss: 0.266682]\n",
      "[Epoch 28/100] [Batch 247/347] [D loss: 0.497542] [G loss: 0.267232]\n",
      "[Epoch 28/100] [Batch 248/347] [D loss: 0.497075] [G loss: 0.272231]\n",
      "[Epoch 28/100] [Batch 249/347] [D loss: 0.496717] [G loss: 0.277923]\n",
      "[Epoch 28/100] [Batch 250/347] [D loss: 0.497575] [G loss: 0.268712]\n",
      "[Epoch 28/100] [Batch 251/347] [D loss: 0.499094] [G loss: 0.267900]\n",
      "[Epoch 28/100] [Batch 252/347] [D loss: 0.499635] [G loss: 0.271012]\n",
      "[Epoch 28/100] [Batch 253/347] [D loss: 0.499685] [G loss: 0.271402]\n",
      "[Epoch 28/100] [Batch 254/347] [D loss: 0.499843] [G loss: 0.269635]\n",
      "[Epoch 28/100] [Batch 255/347] [D loss: 0.499015] [G loss: 0.268065]\n",
      "[Epoch 28/100] [Batch 256/347] [D loss: 0.499290] [G loss: 0.273278]\n",
      "[Epoch 28/100] [Batch 257/347] [D loss: 0.500309] [G loss: 0.275372]\n",
      "[Epoch 28/100] [Batch 258/347] [D loss: 0.499336] [G loss: 0.270391]\n",
      "[Epoch 28/100] [Batch 259/347] [D loss: 0.497485] [G loss: 0.266352]\n",
      "[Epoch 28/100] [Batch 260/347] [D loss: 0.496344] [G loss: 0.280410]\n",
      "[Epoch 28/100] [Batch 261/347] [D loss: 0.496925] [G loss: 0.272344]\n",
      "[Epoch 28/100] [Batch 262/347] [D loss: 0.498126] [G loss: 0.257082]\n",
      "[Epoch 28/100] [Batch 263/347] [D loss: 0.497971] [G loss: 0.257475]\n",
      "[Epoch 28/100] [Batch 264/347] [D loss: 0.496746] [G loss: 0.271855]\n",
      "[Epoch 28/100] [Batch 265/347] [D loss: 0.496363] [G loss: 0.277087]\n",
      "[Epoch 28/100] [Batch 266/347] [D loss: 0.496931] [G loss: 0.269914]\n",
      "[Epoch 28/100] [Batch 267/347] [D loss: 0.497409] [G loss: 0.263062]\n",
      "[Epoch 28/100] [Batch 268/347] [D loss: 0.496792] [G loss: 0.269872]\n",
      "[Epoch 28/100] [Batch 269/347] [D loss: 0.496019] [G loss: 0.280936]\n",
      "[Epoch 28/100] [Batch 270/347] [D loss: 0.496483] [G loss: 0.277484]\n",
      "[Epoch 28/100] [Batch 271/347] [D loss: 0.497324] [G loss: 0.265681]\n",
      "[Epoch 28/100] [Batch 272/347] [D loss: 0.497935] [G loss: 0.257121]\n",
      "[Epoch 28/100] [Batch 273/347] [D loss: 0.494398] [G loss: 0.268995]\n",
      "[Epoch 28/100] [Batch 274/347] [D loss: 0.462575] [G loss: 0.301965]\n",
      "[Epoch 28/100] [Batch 275/347] [D loss: 0.462752] [G loss: 0.297252]\n",
      "[Epoch 28/100] [Batch 276/347] [D loss: 0.496411] [G loss: 0.263442]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 28/100] [Batch 277/347] [D loss: 0.498142] [G loss: 0.250425]\n",
      "[Epoch 28/100] [Batch 278/347] [D loss: 0.499094] [G loss: 0.247273]\n",
      "[Epoch 28/100] [Batch 279/347] [D loss: 0.498763] [G loss: 0.253530]\n",
      "[Epoch 28/100] [Batch 280/347] [D loss: 0.498369] [G loss: 0.256601]\n",
      "[Epoch 28/100] [Batch 281/347] [D loss: 0.498439] [G loss: 0.254857]\n",
      "[Epoch 28/100] [Batch 282/347] [D loss: 0.498493] [G loss: 0.253074]\n",
      "[Epoch 28/100] [Batch 283/347] [D loss: 0.497834] [G loss: 0.253988]\n",
      "[Epoch 28/100] [Batch 284/347] [D loss: 0.497922] [G loss: 0.256950]\n",
      "[Epoch 28/100] [Batch 285/347] [D loss: 0.498564] [G loss: 0.253623]\n",
      "[Epoch 28/100] [Batch 286/347] [D loss: 0.498480] [G loss: 0.247284]\n",
      "[Epoch 28/100] [Batch 287/347] [D loss: 0.498175] [G loss: 0.250315]\n",
      "[Epoch 28/100] [Batch 288/347] [D loss: 0.496174] [G loss: 0.278245]\n",
      "[Epoch 28/100] [Batch 289/347] [D loss: 0.495890] [G loss: 0.283712]\n",
      "[Epoch 28/100] [Batch 290/347] [D loss: 0.497485] [G loss: 0.261742]\n",
      "[Epoch 28/100] [Batch 291/347] [D loss: 0.497141] [G loss: 0.265104]\n",
      "[Epoch 28/100] [Batch 292/347] [D loss: 0.497704] [G loss: 0.257092]\n",
      "[Epoch 28/100] [Batch 293/347] [D loss: 0.499328] [G loss: 0.269158]\n",
      "[Epoch 28/100] [Batch 294/347] [D loss: 0.499679] [G loss: 0.278822]\n",
      "[Epoch 28/100] [Batch 295/347] [D loss: 0.496955] [G loss: 0.276038]\n",
      "[Epoch 28/100] [Batch 296/347] [D loss: 0.497320] [G loss: 0.271513]\n",
      "[Epoch 28/100] [Batch 297/347] [D loss: 0.500161] [G loss: 0.282043]\n",
      "[Epoch 28/100] [Batch 298/347] [D loss: 0.500172] [G loss: 0.276484]\n",
      "[Epoch 28/100] [Batch 299/347] [D loss: 0.500048] [G loss: 0.275004]\n",
      "[Epoch 28/100] [Batch 300/347] [D loss: 0.499584] [G loss: 0.270404]\n",
      "[Epoch 28/100] [Batch 301/347] [D loss: 0.499414] [G loss: 0.272404]\n",
      "[Epoch 28/100] [Batch 302/347] [D loss: 0.499830] [G loss: 0.277642]\n",
      "[Epoch 28/100] [Batch 303/347] [D loss: 0.498127] [G loss: 0.262001]\n",
      "[Epoch 28/100] [Batch 304/347] [D loss: 0.497060] [G loss: 0.264486]\n",
      "[Epoch 28/100] [Batch 305/347] [D loss: 0.496972] [G loss: 0.276696]\n",
      "[Epoch 28/100] [Batch 306/347] [D loss: 0.495812] [G loss: 0.268769]\n",
      "[Epoch 28/100] [Batch 307/347] [D loss: 0.494470] [G loss: 0.280338]\n",
      "[Epoch 28/100] [Batch 308/347] [D loss: 0.495261] [G loss: 0.275511]\n",
      "[Epoch 28/100] [Batch 309/347] [D loss: 0.497921] [G loss: 0.253873]\n",
      "[Epoch 28/100] [Batch 310/347] [D loss: 0.499656] [G loss: 0.272827]\n",
      "[Epoch 28/100] [Batch 311/347] [D loss: 0.499749] [G loss: 0.275429]\n",
      "[Epoch 28/100] [Batch 312/347] [D loss: 0.499657] [G loss: 0.275071]\n",
      "[Epoch 28/100] [Batch 313/347] [D loss: 0.499631] [G loss: 0.274408]\n",
      "[Epoch 28/100] [Batch 314/347] [D loss: 0.499331] [G loss: 0.268259]\n",
      "[Epoch 28/100] [Batch 315/347] [D loss: 0.498769] [G loss: 0.259480]\n",
      "[Epoch 28/100] [Batch 316/347] [D loss: 0.497616] [G loss: 0.255144]\n",
      "[Epoch 28/100] [Batch 317/347] [D loss: 0.496758] [G loss: 0.273891]\n",
      "[Epoch 28/100] [Batch 318/347] [D loss: 0.498147] [G loss: 0.251638]\n",
      "[Epoch 28/100] [Batch 319/347] [D loss: 0.500373] [G loss: 0.283797]\n",
      "[Epoch 28/100] [Batch 320/347] [D loss: 0.501176] [G loss: 0.297822]\n",
      "[Epoch 28/100] [Batch 321/347] [D loss: 0.500570] [G loss: 0.287748]\n",
      "[Epoch 28/100] [Batch 322/347] [D loss: 0.499760] [G loss: 0.274779]\n",
      "[Epoch 28/100] [Batch 323/347] [D loss: 0.499696] [G loss: 0.274015]\n",
      "[Epoch 28/100] [Batch 324/347] [D loss: 0.499924] [G loss: 0.277320]\n",
      "[Epoch 28/100] [Batch 325/347] [D loss: 0.499065] [G loss: 0.266915]\n",
      "[Epoch 28/100] [Batch 326/347] [D loss: 0.498169] [G loss: 0.258132]\n",
      "[Epoch 28/100] [Batch 327/347] [D loss: 0.498266] [G loss: 0.256503]\n",
      "[Epoch 28/100] [Batch 328/347] [D loss: 0.498279] [G loss: 0.253346]\n",
      "[Epoch 28/100] [Batch 329/347] [D loss: 0.496465] [G loss: 0.271424]\n",
      "[Epoch 28/100] [Batch 330/347] [D loss: 0.495280] [G loss: 0.286390]\n",
      "[Epoch 28/100] [Batch 331/347] [D loss: 0.496762] [G loss: 0.267531]\n",
      "[Epoch 28/100] [Batch 332/347] [D loss: 0.499205] [G loss: 0.267005]\n",
      "[Epoch 28/100] [Batch 333/347] [D loss: 0.499886] [G loss: 0.278248]\n",
      "[Epoch 28/100] [Batch 334/347] [D loss: 0.500048] [G loss: 0.279443]\n",
      "[Epoch 28/100] [Batch 335/347] [D loss: 0.499320] [G loss: 0.267238]\n",
      "[Epoch 28/100] [Batch 336/347] [D loss: 0.498356] [G loss: 0.253686]\n",
      "[Epoch 28/100] [Batch 337/347] [D loss: 0.498714] [G loss: 0.258469]\n",
      "[Epoch 28/100] [Batch 338/347] [D loss: 0.499650] [G loss: 0.273305]\n",
      "[Epoch 28/100] [Batch 339/347] [D loss: 0.500001] [G loss: 0.278875]\n",
      "[Epoch 28/100] [Batch 340/347] [D loss: 0.500023] [G loss: 0.279544]\n",
      "[Epoch 28/100] [Batch 341/347] [D loss: 0.499763] [G loss: 0.274933]\n",
      "[Epoch 28/100] [Batch 342/347] [D loss: 0.499253] [G loss: 0.267505]\n",
      "[Epoch 28/100] [Batch 343/347] [D loss: 0.499442] [G loss: 0.272464]\n",
      "[Epoch 28/100] [Batch 344/347] [D loss: 0.498542] [G loss: 0.260659]\n",
      "[Epoch 28/100] [Batch 345/347] [D loss: 0.496321] [G loss: 0.269379]\n",
      "[Epoch 28/100] [Batch 346/347] [D loss: 0.493798] [G loss: 0.287620]\n",
      "[Epoch 28/100] [Batch 347/347] [D loss: 0.490143] [G loss: 0.293105]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 29/100] [Batch 1/347] [D loss: 0.498083] [G loss: 0.258598]\n",
      "[Epoch 29/100] [Batch 2/347] [D loss: 0.498131] [G loss: 0.263550]\n",
      "[Epoch 29/100] [Batch 3/347] [D loss: 0.498732] [G loss: 0.263257]\n",
      "[Epoch 29/100] [Batch 4/347] [D loss: 0.498734] [G loss: 0.264538]\n",
      "[Epoch 29/100] [Batch 5/347] [D loss: 0.498689] [G loss: 0.264014]\n",
      "[Epoch 29/100] [Batch 6/347] [D loss: 0.498820] [G loss: 0.264536]\n",
      "[Epoch 29/100] [Batch 7/347] [D loss: 0.498556] [G loss: 0.264702]\n",
      "[Epoch 29/100] [Batch 8/347] [D loss: 0.498383] [G loss: 0.260358]\n",
      "[Epoch 29/100] [Batch 9/347] [D loss: 0.497711] [G loss: 0.259698]\n",
      "[Epoch 29/100] [Batch 10/347] [D loss: 0.497763] [G loss: 0.261776]\n",
      "[Epoch 29/100] [Batch 11/347] [D loss: 0.498688] [G loss: 0.261893]\n",
      "[Epoch 29/100] [Batch 12/347] [D loss: 0.498975] [G loss: 0.264455]\n",
      "[Epoch 29/100] [Batch 13/347] [D loss: 0.499318] [G loss: 0.268709]\n",
      "[Epoch 29/100] [Batch 14/347] [D loss: 0.499540] [G loss: 0.271081]\n",
      "[Epoch 29/100] [Batch 15/347] [D loss: 0.499288] [G loss: 0.267197]\n",
      "[Epoch 29/100] [Batch 16/347] [D loss: 0.499044] [G loss: 0.263105]\n",
      "[Epoch 29/100] [Batch 17/347] [D loss: 0.498336] [G loss: 0.251234]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 29/100] [Batch 18/347] [D loss: 0.497847] [G loss: 0.255914]\n",
      "[Epoch 29/100] [Batch 19/347] [D loss: 0.498711] [G loss: 0.256560]\n",
      "[Epoch 29/100] [Batch 20/347] [D loss: 0.499514] [G loss: 0.269688]\n",
      "[Epoch 29/100] [Batch 21/347] [D loss: 0.499249] [G loss: 0.265885]\n",
      "[Epoch 29/100] [Batch 22/347] [D loss: 0.498930] [G loss: 0.260788]\n",
      "[Epoch 29/100] [Batch 23/347] [D loss: 0.498532] [G loss: 0.254718]\n",
      "[Epoch 29/100] [Batch 24/347] [D loss: 0.498528] [G loss: 0.253727]\n",
      "[Epoch 29/100] [Batch 25/347] [D loss: 0.498503] [G loss: 0.253319]\n",
      "[Epoch 29/100] [Batch 26/347] [D loss: 0.497249] [G loss: 0.260275]\n",
      "[Epoch 29/100] [Batch 27/347] [D loss: 0.496097] [G loss: 0.265510]\n",
      "[Epoch 29/100] [Batch 28/347] [D loss: 0.497045] [G loss: 0.265180]\n",
      "[Epoch 29/100] [Batch 29/347] [D loss: 0.499426] [G loss: 0.264117]\n",
      "[Epoch 29/100] [Batch 30/347] [D loss: 0.499797] [G loss: 0.271020]\n",
      "[Epoch 29/100] [Batch 31/347] [D loss: 0.499802] [G loss: 0.273544]\n",
      "[Epoch 29/100] [Batch 32/347] [D loss: 0.499108] [G loss: 0.266731]\n",
      "[Epoch 29/100] [Batch 33/347] [D loss: 0.498930] [G loss: 0.262693]\n",
      "[Epoch 29/100] [Batch 34/347] [D loss: 0.499291] [G loss: 0.264019]\n",
      "[Epoch 29/100] [Batch 35/347] [D loss: 0.499230] [G loss: 0.263132]\n",
      "[Epoch 29/100] [Batch 36/347] [D loss: 0.498687] [G loss: 0.254428]\n",
      "[Epoch 29/100] [Batch 37/347] [D loss: 0.496732] [G loss: 0.268392]\n",
      "[Epoch 29/100] [Batch 38/347] [D loss: 0.495556] [G loss: 0.283306]\n",
      "[Epoch 29/100] [Batch 39/347] [D loss: 0.496298] [G loss: 0.273202]\n",
      "[Epoch 29/100] [Batch 40/347] [D loss: 0.496888] [G loss: 0.274306]\n",
      "[Epoch 29/100] [Batch 41/347] [D loss: 0.496713] [G loss: 0.275211]\n",
      "[Epoch 29/100] [Batch 42/347] [D loss: 0.497072] [G loss: 0.267810]\n",
      "[Epoch 29/100] [Batch 43/347] [D loss: 0.498195] [G loss: 0.250301]\n",
      "[Epoch 29/100] [Batch 44/347] [D loss: 0.499546] [G loss: 0.264321]\n",
      "[Epoch 29/100] [Batch 45/347] [D loss: 0.500705] [G loss: 0.281619]\n",
      "[Epoch 29/100] [Batch 46/347] [D loss: 0.500374] [G loss: 0.276313]\n",
      "[Epoch 29/100] [Batch 47/347] [D loss: 0.498349] [G loss: 0.250652]\n",
      "[Epoch 29/100] [Batch 48/347] [D loss: 0.495790] [G loss: 0.282351]\n",
      "[Epoch 29/100] [Batch 49/347] [D loss: 0.494985] [G loss: 0.290969]\n",
      "[Epoch 29/100] [Batch 50/347] [D loss: 0.492560] [G loss: 0.306257]\n",
      "[Epoch 29/100] [Batch 51/347] [D loss: 0.493148] [G loss: 0.290286]\n",
      "[Epoch 29/100] [Batch 52/347] [D loss: 0.498031] [G loss: 0.261768]\n",
      "[Epoch 29/100] [Batch 53/347] [D loss: 0.498002] [G loss: 0.255867]\n",
      "[Epoch 29/100] [Batch 54/347] [D loss: 0.493942] [G loss: 0.305354]\n",
      "[Epoch 29/100] [Batch 55/347] [D loss: 0.491994] [G loss: 0.328015]\n",
      "[Epoch 29/100] [Batch 56/347] [D loss: 0.492806] [G loss: 0.314790]\n",
      "[Epoch 29/100] [Batch 57/347] [D loss: 0.495614] [G loss: 0.280010]\n",
      "[Epoch 29/100] [Batch 58/347] [D loss: 0.498217] [G loss: 0.257610]\n",
      "[Epoch 29/100] [Batch 59/347] [D loss: 0.496888] [G loss: 0.262849]\n",
      "[Epoch 29/100] [Batch 60/347] [D loss: 0.495308] [G loss: 0.282205]\n",
      "[Epoch 29/100] [Batch 61/347] [D loss: 0.494361] [G loss: 0.295383]\n",
      "[Epoch 29/100] [Batch 62/347] [D loss: 0.492500] [G loss: 0.319869]\n",
      "[Epoch 29/100] [Batch 63/347] [D loss: 0.492173] [G loss: 0.321979]\n",
      "[Epoch 29/100] [Batch 64/347] [D loss: 0.495225] [G loss: 0.284779]\n",
      "[Epoch 29/100] [Batch 65/347] [D loss: 0.499332] [G loss: 0.260391]\n",
      "[Epoch 29/100] [Batch 66/347] [D loss: 0.497466] [G loss: 0.262756]\n",
      "[Epoch 29/100] [Batch 67/347] [D loss: 0.493605] [G loss: 0.269572]\n",
      "[Epoch 29/100] [Batch 68/347] [D loss: 0.492908] [G loss: 0.288025]\n",
      "[Epoch 29/100] [Batch 69/347] [D loss: 0.493327] [G loss: 0.307413]\n",
      "[Epoch 29/100] [Batch 70/347] [D loss: 0.493280] [G loss: 0.306033]\n",
      "[Epoch 29/100] [Batch 71/347] [D loss: 0.493181] [G loss: 0.307867]\n",
      "[Epoch 29/100] [Batch 72/347] [D loss: 0.492885] [G loss: 0.310090]\n",
      "[Epoch 29/100] [Batch 73/347] [D loss: 0.494836] [G loss: 0.285181]\n",
      "[Epoch 29/100] [Batch 74/347] [D loss: 0.495898] [G loss: 0.271108]\n",
      "[Epoch 29/100] [Batch 75/347] [D loss: 0.493794] [G loss: 0.301452]\n",
      "[Epoch 29/100] [Batch 76/347] [D loss: 0.493622] [G loss: 0.303905]\n",
      "[Epoch 29/100] [Batch 77/347] [D loss: 0.496359] [G loss: 0.269737]\n",
      "[Epoch 29/100] [Batch 78/347] [D loss: 0.499122] [G loss: 0.265853]\n",
      "[Epoch 29/100] [Batch 79/347] [D loss: 0.500218] [G loss: 0.268521]\n",
      "[Epoch 29/100] [Batch 80/347] [D loss: 0.499934] [G loss: 0.266259]\n",
      "[Epoch 29/100] [Batch 81/347] [D loss: 0.500296] [G loss: 0.271399]\n",
      "[Epoch 29/100] [Batch 82/347] [D loss: 0.499714] [G loss: 0.276229]\n",
      "[Epoch 29/100] [Batch 83/347] [D loss: 0.499493] [G loss: 0.269105]\n",
      "[Epoch 29/100] [Batch 84/347] [D loss: 0.500291] [G loss: 0.276500]\n",
      "[Epoch 29/100] [Batch 85/347] [D loss: 0.500323] [G loss: 0.277864]\n",
      "[Epoch 29/100] [Batch 86/347] [D loss: 0.499951] [G loss: 0.272842]\n",
      "[Epoch 29/100] [Batch 87/347] [D loss: 0.499769] [G loss: 0.271291]\n",
      "[Epoch 29/100] [Batch 88/347] [D loss: 0.499971] [G loss: 0.275127]\n",
      "[Epoch 29/100] [Batch 89/347] [D loss: 0.500166] [G loss: 0.278930]\n",
      "[Epoch 29/100] [Batch 90/347] [D loss: 0.499927] [G loss: 0.275471]\n",
      "[Epoch 29/100] [Batch 91/347] [D loss: 0.499822] [G loss: 0.274251]\n",
      "[Epoch 29/100] [Batch 92/347] [D loss: 0.499902] [G loss: 0.275941]\n",
      "[Epoch 29/100] [Batch 93/347] [D loss: 0.499737] [G loss: 0.274073]\n",
      "[Epoch 29/100] [Batch 94/347] [D loss: 0.499499] [G loss: 0.270627]\n",
      "[Epoch 29/100] [Batch 95/347] [D loss: 0.499562] [G loss: 0.271274]\n",
      "[Epoch 29/100] [Batch 96/347] [D loss: 0.499268] [G loss: 0.266608]\n",
      "[Epoch 29/100] [Batch 97/347] [D loss: 0.498902] [G loss: 0.261538]\n",
      "[Epoch 29/100] [Batch 98/347] [D loss: 0.499210] [G loss: 0.266505]\n",
      "[Epoch 29/100] [Batch 99/347] [D loss: 0.499473] [G loss: 0.270374]\n",
      "[Epoch 29/100] [Batch 100/347] [D loss: 0.499249] [G loss: 0.266813]\n",
      "[Epoch 29/100] [Batch 101/347] [D loss: 0.498923] [G loss: 0.261676]\n",
      "[Epoch 29/100] [Batch 102/347] [D loss: 0.499052] [G loss: 0.263341]\n",
      "[Epoch 29/100] [Batch 103/347] [D loss: 0.499092] [G loss: 0.264174]\n",
      "[Epoch 29/100] [Batch 104/347] [D loss: 0.498489] [G loss: 0.258633]\n",
      "[Epoch 29/100] [Batch 105/347] [D loss: 0.498444] [G loss: 0.260558]\n",
      "[Epoch 29/100] [Batch 106/347] [D loss: 0.498424] [G loss: 0.259808]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 29/100] [Batch 107/347] [D loss: 0.497420] [G loss: 0.253886]\n",
      "[Epoch 29/100] [Batch 108/347] [D loss: 0.492782] [G loss: 0.270327]\n",
      "[Epoch 29/100] [Batch 109/347] [D loss: 0.493098] [G loss: 0.264785]\n",
      "[Epoch 29/100] [Batch 110/347] [D loss: 0.498674] [G loss: 0.253943]\n",
      "[Epoch 29/100] [Batch 111/347] [D loss: 0.494472] [G loss: 0.257019]\n",
      "[Epoch 29/100] [Batch 112/347] [D loss: 0.493873] [G loss: 0.260722]\n",
      "[Epoch 29/100] [Batch 113/347] [D loss: 0.498574] [G loss: 0.265449]\n",
      "[Epoch 29/100] [Batch 114/347] [D loss: 0.501012] [G loss: 0.285654]\n",
      "[Epoch 29/100] [Batch 115/347] [D loss: 0.501074] [G loss: 0.286816]\n",
      "[Epoch 29/100] [Batch 116/347] [D loss: 0.500742] [G loss: 0.281221]\n",
      "[Epoch 29/100] [Batch 117/347] [D loss: 0.498952] [G loss: 0.254854]\n",
      "[Epoch 29/100] [Batch 118/347] [D loss: 0.496670] [G loss: 0.263698]\n",
      "[Epoch 29/100] [Batch 119/347] [D loss: 0.496336] [G loss: 0.266503]\n",
      "[Epoch 29/100] [Batch 120/347] [D loss: 0.496010] [G loss: 0.265780]\n",
      "[Epoch 29/100] [Batch 121/347] [D loss: 0.496144] [G loss: 0.264468]\n",
      "[Epoch 29/100] [Batch 122/347] [D loss: 0.497699] [G loss: 0.252619]\n",
      "[Epoch 29/100] [Batch 123/347] [D loss: 0.498153] [G loss: 0.252170]\n",
      "[Epoch 29/100] [Batch 124/347] [D loss: 0.497846] [G loss: 0.253542]\n",
      "[Epoch 29/100] [Batch 125/347] [D loss: 0.498691] [G loss: 0.256721]\n",
      "[Epoch 29/100] [Batch 126/347] [D loss: 0.499539] [G loss: 0.269651]\n",
      "[Epoch 29/100] [Batch 127/347] [D loss: 0.499620] [G loss: 0.271212]\n",
      "[Epoch 29/100] [Batch 128/347] [D loss: 0.499221] [G loss: 0.265937]\n",
      "[Epoch 29/100] [Batch 129/347] [D loss: 0.498852] [G loss: 0.261143]\n",
      "[Epoch 29/100] [Batch 130/347] [D loss: 0.498155] [G loss: 0.264428]\n",
      "[Epoch 29/100] [Batch 131/347] [D loss: 0.493995] [G loss: 0.265036]\n",
      "[Epoch 29/100] [Batch 132/347] [D loss: 0.486934] [G loss: 0.288843]\n",
      "[Epoch 29/100] [Batch 133/347] [D loss: 0.487431] [G loss: 0.294276]\n",
      "[Epoch 29/100] [Batch 134/347] [D loss: 0.484857] [G loss: 0.307489]\n",
      "[Epoch 29/100] [Batch 135/347] [D loss: 0.477586] [G loss: 0.314493]\n",
      "[Epoch 29/100] [Batch 136/347] [D loss: 0.481080] [G loss: 0.270033]\n",
      "[Epoch 29/100] [Batch 137/347] [D loss: 0.497047] [G loss: 0.257801]\n",
      "[Epoch 29/100] [Batch 138/347] [D loss: 0.495391] [G loss: 0.272164]\n",
      "[Epoch 29/100] [Batch 139/347] [D loss: 0.493228] [G loss: 0.295340]\n",
      "[Epoch 29/100] [Batch 140/347] [D loss: 0.492292] [G loss: 0.306270]\n",
      "[Epoch 29/100] [Batch 141/347] [D loss: 0.491880] [G loss: 0.312817]\n",
      "[Epoch 29/100] [Batch 142/347] [D loss: 0.491316] [G loss: 0.320268]\n",
      "[Epoch 29/100] [Batch 143/347] [D loss: 0.489116] [G loss: 0.341826]\n",
      "[Epoch 29/100] [Batch 144/347] [D loss: 0.488917] [G loss: 0.344446]\n",
      "[Epoch 29/100] [Batch 145/347] [D loss: 0.490184] [G loss: 0.330550]\n",
      "[Epoch 29/100] [Batch 146/347] [D loss: 0.491432] [G loss: 0.314548]\n",
      "[Epoch 29/100] [Batch 147/347] [D loss: 0.493943] [G loss: 0.287350]\n",
      "[Epoch 29/100] [Batch 148/347] [D loss: 0.495019] [G loss: 0.276142]\n",
      "[Epoch 29/100] [Batch 149/347] [D loss: 0.493903] [G loss: 0.291097]\n",
      "[Epoch 29/100] [Batch 150/347] [D loss: 0.494018] [G loss: 0.293089]\n",
      "[Epoch 29/100] [Batch 151/347] [D loss: 0.494991] [G loss: 0.283621]\n",
      "[Epoch 29/100] [Batch 152/347] [D loss: 0.493836] [G loss: 0.296077]\n",
      "[Epoch 29/100] [Batch 153/347] [D loss: 0.491836] [G loss: 0.317766]\n",
      "[Epoch 29/100] [Batch 154/347] [D loss: 0.491217] [G loss: 0.322560]\n",
      "[Epoch 29/100] [Batch 155/347] [D loss: 0.492338] [G loss: 0.310144]\n",
      "[Epoch 29/100] [Batch 156/347] [D loss: 0.494096] [G loss: 0.293733]\n",
      "[Epoch 29/100] [Batch 157/347] [D loss: 0.493466] [G loss: 0.300045]\n",
      "[Epoch 29/100] [Batch 158/347] [D loss: 0.491104] [G loss: 0.323777]\n",
      "[Epoch 29/100] [Batch 159/347] [D loss: 0.491091] [G loss: 0.321226]\n",
      "[Epoch 29/100] [Batch 160/347] [D loss: 0.492163] [G loss: 0.300983]\n",
      "[Epoch 29/100] [Batch 161/347] [D loss: 0.492847] [G loss: 0.292196]\n",
      "[Epoch 29/100] [Batch 162/347] [D loss: 0.493196] [G loss: 0.297729]\n",
      "[Epoch 29/100] [Batch 163/347] [D loss: 0.491532] [G loss: 0.316097]\n",
      "[Epoch 29/100] [Batch 164/347] [D loss: 0.489860] [G loss: 0.331358]\n",
      "[Epoch 29/100] [Batch 165/347] [D loss: 0.490440] [G loss: 0.322279]\n",
      "[Epoch 29/100] [Batch 166/347] [D loss: 0.494089] [G loss: 0.283603]\n",
      "[Epoch 29/100] [Batch 167/347] [D loss: 0.496581] [G loss: 0.264205]\n",
      "[Epoch 29/100] [Batch 168/347] [D loss: 0.497182] [G loss: 0.274689]\n",
      "[Epoch 29/100] [Batch 169/347] [D loss: 0.498918] [G loss: 0.273314]\n",
      "[Epoch 29/100] [Batch 170/347] [D loss: 0.500318] [G loss: 0.269484]\n",
      "[Epoch 29/100] [Batch 171/347] [D loss: 0.501379] [G loss: 0.277256]\n",
      "[Epoch 29/100] [Batch 172/347] [D loss: 0.501796] [G loss: 0.282786]\n",
      "[Epoch 29/100] [Batch 173/347] [D loss: 0.500627] [G loss: 0.272481]\n",
      "[Epoch 29/100] [Batch 174/347] [D loss: 0.500296] [G loss: 0.271014]\n",
      "[Epoch 29/100] [Batch 175/347] [D loss: 0.501186] [G loss: 0.282076]\n",
      "[Epoch 29/100] [Batch 176/347] [D loss: 0.502333] [G loss: 0.296654]\n",
      "[Epoch 29/100] [Batch 177/347] [D loss: 0.502365] [G loss: 0.298773]\n",
      "[Epoch 29/100] [Batch 178/347] [D loss: 0.501850] [G loss: 0.293800]\n",
      "[Epoch 29/100] [Batch 179/347] [D loss: 0.501318] [G loss: 0.287986]\n",
      "[Epoch 29/100] [Batch 180/347] [D loss: 0.500862] [G loss: 0.282281]\n",
      "[Epoch 29/100] [Batch 181/347] [D loss: 0.500875] [G loss: 0.283348]\n",
      "[Epoch 29/100] [Batch 182/347] [D loss: 0.500611] [G loss: 0.281731]\n",
      "[Epoch 29/100] [Batch 183/347] [D loss: 0.500961] [G loss: 0.286036]\n",
      "[Epoch 29/100] [Batch 184/347] [D loss: 0.501254] [G loss: 0.290105]\n",
      "[Epoch 29/100] [Batch 185/347] [D loss: 0.501168] [G loss: 0.288545]\n",
      "[Epoch 29/100] [Batch 186/347] [D loss: 0.501229] [G loss: 0.288168]\n",
      "[Epoch 29/100] [Batch 187/347] [D loss: 0.500863] [G loss: 0.282605]\n",
      "[Epoch 29/100] [Batch 188/347] [D loss: 0.500536] [G loss: 0.278990]\n",
      "[Epoch 29/100] [Batch 189/347] [D loss: 0.500452] [G loss: 0.277831]\n",
      "[Epoch 29/100] [Batch 190/347] [D loss: 0.499369] [G loss: 0.265621]\n",
      "[Epoch 29/100] [Batch 191/347] [D loss: 0.498153] [G loss: 0.255129]\n",
      "[Epoch 29/100] [Batch 192/347] [D loss: 0.498511] [G loss: 0.254483]\n",
      "[Epoch 29/100] [Batch 193/347] [D loss: 0.499398] [G loss: 0.262697]\n",
      "[Epoch 29/100] [Batch 194/347] [D loss: 0.498935] [G loss: 0.258169]\n",
      "[Epoch 29/100] [Batch 195/347] [D loss: 0.498256] [G loss: 0.255572]\n",
      "[Epoch 29/100] [Batch 196/347] [D loss: 0.497876] [G loss: 0.253124]\n",
      "[Epoch 29/100] [Batch 197/347] [D loss: 0.497829] [G loss: 0.249258]\n",
      "[Epoch 29/100] [Batch 198/347] [D loss: 0.497746] [G loss: 0.250996]\n",
      "[Epoch 29/100] [Batch 199/347] [D loss: 0.497675] [G loss: 0.251188]\n",
      "[Epoch 29/100] [Batch 200/347] [D loss: 0.498186] [G loss: 0.250359]\n",
      "[Epoch 29/100] [Batch 201/347] [D loss: 0.498267] [G loss: 0.248186]\n",
      "[Epoch 29/100] [Batch 202/347] [D loss: 0.497661] [G loss: 0.259934]\n",
      "[Epoch 29/100] [Batch 203/347] [D loss: 0.497176] [G loss: 0.270069]\n",
      "[Epoch 29/100] [Batch 204/347] [D loss: 0.497307] [G loss: 0.267838]\n",
      "[Epoch 29/100] [Batch 205/347] [D loss: 0.497542] [G loss: 0.261225]\n",
      "[Epoch 29/100] [Batch 206/347] [D loss: 0.498111] [G loss: 0.250185]\n",
      "[Epoch 29/100] [Batch 207/347] [D loss: 0.499122] [G loss: 0.259190]\n",
      "[Epoch 29/100] [Batch 208/347] [D loss: 0.499025] [G loss: 0.259958]\n",
      "[Epoch 29/100] [Batch 209/347] [D loss: 0.498432] [G loss: 0.254216]\n",
      "[Epoch 29/100] [Batch 210/347] [D loss: 0.499118] [G loss: 0.261062]\n",
      "[Epoch 29/100] [Batch 211/347] [D loss: 0.498965] [G loss: 0.258769]\n",
      "[Epoch 29/100] [Batch 212/347] [D loss: 0.497947] [G loss: 0.257169]\n",
      "[Epoch 29/100] [Batch 213/347] [D loss: 0.496364] [G loss: 0.262928]\n",
      "[Epoch 29/100] [Batch 214/347] [D loss: 0.488260] [G loss: 0.279530]\n",
      "[Epoch 29/100] [Batch 215/347] [D loss: 0.487883] [G loss: 0.287010]\n",
      "[Epoch 29/100] [Batch 216/347] [D loss: 0.496880] [G loss: 0.260070]\n",
      "[Epoch 29/100] [Batch 217/347] [D loss: 0.498564] [G loss: 0.260142]\n",
      "[Epoch 29/100] [Batch 218/347] [D loss: 0.499876] [G loss: 0.267023]\n",
      "[Epoch 29/100] [Batch 219/347] [D loss: 0.500886] [G loss: 0.278992]\n",
      "[Epoch 29/100] [Batch 220/347] [D loss: 0.502103] [G loss: 0.294609]\n",
      "[Epoch 29/100] [Batch 221/347] [D loss: 0.502201] [G loss: 0.295876]\n",
      "[Epoch 29/100] [Batch 222/347] [D loss: 0.501569] [G loss: 0.287953]\n",
      "[Epoch 29/100] [Batch 223/347] [D loss: 0.501387] [G loss: 0.286895]\n",
      "[Epoch 29/100] [Batch 224/347] [D loss: 0.501083] [G loss: 0.283157]\n",
      "[Epoch 29/100] [Batch 225/347] [D loss: 0.498739] [G loss: 0.269803]\n",
      "[Epoch 29/100] [Batch 226/347] [D loss: 0.495881] [G loss: 0.274207]\n",
      "[Epoch 29/100] [Batch 227/347] [D loss: 0.494698] [G loss: 0.284233]\n",
      "[Epoch 29/100] [Batch 228/347] [D loss: 0.494929] [G loss: 0.285853]\n",
      "[Epoch 29/100] [Batch 229/347] [D loss: 0.495916] [G loss: 0.280376]\n",
      "[Epoch 29/100] [Batch 230/347] [D loss: 0.496373] [G loss: 0.275966]\n",
      "[Epoch 29/100] [Batch 231/347] [D loss: 0.495901] [G loss: 0.275580]\n",
      "[Epoch 29/100] [Batch 232/347] [D loss: 0.496221] [G loss: 0.271314]\n",
      "[Epoch 29/100] [Batch 233/347] [D loss: 0.496193] [G loss: 0.268335]\n",
      "[Epoch 29/100] [Batch 234/347] [D loss: 0.495814] [G loss: 0.273277]\n",
      "[Epoch 29/100] [Batch 235/347] [D loss: 0.496744] [G loss: 0.261924]\n",
      "[Epoch 29/100] [Batch 236/347] [D loss: 0.498142] [G loss: 0.258837]\n",
      "[Epoch 29/100] [Batch 237/347] [D loss: 0.499300] [G loss: 0.262511]\n",
      "[Epoch 29/100] [Batch 238/347] [D loss: 0.499646] [G loss: 0.266495]\n",
      "[Epoch 29/100] [Batch 239/347] [D loss: 0.499388] [G loss: 0.264445]\n",
      "[Epoch 29/100] [Batch 240/347] [D loss: 0.499053] [G loss: 0.260802]\n",
      "[Epoch 29/100] [Batch 241/347] [D loss: 0.498596] [G loss: 0.255287]\n",
      "[Epoch 29/100] [Batch 242/347] [D loss: 0.498437] [G loss: 0.253740]\n",
      "[Epoch 29/100] [Batch 243/347] [D loss: 0.499096] [G loss: 0.261887]\n",
      "[Epoch 29/100] [Batch 244/347] [D loss: 0.499856] [G loss: 0.271244]\n",
      "[Epoch 29/100] [Batch 245/347] [D loss: 0.499935] [G loss: 0.270240]\n",
      "[Epoch 29/100] [Batch 246/347] [D loss: 0.497843] [G loss: 0.263513]\n",
      "[Epoch 29/100] [Batch 247/347] [D loss: 0.496157] [G loss: 0.270569]\n",
      "[Epoch 29/100] [Batch 248/347] [D loss: 0.495557] [G loss: 0.275608]\n",
      "[Epoch 29/100] [Batch 249/347] [D loss: 0.495049] [G loss: 0.280891]\n",
      "[Epoch 29/100] [Batch 250/347] [D loss: 0.496173] [G loss: 0.271436]\n",
      "[Epoch 29/100] [Batch 251/347] [D loss: 0.498223] [G loss: 0.264405]\n",
      "[Epoch 29/100] [Batch 252/347] [D loss: 0.498955] [G loss: 0.267413]\n",
      "[Epoch 29/100] [Batch 253/347] [D loss: 0.499053] [G loss: 0.267709]\n",
      "[Epoch 29/100] [Batch 254/347] [D loss: 0.499323] [G loss: 0.265912]\n",
      "[Epoch 29/100] [Batch 255/347] [D loss: 0.498060] [G loss: 0.264292]\n",
      "[Epoch 29/100] [Batch 256/347] [D loss: 0.498434] [G loss: 0.269507]\n",
      "[Epoch 29/100] [Batch 257/347] [D loss: 0.499924] [G loss: 0.271611]\n",
      "[Epoch 29/100] [Batch 258/347] [D loss: 0.498494] [G loss: 0.266697]\n",
      "[Epoch 29/100] [Batch 259/347] [D loss: 0.495852] [G loss: 0.268216]\n",
      "[Epoch 29/100] [Batch 260/347] [D loss: 0.494103] [G loss: 0.282224]\n",
      "[Epoch 29/100] [Batch 261/347] [D loss: 0.494878] [G loss: 0.274096]\n",
      "[Epoch 29/100] [Batch 262/347] [D loss: 0.496837] [G loss: 0.258410]\n",
      "[Epoch 29/100] [Batch 263/347] [D loss: 0.496591] [G loss: 0.258774]\n",
      "[Epoch 29/100] [Batch 264/347] [D loss: 0.494703] [G loss: 0.272851]\n",
      "[Epoch 29/100] [Batch 265/347] [D loss: 0.494219] [G loss: 0.277821]\n",
      "[Epoch 29/100] [Batch 266/347] [D loss: 0.495133] [G loss: 0.270415]\n",
      "[Epoch 29/100] [Batch 267/347] [D loss: 0.495901] [G loss: 0.263361]\n",
      "[Epoch 29/100] [Batch 268/347] [D loss: 0.494821] [G loss: 0.270050]\n",
      "[Epoch 29/100] [Batch 269/347] [D loss: 0.493665] [G loss: 0.280981]\n",
      "[Epoch 29/100] [Batch 270/347] [D loss: 0.494547] [G loss: 0.277458]\n",
      "[Epoch 29/100] [Batch 271/347] [D loss: 0.495896] [G loss: 0.265647]\n",
      "[Epoch 29/100] [Batch 272/347] [D loss: 0.496810] [G loss: 0.257188]\n",
      "[Epoch 29/100] [Batch 273/347] [D loss: 0.490978] [G loss: 0.269099]\n",
      "[Epoch 29/100] [Batch 274/347] [D loss: 0.438543] [G loss: 0.302438]\n",
      "[Epoch 29/100] [Batch 275/347] [D loss: 0.438736] [G loss: 0.298223]\n",
      "[Epoch 29/100] [Batch 276/347] [D loss: 0.494231] [G loss: 0.264715]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 29/100] [Batch 277/347] [D loss: 0.497004] [G loss: 0.252409]\n",
      "[Epoch 29/100] [Batch 278/347] [D loss: 0.498473] [G loss: 0.249631]\n",
      "[Epoch 29/100] [Batch 279/347] [D loss: 0.497927] [G loss: 0.256131]\n",
      "[Epoch 29/100] [Batch 280/347] [D loss: 0.497283] [G loss: 0.259377]\n",
      "[Epoch 29/100] [Batch 281/347] [D loss: 0.497413] [G loss: 0.257689]\n",
      "[Epoch 29/100] [Batch 282/347] [D loss: 0.497584] [G loss: 0.255934]\n",
      "[Epoch 29/100] [Batch 283/347] [D loss: 0.496544] [G loss: 0.256801]\n",
      "[Epoch 29/100] [Batch 284/347] [D loss: 0.496635] [G loss: 0.259657]\n",
      "[Epoch 29/100] [Batch 285/347] [D loss: 0.497776] [G loss: 0.256135]\n",
      "[Epoch 29/100] [Batch 286/347] [D loss: 0.497796] [G loss: 0.249667]\n",
      "[Epoch 29/100] [Batch 287/347] [D loss: 0.497383] [G loss: 0.250477]\n",
      "[Epoch 29/100] [Batch 288/347] [D loss: 0.494520] [G loss: 0.278065]\n",
      "[Epoch 29/100] [Batch 289/347] [D loss: 0.494103] [G loss: 0.283235]\n",
      "[Epoch 29/100] [Batch 290/347] [D loss: 0.496440] [G loss: 0.260954]\n",
      "[Epoch 29/100] [Batch 291/347] [D loss: 0.495909] [G loss: 0.264037]\n",
      "[Epoch 29/100] [Batch 292/347] [D loss: 0.496714] [G loss: 0.255804]\n",
      "[Epoch 29/100] [Batch 293/347] [D loss: 0.498972] [G loss: 0.270552]\n",
      "[Epoch 29/100] [Batch 294/347] [D loss: 0.499353] [G loss: 0.280070]\n",
      "[Epoch 29/100] [Batch 295/347] [D loss: 0.493761] [G loss: 0.277051]\n",
      "[Epoch 29/100] [Batch 296/347] [D loss: 0.494218] [G loss: 0.272223]\n",
      "[Epoch 29/100] [Batch 297/347] [D loss: 0.500018] [G loss: 0.281858]\n",
      "[Epoch 29/100] [Batch 298/347] [D loss: 0.500395] [G loss: 0.276201]\n",
      "[Epoch 29/100] [Batch 299/347] [D loss: 0.500157] [G loss: 0.274749]\n",
      "[Epoch 29/100] [Batch 300/347] [D loss: 0.499425] [G loss: 0.270267]\n",
      "[Epoch 29/100] [Batch 301/347] [D loss: 0.499116] [G loss: 0.273109]\n",
      "[Epoch 29/100] [Batch 302/347] [D loss: 0.499757] [G loss: 0.278616]\n",
      "[Epoch 29/100] [Batch 303/347] [D loss: 0.497348] [G loss: 0.263264]\n",
      "[Epoch 29/100] [Batch 304/347] [D loss: 0.495941] [G loss: 0.261267]\n",
      "[Epoch 29/100] [Batch 305/347] [D loss: 0.495889] [G loss: 0.273620]\n",
      "[Epoch 29/100] [Batch 306/347] [D loss: 0.493615] [G loss: 0.266551]\n",
      "[Epoch 29/100] [Batch 307/347] [D loss: 0.491088] [G loss: 0.278242]\n",
      "[Epoch 29/100] [Batch 308/347] [D loss: 0.492697] [G loss: 0.273522]\n",
      "[Epoch 29/100] [Batch 309/347] [D loss: 0.497268] [G loss: 0.251255]\n",
      "[Epoch 29/100] [Batch 310/347] [D loss: 0.499801] [G loss: 0.275339]\n",
      "[Epoch 29/100] [Batch 311/347] [D loss: 0.499951] [G loss: 0.278116]\n",
      "[Epoch 29/100] [Batch 312/347] [D loss: 0.499863] [G loss: 0.277899]\n",
      "[Epoch 29/100] [Batch 313/347] [D loss: 0.499821] [G loss: 0.277337]\n",
      "[Epoch 29/100] [Batch 314/347] [D loss: 0.499318] [G loss: 0.271239]\n",
      "[Epoch 29/100] [Batch 315/347] [D loss: 0.498395] [G loss: 0.262477]\n",
      "[Epoch 29/100] [Batch 316/347] [D loss: 0.496823] [G loss: 0.252567]\n",
      "[Epoch 29/100] [Batch 317/347] [D loss: 0.495681] [G loss: 0.271258]\n",
      "[Epoch 29/100] [Batch 318/347] [D loss: 0.497630] [G loss: 0.253318]\n",
      "[Epoch 29/100] [Batch 319/347] [D loss: 0.500750] [G loss: 0.286631]\n",
      "[Epoch 29/100] [Batch 320/347] [D loss: 0.501885] [G loss: 0.300424]\n",
      "[Epoch 29/100] [Batch 321/347] [D loss: 0.500951] [G loss: 0.290171]\n",
      "[Epoch 29/100] [Batch 322/347] [D loss: 0.499757] [G loss: 0.276933]\n",
      "[Epoch 29/100] [Batch 323/347] [D loss: 0.499612] [G loss: 0.275926]\n",
      "[Epoch 29/100] [Batch 324/347] [D loss: 0.499899] [G loss: 0.278995]\n",
      "[Epoch 29/100] [Batch 325/347] [D loss: 0.498473] [G loss: 0.268328]\n",
      "[Epoch 29/100] [Batch 326/347] [D loss: 0.497128] [G loss: 0.259890]\n",
      "[Epoch 29/100] [Batch 327/347] [D loss: 0.497371] [G loss: 0.258059]\n",
      "[Epoch 29/100] [Batch 328/347] [D loss: 0.497514] [G loss: 0.254647]\n",
      "[Epoch 29/100] [Batch 329/347] [D loss: 0.494728] [G loss: 0.269524]\n",
      "[Epoch 29/100] [Batch 330/347] [D loss: 0.492996] [G loss: 0.284377]\n",
      "[Epoch 29/100] [Batch 331/347] [D loss: 0.495240] [G loss: 0.265364]\n",
      "[Epoch 29/100] [Batch 332/347] [D loss: 0.498920] [G loss: 0.267047]\n",
      "[Epoch 29/100] [Batch 333/347] [D loss: 0.499938] [G loss: 0.278289]\n",
      "[Epoch 29/100] [Batch 334/347] [D loss: 0.500121] [G loss: 0.279561]\n",
      "[Epoch 29/100] [Batch 335/347] [D loss: 0.498989] [G loss: 0.267476]\n",
      "[Epoch 29/100] [Batch 336/347] [D loss: 0.497577] [G loss: 0.254648]\n",
      "[Epoch 29/100] [Batch 337/347] [D loss: 0.498126] [G loss: 0.259029]\n",
      "[Epoch 29/100] [Batch 338/347] [D loss: 0.499516] [G loss: 0.274058]\n",
      "[Epoch 29/100] [Batch 339/347] [D loss: 0.500065] [G loss: 0.279916]\n",
      "[Epoch 29/100] [Batch 340/347] [D loss: 0.500115] [G loss: 0.280768]\n",
      "[Epoch 29/100] [Batch 341/347] [D loss: 0.499686] [G loss: 0.276384]\n",
      "[Epoch 29/100] [Batch 342/347] [D loss: 0.498941] [G loss: 0.269096]\n",
      "[Epoch 29/100] [Batch 343/347] [D loss: 0.499290] [G loss: 0.274184]\n",
      "[Epoch 29/100] [Batch 344/347] [D loss: 0.497944] [G loss: 0.262463]\n",
      "[Epoch 29/100] [Batch 345/347] [D loss: 0.494645] [G loss: 0.268536]\n",
      "[Epoch 29/100] [Batch 346/347] [D loss: 0.490086] [G loss: 0.286621]\n",
      "[Epoch 29/100] [Batch 347/347] [D loss: 0.482024] [G loss: 0.291812]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 30/100] [Batch 1/347] [D loss: 0.497358] [G loss: 0.256369]\n",
      "[Epoch 30/100] [Batch 2/347] [D loss: 0.497457] [G loss: 0.261145]\n",
      "[Epoch 30/100] [Batch 3/347] [D loss: 0.498352] [G loss: 0.262672]\n",
      "[Epoch 30/100] [Batch 4/347] [D loss: 0.498345] [G loss: 0.262977]\n",
      "[Epoch 30/100] [Batch 5/347] [D loss: 0.498212] [G loss: 0.262449]\n",
      "[Epoch 30/100] [Batch 6/347] [D loss: 0.498352] [G loss: 0.263625]\n",
      "[Epoch 30/100] [Batch 7/347] [D loss: 0.497912] [G loss: 0.264416]\n",
      "[Epoch 30/100] [Batch 8/347] [D loss: 0.497564] [G loss: 0.260715]\n",
      "[Epoch 30/100] [Batch 9/347] [D loss: 0.496537] [G loss: 0.260557]\n",
      "[Epoch 30/100] [Batch 10/347] [D loss: 0.496582] [G loss: 0.263056]\n",
      "[Epoch 30/100] [Batch 11/347] [D loss: 0.497924] [G loss: 0.263508]\n",
      "[Epoch 30/100] [Batch 12/347] [D loss: 0.498333] [G loss: 0.264786]\n",
      "[Epoch 30/100] [Batch 13/347] [D loss: 0.498826] [G loss: 0.268157]\n",
      "[Epoch 30/100] [Batch 14/347] [D loss: 0.499161] [G loss: 0.270557]\n",
      "[Epoch 30/100] [Batch 15/347] [D loss: 0.498781] [G loss: 0.266646]\n",
      "[Epoch 30/100] [Batch 16/347] [D loss: 0.498433] [G loss: 0.262525]\n",
      "[Epoch 30/100] [Batch 17/347] [D loss: 0.497373] [G loss: 0.251926]\n",
      "[Epoch 30/100] [Batch 18/347] [D loss: 0.496666] [G loss: 0.256745]\n",
      "[Epoch 30/100] [Batch 19/347] [D loss: 0.497964] [G loss: 0.256238]\n",
      "[Epoch 30/100] [Batch 20/347] [D loss: 0.499247] [G loss: 0.269493]\n",
      "[Epoch 30/100] [Batch 21/347] [D loss: 0.498920] [G loss: 0.265833]\n",
      "[Epoch 30/100] [Batch 22/347] [D loss: 0.498474] [G loss: 0.260902]\n",
      "[Epoch 30/100] [Batch 23/347] [D loss: 0.497867] [G loss: 0.254718]\n",
      "[Epoch 30/100] [Batch 24/347] [D loss: 0.497844] [G loss: 0.253961]\n",
      "[Epoch 30/100] [Batch 25/347] [D loss: 0.497842] [G loss: 0.253573]\n",
      "[Epoch 30/100] [Batch 26/347] [D loss: 0.495807] [G loss: 0.259468]\n",
      "[Epoch 30/100] [Batch 27/347] [D loss: 0.493123] [G loss: 0.264662]\n",
      "[Epoch 30/100] [Batch 28/347] [D loss: 0.494431] [G loss: 0.265743]\n",
      "[Epoch 30/100] [Batch 29/347] [D loss: 0.499098] [G loss: 0.264177]\n",
      "[Epoch 30/100] [Batch 30/347] [D loss: 0.499534] [G loss: 0.271041]\n",
      "[Epoch 30/100] [Batch 31/347] [D loss: 0.499355] [G loss: 0.273589]\n",
      "[Epoch 30/100] [Batch 32/347] [D loss: 0.498049] [G loss: 0.266798]\n",
      "[Epoch 30/100] [Batch 33/347] [D loss: 0.497947] [G loss: 0.262789]\n",
      "[Epoch 30/100] [Batch 34/347] [D loss: 0.498787] [G loss: 0.264143]\n",
      "[Epoch 30/100] [Batch 35/347] [D loss: 0.498716] [G loss: 0.263315]\n",
      "[Epoch 30/100] [Batch 36/347] [D loss: 0.498021] [G loss: 0.254616]\n",
      "[Epoch 30/100] [Batch 37/347] [D loss: 0.495098] [G loss: 0.267632]\n",
      "[Epoch 30/100] [Batch 38/347] [D loss: 0.493363] [G loss: 0.282458]\n",
      "[Epoch 30/100] [Batch 39/347] [D loss: 0.494556] [G loss: 0.272364]\n",
      "[Epoch 30/100] [Batch 40/347] [D loss: 0.495580] [G loss: 0.272890]\n",
      "[Epoch 30/100] [Batch 41/347] [D loss: 0.495347] [G loss: 0.273808]\n",
      "[Epoch 30/100] [Batch 42/347] [D loss: 0.495843] [G loss: 0.266406]\n",
      "[Epoch 30/100] [Batch 43/347] [D loss: 0.497376] [G loss: 0.249473]\n",
      "[Epoch 30/100] [Batch 44/347] [D loss: 0.499291] [G loss: 0.265069]\n",
      "[Epoch 30/100] [Batch 45/347] [D loss: 0.501005] [G loss: 0.282519]\n",
      "[Epoch 30/100] [Batch 46/347] [D loss: 0.500528] [G loss: 0.277341]\n",
      "[Epoch 30/100] [Batch 47/347] [D loss: 0.497599] [G loss: 0.252323]\n",
      "[Epoch 30/100] [Batch 48/347] [D loss: 0.493729] [G loss: 0.281820]\n",
      "[Epoch 30/100] [Batch 49/347] [D loss: 0.492574] [G loss: 0.290439]\n",
      "[Epoch 30/100] [Batch 50/347] [D loss: 0.488128] [G loss: 0.305670]\n",
      "[Epoch 30/100] [Batch 51/347] [D loss: 0.488525] [G loss: 0.289521]\n",
      "[Epoch 30/100] [Batch 52/347] [D loss: 0.496517] [G loss: 0.263683]\n",
      "[Epoch 30/100] [Batch 53/347] [D loss: 0.497010] [G loss: 0.257726]\n",
      "[Epoch 30/100] [Batch 54/347] [D loss: 0.491025] [G loss: 0.304232]\n",
      "[Epoch 30/100] [Batch 55/347] [D loss: 0.488336] [G loss: 0.326896]\n",
      "[Epoch 30/100] [Batch 56/347] [D loss: 0.489537] [G loss: 0.313576]\n",
      "[Epoch 30/100] [Batch 57/347] [D loss: 0.493472] [G loss: 0.278842]\n",
      "[Epoch 30/100] [Batch 58/347] [D loss: 0.497259] [G loss: 0.259765]\n",
      "[Epoch 30/100] [Batch 59/347] [D loss: 0.495096] [G loss: 0.261693]\n",
      "[Epoch 30/100] [Batch 60/347] [D loss: 0.492695] [G loss: 0.281176]\n",
      "[Epoch 30/100] [Batch 61/347] [D loss: 0.491303] [G loss: 0.294469]\n",
      "[Epoch 30/100] [Batch 62/347] [D loss: 0.488802] [G loss: 0.319083]\n",
      "[Epoch 30/100] [Batch 63/347] [D loss: 0.488575] [G loss: 0.321286]\n",
      "[Epoch 30/100] [Batch 64/347] [D loss: 0.493015] [G loss: 0.284131]\n",
      "[Epoch 30/100] [Batch 65/347] [D loss: 0.499023] [G loss: 0.263772]\n",
      "[Epoch 30/100] [Batch 66/347] [D loss: 0.495268] [G loss: 0.266284]\n",
      "[Epoch 30/100] [Batch 67/347] [D loss: 0.487899] [G loss: 0.269055]\n",
      "[Epoch 30/100] [Batch 68/347] [D loss: 0.487664] [G loss: 0.287318]\n",
      "[Epoch 30/100] [Batch 69/347] [D loss: 0.490250] [G loss: 0.306473]\n",
      "[Epoch 30/100] [Batch 70/347] [D loss: 0.490260] [G loss: 0.304823]\n",
      "[Epoch 30/100] [Batch 71/347] [D loss: 0.490041] [G loss: 0.306325]\n",
      "[Epoch 30/100] [Batch 72/347] [D loss: 0.489638] [G loss: 0.308189]\n",
      "[Epoch 30/100] [Batch 73/347] [D loss: 0.492364] [G loss: 0.282959]\n",
      "[Epoch 30/100] [Batch 74/347] [D loss: 0.493705] [G loss: 0.268604]\n",
      "[Epoch 30/100] [Batch 75/347] [D loss: 0.490851] [G loss: 0.298723]\n",
      "[Epoch 30/100] [Batch 76/347] [D loss: 0.490851] [G loss: 0.301022]\n",
      "[Epoch 30/100] [Batch 77/347] [D loss: 0.494786] [G loss: 0.266771]\n",
      "[Epoch 30/100] [Batch 78/347] [D loss: 0.498694] [G loss: 0.267892]\n",
      "[Epoch 30/100] [Batch 79/347] [D loss: 0.500487] [G loss: 0.269972]\n",
      "[Epoch 30/100] [Batch 80/347] [D loss: 0.500140] [G loss: 0.268076]\n",
      "[Epoch 30/100] [Batch 81/347] [D loss: 0.500610] [G loss: 0.273560]\n",
      "[Epoch 30/100] [Batch 82/347] [D loss: 0.499581] [G loss: 0.279303]\n",
      "[Epoch 30/100] [Batch 83/347] [D loss: 0.499286] [G loss: 0.272392]\n",
      "[Epoch 30/100] [Batch 84/347] [D loss: 0.500630] [G loss: 0.279485]\n",
      "[Epoch 30/100] [Batch 85/347] [D loss: 0.500757] [G loss: 0.281080]\n",
      "[Epoch 30/100] [Batch 86/347] [D loss: 0.500203] [G loss: 0.276163]\n",
      "[Epoch 30/100] [Batch 87/347] [D loss: 0.499963] [G loss: 0.274688]\n",
      "[Epoch 30/100] [Batch 88/347] [D loss: 0.500281] [G loss: 0.278551]\n",
      "[Epoch 30/100] [Batch 89/347] [D loss: 0.500585] [G loss: 0.282290]\n",
      "[Epoch 30/100] [Batch 90/347] [D loss: 0.500229] [G loss: 0.278721]\n",
      "[Epoch 30/100] [Batch 91/347] [D loss: 0.500088] [G loss: 0.277345]\n",
      "[Epoch 30/100] [Batch 92/347] [D loss: 0.500207] [G loss: 0.278885]\n",
      "[Epoch 30/100] [Batch 93/347] [D loss: 0.499965] [G loss: 0.276835]\n",
      "[Epoch 30/100] [Batch 94/347] [D loss: 0.499631] [G loss: 0.273233]\n",
      "[Epoch 30/100] [Batch 95/347] [D loss: 0.499697] [G loss: 0.273734]\n",
      "[Epoch 30/100] [Batch 96/347] [D loss: 0.499273] [G loss: 0.269013]\n",
      "[Epoch 30/100] [Batch 97/347] [D loss: 0.498747] [G loss: 0.263938]\n",
      "[Epoch 30/100] [Batch 98/347] [D loss: 0.499226] [G loss: 0.268990]\n",
      "[Epoch 30/100] [Batch 99/347] [D loss: 0.499619] [G loss: 0.272949]\n",
      "[Epoch 30/100] [Batch 100/347] [D loss: 0.499285] [G loss: 0.269556]\n",
      "[Epoch 30/100] [Batch 101/347] [D loss: 0.498808] [G loss: 0.264698]\n",
      "[Epoch 30/100] [Batch 102/347] [D loss: 0.499028] [G loss: 0.266640]\n",
      "[Epoch 30/100] [Batch 103/347] [D loss: 0.499120] [G loss: 0.267766]\n",
      "[Epoch 30/100] [Batch 104/347] [D loss: 0.498261] [G loss: 0.259269]\n",
      "[Epoch 30/100] [Batch 105/347] [D loss: 0.498183] [G loss: 0.258898]\n",
      "[Epoch 30/100] [Batch 106/347] [D loss: 0.498034] [G loss: 0.258219]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 30/100] [Batch 107/347] [D loss: 0.496108] [G loss: 0.252399]\n",
      "[Epoch 30/100] [Batch 108/347] [D loss: 0.486259] [G loss: 0.269452]\n",
      "[Epoch 30/100] [Batch 109/347] [D loss: 0.486531] [G loss: 0.266915]\n",
      "[Epoch 30/100] [Batch 110/347] [D loss: 0.497841] [G loss: 0.255562]\n",
      "[Epoch 30/100] [Batch 111/347] [D loss: 0.489228] [G loss: 0.257994]\n",
      "[Epoch 30/100] [Batch 112/347] [D loss: 0.487764] [G loss: 0.261116]\n",
      "[Epoch 30/100] [Batch 113/347] [D loss: 0.496592] [G loss: 0.265577]\n",
      "[Epoch 30/100] [Batch 114/347] [D loss: 0.501276] [G loss: 0.285305]\n",
      "[Epoch 30/100] [Batch 115/347] [D loss: 0.501321] [G loss: 0.285995]\n",
      "[Epoch 30/100] [Batch 116/347] [D loss: 0.500737] [G loss: 0.280065]\n",
      "[Epoch 30/100] [Batch 117/347] [D loss: 0.497975] [G loss: 0.253450]\n",
      "[Epoch 30/100] [Batch 118/347] [D loss: 0.494469] [G loss: 0.265027]\n",
      "[Epoch 30/100] [Batch 119/347] [D loss: 0.493911] [G loss: 0.267899]\n",
      "[Epoch 30/100] [Batch 120/347] [D loss: 0.492897] [G loss: 0.267255]\n",
      "[Epoch 30/100] [Batch 121/347] [D loss: 0.493097] [G loss: 0.265852]\n",
      "[Epoch 30/100] [Batch 122/347] [D loss: 0.495991] [G loss: 0.254564]\n",
      "[Epoch 30/100] [Batch 123/347] [D loss: 0.496847] [G loss: 0.254041]\n",
      "[Epoch 30/100] [Batch 124/347] [D loss: 0.496366] [G loss: 0.255328]\n",
      "[Epoch 30/100] [Batch 125/347] [D loss: 0.497629] [G loss: 0.253740]\n",
      "[Epoch 30/100] [Batch 126/347] [D loss: 0.498827] [G loss: 0.266519]\n",
      "[Epoch 30/100] [Batch 127/347] [D loss: 0.498907] [G loss: 0.268062]\n",
      "[Epoch 30/100] [Batch 128/347] [D loss: 0.498331] [G loss: 0.262838]\n",
      "[Epoch 30/100] [Batch 129/347] [D loss: 0.497560] [G loss: 0.258134]\n",
      "[Epoch 30/100] [Batch 130/347] [D loss: 0.496385] [G loss: 0.261102]\n",
      "[Epoch 30/100] [Batch 131/347] [D loss: 0.488174] [G loss: 0.266516]\n",
      "[Epoch 30/100] [Batch 132/347] [D loss: 0.474039] [G loss: 0.289954]\n",
      "[Epoch 30/100] [Batch 133/347] [D loss: 0.475713] [G loss: 0.294785]\n",
      "[Epoch 30/100] [Batch 134/347] [D loss: 0.471315] [G loss: 0.307376]\n",
      "[Epoch 30/100] [Batch 135/347] [D loss: 0.458827] [G loss: 0.313780]\n",
      "[Epoch 30/100] [Batch 136/347] [D loss: 0.462393] [G loss: 0.268771]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 30/100] [Batch 137/347] [D loss: 0.494053] [G loss: 0.251836]\n",
      "[Epoch 30/100] [Batch 138/347] [D loss: 0.492321] [G loss: 0.270704]\n",
      "[Epoch 30/100] [Batch 139/347] [D loss: 0.489021] [G loss: 0.294212]\n",
      "[Epoch 30/100] [Batch 140/347] [D loss: 0.487588] [G loss: 0.305634]\n",
      "[Epoch 30/100] [Batch 141/347] [D loss: 0.487057] [G loss: 0.313009]\n",
      "[Epoch 30/100] [Batch 142/347] [D loss: 0.486251] [G loss: 0.321325]\n",
      "[Epoch 30/100] [Batch 143/347] [D loss: 0.482868] [G loss: 0.343919]\n",
      "[Epoch 30/100] [Batch 144/347] [D loss: 0.482625] [G loss: 0.347484]\n",
      "[Epoch 30/100] [Batch 145/347] [D loss: 0.484624] [G loss: 0.334616]\n",
      "[Epoch 30/100] [Batch 146/347] [D loss: 0.486590] [G loss: 0.319379]\n",
      "[Epoch 30/100] [Batch 147/347] [D loss: 0.490309] [G loss: 0.292826]\n",
      "[Epoch 30/100] [Batch 148/347] [D loss: 0.491878] [G loss: 0.282147]\n",
      "[Epoch 30/100] [Batch 149/347] [D loss: 0.490313] [G loss: 0.297342]\n",
      "[Epoch 30/100] [Batch 150/347] [D loss: 0.490533] [G loss: 0.299367]\n",
      "[Epoch 30/100] [Batch 151/347] [D loss: 0.491912] [G loss: 0.289721]\n",
      "[Epoch 30/100] [Batch 152/347] [D loss: 0.489997] [G loss: 0.301784]\n",
      "[Epoch 30/100] [Batch 153/347] [D loss: 0.486891] [G loss: 0.322956]\n",
      "[Epoch 30/100] [Batch 154/347] [D loss: 0.485983] [G loss: 0.327056]\n",
      "[Epoch 30/100] [Batch 155/347] [D loss: 0.487793] [G loss: 0.313827]\n",
      "[Epoch 30/100] [Batch 156/347] [D loss: 0.490470] [G loss: 0.296660]\n",
      "[Epoch 30/100] [Batch 157/347] [D loss: 0.489257] [G loss: 0.302157]\n",
      "[Epoch 30/100] [Batch 158/347] [D loss: 0.485588] [G loss: 0.325215]\n",
      "[Epoch 30/100] [Batch 159/347] [D loss: 0.485599] [G loss: 0.322100]\n",
      "[Epoch 30/100] [Batch 160/347] [D loss: 0.486525] [G loss: 0.301406]\n",
      "[Epoch 30/100] [Batch 161/347] [D loss: 0.487367] [G loss: 0.292341]\n",
      "[Epoch 30/100] [Batch 162/347] [D loss: 0.488466] [G loss: 0.297737]\n",
      "[Epoch 30/100] [Batch 163/347] [D loss: 0.486084] [G loss: 0.316292]\n",
      "[Epoch 30/100] [Batch 164/347] [D loss: 0.483523] [G loss: 0.331814]\n",
      "[Epoch 30/100] [Batch 165/347] [D loss: 0.484349] [G loss: 0.323279]\n",
      "[Epoch 30/100] [Batch 166/347] [D loss: 0.489932] [G loss: 0.285197]\n",
      "[Epoch 30/100] [Batch 167/347] [D loss: 0.492924] [G loss: 0.264582]\n",
      "[Epoch 30/100] [Batch 168/347] [D loss: 0.493564] [G loss: 0.275583]\n",
      "[Epoch 30/100] [Batch 169/347] [D loss: 0.497209] [G loss: 0.274612]\n",
      "[Epoch 30/100] [Batch 170/347] [D loss: 0.499988] [G loss: 0.271081]\n",
      "[Epoch 30/100] [Batch 171/347] [D loss: 0.501708] [G loss: 0.278757]\n",
      "[Epoch 30/100] [Batch 172/347] [D loss: 0.502407] [G loss: 0.284463]\n",
      "[Epoch 30/100] [Batch 173/347] [D loss: 0.500557] [G loss: 0.274198]\n",
      "[Epoch 30/100] [Batch 174/347] [D loss: 0.500076] [G loss: 0.272600]\n",
      "[Epoch 30/100] [Batch 175/347] [D loss: 0.501648] [G loss: 0.283508]\n",
      "[Epoch 30/100] [Batch 176/347] [D loss: 0.503461] [G loss: 0.297792]\n",
      "[Epoch 30/100] [Batch 177/347] [D loss: 0.503555] [G loss: 0.299593]\n",
      "[Epoch 30/100] [Batch 178/347] [D loss: 0.502738] [G loss: 0.294164]\n",
      "[Epoch 30/100] [Batch 179/347] [D loss: 0.501923] [G loss: 0.287948]\n",
      "[Epoch 30/100] [Batch 180/347] [D loss: 0.501192] [G loss: 0.281751]\n",
      "[Epoch 30/100] [Batch 181/347] [D loss: 0.501227] [G loss: 0.282354]\n",
      "[Epoch 30/100] [Batch 182/347] [D loss: 0.500856] [G loss: 0.280262]\n",
      "[Epoch 30/100] [Batch 183/347] [D loss: 0.501376] [G loss: 0.284195]\n",
      "[Epoch 30/100] [Batch 184/347] [D loss: 0.501876] [G loss: 0.287932]\n",
      "[Epoch 30/100] [Batch 185/347] [D loss: 0.501738] [G loss: 0.286104]\n",
      "[Epoch 30/100] [Batch 186/347] [D loss: 0.501844] [G loss: 0.285662]\n",
      "[Epoch 30/100] [Batch 187/347] [D loss: 0.501295] [G loss: 0.280130]\n",
      "[Epoch 30/100] [Batch 188/347] [D loss: 0.500828] [G loss: 0.276651]\n",
      "[Epoch 30/100] [Batch 189/347] [D loss: 0.500707] [G loss: 0.275741]\n",
      "[Epoch 30/100] [Batch 190/347] [D loss: 0.499076] [G loss: 0.263884]\n",
      "[Epoch 30/100] [Batch 191/347] [D loss: 0.497229] [G loss: 0.252006]\n",
      "[Epoch 30/100] [Batch 192/347] [D loss: 0.497710] [G loss: 0.254375]\n",
      "[Epoch 30/100] [Batch 193/347] [D loss: 0.499094] [G loss: 0.262374]\n",
      "[Epoch 30/100] [Batch 194/347] [D loss: 0.498550] [G loss: 0.258433]\n",
      "[Epoch 30/100] [Batch 195/347] [D loss: 0.497548] [G loss: 0.253923]\n",
      "[Epoch 30/100] [Batch 196/347] [D loss: 0.496957] [G loss: 0.251849]\n",
      "[Epoch 30/100] [Batch 197/347] [D loss: 0.496802] [G loss: 0.249098]\n",
      "[Epoch 30/100] [Batch 198/347] [D loss: 0.496471] [G loss: 0.254115]\n",
      "[Epoch 30/100] [Batch 199/347] [D loss: 0.496378] [G loss: 0.254629]\n",
      "[Epoch 30/100] [Batch 200/347] [D loss: 0.497342] [G loss: 0.254009]\n",
      "[Epoch 30/100] [Batch 201/347] [D loss: 0.497520] [G loss: 0.251144]\n",
      "[Epoch 30/100] [Batch 202/347] [D loss: 0.496700] [G loss: 0.259268]\n",
      "[Epoch 30/100] [Batch 203/347] [D loss: 0.496033] [G loss: 0.269309]\n",
      "[Epoch 30/100] [Batch 204/347] [D loss: 0.496228] [G loss: 0.266831]\n",
      "[Epoch 30/100] [Batch 205/347] [D loss: 0.496583] [G loss: 0.259908]\n",
      "[Epoch 30/100] [Batch 206/347] [D loss: 0.497409] [G loss: 0.250975]\n",
      "[Epoch 30/100] [Batch 207/347] [D loss: 0.498843] [G loss: 0.261430]\n",
      "[Epoch 30/100] [Batch 208/347] [D loss: 0.498724] [G loss: 0.261826]\n",
      "[Epoch 30/100] [Batch 209/347] [D loss: 0.497764] [G loss: 0.255679]\n",
      "[Epoch 30/100] [Batch 210/347] [D loss: 0.498720] [G loss: 0.263002]\n",
      "[Epoch 30/100] [Batch 211/347] [D loss: 0.498495] [G loss: 0.259893]\n",
      "[Epoch 30/100] [Batch 212/347] [D loss: 0.496430] [G loss: 0.258394]\n",
      "[Epoch 30/100] [Batch 213/347] [D loss: 0.493193] [G loss: 0.263632]\n",
      "[Epoch 30/100] [Batch 214/347] [D loss: 0.476313] [G loss: 0.277077]\n",
      "[Epoch 30/100] [Batch 215/347] [D loss: 0.475934] [G loss: 0.283345]\n",
      "[Epoch 30/100] [Batch 216/347] [D loss: 0.494757] [G loss: 0.257375]\n",
      "[Epoch 30/100] [Batch 217/347] [D loss: 0.497676] [G loss: 0.256883]\n",
      "[Epoch 30/100] [Batch 218/347] [D loss: 0.499921] [G loss: 0.263306]\n",
      "[Epoch 30/100] [Batch 219/347] [D loss: 0.501381] [G loss: 0.275598]\n",
      "[Epoch 30/100] [Batch 220/347] [D loss: 0.503210] [G loss: 0.291842]\n",
      "[Epoch 30/100] [Batch 221/347] [D loss: 0.503319] [G loss: 0.293997]\n",
      "[Epoch 30/100] [Batch 222/347] [D loss: 0.502206] [G loss: 0.287076]\n",
      "[Epoch 30/100] [Batch 223/347] [D loss: 0.501940] [G loss: 0.287028]\n",
      "[Epoch 30/100] [Batch 224/347] [D loss: 0.501468] [G loss: 0.284214]\n",
      "[Epoch 30/100] [Batch 225/347] [D loss: 0.497802] [G loss: 0.271957]\n",
      "[Epoch 30/100] [Batch 226/347] [D loss: 0.493571] [G loss: 0.274983]\n",
      "[Epoch 30/100] [Batch 227/347] [D loss: 0.491988] [G loss: 0.285534]\n",
      "[Epoch 30/100] [Batch 228/347] [D loss: 0.492445] [G loss: 0.287147]\n",
      "[Epoch 30/100] [Batch 229/347] [D loss: 0.493986] [G loss: 0.281802]\n",
      "[Epoch 30/100] [Batch 230/347] [D loss: 0.494720] [G loss: 0.277334]\n",
      "[Epoch 30/100] [Batch 231/347] [D loss: 0.494003] [G loss: 0.276754]\n",
      "[Epoch 30/100] [Batch 232/347] [D loss: 0.494453] [G loss: 0.272163]\n",
      "[Epoch 30/100] [Batch 233/347] [D loss: 0.494338] [G loss: 0.268934]\n",
      "[Epoch 30/100] [Batch 234/347] [D loss: 0.493667] [G loss: 0.273391]\n",
      "[Epoch 30/100] [Batch 235/347] [D loss: 0.494963] [G loss: 0.261560]\n",
      "[Epoch 30/100] [Batch 236/347] [D loss: 0.497111] [G loss: 0.261258]\n",
      "[Epoch 30/100] [Batch 237/347] [D loss: 0.498966] [G loss: 0.264399]\n",
      "[Epoch 30/100] [Batch 238/347] [D loss: 0.499599] [G loss: 0.268081]\n",
      "[Epoch 30/100] [Batch 239/347] [D loss: 0.499210] [G loss: 0.265871]\n",
      "[Epoch 30/100] [Batch 240/347] [D loss: 0.498672] [G loss: 0.262142]\n",
      "[Epoch 30/100] [Batch 241/347] [D loss: 0.497973] [G loss: 0.256596]\n",
      "[Epoch 30/100] [Batch 242/347] [D loss: 0.497771] [G loss: 0.255138]\n",
      "[Epoch 30/100] [Batch 243/347] [D loss: 0.498829] [G loss: 0.263433]\n",
      "[Epoch 30/100] [Batch 244/347] [D loss: 0.500006] [G loss: 0.272924]\n",
      "[Epoch 30/100] [Batch 245/347] [D loss: 0.499917] [G loss: 0.272065]\n",
      "[Epoch 30/100] [Batch 246/347] [D loss: 0.496745] [G loss: 0.265861]\n",
      "[Epoch 30/100] [Batch 247/347] [D loss: 0.494390] [G loss: 0.268417]\n",
      "[Epoch 30/100] [Batch 248/347] [D loss: 0.493582] [G loss: 0.273105]\n",
      "[Epoch 30/100] [Batch 249/347] [D loss: 0.492808] [G loss: 0.278720]\n",
      "[Epoch 30/100] [Batch 250/347] [D loss: 0.494361] [G loss: 0.269250]\n",
      "[Epoch 30/100] [Batch 251/347] [D loss: 0.497343] [G loss: 0.267632]\n",
      "[Epoch 30/100] [Batch 252/347] [D loss: 0.498409] [G loss: 0.270757]\n",
      "[Epoch 30/100] [Batch 253/347] [D loss: 0.498620] [G loss: 0.271116]\n",
      "[Epoch 30/100] [Batch 254/347] [D loss: 0.499092] [G loss: 0.269384]\n",
      "[Epoch 30/100] [Batch 255/347] [D loss: 0.496976] [G loss: 0.267884]\n",
      "[Epoch 30/100] [Batch 256/347] [D loss: 0.497500] [G loss: 0.273173]\n",
      "[Epoch 30/100] [Batch 257/347] [D loss: 0.499924] [G loss: 0.275369]\n",
      "[Epoch 30/100] [Batch 258/347] [D loss: 0.497596] [G loss: 0.270537]\n",
      "[Epoch 30/100] [Batch 259/347] [D loss: 0.493446] [G loss: 0.265642]\n",
      "[Epoch 30/100] [Batch 260/347] [D loss: 0.490451] [G loss: 0.279599]\n",
      "[Epoch 30/100] [Batch 261/347] [D loss: 0.491608] [G loss: 0.271466]\n",
      "[Epoch 30/100] [Batch 262/347] [D loss: 0.495182] [G loss: 0.258040]\n",
      "[Epoch 30/100] [Batch 263/347] [D loss: 0.494629] [G loss: 0.256476]\n",
      "[Epoch 30/100] [Batch 264/347] [D loss: 0.491360] [G loss: 0.270833]\n",
      "[Epoch 30/100] [Batch 265/347] [D loss: 0.490619] [G loss: 0.276054]\n",
      "[Epoch 30/100] [Batch 266/347] [D loss: 0.492183] [G loss: 0.268822]\n",
      "[Epoch 30/100] [Batch 267/347] [D loss: 0.493436] [G loss: 0.261861]\n",
      "[Epoch 30/100] [Batch 268/347] [D loss: 0.491298] [G loss: 0.268618]\n",
      "[Epoch 30/100] [Batch 269/347] [D loss: 0.489347] [G loss: 0.279661]\n",
      "[Epoch 30/100] [Batch 270/347] [D loss: 0.491080] [G loss: 0.276224]\n",
      "[Epoch 30/100] [Batch 271/347] [D loss: 0.493454] [G loss: 0.264406]\n",
      "[Epoch 30/100] [Batch 272/347] [D loss: 0.494976] [G loss: 0.257207]\n",
      "[Epoch 30/100] [Batch 273/347] [D loss: 0.484879] [G loss: 0.268169]\n",
      "[Epoch 30/100] [Batch 274/347] [D loss: 0.397023] [G loss: 0.302650]\n",
      "[Epoch 30/100] [Batch 275/347] [D loss: 0.396821] [G loss: 0.300142]\n",
      "[Epoch 30/100] [Batch 276/347] [D loss: 0.489797] [G loss: 0.268070]\n",
      "[Epoch 30/100] [Batch 277/347] [D loss: 0.494677] [G loss: 0.259238]\n",
      "[Epoch 30/100] [Batch 278/347] [D loss: 0.497365] [G loss: 0.256901]\n",
      "[Epoch 30/100] [Batch 279/347] [D loss: 0.496209] [G loss: 0.263495]\n",
      "[Epoch 30/100] [Batch 280/347] [D loss: 0.495018] [G loss: 0.266523]\n",
      "[Epoch 30/100] [Batch 281/347] [D loss: 0.495224] [G loss: 0.264435]\n",
      "[Epoch 30/100] [Batch 282/347] [D loss: 0.495644] [G loss: 0.261991]\n",
      "[Epoch 30/100] [Batch 283/347] [D loss: 0.493720] [G loss: 0.262055]\n",
      "[Epoch 30/100] [Batch 284/347] [D loss: 0.493794] [G loss: 0.263840]\n",
      "[Epoch 30/100] [Batch 285/347] [D loss: 0.496014] [G loss: 0.259291]\n",
      "[Epoch 30/100] [Batch 286/347] [D loss: 0.496297] [G loss: 0.251759]\n",
      "[Epoch 30/100] [Batch 287/347] [D loss: 0.495758] [G loss: 0.250663]\n",
      "[Epoch 30/100] [Batch 288/347] [D loss: 0.491291] [G loss: 0.277347]\n",
      "[Epoch 30/100] [Batch 289/347] [D loss: 0.490601] [G loss: 0.281895]\n",
      "[Epoch 30/100] [Batch 290/347] [D loss: 0.494262] [G loss: 0.258985]\n",
      "[Epoch 30/100] [Batch 291/347] [D loss: 0.493336] [G loss: 0.261701]\n",
      "[Epoch 30/100] [Batch 292/347] [D loss: 0.494480] [G loss: 0.253258]\n",
      "[Epoch 30/100] [Batch 293/347] [D loss: 0.497655] [G loss: 0.266790]\n",
      "[Epoch 30/100] [Batch 294/347] [D loss: 0.497931] [G loss: 0.276244]\n",
      "[Epoch 30/100] [Batch 295/347] [D loss: 0.484449] [G loss: 0.273108]\n",
      "[Epoch 30/100] [Batch 296/347] [D loss: 0.484728] [G loss: 0.268018]\n",
      "[Epoch 30/100] [Batch 297/347] [D loss: 0.498522] [G loss: 0.278492]\n",
      "[Epoch 30/100] [Batch 298/347] [D loss: 0.500243] [G loss: 0.273092]\n",
      "[Epoch 30/100] [Batch 299/347] [D loss: 0.499738] [G loss: 0.272061]\n",
      "[Epoch 30/100] [Batch 300/347] [D loss: 0.498339] [G loss: 0.268134]\n",
      "[Epoch 30/100] [Batch 301/347] [D loss: 0.497713] [G loss: 0.270628]\n",
      "[Epoch 30/100] [Batch 302/347] [D loss: 0.498708] [G loss: 0.276693]\n",
      "[Epoch 30/100] [Batch 303/347] [D loss: 0.495058] [G loss: 0.261887]\n",
      "[Epoch 30/100] [Batch 304/347] [D loss: 0.493170] [G loss: 0.263149]\n",
      "[Epoch 30/100] [Batch 305/347] [D loss: 0.493213] [G loss: 0.275782]\n",
      "[Epoch 30/100] [Batch 306/347] [D loss: 0.487748] [G loss: 0.267962]\n",
      "[Epoch 30/100] [Batch 307/347] [D loss: 0.481948] [G loss: 0.279520]\n",
      "[Epoch 30/100] [Batch 308/347] [D loss: 0.485738] [G loss: 0.274622]\n",
      "[Epoch 30/100] [Batch 309/347] [D loss: 0.495279] [G loss: 0.253145]\n",
      "[Epoch 30/100] [Batch 310/347] [D loss: 0.499427] [G loss: 0.275875]\n",
      "[Epoch 30/100] [Batch 311/347] [D loss: 0.499660] [G loss: 0.278664]\n",
      "[Epoch 30/100] [Batch 312/347] [D loss: 0.499594] [G loss: 0.278529]\n",
      "[Epoch 30/100] [Batch 313/347] [D loss: 0.499493] [G loss: 0.278106]\n",
      "[Epoch 30/100] [Batch 314/347] [D loss: 0.498504] [G loss: 0.272156]\n",
      "[Epoch 30/100] [Batch 315/347] [D loss: 0.496766] [G loss: 0.263530]\n",
      "[Epoch 30/100] [Batch 316/347] [D loss: 0.494539] [G loss: 0.254278]\n",
      "[Epoch 30/100] [Batch 317/347] [D loss: 0.493038] [G loss: 0.272817]\n",
      "[Epoch 30/100] [Batch 318/347] [D loss: 0.496033] [G loss: 0.254422]\n",
      "[Epoch 30/100] [Batch 319/347] [D loss: 0.500880] [G loss: 0.287642]\n",
      "[Epoch 30/100] [Batch 320/347] [D loss: 0.502730] [G loss: 0.301255]\n",
      "[Epoch 30/100] [Batch 321/347] [D loss: 0.501214] [G loss: 0.290731]\n",
      "[Epoch 30/100] [Batch 322/347] [D loss: 0.499302] [G loss: 0.277259]\n",
      "[Epoch 30/100] [Batch 323/347] [D loss: 0.498996] [G loss: 0.275950]\n",
      "[Epoch 30/100] [Batch 324/347] [D loss: 0.499401] [G loss: 0.278799]\n",
      "[Epoch 30/100] [Batch 325/347] [D loss: 0.496692] [G loss: 0.267920]\n",
      "[Epoch 30/100] [Batch 326/347] [D loss: 0.494463] [G loss: 0.258859]\n",
      "[Epoch 30/100] [Batch 327/347] [D loss: 0.495186] [G loss: 0.256935]\n",
      "[Epoch 30/100] [Batch 328/347] [D loss: 0.495751] [G loss: 0.253508]\n",
      "[Epoch 30/100] [Batch 329/347] [D loss: 0.490976] [G loss: 0.266774]\n",
      "[Epoch 30/100] [Batch 330/347] [D loss: 0.488244] [G loss: 0.281626]\n",
      "[Epoch 30/100] [Batch 331/347] [D loss: 0.492045] [G loss: 0.262741]\n",
      "[Epoch 30/100] [Batch 332/347] [D loss: 0.498250] [G loss: 0.267350]\n",
      "[Epoch 30/100] [Batch 333/347] [D loss: 0.499960] [G loss: 0.279089]\n",
      "[Epoch 30/100] [Batch 334/347] [D loss: 0.500148] [G loss: 0.280917]\n",
      "[Epoch 30/100] [Batch 335/347] [D loss: 0.498193] [G loss: 0.269387]\n",
      "[Epoch 30/100] [Batch 336/347] [D loss: 0.495920] [G loss: 0.256852]\n",
      "[Epoch 30/100] [Batch 337/347] [D loss: 0.496859] [G loss: 0.261898]\n",
      "[Epoch 30/100] [Batch 338/347] [D loss: 0.499208] [G loss: 0.277333]\n",
      "[Epoch 30/100] [Batch 339/347] [D loss: 0.500176] [G loss: 0.283421]\n",
      "[Epoch 30/100] [Batch 340/347] [D loss: 0.500311] [G loss: 0.284435]\n",
      "[Epoch 30/100] [Batch 341/347] [D loss: 0.499507] [G loss: 0.280042]\n",
      "[Epoch 30/100] [Batch 342/347] [D loss: 0.498297] [G loss: 0.272672]\n",
      "[Epoch 30/100] [Batch 343/347] [D loss: 0.499051] [G loss: 0.277563]\n",
      "[Epoch 30/100] [Batch 344/347] [D loss: 0.496758] [G loss: 0.265638]\n",
      "[Epoch 30/100] [Batch 345/347] [D loss: 0.491266] [G loss: 0.266683]\n",
      "[Epoch 30/100] [Batch 346/347] [D loss: 0.482278] [G loss: 0.284326]\n",
      "[Epoch 30/100] [Batch 347/347] [D loss: 0.463182] [G loss: 0.289257]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 31/100] [Batch 1/347] [D loss: 0.496053] [G loss: 0.254820]\n",
      "[Epoch 31/100] [Batch 2/347] [D loss: 0.496216] [G loss: 0.258392]\n",
      "[Epoch 31/100] [Batch 3/347] [D loss: 0.497674] [G loss: 0.265007]\n",
      "[Epoch 31/100] [Batch 4/347] [D loss: 0.497634] [G loss: 0.265397]\n",
      "[Epoch 31/100] [Batch 5/347] [D loss: 0.497393] [G loss: 0.264012]\n",
      "[Epoch 31/100] [Batch 6/347] [D loss: 0.497565] [G loss: 0.265580]\n",
      "[Epoch 31/100] [Batch 7/347] [D loss: 0.496738] [G loss: 0.264594]\n",
      "[Epoch 31/100] [Batch 8/347] [D loss: 0.495988] [G loss: 0.261655]\n",
      "[Epoch 31/100] [Batch 9/347] [D loss: 0.494178] [G loss: 0.262152]\n",
      "[Epoch 31/100] [Batch 10/347] [D loss: 0.494230] [G loss: 0.264993]\n",
      "[Epoch 31/100] [Batch 11/347] [D loss: 0.496409] [G loss: 0.265676]\n",
      "[Epoch 31/100] [Batch 12/347] [D loss: 0.497053] [G loss: 0.266993]\n",
      "[Epoch 31/100] [Batch 13/347] [D loss: 0.497771] [G loss: 0.267432]\n",
      "[Epoch 31/100] [Batch 14/347] [D loss: 0.498200] [G loss: 0.269246]\n",
      "[Epoch 31/100] [Batch 15/347] [D loss: 0.497521] [G loss: 0.264816]\n",
      "[Epoch 31/100] [Batch 16/347] [D loss: 0.496887] [G loss: 0.260270]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 31/100] [Batch 17/347] [D loss: 0.495023] [G loss: 0.253785]\n",
      "[Epoch 31/100] [Batch 18/347] [D loss: 0.493753] [G loss: 0.257936]\n",
      "[Epoch 31/100] [Batch 19/347] [D loss: 0.495871] [G loss: 0.253145]\n",
      "[Epoch 31/100] [Batch 20/347] [D loss: 0.498151] [G loss: 0.266337]\n",
      "[Epoch 31/100] [Batch 21/347] [D loss: 0.497640] [G loss: 0.262714]\n",
      "[Epoch 31/100] [Batch 22/347] [D loss: 0.496875] [G loss: 0.257953]\n",
      "[Epoch 31/100] [Batch 23/347] [D loss: 0.495753] [G loss: 0.255891]\n",
      "[Epoch 31/100] [Batch 24/347] [D loss: 0.495725] [G loss: 0.252349]\n",
      "[Epoch 31/100] [Batch 25/347] [D loss: 0.495922] [G loss: 0.253797]\n",
      "[Epoch 31/100] [Batch 26/347] [D loss: 0.492179] [G loss: 0.260579]\n",
      "[Epoch 31/100] [Batch 27/347] [D loss: 0.485414] [G loss: 0.265184]\n",
      "[Epoch 31/100] [Batch 28/347] [D loss: 0.487508] [G loss: 0.266006]\n",
      "[Epoch 31/100] [Batch 29/347] [D loss: 0.498307] [G loss: 0.264966]\n",
      "[Epoch 31/100] [Batch 30/347] [D loss: 0.498895] [G loss: 0.272405]\n",
      "[Epoch 31/100] [Batch 31/347] [D loss: 0.498243] [G loss: 0.275496]\n",
      "[Epoch 31/100] [Batch 32/347] [D loss: 0.495330] [G loss: 0.269131]\n",
      "[Epoch 31/100] [Batch 33/347] [D loss: 0.495585] [G loss: 0.265490]\n",
      "[Epoch 31/100] [Batch 34/347] [D loss: 0.497944] [G loss: 0.267288]\n",
      "[Epoch 31/100] [Batch 35/347] [D loss: 0.497924] [G loss: 0.266790]\n",
      "[Epoch 31/100] [Batch 36/347] [D loss: 0.497094] [G loss: 0.258422]\n",
      "[Epoch 31/100] [Batch 37/347] [D loss: 0.492164] [G loss: 0.264318]\n",
      "[Epoch 31/100] [Batch 38/347] [D loss: 0.489301] [G loss: 0.278882]\n",
      "[Epoch 31/100] [Batch 39/347] [D loss: 0.491581] [G loss: 0.268513]\n",
      "[Epoch 31/100] [Batch 40/347] [D loss: 0.493684] [G loss: 0.267786]\n",
      "[Epoch 31/100] [Batch 41/347] [D loss: 0.493382] [G loss: 0.268501]\n",
      "[Epoch 31/100] [Batch 42/347] [D loss: 0.494176] [G loss: 0.261009]\n",
      "[Epoch 31/100] [Batch 43/347] [D loss: 0.496465] [G loss: 0.254385]\n",
      "[Epoch 31/100] [Batch 44/347] [D loss: 0.499450] [G loss: 0.271094]\n",
      "[Epoch 31/100] [Batch 45/347] [D loss: 0.502271] [G loss: 0.288666]\n",
      "[Epoch 31/100] [Batch 46/347] [D loss: 0.501510] [G loss: 0.283519]\n",
      "[Epoch 31/100] [Batch 47/347] [D loss: 0.496765] [G loss: 0.259667]\n",
      "[Epoch 31/100] [Batch 48/347] [D loss: 0.490060] [G loss: 0.278390]\n",
      "[Epoch 31/100] [Batch 49/347] [D loss: 0.488225] [G loss: 0.286824]\n",
      "[Epoch 31/100] [Batch 50/347] [D loss: 0.479065] [G loss: 0.301755]\n",
      "[Epoch 31/100] [Batch 51/347] [D loss: 0.478711] [G loss: 0.285216]\n",
      "[Epoch 31/100] [Batch 52/347] [D loss: 0.493373] [G loss: 0.269875]\n",
      "[Epoch 31/100] [Batch 53/347] [D loss: 0.495625] [G loss: 0.263774]\n",
      "[Epoch 31/100] [Batch 54/347] [D loss: 0.485710] [G loss: 0.299295]\n",
      "[Epoch 31/100] [Batch 55/347] [D loss: 0.481663] [G loss: 0.322116]\n",
      "[Epoch 31/100] [Batch 56/347] [D loss: 0.483613] [G loss: 0.309144]\n",
      "[Epoch 31/100] [Batch 57/347] [D loss: 0.489661] [G loss: 0.274654]\n",
      "[Epoch 31/100] [Batch 58/347] [D loss: 0.495791] [G loss: 0.267440]\n",
      "[Epoch 31/100] [Batch 59/347] [D loss: 0.491861] [G loss: 0.267724]\n",
      "[Epoch 31/100] [Batch 60/347] [D loss: 0.487708] [G loss: 0.278232]\n",
      "[Epoch 31/100] [Batch 61/347] [D loss: 0.485464] [G loss: 0.292011]\n",
      "[Epoch 31/100] [Batch 62/347] [D loss: 0.481861] [G loss: 0.316849]\n",
      "[Epoch 31/100] [Batch 63/347] [D loss: 0.481983] [G loss: 0.319096]\n",
      "[Epoch 31/100] [Batch 64/347] [D loss: 0.489092] [G loss: 0.281795]\n",
      "[Epoch 31/100] [Batch 65/347] [D loss: 0.498857] [G loss: 0.270943]\n",
      "[Epoch 31/100] [Batch 66/347] [D loss: 0.490568] [G loss: 0.272778]\n",
      "[Epoch 31/100] [Batch 67/347] [D loss: 0.473821] [G loss: 0.265110]\n",
      "[Epoch 31/100] [Batch 68/347] [D loss: 0.475011] [G loss: 0.282571]\n",
      "[Epoch 31/100] [Batch 69/347] [D loss: 0.484249] [G loss: 0.301192]\n",
      "[Epoch 31/100] [Batch 70/347] [D loss: 0.484315] [G loss: 0.299456]\n",
      "[Epoch 31/100] [Batch 71/347] [D loss: 0.483525] [G loss: 0.301132]\n",
      "[Epoch 31/100] [Batch 72/347] [D loss: 0.482817] [G loss: 0.303569]\n",
      "[Epoch 31/100] [Batch 73/347] [D loss: 0.487170] [G loss: 0.279097]\n",
      "[Epoch 31/100] [Batch 74/347] [D loss: 0.488839] [G loss: 0.266187]\n",
      "[Epoch 31/100] [Batch 75/347] [D loss: 0.484692] [G loss: 0.296401]\n",
      "[Epoch 31/100] [Batch 76/347] [D loss: 0.485172] [G loss: 0.299498]\n",
      "[Epoch 31/100] [Batch 77/347] [D loss: 0.491499] [G loss: 0.265860]\n",
      "[Epoch 31/100] [Batch 78/347] [D loss: 0.497648] [G loss: 0.275491]\n",
      "[Epoch 31/100] [Batch 79/347] [D loss: 0.501070] [G loss: 0.277533]\n",
      "[Epoch 31/100] [Batch 80/347] [D loss: 0.500739] [G loss: 0.275008]\n",
      "[Epoch 31/100] [Batch 81/347] [D loss: 0.501396] [G loss: 0.280193]\n",
      "[Epoch 31/100] [Batch 82/347] [D loss: 0.499327] [G loss: 0.285864]\n",
      "[Epoch 31/100] [Batch 83/347] [D loss: 0.498823] [G loss: 0.278395]\n",
      "[Epoch 31/100] [Batch 84/347] [D loss: 0.501491] [G loss: 0.284477]\n",
      "[Epoch 31/100] [Batch 85/347] [D loss: 0.501854] [G loss: 0.285377]\n",
      "[Epoch 31/100] [Batch 86/347] [D loss: 0.500937] [G loss: 0.279930]\n",
      "[Epoch 31/100] [Batch 87/347] [D loss: 0.500523] [G loss: 0.277816]\n",
      "[Epoch 31/100] [Batch 88/347] [D loss: 0.501058] [G loss: 0.281197]\n",
      "[Epoch 31/100] [Batch 89/347] [D loss: 0.501606] [G loss: 0.284581]\n",
      "[Epoch 31/100] [Batch 90/347] [D loss: 0.501023] [G loss: 0.280744]\n",
      "[Epoch 31/100] [Batch 91/347] [D loss: 0.500785] [G loss: 0.279226]\n",
      "[Epoch 31/100] [Batch 92/347] [D loss: 0.501011] [G loss: 0.280716]\n",
      "[Epoch 31/100] [Batch 93/347] [D loss: 0.500657] [G loss: 0.278775]\n",
      "[Epoch 31/100] [Batch 94/347] [D loss: 0.500077] [G loss: 0.275428]\n",
      "[Epoch 31/100] [Batch 95/347] [D loss: 0.500225] [G loss: 0.276298]\n",
      "[Epoch 31/100] [Batch 96/347] [D loss: 0.499507] [G loss: 0.271958]\n",
      "[Epoch 31/100] [Batch 97/347] [D loss: 0.498638] [G loss: 0.267377]\n",
      "[Epoch 31/100] [Batch 98/347] [D loss: 0.499480] [G loss: 0.272915]\n",
      "[Epoch 31/100] [Batch 99/347] [D loss: 0.500224] [G loss: 0.277392]\n",
      "[Epoch 31/100] [Batch 100/347] [D loss: 0.499594] [G loss: 0.274461]\n",
      "[Epoch 31/100] [Batch 101/347] [D loss: 0.498885] [G loss: 0.270076]\n",
      "[Epoch 31/100] [Batch 102/347] [D loss: 0.499290] [G loss: 0.272334]\n",
      "[Epoch 31/100] [Batch 103/347] [D loss: 0.499420] [G loss: 0.273653]\n",
      "[Epoch 31/100] [Batch 104/347] [D loss: 0.498030] [G loss: 0.265280]\n",
      "[Epoch 31/100] [Batch 105/347] [D loss: 0.497947] [G loss: 0.264859]\n",
      "[Epoch 31/100] [Batch 106/347] [D loss: 0.497707] [G loss: 0.264015]\n",
      "[Epoch 31/100] [Batch 107/347] [D loss: 0.493603] [G loss: 0.255934]\n",
      "[Epoch 31/100] [Batch 108/347] [D loss: 0.471027] [G loss: 0.268915]\n",
      "[Epoch 31/100] [Batch 109/347] [D loss: 0.471012] [G loss: 0.271061]\n",
      "[Epoch 31/100] [Batch 110/347] [D loss: 0.496535] [G loss: 0.257562]\n",
      "[Epoch 31/100] [Batch 111/347] [D loss: 0.476633] [G loss: 0.259753]\n",
      "[Epoch 31/100] [Batch 112/347] [D loss: 0.472594] [G loss: 0.262000]\n",
      "[Epoch 31/100] [Batch 113/347] [D loss: 0.492150] [G loss: 0.265140]\n",
      "[Epoch 31/100] [Batch 114/347] [D loss: 0.502465] [G loss: 0.284844]\n",
      "[Epoch 31/100] [Batch 115/347] [D loss: 0.502352] [G loss: 0.286072]\n",
      "[Epoch 31/100] [Batch 116/347] [D loss: 0.501406] [G loss: 0.280955]\n",
      "[Epoch 31/100] [Batch 117/347] [D loss: 0.496628] [G loss: 0.255290]\n",
      "[Epoch 31/100] [Batch 118/347] [D loss: 0.490453] [G loss: 0.262960]\n",
      "[Epoch 31/100] [Batch 119/347] [D loss: 0.489281] [G loss: 0.266943]\n",
      "[Epoch 31/100] [Batch 120/347] [D loss: 0.486175] [G loss: 0.267133]\n",
      "[Epoch 31/100] [Batch 121/347] [D loss: 0.486410] [G loss: 0.266399]\n",
      "[Epoch 31/100] [Batch 122/347] [D loss: 0.492946] [G loss: 0.254899]\n",
      "[Epoch 31/100] [Batch 123/347] [D loss: 0.495025] [G loss: 0.254567]\n",
      "[Epoch 31/100] [Batch 124/347] [D loss: 0.494312] [G loss: 0.255819]\n",
      "[Epoch 31/100] [Batch 125/347] [D loss: 0.496406] [G loss: 0.259403]\n",
      "[Epoch 31/100] [Batch 126/347] [D loss: 0.498200] [G loss: 0.271875]\n",
      "[Epoch 31/100] [Batch 127/347] [D loss: 0.498230] [G loss: 0.272986]\n",
      "[Epoch 31/100] [Batch 128/347] [D loss: 0.497270] [G loss: 0.267227]\n",
      "[Epoch 31/100] [Batch 129/347] [D loss: 0.495449] [G loss: 0.262031]\n",
      "[Epoch 31/100] [Batch 130/347] [D loss: 0.493128] [G loss: 0.264936]\n",
      "[Epoch 31/100] [Batch 131/347] [D loss: 0.475707] [G loss: 0.264679]\n",
      "[Epoch 31/100] [Batch 132/347] [D loss: 0.444678] [G loss: 0.288439]\n",
      "[Epoch 31/100] [Batch 133/347] [D loss: 0.449351] [G loss: 0.293927]\n",
      "[Epoch 31/100] [Batch 134/347] [D loss: 0.442130] [G loss: 0.307646]\n",
      "[Epoch 31/100] [Batch 135/347] [D loss: 0.421565] [G loss: 0.315812]\n",
      "[Epoch 31/100] [Batch 136/347] [D loss: 0.424376] [G loss: 0.273118]\n",
      "[Epoch 31/100] [Batch 137/347] [D loss: 0.487726] [G loss: 0.264302]\n",
      "[Epoch 31/100] [Batch 138/347] [D loss: 0.486333] [G loss: 0.277922]\n",
      "[Epoch 31/100] [Batch 139/347] [D loss: 0.480613] [G loss: 0.301994]\n",
      "[Epoch 31/100] [Batch 140/347] [D loss: 0.477956] [G loss: 0.313411]\n",
      "[Epoch 31/100] [Batch 141/347] [D loss: 0.477255] [G loss: 0.320285]\n",
      "[Epoch 31/100] [Batch 142/347] [D loss: 0.475967] [G loss: 0.327633]\n",
      "[Epoch 31/100] [Batch 143/347] [D loss: 0.470172] [G loss: 0.349045]\n",
      "[Epoch 31/100] [Batch 144/347] [D loss: 0.469942] [G loss: 0.351352]\n",
      "[Epoch 31/100] [Batch 145/347] [D loss: 0.473526] [G loss: 0.336965]\n",
      "[Epoch 31/100] [Batch 146/347] [D loss: 0.476912] [G loss: 0.320281]\n",
      "[Epoch 31/100] [Batch 147/347] [D loss: 0.483469] [G loss: 0.292270]\n",
      "[Epoch 31/100] [Batch 148/347] [D loss: 0.486134] [G loss: 0.279908]\n",
      "[Epoch 31/100] [Batch 149/347] [D loss: 0.483659] [G loss: 0.293542]\n",
      "[Epoch 31/100] [Batch 150/347] [D loss: 0.484190] [G loss: 0.294152]\n",
      "[Epoch 31/100] [Batch 151/347] [D loss: 0.486330] [G loss: 0.283202]\n",
      "[Epoch 31/100] [Batch 152/347] [D loss: 0.482638] [G loss: 0.294163]\n",
      "[Epoch 31/100] [Batch 153/347] [D loss: 0.477221] [G loss: 0.314656]\n",
      "[Epoch 31/100] [Batch 154/347] [D loss: 0.475919] [G loss: 0.318518]\n",
      "[Epoch 31/100] [Batch 155/347] [D loss: 0.479282] [G loss: 0.305429]\n",
      "[Epoch 31/100] [Batch 156/347] [D loss: 0.484120] [G loss: 0.288668]\n",
      "[Epoch 31/100] [Batch 157/347] [D loss: 0.481702] [G loss: 0.294827]\n",
      "[Epoch 31/100] [Batch 158/347] [D loss: 0.475480] [G loss: 0.318834]\n",
      "[Epoch 31/100] [Batch 159/347] [D loss: 0.475557] [G loss: 0.316902]\n",
      "[Epoch 31/100] [Batch 160/347] [D loss: 0.475729] [G loss: 0.297138]\n",
      "[Epoch 31/100] [Batch 161/347] [D loss: 0.476840] [G loss: 0.288753]\n",
      "[Epoch 31/100] [Batch 162/347] [D loss: 0.480019] [G loss: 0.294683]\n",
      "[Epoch 31/100] [Batch 163/347] [D loss: 0.476441] [G loss: 0.313557]\n",
      "[Epoch 31/100] [Batch 164/347] [D loss: 0.472073] [G loss: 0.329371]\n",
      "[Epoch 31/100] [Batch 165/347] [D loss: 0.473129] [G loss: 0.320970]\n",
      "[Epoch 31/100] [Batch 166/347] [D loss: 0.482548] [G loss: 0.282721]\n",
      "[Epoch 31/100] [Batch 167/347] [D loss: 0.485118] [G loss: 0.274810]\n",
      "[Epoch 31/100] [Batch 168/347] [D loss: 0.484893] [G loss: 0.285215]\n",
      "[Epoch 31/100] [Batch 169/347] [D loss: 0.494446] [G loss: 0.283777]\n",
      "[Epoch 31/100] [Batch 170/347] [D loss: 0.501219] [G loss: 0.279811]\n",
      "[Epoch 31/100] [Batch 171/347] [D loss: 0.504597] [G loss: 0.287446]\n",
      "[Epoch 31/100] [Batch 172/347] [D loss: 0.505971] [G loss: 0.292771]\n",
      "[Epoch 31/100] [Batch 173/347] [D loss: 0.502367] [G loss: 0.282271]\n",
      "[Epoch 31/100] [Batch 174/347] [D loss: 0.501587] [G loss: 0.280445]\n",
      "[Epoch 31/100] [Batch 175/347] [D loss: 0.504880] [G loss: 0.291222]\n",
      "[Epoch 31/100] [Batch 176/347] [D loss: 0.508216] [G loss: 0.305574]\n",
      "[Epoch 31/100] [Batch 177/347] [D loss: 0.508426] [G loss: 0.307552]\n",
      "[Epoch 31/100] [Batch 178/347] [D loss: 0.507011] [G loss: 0.302316]\n",
      "[Epoch 31/100] [Batch 179/347] [D loss: 0.505511] [G loss: 0.296190]\n",
      "[Epoch 31/100] [Batch 180/347] [D loss: 0.504236] [G loss: 0.290067]\n",
      "[Epoch 31/100] [Batch 181/347] [D loss: 0.504334] [G loss: 0.290783]\n",
      "[Epoch 31/100] [Batch 182/347] [D loss: 0.503778] [G loss: 0.288776]\n",
      "[Epoch 31/100] [Batch 183/347] [D loss: 0.504704] [G loss: 0.292818]\n",
      "[Epoch 31/100] [Batch 184/347] [D loss: 0.505632] [G loss: 0.296721]\n",
      "[Epoch 31/100] [Batch 185/347] [D loss: 0.505422] [G loss: 0.295015]\n",
      "[Epoch 31/100] [Batch 186/347] [D loss: 0.505593] [G loss: 0.294722]\n",
      "[Epoch 31/100] [Batch 187/347] [D loss: 0.504619] [G loss: 0.289392]\n",
      "[Epoch 31/100] [Batch 188/347] [D loss: 0.503861] [G loss: 0.286205]\n",
      "[Epoch 31/100] [Batch 189/347] [D loss: 0.503646] [G loss: 0.285613]\n",
      "[Epoch 31/100] [Batch 190/347] [D loss: 0.500937] [G loss: 0.274081]\n",
      "[Epoch 31/100] [Batch 191/347] [D loss: 0.497767] [G loss: 0.261743]\n",
      "[Epoch 31/100] [Batch 192/347] [D loss: 0.498327] [G loss: 0.265447]\n",
      "[Epoch 31/100] [Batch 193/347] [D loss: 0.500600] [G loss: 0.273120]\n",
      "[Epoch 31/100] [Batch 194/347] [D loss: 0.499964] [G loss: 0.269300]\n",
      "[Epoch 31/100] [Batch 195/347] [D loss: 0.498366] [G loss: 0.262437]\n",
      "[Epoch 31/100] [Batch 196/347] [D loss: 0.497229] [G loss: 0.258168]\n",
      "[Epoch 31/100] [Batch 197/347] [D loss: 0.496587] [G loss: 0.259251]\n",
      "[Epoch 31/100] [Batch 198/347] [D loss: 0.495264] [G loss: 0.264566]\n",
      "[Epoch 31/100] [Batch 199/347] [D loss: 0.494942] [G loss: 0.264390]\n",
      "[Epoch 31/100] [Batch 200/347] [D loss: 0.496912] [G loss: 0.263083]\n",
      "[Epoch 31/100] [Batch 201/347] [D loss: 0.497158] [G loss: 0.259422]\n",
      "[Epoch 31/100] [Batch 202/347] [D loss: 0.495934] [G loss: 0.254700]\n",
      "[Epoch 31/100] [Batch 203/347] [D loss: 0.494834] [G loss: 0.264846]\n",
      "[Epoch 31/100] [Batch 204/347] [D loss: 0.494986] [G loss: 0.262818]\n",
      "[Epoch 31/100] [Batch 205/347] [D loss: 0.495360] [G loss: 0.256283]\n",
      "[Epoch 31/100] [Batch 206/347] [D loss: 0.496463] [G loss: 0.255980]\n",
      "[Epoch 31/100] [Batch 207/347] [D loss: 0.498586] [G loss: 0.265936]\n",
      "[Epoch 31/100] [Batch 208/347] [D loss: 0.498417] [G loss: 0.265852]\n",
      "[Epoch 31/100] [Batch 209/347] [D loss: 0.496694] [G loss: 0.259335]\n",
      "[Epoch 31/100] [Batch 210/347] [D loss: 0.498010] [G loss: 0.266007]\n",
      "[Epoch 31/100] [Batch 211/347] [D loss: 0.497714] [G loss: 0.262636]\n",
      "[Epoch 31/100] [Batch 212/347] [D loss: 0.492730] [G loss: 0.260918]\n",
      "[Epoch 31/100] [Batch 213/347] [D loss: 0.485723] [G loss: 0.266153]\n",
      "[Epoch 31/100] [Batch 214/347] [D loss: 0.448535] [G loss: 0.275788]\n",
      "[Epoch 31/100] [Batch 215/347] [D loss: 0.448856] [G loss: 0.283508]\n",
      "[Epoch 31/100] [Batch 216/347] [D loss: 0.490312] [G loss: 0.262976]\n",
      "[Epoch 31/100] [Batch 217/347] [D loss: 0.495716] [G loss: 0.263198]\n",
      "[Epoch 31/100] [Batch 218/347] [D loss: 0.499779] [G loss: 0.270443]\n",
      "[Epoch 31/100] [Batch 219/347] [D loss: 0.502052] [G loss: 0.282829]\n",
      "[Epoch 31/100] [Batch 220/347] [D loss: 0.504957] [G loss: 0.298703]\n",
      "[Epoch 31/100] [Batch 221/347] [D loss: 0.505206] [G loss: 0.300210]\n",
      "[Epoch 31/100] [Batch 222/347] [D loss: 0.503245] [G loss: 0.292373]\n",
      "[Epoch 31/100] [Batch 223/347] [D loss: 0.502718] [G loss: 0.291328]\n",
      "[Epoch 31/100] [Batch 224/347] [D loss: 0.502051] [G loss: 0.287489]\n",
      "[Epoch 31/100] [Batch 225/347] [D loss: 0.495801] [G loss: 0.273821]\n",
      "[Epoch 31/100] [Batch 226/347] [D loss: 0.489016] [G loss: 0.271495]\n",
      "[Epoch 31/100] [Batch 227/347] [D loss: 0.486707] [G loss: 0.281117]\n",
      "[Epoch 31/100] [Batch 228/347] [D loss: 0.487595] [G loss: 0.282365]\n",
      "[Epoch 31/100] [Batch 229/347] [D loss: 0.490299] [G loss: 0.276595]\n",
      "[Epoch 31/100] [Batch 230/347] [D loss: 0.491551] [G loss: 0.272011]\n",
      "[Epoch 31/100] [Batch 231/347] [D loss: 0.490358] [G loss: 0.271789]\n",
      "[Epoch 31/100] [Batch 232/347] [D loss: 0.491115] [G loss: 0.267665]\n",
      "[Epoch 31/100] [Batch 233/347] [D loss: 0.490769] [G loss: 0.264968]\n",
      "[Epoch 31/100] [Batch 234/347] [D loss: 0.489402] [G loss: 0.270298]\n",
      "[Epoch 31/100] [Batch 235/347] [D loss: 0.491360] [G loss: 0.259422]\n",
      "[Epoch 31/100] [Batch 236/347] [D loss: 0.494981] [G loss: 0.266142]\n",
      "[Epoch 31/100] [Batch 237/347] [D loss: 0.498398] [G loss: 0.269920]\n",
      "[Epoch 31/100] [Batch 238/347] [D loss: 0.499706] [G loss: 0.274170]\n",
      "[Epoch 31/100] [Batch 239/347] [D loss: 0.498949] [G loss: 0.272257]\n",
      "[Epoch 31/100] [Batch 240/347] [D loss: 0.497941] [G loss: 0.268510]\n",
      "[Epoch 31/100] [Batch 241/347] [D loss: 0.496708] [G loss: 0.262807]\n",
      "[Epoch 31/100] [Batch 242/347] [D loss: 0.496452] [G loss: 0.260912]\n",
      "[Epoch 31/100] [Batch 243/347] [D loss: 0.498361] [G loss: 0.268561]\n",
      "[Epoch 31/100] [Batch 244/347] [D loss: 0.500406] [G loss: 0.277252]\n",
      "[Epoch 31/100] [Batch 245/347] [D loss: 0.499747] [G loss: 0.275522]\n",
      "[Epoch 31/100] [Batch 246/347] [D loss: 0.494360] [G loss: 0.268483]\n",
      "[Epoch 31/100] [Batch 247/347] [D loss: 0.490830] [G loss: 0.264651]\n",
      "[Epoch 31/100] [Batch 248/347] [D loss: 0.489675] [G loss: 0.268729]\n",
      "[Epoch 31/100] [Batch 249/347] [D loss: 0.488350] [G loss: 0.274029]\n",
      "[Epoch 31/100] [Batch 250/347] [D loss: 0.490666] [G loss: 0.264455]\n",
      "[Epoch 31/100] [Batch 251/347] [D loss: 0.495351] [G loss: 0.269405]\n",
      "[Epoch 31/100] [Batch 252/347] [D loss: 0.497089] [G loss: 0.273117]\n",
      "[Epoch 31/100] [Batch 253/347] [D loss: 0.497632] [G loss: 0.274257]\n",
      "[Epoch 31/100] [Batch 254/347] [D loss: 0.498616] [G loss: 0.273324]\n",
      "[Epoch 31/100] [Batch 255/347] [D loss: 0.494533] [G loss: 0.272602]\n",
      "[Epoch 31/100] [Batch 256/347] [D loss: 0.495296] [G loss: 0.278553]\n",
      "[Epoch 31/100] [Batch 257/347] [D loss: 0.499788] [G loss: 0.281295]\n",
      "[Epoch 31/100] [Batch 258/347] [D loss: 0.495464] [G loss: 0.276787]\n",
      "[Epoch 31/100] [Batch 259/347] [D loss: 0.488086] [G loss: 0.263882]\n",
      "[Epoch 31/100] [Batch 260/347] [D loss: 0.482106] [G loss: 0.277883]\n",
      "[Epoch 31/100] [Batch 261/347] [D loss: 0.483928] [G loss: 0.269619]\n",
      "[Epoch 31/100] [Batch 262/347] [D loss: 0.491430] [G loss: 0.263581]\n",
      "[Epoch 31/100] [Batch 263/347] [D loss: 0.489957] [G loss: 0.261521]\n",
      "[Epoch 31/100] [Batch 264/347] [D loss: 0.483403] [G loss: 0.268622]\n",
      "[Epoch 31/100] [Batch 265/347] [D loss: 0.482251] [G loss: 0.274054]\n",
      "[Epoch 31/100] [Batch 266/347] [D loss: 0.485205] [G loss: 0.267065]\n",
      "[Epoch 31/100] [Batch 267/347] [D loss: 0.487564] [G loss: 0.260503]\n",
      "[Epoch 31/100] [Batch 268/347] [D loss: 0.482601] [G loss: 0.267666]\n",
      "[Epoch 31/100] [Batch 269/347] [D loss: 0.479010] [G loss: 0.279159]\n",
      "[Epoch 31/100] [Batch 270/347] [D loss: 0.483038] [G loss: 0.276234]\n",
      "[Epoch 31/100] [Batch 271/347] [D loss: 0.487860] [G loss: 0.264918]\n",
      "[Epoch 31/100] [Batch 272/347] [D loss: 0.490759] [G loss: 0.262609]\n",
      "[Epoch 31/100] [Batch 273/347] [D loss: 0.473046] [G loss: 0.271765]\n",
      "[Epoch 31/100] [Batch 274/347] [D loss: 0.329626] [G loss: 0.308747]\n",
      "[Epoch 31/100] [Batch 275/347] [D loss: 0.328117] [G loss: 0.312808]\n",
      "[Epoch 31/100] [Batch 276/347] [D loss: 0.480635] [G loss: 0.285763]\n",
      "[Epoch 31/100] [Batch 277/347] [D loss: 0.490014] [G loss: 0.282903]\n",
      "[Epoch 31/100] [Batch 278/347] [D loss: 0.496073] [G loss: 0.281901]\n",
      "[Epoch 31/100] [Batch 279/347] [D loss: 0.493803] [G loss: 0.288234]\n",
      "[Epoch 31/100] [Batch 280/347] [D loss: 0.491301] [G loss: 0.289486]\n",
      "[Epoch 31/100] [Batch 281/347] [D loss: 0.491572] [G loss: 0.284362]\n",
      "[Epoch 31/100] [Batch 282/347] [D loss: 0.492336] [G loss: 0.277940]\n",
      "[Epoch 31/100] [Batch 283/347] [D loss: 0.487565] [G loss: 0.273195]\n",
      "[Epoch 31/100] [Batch 284/347] [D loss: 0.486993] [G loss: 0.270010]\n",
      "[Epoch 31/100] [Batch 285/347] [D loss: 0.492008] [G loss: 0.260475]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 31/100] [Batch 286/347] [D loss: 0.493215] [G loss: 0.248497]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 31/100] [Batch 287/347] [D loss: 0.492457] [G loss: 0.243935]\n",
      "[Epoch 31/100] [Batch 288/347] [D loss: 0.484972] [G loss: 0.265850]\n",
      "[Epoch 31/100] [Batch 289/347] [D loss: 0.483943] [G loss: 0.268957]\n",
      "[Epoch 31/100] [Batch 290/347] [D loss: 0.490518] [G loss: 0.245695]\n",
      "[Epoch 31/100] [Batch 291/347] [D loss: 0.488664] [G loss: 0.249006]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 31/100] [Batch 292/347] [D loss: 0.490404] [G loss: 0.242009]\n",
      "[Epoch 31/100] [Batch 293/347] [D loss: 0.494884] [G loss: 0.260792]\n",
      "[Epoch 31/100] [Batch 294/347] [D loss: 0.494496] [G loss: 0.272650]\n",
      "[Epoch 31/100] [Batch 295/347] [D loss: 0.459900] [G loss: 0.272119]\n",
      "[Epoch 31/100] [Batch 296/347] [D loss: 0.458933] [G loss: 0.269924]\n",
      "[Epoch 31/100] [Batch 297/347] [D loss: 0.494609] [G loss: 0.284574]\n",
      "[Epoch 31/100] [Batch 298/347] [D loss: 0.500794] [G loss: 0.281276]\n",
      "[Epoch 31/100] [Batch 299/347] [D loss: 0.499581] [G loss: 0.281798]\n",
      "[Epoch 31/100] [Batch 300/347] [D loss: 0.496517] [G loss: 0.278864]\n",
      "[Epoch 31/100] [Batch 301/347] [D loss: 0.495368] [G loss: 0.280090]\n",
      "[Epoch 31/100] [Batch 302/347] [D loss: 0.497395] [G loss: 0.286076]\n",
      "[Epoch 31/100] [Batch 303/347] [D loss: 0.491337] [G loss: 0.270838]\n",
      "[Epoch 31/100] [Batch 304/347] [D loss: 0.488616] [G loss: 0.266597]\n",
      "[Epoch 31/100] [Batch 305/347] [D loss: 0.489091] [G loss: 0.278260]\n",
      "[Epoch 31/100] [Batch 306/347] [D loss: 0.475241] [G loss: 0.267827]\n",
      "[Epoch 31/100] [Batch 307/347] [D loss: 0.460587] [G loss: 0.278683]\n",
      "[Epoch 31/100] [Batch 308/347] [D loss: 0.469955] [G loss: 0.273166]\n",
      "[Epoch 31/100] [Batch 309/347] [D loss: 0.492836] [G loss: 0.256967]\n",
      "[Epoch 31/100] [Batch 310/347] [D loss: 0.500371] [G loss: 0.283384]\n",
      "[Epoch 31/100] [Batch 311/347] [D loss: 0.500899] [G loss: 0.285440]\n",
      "[Epoch 31/100] [Batch 312/347] [D loss: 0.500654] [G loss: 0.284627]\n",
      "[Epoch 31/100] [Batch 313/347] [D loss: 0.500363] [G loss: 0.283527]\n",
      "[Epoch 31/100] [Batch 314/347] [D loss: 0.497970] [G loss: 0.277071]\n",
      "[Epoch 31/100] [Batch 315/347] [D loss: 0.494164] [G loss: 0.268023]\n",
      "[Epoch 31/100] [Batch 316/347] [D loss: 0.490786] [G loss: 0.251991]\n",
      "[Epoch 31/100] [Batch 317/347] [D loss: 0.488763] [G loss: 0.268936]\n",
      "[Epoch 31/100] [Batch 318/347] [D loss: 0.493830] [G loss: 0.258507]\n",
      "[Epoch 31/100] [Batch 319/347] [D loss: 0.502305] [G loss: 0.291728]\n",
      "[Epoch 31/100] [Batch 320/347] [D loss: 0.505676] [G loss: 0.305391]\n",
      "[Epoch 31/100] [Batch 321/347] [D loss: 0.502715] [G loss: 0.294947]\n",
      "[Epoch 31/100] [Batch 322/347] [D loss: 0.499156] [G loss: 0.281484]\n",
      "[Epoch 31/100] [Batch 323/347] [D loss: 0.498339] [G loss: 0.280224]\n",
      "[Epoch 31/100] [Batch 324/347] [D loss: 0.498917] [G loss: 0.283108]\n",
      "[Epoch 31/100] [Batch 325/347] [D loss: 0.492482] [G loss: 0.272194]\n",
      "[Epoch 31/100] [Batch 326/347] [D loss: 0.488227] [G loss: 0.262620]\n",
      "[Epoch 31/100] [Batch 327/347] [D loss: 0.490647] [G loss: 0.260709]\n",
      "[Epoch 31/100] [Batch 328/347] [D loss: 0.492600] [G loss: 0.257607]\n",
      "[Epoch 31/100] [Batch 329/347] [D loss: 0.483050] [G loss: 0.263570]\n",
      "[Epoch 31/100] [Batch 330/347] [D loss: 0.478285] [G loss: 0.278474]\n",
      "[Epoch 31/100] [Batch 331/347] [D loss: 0.485738] [G loss: 0.259687]\n",
      "[Epoch 31/100] [Batch 332/347] [D loss: 0.497699] [G loss: 0.272504]\n",
      "[Epoch 31/100] [Batch 333/347] [D loss: 0.501008] [G loss: 0.284350]\n",
      "[Epoch 31/100] [Batch 334/347] [D loss: 0.501095] [G loss: 0.286278]\n",
      "[Epoch 31/100] [Batch 335/347] [D loss: 0.497225] [G loss: 0.274807]\n",
      "[Epoch 31/100] [Batch 336/347] [D loss: 0.493101] [G loss: 0.262773]\n",
      "[Epoch 31/100] [Batch 337/347] [D loss: 0.494952] [G loss: 0.267427]\n",
      "[Epoch 31/100] [Batch 338/347] [D loss: 0.499499] [G loss: 0.282869]\n",
      "[Epoch 31/100] [Batch 339/347] [D loss: 0.501543] [G loss: 0.289027]\n",
      "[Epoch 31/100] [Batch 340/347] [D loss: 0.501927] [G loss: 0.290127]\n",
      "[Epoch 31/100] [Batch 341/347] [D loss: 0.500138] [G loss: 0.285829]\n",
      "[Epoch 31/100] [Batch 342/347] [D loss: 0.497971] [G loss: 0.278496]\n",
      "[Epoch 31/100] [Batch 343/347] [D loss: 0.499784] [G loss: 0.283377]\n",
      "[Epoch 31/100] [Batch 344/347] [D loss: 0.495114] [G loss: 0.271441]\n",
      "[Epoch 31/100] [Batch 345/347] [D loss: 0.484862] [G loss: 0.261363]\n",
      "[Epoch 31/100] [Batch 346/347] [D loss: 0.466062] [G loss: 0.279056]\n",
      "[Epoch 31/100] [Batch 347/347] [D loss: 0.420137] [G loss: 0.284948]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 32/100] [Batch 1/347] [D loss: 0.494705] [G loss: 0.263477]\n",
      "[Epoch 32/100] [Batch 2/347] [D loss: 0.495141] [G loss: 0.265143]\n",
      "[Epoch 32/100] [Batch 3/347] [D loss: 0.497848] [G loss: 0.274865]\n",
      "[Epoch 32/100] [Batch 4/347] [D loss: 0.497823] [G loss: 0.275328]\n",
      "[Epoch 32/100] [Batch 5/347] [D loss: 0.497354] [G loss: 0.273782]\n",
      "[Epoch 32/100] [Batch 6/347] [D loss: 0.497748] [G loss: 0.274998]\n",
      "[Epoch 32/100] [Batch 7/347] [D loss: 0.496293] [G loss: 0.269483]\n",
      "[Epoch 32/100] [Batch 8/347] [D loss: 0.494697] [G loss: 0.263964]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 32/100] [Batch 9/347] [D loss: 0.491163] [G loss: 0.257076]\n",
      "[Epoch 32/100] [Batch 10/347] [D loss: 0.491221] [G loss: 0.259826]\n",
      "[Epoch 32/100] [Batch 11/347] [D loss: 0.495213] [G loss: 0.264539]\n",
      "[Epoch 32/100] [Batch 12/347] [D loss: 0.496215] [G loss: 0.267953]\n",
      "[Epoch 32/100] [Batch 13/347] [D loss: 0.497227] [G loss: 0.270846]\n",
      "[Epoch 32/100] [Batch 14/347] [D loss: 0.497692] [G loss: 0.271978]\n",
      "[Epoch 32/100] [Batch 15/347] [D loss: 0.496203] [G loss: 0.267029]\n",
      "[Epoch 32/100] [Batch 16/347] [D loss: 0.494754] [G loss: 0.262069]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 32/100] [Batch 17/347] [D loss: 0.491135] [G loss: 0.252516]\n",
      "[Epoch 32/100] [Batch 18/347] [D loss: 0.488463] [G loss: 0.258074]\n",
      "[Epoch 32/100] [Batch 19/347] [D loss: 0.492080] [G loss: 0.254174]\n",
      "[Epoch 32/100] [Batch 20/347] [D loss: 0.496658] [G loss: 0.267220]\n",
      "[Epoch 32/100] [Batch 21/347] [D loss: 0.495805] [G loss: 0.263388]\n",
      "[Epoch 32/100] [Batch 22/347] [D loss: 0.494235] [G loss: 0.258530]\n",
      "[Epoch 32/100] [Batch 23/347] [D loss: 0.491913] [G loss: 0.256295]\n",
      "[Epoch 32/100] [Batch 24/347] [D loss: 0.491810] [G loss: 0.252585]\n",
      "[Epoch 32/100] [Batch 25/347] [D loss: 0.492522] [G loss: 0.253818]\n",
      "[Epoch 32/100] [Batch 26/347] [D loss: 0.484304] [G loss: 0.261469]\n",
      "[Epoch 32/100] [Batch 27/347] [D loss: 0.464725] [G loss: 0.266538]\n",
      "[Epoch 32/100] [Batch 28/347] [D loss: 0.468215] [G loss: 0.269520]\n",
      "[Epoch 32/100] [Batch 29/347] [D loss: 0.496379] [G loss: 0.268139]\n",
      "[Epoch 32/100] [Batch 30/347] [D loss: 0.496643] [G loss: 0.276053]\n",
      "[Epoch 32/100] [Batch 31/347] [D loss: 0.494089] [G loss: 0.279350]\n",
      "[Epoch 32/100] [Batch 32/347] [D loss: 0.486024] [G loss: 0.273747]\n",
      "[Epoch 32/100] [Batch 33/347] [D loss: 0.487587] [G loss: 0.269350]\n",
      "[Epoch 32/100] [Batch 34/347] [D loss: 0.494989] [G loss: 0.270964]\n",
      "[Epoch 32/100] [Batch 35/347] [D loss: 0.495038] [G loss: 0.270185]\n",
      "[Epoch 32/100] [Batch 36/347] [D loss: 0.494455] [G loss: 0.262266]\n",
      "[Epoch 32/100] [Batch 37/347] [D loss: 0.484982] [G loss: 0.264087]\n",
      "[Epoch 32/100] [Batch 38/347] [D loss: 0.479591] [G loss: 0.278333]\n",
      "[Epoch 32/100] [Batch 39/347] [D loss: 0.484448] [G loss: 0.267616]\n",
      "[Epoch 32/100] [Batch 40/347] [D loss: 0.489425] [G loss: 0.265669]\n",
      "[Epoch 32/100] [Batch 41/347] [D loss: 0.489017] [G loss: 0.266214]\n",
      "[Epoch 32/100] [Batch 42/347] [D loss: 0.490344] [G loss: 0.258666]\n",
      "[Epoch 32/100] [Batch 43/347] [D loss: 0.493952] [G loss: 0.259084]\n",
      "[Epoch 32/100] [Batch 44/347] [D loss: 0.499070] [G loss: 0.275197]\n",
      "[Epoch 32/100] [Batch 45/347] [D loss: 0.504431] [G loss: 0.292950]\n",
      "[Epoch 32/100] [Batch 46/347] [D loss: 0.503229] [G loss: 0.287920]\n",
      "[Epoch 32/100] [Batch 47/347] [D loss: 0.494764] [G loss: 0.265068]\n",
      "[Epoch 32/100] [Batch 48/347] [D loss: 0.481382] [G loss: 0.276038]\n",
      "[Epoch 32/100] [Batch 49/347] [D loss: 0.478290] [G loss: 0.284250]\n",
      "[Epoch 32/100] [Batch 50/347] [D loss: 0.457351] [G loss: 0.299415]\n",
      "[Epoch 32/100] [Batch 51/347] [D loss: 0.454484] [G loss: 0.283319]\n",
      "[Epoch 32/100] [Batch 52/347] [D loss: 0.484297] [G loss: 0.277785]\n",
      "[Epoch 32/100] [Batch 53/347] [D loss: 0.492403] [G loss: 0.272068]\n",
      "[Epoch 32/100] [Batch 54/347] [D loss: 0.474397] [G loss: 0.297605]\n",
      "[Epoch 32/100] [Batch 55/347] [D loss: 0.467816] [G loss: 0.320402]\n",
      "[Epoch 32/100] [Batch 56/347] [D loss: 0.471174] [G loss: 0.307259]\n",
      "[Epoch 32/100] [Batch 57/347] [D loss: 0.481193] [G loss: 0.272430]\n",
      "[Epoch 32/100] [Batch 58/347] [D loss: 0.492107] [G loss: 0.276525]\n",
      "[Epoch 32/100] [Batch 59/347] [D loss: 0.483814] [G loss: 0.276774]\n",
      "[Epoch 32/100] [Batch 60/347] [D loss: 0.476152] [G loss: 0.274746]\n",
      "[Epoch 32/100] [Batch 61/347] [D loss: 0.472309] [G loss: 0.288474]\n",
      "[Epoch 32/100] [Batch 62/347] [D loss: 0.467175] [G loss: 0.313665]\n",
      "[Epoch 32/100] [Batch 63/347] [D loss: 0.468718] [G loss: 0.316254]\n",
      "[Epoch 32/100] [Batch 64/347] [D loss: 0.481505] [G loss: 0.279015]\n",
      "[Epoch 32/100] [Batch 65/347] [D loss: 0.499488] [G loss: 0.282681]\n",
      "[Epoch 32/100] [Batch 66/347] [D loss: 0.480569] [G loss: 0.284630]\n",
      "[Epoch 32/100] [Batch 67/347] [D loss: 0.439535] [G loss: 0.277251]\n",
      "[Epoch 32/100] [Batch 68/347] [D loss: 0.445195] [G loss: 0.279919]\n",
      "[Epoch 32/100] [Batch 69/347] [D loss: 0.473352] [G loss: 0.298944]\n",
      "[Epoch 32/100] [Batch 70/347] [D loss: 0.473781] [G loss: 0.297300]\n",
      "[Epoch 32/100] [Batch 71/347] [D loss: 0.471883] [G loss: 0.298831]\n",
      "[Epoch 32/100] [Batch 72/347] [D loss: 0.470513] [G loss: 0.300985]\n",
      "[Epoch 32/100] [Batch 73/347] [D loss: 0.477137] [G loss: 0.275973]\n",
      "[Epoch 32/100] [Batch 74/347] [D loss: 0.478554] [G loss: 0.278312]\n",
      "[Epoch 32/100] [Batch 75/347] [D loss: 0.472856] [G loss: 0.292282]\n",
      "[Epoch 32/100] [Batch 76/347] [D loss: 0.474864] [G loss: 0.294893]\n",
      "[Epoch 32/100] [Batch 77/347] [D loss: 0.485438] [G loss: 0.266266]\n",
      "[Epoch 32/100] [Batch 78/347] [D loss: 0.495439] [G loss: 0.285888]\n",
      "[Epoch 32/100] [Batch 79/347] [D loss: 0.503339] [G loss: 0.287099]\n",
      "[Epoch 32/100] [Batch 80/347] [D loss: 0.503406] [G loss: 0.283641]\n",
      "[Epoch 32/100] [Batch 81/347] [D loss: 0.504149] [G loss: 0.288017]\n",
      "[Epoch 32/100] [Batch 82/347] [D loss: 0.498731] [G loss: 0.292980]\n",
      "[Epoch 32/100] [Batch 83/347] [D loss: 0.497745] [G loss: 0.284649]\n",
      "[Epoch 32/100] [Batch 84/347] [D loss: 0.504317] [G loss: 0.290401]\n",
      "[Epoch 32/100] [Batch 85/347] [D loss: 0.505677] [G loss: 0.291445]\n",
      "[Epoch 32/100] [Batch 86/347] [D loss: 0.503884] [G loss: 0.286604]\n",
      "[Epoch 32/100] [Batch 87/347] [D loss: 0.502970] [G loss: 0.286038]\n",
      "[Epoch 32/100] [Batch 88/347] [D loss: 0.504061] [G loss: 0.291103]\n",
      "[Epoch 32/100] [Batch 89/347] [D loss: 0.505448] [G loss: 0.295501]\n",
      "[Epoch 32/100] [Batch 90/347] [D loss: 0.504629] [G loss: 0.291843]\n",
      "[Epoch 32/100] [Batch 91/347] [D loss: 0.504319] [G loss: 0.290032]\n",
      "[Epoch 32/100] [Batch 92/347] [D loss: 0.504894] [G loss: 0.291157]\n",
      "[Epoch 32/100] [Batch 93/347] [D loss: 0.504269] [G loss: 0.288766]\n",
      "[Epoch 32/100] [Batch 94/347] [D loss: 0.503207] [G loss: 0.285112]\n",
      "[Epoch 32/100] [Batch 95/347] [D loss: 0.503474] [G loss: 0.285672]\n",
      "[Epoch 32/100] [Batch 96/347] [D loss: 0.502178] [G loss: 0.281253]\n",
      "[Epoch 32/100] [Batch 97/347] [D loss: 0.500667] [G loss: 0.276577]\n",
      "[Epoch 32/100] [Batch 98/347] [D loss: 0.502377] [G loss: 0.282261]\n",
      "[Epoch 32/100] [Batch 99/347] [D loss: 0.503756] [G loss: 0.286905]\n",
      "[Epoch 32/100] [Batch 100/347] [D loss: 0.502536] [G loss: 0.284266]\n",
      "[Epoch 32/100] [Batch 101/347] [D loss: 0.501317] [G loss: 0.280242]\n",
      "[Epoch 32/100] [Batch 102/347] [D loss: 0.502263] [G loss: 0.282821]\n",
      "[Epoch 32/100] [Batch 103/347] [D loss: 0.502544] [G loss: 0.284583]\n",
      "[Epoch 32/100] [Batch 104/347] [D loss: 0.500075] [G loss: 0.276594]\n",
      "[Epoch 32/100] [Batch 105/347] [D loss: 0.499983] [G loss: 0.276462]\n",
      "[Epoch 32/100] [Batch 106/347] [D loss: 0.499537] [G loss: 0.275907]\n",
      "[Epoch 32/100] [Batch 107/347] [D loss: 0.489565] [G loss: 0.269376]\n",
      "[Epoch 32/100] [Batch 108/347] [D loss: 0.433231] [G loss: 0.283686]\n",
      "[Epoch 32/100] [Batch 109/347] [D loss: 0.432991] [G loss: 0.288042]\n",
      "[Epoch 32/100] [Batch 110/347] [D loss: 0.495422] [G loss: 0.276181]\n",
      "[Epoch 32/100] [Batch 111/347] [D loss: 0.446409] [G loss: 0.280442]\n",
      "[Epoch 32/100] [Batch 112/347] [D loss: 0.435550] [G loss: 0.284795]\n",
      "[Epoch 32/100] [Batch 113/347] [D loss: 0.483302] [G loss: 0.287986]\n",
      "[Epoch 32/100] [Batch 114/347] [D loss: 0.507602] [G loss: 0.308036]\n",
      "[Epoch 32/100] [Batch 115/347] [D loss: 0.507222] [G loss: 0.308548]\n",
      "[Epoch 32/100] [Batch 116/347] [D loss: 0.505745] [G loss: 0.301908]\n",
      "[Epoch 32/100] [Batch 117/347] [D loss: 0.497255] [G loss: 0.275384]\n",
      "[Epoch 32/100] [Batch 118/347] [D loss: 0.485156] [G loss: 0.263753]\n",
      "[Epoch 32/100] [Batch 119/347] [D loss: 0.482272] [G loss: 0.255973]\n",
      "[Epoch 32/100] [Batch 120/347] [D loss: 0.472548] [G loss: 0.259281]\n",
      "[Epoch 32/100] [Batch 121/347] [D loss: 0.472194] [G loss: 0.258247]\n",
      "[Epoch 32/100] [Batch 122/347] [D loss: 0.488827] [G loss: 0.257335]\n",
      "[Epoch 32/100] [Batch 123/347] [D loss: 0.494322] [G loss: 0.260170]\n",
      "[Epoch 32/100] [Batch 124/347] [D loss: 0.492593] [G loss: 0.256176]\n",
      "[Epoch 32/100] [Batch 125/347] [D loss: 0.495886] [G loss: 0.267378]\n",
      "[Epoch 32/100] [Batch 126/347] [D loss: 0.498238] [G loss: 0.279811]\n",
      "[Epoch 32/100] [Batch 127/347] [D loss: 0.497668] [G loss: 0.280557]\n",
      "[Epoch 32/100] [Batch 128/347] [D loss: 0.495786] [G loss: 0.274446]\n",
      "[Epoch 32/100] [Batch 129/347] [D loss: 0.490312] [G loss: 0.268797]\n",
      "[Epoch 32/100] [Batch 130/347] [D loss: 0.484916] [G loss: 0.269812]\n",
      "[Epoch 32/100] [Batch 131/347] [D loss: 0.448714] [G loss: 0.268135]\n",
      "[Epoch 32/100] [Batch 132/347] [D loss: 0.382516] [G loss: 0.291156]\n",
      "[Epoch 32/100] [Batch 133/347] [D loss: 0.392887] [G loss: 0.302615]\n",
      "[Epoch 32/100] [Batch 134/347] [D loss: 0.380311] [G loss: 0.323225]\n",
      "[Epoch 32/100] [Batch 135/347] [D loss: 0.349780] [G loss: 0.339278]\n",
      "[Epoch 32/100] [Batch 136/347] [D loss: 0.350214] [G loss: 0.305506]\n",
      "[Epoch 32/100] [Batch 137/347] [D loss: 0.475678] [G loss: 0.300645]\n",
      "[Epoch 32/100] [Batch 138/347] [D loss: 0.475300] [G loss: 0.315431]\n",
      "[Epoch 32/100] [Batch 139/347] [D loss: 0.464545] [G loss: 0.337492]\n",
      "[Epoch 32/100] [Batch 140/347] [D loss: 0.458740] [G loss: 0.344455]\n",
      "[Epoch 32/100] [Batch 141/347] [D loss: 0.457029] [G loss: 0.344962]\n",
      "[Epoch 32/100] [Batch 142/347] [D loss: 0.454165] [G loss: 0.344885]\n",
      "[Epoch 32/100] [Batch 143/347] [D loss: 0.443031] [G loss: 0.358663]\n",
      "[Epoch 32/100] [Batch 144/347] [D loss: 0.442453] [G loss: 0.354133]\n",
      "[Epoch 32/100] [Batch 145/347] [D loss: 0.448947] [G loss: 0.334253]\n",
      "[Epoch 32/100] [Batch 146/347] [D loss: 0.455219] [G loss: 0.313676]\n",
      "[Epoch 32/100] [Batch 147/347] [D loss: 0.466829] [G loss: 0.283358]\n",
      "[Epoch 32/100] [Batch 148/347] [D loss: 0.471477] [G loss: 0.270401]\n",
      "[Epoch 32/100] [Batch 149/347] [D loss: 0.467549] [G loss: 0.284961]\n",
      "[Epoch 32/100] [Batch 150/347] [D loss: 0.468592] [G loss: 0.287962]\n",
      "[Epoch 32/100] [Batch 151/347] [D loss: 0.471537] [G loss: 0.280256]\n",
      "[Epoch 32/100] [Batch 152/347] [D loss: 0.463481] [G loss: 0.295348]\n",
      "[Epoch 32/100] [Batch 153/347] [D loss: 0.453011] [G loss: 0.320448]\n",
      "[Epoch 32/100] [Batch 154/347] [D loss: 0.450804] [G loss: 0.328503]\n",
      "[Epoch 32/100] [Batch 155/347] [D loss: 0.457447] [G loss: 0.319179]\n",
      "[Epoch 32/100] [Batch 156/347] [D loss: 0.467115] [G loss: 0.304892]\n",
      "[Epoch 32/100] [Batch 157/347] [D loss: 0.462088] [G loss: 0.312242]\n",
      "[Epoch 32/100] [Batch 158/347] [D loss: 0.450684] [G loss: 0.336095]\n",
      "[Epoch 32/100] [Batch 159/347] [D loss: 0.450814] [G loss: 0.332736]\n",
      "[Epoch 32/100] [Batch 160/347] [D loss: 0.446780] [G loss: 0.310752]\n",
      "[Epoch 32/100] [Batch 161/347] [D loss: 0.448034] [G loss: 0.299360]\n",
      "[Epoch 32/100] [Batch 162/347] [D loss: 0.458311] [G loss: 0.301917]\n",
      "[Epoch 32/100] [Batch 163/347] [D loss: 0.453349] [G loss: 0.317564]\n",
      "[Epoch 32/100] [Batch 164/347] [D loss: 0.445645] [G loss: 0.330775]\n",
      "[Epoch 32/100] [Batch 165/347] [D loss: 0.446690] [G loss: 0.320582]\n",
      "[Epoch 32/100] [Batch 166/347] [D loss: 0.462651] [G loss: 0.281057]\n",
      "[Epoch 32/100] [Batch 167/347] [D loss: 0.460419] [G loss: 0.272910]\n",
      "[Epoch 32/100] [Batch 168/347] [D loss: 0.456153] [G loss: 0.284077]\n",
      "[Epoch 32/100] [Batch 169/347] [D loss: 0.483017] [G loss: 0.283558]\n",
      "[Epoch 32/100] [Batch 170/347] [D loss: 0.500564] [G loss: 0.281671]\n",
      "[Epoch 32/100] [Batch 171/347] [D loss: 0.507865] [G loss: 0.294685]\n",
      "[Epoch 32/100] [Batch 172/347] [D loss: 0.510690] [G loss: 0.301209]\n",
      "[Epoch 32/100] [Batch 173/347] [D loss: 0.502879] [G loss: 0.291436]\n",
      "[Epoch 32/100] [Batch 174/347] [D loss: 0.501646] [G loss: 0.289856]\n",
      "[Epoch 32/100] [Batch 175/347] [D loss: 0.509779] [G loss: 0.300396]\n",
      "[Epoch 32/100] [Batch 176/347] [D loss: 0.516644] [G loss: 0.314148]\n",
      "[Epoch 32/100] [Batch 177/347] [D loss: 0.517344] [G loss: 0.315333]\n",
      "[Epoch 32/100] [Batch 178/347] [D loss: 0.514778] [G loss: 0.309499]\n",
      "[Epoch 32/100] [Batch 179/347] [D loss: 0.511986] [G loss: 0.302797]\n",
      "[Epoch 32/100] [Batch 180/347] [D loss: 0.509654] [G loss: 0.296211]\n",
      "[Epoch 32/100] [Batch 181/347] [D loss: 0.510029] [G loss: 0.296830]\n",
      "[Epoch 32/100] [Batch 182/347] [D loss: 0.509269] [G loss: 0.294830]\n",
      "[Epoch 32/100] [Batch 183/347] [D loss: 0.511164] [G loss: 0.299193]\n",
      "[Epoch 32/100] [Batch 184/347] [D loss: 0.513125] [G loss: 0.303757]\n",
      "[Epoch 32/100] [Batch 185/347] [D loss: 0.512924] [G loss: 0.302796]\n",
      "[Epoch 32/100] [Batch 186/347] [D loss: 0.513289] [G loss: 0.303381]\n",
      "[Epoch 32/100] [Batch 187/347] [D loss: 0.511481] [G loss: 0.298950]\n",
      "[Epoch 32/100] [Batch 188/347] [D loss: 0.510236] [G loss: 0.296449]\n",
      "[Epoch 32/100] [Batch 189/347] [D loss: 0.509917] [G loss: 0.296560]\n",
      "[Epoch 32/100] [Batch 190/347] [D loss: 0.504959] [G loss: 0.285469]\n",
      "[Epoch 32/100] [Batch 191/347] [D loss: 0.498894] [G loss: 0.273636]\n",
      "[Epoch 32/100] [Batch 192/347] [D loss: 0.499524] [G loss: 0.276125]\n",
      "[Epoch 32/100] [Batch 193/347] [D loss: 0.504046] [G loss: 0.285376]\n",
      "[Epoch 32/100] [Batch 194/347] [D loss: 0.503779] [G loss: 0.281504]\n",
      "[Epoch 32/100] [Batch 195/347] [D loss: 0.501195] [G loss: 0.274431]\n",
      "[Epoch 32/100] [Batch 196/347] [D loss: 0.499017] [G loss: 0.269966]\n",
      "[Epoch 32/100] [Batch 197/347] [D loss: 0.497331] [G loss: 0.268836]\n",
      "[Epoch 32/100] [Batch 198/347] [D loss: 0.493335] [G loss: 0.274018]\n",
      "[Epoch 32/100] [Batch 199/347] [D loss: 0.492970] [G loss: 0.273948]\n",
      "[Epoch 32/100] [Batch 200/347] [D loss: 0.498332] [G loss: 0.272914]\n",
      "[Epoch 32/100] [Batch 201/347] [D loss: 0.499157] [G loss: 0.271014]\n",
      "[Epoch 32/100] [Batch 202/347] [D loss: 0.497571] [G loss: 0.266593]\n",
      "[Epoch 32/100] [Batch 203/347] [D loss: 0.496096] [G loss: 0.263101]\n",
      "[Epoch 32/100] [Batch 204/347] [D loss: 0.496356] [G loss: 0.263640]\n",
      "[Epoch 32/100] [Batch 205/347] [D loss: 0.496767] [G loss: 0.264579]\n",
      "[Epoch 32/100] [Batch 206/347] [D loss: 0.498285] [G loss: 0.268871]\n",
      "[Epoch 32/100] [Batch 207/347] [D loss: 0.501642] [G loss: 0.278764]\n",
      "[Epoch 32/100] [Batch 208/347] [D loss: 0.501407] [G loss: 0.278460]\n",
      "[Epoch 32/100] [Batch 209/347] [D loss: 0.497948] [G loss: 0.271682]\n",
      "[Epoch 32/100] [Batch 210/347] [D loss: 0.499819] [G loss: 0.277270]\n",
      "[Epoch 32/100] [Batch 211/347] [D loss: 0.499470] [G loss: 0.274424]\n",
      "[Epoch 32/100] [Batch 212/347] [D loss: 0.485110] [G loss: 0.271633]\n",
      "[Epoch 32/100] [Batch 213/347] [D loss: 0.470085] [G loss: 0.277157]\n",
      "[Epoch 32/100] [Batch 214/347] [D loss: 0.390618] [G loss: 0.285026]\n",
      "[Epoch 32/100] [Batch 215/347] [D loss: 0.391816] [G loss: 0.288016]\n",
      "[Epoch 32/100] [Batch 216/347] [D loss: 0.482839] [G loss: 0.284731]\n",
      "[Epoch 32/100] [Batch 217/347] [D loss: 0.494554] [G loss: 0.286825]\n",
      "[Epoch 32/100] [Batch 218/347] [D loss: 0.503220] [G loss: 0.295026]\n",
      "[Epoch 32/100] [Batch 219/347] [D loss: 0.506648] [G loss: 0.306494]\n",
      "[Epoch 32/100] [Batch 220/347] [D loss: 0.511543] [G loss: 0.320651]\n",
      "[Epoch 32/100] [Batch 221/347] [D loss: 0.511937] [G loss: 0.319609]\n",
      "[Epoch 32/100] [Batch 222/347] [D loss: 0.507638] [G loss: 0.308614]\n",
      "[Epoch 32/100] [Batch 223/347] [D loss: 0.506450] [G loss: 0.304120]\n",
      "[Epoch 32/100] [Batch 224/347] [D loss: 0.505361] [G loss: 0.296795]\n",
      "[Epoch 32/100] [Batch 225/347] [D loss: 0.493673] [G loss: 0.279780]\n",
      "[Epoch 32/100] [Batch 226/347] [D loss: 0.482253] [G loss: 0.260749]\n",
      "[Epoch 32/100] [Batch 227/347] [D loss: 0.479227] [G loss: 0.268574]\n",
      "[Epoch 32/100] [Batch 228/347] [D loss: 0.481101] [G loss: 0.269158]\n",
      "[Epoch 32/100] [Batch 229/347] [D loss: 0.486159] [G loss: 0.263228]\n",
      "[Epoch 32/100] [Batch 230/347] [D loss: 0.488496] [G loss: 0.259050]\n",
      "[Epoch 32/100] [Batch 231/347] [D loss: 0.486315] [G loss: 0.259601]\n",
      "[Epoch 32/100] [Batch 232/347] [D loss: 0.487644] [G loss: 0.256730]\n",
      "[Epoch 32/100] [Batch 233/347] [D loss: 0.486552] [G loss: 0.255390]\n",
      "[Epoch 32/100] [Batch 234/347] [D loss: 0.483463] [G loss: 0.262336]\n",
      "[Epoch 32/100] [Batch 235/347] [D loss: 0.486390] [G loss: 0.269671]\n",
      "[Epoch 32/100] [Batch 236/347] [D loss: 0.492916] [G loss: 0.277735]\n",
      "[Epoch 32/100] [Batch 237/347] [D loss: 0.499744] [G loss: 0.282685]\n",
      "[Epoch 32/100] [Batch 238/347] [D loss: 0.503070] [G loss: 0.287719]\n",
      "[Epoch 32/100] [Batch 239/347] [D loss: 0.501601] [G loss: 0.286227]\n",
      "[Epoch 32/100] [Batch 240/347] [D loss: 0.499704] [G loss: 0.282562]\n",
      "[Epoch 32/100] [Batch 241/347] [D loss: 0.497582] [G loss: 0.276669]\n",
      "[Epoch 32/100] [Batch 242/347] [D loss: 0.497418] [G loss: 0.274320]\n",
      "[Epoch 32/100] [Batch 243/347] [D loss: 0.501263] [G loss: 0.281533]\n",
      "[Epoch 32/100] [Batch 244/347] [D loss: 0.505057] [G loss: 0.289804]\n",
      "[Epoch 32/100] [Batch 245/347] [D loss: 0.502705] [G loss: 0.288106]\n",
      "[Epoch 32/100] [Batch 246/347] [D loss: 0.493083] [G loss: 0.280860]\n",
      "[Epoch 32/100] [Batch 247/347] [D loss: 0.488119] [G loss: 0.254600]\n",
      "[Epoch 32/100] [Batch 248/347] [D loss: 0.486717] [G loss: 0.257788]\n",
      "[Epoch 32/100] [Batch 249/347] [D loss: 0.484400] [G loss: 0.262936]\n",
      "[Epoch 32/100] [Batch 250/347] [D loss: 0.487833] [G loss: 0.263887]\n",
      "[Epoch 32/100] [Batch 251/347] [D loss: 0.495065] [G loss: 0.281664]\n",
      "[Epoch 32/100] [Batch 252/347] [D loss: 0.497791] [G loss: 0.285445]\n",
      "[Epoch 32/100] [Batch 253/347] [D loss: 0.499277] [G loss: 0.286593]\n",
      "[Epoch 32/100] [Batch 254/347] [D loss: 0.501420] [G loss: 0.285735]\n",
      "[Epoch 32/100] [Batch 255/347] [D loss: 0.492800] [G loss: 0.285198]\n",
      "[Epoch 32/100] [Batch 256/347] [D loss: 0.493744] [G loss: 0.291443]\n",
      "[Epoch 32/100] [Batch 257/347] [D loss: 0.502574] [G loss: 0.294112]\n",
      "[Epoch 32/100] [Batch 258/347] [D loss: 0.493752] [G loss: 0.289690]\n",
      "[Epoch 32/100] [Batch 259/347] [D loss: 0.479989] [G loss: 0.276962]\n",
      "[Epoch 32/100] [Batch 260/347] [D loss: 0.467360] [G loss: 0.275053]\n",
      "[Epoch 32/100] [Batch 261/347] [D loss: 0.470523] [G loss: 0.282867]\n",
      "[Epoch 32/100] [Batch 262/347] [D loss: 0.487224] [G loss: 0.278117]\n",
      "[Epoch 32/100] [Batch 263/347] [D loss: 0.483013] [G loss: 0.276116]\n",
      "[Epoch 32/100] [Batch 264/347] [D loss: 0.469308] [G loss: 0.278038]\n",
      "[Epoch 32/100] [Batch 265/347] [D loss: 0.467670] [G loss: 0.275162]\n",
      "[Epoch 32/100] [Batch 266/347] [D loss: 0.473365] [G loss: 0.271433]\n",
      "[Epoch 32/100] [Batch 267/347] [D loss: 0.477776] [G loss: 0.269022]\n",
      "[Epoch 32/100] [Batch 268/347] [D loss: 0.465320] [G loss: 0.273335]\n",
      "[Epoch 32/100] [Batch 269/347] [D loss: 0.458439] [G loss: 0.274622]\n",
      "[Epoch 32/100] [Batch 270/347] [D loss: 0.467730] [G loss: 0.272599]\n",
      "[Epoch 32/100] [Batch 271/347] [D loss: 0.477464] [G loss: 0.267846]\n",
      "[Epoch 32/100] [Batch 272/347] [D loss: 0.482864] [G loss: 0.269358]\n",
      "[Epoch 32/100] [Batch 273/347] [D loss: 0.453587] [G loss: 0.277708]\n",
      "[Epoch 32/100] [Batch 274/347] [D loss: 0.265729] [G loss: 0.315279]\n",
      "[Epoch 32/100] [Batch 275/347] [D loss: 0.256603] [G loss: 0.329355]\n",
      "[Epoch 32/100] [Batch 276/347] [D loss: 0.462468] [G loss: 0.310147]\n",
      "[Epoch 32/100] [Batch 277/347] [D loss: 0.480239] [G loss: 0.313331]\n",
      "[Epoch 32/100] [Batch 278/347] [D loss: 0.495519] [G loss: 0.320075]\n",
      "[Epoch 32/100] [Batch 279/347] [D loss: 0.491388] [G loss: 0.323614]\n",
      "[Epoch 32/100] [Batch 280/347] [D loss: 0.486445] [G loss: 0.325523]\n",
      "[Epoch 32/100] [Batch 281/347] [D loss: 0.486878] [G loss: 0.319810]\n",
      "[Epoch 32/100] [Batch 282/347] [D loss: 0.488514] [G loss: 0.311642]\n",
      "[Epoch 32/100] [Batch 283/347] [D loss: 0.476095] [G loss: 0.303659]\n",
      "[Epoch 32/100] [Batch 284/347] [D loss: 0.472476] [G loss: 0.295993]\n",
      "[Epoch 32/100] [Batch 285/347] [D loss: 0.483199] [G loss: 0.281083]\n",
      "[Epoch 32/100] [Batch 286/347] [D loss: 0.486164] [G loss: 0.267394]\n",
      "[Epoch 32/100] [Batch 287/347] [D loss: 0.484128] [G loss: 0.256188]\n",
      "[Epoch 32/100] [Batch 288/347] [D loss: 0.470812] [G loss: 0.272739]\n",
      "[Epoch 32/100] [Batch 289/347] [D loss: 0.469519] [G loss: 0.269937]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 32/100] [Batch 290/347] [D loss: 0.481479] [G loss: 0.241337]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 32/100] [Batch 291/347] [D loss: 0.478347] [G loss: 0.239863]\n",
      "[Epoch 32/100] [Batch 292/347] [D loss: 0.481623] [G loss: 0.230197]\n",
      "[Epoch 32/100] [Batch 293/347] [D loss: 0.487186] [G loss: 0.246325]\n",
      "[Epoch 32/100] [Batch 294/347] [D loss: 0.485331] [G loss: 0.253396]\n",
      "[Epoch 32/100] [Batch 295/347] [D loss: 0.413345] [G loss: 0.254220]\n",
      "[Epoch 32/100] [Batch 296/347] [D loss: 0.408242] [G loss: 0.255922]\n",
      "[Epoch 32/100] [Batch 297/347] [D loss: 0.486571] [G loss: 0.278603]\n",
      "[Epoch 32/100] [Batch 298/347] [D loss: 0.501976] [G loss: 0.279652]\n",
      "[Epoch 32/100] [Batch 299/347] [D loss: 0.498762] [G loss: 0.284466]\n",
      "[Epoch 32/100] [Batch 300/347] [D loss: 0.491710] [G loss: 0.285790]\n",
      "[Epoch 32/100] [Batch 301/347] [D loss: 0.489831] [G loss: 0.288327]\n",
      "[Epoch 32/100] [Batch 302/347] [D loss: 0.494329] [G loss: 0.298145]\n",
      "[Epoch 32/100] [Batch 303/347] [D loss: 0.484732] [G loss: 0.286045]\n",
      "[Epoch 32/100] [Batch 304/347] [D loss: 0.481706] [G loss: 0.280379]\n",
      "[Epoch 32/100] [Batch 305/347] [D loss: 0.483458] [G loss: 0.292754]\n",
      "[Epoch 32/100] [Batch 306/347] [D loss: 0.449839] [G loss: 0.282572]\n",
      "[Epoch 32/100] [Batch 307/347] [D loss: 0.412870] [G loss: 0.291543]\n",
      "[Epoch 32/100] [Batch 308/347] [D loss: 0.434027] [G loss: 0.285760]\n",
      "[Epoch 32/100] [Batch 309/347] [D loss: 0.489539] [G loss: 0.279977]\n",
      "[Epoch 32/100] [Batch 310/347] [D loss: 0.503635] [G loss: 0.305290]\n",
      "[Epoch 32/100] [Batch 311/347] [D loss: 0.504627] [G loss: 0.305792]\n",
      "[Epoch 32/100] [Batch 312/347] [D loss: 0.504248] [G loss: 0.302989]\n",
      "[Epoch 32/100] [Batch 313/347] [D loss: 0.503547] [G loss: 0.299582]\n",
      "[Epoch 32/100] [Batch 314/347] [D loss: 0.497735] [G loss: 0.290860]\n",
      "[Epoch 32/100] [Batch 315/347] [D loss: 0.488900] [G loss: 0.279476]\n",
      "[Epoch 32/100] [Batch 316/347] [D loss: 0.484595] [G loss: 0.261491]\n",
      "[Epoch 32/100] [Batch 317/347] [D loss: 0.483523] [G loss: 0.262048]\n",
      "[Epoch 32/100] [Batch 318/347] [D loss: 0.492162] [G loss: 0.265726]\n",
      "[Epoch 32/100] [Batch 319/347] [D loss: 0.506644] [G loss: 0.298534]\n",
      "[Epoch 32/100] [Batch 320/347] [D loss: 0.513128] [G loss: 0.312049]\n",
      "[Epoch 32/100] [Batch 321/347] [D loss: 0.507609] [G loss: 0.301535]\n",
      "[Epoch 32/100] [Batch 322/347] [D loss: 0.501526] [G loss: 0.288185]\n",
      "[Epoch 32/100] [Batch 323/347] [D loss: 0.499472] [G loss: 0.287317]\n",
      "[Epoch 32/100] [Batch 324/347] [D loss: 0.500212] [G loss: 0.290685]\n",
      "[Epoch 32/100] [Batch 325/347] [D loss: 0.484304] [G loss: 0.280500]\n",
      "[Epoch 32/100] [Batch 326/347] [D loss: 0.476343] [G loss: 0.272397]\n",
      "[Epoch 32/100] [Batch 327/347] [D loss: 0.484339] [G loss: 0.271671]\n",
      "[Epoch 32/100] [Batch 328/347] [D loss: 0.490528] [G loss: 0.269620]\n",
      "[Epoch 32/100] [Batch 329/347] [D loss: 0.471264] [G loss: 0.263215]\n",
      "[Epoch 32/100] [Batch 330/347] [D loss: 0.463455] [G loss: 0.269647]\n",
      "[Epoch 32/100] [Batch 331/347] [D loss: 0.478086] [G loss: 0.267182]\n",
      "[Epoch 32/100] [Batch 332/347] [D loss: 0.500828] [G loss: 0.287530]\n",
      "[Epoch 32/100] [Batch 333/347] [D loss: 0.506997] [G loss: 0.299677]\n",
      "[Epoch 32/100] [Batch 334/347] [D loss: 0.506282] [G loss: 0.301461]\n",
      "[Epoch 32/100] [Batch 335/347] [D loss: 0.498511] [G loss: 0.289626]\n",
      "[Epoch 32/100] [Batch 336/347] [D loss: 0.491226] [G loss: 0.277406]\n",
      "[Epoch 32/100] [Batch 337/347] [D loss: 0.494513] [G loss: 0.281355]\n",
      "[Epoch 32/100] [Batch 338/347] [D loss: 0.503025] [G loss: 0.296343]\n",
      "[Epoch 32/100] [Batch 339/347] [D loss: 0.507572] [G loss: 0.301893]\n",
      "[Epoch 32/100] [Batch 340/347] [D loss: 0.508497] [G loss: 0.302516]\n",
      "[Epoch 32/100] [Batch 341/347] [D loss: 0.504467] [G loss: 0.297873]\n",
      "[Epoch 32/100] [Batch 342/347] [D loss: 0.500504] [G loss: 0.290260]\n",
      "[Epoch 32/100] [Batch 343/347] [D loss: 0.504743] [G loss: 0.295165]\n",
      "[Epoch 32/100] [Batch 344/347] [D loss: 0.494572] [G loss: 0.283233]\n",
      "[Epoch 32/100] [Batch 345/347] [D loss: 0.475549] [G loss: 0.259857]\n",
      "[Epoch 32/100] [Batch 346/347] [D loss: 0.440434] [G loss: 0.268405]\n",
      "[Epoch 32/100] [Batch 347/347] [D loss: 0.352112] [G loss: 0.277242]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 33/100] [Batch 1/347] [D loss: 0.495908] [G loss: 0.281392]\n",
      "[Epoch 33/100] [Batch 2/347] [D loss: 0.497021] [G loss: 0.284943]\n",
      "[Epoch 33/100] [Batch 3/347] [D loss: 0.502268] [G loss: 0.295973]\n",
      "[Epoch 33/100] [Batch 4/347] [D loss: 0.502383] [G loss: 0.297246]\n",
      "[Epoch 33/100] [Batch 5/347] [D loss: 0.501641] [G loss: 0.295811]\n",
      "[Epoch 33/100] [Batch 6/347] [D loss: 0.502599] [G loss: 0.296687]\n",
      "[Epoch 33/100] [Batch 7/347] [D loss: 0.500129] [G loss: 0.290566]\n",
      "[Epoch 33/100] [Batch 8/347] [D loss: 0.496981] [G loss: 0.284206]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 33/100] [Batch 9/347] [D loss: 0.490543] [G loss: 0.271429]\n",
      "[Epoch 33/100] [Batch 10/347] [D loss: 0.490782] [G loss: 0.269477]\n",
      "[Epoch 33/100] [Batch 11/347] [D loss: 0.497988] [G loss: 0.280887]\n",
      "[Epoch 33/100] [Batch 12/347] [D loss: 0.499811] [G loss: 0.282866]\n",
      "[Epoch 33/100] [Batch 13/347] [D loss: 0.501403] [G loss: 0.284155]\n",
      "[Epoch 33/100] [Batch 14/347] [D loss: 0.501981] [G loss: 0.283920]\n",
      "[Epoch 33/100] [Batch 15/347] [D loss: 0.499118] [G loss: 0.277908]\n",
      "[Epoch 33/100] [Batch 16/347] [D loss: 0.496303] [G loss: 0.271947]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 33/100] [Batch 17/347] [D loss: 0.489674] [G loss: 0.258741]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 33/100] [Batch 18/347] [D loss: 0.484266] [G loss: 0.257048]\n",
      "[Epoch 33/100] [Batch 19/347] [D loss: 0.490097] [G loss: 0.262451]\n",
      "[Epoch 33/100] [Batch 20/347] [D loss: 0.499244] [G loss: 0.275122]\n",
      "[Epoch 33/100] [Batch 21/347] [D loss: 0.497899] [G loss: 0.271334]\n",
      "[Epoch 33/100] [Batch 22/347] [D loss: 0.494881] [G loss: 0.266495]\n",
      "[Epoch 33/100] [Batch 23/347] [D loss: 0.489705] [G loss: 0.260488]\n",
      "[Epoch 33/100] [Batch 24/347] [D loss: 0.488935] [G loss: 0.260233]\n",
      "[Epoch 33/100] [Batch 25/347] [D loss: 0.490468] [G loss: 0.260181]\n",
      "[Epoch 33/100] [Batch 26/347] [D loss: 0.472391] [G loss: 0.257131]\n",
      "[Epoch 33/100] [Batch 27/347] [D loss: 0.422760] [G loss: 0.267662]\n",
      "[Epoch 33/100] [Batch 28/347] [D loss: 0.427629] [G loss: 0.278391]\n",
      "[Epoch 33/100] [Batch 29/347] [D loss: 0.493532] [G loss: 0.277322]\n",
      "[Epoch 33/100] [Batch 30/347] [D loss: 0.491139] [G loss: 0.285406]\n",
      "[Epoch 33/100] [Batch 31/347] [D loss: 0.482564] [G loss: 0.288726]\n",
      "[Epoch 33/100] [Batch 32/347] [D loss: 0.460978] [G loss: 0.282783]\n",
      "[Epoch 33/100] [Batch 33/347] [D loss: 0.465658] [G loss: 0.278537]\n",
      "[Epoch 33/100] [Batch 34/347] [D loss: 0.486492] [G loss: 0.279667]\n",
      "[Epoch 33/100] [Batch 35/347] [D loss: 0.486266] [G loss: 0.278193]\n",
      "[Epoch 33/100] [Batch 36/347] [D loss: 0.487725] [G loss: 0.268849]\n",
      "[Epoch 33/100] [Batch 37/347] [D loss: 0.469815] [G loss: 0.271250]\n",
      "[Epoch 33/100] [Batch 38/347] [D loss: 0.459469] [G loss: 0.284698]\n",
      "[Epoch 33/100] [Batch 39/347] [D loss: 0.469385] [G loss: 0.273374]\n",
      "[Epoch 33/100] [Batch 40/347] [D loss: 0.480968] [G loss: 0.271087]\n",
      "[Epoch 33/100] [Batch 41/347] [D loss: 0.480421] [G loss: 0.270663]\n",
      "[Epoch 33/100] [Batch 42/347] [D loss: 0.482226] [G loss: 0.261895]\n",
      "[Epoch 33/100] [Batch 43/347] [D loss: 0.487228] [G loss: 0.258105]\n",
      "[Epoch 33/100] [Batch 44/347] [D loss: 0.495349] [G loss: 0.273948]\n",
      "[Epoch 33/100] [Batch 45/347] [D loss: 0.505287] [G loss: 0.291080]\n",
      "[Epoch 33/100] [Batch 46/347] [D loss: 0.503490] [G loss: 0.285696]\n",
      "[Epoch 33/100] [Batch 47/347] [D loss: 0.488807] [G loss: 0.262559]\n",
      "[Epoch 33/100] [Batch 48/347] [D loss: 0.461930] [G loss: 0.275952]\n",
      "[Epoch 33/100] [Batch 49/347] [D loss: 0.457274] [G loss: 0.285186]\n",
      "[Epoch 33/100] [Batch 50/347] [D loss: 0.414481] [G loss: 0.302427]\n",
      "[Epoch 33/100] [Batch 51/347] [D loss: 0.406224] [G loss: 0.289187]\n",
      "[Epoch 33/100] [Batch 52/347] [D loss: 0.461110] [G loss: 0.286702]\n",
      "[Epoch 33/100] [Batch 53/347] [D loss: 0.483978] [G loss: 0.283680]\n",
      "[Epoch 33/100] [Batch 54/347] [D loss: 0.452841] [G loss: 0.310706]\n",
      "[Epoch 33/100] [Batch 55/347] [D loss: 0.443026] [G loss: 0.334933]\n",
      "[Epoch 33/100] [Batch 56/347] [D loss: 0.448308] [G loss: 0.322600]\n",
      "[Epoch 33/100] [Batch 57/347] [D loss: 0.464015] [G loss: 0.288146]\n",
      "[Epoch 33/100] [Batch 58/347] [D loss: 0.482619] [G loss: 0.294841]\n",
      "[Epoch 33/100] [Batch 59/347] [D loss: 0.466802] [G loss: 0.293940]\n",
      "[Epoch 33/100] [Batch 60/347] [D loss: 0.454190] [G loss: 0.289555]\n",
      "[Epoch 33/100] [Batch 61/347] [D loss: 0.447571] [G loss: 0.296664]\n",
      "[Epoch 33/100] [Batch 62/347] [D loss: 0.441326] [G loss: 0.318505]\n",
      "[Epoch 33/100] [Batch 63/347] [D loss: 0.445892] [G loss: 0.318038]\n",
      "[Epoch 33/100] [Batch 64/347] [D loss: 0.466772] [G loss: 0.277987]\n",
      "[Epoch 33/100] [Batch 65/347] [D loss: 0.498298] [G loss: 0.283930]\n",
      "[Epoch 33/100] [Batch 66/347] [D loss: 0.460029] [G loss: 0.285183]\n",
      "[Epoch 33/100] [Batch 67/347] [D loss: 0.374789] [G loss: 0.280211]\n",
      "[Epoch 33/100] [Batch 68/347] [D loss: 0.388447] [G loss: 0.281623]\n",
      "[Epoch 33/100] [Batch 69/347] [D loss: 0.452867] [G loss: 0.304484]\n",
      "[Epoch 33/100] [Batch 70/347] [D loss: 0.453967] [G loss: 0.305790]\n",
      "[Epoch 33/100] [Batch 71/347] [D loss: 0.449830] [G loss: 0.309409]\n",
      "[Epoch 33/100] [Batch 72/347] [D loss: 0.447639] [G loss: 0.312709]\n",
      "[Epoch 33/100] [Batch 73/347] [D loss: 0.457216] [G loss: 0.287768]\n",
      "[Epoch 33/100] [Batch 74/347] [D loss: 0.458010] [G loss: 0.298094]\n",
      "[Epoch 33/100] [Batch 75/347] [D loss: 0.452161] [G loss: 0.301969]\n",
      "[Epoch 33/100] [Batch 76/347] [D loss: 0.457816] [G loss: 0.302520]\n",
      "[Epoch 33/100] [Batch 77/347] [D loss: 0.474595] [G loss: 0.281444]\n",
      "[Epoch 33/100] [Batch 78/347] [D loss: 0.489982] [G loss: 0.298607]\n",
      "[Epoch 33/100] [Batch 79/347] [D loss: 0.507317] [G loss: 0.297245]\n",
      "[Epoch 33/100] [Batch 80/347] [D loss: 0.508937] [G loss: 0.292063]\n",
      "[Epoch 33/100] [Batch 81/347] [D loss: 0.509699] [G loss: 0.294503]\n",
      "[Epoch 33/100] [Batch 82/347] [D loss: 0.497884] [G loss: 0.297541]\n",
      "[Epoch 33/100] [Batch 83/347] [D loss: 0.496243] [G loss: 0.288692]\n",
      "[Epoch 33/100] [Batch 84/347] [D loss: 0.510807] [G loss: 0.294283]\n",
      "[Epoch 33/100] [Batch 85/347] [D loss: 0.514961] [G loss: 0.295310]\n",
      "[Epoch 33/100] [Batch 86/347] [D loss: 0.512317] [G loss: 0.290455]\n",
      "[Epoch 33/100] [Batch 87/347] [D loss: 0.511447] [G loss: 0.289582]\n",
      "[Epoch 33/100] [Batch 88/347] [D loss: 0.513816] [G loss: 0.294703]\n",
      "[Epoch 33/100] [Batch 89/347] [D loss: 0.516221] [G loss: 0.299987]\n",
      "[Epoch 33/100] [Batch 90/347] [D loss: 0.514400] [G loss: 0.298323]\n",
      "[Epoch 33/100] [Batch 91/347] [D loss: 0.513825] [G loss: 0.299122]\n",
      "[Epoch 33/100] [Batch 92/347] [D loss: 0.515141] [G loss: 0.302822]\n",
      "[Epoch 33/100] [Batch 93/347] [D loss: 0.514337] [G loss: 0.302667]\n",
      "[Epoch 33/100] [Batch 94/347] [D loss: 0.512330] [G loss: 0.300907]\n",
      "[Epoch 33/100] [Batch 95/347] [D loss: 0.512999] [G loss: 0.302982]\n",
      "[Epoch 33/100] [Batch 96/347] [D loss: 0.510840] [G loss: 0.299561]\n",
      "[Epoch 33/100] [Batch 97/347] [D loss: 0.508364] [G loss: 0.295388]\n",
      "[Epoch 33/100] [Batch 98/347] [D loss: 0.511813] [G loss: 0.301060]\n",
      "[Epoch 33/100] [Batch 99/347] [D loss: 0.514444] [G loss: 0.305374]\n",
      "[Epoch 33/100] [Batch 100/347] [D loss: 0.511988] [G loss: 0.301969]\n",
      "[Epoch 33/100] [Batch 101/347] [D loss: 0.510085] [G loss: 0.297157]\n",
      "[Epoch 33/100] [Batch 102/347] [D loss: 0.512411] [G loss: 0.298692]\n",
      "[Epoch 33/100] [Batch 103/347] [D loss: 0.512982] [G loss: 0.299570]\n",
      "[Epoch 33/100] [Batch 104/347] [D loss: 0.508741] [G loss: 0.290799]\n",
      "[Epoch 33/100] [Batch 105/347] [D loss: 0.508942] [G loss: 0.290306]\n",
      "[Epoch 33/100] [Batch 106/347] [D loss: 0.508010] [G loss: 0.289577]\n",
      "[Epoch 33/100] [Batch 107/347] [D loss: 0.486677] [G loss: 0.285661]\n",
      "[Epoch 33/100] [Batch 108/347] [D loss: 0.371460] [G loss: 0.303402]\n",
      "[Epoch 33/100] [Batch 109/347] [D loss: 0.371190] [G loss: 0.313779]\n",
      "[Epoch 33/100] [Batch 110/347] [D loss: 0.495572] [G loss: 0.306748]\n",
      "[Epoch 33/100] [Batch 111/347] [D loss: 0.396442] [G loss: 0.316369]\n",
      "[Epoch 33/100] [Batch 112/347] [D loss: 0.372463] [G loss: 0.326329]\n",
      "[Epoch 33/100] [Batch 113/347] [D loss: 0.473150] [G loss: 0.331515]\n",
      "[Epoch 33/100] [Batch 114/347] [D loss: 0.521727] [G loss: 0.354992]\n",
      "[Epoch 33/100] [Batch 115/347] [D loss: 0.520803] [G loss: 0.357689]\n",
      "[Epoch 33/100] [Batch 116/347] [D loss: 0.519421] [G loss: 0.352201]\n",
      "[Epoch 33/100] [Batch 117/347] [D loss: 0.506135] [G loss: 0.328381]\n",
      "[Epoch 33/100] [Batch 118/347] [D loss: 0.483598] [G loss: 0.314327]\n",
      "[Epoch 33/100] [Batch 119/347] [D loss: 0.476222] [G loss: 0.302334]\n",
      "[Epoch 33/100] [Batch 120/347] [D loss: 0.450610] [G loss: 0.300123]\n",
      "[Epoch 33/100] [Batch 121/347] [D loss: 0.448658] [G loss: 0.292645]\n",
      "[Epoch 33/100] [Batch 122/347] [D loss: 0.488269] [G loss: 0.284660]\n",
      "[Epoch 33/100] [Batch 123/347] [D loss: 0.503337] [G loss: 0.278300]\n",
      "[Epoch 33/100] [Batch 124/347] [D loss: 0.500769] [G loss: 0.270482]\n",
      "[Epoch 33/100] [Batch 125/347] [D loss: 0.506474] [G loss: 0.273449]\n",
      "[Epoch 33/100] [Batch 126/347] [D loss: 0.509441] [G loss: 0.282421]\n",
      "[Epoch 33/100] [Batch 127/347] [D loss: 0.508047] [G loss: 0.281719]\n",
      "[Epoch 33/100] [Batch 128/347] [D loss: 0.505152] [G loss: 0.275766]\n",
      "[Epoch 33/100] [Batch 129/347] [D loss: 0.491692] [G loss: 0.273665]\n",
      "[Epoch 33/100] [Batch 130/347] [D loss: 0.481236] [G loss: 0.279440]\n",
      "[Epoch 33/100] [Batch 131/347] [D loss: 0.424185] [G loss: 0.283062]\n",
      "[Epoch 33/100] [Batch 132/347] [D loss: 0.320888] [G loss: 0.294523]\n",
      "[Epoch 33/100] [Batch 133/347] [D loss: 0.334128] [G loss: 0.304691]\n",
      "[Epoch 33/100] [Batch 134/347] [D loss: 0.312723] [G loss: 0.319564]\n",
      "[Epoch 33/100] [Batch 135/347] [D loss: 0.277453] [G loss: 0.343125]\n",
      "[Epoch 33/100] [Batch 136/347] [D loss: 0.272616] [G loss: 0.364254]\n",
      "[Epoch 33/100] [Batch 137/347] [D loss: 0.476137] [G loss: 0.367053]\n",
      "[Epoch 33/100] [Batch 138/347] [D loss: 0.481827] [G loss: 0.364910]\n",
      "[Epoch 33/100] [Batch 139/347] [D loss: 0.468961] [G loss: 0.372796]\n",
      "[Epoch 33/100] [Batch 140/347] [D loss: 0.461999] [G loss: 0.384056]\n",
      "[Epoch 33/100] [Batch 141/347] [D loss: 0.460272] [G loss: 0.386529]\n",
      "[Epoch 33/100] [Batch 142/347] [D loss: 0.454292] [G loss: 0.385766]\n",
      "[Epoch 33/100] [Batch 143/347] [D loss: 0.431598] [G loss: 0.395518]\n",
      "[Epoch 33/100] [Batch 144/347] [D loss: 0.425474] [G loss: 0.383797]\n",
      "[Epoch 33/100] [Batch 145/347] [D loss: 0.430970] [G loss: 0.353578]\n",
      "[Epoch 33/100] [Batch 146/347] [D loss: 0.437161] [G loss: 0.320966]\n",
      "[Epoch 33/100] [Batch 147/347] [D loss: 0.453787] [G loss: 0.277747]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 33/100] [Batch 148/347] [D loss: 0.460014] [G loss: 0.252168]\n",
      "[Epoch 33/100] [Batch 149/347] [D loss: 0.456433] [G loss: 0.254999]\n",
      "[Epoch 33/100] [Batch 150/347] [D loss: 0.460655] [G loss: 0.247231]\n",
      "[Epoch 33/100] [Batch 151/347] [D loss: 0.465826] [G loss: 0.230749]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 33/100] [Batch 152/347] [D loss: 0.453750] [G loss: 0.239315]\n",
      "[Epoch 33/100] [Batch 153/347] [D loss: 0.439009] [G loss: 0.260514]\n",
      "[Epoch 33/100] [Batch 154/347] [D loss: 0.436637] [G loss: 0.267957]\n",
      "[Epoch 33/100] [Batch 155/347] [D loss: 0.446211] [G loss: 0.261088]\n",
      "[Epoch 33/100] [Batch 156/347] [D loss: 0.460098] [G loss: 0.251766]\n",
      "[Epoch 33/100] [Batch 157/347] [D loss: 0.450599] [G loss: 0.266028]\n",
      "[Epoch 33/100] [Batch 158/347] [D loss: 0.433392] [G loss: 0.298237]\n",
      "[Epoch 33/100] [Batch 159/347] [D loss: 0.432048] [G loss: 0.304297]\n",
      "[Epoch 33/100] [Batch 160/347] [D loss: 0.418260] [G loss: 0.292556]\n",
      "[Epoch 33/100] [Batch 161/347] [D loss: 0.418718] [G loss: 0.310493]\n",
      "[Epoch 33/100] [Batch 162/347] [D loss: 0.442563] [G loss: 0.316639]\n",
      "[Epoch 33/100] [Batch 163/347] [D loss: 0.437851] [G loss: 0.328117]\n",
      "[Epoch 33/100] [Batch 164/347] [D loss: 0.426341] [G loss: 0.347503]\n",
      "[Epoch 33/100] [Batch 165/347] [D loss: 0.426239] [G loss: 0.340901]\n",
      "[Epoch 33/100] [Batch 166/347] [D loss: 0.449286] [G loss: 0.311956]\n",
      "[Epoch 33/100] [Batch 167/347] [D loss: 0.435226] [G loss: 0.330533]\n",
      "[Epoch 33/100] [Batch 168/347] [D loss: 0.423629] [G loss: 0.339110]\n",
      "[Epoch 33/100] [Batch 169/347] [D loss: 0.478562] [G loss: 0.334744]\n",
      "[Epoch 33/100] [Batch 170/347] [D loss: 0.512476] [G loss: 0.332753]\n",
      "[Epoch 33/100] [Batch 171/347] [D loss: 0.523889] [G loss: 0.340059]\n",
      "[Epoch 33/100] [Batch 172/347] [D loss: 0.528090] [G loss: 0.340671]\n",
      "[Epoch 33/100] [Batch 173/347] [D loss: 0.513084] [G loss: 0.325014]\n",
      "[Epoch 33/100] [Batch 174/347] [D loss: 0.510595] [G loss: 0.317667]\n",
      "[Epoch 33/100] [Batch 175/347] [D loss: 0.525889] [G loss: 0.323370]\n",
      "[Epoch 33/100] [Batch 176/347] [D loss: 0.536421] [G loss: 0.333092]\n",
      "[Epoch 33/100] [Batch 177/347] [D loss: 0.537763] [G loss: 0.331139]\n",
      "[Epoch 33/100] [Batch 178/347] [D loss: 0.533960] [G loss: 0.322767]\n",
      "[Epoch 33/100] [Batch 179/347] [D loss: 0.529721] [G loss: 0.314680]\n",
      "[Epoch 33/100] [Batch 180/347] [D loss: 0.526284] [G loss: 0.307196]\n",
      "[Epoch 33/100] [Batch 181/347] [D loss: 0.527166] [G loss: 0.307404]\n",
      "[Epoch 33/100] [Batch 182/347] [D loss: 0.526382] [G loss: 0.305824]\n",
      "[Epoch 33/100] [Batch 183/347] [D loss: 0.529116] [G loss: 0.310889]\n",
      "[Epoch 33/100] [Batch 184/347] [D loss: 0.532255] [G loss: 0.316451]\n",
      "[Epoch 33/100] [Batch 185/347] [D loss: 0.532184] [G loss: 0.317023]\n",
      "[Epoch 33/100] [Batch 186/347] [D loss: 0.532675] [G loss: 0.319484]\n",
      "[Epoch 33/100] [Batch 187/347] [D loss: 0.529988] [G loss: 0.316864]\n",
      "[Epoch 33/100] [Batch 188/347] [D loss: 0.528292] [G loss: 0.316445]\n",
      "[Epoch 33/100] [Batch 189/347] [D loss: 0.527790] [G loss: 0.318795]\n",
      "[Epoch 33/100] [Batch 190/347] [D loss: 0.520614] [G loss: 0.309722]\n",
      "[Epoch 33/100] [Batch 191/347] [D loss: 0.511116] [G loss: 0.299938]\n",
      "[Epoch 33/100] [Batch 192/347] [D loss: 0.511116] [G loss: 0.304368]\n",
      "[Epoch 33/100] [Batch 193/347] [D loss: 0.518064] [G loss: 0.315231]\n",
      "[Epoch 33/100] [Batch 194/347] [D loss: 0.519512] [G loss: 0.312845]\n",
      "[Epoch 33/100] [Batch 195/347] [D loss: 0.516618] [G loss: 0.307124]\n",
      "[Epoch 33/100] [Batch 196/347] [D loss: 0.513146] [G loss: 0.303775]\n",
      "[Epoch 33/100] [Batch 197/347] [D loss: 0.509537] [G loss: 0.303100]\n",
      "[Epoch 33/100] [Batch 198/347] [D loss: 0.499904] [G loss: 0.305822]\n",
      "[Epoch 33/100] [Batch 199/347] [D loss: 0.499858] [G loss: 0.305869]\n",
      "[Epoch 33/100] [Batch 200/347] [D loss: 0.511331] [G loss: 0.304390]\n",
      "[Epoch 33/100] [Batch 201/347] [D loss: 0.513117] [G loss: 0.304000]\n",
      "[Epoch 33/100] [Batch 202/347] [D loss: 0.511980] [G loss: 0.298558]\n",
      "[Epoch 33/100] [Batch 203/347] [D loss: 0.510641] [G loss: 0.294052]\n",
      "[Epoch 33/100] [Batch 204/347] [D loss: 0.511159] [G loss: 0.293536]\n",
      "[Epoch 33/100] [Batch 205/347] [D loss: 0.511602] [G loss: 0.293312]\n",
      "[Epoch 33/100] [Batch 206/347] [D loss: 0.513313] [G loss: 0.296497]\n",
      "[Epoch 33/100] [Batch 207/347] [D loss: 0.517546] [G loss: 0.305608]\n",
      "[Epoch 33/100] [Batch 208/347] [D loss: 0.517673] [G loss: 0.304724]\n",
      "[Epoch 33/100] [Batch 209/347] [D loss: 0.512600] [G loss: 0.297525]\n",
      "[Epoch 33/100] [Batch 210/347] [D loss: 0.514464] [G loss: 0.302529]\n",
      "[Epoch 33/100] [Batch 211/347] [D loss: 0.514560] [G loss: 0.299998]\n",
      "[Epoch 33/100] [Batch 212/347] [D loss: 0.482599] [G loss: 0.297173]\n",
      "[Epoch 33/100] [Batch 213/347] [D loss: 0.459226] [G loss: 0.302718]\n",
      "[Epoch 33/100] [Batch 214/347] [D loss: 0.342818] [G loss: 0.311045]\n",
      "[Epoch 33/100] [Batch 215/347] [D loss: 0.344713] [G loss: 0.315133]\n",
      "[Epoch 33/100] [Batch 216/347] [D loss: 0.485874] [G loss: 0.312862]\n",
      "[Epoch 33/100] [Batch 217/347] [D loss: 0.506019] [G loss: 0.316437]\n",
      "[Epoch 33/100] [Batch 218/347] [D loss: 0.521001] [G loss: 0.325735]\n",
      "[Epoch 33/100] [Batch 219/347] [D loss: 0.524564] [G loss: 0.339623]\n",
      "[Epoch 33/100] [Batch 220/347] [D loss: 0.530708] [G loss: 0.356543]\n",
      "[Epoch 33/100] [Batch 221/347] [D loss: 0.531636] [G loss: 0.358625]\n",
      "[Epoch 33/100] [Batch 222/347] [D loss: 0.525457] [G loss: 0.350493]\n",
      "[Epoch 33/100] [Batch 223/347] [D loss: 0.523978] [G loss: 0.348969]\n",
      "[Epoch 33/100] [Batch 224/347] [D loss: 0.523101] [G loss: 0.344373]\n",
      "[Epoch 33/100] [Batch 225/347] [D loss: 0.507191] [G loss: 0.331039]\n",
      "[Epoch 33/100] [Batch 226/347] [D loss: 0.493667] [G loss: 0.305965]\n",
      "[Epoch 33/100] [Batch 227/347] [D loss: 0.490587] [G loss: 0.279065]\n",
      "[Epoch 33/100] [Batch 228/347] [D loss: 0.493043] [G loss: 0.272870]\n",
      "[Epoch 33/100] [Batch 229/347] [D loss: 0.499717] [G loss: 0.281810]\n",
      "[Epoch 33/100] [Batch 230/347] [D loss: 0.502407] [G loss: 0.282497]\n",
      "[Epoch 33/100] [Batch 231/347] [D loss: 0.498928] [G loss: 0.273612]\n",
      "[Epoch 33/100] [Batch 232/347] [D loss: 0.499911] [G loss: 0.272981]\n",
      "[Epoch 33/100] [Batch 233/347] [D loss: 0.497149] [G loss: 0.275760]\n",
      "[Epoch 33/100] [Batch 234/347] [D loss: 0.491183] [G loss: 0.279953]\n",
      "[Epoch 33/100] [Batch 235/347] [D loss: 0.493037] [G loss: 0.287223]\n",
      "[Epoch 33/100] [Batch 236/347] [D loss: 0.500990] [G loss: 0.291182]\n",
      "[Epoch 33/100] [Batch 237/347] [D loss: 0.510323] [G loss: 0.291733]\n",
      "[Epoch 33/100] [Batch 238/347] [D loss: 0.515456] [G loss: 0.294514]\n",
      "[Epoch 33/100] [Batch 239/347] [D loss: 0.512620] [G loss: 0.291807]\n",
      "[Epoch 33/100] [Batch 240/347] [D loss: 0.509173] [G loss: 0.287924]\n",
      "[Epoch 33/100] [Batch 241/347] [D loss: 0.505875] [G loss: 0.282615]\n",
      "[Epoch 33/100] [Batch 242/347] [D loss: 0.505569] [G loss: 0.281668]\n",
      "[Epoch 33/100] [Batch 243/347] [D loss: 0.510788] [G loss: 0.290817]\n",
      "[Epoch 33/100] [Batch 244/347] [D loss: 0.515418] [G loss: 0.301353]\n",
      "[Epoch 33/100] [Batch 245/347] [D loss: 0.509944] [G loss: 0.302371]\n",
      "[Epoch 33/100] [Batch 246/347] [D loss: 0.497115] [G loss: 0.297528]\n",
      "[Epoch 33/100] [Batch 247/347] [D loss: 0.492391] [G loss: 0.269897]\n",
      "[Epoch 33/100] [Batch 248/347] [D loss: 0.491238] [G loss: 0.260834]\n",
      "[Epoch 33/100] [Batch 249/347] [D loss: 0.487658] [G loss: 0.262205]\n",
      "[Epoch 33/100] [Batch 250/347] [D loss: 0.490469] [G loss: 0.284202]\n",
      "[Epoch 33/100] [Batch 251/347] [D loss: 0.497568] [G loss: 0.301467]\n",
      "[Epoch 33/100] [Batch 252/347] [D loss: 0.499963] [G loss: 0.304163]\n",
      "[Epoch 33/100] [Batch 253/347] [D loss: 0.502438] [G loss: 0.303888]\n",
      "[Epoch 33/100] [Batch 254/347] [D loss: 0.505303] [G loss: 0.301357]\n",
      "[Epoch 33/100] [Batch 255/347] [D loss: 0.491733] [G loss: 0.298941]\n",
      "[Epoch 33/100] [Batch 256/347] [D loss: 0.491848] [G loss: 0.303276]\n",
      "[Epoch 33/100] [Batch 257/347] [D loss: 0.504077] [G loss: 0.304433]\n",
      "[Epoch 33/100] [Batch 258/347] [D loss: 0.490251] [G loss: 0.298430]\n",
      "[Epoch 33/100] [Batch 259/347] [D loss: 0.471554] [G loss: 0.284358]\n",
      "[Epoch 33/100] [Batch 260/347] [D loss: 0.451939] [G loss: 0.281035]\n",
      "[Epoch 33/100] [Batch 261/347] [D loss: 0.456064] [G loss: 0.287852]\n",
      "[Epoch 33/100] [Batch 262/347] [D loss: 0.482736] [G loss: 0.282213]\n",
      "[Epoch 33/100] [Batch 263/347] [D loss: 0.474441] [G loss: 0.279858]\n",
      "[Epoch 33/100] [Batch 264/347] [D loss: 0.453805] [G loss: 0.281591]\n",
      "[Epoch 33/100] [Batch 265/347] [D loss: 0.452710] [G loss: 0.278691]\n",
      "[Epoch 33/100] [Batch 266/347] [D loss: 0.461097] [G loss: 0.275116]\n",
      "[Epoch 33/100] [Batch 267/347] [D loss: 0.467333] [G loss: 0.273337]\n",
      "[Epoch 33/100] [Batch 268/347] [D loss: 0.446482] [G loss: 0.278156]\n",
      "[Epoch 33/100] [Batch 269/347] [D loss: 0.437960] [G loss: 0.279956]\n",
      "[Epoch 33/100] [Batch 270/347] [D loss: 0.454135] [G loss: 0.277337]\n",
      "[Epoch 33/100] [Batch 271/347] [D loss: 0.469220] [G loss: 0.274205]\n",
      "[Epoch 33/100] [Batch 272/347] [D loss: 0.477576] [G loss: 0.276179]\n",
      "[Epoch 33/100] [Batch 273/347] [D loss: 0.440589] [G loss: 0.284988]\n",
      "[Epoch 33/100] [Batch 274/347] [D loss: 0.277685] [G loss: 0.309225]\n",
      "[Epoch 33/100] [Batch 275/347] [D loss: 0.261659] [G loss: 0.324680]\n",
      "[Epoch 33/100] [Batch 276/347] [D loss: 0.446500] [G loss: 0.319745]\n",
      "[Epoch 33/100] [Batch 277/347] [D loss: 0.468148] [G loss: 0.326090]\n",
      "[Epoch 33/100] [Batch 278/347] [D loss: 0.494696] [G loss: 0.338217]\n",
      "[Epoch 33/100] [Batch 279/347] [D loss: 0.487718] [G loss: 0.340959]\n",
      "[Epoch 33/100] [Batch 280/347] [D loss: 0.480351] [G loss: 0.345796]\n",
      "[Epoch 33/100] [Batch 281/347] [D loss: 0.482363] [G loss: 0.343362]\n",
      "[Epoch 33/100] [Batch 282/347] [D loss: 0.487128] [G loss: 0.338800]\n",
      "[Epoch 33/100] [Batch 283/347] [D loss: 0.467646] [G loss: 0.334860]\n",
      "[Epoch 33/100] [Batch 284/347] [D loss: 0.462704] [G loss: 0.331108]\n",
      "[Epoch 33/100] [Batch 285/347] [D loss: 0.482497] [G loss: 0.320663]\n",
      "[Epoch 33/100] [Batch 286/347] [D loss: 0.489400] [G loss: 0.312649]\n",
      "[Epoch 33/100] [Batch 287/347] [D loss: 0.486311] [G loss: 0.300076]\n",
      "[Epoch 33/100] [Batch 288/347] [D loss: 0.467141] [G loss: 0.304975]\n",
      "[Epoch 33/100] [Batch 289/347] [D loss: 0.463372] [G loss: 0.300049]\n",
      "[Epoch 33/100] [Batch 290/347] [D loss: 0.477465] [G loss: 0.270935]\n",
      "[Epoch 33/100] [Batch 291/347] [D loss: 0.470467] [G loss: 0.264614]\n",
      "[Epoch 33/100] [Batch 292/347] [D loss: 0.472914] [G loss: 0.251491]\n",
      "[Epoch 33/100] [Batch 293/347] [D loss: 0.475325] [G loss: 0.267331]\n",
      "[Epoch 33/100] [Batch 294/347] [D loss: 0.469543] [G loss: 0.266481]\n",
      "[Epoch 33/100] [Batch 295/347] [D loss: 0.367118] [G loss: 0.260005]\n",
      "[Epoch 33/100] [Batch 296/347] [D loss: 0.360280] [G loss: 0.260223]\n",
      "[Epoch 33/100] [Batch 297/347] [D loss: 0.479242] [G loss: 0.278662]\n",
      "[Epoch 33/100] [Batch 298/347] [D loss: 0.503625] [G loss: 0.275980]\n",
      "[Epoch 33/100] [Batch 299/347] [D loss: 0.497506] [G loss: 0.277515]\n",
      "[Epoch 33/100] [Batch 300/347] [D loss: 0.485226] [G loss: 0.276039]\n",
      "[Epoch 33/100] [Batch 301/347] [D loss: 0.482713] [G loss: 0.275517]\n",
      "[Epoch 33/100] [Batch 302/347] [D loss: 0.489699] [G loss: 0.285055]\n",
      "[Epoch 33/100] [Batch 303/347] [D loss: 0.477546] [G loss: 0.273022]\n",
      "[Epoch 33/100] [Batch 304/347] [D loss: 0.475130] [G loss: 0.262550]\n",
      "[Epoch 33/100] [Batch 305/347] [D loss: 0.478248] [G loss: 0.276275]\n",
      "[Epoch 33/100] [Batch 306/347] [D loss: 0.423353] [G loss: 0.268507]\n",
      "[Epoch 33/100] [Batch 307/347] [D loss: 0.366260] [G loss: 0.281766]\n",
      "[Epoch 33/100] [Batch 308/347] [D loss: 0.398767] [G loss: 0.280703]\n",
      "[Epoch 33/100] [Batch 309/347] [D loss: 0.486097] [G loss: 0.286047]\n",
      "[Epoch 33/100] [Batch 310/347] [D loss: 0.506679] [G loss: 0.315718]\n",
      "[Epoch 33/100] [Batch 311/347] [D loss: 0.508573] [G loss: 0.320372]\n",
      "[Epoch 33/100] [Batch 312/347] [D loss: 0.508480] [G loss: 0.321013]\n",
      "[Epoch 33/100] [Batch 313/347] [D loss: 0.507455] [G loss: 0.320933]\n",
      "[Epoch 33/100] [Batch 314/347] [D loss: 0.498054] [G loss: 0.314222]\n",
      "[Epoch 33/100] [Batch 315/347] [D loss: 0.483711] [G loss: 0.304372]\n",
      "[Epoch 33/100] [Batch 316/347] [D loss: 0.479790] [G loss: 0.286643]\n",
      "[Epoch 33/100] [Batch 317/347] [D loss: 0.481485] [G loss: 0.275708]\n",
      "[Epoch 33/100] [Batch 318/347] [D loss: 0.492814] [G loss: 0.288276]\n",
      "[Epoch 33/100] [Batch 319/347] [D loss: 0.510914] [G loss: 0.318880]\n",
      "[Epoch 33/100] [Batch 320/347] [D loss: 0.519635] [G loss: 0.329879]\n",
      "[Epoch 33/100] [Batch 321/347] [D loss: 0.511290] [G loss: 0.316891]\n",
      "[Epoch 33/100] [Batch 322/347] [D loss: 0.502709] [G loss: 0.301098]\n",
      "[Epoch 33/100] [Batch 323/347] [D loss: 0.498467] [G loss: 0.297636]\n",
      "[Epoch 33/100] [Batch 324/347] [D loss: 0.498819] [G loss: 0.298892]\n",
      "[Epoch 33/100] [Batch 325/347] [D loss: 0.468492] [G loss: 0.286722]\n",
      "[Epoch 33/100] [Batch 326/347] [D loss: 0.456988] [G loss: 0.280642]\n",
      "[Epoch 33/100] [Batch 327/347] [D loss: 0.474918] [G loss: 0.279239]\n",
      "[Epoch 33/100] [Batch 328/347] [D loss: 0.487542] [G loss: 0.276838]\n",
      "[Epoch 33/100] [Batch 329/347] [D loss: 0.456816] [G loss: 0.270783]\n",
      "[Epoch 33/100] [Batch 330/347] [D loss: 0.447587] [G loss: 0.266141]\n",
      "[Epoch 33/100] [Batch 331/347] [D loss: 0.470436] [G loss: 0.276768]\n",
      "[Epoch 33/100] [Batch 332/347] [D loss: 0.504167] [G loss: 0.294357]\n",
      "[Epoch 33/100] [Batch 333/347] [D loss: 0.513280] [G loss: 0.307219]\n",
      "[Epoch 33/100] [Batch 334/347] [D loss: 0.511214] [G loss: 0.309819]\n",
      "[Epoch 33/100] [Batch 335/347] [D loss: 0.499387] [G loss: 0.298637]\n",
      "[Epoch 33/100] [Batch 336/347] [D loss: 0.489770] [G loss: 0.290973]\n",
      "[Epoch 33/100] [Batch 337/347] [D loss: 0.494390] [G loss: 0.291277]\n",
      "[Epoch 33/100] [Batch 338/347] [D loss: 0.506446] [G loss: 0.306525]\n",
      "[Epoch 33/100] [Batch 339/347] [D loss: 0.514089] [G loss: 0.312399]\n",
      "[Epoch 33/100] [Batch 340/347] [D loss: 0.515703] [G loss: 0.313209]\n",
      "[Epoch 33/100] [Batch 341/347] [D loss: 0.509172] [G loss: 0.308642]\n",
      "[Epoch 33/100] [Batch 342/347] [D loss: 0.503713] [G loss: 0.301094]\n",
      "[Epoch 33/100] [Batch 343/347] [D loss: 0.510810] [G loss: 0.305915]\n",
      "[Epoch 33/100] [Batch 344/347] [D loss: 0.493423] [G loss: 0.293934]\n",
      "[Epoch 33/100] [Batch 345/347] [D loss: 0.466644] [G loss: 0.275037]\n",
      "[Epoch 33/100] [Batch 346/347] [D loss: 0.419823] [G loss: 0.273934]\n",
      "[Epoch 33/100] [Batch 347/347] [D loss: 0.306382] [G loss: 0.286109]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 34/100] [Batch 1/347] [D loss: 0.498884] [G loss: 0.293230]\n",
      "[Epoch 34/100] [Batch 2/347] [D loss: 0.500620] [G loss: 0.297187]\n",
      "[Epoch 34/100] [Batch 3/347] [D loss: 0.508102] [G loss: 0.308534]\n",
      "[Epoch 34/100] [Batch 4/347] [D loss: 0.508291] [G loss: 0.310109]\n",
      "[Epoch 34/100] [Batch 5/347] [D loss: 0.507228] [G loss: 0.309157]\n",
      "[Epoch 34/100] [Batch 6/347] [D loss: 0.508679] [G loss: 0.310472]\n",
      "[Epoch 34/100] [Batch 7/347] [D loss: 0.505409] [G loss: 0.304661]\n",
      "[Epoch 34/100] [Batch 8/347] [D loss: 0.500666] [G loss: 0.298575]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 34/100] [Batch 9/347] [D loss: 0.491604] [G loss: 0.285923]\n",
      "[Epoch 34/100] [Batch 10/347] [D loss: 0.492206] [G loss: 0.283679]\n",
      "[Epoch 34/100] [Batch 11/347] [D loss: 0.502447] [G loss: 0.294917]\n",
      "[Epoch 34/100] [Batch 12/347] [D loss: 0.505120] [G loss: 0.296319]\n",
      "[Epoch 34/100] [Batch 13/347] [D loss: 0.507140] [G loss: 0.297128]\n",
      "[Epoch 34/100] [Batch 14/347] [D loss: 0.507754] [G loss: 0.296239]\n",
      "[Epoch 34/100] [Batch 15/347] [D loss: 0.503715] [G loss: 0.289271]\n",
      "[Epoch 34/100] [Batch 16/347] [D loss: 0.499605] [G loss: 0.282451]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 34/100] [Batch 17/347] [D loss: 0.490363] [G loss: 0.271682]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 34/100] [Batch 18/347] [D loss: 0.482121] [G loss: 0.269903]\n",
      "[Epoch 34/100] [Batch 19/347] [D loss: 0.489811] [G loss: 0.270901]\n",
      "[Epoch 34/100] [Batch 20/347] [D loss: 0.504230] [G loss: 0.281405]\n",
      "[Epoch 34/100] [Batch 21/347] [D loss: 0.502892] [G loss: 0.276659]\n",
      "[Epoch 34/100] [Batch 22/347] [D loss: 0.498620] [G loss: 0.270936]\n",
      "[Epoch 34/100] [Batch 23/347] [D loss: 0.490545] [G loss: 0.264524]\n",
      "[Epoch 34/100] [Batch 24/347] [D loss: 0.489501] [G loss: 0.264285]\n",
      "[Epoch 34/100] [Batch 25/347] [D loss: 0.492701] [G loss: 0.263653]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 34/100] [Batch 26/347] [D loss: 0.465509] [G loss: 0.257486]\n",
      "[Epoch 34/100] [Batch 27/347] [D loss: 0.385567] [G loss: 0.275269]\n",
      "[Epoch 34/100] [Batch 28/347] [D loss: 0.391461] [G loss: 0.286859]\n",
      "[Epoch 34/100] [Batch 29/347] [D loss: 0.494582] [G loss: 0.283454]\n",
      "[Epoch 34/100] [Batch 30/347] [D loss: 0.487718] [G loss: 0.292801]\n",
      "[Epoch 34/100] [Batch 31/347] [D loss: 0.471630] [G loss: 0.297254]\n",
      "[Epoch 34/100] [Batch 32/347] [D loss: 0.434757] [G loss: 0.295605]\n",
      "[Epoch 34/100] [Batch 33/347] [D loss: 0.443420] [G loss: 0.289479]\n",
      "[Epoch 34/100] [Batch 34/347] [D loss: 0.481011] [G loss: 0.291736]\n",
      "[Epoch 34/100] [Batch 35/347] [D loss: 0.480436] [G loss: 0.291061]\n",
      "[Epoch 34/100] [Batch 36/347] [D loss: 0.486714] [G loss: 0.285161]\n",
      "[Epoch 34/100] [Batch 37/347] [D loss: 0.461070] [G loss: 0.277168]\n",
      "[Epoch 34/100] [Batch 38/347] [D loss: 0.446133] [G loss: 0.284091]\n",
      "[Epoch 34/100] [Batch 39/347] [D loss: 0.461270] [G loss: 0.272634]\n",
      "[Epoch 34/100] [Batch 40/347] [D loss: 0.480787] [G loss: 0.267696]\n",
      "[Epoch 34/100] [Batch 41/347] [D loss: 0.480313] [G loss: 0.266624]\n",
      "[Epoch 34/100] [Batch 42/347] [D loss: 0.482093] [G loss: 0.257266]\n",
      "[Epoch 34/100] [Batch 43/347] [D loss: 0.487083] [G loss: 0.271615]\n",
      "[Epoch 34/100] [Batch 44/347] [D loss: 0.496473] [G loss: 0.284231]\n",
      "[Epoch 34/100] [Batch 45/347] [D loss: 0.510015] [G loss: 0.300197]\n",
      "[Epoch 34/100] [Batch 46/347] [D loss: 0.507994] [G loss: 0.293917]\n",
      "[Epoch 34/100] [Batch 47/347] [D loss: 0.489322] [G loss: 0.272055]\n",
      "[Epoch 34/100] [Batch 48/347] [D loss: 0.448543] [G loss: 0.267716]\n",
      "[Epoch 34/100] [Batch 49/347] [D loss: 0.443696] [G loss: 0.275961]\n",
      "[Epoch 34/100] [Batch 50/347] [D loss: 0.384599] [G loss: 0.292520]\n",
      "[Epoch 34/100] [Batch 51/347] [D loss: 0.372553] [G loss: 0.292437]\n",
      "[Epoch 34/100] [Batch 52/347] [D loss: 0.443913] [G loss: 0.294877]\n",
      "[Epoch 34/100] [Batch 53/347] [D loss: 0.481593] [G loss: 0.292931]\n",
      "[Epoch 34/100] [Batch 54/347] [D loss: 0.441716] [G loss: 0.303827]\n",
      "[Epoch 34/100] [Batch 55/347] [D loss: 0.430601] [G loss: 0.328946]\n",
      "[Epoch 34/100] [Batch 56/347] [D loss: 0.436622] [G loss: 0.317458]\n",
      "[Epoch 34/100] [Batch 57/347] [D loss: 0.454013] [G loss: 0.295097]\n",
      "[Epoch 34/100] [Batch 58/347] [D loss: 0.476490] [G loss: 0.307211]\n",
      "[Epoch 34/100] [Batch 59/347] [D loss: 0.453286] [G loss: 0.307282]\n",
      "[Epoch 34/100] [Batch 60/347] [D loss: 0.436692] [G loss: 0.304090]\n",
      "[Epoch 34/100] [Batch 61/347] [D loss: 0.427553] [G loss: 0.301498]\n",
      "[Epoch 34/100] [Batch 62/347] [D loss: 0.422580] [G loss: 0.321422]\n",
      "[Epoch 34/100] [Batch 63/347] [D loss: 0.431241] [G loss: 0.322347]\n",
      "[Epoch 34/100] [Batch 64/347] [D loss: 0.457050] [G loss: 0.284871]\n",
      "[Epoch 34/100] [Batch 65/347] [D loss: 0.497938] [G loss: 0.303041]\n",
      "[Epoch 34/100] [Batch 66/347] [D loss: 0.441975] [G loss: 0.303712]\n",
      "[Epoch 34/100] [Batch 67/347] [D loss: 0.321718] [G loss: 0.298245]\n",
      "[Epoch 34/100] [Batch 68/347] [D loss: 0.342468] [G loss: 0.295331]\n",
      "[Epoch 34/100] [Batch 69/347] [D loss: 0.437247] [G loss: 0.312008]\n",
      "[Epoch 34/100] [Batch 70/347] [D loss: 0.438851] [G loss: 0.313250]\n",
      "[Epoch 34/100] [Batch 71/347] [D loss: 0.432121] [G loss: 0.316210]\n",
      "[Epoch 34/100] [Batch 72/347] [D loss: 0.428824] [G loss: 0.318973]\n",
      "[Epoch 34/100] [Batch 73/347] [D loss: 0.438019] [G loss: 0.293827]\n",
      "[Epoch 34/100] [Batch 74/347] [D loss: 0.437011] [G loss: 0.310771]\n",
      "[Epoch 34/100] [Batch 75/347] [D loss: 0.434977] [G loss: 0.308486]\n",
      "[Epoch 34/100] [Batch 76/347] [D loss: 0.444844] [G loss: 0.309186]\n",
      "[Epoch 34/100] [Batch 77/347] [D loss: 0.464044] [G loss: 0.293766]\n",
      "[Epoch 34/100] [Batch 78/347] [D loss: 0.480778] [G loss: 0.310385]\n",
      "[Epoch 34/100] [Batch 79/347] [D loss: 0.507435] [G loss: 0.308978]\n",
      "[Epoch 34/100] [Batch 80/347] [D loss: 0.511397] [G loss: 0.302653]\n",
      "[Epoch 34/100] [Batch 81/347] [D loss: 0.511463] [G loss: 0.303967]\n",
      "[Epoch 34/100] [Batch 82/347] [D loss: 0.492770] [G loss: 0.304911]\n",
      "[Epoch 34/100] [Batch 83/347] [D loss: 0.490208] [G loss: 0.294546]\n",
      "[Epoch 34/100] [Batch 84/347] [D loss: 0.512460] [G loss: 0.299684]\n",
      "[Epoch 34/100] [Batch 85/347] [D loss: 0.520062] [G loss: 0.299267]\n",
      "[Epoch 34/100] [Batch 86/347] [D loss: 0.516730] [G loss: 0.292825]\n",
      "[Epoch 34/100] [Batch 87/347] [D loss: 0.515834] [G loss: 0.290786]\n",
      "[Epoch 34/100] [Batch 88/347] [D loss: 0.519181] [G loss: 0.294652]\n",
      "[Epoch 34/100] [Batch 89/347] [D loss: 0.522753] [G loss: 0.299260]\n",
      "[Epoch 34/100] [Batch 90/347] [D loss: 0.520545] [G loss: 0.296982]\n",
      "[Epoch 34/100] [Batch 91/347] [D loss: 0.520088] [G loss: 0.297493]\n",
      "[Epoch 34/100] [Batch 92/347] [D loss: 0.521802] [G loss: 0.301124]\n",
      "[Epoch 34/100] [Batch 93/347] [D loss: 0.520941] [G loss: 0.301613]\n",
      "[Epoch 34/100] [Batch 94/347] [D loss: 0.518366] [G loss: 0.300624]\n",
      "[Epoch 34/100] [Batch 95/347] [D loss: 0.519255] [G loss: 0.303787]\n",
      "[Epoch 34/100] [Batch 96/347] [D loss: 0.516493] [G loss: 0.301702]\n",
      "[Epoch 34/100] [Batch 97/347] [D loss: 0.513423] [G loss: 0.299196]\n",
      "[Epoch 34/100] [Batch 98/347] [D loss: 0.518291] [G loss: 0.306742]\n",
      "[Epoch 34/100] [Batch 99/347] [D loss: 0.521859] [G loss: 0.312746]\n",
      "[Epoch 34/100] [Batch 100/347] [D loss: 0.518229] [G loss: 0.311338]\n",
      "[Epoch 34/100] [Batch 101/347] [D loss: 0.516102] [G loss: 0.308092]\n",
      "[Epoch 34/100] [Batch 102/347] [D loss: 0.519727] [G loss: 0.311372]\n",
      "[Epoch 34/100] [Batch 103/347] [D loss: 0.520551] [G loss: 0.313515]\n",
      "[Epoch 34/100] [Batch 104/347] [D loss: 0.515471] [G loss: 0.305994]\n",
      "[Epoch 34/100] [Batch 105/347] [D loss: 0.515777] [G loss: 0.306330]\n",
      "[Epoch 34/100] [Batch 106/347] [D loss: 0.514538] [G loss: 0.305937]\n",
      "[Epoch 34/100] [Batch 107/347] [D loss: 0.483997] [G loss: 0.302284]\n",
      "[Epoch 34/100] [Batch 108/347] [D loss: 0.325151] [G loss: 0.320606]\n",
      "[Epoch 34/100] [Batch 109/347] [D loss: 0.325150] [G loss: 0.331178]\n",
      "[Epoch 34/100] [Batch 110/347] [D loss: 0.491935] [G loss: 0.324360]\n",
      "[Epoch 34/100] [Batch 111/347] [D loss: 0.358374] [G loss: 0.334565]\n",
      "[Epoch 34/100] [Batch 112/347] [D loss: 0.324720] [G loss: 0.345699]\n",
      "[Epoch 34/100] [Batch 113/347] [D loss: 0.465838] [G loss: 0.351895]\n",
      "[Epoch 34/100] [Batch 114/347] [D loss: 0.529792] [G loss: 0.376703]\n",
      "[Epoch 34/100] [Batch 115/347] [D loss: 0.527930] [G loss: 0.380901]\n",
      "[Epoch 34/100] [Batch 116/347] [D loss: 0.527282] [G loss: 0.377003]\n",
      "[Epoch 34/100] [Batch 117/347] [D loss: 0.511397] [G loss: 0.355432]\n",
      "[Epoch 34/100] [Batch 118/347] [D loss: 0.480216] [G loss: 0.343877]\n",
      "[Epoch 34/100] [Batch 119/347] [D loss: 0.468683] [G loss: 0.334093]\n",
      "[Epoch 34/100] [Batch 120/347] [D loss: 0.428769] [G loss: 0.334169]\n",
      "[Epoch 34/100] [Batch 121/347] [D loss: 0.424494] [G loss: 0.328087]\n",
      "[Epoch 34/100] [Batch 122/347] [D loss: 0.486720] [G loss: 0.321103]\n",
      "[Epoch 34/100] [Batch 123/347] [D loss: 0.511236] [G loss: 0.315174]\n",
      "[Epoch 34/100] [Batch 124/347] [D loss: 0.507910] [G loss: 0.306882]\n",
      "[Epoch 34/100] [Batch 125/347] [D loss: 0.514165] [G loss: 0.308022]\n",
      "[Epoch 34/100] [Batch 126/347] [D loss: 0.515966] [G loss: 0.314327]\n",
      "[Epoch 34/100] [Batch 127/347] [D loss: 0.513174] [G loss: 0.309973]\n",
      "[Epoch 34/100] [Batch 128/347] [D loss: 0.509816] [G loss: 0.299733]\n",
      "[Epoch 34/100] [Batch 129/347] [D loss: 0.487756] [G loss: 0.292966]\n",
      "[Epoch 34/100] [Batch 130/347] [D loss: 0.473743] [G loss: 0.293262]\n",
      "[Epoch 34/100] [Batch 131/347] [D loss: 0.409133] [G loss: 0.291488]\n",
      "[Epoch 34/100] [Batch 132/347] [D loss: 0.297867] [G loss: 0.298430]\n",
      "[Epoch 34/100] [Batch 133/347] [D loss: 0.312423] [G loss: 0.305595]\n",
      "[Epoch 34/100] [Batch 134/347] [D loss: 0.288946] [G loss: 0.319194]\n",
      "[Epoch 34/100] [Batch 135/347] [D loss: 0.260099] [G loss: 0.343571]\n",
      "[Epoch 34/100] [Batch 136/347] [D loss: 0.249928] [G loss: 0.366731]\n",
      "[Epoch 34/100] [Batch 137/347] [D loss: 0.471587] [G loss: 0.372060]\n",
      "[Epoch 34/100] [Batch 138/347] [D loss: 0.472481] [G loss: 0.372783]\n",
      "[Epoch 34/100] [Batch 139/347] [D loss: 0.456081] [G loss: 0.366415]\n",
      "[Epoch 34/100] [Batch 140/347] [D loss: 0.448061] [G loss: 0.373861]\n",
      "[Epoch 34/100] [Batch 141/347] [D loss: 0.450212] [G loss: 0.382205]\n",
      "[Epoch 34/100] [Batch 142/347] [D loss: 0.447974] [G loss: 0.388328]\n",
      "[Epoch 34/100] [Batch 143/347] [D loss: 0.423851] [G loss: 0.405637]\n",
      "[Epoch 34/100] [Batch 144/347] [D loss: 0.420319] [G loss: 0.401464]\n",
      "[Epoch 34/100] [Batch 145/347] [D loss: 0.428901] [G loss: 0.378297]\n",
      "[Epoch 34/100] [Batch 146/347] [D loss: 0.436144] [G loss: 0.350954]\n",
      "[Epoch 34/100] [Batch 147/347] [D loss: 0.455774] [G loss: 0.310576]\n",
      "[Epoch 34/100] [Batch 148/347] [D loss: 0.460712] [G loss: 0.294938]\n",
      "[Epoch 34/100] [Batch 149/347] [D loss: 0.454686] [G loss: 0.286814]\n",
      "[Epoch 34/100] [Batch 150/347] [D loss: 0.457616] [G loss: 0.275599]\n",
      "[Epoch 34/100] [Batch 151/347] [D loss: 0.460258] [G loss: 0.275364]\n",
      "[Epoch 34/100] [Batch 152/347] [D loss: 0.441121] [G loss: 0.271547]\n",
      "[Epoch 34/100] [Batch 153/347] [D loss: 0.421549] [G loss: 0.269955]\n",
      "[Epoch 34/100] [Batch 154/347] [D loss: 0.419967] [G loss: 0.269324]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 34/100] [Batch 155/347] [D loss: 0.434972] [G loss: 0.253387]\n",
      "[Epoch 34/100] [Batch 156/347] [D loss: 0.455294] [G loss: 0.242211]\n",
      "[Epoch 34/100] [Batch 157/347] [D loss: 0.444388] [G loss: 0.255958]\n",
      "[Epoch 34/100] [Batch 158/347] [D loss: 0.424588] [G loss: 0.267184]\n",
      "[Epoch 34/100] [Batch 159/347] [D loss: 0.422407] [G loss: 0.268647]\n",
      "[Epoch 34/100] [Batch 160/347] [D loss: 0.399641] [G loss: 0.265284]\n",
      "[Epoch 34/100] [Batch 161/347] [D loss: 0.397138] [G loss: 0.287353]\n",
      "[Epoch 34/100] [Batch 162/347] [D loss: 0.429897] [G loss: 0.293389]\n",
      "[Epoch 34/100] [Batch 163/347] [D loss: 0.425629] [G loss: 0.293423]\n",
      "[Epoch 34/100] [Batch 164/347] [D loss: 0.410910] [G loss: 0.316883]\n",
      "[Epoch 34/100] [Batch 165/347] [D loss: 0.407021] [G loss: 0.314985]\n",
      "[Epoch 34/100] [Batch 166/347] [D loss: 0.429576] [G loss: 0.302532]\n",
      "[Epoch 34/100] [Batch 167/347] [D loss: 0.403971] [G loss: 0.326800]\n",
      "[Epoch 34/100] [Batch 168/347] [D loss: 0.385382] [G loss: 0.341729]\n",
      "[Epoch 34/100] [Batch 169/347] [D loss: 0.464038] [G loss: 0.343395]\n",
      "[Epoch 34/100] [Batch 170/347] [D loss: 0.512428] [G loss: 0.350879]\n",
      "[Epoch 34/100] [Batch 171/347] [D loss: 0.527781] [G loss: 0.363456]\n",
      "[Epoch 34/100] [Batch 172/347] [D loss: 0.533009] [G loss: 0.368857]\n",
      "[Epoch 34/100] [Batch 173/347] [D loss: 0.513124] [G loss: 0.357125]\n",
      "[Epoch 34/100] [Batch 174/347] [D loss: 0.510623] [G loss: 0.352874]\n",
      "[Epoch 34/100] [Batch 175/347] [D loss: 0.531467] [G loss: 0.361156]\n",
      "[Epoch 34/100] [Batch 176/347] [D loss: 0.542905] [G loss: 0.372801]\n",
      "[Epoch 34/100] [Batch 177/347] [D loss: 0.544254] [G loss: 0.372288]\n",
      "[Epoch 34/100] [Batch 178/347] [D loss: 0.540098] [G loss: 0.364870]\n",
      "[Epoch 34/100] [Batch 179/347] [D loss: 0.535257] [G loss: 0.356703]\n",
      "[Epoch 34/100] [Batch 180/347] [D loss: 0.531370] [G loss: 0.349041]\n",
      "[Epoch 34/100] [Batch 181/347] [D loss: 0.532026] [G loss: 0.348360]\n",
      "[Epoch 34/100] [Batch 182/347] [D loss: 0.531245] [G loss: 0.345126]\n",
      "[Epoch 34/100] [Batch 183/347] [D loss: 0.534171] [G loss: 0.348190]\n",
      "[Epoch 34/100] [Batch 184/347] [D loss: 0.537551] [G loss: 0.351380]\n",
      "[Epoch 34/100] [Batch 185/347] [D loss: 0.537723] [G loss: 0.348929]\n",
      "[Epoch 34/100] [Batch 186/347] [D loss: 0.538284] [G loss: 0.348286]\n",
      "[Epoch 34/100] [Batch 187/347] [D loss: 0.535266] [G loss: 0.342595]\n",
      "[Epoch 34/100] [Batch 188/347] [D loss: 0.533726] [G loss: 0.338781]\n",
      "[Epoch 34/100] [Batch 189/347] [D loss: 0.533136] [G loss: 0.337880]\n",
      "[Epoch 34/100] [Batch 190/347] [D loss: 0.525225] [G loss: 0.325903]\n",
      "[Epoch 34/100] [Batch 191/347] [D loss: 0.513963] [G loss: 0.312923]\n",
      "[Epoch 34/100] [Batch 192/347] [D loss: 0.512976] [G loss: 0.314408]\n",
      "[Epoch 34/100] [Batch 193/347] [D loss: 0.521110] [G loss: 0.322530]\n",
      "[Epoch 34/100] [Batch 194/347] [D loss: 0.524395] [G loss: 0.317875]\n",
      "[Epoch 34/100] [Batch 195/347] [D loss: 0.521746] [G loss: 0.310305]\n",
      "[Epoch 34/100] [Batch 196/347] [D loss: 0.517612] [G loss: 0.305376]\n",
      "[Epoch 34/100] [Batch 197/347] [D loss: 0.511988] [G loss: 0.303765]\n",
      "[Epoch 34/100] [Batch 198/347] [D loss: 0.496566] [G loss: 0.302294]\n",
      "[Epoch 34/100] [Batch 199/347] [D loss: 0.496974] [G loss: 0.301939]\n",
      "[Epoch 34/100] [Batch 200/347] [D loss: 0.514527] [G loss: 0.302942]\n",
      "[Epoch 34/100] [Batch 201/347] [D loss: 0.517023] [G loss: 0.303639]\n",
      "[Epoch 34/100] [Batch 202/347] [D loss: 0.516699] [G loss: 0.299012]\n",
      "[Epoch 34/100] [Batch 203/347] [D loss: 0.516438] [G loss: 0.295272]\n",
      "[Epoch 34/100] [Batch 204/347] [D loss: 0.516941] [G loss: 0.295748]\n",
      "[Epoch 34/100] [Batch 205/347] [D loss: 0.517253] [G loss: 0.296717]\n",
      "[Epoch 34/100] [Batch 206/347] [D loss: 0.518653] [G loss: 0.301427]\n",
      "[Epoch 34/100] [Batch 207/347] [D loss: 0.523026] [G loss: 0.312041]\n",
      "[Epoch 34/100] [Batch 208/347] [D loss: 0.523645] [G loss: 0.312674]\n",
      "[Epoch 34/100] [Batch 209/347] [D loss: 0.517397] [G loss: 0.307017]\n",
      "[Epoch 34/100] [Batch 210/347] [D loss: 0.518850] [G loss: 0.313347]\n",
      "[Epoch 34/100] [Batch 211/347] [D loss: 0.519483] [G loss: 0.312010]\n",
      "[Epoch 34/100] [Batch 212/347] [D loss: 0.468602] [G loss: 0.309243]\n",
      "[Epoch 34/100] [Batch 213/347] [D loss: 0.440342] [G loss: 0.315512]\n",
      "[Epoch 34/100] [Batch 214/347] [D loss: 0.305844] [G loss: 0.324885]\n",
      "[Epoch 34/100] [Batch 215/347] [D loss: 0.307438] [G loss: 0.329997]\n",
      "[Epoch 34/100] [Batch 216/347] [D loss: 0.481549] [G loss: 0.328690]\n",
      "[Epoch 34/100] [Batch 217/347] [D loss: 0.508461] [G loss: 0.332955]\n",
      "[Epoch 34/100] [Batch 218/347] [D loss: 0.527621] [G loss: 0.343243]\n",
      "[Epoch 34/100] [Batch 219/347] [D loss: 0.530248] [G loss: 0.358260]\n",
      "[Epoch 34/100] [Batch 220/347] [D loss: 0.536070] [G loss: 0.376053]\n",
      "[Epoch 34/100] [Batch 221/347] [D loss: 0.537236] [G loss: 0.379204]\n",
      "[Epoch 34/100] [Batch 222/347] [D loss: 0.530341] [G loss: 0.372273]\n",
      "[Epoch 34/100] [Batch 223/347] [D loss: 0.528897] [G loss: 0.371943]\n",
      "[Epoch 34/100] [Batch 224/347] [D loss: 0.528486] [G loss: 0.368385]\n",
      "[Epoch 34/100] [Batch 225/347] [D loss: 0.511858] [G loss: 0.356366]\n",
      "[Epoch 34/100] [Batch 226/347] [D loss: 0.498538] [G loss: 0.332080]\n",
      "[Epoch 34/100] [Batch 227/347] [D loss: 0.496491] [G loss: 0.305519]\n",
      "[Epoch 34/100] [Batch 228/347] [D loss: 0.499573] [G loss: 0.299178]\n",
      "[Epoch 34/100] [Batch 229/347] [D loss: 0.506797] [G loss: 0.307618]\n",
      "[Epoch 34/100] [Batch 230/347] [D loss: 0.509547] [G loss: 0.307790]\n",
      "[Epoch 34/100] [Batch 231/347] [D loss: 0.505442] [G loss: 0.298316]\n",
      "[Epoch 34/100] [Batch 232/347] [D loss: 0.506220] [G loss: 0.296923]\n",
      "[Epoch 34/100] [Batch 233/347] [D loss: 0.502317] [G loss: 0.299364]\n",
      "[Epoch 34/100] [Batch 234/347] [D loss: 0.494076] [G loss: 0.302161]\n",
      "[Epoch 34/100] [Batch 235/347] [D loss: 0.494657] [G loss: 0.308033]\n",
      "[Epoch 34/100] [Batch 236/347] [D loss: 0.503231] [G loss: 0.310441]\n",
      "[Epoch 34/100] [Batch 237/347] [D loss: 0.514682] [G loss: 0.308657]\n",
      "[Epoch 34/100] [Batch 238/347] [D loss: 0.521902] [G loss: 0.310100]\n",
      "[Epoch 34/100] [Batch 239/347] [D loss: 0.518490] [G loss: 0.305824]\n",
      "[Epoch 34/100] [Batch 240/347] [D loss: 0.514479] [G loss: 0.300669]\n",
      "[Epoch 34/100] [Batch 241/347] [D loss: 0.510995] [G loss: 0.293962]\n",
      "[Epoch 34/100] [Batch 242/347] [D loss: 0.511109] [G loss: 0.291858]\n",
      "[Epoch 34/100] [Batch 243/347] [D loss: 0.517542] [G loss: 0.299826]\n",
      "[Epoch 34/100] [Batch 244/347] [D loss: 0.522465] [G loss: 0.309646]\n",
      "[Epoch 34/100] [Batch 245/347] [D loss: 0.514175] [G loss: 0.310982]\n",
      "[Epoch 34/100] [Batch 246/347] [D loss: 0.500002] [G loss: 0.305557]\n",
      "[Epoch 34/100] [Batch 247/347] [D loss: 0.496894] [G loss: 0.277893]\n",
      "[Epoch 34/100] [Batch 248/347] [D loss: 0.496836] [G loss: 0.268761]\n",
      "[Epoch 34/100] [Batch 249/347] [D loss: 0.492724] [G loss: 0.270346]\n",
      "[Epoch 34/100] [Batch 250/347] [D loss: 0.494772] [G loss: 0.292738]\n",
      "[Epoch 34/100] [Batch 251/347] [D loss: 0.500724] [G loss: 0.310602]\n",
      "[Epoch 34/100] [Batch 252/347] [D loss: 0.502601] [G loss: 0.314042]\n",
      "[Epoch 34/100] [Batch 253/347] [D loss: 0.506329] [G loss: 0.314830]\n",
      "[Epoch 34/100] [Batch 254/347] [D loss: 0.510040] [G loss: 0.313584]\n",
      "[Epoch 34/100] [Batch 255/347] [D loss: 0.493069] [G loss: 0.312336]\n",
      "[Epoch 34/100] [Batch 256/347] [D loss: 0.492354] [G loss: 0.317557]\n",
      "[Epoch 34/100] [Batch 257/347] [D loss: 0.506460] [G loss: 0.319837]\n",
      "[Epoch 34/100] [Batch 258/347] [D loss: 0.488875] [G loss: 0.314704]\n",
      "[Epoch 34/100] [Batch 259/347] [D loss: 0.467214] [G loss: 0.301064]\n",
      "[Epoch 34/100] [Batch 260/347] [D loss: 0.441077] [G loss: 0.297691]\n",
      "[Epoch 34/100] [Batch 261/347] [D loss: 0.446286] [G loss: 0.303932]\n",
      "[Epoch 34/100] [Batch 262/347] [D loss: 0.482644] [G loss: 0.297736]\n",
      "[Epoch 34/100] [Batch 263/347] [D loss: 0.469751] [G loss: 0.294171]\n",
      "[Epoch 34/100] [Batch 264/347] [D loss: 0.442734] [G loss: 0.294633]\n",
      "[Epoch 34/100] [Batch 265/347] [D loss: 0.443058] [G loss: 0.290224]\n",
      "[Epoch 34/100] [Batch 266/347] [D loss: 0.454110] [G loss: 0.285019]\n",
      "[Epoch 34/100] [Batch 267/347] [D loss: 0.461821] [G loss: 0.281635]\n",
      "[Epoch 34/100] [Batch 268/347] [D loss: 0.432973] [G loss: 0.284899]\n",
      "[Epoch 34/100] [Batch 269/347] [D loss: 0.424264] [G loss: 0.285470]\n",
      "[Epoch 34/100] [Batch 270/347] [D loss: 0.447642] [G loss: 0.281655]\n",
      "[Epoch 34/100] [Batch 271/347] [D loss: 0.467746] [G loss: 0.277778]\n",
      "[Epoch 34/100] [Batch 272/347] [D loss: 0.479099] [G loss: 0.279585]\n",
      "[Epoch 34/100] [Batch 273/347] [D loss: 0.437626] [G loss: 0.288017]\n",
      "[Epoch 34/100] [Batch 274/347] [D loss: 0.336862] [G loss: 0.311596]\n",
      "[Epoch 34/100] [Batch 275/347] [D loss: 0.314997] [G loss: 0.325952]\n",
      "[Epoch 34/100] [Batch 276/347] [D loss: 0.437884] [G loss: 0.322348]\n",
      "[Epoch 34/100] [Batch 277/347] [D loss: 0.459304] [G loss: 0.329083]\n",
      "[Epoch 34/100] [Batch 278/347] [D loss: 0.495234] [G loss: 0.342580]\n",
      "[Epoch 34/100] [Batch 279/347] [D loss: 0.485511] [G loss: 0.346707]\n",
      "[Epoch 34/100] [Batch 280/347] [D loss: 0.476489] [G loss: 0.353448]\n",
      "[Epoch 34/100] [Batch 281/347] [D loss: 0.479285] [G loss: 0.353400]\n",
      "[Epoch 34/100] [Batch 282/347] [D loss: 0.486726] [G loss: 0.351674]\n",
      "[Epoch 34/100] [Batch 283/347] [D loss: 0.461947] [G loss: 0.350801]\n",
      "[Epoch 34/100] [Batch 284/347] [D loss: 0.456587] [G loss: 0.350108]\n",
      "[Epoch 34/100] [Batch 285/347] [D loss: 0.484401] [G loss: 0.343813]\n",
      "[Epoch 34/100] [Batch 286/347] [D loss: 0.496124] [G loss: 0.339511]\n",
      "[Epoch 34/100] [Batch 287/347] [D loss: 0.494196] [G loss: 0.330347]\n",
      "[Epoch 34/100] [Batch 288/347] [D loss: 0.474611] [G loss: 0.316555]\n",
      "[Epoch 34/100] [Batch 289/347] [D loss: 0.470362] [G loss: 0.314111]\n",
      "[Epoch 34/100] [Batch 290/347] [D loss: 0.485061] [G loss: 0.299978]\n",
      "[Epoch 34/100] [Batch 291/347] [D loss: 0.474517] [G loss: 0.288559]\n",
      "[Epoch 34/100] [Batch 292/347] [D loss: 0.474227] [G loss: 0.288286]\n",
      "[Epoch 34/100] [Batch 293/347] [D loss: 0.469301] [G loss: 0.302350]\n",
      "[Epoch 34/100] [Batch 294/347] [D loss: 0.456197] [G loss: 0.298821]\n",
      "[Epoch 34/100] [Batch 295/347] [D loss: 0.325866] [G loss: 0.287524]\n",
      "[Epoch 34/100] [Batch 296/347] [D loss: 0.317992] [G loss: 0.286149]\n",
      "[Epoch 34/100] [Batch 297/347] [D loss: 0.474195] [G loss: 0.301469]\n",
      "[Epoch 34/100] [Batch 298/347] [D loss: 0.506675] [G loss: 0.295214]\n",
      "[Epoch 34/100] [Batch 299/347] [D loss: 0.497446] [G loss: 0.293452]\n",
      "[Epoch 34/100] [Batch 300/347] [D loss: 0.479802] [G loss: 0.288744]\n",
      "[Epoch 34/100] [Batch 301/347] [D loss: 0.477697] [G loss: 0.284587]\n",
      "[Epoch 34/100] [Batch 302/347] [D loss: 0.487984] [G loss: 0.290896]\n",
      "[Epoch 34/100] [Batch 303/347] [D loss: 0.474572] [G loss: 0.274135]\n",
      "[Epoch 34/100] [Batch 304/347] [D loss: 0.473329] [G loss: 0.254824]\n",
      "[Epoch 34/100] [Batch 305/347] [D loss: 0.477670] [G loss: 0.263790]\n",
      "[Epoch 34/100] [Batch 306/347] [D loss: 0.405218] [G loss: 0.254909]\n",
      "[Epoch 34/100] [Batch 307/347] [D loss: 0.336141] [G loss: 0.266473]\n",
      "[Epoch 34/100] [Batch 308/347] [D loss: 0.376394] [G loss: 0.266245]\n",
      "[Epoch 34/100] [Batch 309/347] [D loss: 0.484323] [G loss: 0.281899]\n",
      "[Epoch 34/100] [Batch 310/347] [D loss: 0.508738] [G loss: 0.312275]\n",
      "[Epoch 34/100] [Batch 311/347] [D loss: 0.510500] [G loss: 0.317827]\n",
      "[Epoch 34/100] [Batch 312/347] [D loss: 0.510002] [G loss: 0.320058]\n",
      "[Epoch 34/100] [Batch 313/347] [D loss: 0.508109] [G loss: 0.321129]\n",
      "[Epoch 34/100] [Batch 314/347] [D loss: 0.495071] [G loss: 0.316264]\n",
      "[Epoch 34/100] [Batch 315/347] [D loss: 0.475705] [G loss: 0.307825]\n",
      "[Epoch 34/100] [Batch 316/347] [D loss: 0.472972] [G loss: 0.291767]\n",
      "[Epoch 34/100] [Batch 317/347] [D loss: 0.478715] [G loss: 0.281053]\n",
      "[Epoch 34/100] [Batch 318/347] [D loss: 0.491394] [G loss: 0.296468]\n",
      "[Epoch 34/100] [Batch 319/347] [D loss: 0.510434] [G loss: 0.328329]\n",
      "[Epoch 34/100] [Batch 320/347] [D loss: 0.519511] [G loss: 0.340792]\n",
      "[Epoch 34/100] [Batch 321/347] [D loss: 0.509394] [G loss: 0.328979]\n",
      "[Epoch 34/100] [Batch 322/347] [D loss: 0.499909] [G loss: 0.314165]\n",
      "[Epoch 34/100] [Batch 323/347] [D loss: 0.493468] [G loss: 0.311342]\n",
      "[Epoch 34/100] [Batch 324/347] [D loss: 0.492886] [G loss: 0.312614]\n",
      "[Epoch 34/100] [Batch 325/347] [D loss: 0.449577] [G loss: 0.300274]\n",
      "[Epoch 34/100] [Batch 326/347] [D loss: 0.435320] [G loss: 0.292517]\n",
      "[Epoch 34/100] [Batch 327/347] [D loss: 0.462555] [G loss: 0.289914]\n",
      "[Epoch 34/100] [Batch 328/347] [D loss: 0.480716] [G loss: 0.285919]\n",
      "[Epoch 34/100] [Batch 329/347] [D loss: 0.440184] [G loss: 0.277747]\n",
      "[Epoch 34/100] [Batch 330/347] [D loss: 0.430046] [G loss: 0.270903]\n",
      "[Epoch 34/100] [Batch 331/347] [D loss: 0.459621] [G loss: 0.278924]\n",
      "[Epoch 34/100] [Batch 332/347] [D loss: 0.501374] [G loss: 0.295518]\n",
      "[Epoch 34/100] [Batch 333/347] [D loss: 0.512280] [G loss: 0.306836]\n",
      "[Epoch 34/100] [Batch 334/347] [D loss: 0.507894] [G loss: 0.308301]\n",
      "[Epoch 34/100] [Batch 335/347] [D loss: 0.492791] [G loss: 0.296402]\n",
      "[Epoch 34/100] [Batch 336/347] [D loss: 0.481903] [G loss: 0.287237]\n",
      "[Epoch 34/100] [Batch 337/347] [D loss: 0.486965] [G loss: 0.288390]\n",
      "[Epoch 34/100] [Batch 338/347] [D loss: 0.501711] [G loss: 0.303702]\n",
      "[Epoch 34/100] [Batch 339/347] [D loss: 0.512521] [G loss: 0.309897]\n",
      "[Epoch 34/100] [Batch 340/347] [D loss: 0.514769] [G loss: 0.311343]\n",
      "[Epoch 34/100] [Batch 341/347] [D loss: 0.505759] [G loss: 0.307624]\n",
      "[Epoch 34/100] [Batch 342/347] [D loss: 0.499327] [G loss: 0.300893]\n",
      "[Epoch 34/100] [Batch 343/347] [D loss: 0.509142] [G loss: 0.306577]\n",
      "[Epoch 34/100] [Batch 344/347] [D loss: 0.483010] [G loss: 0.295575]\n",
      "[Epoch 34/100] [Batch 345/347] [D loss: 0.450709] [G loss: 0.276741]\n",
      "[Epoch 34/100] [Batch 346/347] [D loss: 0.399308] [G loss: 0.276768]\n",
      "[Epoch 34/100] [Batch 347/347] [D loss: 0.278435] [G loss: 0.289935]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 35/100] [Batch 1/347] [D loss: 0.495686] [G loss: 0.298573]\n",
      "[Epoch 35/100] [Batch 2/347] [D loss: 0.498247] [G loss: 0.303604]\n",
      "[Epoch 35/100] [Batch 3/347] [D loss: 0.507659] [G loss: 0.315883]\n",
      "[Epoch 35/100] [Batch 4/347] [D loss: 0.508130] [G loss: 0.318327]\n",
      "[Epoch 35/100] [Batch 5/347] [D loss: 0.507047] [G loss: 0.318272]\n",
      "[Epoch 35/100] [Batch 6/347] [D loss: 0.509054] [G loss: 0.320375]\n",
      "[Epoch 35/100] [Batch 7/347] [D loss: 0.505557] [G loss: 0.315332]\n",
      "[Epoch 35/100] [Batch 8/347] [D loss: 0.499601] [G loss: 0.309872]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 35/100] [Batch 9/347] [D loss: 0.489051] [G loss: 0.297608]\n",
      "[Epoch 35/100] [Batch 10/347] [D loss: 0.490192] [G loss: 0.296084]\n",
      "[Epoch 35/100] [Batch 11/347] [D loss: 0.502609] [G loss: 0.307293]\n",
      "[Epoch 35/100] [Batch 12/347] [D loss: 0.505798] [G loss: 0.308901]\n",
      "[Epoch 35/100] [Batch 13/347] [D loss: 0.508087] [G loss: 0.309643]\n",
      "[Epoch 35/100] [Batch 14/347] [D loss: 0.508545] [G loss: 0.308520]\n",
      "[Epoch 35/100] [Batch 15/347] [D loss: 0.503648] [G loss: 0.301331]\n",
      "[Epoch 35/100] [Batch 16/347] [D loss: 0.498497] [G loss: 0.294091]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 35/100] [Batch 17/347] [D loss: 0.487405] [G loss: 0.282589]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 35/100] [Batch 18/347] [D loss: 0.476519] [G loss: 0.279930]\n",
      "[Epoch 35/100] [Batch 19/347] [D loss: 0.485148] [G loss: 0.279916]\n",
      "[Epoch 35/100] [Batch 20/347] [D loss: 0.504505] [G loss: 0.289301]\n",
      "[Epoch 35/100] [Batch 21/347] [D loss: 0.503388] [G loss: 0.283523]\n",
      "[Epoch 35/100] [Batch 22/347] [D loss: 0.498233] [G loss: 0.276764]\n",
      "[Epoch 35/100] [Batch 23/347] [D loss: 0.487321] [G loss: 0.269212]\n",
      "[Epoch 35/100] [Batch 24/347] [D loss: 0.485955] [G loss: 0.268274]\n",
      "[Epoch 35/100] [Batch 25/347] [D loss: 0.491236] [G loss: 0.266525]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 35/100] [Batch 26/347] [D loss: 0.456466] [G loss: 0.259990]\n",
      "[Epoch 35/100] [Batch 27/347] [D loss: 0.351513] [G loss: 0.277618]\n",
      "[Epoch 35/100] [Batch 28/347] [D loss: 0.358542] [G loss: 0.289273]\n",
      "[Epoch 35/100] [Batch 29/347] [D loss: 0.491479] [G loss: 0.285904]\n",
      "[Epoch 35/100] [Batch 30/347] [D loss: 0.478705] [G loss: 0.295328]\n",
      "[Epoch 35/100] [Batch 31/347] [D loss: 0.454812] [G loss: 0.300093]\n",
      "[Epoch 35/100] [Batch 32/347] [D loss: 0.404937] [G loss: 0.299301]\n",
      "[Epoch 35/100] [Batch 33/347] [D loss: 0.417194] [G loss: 0.293790]\n",
      "[Epoch 35/100] [Batch 34/347] [D loss: 0.470364] [G loss: 0.296538]\n",
      "[Epoch 35/100] [Batch 35/347] [D loss: 0.469138] [G loss: 0.296506]\n",
      "[Epoch 35/100] [Batch 36/347] [D loss: 0.481983] [G loss: 0.291466]\n",
      "[Epoch 35/100] [Batch 37/347] [D loss: 0.450384] [G loss: 0.284060]\n",
      "[Epoch 35/100] [Batch 38/347] [D loss: 0.431428] [G loss: 0.285215]\n",
      "[Epoch 35/100] [Batch 39/347] [D loss: 0.451601] [G loss: 0.273727]\n",
      "[Epoch 35/100] [Batch 40/347] [D loss: 0.479791] [G loss: 0.268552]\n",
      "[Epoch 35/100] [Batch 41/347] [D loss: 0.479611] [G loss: 0.267367]\n",
      "[Epoch 35/100] [Batch 42/347] [D loss: 0.481269] [G loss: 0.263097]\n",
      "[Epoch 35/100] [Batch 43/347] [D loss: 0.485140] [G loss: 0.279009]\n",
      "[Epoch 35/100] [Batch 44/347] [D loss: 0.494640] [G loss: 0.291437]\n",
      "[Epoch 35/100] [Batch 45/347] [D loss: 0.510381] [G loss: 0.307571]\n",
      "[Epoch 35/100] [Batch 46/347] [D loss: 0.508403] [G loss: 0.301205]\n",
      "[Epoch 35/100] [Batch 47/347] [D loss: 0.487437] [G loss: 0.279123]\n",
      "[Epoch 35/100] [Batch 48/347] [D loss: 0.432889] [G loss: 0.268365]\n",
      "[Epoch 35/100] [Batch 49/347] [D loss: 0.428151] [G loss: 0.276852]\n",
      "[Epoch 35/100] [Batch 50/347] [D loss: 0.357986] [G loss: 0.293420]\n",
      "[Epoch 35/100] [Batch 51/347] [D loss: 0.343496] [G loss: 0.297845]\n",
      "[Epoch 35/100] [Batch 52/347] [D loss: 0.425205] [G loss: 0.300111]\n",
      "[Epoch 35/100] [Batch 53/347] [D loss: 0.476210] [G loss: 0.297651]\n",
      "[Epoch 35/100] [Batch 54/347] [D loss: 0.430487] [G loss: 0.304487]\n",
      "[Epoch 35/100] [Batch 55/347] [D loss: 0.418924] [G loss: 0.329312]\n",
      "[Epoch 35/100] [Batch 56/347] [D loss: 0.424756] [G loss: 0.317107]\n",
      "[Epoch 35/100] [Batch 57/347] [D loss: 0.442049] [G loss: 0.297603]\n",
      "[Epoch 35/100] [Batch 58/347] [D loss: 0.466460] [G loss: 0.309292]\n",
      "[Epoch 35/100] [Batch 59/347] [D loss: 0.438460] [G loss: 0.308692]\n",
      "[Epoch 35/100] [Batch 60/347] [D loss: 0.419886] [G loss: 0.305167]\n",
      "[Epoch 35/100] [Batch 61/347] [D loss: 0.408732] [G loss: 0.302408]\n",
      "[Epoch 35/100] [Batch 62/347] [D loss: 0.406066] [G loss: 0.318529]\n",
      "[Epoch 35/100] [Batch 63/347] [D loss: 0.418634] [G loss: 0.319389]\n",
      "[Epoch 35/100] [Batch 64/347] [D loss: 0.446946] [G loss: 0.285905]\n",
      "[Epoch 35/100] [Batch 65/347] [D loss: 0.494768] [G loss: 0.304068]\n",
      "[Epoch 35/100] [Batch 66/347] [D loss: 0.429739] [G loss: 0.305355]\n",
      "[Epoch 35/100] [Batch 67/347] [D loss: 0.292200] [G loss: 0.301065]\n",
      "[Epoch 35/100] [Batch 68/347] [D loss: 0.315732] [G loss: 0.299497]\n",
      "[Epoch 35/100] [Batch 69/347] [D loss: 0.425052] [G loss: 0.312126]\n",
      "[Epoch 35/100] [Batch 70/347] [D loss: 0.427264] [G loss: 0.313928]\n",
      "[Epoch 35/100] [Batch 71/347] [D loss: 0.418629] [G loss: 0.317366]\n",
      "[Epoch 35/100] [Batch 72/347] [D loss: 0.415146] [G loss: 0.320186]\n",
      "[Epoch 35/100] [Batch 73/347] [D loss: 0.423134] [G loss: 0.297958]\n",
      "[Epoch 35/100] [Batch 74/347] [D loss: 0.420428] [G loss: 0.317547]\n",
      "[Epoch 35/100] [Batch 75/347] [D loss: 0.422570] [G loss: 0.309478]\n",
      "[Epoch 35/100] [Batch 76/347] [D loss: 0.435501] [G loss: 0.310694]\n",
      "[Epoch 35/100] [Batch 77/347] [D loss: 0.453989] [G loss: 0.301565]\n",
      "[Epoch 35/100] [Batch 78/347] [D loss: 0.470006] [G loss: 0.319174]\n",
      "[Epoch 35/100] [Batch 79/347] [D loss: 0.506184] [G loss: 0.320870]\n",
      "[Epoch 35/100] [Batch 80/347] [D loss: 0.513017] [G loss: 0.315261]\n",
      "[Epoch 35/100] [Batch 81/347] [D loss: 0.511845] [G loss: 0.316898]\n",
      "[Epoch 35/100] [Batch 82/347] [D loss: 0.486415] [G loss: 0.314968]\n",
      "[Epoch 35/100] [Batch 83/347] [D loss: 0.482648] [G loss: 0.304056]\n",
      "[Epoch 35/100] [Batch 84/347] [D loss: 0.511949] [G loss: 0.311645]\n",
      "[Epoch 35/100] [Batch 85/347] [D loss: 0.523573] [G loss: 0.310380]\n",
      "[Epoch 35/100] [Batch 86/347] [D loss: 0.519975] [G loss: 0.303461]\n",
      "[Epoch 35/100] [Batch 87/347] [D loss: 0.519168] [G loss: 0.300628]\n",
      "[Epoch 35/100] [Batch 88/347] [D loss: 0.523202] [G loss: 0.303819]\n",
      "[Epoch 35/100] [Batch 89/347] [D loss: 0.527526] [G loss: 0.307704]\n",
      "[Epoch 35/100] [Batch 90/347] [D loss: 0.525101] [G loss: 0.304941]\n",
      "[Epoch 35/100] [Batch 91/347] [D loss: 0.524743] [G loss: 0.305014]\n",
      "[Epoch 35/100] [Batch 92/347] [D loss: 0.526934] [G loss: 0.308459]\n",
      "[Epoch 35/100] [Batch 93/347] [D loss: 0.526035] [G loss: 0.308497]\n",
      "[Epoch 35/100] [Batch 94/347] [D loss: 0.522953] [G loss: 0.307488]\n",
      "[Epoch 35/100] [Batch 95/347] [D loss: 0.523977] [G loss: 0.310645]\n",
      "[Epoch 35/100] [Batch 96/347] [D loss: 0.520838] [G loss: 0.308874]\n",
      "[Epoch 35/100] [Batch 97/347] [D loss: 0.517352] [G loss: 0.306544]\n",
      "[Epoch 35/100] [Batch 98/347] [D loss: 0.523206] [G loss: 0.314363]\n",
      "[Epoch 35/100] [Batch 99/347] [D loss: 0.527233] [G loss: 0.321042]\n",
      "[Epoch 35/100] [Batch 100/347] [D loss: 0.522540] [G loss: 0.320168]\n",
      "[Epoch 35/100] [Batch 101/347] [D loss: 0.520281] [G loss: 0.317745]\n",
      "[Epoch 35/100] [Batch 102/347] [D loss: 0.525129] [G loss: 0.321866]\n",
      "[Epoch 35/100] [Batch 103/347] [D loss: 0.525981] [G loss: 0.324951]\n",
      "[Epoch 35/100] [Batch 104/347] [D loss: 0.520454] [G loss: 0.318433]\n",
      "[Epoch 35/100] [Batch 105/347] [D loss: 0.521025] [G loss: 0.319835]\n",
      "[Epoch 35/100] [Batch 106/347] [D loss: 0.519055] [G loss: 0.320687]\n",
      "[Epoch 35/100] [Batch 107/347] [D loss: 0.481754] [G loss: 0.315966]\n",
      "[Epoch 35/100] [Batch 108/347] [D loss: 0.292823] [G loss: 0.335062]\n",
      "[Epoch 35/100] [Batch 109/347] [D loss: 0.292703] [G loss: 0.346435]\n",
      "[Epoch 35/100] [Batch 110/347] [D loss: 0.485261] [G loss: 0.340282]\n",
      "[Epoch 35/100] [Batch 111/347] [D loss: 0.330408] [G loss: 0.350875]\n",
      "[Epoch 35/100] [Batch 112/347] [D loss: 0.290364] [G loss: 0.362010]\n",
      "[Epoch 35/100] [Batch 113/347] [D loss: 0.459292] [G loss: 0.370401]\n",
      "[Epoch 35/100] [Batch 114/347] [D loss: 0.531055] [G loss: 0.395621]\n",
      "[Epoch 35/100] [Batch 115/347] [D loss: 0.527952] [G loss: 0.400519]\n",
      "[Epoch 35/100] [Batch 116/347] [D loss: 0.528785] [G loss: 0.397451]\n",
      "[Epoch 35/100] [Batch 117/347] [D loss: 0.512971] [G loss: 0.375265]\n",
      "[Epoch 35/100] [Batch 118/347] [D loss: 0.476503] [G loss: 0.364702]\n",
      "[Epoch 35/100] [Batch 119/347] [D loss: 0.460984] [G loss: 0.356231]\n",
      "[Epoch 35/100] [Batch 120/347] [D loss: 0.409467] [G loss: 0.356610]\n",
      "[Epoch 35/100] [Batch 121/347] [D loss: 0.402423] [G loss: 0.350854]\n",
      "[Epoch 35/100] [Batch 122/347] [D loss: 0.483626] [G loss: 0.344209]\n",
      "[Epoch 35/100] [Batch 123/347] [D loss: 0.516823] [G loss: 0.338582]\n",
      "[Epoch 35/100] [Batch 124/347] [D loss: 0.513424] [G loss: 0.329817]\n",
      "[Epoch 35/100] [Batch 125/347] [D loss: 0.519801] [G loss: 0.332426]\n",
      "[Epoch 35/100] [Batch 126/347] [D loss: 0.519501] [G loss: 0.338500]\n",
      "[Epoch 35/100] [Batch 127/347] [D loss: 0.515556] [G loss: 0.333715]\n",
      "[Epoch 35/100] [Batch 128/347] [D loss: 0.512073] [G loss: 0.322293]\n",
      "[Epoch 35/100] [Batch 129/347] [D loss: 0.480809] [G loss: 0.312698]\n",
      "[Epoch 35/100] [Batch 130/347] [D loss: 0.463686] [G loss: 0.311201]\n",
      "[Epoch 35/100] [Batch 131/347] [D loss: 0.395035] [G loss: 0.307165]\n",
      "[Epoch 35/100] [Batch 132/347] [D loss: 0.278551] [G loss: 0.312448]\n",
      "[Epoch 35/100] [Batch 133/347] [D loss: 0.292283] [G loss: 0.318427]\n",
      "[Epoch 35/100] [Batch 134/347] [D loss: 0.270270] [G loss: 0.331282]\n",
      "[Epoch 35/100] [Batch 135/347] [D loss: 0.247949] [G loss: 0.354826]\n",
      "[Epoch 35/100] [Batch 136/347] [D loss: 0.236731] [G loss: 0.377408]\n",
      "[Epoch 35/100] [Batch 137/347] [D loss: 0.470368] [G loss: 0.382348]\n",
      "[Epoch 35/100] [Batch 138/347] [D loss: 0.470588] [G loss: 0.383152]\n",
      "[Epoch 35/100] [Batch 139/347] [D loss: 0.453292] [G loss: 0.376919]\n",
      "[Epoch 35/100] [Batch 140/347] [D loss: 0.444467] [G loss: 0.379557]\n",
      "[Epoch 35/100] [Batch 141/347] [D loss: 0.447881] [G loss: 0.376923]\n",
      "[Epoch 35/100] [Batch 142/347] [D loss: 0.445827] [G loss: 0.383467]\n",
      "[Epoch 35/100] [Batch 143/347] [D loss: 0.418704] [G loss: 0.401372]\n",
      "[Epoch 35/100] [Batch 144/347] [D loss: 0.414416] [G loss: 0.397631]\n",
      "[Epoch 35/100] [Batch 145/347] [D loss: 0.422793] [G loss: 0.374854]\n",
      "[Epoch 35/100] [Batch 146/347] [D loss: 0.429180] [G loss: 0.347518]\n",
      "[Epoch 35/100] [Batch 147/347] [D loss: 0.450916] [G loss: 0.311982]\n",
      "[Epoch 35/100] [Batch 148/347] [D loss: 0.455526] [G loss: 0.305590]\n",
      "[Epoch 35/100] [Batch 149/347] [D loss: 0.450815] [G loss: 0.288602]\n",
      "[Epoch 35/100] [Batch 150/347] [D loss: 0.454189] [G loss: 0.280396]\n",
      "[Epoch 35/100] [Batch 151/347] [D loss: 0.454965] [G loss: 0.280926]\n",
      "[Epoch 35/100] [Batch 152/347] [D loss: 0.430094] [G loss: 0.275150]\n",
      "[Epoch 35/100] [Batch 153/347] [D loss: 0.406389] [G loss: 0.264408]\n",
      "[Epoch 35/100] [Batch 154/347] [D loss: 0.404161] [G loss: 0.264429]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 35/100] [Batch 155/347] [D loss: 0.420992] [G loss: 0.249674]\n",
      "[Epoch 35/100] [Batch 156/347] [D loss: 0.444990] [G loss: 0.246031]\n",
      "[Epoch 35/100] [Batch 157/347] [D loss: 0.431789] [G loss: 0.260301]\n",
      "[Epoch 35/100] [Batch 158/347] [D loss: 0.408959] [G loss: 0.267136]\n",
      "[Epoch 35/100] [Batch 159/347] [D loss: 0.405669] [G loss: 0.268622]\n",
      "[Epoch 35/100] [Batch 160/347] [D loss: 0.374745] [G loss: 0.269029]\n",
      "[Epoch 35/100] [Batch 161/347] [D loss: 0.371536] [G loss: 0.290011]\n",
      "[Epoch 35/100] [Batch 162/347] [D loss: 0.414382] [G loss: 0.295164]\n",
      "[Epoch 35/100] [Batch 163/347] [D loss: 0.412466] [G loss: 0.291896]\n",
      "[Epoch 35/100] [Batch 164/347] [D loss: 0.395307] [G loss: 0.313901]\n",
      "[Epoch 35/100] [Batch 165/347] [D loss: 0.388605] [G loss: 0.311870]\n",
      "[Epoch 35/100] [Batch 166/347] [D loss: 0.410182] [G loss: 0.301153]\n",
      "[Epoch 35/100] [Batch 167/347] [D loss: 0.375836] [G loss: 0.325225]\n",
      "[Epoch 35/100] [Batch 168/347] [D loss: 0.351210] [G loss: 0.340612]\n",
      "[Epoch 35/100] [Batch 169/347] [D loss: 0.448456] [G loss: 0.343264]\n",
      "[Epoch 35/100] [Batch 170/347] [D loss: 0.507870] [G loss: 0.355678]\n",
      "[Epoch 35/100] [Batch 171/347] [D loss: 0.526707] [G loss: 0.369587]\n",
      "[Epoch 35/100] [Batch 172/347] [D loss: 0.532549] [G loss: 0.376419]\n",
      "[Epoch 35/100] [Batch 173/347] [D loss: 0.507037] [G loss: 0.366168]\n",
      "[Epoch 35/100] [Batch 174/347] [D loss: 0.504642] [G loss: 0.363614]\n",
      "[Epoch 35/100] [Batch 175/347] [D loss: 0.531832] [G loss: 0.373381]\n",
      "[Epoch 35/100] [Batch 176/347] [D loss: 0.544187] [G loss: 0.386574]\n",
      "[Epoch 35/100] [Batch 177/347] [D loss: 0.545764] [G loss: 0.387461]\n",
      "[Epoch 35/100] [Batch 178/347] [D loss: 0.541387] [G loss: 0.381193]\n",
      "[Epoch 35/100] [Batch 179/347] [D loss: 0.536556] [G loss: 0.374309]\n",
      "[Epoch 35/100] [Batch 180/347] [D loss: 0.532673] [G loss: 0.367184]\n",
      "[Epoch 35/100] [Batch 181/347] [D loss: 0.533502] [G loss: 0.367235]\n",
      "[Epoch 35/100] [Batch 182/347] [D loss: 0.532785] [G loss: 0.364605]\n",
      "[Epoch 35/100] [Batch 183/347] [D loss: 0.535427] [G loss: 0.367972]\n",
      "[Epoch 35/100] [Batch 184/347] [D loss: 0.538816] [G loss: 0.371315]\n",
      "[Epoch 35/100] [Batch 185/347] [D loss: 0.539001] [G loss: 0.369324]\n",
      "[Epoch 35/100] [Batch 186/347] [D loss: 0.539431] [G loss: 0.368940]\n",
      "[Epoch 35/100] [Batch 187/347] [D loss: 0.536512] [G loss: 0.363383]\n",
      "[Epoch 35/100] [Batch 188/347] [D loss: 0.534875] [G loss: 0.360084]\n",
      "[Epoch 35/100] [Batch 189/347] [D loss: 0.534068] [G loss: 0.359360]\n",
      "[Epoch 35/100] [Batch 190/347] [D loss: 0.525910] [G loss: 0.347375]\n",
      "[Epoch 35/100] [Batch 191/347] [D loss: 0.513404] [G loss: 0.334379]\n",
      "[Epoch 35/100] [Batch 192/347] [D loss: 0.511157] [G loss: 0.335610]\n",
      "[Epoch 35/100] [Batch 193/347] [D loss: 0.519846] [G loss: 0.343508]\n",
      "[Epoch 35/100] [Batch 194/347] [D loss: 0.525177] [G loss: 0.338601]\n",
      "[Epoch 35/100] [Batch 195/347] [D loss: 0.523124] [G loss: 0.330407]\n",
      "[Epoch 35/100] [Batch 196/347] [D loss: 0.518542] [G loss: 0.324990]\n",
      "[Epoch 35/100] [Batch 197/347] [D loss: 0.510346] [G loss: 0.322925]\n",
      "[Epoch 35/100] [Batch 198/347] [D loss: 0.487975] [G loss: 0.320789]\n",
      "[Epoch 35/100] [Batch 199/347] [D loss: 0.489244] [G loss: 0.316903]\n",
      "[Epoch 35/100] [Batch 200/347] [D loss: 0.513754] [G loss: 0.319506]\n",
      "[Epoch 35/100] [Batch 201/347] [D loss: 0.516573] [G loss: 0.319389]\n",
      "[Epoch 35/100] [Batch 202/347] [D loss: 0.517395] [G loss: 0.313525]\n",
      "[Epoch 35/100] [Batch 203/347] [D loss: 0.518194] [G loss: 0.308832]\n",
      "[Epoch 35/100] [Batch 204/347] [D loss: 0.518758] [G loss: 0.308343]\n",
      "[Epoch 35/100] [Batch 205/347] [D loss: 0.518925] [G loss: 0.308649]\n",
      "[Epoch 35/100] [Batch 206/347] [D loss: 0.519930] [G loss: 0.312479]\n",
      "[Epoch 35/100] [Batch 207/347] [D loss: 0.523754] [G loss: 0.322357]\n",
      "[Epoch 35/100] [Batch 208/347] [D loss: 0.524853] [G loss: 0.322285]\n",
      "[Epoch 35/100] [Batch 209/347] [D loss: 0.517745] [G loss: 0.316002]\n",
      "[Epoch 35/100] [Batch 210/347] [D loss: 0.518383] [G loss: 0.321814]\n",
      "[Epoch 35/100] [Batch 211/347] [D loss: 0.519560] [G loss: 0.320159]\n",
      "[Epoch 35/100] [Batch 212/347] [D loss: 0.448526] [G loss: 0.314436]\n",
      "[Epoch 35/100] [Batch 213/347] [D loss: 0.418700] [G loss: 0.320272]\n",
      "[Epoch 35/100] [Batch 214/347] [D loss: 0.281027] [G loss: 0.329444]\n",
      "[Epoch 35/100] [Batch 215/347] [D loss: 0.281922] [G loss: 0.334317]\n",
      "[Epoch 35/100] [Batch 216/347] [D loss: 0.472551] [G loss: 0.332731]\n",
      "[Epoch 35/100] [Batch 217/347] [D loss: 0.505892] [G loss: 0.336712]\n",
      "[Epoch 35/100] [Batch 218/347] [D loss: 0.528823] [G loss: 0.349155]\n",
      "[Epoch 35/100] [Batch 219/347] [D loss: 0.529795] [G loss: 0.364095]\n",
      "[Epoch 35/100] [Batch 220/347] [D loss: 0.534928] [G loss: 0.381917]\n",
      "[Epoch 35/100] [Batch 221/347] [D loss: 0.536633] [G loss: 0.385220]\n",
      "[Epoch 35/100] [Batch 222/347] [D loss: 0.529164] [G loss: 0.378595]\n",
      "[Epoch 35/100] [Batch 223/347] [D loss: 0.527804] [G loss: 0.378466]\n",
      "[Epoch 35/100] [Batch 224/347] [D loss: 0.527862] [G loss: 0.375117]\n",
      "[Epoch 35/100] [Batch 225/347] [D loss: 0.510961] [G loss: 0.361530]\n",
      "[Epoch 35/100] [Batch 226/347] [D loss: 0.498771] [G loss: 0.337879]\n",
      "[Epoch 35/100] [Batch 227/347] [D loss: 0.498046] [G loss: 0.312024]\n",
      "[Epoch 35/100] [Batch 228/347] [D loss: 0.501550] [G loss: 0.308523]\n",
      "[Epoch 35/100] [Batch 229/347] [D loss: 0.509157] [G loss: 0.317810]\n",
      "[Epoch 35/100] [Batch 230/347] [D loss: 0.512006] [G loss: 0.318928]\n",
      "[Epoch 35/100] [Batch 231/347] [D loss: 0.507900] [G loss: 0.310164]\n",
      "[Epoch 35/100] [Batch 232/347] [D loss: 0.508667] [G loss: 0.309562]\n",
      "[Epoch 35/100] [Batch 233/347] [D loss: 0.503666] [G loss: 0.310738]\n",
      "[Epoch 35/100] [Batch 234/347] [D loss: 0.493832] [G loss: 0.313795]\n",
      "[Epoch 35/100] [Batch 235/347] [D loss: 0.493082] [G loss: 0.319824]\n",
      "[Epoch 35/100] [Batch 236/347] [D loss: 0.501896] [G loss: 0.321992]\n",
      "[Epoch 35/100] [Batch 237/347] [D loss: 0.514211] [G loss: 0.322004]\n",
      "[Epoch 35/100] [Batch 238/347] [D loss: 0.523381] [G loss: 0.322894]\n",
      "[Epoch 35/100] [Batch 239/347] [D loss: 0.519437] [G loss: 0.318050]\n",
      "[Epoch 35/100] [Batch 240/347] [D loss: 0.514848] [G loss: 0.312106]\n",
      "[Epoch 35/100] [Batch 241/347] [D loss: 0.511470] [G loss: 0.304701]\n",
      "[Epoch 35/100] [Batch 242/347] [D loss: 0.512048] [G loss: 0.301667]\n",
      "[Epoch 35/100] [Batch 243/347] [D loss: 0.519173] [G loss: 0.308867]\n",
      "[Epoch 35/100] [Batch 244/347] [D loss: 0.524310] [G loss: 0.318100]\n",
      "[Epoch 35/100] [Batch 245/347] [D loss: 0.512179] [G loss: 0.317141]\n",
      "[Epoch 35/100] [Batch 246/347] [D loss: 0.497337] [G loss: 0.310672]\n",
      "[Epoch 35/100] [Batch 247/347] [D loss: 0.496834] [G loss: 0.282220]\n",
      "[Epoch 35/100] [Batch 248/347] [D loss: 0.498376] [G loss: 0.272626]\n",
      "[Epoch 35/100] [Batch 249/347] [D loss: 0.493695] [G loss: 0.273733]\n",
      "[Epoch 35/100] [Batch 250/347] [D loss: 0.494567] [G loss: 0.295796]\n",
      "[Epoch 35/100] [Batch 251/347] [D loss: 0.498199] [G loss: 0.313329]\n",
      "[Epoch 35/100] [Batch 252/347] [D loss: 0.499181] [G loss: 0.316402]\n",
      "[Epoch 35/100] [Batch 253/347] [D loss: 0.504357] [G loss: 0.317055]\n",
      "[Epoch 35/100] [Batch 254/347] [D loss: 0.509098] [G loss: 0.315778]\n",
      "[Epoch 35/100] [Batch 255/347] [D loss: 0.487967] [G loss: 0.314607]\n",
      "[Epoch 35/100] [Batch 256/347] [D loss: 0.486176] [G loss: 0.320210]\n",
      "[Epoch 35/100] [Batch 257/347] [D loss: 0.502060] [G loss: 0.322509]\n",
      "[Epoch 35/100] [Batch 258/347] [D loss: 0.479917] [G loss: 0.317541]\n",
      "[Epoch 35/100] [Batch 259/347] [D loss: 0.456071] [G loss: 0.303877]\n",
      "[Epoch 35/100] [Batch 260/347] [D loss: 0.424591] [G loss: 0.300727]\n",
      "[Epoch 35/100] [Batch 261/347] [D loss: 0.431049] [G loss: 0.306815]\n",
      "[Epoch 35/100] [Batch 262/347] [D loss: 0.476415] [G loss: 0.300819]\n",
      "[Epoch 35/100] [Batch 263/347] [D loss: 0.458087] [G loss: 0.297416]\n",
      "[Epoch 35/100] [Batch 264/347] [D loss: 0.425424] [G loss: 0.298227]\n",
      "[Epoch 35/100] [Batch 265/347] [D loss: 0.428155] [G loss: 0.294340]\n",
      "[Epoch 35/100] [Batch 266/347] [D loss: 0.441441] [G loss: 0.289469]\n",
      "[Epoch 35/100] [Batch 267/347] [D loss: 0.450232] [G loss: 0.286489]\n",
      "[Epoch 35/100] [Batch 268/347] [D loss: 0.414934] [G loss: 0.290371]\n",
      "[Epoch 35/100] [Batch 269/347] [D loss: 0.406987] [G loss: 0.291477]\n",
      "[Epoch 35/100] [Batch 270/347] [D loss: 0.436914] [G loss: 0.288274]\n",
      "[Epoch 35/100] [Batch 271/347] [D loss: 0.461833] [G loss: 0.284887]\n",
      "[Epoch 35/100] [Batch 272/347] [D loss: 0.476100] [G loss: 0.286852]\n",
      "[Epoch 35/100] [Batch 273/347] [D loss: 0.430092] [G loss: 0.295437]\n",
      "[Epoch 35/100] [Batch 274/347] [D loss: 0.387953] [G loss: 0.318798]\n",
      "[Epoch 35/100] [Batch 275/347] [D loss: 0.362272] [G loss: 0.332702]\n",
      "[Epoch 35/100] [Batch 276/347] [D loss: 0.426999] [G loss: 0.328498]\n",
      "[Epoch 35/100] [Batch 277/347] [D loss: 0.448399] [G loss: 0.334566]\n",
      "[Epoch 35/100] [Batch 278/347] [D loss: 0.494716] [G loss: 0.347549]\n",
      "[Epoch 35/100] [Batch 279/347] [D loss: 0.482284] [G loss: 0.351407]\n",
      "[Epoch 35/100] [Batch 280/347] [D loss: 0.471007] [G loss: 0.358172]\n",
      "[Epoch 35/100] [Batch 281/347] [D loss: 0.474160] [G loss: 0.358534]\n",
      "[Epoch 35/100] [Batch 282/347] [D loss: 0.483327] [G loss: 0.357279]\n",
      "[Epoch 35/100] [Batch 283/347] [D loss: 0.451149] [G loss: 0.357098]\n",
      "[Epoch 35/100] [Batch 284/347] [D loss: 0.444272] [G loss: 0.357581]\n",
      "[Epoch 35/100] [Batch 285/347] [D loss: 0.480728] [G loss: 0.352705]\n",
      "[Epoch 35/100] [Batch 286/347] [D loss: 0.497761] [G loss: 0.349853]\n",
      "[Epoch 35/100] [Batch 287/347] [D loss: 0.496731] [G loss: 0.342620]\n",
      "[Epoch 35/100] [Batch 288/347] [D loss: 0.477247] [G loss: 0.322772]\n",
      "[Epoch 35/100] [Batch 289/347] [D loss: 0.473426] [G loss: 0.317243]\n",
      "[Epoch 35/100] [Batch 290/347] [D loss: 0.489280] [G loss: 0.318370]\n",
      "[Epoch 35/100] [Batch 291/347] [D loss: 0.476772] [G loss: 0.308698]\n",
      "[Epoch 35/100] [Batch 292/347] [D loss: 0.475212] [G loss: 0.309860]\n",
      "[Epoch 35/100] [Batch 293/347] [D loss: 0.463800] [G loss: 0.325112]\n",
      "[Epoch 35/100] [Batch 294/347] [D loss: 0.444625] [G loss: 0.321924]\n",
      "[Epoch 35/100] [Batch 295/347] [D loss: 0.296609] [G loss: 0.309607]\n",
      "[Epoch 35/100] [Batch 296/347] [D loss: 0.286807] [G loss: 0.307756]\n",
      "[Epoch 35/100] [Batch 297/347] [D loss: 0.471513] [G loss: 0.321875]\n",
      "[Epoch 35/100] [Batch 298/347] [D loss: 0.510190] [G loss: 0.314478]\n",
      "[Epoch 35/100] [Batch 299/347] [D loss: 0.497360] [G loss: 0.311573]\n",
      "[Epoch 35/100] [Batch 300/347] [D loss: 0.474301] [G loss: 0.305198]\n",
      "[Epoch 35/100] [Batch 301/347] [D loss: 0.472665] [G loss: 0.299397]\n",
      "[Epoch 35/100] [Batch 302/347] [D loss: 0.486324] [G loss: 0.304133]\n",
      "[Epoch 35/100] [Batch 303/347] [D loss: 0.471744] [G loss: 0.285160]\n",
      "[Epoch 35/100] [Batch 304/347] [D loss: 0.471989] [G loss: 0.264871]\n",
      "[Epoch 35/100] [Batch 305/347] [D loss: 0.477652] [G loss: 0.266716]\n",
      "[Epoch 35/100] [Batch 306/347] [D loss: 0.387026] [G loss: 0.258066]\n",
      "[Epoch 35/100] [Batch 307/347] [D loss: 0.309503] [G loss: 0.267627]\n",
      "[Epoch 35/100] [Batch 308/347] [D loss: 0.356977] [G loss: 0.270605]\n",
      "[Epoch 35/100] [Batch 309/347] [D loss: 0.482238] [G loss: 0.286733]\n",
      "[Epoch 35/100] [Batch 310/347] [D loss: 0.510436] [G loss: 0.316736]\n",
      "[Epoch 35/100] [Batch 311/347] [D loss: 0.511987] [G loss: 0.321861]\n",
      "[Epoch 35/100] [Batch 312/347] [D loss: 0.510926] [G loss: 0.324117]\n",
      "[Epoch 35/100] [Batch 313/347] [D loss: 0.507866] [G loss: 0.325223]\n",
      "[Epoch 35/100] [Batch 314/347] [D loss: 0.490505] [G loss: 0.320228]\n",
      "[Epoch 35/100] [Batch 315/347] [D loss: 0.465204] [G loss: 0.311876]\n",
      "[Epoch 35/100] [Batch 316/347] [D loss: 0.463400] [G loss: 0.295751]\n",
      "[Epoch 35/100] [Batch 317/347] [D loss: 0.474028] [G loss: 0.284841]\n",
      "[Epoch 35/100] [Batch 318/347] [D loss: 0.488291] [G loss: 0.300376]\n",
      "[Epoch 35/100] [Batch 319/347] [D loss: 0.507658] [G loss: 0.332095]\n",
      "[Epoch 35/100] [Batch 320/347] [D loss: 0.516916] [G loss: 0.344628]\n",
      "[Epoch 35/100] [Batch 321/347] [D loss: 0.504911] [G loss: 0.332974]\n",
      "[Epoch 35/100] [Batch 322/347] [D loss: 0.494693] [G loss: 0.318159]\n",
      "[Epoch 35/100] [Batch 323/347] [D loss: 0.485435] [G loss: 0.315561]\n",
      "[Epoch 35/100] [Batch 324/347] [D loss: 0.483764] [G loss: 0.316925]\n",
      "[Epoch 35/100] [Batch 325/347] [D loss: 0.427049] [G loss: 0.304755]\n",
      "[Epoch 35/100] [Batch 326/347] [D loss: 0.410186] [G loss: 0.294723]\n",
      "[Epoch 35/100] [Batch 327/347] [D loss: 0.447548] [G loss: 0.292134]\n",
      "[Epoch 35/100] [Batch 328/347] [D loss: 0.471937] [G loss: 0.288306]\n",
      "[Epoch 35/100] [Batch 329/347] [D loss: 0.421485] [G loss: 0.280073]\n",
      "[Epoch 35/100] [Batch 330/347] [D loss: 0.410791] [G loss: 0.273295]\n",
      "[Epoch 35/100] [Batch 331/347] [D loss: 0.447735] [G loss: 0.281297]\n",
      "[Epoch 35/100] [Batch 332/347] [D loss: 0.498039] [G loss: 0.299844]\n",
      "[Epoch 35/100] [Batch 333/347] [D loss: 0.510905] [G loss: 0.311066]\n",
      "[Epoch 35/100] [Batch 334/347] [D loss: 0.504168] [G loss: 0.312329]\n",
      "[Epoch 35/100] [Batch 335/347] [D loss: 0.486129] [G loss: 0.300122]\n",
      "[Epoch 35/100] [Batch 336/347] [D loss: 0.474596] [G loss: 0.288774]\n",
      "[Epoch 35/100] [Batch 337/347] [D loss: 0.479898] [G loss: 0.291679]\n",
      "[Epoch 35/100] [Batch 338/347] [D loss: 0.497358] [G loss: 0.306947]\n",
      "[Epoch 35/100] [Batch 339/347] [D loss: 0.511649] [G loss: 0.313214]\n",
      "[Epoch 35/100] [Batch 340/347] [D loss: 0.514790] [G loss: 0.314674]\n",
      "[Epoch 35/100] [Batch 341/347] [D loss: 0.503127] [G loss: 0.311023]\n",
      "[Epoch 35/100] [Batch 342/347] [D loss: 0.495989] [G loss: 0.304491]\n",
      "[Epoch 35/100] [Batch 343/347] [D loss: 0.508677] [G loss: 0.310364]\n",
      "[Epoch 35/100] [Batch 344/347] [D loss: 0.472570] [G loss: 0.299721]\n",
      "[Epoch 35/100] [Batch 345/347] [D loss: 0.435135] [G loss: 0.279485]\n",
      "[Epoch 35/100] [Batch 346/347] [D loss: 0.382719] [G loss: 0.280198]\n",
      "[Epoch 35/100] [Batch 347/347] [D loss: 0.263871] [G loss: 0.294204]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 36/100] [Batch 1/347] [D loss: 0.494026] [G loss: 0.305623]\n",
      "[Epoch 36/100] [Batch 2/347] [D loss: 0.497671] [G loss: 0.311113]\n",
      "[Epoch 36/100] [Batch 3/347] [D loss: 0.508950] [G loss: 0.324216]\n",
      "[Epoch 36/100] [Batch 4/347] [D loss: 0.509654] [G loss: 0.327639]\n",
      "[Epoch 36/100] [Batch 5/347] [D loss: 0.508652] [G loss: 0.328204]\n",
      "[Epoch 36/100] [Batch 6/347] [D loss: 0.511160] [G loss: 0.331250]\n",
      "[Epoch 36/100] [Batch 7/347] [D loss: 0.507509] [G loss: 0.327136]\n",
      "[Epoch 36/100] [Batch 8/347] [D loss: 0.500676] [G loss: 0.322611]\n",
      "[Epoch 36/100] [Batch 9/347] [D loss: 0.488940] [G loss: 0.311260]\n",
      "[Epoch 36/100] [Batch 10/347] [D loss: 0.490891] [G loss: 0.310049]\n",
      "[Epoch 36/100] [Batch 11/347] [D loss: 0.505172] [G loss: 0.322008]\n",
      "[Epoch 36/100] [Batch 12/347] [D loss: 0.508968] [G loss: 0.324029]\n",
      "[Epoch 36/100] [Batch 13/347] [D loss: 0.511485] [G loss: 0.325096]\n",
      "[Epoch 36/100] [Batch 14/347] [D loss: 0.511726] [G loss: 0.324461]\n",
      "[Epoch 36/100] [Batch 15/347] [D loss: 0.506126] [G loss: 0.317497]\n",
      "[Epoch 36/100] [Batch 16/347] [D loss: 0.500368] [G loss: 0.310274]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 36/100] [Batch 17/347] [D loss: 0.487526] [G loss: 0.297120]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 36/100] [Batch 18/347] [D loss: 0.474097] [G loss: 0.294152]\n",
      "[Epoch 36/100] [Batch 19/347] [D loss: 0.483345] [G loss: 0.293296]\n",
      "[Epoch 36/100] [Batch 20/347] [D loss: 0.507388] [G loss: 0.303016]\n",
      "[Epoch 36/100] [Batch 21/347] [D loss: 0.506642] [G loss: 0.296266]\n",
      "[Epoch 36/100] [Batch 22/347] [D loss: 0.500680] [G loss: 0.288979]\n",
      "[Epoch 36/100] [Batch 23/347] [D loss: 0.486786] [G loss: 0.280402]\n",
      "[Epoch 36/100] [Batch 24/347] [D loss: 0.485028] [G loss: 0.277487]\n",
      "[Epoch 36/100] [Batch 25/347] [D loss: 0.492505] [G loss: 0.275680]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 36/100] [Batch 26/347] [D loss: 0.450953] [G loss: 0.267407]\n",
      "[Epoch 36/100] [Batch 27/347] [D loss: 0.325096] [G loss: 0.284494]\n",
      "[Epoch 36/100] [Batch 28/347] [D loss: 0.333042] [G loss: 0.296250]\n",
      "[Epoch 36/100] [Batch 29/347] [D loss: 0.490643] [G loss: 0.293307]\n",
      "[Epoch 36/100] [Batch 30/347] [D loss: 0.471347] [G loss: 0.302552]\n",
      "[Epoch 36/100] [Batch 31/347] [D loss: 0.439499] [G loss: 0.306837]\n",
      "[Epoch 36/100] [Batch 32/347] [D loss: 0.379107] [G loss: 0.305631]\n",
      "[Epoch 36/100] [Batch 33/347] [D loss: 0.394171] [G loss: 0.300118]\n",
      "[Epoch 36/100] [Batch 34/347] [D loss: 0.460736] [G loss: 0.302633]\n",
      "[Epoch 36/100] [Batch 35/347] [D loss: 0.458129] [G loss: 0.302128]\n",
      "[Epoch 36/100] [Batch 36/347] [D loss: 0.478991] [G loss: 0.296945]\n",
      "[Epoch 36/100] [Batch 37/347] [D loss: 0.441582] [G loss: 0.289211]\n",
      "[Epoch 36/100] [Batch 38/347] [D loss: 0.418020] [G loss: 0.276718]\n",
      "[Epoch 36/100] [Batch 39/347] [D loss: 0.443465] [G loss: 0.271367]\n",
      "[Epoch 36/100] [Batch 40/347] [D loss: 0.481575] [G loss: 0.267888]\n",
      "[Epoch 36/100] [Batch 41/347] [D loss: 0.481490] [G loss: 0.264152]\n",
      "[Epoch 36/100] [Batch 42/347] [D loss: 0.482251] [G loss: 0.266594]\n",
      "[Epoch 36/100] [Batch 43/347] [D loss: 0.483694] [G loss: 0.282950]\n",
      "[Epoch 36/100] [Batch 44/347] [D loss: 0.492030] [G loss: 0.295940]\n",
      "[Epoch 36/100] [Batch 45/347] [D loss: 0.509950] [G loss: 0.313760]\n",
      "[Epoch 36/100] [Batch 46/347] [D loss: 0.507606] [G loss: 0.309756]\n",
      "[Epoch 36/100] [Batch 47/347] [D loss: 0.485236] [G loss: 0.289263]\n",
      "[Epoch 36/100] [Batch 48/347] [D loss: 0.415658] [G loss: 0.279346]\n",
      "[Epoch 36/100] [Batch 49/347] [D loss: 0.411740] [G loss: 0.282249]\n",
      "[Epoch 36/100] [Batch 50/347] [D loss: 0.333098] [G loss: 0.298973]\n",
      "[Epoch 36/100] [Batch 51/347] [D loss: 0.316967] [G loss: 0.307635]\n",
      "[Epoch 36/100] [Batch 52/347] [D loss: 0.407875] [G loss: 0.309174]\n",
      "[Epoch 36/100] [Batch 53/347] [D loss: 0.471054] [G loss: 0.306075]\n",
      "[Epoch 36/100] [Batch 54/347] [D loss: 0.420048] [G loss: 0.307966]\n",
      "[Epoch 36/100] [Batch 55/347] [D loss: 0.408129] [G loss: 0.332002]\n",
      "[Epoch 36/100] [Batch 56/347] [D loss: 0.413544] [G loss: 0.319055]\n",
      "[Epoch 36/100] [Batch 57/347] [D loss: 0.430146] [G loss: 0.302401]\n",
      "[Epoch 36/100] [Batch 58/347] [D loss: 0.455706] [G loss: 0.313420]\n",
      "[Epoch 36/100] [Batch 59/347] [D loss: 0.423992] [G loss: 0.312533]\n",
      "[Epoch 36/100] [Batch 60/347] [D loss: 0.404185] [G loss: 0.308814]\n",
      "[Epoch 36/100] [Batch 61/347] [D loss: 0.391105] [G loss: 0.306105]\n",
      "[Epoch 36/100] [Batch 62/347] [D loss: 0.390966] [G loss: 0.318574]\n",
      "[Epoch 36/100] [Batch 63/347] [D loss: 0.407579] [G loss: 0.319765]\n",
      "[Epoch 36/100] [Batch 64/347] [D loss: 0.438183] [G loss: 0.290694]\n",
      "[Epoch 36/100] [Batch 65/347] [D loss: 0.491934] [G loss: 0.309397]\n",
      "[Epoch 36/100] [Batch 66/347] [D loss: 0.421184] [G loss: 0.311227]\n",
      "[Epoch 36/100] [Batch 67/347] [D loss: 0.272117] [G loss: 0.307317]\n",
      "[Epoch 36/100] [Batch 68/347] [D loss: 0.297163] [G loss: 0.306028]\n",
      "[Epoch 36/100] [Batch 69/347] [D loss: 0.415284] [G loss: 0.314278]\n",
      "[Epoch 36/100] [Batch 70/347] [D loss: 0.418219] [G loss: 0.316147]\n",
      "[Epoch 36/100] [Batch 71/347] [D loss: 0.408308] [G loss: 0.319572]\n",
      "[Epoch 36/100] [Batch 72/347] [D loss: 0.404679] [G loss: 0.322252]\n",
      "[Epoch 36/100] [Batch 73/347] [D loss: 0.411849] [G loss: 0.306408]\n",
      "[Epoch 36/100] [Batch 74/347] [D loss: 0.408857] [G loss: 0.326200]\n",
      "[Epoch 36/100] [Batch 75/347] [D loss: 0.414577] [G loss: 0.317709]\n",
      "[Epoch 36/100] [Batch 76/347] [D loss: 0.430057] [G loss: 0.311678]\n",
      "[Epoch 36/100] [Batch 77/347] [D loss: 0.447030] [G loss: 0.307718]\n",
      "[Epoch 36/100] [Batch 78/347] [D loss: 0.460687] [G loss: 0.324598]\n",
      "[Epoch 36/100] [Batch 79/347] [D loss: 0.504680] [G loss: 0.327091]\n",
      "[Epoch 36/100] [Batch 80/347] [D loss: 0.514090] [G loss: 0.321695]\n",
      "[Epoch 36/100] [Batch 81/347] [D loss: 0.511376] [G loss: 0.323702]\n",
      "[Epoch 36/100] [Batch 82/347] [D loss: 0.478361] [G loss: 0.320703]\n",
      "[Epoch 36/100] [Batch 83/347] [D loss: 0.472873] [G loss: 0.310456]\n",
      "[Epoch 36/100] [Batch 84/347] [D loss: 0.509553] [G loss: 0.319789]\n",
      "[Epoch 36/100] [Batch 85/347] [D loss: 0.525760] [G loss: 0.319262]\n",
      "[Epoch 36/100] [Batch 86/347] [D loss: 0.521917] [G loss: 0.312864]\n",
      "[Epoch 36/100] [Batch 87/347] [D loss: 0.521109] [G loss: 0.310553]\n",
      "[Epoch 36/100] [Batch 88/347] [D loss: 0.525650] [G loss: 0.314237]\n",
      "[Epoch 36/100] [Batch 89/347] [D loss: 0.530633] [G loss: 0.318415]\n",
      "[Epoch 36/100] [Batch 90/347] [D loss: 0.527954] [G loss: 0.315955]\n",
      "[Epoch 36/100] [Batch 91/347] [D loss: 0.527591] [G loss: 0.316312]\n",
      "[Epoch 36/100] [Batch 92/347] [D loss: 0.530020] [G loss: 0.319823]\n",
      "[Epoch 36/100] [Batch 93/347] [D loss: 0.529152] [G loss: 0.320373]\n",
      "[Epoch 36/100] [Batch 94/347] [D loss: 0.525634] [G loss: 0.319533]\n",
      "[Epoch 36/100] [Batch 95/347] [D loss: 0.526636] [G loss: 0.323044]\n",
      "[Epoch 36/100] [Batch 96/347] [D loss: 0.523254] [G loss: 0.321232]\n",
      "[Epoch 36/100] [Batch 97/347] [D loss: 0.519597] [G loss: 0.319128]\n",
      "[Epoch 36/100] [Batch 98/347] [D loss: 0.526093] [G loss: 0.327175]\n",
      "[Epoch 36/100] [Batch 99/347] [D loss: 0.530195] [G loss: 0.334211]\n",
      "[Epoch 36/100] [Batch 100/347] [D loss: 0.524312] [G loss: 0.333484]\n",
      "[Epoch 36/100] [Batch 101/347] [D loss: 0.522260] [G loss: 0.331170]\n",
      "[Epoch 36/100] [Batch 102/347] [D loss: 0.528170] [G loss: 0.335852]\n",
      "[Epoch 36/100] [Batch 103/347] [D loss: 0.528825] [G loss: 0.339065]\n",
      "[Epoch 36/100] [Batch 104/347] [D loss: 0.523306] [G loss: 0.332885]\n",
      "[Epoch 36/100] [Batch 105/347] [D loss: 0.524013] [G loss: 0.334447]\n",
      "[Epoch 36/100] [Batch 106/347] [D loss: 0.521079] [G loss: 0.335370]\n",
      "[Epoch 36/100] [Batch 107/347] [D loss: 0.478163] [G loss: 0.329539]\n",
      "[Epoch 36/100] [Batch 108/347] [D loss: 0.266007] [G loss: 0.348593]\n",
      "[Epoch 36/100] [Batch 109/347] [D loss: 0.265784] [G loss: 0.359299]\n",
      "[Epoch 36/100] [Batch 110/347] [D loss: 0.475103] [G loss: 0.352225]\n",
      "[Epoch 36/100] [Batch 111/347] [D loss: 0.307589] [G loss: 0.362126]\n",
      "[Epoch 36/100] [Batch 112/347] [D loss: 0.262993] [G loss: 0.372330]\n",
      "[Epoch 36/100] [Batch 113/347] [D loss: 0.452670] [G loss: 0.381414]\n",
      "[Epoch 36/100] [Batch 114/347] [D loss: 0.528222] [G loss: 0.406008]\n",
      "[Epoch 36/100] [Batch 115/347] [D loss: 0.523548] [G loss: 0.410188]\n",
      "[Epoch 36/100] [Batch 116/347] [D loss: 0.526814] [G loss: 0.406445]\n",
      "[Epoch 36/100] [Batch 117/347] [D loss: 0.510873] [G loss: 0.382220]\n",
      "[Epoch 36/100] [Batch 118/347] [D loss: 0.467136] [G loss: 0.371691]\n",
      "[Epoch 36/100] [Batch 119/347] [D loss: 0.446613] [G loss: 0.363378]\n",
      "[Epoch 36/100] [Batch 120/347] [D loss: 0.386189] [G loss: 0.364287]\n",
      "[Epoch 36/100] [Batch 121/347] [D loss: 0.376988] [G loss: 0.359335]\n",
      "[Epoch 36/100] [Batch 122/347] [D loss: 0.477542] [G loss: 0.353401]\n",
      "[Epoch 36/100] [Batch 123/347] [D loss: 0.519071] [G loss: 0.350205]\n",
      "[Epoch 36/100] [Batch 124/347] [D loss: 0.516036] [G loss: 0.340852]\n",
      "[Epoch 36/100] [Batch 125/347] [D loss: 0.522158] [G loss: 0.345809]\n",
      "[Epoch 36/100] [Batch 126/347] [D loss: 0.519540] [G loss: 0.352690]\n",
      "[Epoch 36/100] [Batch 127/347] [D loss: 0.514223] [G loss: 0.348379]\n",
      "[Epoch 36/100] [Batch 128/347] [D loss: 0.510725] [G loss: 0.337774]\n",
      "[Epoch 36/100] [Batch 129/347] [D loss: 0.469375] [G loss: 0.327545]\n",
      "[Epoch 36/100] [Batch 130/347] [D loss: 0.449670] [G loss: 0.325197]\n",
      "[Epoch 36/100] [Batch 131/347] [D loss: 0.381462] [G loss: 0.320972]\n",
      "[Epoch 36/100] [Batch 132/347] [D loss: 0.263434] [G loss: 0.325058]\n",
      "[Epoch 36/100] [Batch 133/347] [D loss: 0.274566] [G loss: 0.329253]\n",
      "[Epoch 36/100] [Batch 134/347] [D loss: 0.256109] [G loss: 0.340117]\n",
      "[Epoch 36/100] [Batch 135/347] [D loss: 0.241740] [G loss: 0.361428]\n",
      "[Epoch 36/100] [Batch 136/347] [D loss: 0.231598] [G loss: 0.381481]\n",
      "[Epoch 36/100] [Batch 137/347] [D loss: 0.466672] [G loss: 0.384423]\n",
      "[Epoch 36/100] [Batch 138/347] [D loss: 0.464049] [G loss: 0.383938]\n",
      "[Epoch 36/100] [Batch 139/347] [D loss: 0.444698] [G loss: 0.377148]\n",
      "[Epoch 36/100] [Batch 140/347] [D loss: 0.433576] [G loss: 0.379889]\n",
      "[Epoch 36/100] [Batch 141/347] [D loss: 0.438152] [G loss: 0.375609]\n",
      "[Epoch 36/100] [Batch 142/347] [D loss: 0.437217] [G loss: 0.374586]\n",
      "[Epoch 36/100] [Batch 143/347] [D loss: 0.406741] [G loss: 0.394046]\n",
      "[Epoch 36/100] [Batch 144/347] [D loss: 0.402493] [G loss: 0.392358]\n",
      "[Epoch 36/100] [Batch 145/347] [D loss: 0.411156] [G loss: 0.371700]\n",
      "[Epoch 36/100] [Batch 146/347] [D loss: 0.417654] [G loss: 0.346986]\n",
      "[Epoch 36/100] [Batch 147/347] [D loss: 0.442914] [G loss: 0.323599]\n",
      "[Epoch 36/100] [Batch 148/347] [D loss: 0.447958] [G loss: 0.319002]\n",
      "[Epoch 36/100] [Batch 149/347] [D loss: 0.445775] [G loss: 0.304395]\n",
      "[Epoch 36/100] [Batch 150/347] [D loss: 0.450494] [G loss: 0.297919]\n",
      "[Epoch 36/100] [Batch 151/347] [D loss: 0.449202] [G loss: 0.299868]\n",
      "[Epoch 36/100] [Batch 152/347] [D loss: 0.418443] [G loss: 0.294913]\n",
      "[Epoch 36/100] [Batch 153/347] [D loss: 0.390158] [G loss: 0.275048]\n",
      "[Epoch 36/100] [Batch 154/347] [D loss: 0.387241] [G loss: 0.273993]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 36/100] [Batch 155/347] [D loss: 0.406483] [G loss: 0.257269]\n",
      "[Epoch 36/100] [Batch 156/347] [D loss: 0.435400] [G loss: 0.258365]\n",
      "[Epoch 36/100] [Batch 157/347] [D loss: 0.420646] [G loss: 0.269664]\n",
      "[Epoch 36/100] [Batch 158/347] [D loss: 0.395782] [G loss: 0.266099]\n",
      "[Epoch 36/100] [Batch 159/347] [D loss: 0.391548] [G loss: 0.265603]\n",
      "[Epoch 36/100] [Batch 160/347] [D loss: 0.354930] [G loss: 0.271552]\n",
      "[Epoch 36/100] [Batch 161/347] [D loss: 0.351176] [G loss: 0.291712]\n",
      "[Epoch 36/100] [Batch 162/347] [D loss: 0.401817] [G loss: 0.296378]\n",
      "[Epoch 36/100] [Batch 163/347] [D loss: 0.402089] [G loss: 0.292836]\n",
      "[Epoch 36/100] [Batch 164/347] [D loss: 0.383047] [G loss: 0.307554]\n",
      "[Epoch 36/100] [Batch 165/347] [D loss: 0.373467] [G loss: 0.305885]\n",
      "[Epoch 36/100] [Batch 166/347] [D loss: 0.393589] [G loss: 0.302945]\n",
      "[Epoch 36/100] [Batch 167/347] [D loss: 0.354187] [G loss: 0.327934]\n",
      "[Epoch 36/100] [Batch 168/347] [D loss: 0.324934] [G loss: 0.344726]\n",
      "[Epoch 36/100] [Batch 169/347] [D loss: 0.437664] [G loss: 0.348445]\n",
      "[Epoch 36/100] [Batch 170/347] [D loss: 0.505971] [G loss: 0.363071]\n",
      "[Epoch 36/100] [Batch 171/347] [D loss: 0.528485] [G loss: 0.378193]\n",
      "[Epoch 36/100] [Batch 172/347] [D loss: 0.534922] [G loss: 0.386255]\n",
      "[Epoch 36/100] [Batch 173/347] [D loss: 0.503640] [G loss: 0.376947]\n",
      "[Epoch 36/100] [Batch 174/347] [D loss: 0.501668] [G loss: 0.375449]\n",
      "[Epoch 36/100] [Batch 175/347] [D loss: 0.535468] [G loss: 0.386199]\n",
      "[Epoch 36/100] [Batch 176/347] [D loss: 0.548831] [G loss: 0.400252]\n",
      "[Epoch 36/100] [Batch 177/347] [D loss: 0.550644] [G loss: 0.401996]\n",
      "[Epoch 36/100] [Batch 178/347] [D loss: 0.546106] [G loss: 0.396681]\n",
      "[Epoch 36/100] [Batch 179/347] [D loss: 0.541149] [G loss: 0.390538]\n",
      "[Epoch 36/100] [Batch 180/347] [D loss: 0.537394] [G loss: 0.384355]\n",
      "[Epoch 36/100] [Batch 181/347] [D loss: 0.538279] [G loss: 0.385304]\n",
      "[Epoch 36/100] [Batch 182/347] [D loss: 0.537750] [G loss: 0.383396]\n",
      "[Epoch 36/100] [Batch 183/347] [D loss: 0.540300] [G loss: 0.387544]\n",
      "[Epoch 36/100] [Batch 184/347] [D loss: 0.543789] [G loss: 0.391463]\n",
      "[Epoch 36/100] [Batch 185/347] [D loss: 0.544104] [G loss: 0.390026]\n",
      "[Epoch 36/100] [Batch 186/347] [D loss: 0.544484] [G loss: 0.390082]\n",
      "[Epoch 36/100] [Batch 187/347] [D loss: 0.541520] [G loss: 0.384896]\n",
      "[Epoch 36/100] [Batch 188/347] [D loss: 0.540008] [G loss: 0.381643]\n",
      "[Epoch 36/100] [Batch 189/347] [D loss: 0.538988] [G loss: 0.380946]\n",
      "[Epoch 36/100] [Batch 190/347] [D loss: 0.530653] [G loss: 0.369116]\n",
      "[Epoch 36/100] [Batch 191/347] [D loss: 0.517575] [G loss: 0.356018]\n",
      "[Epoch 36/100] [Batch 192/347] [D loss: 0.514464] [G loss: 0.357308]\n",
      "[Epoch 36/100] [Batch 193/347] [D loss: 0.523368] [G loss: 0.365259]\n",
      "[Epoch 36/100] [Batch 194/347] [D loss: 0.530120] [G loss: 0.360077]\n",
      "[Epoch 36/100] [Batch 195/347] [D loss: 0.528756] [G loss: 0.351700]\n",
      "[Epoch 36/100] [Batch 196/347] [D loss: 0.523747] [G loss: 0.345989]\n",
      "[Epoch 36/100] [Batch 197/347] [D loss: 0.513434] [G loss: 0.343231]\n",
      "[Epoch 36/100] [Batch 198/347] [D loss: 0.485472] [G loss: 0.340292]\n",
      "[Epoch 36/100] [Batch 199/347] [D loss: 0.487103] [G loss: 0.335892]\n",
      "[Epoch 36/100] [Batch 200/347] [D loss: 0.517429] [G loss: 0.337326]\n",
      "[Epoch 36/100] [Batch 201/347] [D loss: 0.520465] [G loss: 0.336329]\n",
      "[Epoch 36/100] [Batch 202/347] [D loss: 0.522309] [G loss: 0.330022]\n",
      "[Epoch 36/100] [Batch 203/347] [D loss: 0.524284] [G loss: 0.324855]\n",
      "[Epoch 36/100] [Batch 204/347] [D loss: 0.524794] [G loss: 0.323999]\n",
      "[Epoch 36/100] [Batch 205/347] [D loss: 0.524523] [G loss: 0.324105]\n",
      "[Epoch 36/100] [Batch 206/347] [D loss: 0.524848] [G loss: 0.327898]\n",
      "[Epoch 36/100] [Batch 207/347] [D loss: 0.528023] [G loss: 0.337838]\n",
      "[Epoch 36/100] [Batch 208/347] [D loss: 0.529393] [G loss: 0.338075]\n",
      "[Epoch 36/100] [Batch 209/347] [D loss: 0.521457] [G loss: 0.331890]\n",
      "[Epoch 36/100] [Batch 210/347] [D loss: 0.521057] [G loss: 0.338046]\n",
      "[Epoch 36/100] [Batch 211/347] [D loss: 0.522535] [G loss: 0.336566]\n",
      "[Epoch 36/100] [Batch 212/347] [D loss: 0.430183] [G loss: 0.329717]\n",
      "[Epoch 36/100] [Batch 213/347] [D loss: 0.399832] [G loss: 0.335720]\n",
      "[Epoch 36/100] [Batch 214/347] [D loss: 0.261312] [G loss: 0.344585]\n",
      "[Epoch 36/100] [Batch 215/347] [D loss: 0.261649] [G loss: 0.349365]\n",
      "[Epoch 36/100] [Batch 216/347] [D loss: 0.466683] [G loss: 0.347422]\n",
      "[Epoch 36/100] [Batch 217/347] [D loss: 0.506197] [G loss: 0.351392]\n",
      "[Epoch 36/100] [Batch 218/347] [D loss: 0.533222] [G loss: 0.364852]\n",
      "[Epoch 36/100] [Batch 219/347] [D loss: 0.531929] [G loss: 0.379551]\n",
      "[Epoch 36/100] [Batch 220/347] [D loss: 0.536096] [G loss: 0.397268]\n",
      "[Epoch 36/100] [Batch 221/347] [D loss: 0.538580] [G loss: 0.400256]\n",
      "[Epoch 36/100] [Batch 222/347] [D loss: 0.530680] [G loss: 0.393524]\n",
      "[Epoch 36/100] [Batch 223/347] [D loss: 0.529536] [G loss: 0.393100]\n",
      "[Epoch 36/100] [Batch 224/347] [D loss: 0.530011] [G loss: 0.389790]\n",
      "[Epoch 36/100] [Batch 225/347] [D loss: 0.513086] [G loss: 0.375022]\n",
      "[Epoch 36/100] [Batch 226/347] [D loss: 0.502647] [G loss: 0.351364]\n",
      "[Epoch 36/100] [Batch 227/347] [D loss: 0.503313] [G loss: 0.325652]\n",
      "[Epoch 36/100] [Batch 228/347] [D loss: 0.507064] [G loss: 0.323118]\n",
      "[Epoch 36/100] [Batch 229/347] [D loss: 0.514916] [G loss: 0.332581]\n",
      "[Epoch 36/100] [Batch 230/347] [D loss: 0.517837] [G loss: 0.333758]\n",
      "[Epoch 36/100] [Batch 231/347] [D loss: 0.513493] [G loss: 0.325180]\n",
      "[Epoch 36/100] [Batch 232/347] [D loss: 0.514131] [G loss: 0.324576]\n",
      "[Epoch 36/100] [Batch 233/347] [D loss: 0.508072] [G loss: 0.324906]\n",
      "[Epoch 36/100] [Batch 234/347] [D loss: 0.496561] [G loss: 0.328375]\n",
      "[Epoch 36/100] [Batch 235/347] [D loss: 0.494522] [G loss: 0.334420]\n",
      "[Epoch 36/100] [Batch 236/347] [D loss: 0.503090] [G loss: 0.336701]\n",
      "[Epoch 36/100] [Batch 237/347] [D loss: 0.516489] [G loss: 0.337624]\n",
      "[Epoch 36/100] [Batch 238/347] [D loss: 0.527646] [G loss: 0.338537]\n",
      "[Epoch 36/100] [Batch 239/347] [D loss: 0.523027] [G loss: 0.333647]\n",
      "[Epoch 36/100] [Batch 240/347] [D loss: 0.518115] [G loss: 0.327835]\n",
      "[Epoch 36/100] [Batch 241/347] [D loss: 0.514967] [G loss: 0.320580]\n",
      "[Epoch 36/100] [Batch 242/347] [D loss: 0.516058] [G loss: 0.317632]\n",
      "[Epoch 36/100] [Batch 243/347] [D loss: 0.523391] [G loss: 0.324935]\n",
      "[Epoch 36/100] [Batch 244/347] [D loss: 0.528347] [G loss: 0.333849]\n",
      "[Epoch 36/100] [Batch 245/347] [D loss: 0.513390] [G loss: 0.332591]\n",
      "[Epoch 36/100] [Batch 246/347] [D loss: 0.498537] [G loss: 0.325527]\n",
      "[Epoch 36/100] [Batch 247/347] [D loss: 0.500907] [G loss: 0.296844]\n",
      "[Epoch 36/100] [Batch 248/347] [D loss: 0.503781] [G loss: 0.287715]\n",
      "[Epoch 36/100] [Batch 249/347] [D loss: 0.499153] [G loss: 0.287971]\n",
      "[Epoch 36/100] [Batch 250/347] [D loss: 0.498716] [G loss: 0.309574]\n",
      "[Epoch 36/100] [Batch 251/347] [D loss: 0.500176] [G loss: 0.326772]\n",
      "[Epoch 36/100] [Batch 252/347] [D loss: 0.500385] [G loss: 0.329617]\n",
      "[Epoch 36/100] [Batch 253/347] [D loss: 0.506379] [G loss: 0.329783]\n",
      "[Epoch 36/100] [Batch 254/347] [D loss: 0.511915] [G loss: 0.328039]\n",
      "[Epoch 36/100] [Batch 255/347] [D loss: 0.488336] [G loss: 0.326277]\n",
      "[Epoch 36/100] [Batch 256/347] [D loss: 0.485321] [G loss: 0.331060]\n",
      "[Epoch 36/100] [Batch 257/347] [D loss: 0.501190] [G loss: 0.332666]\n",
      "[Epoch 36/100] [Batch 258/347] [D loss: 0.474813] [G loss: 0.327007]\n",
      "[Epoch 36/100] [Batch 259/347] [D loss: 0.450191] [G loss: 0.312573]\n",
      "[Epoch 36/100] [Batch 260/347] [D loss: 0.414740] [G loss: 0.308544]\n",
      "[Epoch 36/100] [Batch 261/347] [D loss: 0.422214] [G loss: 0.314147]\n",
      "[Epoch 36/100] [Batch 262/347] [D loss: 0.473606] [G loss: 0.307324]\n",
      "[Epoch 36/100] [Batch 263/347] [D loss: 0.450572] [G loss: 0.303346]\n",
      "[Epoch 36/100] [Batch 264/347] [D loss: 0.413751] [G loss: 0.303656]\n",
      "[Epoch 36/100] [Batch 265/347] [D loss: 0.418584] [G loss: 0.299150]\n",
      "[Epoch 36/100] [Batch 266/347] [D loss: 0.433281] [G loss: 0.293970]\n",
      "[Epoch 36/100] [Batch 267/347] [D loss: 0.441965] [G loss: 0.290616]\n",
      "[Epoch 36/100] [Batch 268/347] [D loss: 0.401109] [G loss: 0.294158]\n",
      "[Epoch 36/100] [Batch 269/347] [D loss: 0.394377] [G loss: 0.295363]\n",
      "[Epoch 36/100] [Batch 270/347] [D loss: 0.429499] [G loss: 0.292300]\n",
      "[Epoch 36/100] [Batch 271/347] [D loss: 0.458235] [G loss: 0.289187]\n",
      "[Epoch 36/100] [Batch 272/347] [D loss: 0.474933] [G loss: 0.291525]\n",
      "[Epoch 36/100] [Batch 273/347] [D loss: 0.424153] [G loss: 0.300742]\n",
      "[Epoch 36/100] [Batch 274/347] [D loss: 0.446597] [G loss: 0.324526]\n",
      "[Epoch 36/100] [Batch 275/347] [D loss: 0.415942] [G loss: 0.338829]\n",
      "[Epoch 36/100] [Batch 276/347] [D loss: 0.418052] [G loss: 0.334882]\n",
      "[Epoch 36/100] [Batch 277/347] [D loss: 0.437677] [G loss: 0.341344]\n",
      "[Epoch 36/100] [Batch 278/347] [D loss: 0.495126] [G loss: 0.355072]\n",
      "[Epoch 36/100] [Batch 279/347] [D loss: 0.480649] [G loss: 0.358829]\n",
      "[Epoch 36/100] [Batch 280/347] [D loss: 0.468251] [G loss: 0.366248]\n",
      "[Epoch 36/100] [Batch 281/347] [D loss: 0.471832] [G loss: 0.367200]\n",
      "[Epoch 36/100] [Batch 282/347] [D loss: 0.482333] [G loss: 0.366652]\n",
      "[Epoch 36/100] [Batch 283/347] [D loss: 0.443981] [G loss: 0.367321]\n",
      "[Epoch 36/100] [Batch 284/347] [D loss: 0.436414] [G loss: 0.368432]\n",
      "[Epoch 36/100] [Batch 285/347] [D loss: 0.480031] [G loss: 0.365013]\n",
      "[Epoch 36/100] [Batch 286/347] [D loss: 0.501631] [G loss: 0.362797]\n",
      "[Epoch 36/100] [Batch 287/347] [D loss: 0.501087] [G loss: 0.356179]\n",
      "[Epoch 36/100] [Batch 288/347] [D loss: 0.482622] [G loss: 0.336576]\n",
      "[Epoch 36/100] [Batch 289/347] [D loss: 0.479390] [G loss: 0.327398]\n",
      "[Epoch 36/100] [Batch 290/347] [D loss: 0.494806] [G loss: 0.334105]\n",
      "[Epoch 36/100] [Batch 291/347] [D loss: 0.480573] [G loss: 0.325249]\n",
      "[Epoch 36/100] [Batch 292/347] [D loss: 0.477416] [G loss: 0.326895]\n",
      "[Epoch 36/100] [Batch 293/347] [D loss: 0.458353] [G loss: 0.342180]\n",
      "[Epoch 36/100] [Batch 294/347] [D loss: 0.432303] [G loss: 0.338979]\n",
      "[Epoch 36/100] [Batch 295/347] [D loss: 0.274649] [G loss: 0.325204]\n",
      "[Epoch 36/100] [Batch 296/347] [D loss: 0.263862] [G loss: 0.323834]\n",
      "[Epoch 36/100] [Batch 297/347] [D loss: 0.468888] [G loss: 0.337531]\n",
      "[Epoch 36/100] [Batch 298/347] [D loss: 0.512554] [G loss: 0.329595]\n",
      "[Epoch 36/100] [Batch 299/347] [D loss: 0.495592] [G loss: 0.325974]\n",
      "[Epoch 36/100] [Batch 300/347] [D loss: 0.467727] [G loss: 0.319083]\n",
      "[Epoch 36/100] [Batch 301/347] [D loss: 0.466967] [G loss: 0.312595]\n",
      "[Epoch 36/100] [Batch 302/347] [D loss: 0.484421] [G loss: 0.316585]\n",
      "[Epoch 36/100] [Batch 303/347] [D loss: 0.469422] [G loss: 0.295325]\n",
      "[Epoch 36/100] [Batch 304/347] [D loss: 0.470863] [G loss: 0.275422]\n",
      "[Epoch 36/100] [Batch 305/347] [D loss: 0.477793] [G loss: 0.276243]\n",
      "[Epoch 36/100] [Batch 306/347] [D loss: 0.371283] [G loss: 0.266503]\n",
      "[Epoch 36/100] [Batch 307/347] [D loss: 0.290417] [G loss: 0.273895]\n",
      "[Epoch 36/100] [Batch 308/347] [D loss: 0.343767] [G loss: 0.276203]\n",
      "[Epoch 36/100] [Batch 309/347] [D loss: 0.481544] [G loss: 0.293215]\n",
      "[Epoch 36/100] [Batch 310/347] [D loss: 0.513453] [G loss: 0.322745]\n",
      "[Epoch 36/100] [Batch 311/347] [D loss: 0.514955] [G loss: 0.327995]\n",
      "[Epoch 36/100] [Batch 312/347] [D loss: 0.513799] [G loss: 0.329775]\n",
      "[Epoch 36/100] [Batch 313/347] [D loss: 0.509681] [G loss: 0.330906]\n",
      "[Epoch 36/100] [Batch 314/347] [D loss: 0.488511] [G loss: 0.326083]\n",
      "[Epoch 36/100] [Batch 315/347] [D loss: 0.457817] [G loss: 0.317936]\n",
      "[Epoch 36/100] [Batch 316/347] [D loss: 0.457166] [G loss: 0.302071]\n",
      "[Epoch 36/100] [Batch 317/347] [D loss: 0.473846] [G loss: 0.291157]\n",
      "[Epoch 36/100] [Batch 318/347] [D loss: 0.489488] [G loss: 0.306783]\n",
      "[Epoch 36/100] [Batch 319/347] [D loss: 0.508289] [G loss: 0.338932]\n",
      "[Epoch 36/100] [Batch 320/347] [D loss: 0.517062] [G loss: 0.351793]\n",
      "[Epoch 36/100] [Batch 321/347] [D loss: 0.503591] [G loss: 0.340626]\n",
      "[Epoch 36/100] [Batch 322/347] [D loss: 0.493499] [G loss: 0.326270]\n",
      "[Epoch 36/100] [Batch 323/347] [D loss: 0.481343] [G loss: 0.323881]\n",
      "[Epoch 36/100] [Batch 324/347] [D loss: 0.478585] [G loss: 0.325491]\n",
      "[Epoch 36/100] [Batch 325/347] [D loss: 0.410105] [G loss: 0.313471]\n",
      "[Epoch 36/100] [Batch 326/347] [D loss: 0.391048] [G loss: 0.302482]\n",
      "[Epoch 36/100] [Batch 327/347] [D loss: 0.437896] [G loss: 0.300057]\n",
      "[Epoch 36/100] [Batch 328/347] [D loss: 0.468293] [G loss: 0.296684]\n",
      "[Epoch 36/100] [Batch 329/347] [D loss: 0.408763] [G loss: 0.288238]\n",
      "[Epoch 36/100] [Batch 330/347] [D loss: 0.397837] [G loss: 0.281243]\n",
      "[Epoch 36/100] [Batch 331/347] [D loss: 0.441618] [G loss: 0.289279]\n",
      "[Epoch 36/100] [Batch 332/347] [D loss: 0.498832] [G loss: 0.308879]\n",
      "[Epoch 36/100] [Batch 333/347] [D loss: 0.512704] [G loss: 0.320206]\n",
      "[Epoch 36/100] [Batch 334/347] [D loss: 0.502851] [G loss: 0.321523]\n",
      "[Epoch 36/100] [Batch 335/347] [D loss: 0.482144] [G loss: 0.309592]\n",
      "[Epoch 36/100] [Batch 336/347] [D loss: 0.470232] [G loss: 0.297172]\n",
      "[Epoch 36/100] [Batch 337/347] [D loss: 0.475236] [G loss: 0.301149]\n",
      "[Epoch 36/100] [Batch 338/347] [D loss: 0.494620] [G loss: 0.316119]\n",
      "[Epoch 36/100] [Batch 339/347] [D loss: 0.512151] [G loss: 0.322190]\n",
      "[Epoch 36/100] [Batch 340/347] [D loss: 0.515884] [G loss: 0.323527]\n",
      "[Epoch 36/100] [Batch 341/347] [D loss: 0.501805] [G loss: 0.319891]\n",
      "[Epoch 36/100] [Batch 342/347] [D loss: 0.494060] [G loss: 0.313463]\n",
      "[Epoch 36/100] [Batch 343/347] [D loss: 0.509220] [G loss: 0.319499]\n",
      "[Epoch 36/100] [Batch 344/347] [D loss: 0.462783] [G loss: 0.308720]\n",
      "[Epoch 36/100] [Batch 345/347] [D loss: 0.421143] [G loss: 0.287814]\n",
      "[Epoch 36/100] [Batch 346/347] [D loss: 0.369502] [G loss: 0.288315]\n",
      "[Epoch 36/100] [Batch 347/347] [D loss: 0.255519] [G loss: 0.302371]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 37/100] [Batch 1/347] [D loss: 0.493432] [G loss: 0.314155]\n",
      "[Epoch 37/100] [Batch 2/347] [D loss: 0.497925] [G loss: 0.319561]\n",
      "[Epoch 37/100] [Batch 3/347] [D loss: 0.510788] [G loss: 0.332349]\n",
      "[Epoch 37/100] [Batch 4/347] [D loss: 0.511560] [G loss: 0.335412]\n",
      "[Epoch 37/100] [Batch 5/347] [D loss: 0.510533] [G loss: 0.336067]\n",
      "[Epoch 37/100] [Batch 6/347] [D loss: 0.513374] [G loss: 0.338888]\n",
      "[Epoch 37/100] [Batch 7/347] [D loss: 0.509712] [G loss: 0.334574]\n",
      "[Epoch 37/100] [Batch 8/347] [D loss: 0.501524] [G loss: 0.330010]\n",
      "[Epoch 37/100] [Batch 9/347] [D loss: 0.488692] [G loss: 0.318548]\n",
      "[Epoch 37/100] [Batch 10/347] [D loss: 0.491290] [G loss: 0.317476]\n",
      "[Epoch 37/100] [Batch 11/347] [D loss: 0.507203] [G loss: 0.329480]\n",
      "[Epoch 37/100] [Batch 12/347] [D loss: 0.511447] [G loss: 0.331710]\n",
      "[Epoch 37/100] [Batch 13/347] [D loss: 0.514105] [G loss: 0.333123]\n",
      "[Epoch 37/100] [Batch 14/347] [D loss: 0.514168] [G loss: 0.332846]\n",
      "[Epoch 37/100] [Batch 15/347] [D loss: 0.507736] [G loss: 0.326138]\n",
      "[Epoch 37/100] [Batch 16/347] [D loss: 0.501141] [G loss: 0.319158]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 37/100] [Batch 17/347] [D loss: 0.486748] [G loss: 0.305918]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 37/100] [Batch 18/347] [D loss: 0.470757] [G loss: 0.303113]\n",
      "[Epoch 37/100] [Batch 19/347] [D loss: 0.480511] [G loss: 0.303021]\n",
      "[Epoch 37/100] [Batch 20/347] [D loss: 0.509615] [G loss: 0.312884]\n",
      "[Epoch 37/100] [Batch 21/347] [D loss: 0.509353] [G loss: 0.306404]\n",
      "[Epoch 37/100] [Batch 22/347] [D loss: 0.502595] [G loss: 0.299054]\n",
      "[Epoch 37/100] [Batch 23/347] [D loss: 0.485520] [G loss: 0.290647]\n",
      "[Epoch 37/100] [Batch 24/347] [D loss: 0.483455] [G loss: 0.287943]\n",
      "[Epoch 37/100] [Batch 25/347] [D loss: 0.493501] [G loss: 0.285674]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 37/100] [Batch 26/347] [D loss: 0.446231] [G loss: 0.277269]\n",
      "[Epoch 37/100] [Batch 27/347] [D loss: 0.304085] [G loss: 0.294253]\n",
      "[Epoch 37/100] [Batch 28/347] [D loss: 0.312102] [G loss: 0.305984]\n",
      "[Epoch 37/100] [Batch 29/347] [D loss: 0.488740] [G loss: 0.302568]\n",
      "[Epoch 37/100] [Batch 30/347] [D loss: 0.462423] [G loss: 0.311690]\n",
      "[Epoch 37/100] [Batch 31/347] [D loss: 0.423243] [G loss: 0.316247]\n",
      "[Epoch 37/100] [Batch 32/347] [D loss: 0.356306] [G loss: 0.315488]\n",
      "[Epoch 37/100] [Batch 33/347] [D loss: 0.373706] [G loss: 0.310331]\n",
      "[Epoch 37/100] [Batch 34/347] [D loss: 0.450165] [G loss: 0.313024]\n",
      "[Epoch 37/100] [Batch 35/347] [D loss: 0.446324] [G loss: 0.313285]\n",
      "[Epoch 37/100] [Batch 36/347] [D loss: 0.475796] [G loss: 0.308856]\n",
      "[Epoch 37/100] [Batch 37/347] [D loss: 0.434161] [G loss: 0.301414]\n",
      "[Epoch 37/100] [Batch 38/347] [D loss: 0.406926] [G loss: 0.288999]\n",
      "[Epoch 37/100] [Batch 39/347] [D loss: 0.436778] [G loss: 0.284350]\n",
      "[Epoch 37/100] [Batch 40/347] [D loss: 0.483400] [G loss: 0.280784]\n",
      "[Epoch 37/100] [Batch 41/347] [D loss: 0.483348] [G loss: 0.277148]\n",
      "[Epoch 37/100] [Batch 42/347] [D loss: 0.483536] [G loss: 0.279268]\n",
      "[Epoch 37/100] [Batch 43/347] [D loss: 0.483123] [G loss: 0.294768]\n",
      "[Epoch 37/100] [Batch 44/347] [D loss: 0.490485] [G loss: 0.306733]\n",
      "[Epoch 37/100] [Batch 45/347] [D loss: 0.509570] [G loss: 0.322453]\n",
      "[Epoch 37/100] [Batch 46/347] [D loss: 0.507158] [G loss: 0.315944]\n",
      "[Epoch 37/100] [Batch 47/347] [D loss: 0.483829] [G loss: 0.292662]\n",
      "[Epoch 37/100] [Batch 48/347] [D loss: 0.398466] [G loss: 0.281337]\n",
      "[Epoch 37/100] [Batch 49/347] [D loss: 0.394940] [G loss: 0.281783]\n",
      "[Epoch 37/100] [Batch 50/347] [D loss: 0.314944] [G loss: 0.295466]\n",
      "[Epoch 37/100] [Batch 51/347] [D loss: 0.298021] [G loss: 0.309431]\n",
      "[Epoch 37/100] [Batch 52/347] [D loss: 0.392652] [G loss: 0.311442]\n",
      "[Epoch 37/100] [Batch 53/347] [D loss: 0.464082] [G loss: 0.308419]\n",
      "[Epoch 37/100] [Batch 54/347] [D loss: 0.409828] [G loss: 0.308430]\n",
      "[Epoch 37/100] [Batch 55/347] [D loss: 0.398075] [G loss: 0.332957]\n",
      "[Epoch 37/100] [Batch 56/347] [D loss: 0.402423] [G loss: 0.320032]\n",
      "[Epoch 37/100] [Batch 57/347] [D loss: 0.416951] [G loss: 0.305395]\n",
      "[Epoch 37/100] [Batch 58/347] [D loss: 0.441967] [G loss: 0.316198]\n",
      "[Epoch 37/100] [Batch 59/347] [D loss: 0.408289] [G loss: 0.314926]\n",
      "[Epoch 37/100] [Batch 60/347] [D loss: 0.387661] [G loss: 0.310903]\n",
      "[Epoch 37/100] [Batch 61/347] [D loss: 0.371998] [G loss: 0.307845]\n",
      "[Epoch 37/100] [Batch 62/347] [D loss: 0.374491] [G loss: 0.318691]\n",
      "[Epoch 37/100] [Batch 63/347] [D loss: 0.395157] [G loss: 0.319295]\n",
      "[Epoch 37/100] [Batch 64/347] [D loss: 0.426461] [G loss: 0.290671]\n",
      "[Epoch 37/100] [Batch 65/347] [D loss: 0.485010] [G loss: 0.308724]\n",
      "[Epoch 37/100] [Batch 66/347] [D loss: 0.412146] [G loss: 0.309929]\n",
      "[Epoch 37/100] [Batch 67/347] [D loss: 0.260129] [G loss: 0.306479]\n",
      "[Epoch 37/100] [Batch 68/347] [D loss: 0.283415] [G loss: 0.306022]\n",
      "[Epoch 37/100] [Batch 69/347] [D loss: 0.401695] [G loss: 0.313114]\n",
      "[Epoch 37/100] [Batch 70/347] [D loss: 0.404728] [G loss: 0.315210]\n",
      "[Epoch 37/100] [Batch 71/347] [D loss: 0.393346] [G loss: 0.318852]\n",
      "[Epoch 37/100] [Batch 72/347] [D loss: 0.389499] [G loss: 0.321505]\n",
      "[Epoch 37/100] [Batch 73/347] [D loss: 0.394780] [G loss: 0.307976]\n",
      "[Epoch 37/100] [Batch 74/347] [D loss: 0.391662] [G loss: 0.327974]\n",
      "[Epoch 37/100] [Batch 75/347] [D loss: 0.402274] [G loss: 0.319399]\n",
      "[Epoch 37/100] [Batch 76/347] [D loss: 0.420512] [G loss: 0.310474]\n",
      "[Epoch 37/100] [Batch 77/347] [D loss: 0.434551] [G loss: 0.309677]\n",
      "[Epoch 37/100] [Batch 78/347] [D loss: 0.445312] [G loss: 0.326226]\n",
      "[Epoch 37/100] [Batch 79/347] [D loss: 0.500120] [G loss: 0.330485]\n",
      "[Epoch 37/100] [Batch 80/347] [D loss: 0.513411] [G loss: 0.325394]\n",
      "[Epoch 37/100] [Batch 81/347] [D loss: 0.508832] [G loss: 0.328241]\n",
      "[Epoch 37/100] [Batch 82/347] [D loss: 0.467354] [G loss: 0.325040]\n",
      "[Epoch 37/100] [Batch 83/347] [D loss: 0.460777] [G loss: 0.316826]\n",
      "[Epoch 37/100] [Batch 84/347] [D loss: 0.505983] [G loss: 0.326835]\n",
      "[Epoch 37/100] [Batch 85/347] [D loss: 0.528100] [G loss: 0.326460]\n",
      "[Epoch 37/100] [Batch 86/347] [D loss: 0.524310] [G loss: 0.319983]\n",
      "[Epoch 37/100] [Batch 87/347] [D loss: 0.523836] [G loss: 0.317539]\n",
      "[Epoch 37/100] [Batch 88/347] [D loss: 0.528983] [G loss: 0.320941]\n",
      "[Epoch 37/100] [Batch 89/347] [D loss: 0.534752] [G loss: 0.325193]\n",
      "[Epoch 37/100] [Batch 90/347] [D loss: 0.532069] [G loss: 0.322613]\n",
      "[Epoch 37/100] [Batch 91/347] [D loss: 0.531856] [G loss: 0.322848]\n",
      "[Epoch 37/100] [Batch 92/347] [D loss: 0.534586] [G loss: 0.326599]\n",
      "[Epoch 37/100] [Batch 93/347] [D loss: 0.533864] [G loss: 0.327210]\n",
      "[Epoch 37/100] [Batch 94/347] [D loss: 0.529952] [G loss: 0.326499]\n",
      "[Epoch 37/100] [Batch 95/347] [D loss: 0.531050] [G loss: 0.330178]\n",
      "[Epoch 37/100] [Batch 96/347] [D loss: 0.527447] [G loss: 0.328778]\n",
      "[Epoch 37/100] [Batch 97/347] [D loss: 0.523687] [G loss: 0.326922]\n",
      "[Epoch 37/100] [Batch 98/347] [D loss: 0.530986] [G loss: 0.335404]\n",
      "[Epoch 37/100] [Batch 99/347] [D loss: 0.535149] [G loss: 0.342939]\n",
      "[Epoch 37/100] [Batch 100/347] [D loss: 0.527981] [G loss: 0.342839]\n",
      "[Epoch 37/100] [Batch 101/347] [D loss: 0.526081] [G loss: 0.341248]\n",
      "[Epoch 37/100] [Batch 102/347] [D loss: 0.533302] [G loss: 0.346004]\n",
      "[Epoch 37/100] [Batch 103/347] [D loss: 0.533915] [G loss: 0.350005]\n",
      "[Epoch 37/100] [Batch 104/347] [D loss: 0.528225] [G loss: 0.344293]\n",
      "[Epoch 37/100] [Batch 105/347] [D loss: 0.529119] [G loss: 0.346336]\n",
      "[Epoch 37/100] [Batch 106/347] [D loss: 0.525232] [G loss: 0.347757]\n",
      "[Epoch 37/100] [Batch 107/347] [D loss: 0.478145] [G loss: 0.341886]\n",
      "[Epoch 37/100] [Batch 108/347] [D loss: 0.250520] [G loss: 0.361113]\n",
      "[Epoch 37/100] [Batch 109/347] [D loss: 0.249921] [G loss: 0.372022]\n",
      "[Epoch 37/100] [Batch 110/347] [D loss: 0.468598] [G loss: 0.365217]\n",
      "[Epoch 37/100] [Batch 111/347] [D loss: 0.294482] [G loss: 0.374976]\n",
      "[Epoch 37/100] [Batch 112/347] [D loss: 0.246183] [G loss: 0.385141]\n",
      "[Epoch 37/100] [Batch 113/347] [D loss: 0.450656] [G loss: 0.394229]\n",
      "[Epoch 37/100] [Batch 114/347] [D loss: 0.527895] [G loss: 0.418354]\n",
      "[Epoch 37/100] [Batch 115/347] [D loss: 0.521676] [G loss: 0.422216]\n",
      "[Epoch 37/100] [Batch 116/347] [D loss: 0.527389] [G loss: 0.418319]\n",
      "[Epoch 37/100] [Batch 117/347] [D loss: 0.511206] [G loss: 0.393475]\n",
      "[Epoch 37/100] [Batch 118/347] [D loss: 0.459788] [G loss: 0.382680]\n",
      "[Epoch 37/100] [Batch 119/347] [D loss: 0.433969] [G loss: 0.374172]\n",
      "[Epoch 37/100] [Batch 120/347] [D loss: 0.367830] [G loss: 0.375056]\n",
      "[Epoch 37/100] [Batch 121/347] [D loss: 0.356389] [G loss: 0.370419]\n",
      "[Epoch 37/100] [Batch 122/347] [D loss: 0.474057] [G loss: 0.364701]\n",
      "[Epoch 37/100] [Batch 123/347] [D loss: 0.523623] [G loss: 0.362264]\n",
      "[Epoch 37/100] [Batch 124/347] [D loss: 0.520853] [G loss: 0.353072]\n",
      "[Epoch 37/100] [Batch 125/347] [D loss: 0.527105] [G loss: 0.358792]\n",
      "[Epoch 37/100] [Batch 126/347] [D loss: 0.521880] [G loss: 0.366097]\n",
      "[Epoch 37/100] [Batch 127/347] [D loss: 0.515318] [G loss: 0.362454]\n",
      "[Epoch 37/100] [Batch 128/347] [D loss: 0.512261] [G loss: 0.352033]\n",
      "[Epoch 37/100] [Batch 129/347] [D loss: 0.461410] [G loss: 0.341954]\n",
      "[Epoch 37/100] [Batch 130/347] [D loss: 0.440515] [G loss: 0.339486]\n",
      "[Epoch 37/100] [Batch 131/347] [D loss: 0.374413] [G loss: 0.334882]\n",
      "[Epoch 37/100] [Batch 132/347] [D loss: 0.256359] [G loss: 0.338235]\n",
      "[Epoch 37/100] [Batch 133/347] [D loss: 0.265121] [G loss: 0.341991]\n",
      "[Epoch 37/100] [Batch 134/347] [D loss: 0.249074] [G loss: 0.352047]\n",
      "[Epoch 37/100] [Batch 135/347] [D loss: 0.239857] [G loss: 0.372824]\n",
      "[Epoch 37/100] [Batch 136/347] [D loss: 0.229693] [G loss: 0.392494]\n",
      "[Epoch 37/100] [Batch 137/347] [D loss: 0.466156] [G loss: 0.394907]\n",
      "[Epoch 37/100] [Batch 138/347] [D loss: 0.461594] [G loss: 0.394022]\n",
      "[Epoch 37/100] [Batch 139/347] [D loss: 0.441132] [G loss: 0.387093]\n",
      "[Epoch 37/100] [Batch 140/347] [D loss: 0.428089] [G loss: 0.389522]\n",
      "[Epoch 37/100] [Batch 141/347] [D loss: 0.433407] [G loss: 0.385479]\n",
      "[Epoch 37/100] [Batch 142/347] [D loss: 0.433406] [G loss: 0.383446]\n",
      "[Epoch 37/100] [Batch 143/347] [D loss: 0.399748] [G loss: 0.388910]\n",
      "[Epoch 37/100] [Batch 144/347] [D loss: 0.394910] [G loss: 0.388129]\n",
      "[Epoch 37/100] [Batch 145/347] [D loss: 0.403041] [G loss: 0.368266]\n",
      "[Epoch 37/100] [Batch 146/347] [D loss: 0.408676] [G loss: 0.344538]\n",
      "[Epoch 37/100] [Batch 147/347] [D loss: 0.437063] [G loss: 0.336872]\n",
      "[Epoch 37/100] [Batch 148/347] [D loss: 0.442966] [G loss: 0.333276]\n",
      "[Epoch 37/100] [Batch 149/347] [D loss: 0.444570] [G loss: 0.319178]\n",
      "[Epoch 37/100] [Batch 150/347] [D loss: 0.450987] [G loss: 0.312805]\n",
      "[Epoch 37/100] [Batch 151/347] [D loss: 0.447812] [G loss: 0.314561]\n",
      "[Epoch 37/100] [Batch 152/347] [D loss: 0.411401] [G loss: 0.309186]\n",
      "[Epoch 37/100] [Batch 153/347] [D loss: 0.379384] [G loss: 0.288431]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 37/100] [Batch 154/347] [D loss: 0.375610] [G loss: 0.272232]\n",
      "[Epoch 37/100] [Batch 155/347] [D loss: 0.397072] [G loss: 0.261551]\n",
      "[Epoch 37/100] [Batch 156/347] [D loss: 0.429571] [G loss: 0.269621]\n",
      "[Epoch 37/100] [Batch 157/347] [D loss: 0.413341] [G loss: 0.279881]\n",
      "[Epoch 37/100] [Batch 158/347] [D loss: 0.385877] [G loss: 0.268797]\n",
      "[Epoch 37/100] [Batch 159/347] [D loss: 0.379895] [G loss: 0.262512]\n",
      "[Epoch 37/100] [Batch 160/347] [D loss: 0.337984] [G loss: 0.279853]\n",
      "[Epoch 37/100] [Batch 161/347] [D loss: 0.333308] [G loss: 0.299711]\n",
      "[Epoch 37/100] [Batch 162/347] [D loss: 0.390533] [G loss: 0.303700]\n",
      "[Epoch 37/100] [Batch 163/347] [D loss: 0.392964] [G loss: 0.299912]\n",
      "[Epoch 37/100] [Batch 164/347] [D loss: 0.372025] [G loss: 0.305662]\n",
      "[Epoch 37/100] [Batch 165/347] [D loss: 0.359495] [G loss: 0.303889]\n",
      "[Epoch 37/100] [Batch 166/347] [D loss: 0.377530] [G loss: 0.308849]\n",
      "[Epoch 37/100] [Batch 167/347] [D loss: 0.335893] [G loss: 0.333739]\n",
      "[Epoch 37/100] [Batch 168/347] [D loss: 0.302770] [G loss: 0.350742]\n",
      "[Epoch 37/100] [Batch 169/347] [D loss: 0.427339] [G loss: 0.354786]\n",
      "[Epoch 37/100] [Batch 170/347] [D loss: 0.502293] [G loss: 0.370557]\n",
      "[Epoch 37/100] [Batch 171/347] [D loss: 0.529091] [G loss: 0.385919]\n",
      "[Epoch 37/100] [Batch 172/347] [D loss: 0.535822] [G loss: 0.394121]\n",
      "[Epoch 37/100] [Batch 173/347] [D loss: 0.495848] [G loss: 0.385218]\n",
      "[Epoch 37/100] [Batch 174/347] [D loss: 0.494171] [G loss: 0.383647]\n",
      "[Epoch 37/100] [Batch 175/347] [D loss: 0.537398] [G loss: 0.394449]\n",
      "[Epoch 37/100] [Batch 176/347] [D loss: 0.552118] [G loss: 0.408733]\n",
      "[Epoch 37/100] [Batch 177/347] [D loss: 0.554128] [G loss: 0.410910]\n",
      "[Epoch 37/100] [Batch 178/347] [D loss: 0.549302] [G loss: 0.405494]\n",
      "[Epoch 37/100] [Batch 179/347] [D loss: 0.544101] [G loss: 0.399738]\n",
      "[Epoch 37/100] [Batch 180/347] [D loss: 0.540241] [G loss: 0.393823]\n",
      "[Epoch 37/100] [Batch 181/347] [D loss: 0.541271] [G loss: 0.394700]\n",
      "[Epoch 37/100] [Batch 182/347] [D loss: 0.540783] [G loss: 0.392938]\n",
      "[Epoch 37/100] [Batch 183/347] [D loss: 0.543195] [G loss: 0.397397]\n",
      "[Epoch 37/100] [Batch 184/347] [D loss: 0.546856] [G loss: 0.401483]\n",
      "[Epoch 37/100] [Batch 185/347] [D loss: 0.547461] [G loss: 0.400394]\n",
      "[Epoch 37/100] [Batch 186/347] [D loss: 0.547854] [G loss: 0.400522]\n",
      "[Epoch 37/100] [Batch 187/347] [D loss: 0.544852] [G loss: 0.395452]\n",
      "[Epoch 37/100] [Batch 188/347] [D loss: 0.543402] [G loss: 0.392566]\n",
      "[Epoch 37/100] [Batch 189/347] [D loss: 0.542183] [G loss: 0.391993]\n",
      "[Epoch 37/100] [Batch 190/347] [D loss: 0.533274] [G loss: 0.380226]\n",
      "[Epoch 37/100] [Batch 191/347] [D loss: 0.518270] [G loss: 0.367211]\n",
      "[Epoch 37/100] [Batch 192/347] [D loss: 0.513978] [G loss: 0.368297]\n",
      "[Epoch 37/100] [Batch 193/347] [D loss: 0.523629] [G loss: 0.375943]\n",
      "[Epoch 37/100] [Batch 194/347] [D loss: 0.533149] [G loss: 0.370722]\n",
      "[Epoch 37/100] [Batch 195/347] [D loss: 0.532808] [G loss: 0.362261]\n",
      "[Epoch 37/100] [Batch 196/347] [D loss: 0.527157] [G loss: 0.356324]\n",
      "[Epoch 37/100] [Batch 197/347] [D loss: 0.513366] [G loss: 0.353634]\n",
      "[Epoch 37/100] [Batch 198/347] [D loss: 0.476101] [G loss: 0.350393]\n",
      "[Epoch 37/100] [Batch 199/347] [D loss: 0.478959] [G loss: 0.345746]\n",
      "[Epoch 37/100] [Batch 200/347] [D loss: 0.518734] [G loss: 0.347223]\n",
      "[Epoch 37/100] [Batch 201/347] [D loss: 0.522105] [G loss: 0.345980]\n",
      "[Epoch 37/100] [Batch 202/347] [D loss: 0.525331] [G loss: 0.339449]\n",
      "[Epoch 37/100] [Batch 203/347] [D loss: 0.528971] [G loss: 0.334039]\n",
      "[Epoch 37/100] [Batch 204/347] [D loss: 0.529526] [G loss: 0.332879]\n",
      "[Epoch 37/100] [Batch 205/347] [D loss: 0.528919] [G loss: 0.332596]\n",
      "[Epoch 37/100] [Batch 206/347] [D loss: 0.528442] [G loss: 0.336167]\n",
      "[Epoch 37/100] [Batch 207/347] [D loss: 0.531035] [G loss: 0.346003]\n",
      "[Epoch 37/100] [Batch 208/347] [D loss: 0.533017] [G loss: 0.346072]\n",
      "[Epoch 37/100] [Batch 209/347] [D loss: 0.523586] [G loss: 0.339720]\n",
      "[Epoch 37/100] [Batch 210/347] [D loss: 0.522172] [G loss: 0.345591]\n",
      "[Epoch 37/100] [Batch 211/347] [D loss: 0.524324] [G loss: 0.344130]\n",
      "[Epoch 37/100] [Batch 212/347] [D loss: 0.407995] [G loss: 0.337575]\n",
      "[Epoch 37/100] [Batch 213/347] [D loss: 0.379939] [G loss: 0.341917]\n",
      "[Epoch 37/100] [Batch 214/347] [D loss: 0.250637] [G loss: 0.351611]\n",
      "[Epoch 37/100] [Batch 215/347] [D loss: 0.249870] [G loss: 0.356964]\n",
      "[Epoch 37/100] [Batch 216/347] [D loss: 0.457483] [G loss: 0.355916]\n",
      "[Epoch 37/100] [Batch 217/347] [D loss: 0.504891] [G loss: 0.360523]\n",
      "[Epoch 37/100] [Batch 218/347] [D loss: 0.537251] [G loss: 0.376779]\n",
      "[Epoch 37/100] [Batch 219/347] [D loss: 0.533601] [G loss: 0.392323]\n",
      "[Epoch 37/100] [Batch 220/347] [D loss: 0.537088] [G loss: 0.410674]\n",
      "[Epoch 37/100] [Batch 221/347] [D loss: 0.540667] [G loss: 0.414145]\n",
      "[Epoch 37/100] [Batch 222/347] [D loss: 0.532567] [G loss: 0.407792]\n",
      "[Epoch 37/100] [Batch 223/347] [D loss: 0.531834] [G loss: 0.407643]\n",
      "[Epoch 37/100] [Batch 224/347] [D loss: 0.532832] [G loss: 0.404408]\n",
      "[Epoch 37/100] [Batch 225/347] [D loss: 0.515548] [G loss: 0.387425]\n",
      "[Epoch 37/100] [Batch 226/347] [D loss: 0.506294] [G loss: 0.363669]\n",
      "[Epoch 37/100] [Batch 227/347] [D loss: 0.508095] [G loss: 0.338002]\n",
      "[Epoch 37/100] [Batch 228/347] [D loss: 0.512159] [G loss: 0.337597]\n",
      "[Epoch 37/100] [Batch 229/347] [D loss: 0.520401] [G loss: 0.347146]\n",
      "[Epoch 37/100] [Batch 230/347] [D loss: 0.523394] [G loss: 0.348265]\n",
      "[Epoch 37/100] [Batch 231/347] [D loss: 0.518931] [G loss: 0.339665]\n",
      "[Epoch 37/100] [Batch 232/347] [D loss: 0.519487] [G loss: 0.339141]\n",
      "[Epoch 37/100] [Batch 233/347] [D loss: 0.512208] [G loss: 0.337817]\n",
      "[Epoch 37/100] [Batch 234/347] [D loss: 0.498601] [G loss: 0.341160]\n",
      "[Epoch 37/100] [Batch 235/347] [D loss: 0.495256] [G loss: 0.347317]\n",
      "[Epoch 37/100] [Batch 236/347] [D loss: 0.503955] [G loss: 0.349112]\n",
      "[Epoch 37/100] [Batch 237/347] [D loss: 0.518637] [G loss: 0.351548]\n",
      "[Epoch 37/100] [Batch 238/347] [D loss: 0.532228] [G loss: 0.351991]\n",
      "[Epoch 37/100] [Batch 239/347] [D loss: 0.526809] [G loss: 0.346801]\n",
      "[Epoch 37/100] [Batch 240/347] [D loss: 0.521380] [G loss: 0.340322]\n",
      "[Epoch 37/100] [Batch 241/347] [D loss: 0.518412] [G loss: 0.332450]\n",
      "[Epoch 37/100] [Batch 242/347] [D loss: 0.520008] [G loss: 0.328912]\n",
      "[Epoch 37/100] [Batch 243/347] [D loss: 0.528465] [G loss: 0.335751]\n",
      "[Epoch 37/100] [Batch 244/347] [D loss: 0.533310] [G loss: 0.344156]\n",
      "[Epoch 37/100] [Batch 245/347] [D loss: 0.513391] [G loss: 0.342436]\n",
      "[Epoch 37/100] [Batch 246/347] [D loss: 0.497642] [G loss: 0.332905]\n",
      "[Epoch 37/100] [Batch 247/347] [D loss: 0.503778] [G loss: 0.303690]\n",
      "[Epoch 37/100] [Batch 248/347] [D loss: 0.509033] [G loss: 0.296250]\n",
      "[Epoch 37/100] [Batch 249/347] [D loss: 0.504000] [G loss: 0.294468]\n",
      "[Epoch 37/100] [Batch 250/347] [D loss: 0.501847] [G loss: 0.315988]\n",
      "[Epoch 37/100] [Batch 251/347] [D loss: 0.500329] [G loss: 0.333099]\n",
      "[Epoch 37/100] [Batch 252/347] [D loss: 0.499306] [G loss: 0.335570]\n",
      "[Epoch 37/100] [Batch 253/347] [D loss: 0.507112] [G loss: 0.335773]\n",
      "[Epoch 37/100] [Batch 254/347] [D loss: 0.514179] [G loss: 0.333828]\n",
      "[Epoch 37/100] [Batch 255/347] [D loss: 0.485579] [G loss: 0.331954]\n",
      "[Epoch 37/100] [Batch 256/347] [D loss: 0.480940] [G loss: 0.336436]\n",
      "[Epoch 37/100] [Batch 257/347] [D loss: 0.498007] [G loss: 0.340076]\n",
      "[Epoch 37/100] [Batch 258/347] [D loss: 0.464841] [G loss: 0.332229]\n",
      "[Epoch 37/100] [Batch 259/347] [D loss: 0.440030] [G loss: 0.317995]\n",
      "[Epoch 37/100] [Batch 260/347] [D loss: 0.400948] [G loss: 0.314394]\n",
      "[Epoch 37/100] [Batch 261/347] [D loss: 0.409753] [G loss: 0.320621]\n",
      "[Epoch 37/100] [Batch 262/347] [D loss: 0.468036] [G loss: 0.314442]\n",
      "[Epoch 37/100] [Batch 263/347] [D loss: 0.440424] [G loss: 0.311605]\n",
      "[Epoch 37/100] [Batch 264/347] [D loss: 0.399533] [G loss: 0.313310]\n",
      "[Epoch 37/100] [Batch 265/347] [D loss: 0.407447] [G loss: 0.310567]\n",
      "[Epoch 37/100] [Batch 266/347] [D loss: 0.424510] [G loss: 0.306924]\n",
      "[Epoch 37/100] [Batch 267/347] [D loss: 0.433872] [G loss: 0.304874]\n",
      "[Epoch 37/100] [Batch 268/347] [D loss: 0.389549] [G loss: 0.309536]\n",
      "[Epoch 37/100] [Batch 269/347] [D loss: 0.384386] [G loss: 0.311208]\n",
      "[Epoch 37/100] [Batch 270/347] [D loss: 0.425028] [G loss: 0.308175]\n",
      "[Epoch 37/100] [Batch 271/347] [D loss: 0.457301] [G loss: 0.304667]\n",
      "[Epoch 37/100] [Batch 272/347] [D loss: 0.476718] [G loss: 0.306620]\n",
      "[Epoch 37/100] [Batch 273/347] [D loss: 0.418796] [G loss: 0.315250]\n",
      "[Epoch 37/100] [Batch 274/347] [D loss: 0.468398] [G loss: 0.338320]\n",
      "[Epoch 37/100] [Batch 275/347] [D loss: 0.438712] [G loss: 0.351731]\n",
      "[Epoch 37/100] [Batch 276/347] [D loss: 0.411956] [G loss: 0.347220]\n",
      "[Epoch 37/100] [Batch 277/347] [D loss: 0.429694] [G loss: 0.353063]\n",
      "[Epoch 37/100] [Batch 278/347] [D loss: 0.497822] [G loss: 0.367404]\n",
      "[Epoch 37/100] [Batch 279/347] [D loss: 0.480757] [G loss: 0.370070]\n",
      "[Epoch 37/100] [Batch 280/347] [D loss: 0.466242] [G loss: 0.377134]\n",
      "[Epoch 37/100] [Batch 281/347] [D loss: 0.469580] [G loss: 0.377831]\n",
      "[Epoch 37/100] [Batch 282/347] [D loss: 0.481244] [G loss: 0.377192]\n",
      "[Epoch 37/100] [Batch 283/347] [D loss: 0.434652] [G loss: 0.377742]\n",
      "[Epoch 37/100] [Batch 284/347] [D loss: 0.425220] [G loss: 0.378903]\n",
      "[Epoch 37/100] [Batch 285/347] [D loss: 0.477917] [G loss: 0.376410]\n",
      "[Epoch 37/100] [Batch 286/347] [D loss: 0.505521] [G loss: 0.374535]\n",
      "[Epoch 37/100] [Batch 287/347] [D loss: 0.505717] [G loss: 0.368374]\n",
      "[Epoch 37/100] [Batch 288/347] [D loss: 0.487182] [G loss: 0.348252]\n",
      "[Epoch 37/100] [Batch 289/347] [D loss: 0.484480] [G loss: 0.339844]\n",
      "[Epoch 37/100] [Batch 290/347] [D loss: 0.501154] [G loss: 0.348241]\n",
      "[Epoch 37/100] [Batch 291/347] [D loss: 0.484894] [G loss: 0.340416]\n",
      "[Epoch 37/100] [Batch 292/347] [D loss: 0.481020] [G loss: 0.342980]\n",
      "[Epoch 37/100] [Batch 293/347] [D loss: 0.455764] [G loss: 0.359429]\n",
      "[Epoch 37/100] [Batch 294/347] [D loss: 0.424713] [G loss: 0.357442]\n",
      "[Epoch 37/100] [Batch 295/347] [D loss: 0.262975] [G loss: 0.343646]\n",
      "[Epoch 37/100] [Batch 296/347] [D loss: 0.250952] [G loss: 0.343787]\n",
      "[Epoch 37/100] [Batch 297/347] [D loss: 0.473248] [G loss: 0.357764]\n",
      "[Epoch 37/100] [Batch 298/347] [D loss: 0.521831] [G loss: 0.350213]\n",
      "[Epoch 37/100] [Batch 299/347] [D loss: 0.501018] [G loss: 0.346688]\n",
      "[Epoch 37/100] [Batch 300/347] [D loss: 0.468527] [G loss: 0.339778]\n",
      "[Epoch 37/100] [Batch 301/347] [D loss: 0.469335] [G loss: 0.332954]\n",
      "[Epoch 37/100] [Batch 302/347] [D loss: 0.490475] [G loss: 0.336602]\n",
      "[Epoch 37/100] [Batch 303/347] [D loss: 0.474537] [G loss: 0.313835]\n",
      "[Epoch 37/100] [Batch 304/347] [D loss: 0.477237] [G loss: 0.294213]\n",
      "[Epoch 37/100] [Batch 305/347] [D loss: 0.484965] [G loss: 0.294451]\n",
      "[Epoch 37/100] [Batch 306/347] [D loss: 0.361455] [G loss: 0.284066]\n",
      "[Epoch 37/100] [Batch 307/347] [D loss: 0.277324] [G loss: 0.289652]\n",
      "[Epoch 37/100] [Batch 308/347] [D loss: 0.337047] [G loss: 0.291668]\n",
      "[Epoch 37/100] [Batch 309/347] [D loss: 0.488040] [G loss: 0.308913]\n",
      "[Epoch 37/100] [Batch 310/347] [D loss: 0.523624] [G loss: 0.337942]\n",
      "[Epoch 37/100] [Batch 311/347] [D loss: 0.525208] [G loss: 0.342870]\n",
      "[Epoch 37/100] [Batch 312/347] [D loss: 0.523911] [G loss: 0.344513]\n",
      "[Epoch 37/100] [Batch 313/347] [D loss: 0.518749] [G loss: 0.345748]\n",
      "[Epoch 37/100] [Batch 314/347] [D loss: 0.493868] [G loss: 0.340840]\n",
      "[Epoch 37/100] [Batch 315/347] [D loss: 0.457621] [G loss: 0.332704]\n",
      "[Epoch 37/100] [Batch 316/347] [D loss: 0.457861] [G loss: 0.316726]\n",
      "[Epoch 37/100] [Batch 317/347] [D loss: 0.481129] [G loss: 0.306024]\n",
      "[Epoch 37/100] [Batch 318/347] [D loss: 0.498554] [G loss: 0.321852]\n",
      "[Epoch 37/100] [Batch 319/347] [D loss: 0.516295] [G loss: 0.354368]\n",
      "[Epoch 37/100] [Batch 320/347] [D loss: 0.524334] [G loss: 0.367352]\n",
      "[Epoch 37/100] [Batch 321/347] [D loss: 0.509315] [G loss: 0.356291]\n",
      "[Epoch 37/100] [Batch 322/347] [D loss: 0.499675] [G loss: 0.342267]\n",
      "[Epoch 37/100] [Batch 323/347] [D loss: 0.484262] [G loss: 0.340369]\n",
      "[Epoch 37/100] [Batch 324/347] [D loss: 0.480544] [G loss: 0.342326]\n",
      "[Epoch 37/100] [Batch 325/347] [D loss: 0.401010] [G loss: 0.330569]\n",
      "[Epoch 37/100] [Batch 326/347] [D loss: 0.379810] [G loss: 0.318709]\n",
      "[Epoch 37/100] [Batch 327/347] [D loss: 0.436248] [G loss: 0.316534]\n",
      "[Epoch 37/100] [Batch 328/347] [D loss: 0.472623] [G loss: 0.314147]\n",
      "[Epoch 37/100] [Batch 329/347] [D loss: 0.403977] [G loss: 0.304767]\n",
      "[Epoch 37/100] [Batch 330/347] [D loss: 0.392985] [G loss: 0.297599]\n",
      "[Epoch 37/100] [Batch 331/347] [D loss: 0.443993] [G loss: 0.305535]\n",
      "[Epoch 37/100] [Batch 332/347] [D loss: 0.507820] [G loss: 0.325740]\n",
      "[Epoch 37/100] [Batch 333/347] [D loss: 0.522412] [G loss: 0.336743]\n",
      "[Epoch 37/100] [Batch 334/347] [D loss: 0.509453] [G loss: 0.338083]\n",
      "[Epoch 37/100] [Batch 335/347] [D loss: 0.487116] [G loss: 0.326020]\n",
      "[Epoch 37/100] [Batch 336/347] [D loss: 0.475515] [G loss: 0.312650]\n",
      "[Epoch 37/100] [Batch 337/347] [D loss: 0.479715] [G loss: 0.317302]\n",
      "[Epoch 37/100] [Batch 338/347] [D loss: 0.500545] [G loss: 0.331953]\n",
      "[Epoch 37/100] [Batch 339/347] [D loss: 0.521583] [G loss: 0.338028]\n",
      "[Epoch 37/100] [Batch 340/347] [D loss: 0.525884] [G loss: 0.339452]\n",
      "[Epoch 37/100] [Batch 341/347] [D loss: 0.509861] [G loss: 0.335954]\n",
      "[Epoch 37/100] [Batch 342/347] [D loss: 0.501832] [G loss: 0.329508]\n",
      "[Epoch 37/100] [Batch 343/347] [D loss: 0.518885] [G loss: 0.335632]\n",
      "[Epoch 37/100] [Batch 344/347] [D loss: 0.461978] [G loss: 0.325053]\n",
      "[Epoch 37/100] [Batch 345/347] [D loss: 0.416982] [G loss: 0.303033]\n",
      "[Epoch 37/100] [Batch 346/347] [D loss: 0.364827] [G loss: 0.303566]\n",
      "[Epoch 37/100] [Batch 347/347] [D loss: 0.251771] [G loss: 0.317382]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 38/100] [Batch 1/347] [D loss: 0.502184] [G loss: 0.330115]\n",
      "[Epoch 38/100] [Batch 2/347] [D loss: 0.507334] [G loss: 0.335337]\n",
      "[Epoch 38/100] [Batch 3/347] [D loss: 0.521290] [G loss: 0.348368]\n",
      "[Epoch 38/100] [Batch 4/347] [D loss: 0.522113] [G loss: 0.351549]\n",
      "[Epoch 38/100] [Batch 5/347] [D loss: 0.520917] [G loss: 0.352640]\n",
      "[Epoch 38/100] [Batch 6/347] [D loss: 0.524058] [G loss: 0.355810]\n",
      "[Epoch 38/100] [Batch 7/347] [D loss: 0.520350] [G loss: 0.352086]\n",
      "[Epoch 38/100] [Batch 8/347] [D loss: 0.511343] [G loss: 0.347873]\n",
      "[Epoch 38/100] [Batch 9/347] [D loss: 0.498048] [G loss: 0.337112]\n",
      "[Epoch 38/100] [Batch 10/347] [D loss: 0.501242] [G loss: 0.336841]\n",
      "[Epoch 38/100] [Batch 11/347] [D loss: 0.517964] [G loss: 0.349604]\n",
      "[Epoch 38/100] [Batch 12/347] [D loss: 0.522453] [G loss: 0.352680]\n",
      "[Epoch 38/100] [Batch 13/347] [D loss: 0.525040] [G loss: 0.355072]\n",
      "[Epoch 38/100] [Batch 14/347] [D loss: 0.524917] [G loss: 0.355658]\n",
      "[Epoch 38/100] [Batch 15/347] [D loss: 0.518211] [G loss: 0.349973]\n",
      "[Epoch 38/100] [Batch 16/347] [D loss: 0.511389] [G loss: 0.343840]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 38/100] [Batch 17/347] [D loss: 0.496609] [G loss: 0.330093]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 38/100] [Batch 18/347] [D loss: 0.479251] [G loss: 0.328030]\n",
      "[Epoch 38/100] [Batch 19/347] [D loss: 0.488622] [G loss: 0.329754]\n",
      "[Epoch 38/100] [Batch 20/347] [D loss: 0.520210] [G loss: 0.340239]\n",
      "[Epoch 38/100] [Batch 21/347] [D loss: 0.520229] [G loss: 0.334128]\n",
      "[Epoch 38/100] [Batch 22/347] [D loss: 0.513204] [G loss: 0.327071]\n",
      "[Epoch 38/100] [Batch 23/347] [D loss: 0.494478] [G loss: 0.318515]\n",
      "[Epoch 38/100] [Batch 24/347] [D loss: 0.492110] [G loss: 0.315507]\n",
      "[Epoch 38/100] [Batch 25/347] [D loss: 0.503595] [G loss: 0.312868]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 38/100] [Batch 26/347] [D loss: 0.450674] [G loss: 0.302574]\n",
      "[Epoch 38/100] [Batch 27/347] [D loss: 0.289997] [G loss: 0.318112]\n",
      "[Epoch 38/100] [Batch 28/347] [D loss: 0.299072] [G loss: 0.327707]\n",
      "[Epoch 38/100] [Batch 29/347] [D loss: 0.495425] [G loss: 0.323777]\n",
      "[Epoch 38/100] [Batch 30/347] [D loss: 0.462889] [G loss: 0.331027]\n",
      "[Epoch 38/100] [Batch 31/347] [D loss: 0.416934] [G loss: 0.333689]\n",
      "[Epoch 38/100] [Batch 32/347] [D loss: 0.344941] [G loss: 0.329906]\n",
      "[Epoch 38/100] [Batch 33/347] [D loss: 0.364435] [G loss: 0.324205]\n",
      "[Epoch 38/100] [Batch 34/347] [D loss: 0.447496] [G loss: 0.325684]\n",
      "[Epoch 38/100] [Batch 35/347] [D loss: 0.441578] [G loss: 0.324558]\n",
      "[Epoch 38/100] [Batch 36/347] [D loss: 0.479884] [G loss: 0.317910]\n",
      "[Epoch 38/100] [Batch 37/347] [D loss: 0.434583] [G loss: 0.309684]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 38/100] [Batch 38/347] [D loss: 0.403664] [G loss: 0.296784]\n",
      "[Epoch 38/100] [Batch 39/347] [D loss: 0.437606] [G loss: 0.291657]\n",
      "[Epoch 38/100] [Batch 40/347] [D loss: 0.492994] [G loss: 0.289190]\n",
      "[Epoch 38/100] [Batch 41/347] [D loss: 0.493705] [G loss: 0.285356]\n",
      "[Epoch 38/100] [Batch 42/347] [D loss: 0.493406] [G loss: 0.287596]\n",
      "[Epoch 38/100] [Batch 43/347] [D loss: 0.490800] [G loss: 0.303268]\n",
      "[Epoch 38/100] [Batch 44/347] [D loss: 0.496788] [G loss: 0.316212]\n",
      "[Epoch 38/100] [Batch 45/347] [D loss: 0.517152] [G loss: 0.332613]\n",
      "[Epoch 38/100] [Batch 46/347] [D loss: 0.514846] [G loss: 0.326796]\n",
      "[Epoch 38/100] [Batch 47/347] [D loss: 0.492028] [G loss: 0.304199]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 38/100] [Batch 48/347] [D loss: 0.392408] [G loss: 0.293659]\n",
      "[Epoch 38/100] [Batch 49/347] [D loss: 0.389901] [G loss: 0.294577]\n",
      "[Epoch 38/100] [Batch 50/347] [D loss: 0.308603] [G loss: 0.306303]\n",
      "[Epoch 38/100] [Batch 51/347] [D loss: 0.290697] [G loss: 0.322652]\n",
      "[Epoch 38/100] [Batch 52/347] [D loss: 0.389326] [G loss: 0.324882]\n",
      "[Epoch 38/100] [Batch 53/347] [D loss: 0.469073] [G loss: 0.322066]\n",
      "[Epoch 38/100] [Batch 54/347] [D loss: 0.413005] [G loss: 0.309864]\n",
      "[Epoch 38/100] [Batch 55/347] [D loss: 0.400923] [G loss: 0.321930]\n",
      "[Epoch 38/100] [Batch 56/347] [D loss: 0.403648] [G loss: 0.309652]\n",
      "[Epoch 38/100] [Batch 57/347] [D loss: 0.415316] [G loss: 0.317649]\n",
      "[Epoch 38/100] [Batch 58/347] [D loss: 0.438759] [G loss: 0.328198]\n",
      "[Epoch 38/100] [Batch 59/347] [D loss: 0.404107] [G loss: 0.326640]\n",
      "[Epoch 38/100] [Batch 60/347] [D loss: 0.382722] [G loss: 0.322180]\n",
      "[Epoch 38/100] [Batch 61/347] [D loss: 0.363887] [G loss: 0.318750]\n",
      "[Epoch 38/100] [Batch 62/347] [D loss: 0.368869] [G loss: 0.309945]\n",
      "[Epoch 38/100] [Batch 63/347] [D loss: 0.393875] [G loss: 0.310330]\n",
      "[Epoch 38/100] [Batch 64/347] [D loss: 0.425393] [G loss: 0.300187]\n",
      "[Epoch 38/100] [Batch 65/347] [D loss: 0.487212] [G loss: 0.317784]\n",
      "[Epoch 38/100] [Batch 66/347] [D loss: 0.411626] [G loss: 0.318781]\n",
      "[Epoch 38/100] [Batch 67/347] [D loss: 0.254414] [G loss: 0.315073]\n",
      "[Epoch 38/100] [Batch 68/347] [D loss: 0.278047] [G loss: 0.314641]\n",
      "[Epoch 38/100] [Batch 69/347] [D loss: 0.399488] [G loss: 0.304281]\n",
      "[Epoch 38/100] [Batch 70/347] [D loss: 0.403395] [G loss: 0.306668]\n",
      "[Epoch 38/100] [Batch 71/347] [D loss: 0.390945] [G loss: 0.310454]\n",
      "[Epoch 38/100] [Batch 72/347] [D loss: 0.387699] [G loss: 0.313203]\n",
      "[Epoch 38/100] [Batch 73/347] [D loss: 0.392092] [G loss: 0.317419]\n",
      "[Epoch 38/100] [Batch 74/347] [D loss: 0.389419] [G loss: 0.337156]\n",
      "[Epoch 38/100] [Batch 75/347] [D loss: 0.403446] [G loss: 0.328400]\n",
      "[Epoch 38/100] [Batch 76/347] [D loss: 0.424106] [G loss: 0.306977]\n",
      "[Epoch 38/100] [Batch 77/347] [D loss: 0.435259] [G loss: 0.317808]\n",
      "[Epoch 38/100] [Batch 78/347] [D loss: 0.443231] [G loss: 0.333984]\n",
      "[Epoch 38/100] [Batch 79/347] [D loss: 0.504649] [G loss: 0.338847]\n",
      "[Epoch 38/100] [Batch 80/347] [D loss: 0.520179] [G loss: 0.333231]\n",
      "[Epoch 38/100] [Batch 81/347] [D loss: 0.514026] [G loss: 0.335442]\n",
      "[Epoch 38/100] [Batch 82/347] [D loss: 0.465597] [G loss: 0.329727]\n",
      "[Epoch 38/100] [Batch 83/347] [D loss: 0.456557] [G loss: 0.321790]\n",
      "[Epoch 38/100] [Batch 84/347] [D loss: 0.507183] [G loss: 0.331148]\n",
      "[Epoch 38/100] [Batch 85/347] [D loss: 0.534802] [G loss: 0.330589]\n",
      "[Epoch 38/100] [Batch 86/347] [D loss: 0.530902] [G loss: 0.324393]\n",
      "[Epoch 38/100] [Batch 87/347] [D loss: 0.530252] [G loss: 0.322247]\n",
      "[Epoch 38/100] [Batch 88/347] [D loss: 0.535690] [G loss: 0.326380]\n",
      "[Epoch 38/100] [Batch 89/347] [D loss: 0.541758] [G loss: 0.331248]\n",
      "[Epoch 38/100] [Batch 90/347] [D loss: 0.538667] [G loss: 0.329500]\n",
      "[Epoch 38/100] [Batch 91/347] [D loss: 0.538269] [G loss: 0.330315]\n",
      "[Epoch 38/100] [Batch 92/347] [D loss: 0.541107] [G loss: 0.334565]\n",
      "[Epoch 38/100] [Batch 93/347] [D loss: 0.540128] [G loss: 0.335979]\n",
      "[Epoch 38/100] [Batch 94/347] [D loss: 0.535655] [G loss: 0.335851]\n",
      "[Epoch 38/100] [Batch 95/347] [D loss: 0.536548] [G loss: 0.340283]\n",
      "[Epoch 38/100] [Batch 96/347] [D loss: 0.532709] [G loss: 0.339477]\n",
      "[Epoch 38/100] [Batch 97/347] [D loss: 0.528839] [G loss: 0.338150]\n",
      "[Epoch 38/100] [Batch 98/347] [D loss: 0.536348] [G loss: 0.347002]\n",
      "[Epoch 38/100] [Batch 99/347] [D loss: 0.540269] [G loss: 0.354755]\n",
      "[Epoch 38/100] [Batch 100/347] [D loss: 0.531691] [G loss: 0.355036]\n",
      "[Epoch 38/100] [Batch 101/347] [D loss: 0.530041] [G loss: 0.353621]\n",
      "[Epoch 38/100] [Batch 102/347] [D loss: 0.538330] [G loss: 0.358785]\n",
      "[Epoch 38/100] [Batch 103/347] [D loss: 0.538788] [G loss: 0.362997]\n",
      "[Epoch 38/100] [Batch 104/347] [D loss: 0.533145] [G loss: 0.357435]\n",
      "[Epoch 38/100] [Batch 105/347] [D loss: 0.534043] [G loss: 0.359894]\n",
      "[Epoch 38/100] [Batch 106/347] [D loss: 0.529005] [G loss: 0.361517]\n",
      "[Epoch 38/100] [Batch 107/347] [D loss: 0.478063] [G loss: 0.353632]\n",
      "[Epoch 38/100] [Batch 108/347] [D loss: 0.239188] [G loss: 0.372464]\n",
      "[Epoch 38/100] [Batch 109/347] [D loss: 0.238628] [G loss: 0.382802]\n",
      "[Epoch 38/100] [Batch 110/347] [D loss: 0.461725] [G loss: 0.377317]\n",
      "[Epoch 38/100] [Batch 111/347] [D loss: 0.286131] [G loss: 0.384935]\n",
      "[Epoch 38/100] [Batch 112/347] [D loss: 0.235127] [G loss: 0.394524]\n",
      "[Epoch 38/100] [Batch 113/347] [D loss: 0.448244] [G loss: 0.404960]\n",
      "[Epoch 38/100] [Batch 114/347] [D loss: 0.524645] [G loss: 0.428829]\n",
      "[Epoch 38/100] [Batch 115/347] [D loss: 0.516685] [G loss: 0.432227]\n",
      "[Epoch 38/100] [Batch 116/347] [D loss: 0.525645] [G loss: 0.428128]\n",
      "[Epoch 38/100] [Batch 117/347] [D loss: 0.509903] [G loss: 0.402195]\n",
      "[Epoch 38/100] [Batch 118/347] [D loss: 0.452225] [G loss: 0.390886]\n",
      "[Epoch 38/100] [Batch 119/347] [D loss: 0.421763] [G loss: 0.382542]\n",
      "[Epoch 38/100] [Batch 120/347] [D loss: 0.353977] [G loss: 0.383618]\n",
      "[Epoch 38/100] [Batch 121/347] [D loss: 0.341220] [G loss: 0.379375]\n",
      "[Epoch 38/100] [Batch 122/347] [D loss: 0.470496] [G loss: 0.374495]\n",
      "[Epoch 38/100] [Batch 123/347] [D loss: 0.527149] [G loss: 0.372569]\n",
      "[Epoch 38/100] [Batch 124/347] [D loss: 0.524664] [G loss: 0.363618]\n",
      "[Epoch 38/100] [Batch 125/347] [D loss: 0.530577] [G loss: 0.369795]\n",
      "[Epoch 38/100] [Batch 126/347] [D loss: 0.522235] [G loss: 0.377479]\n",
      "[Epoch 38/100] [Batch 127/347] [D loss: 0.514325] [G loss: 0.373801]\n",
      "[Epoch 38/100] [Batch 128/347] [D loss: 0.511493] [G loss: 0.363543]\n",
      "[Epoch 38/100] [Batch 129/347] [D loss: 0.450970] [G loss: 0.353365]\n",
      "[Epoch 38/100] [Batch 130/347] [D loss: 0.429791] [G loss: 0.351460]\n",
      "[Epoch 38/100] [Batch 131/347] [D loss: 0.366302] [G loss: 0.346599]\n",
      "[Epoch 38/100] [Batch 132/347] [D loss: 0.251098] [G loss: 0.349072]\n",
      "[Epoch 38/100] [Batch 133/347] [D loss: 0.258391] [G loss: 0.351693]\n",
      "[Epoch 38/100] [Batch 134/347] [D loss: 0.245236] [G loss: 0.360722]\n",
      "[Epoch 38/100] [Batch 135/347] [D loss: 0.240313] [G loss: 0.380273]\n",
      "[Epoch 38/100] [Batch 136/347] [D loss: 0.230720] [G loss: 0.398940]\n",
      "[Epoch 38/100] [Batch 137/347] [D loss: 0.464590] [G loss: 0.400645]\n",
      "[Epoch 38/100] [Batch 138/347] [D loss: 0.457933] [G loss: 0.399241]\n",
      "[Epoch 38/100] [Batch 139/347] [D loss: 0.437094] [G loss: 0.391985]\n",
      "[Epoch 38/100] [Batch 140/347] [D loss: 0.421580] [G loss: 0.394523]\n",
      "[Epoch 38/100] [Batch 141/347] [D loss: 0.427539] [G loss: 0.390277]\n",
      "[Epoch 38/100] [Batch 142/347] [D loss: 0.428879] [G loss: 0.388663]\n",
      "[Epoch 38/100] [Batch 143/347] [D loss: 0.393011] [G loss: 0.380716]\n",
      "[Epoch 38/100] [Batch 144/347] [D loss: 0.387466] [G loss: 0.380422]\n",
      "[Epoch 38/100] [Batch 145/347] [D loss: 0.394051] [G loss: 0.361281]\n",
      "[Epoch 38/100] [Batch 146/347] [D loss: 0.398964] [G loss: 0.342273]\n",
      "[Epoch 38/100] [Batch 147/347] [D loss: 0.430015] [G loss: 0.345709]\n",
      "[Epoch 38/100] [Batch 148/347] [D loss: 0.436790] [G loss: 0.343222]\n",
      "[Epoch 38/100] [Batch 149/347] [D loss: 0.442946] [G loss: 0.330311]\n",
      "[Epoch 38/100] [Batch 150/347] [D loss: 0.450938] [G loss: 0.324732]\n",
      "[Epoch 38/100] [Batch 151/347] [D loss: 0.445539] [G loss: 0.327319]\n",
      "[Epoch 38/100] [Batch 152/347] [D loss: 0.404748] [G loss: 0.322300]\n",
      "[Epoch 38/100] [Batch 153/347] [D loss: 0.369608] [G loss: 0.301799]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 38/100] [Batch 154/347] [D loss: 0.365914] [G loss: 0.279451]\n",
      "[Epoch 38/100] [Batch 155/347] [D loss: 0.386451] [G loss: 0.274152]\n",
      "[Epoch 38/100] [Batch 156/347] [D loss: 0.422100] [G loss: 0.281416]\n",
      "[Epoch 38/100] [Batch 157/347] [D loss: 0.404896] [G loss: 0.291291]\n",
      "[Epoch 38/100] [Batch 158/347] [D loss: 0.375243] [G loss: 0.279105]\n",
      "[Epoch 38/100] [Batch 159/347] [D loss: 0.367625] [G loss: 0.267209]\n",
      "[Epoch 38/100] [Batch 160/347] [D loss: 0.322292] [G loss: 0.288695]\n",
      "[Epoch 38/100] [Batch 161/347] [D loss: 0.316801] [G loss: 0.307992]\n",
      "[Epoch 38/100] [Batch 162/347] [D loss: 0.378323] [G loss: 0.311761]\n",
      "[Epoch 38/100] [Batch 163/347] [D loss: 0.382575] [G loss: 0.307158]\n",
      "[Epoch 38/100] [Batch 164/347] [D loss: 0.360149] [G loss: 0.309043]\n",
      "[Epoch 38/100] [Batch 165/347] [D loss: 0.344980] [G loss: 0.306986]\n",
      "[Epoch 38/100] [Batch 166/347] [D loss: 0.360659] [G loss: 0.313803]\n",
      "[Epoch 38/100] [Batch 167/347] [D loss: 0.320033] [G loss: 0.338276]\n",
      "[Epoch 38/100] [Batch 168/347] [D loss: 0.284699] [G loss: 0.354912]\n",
      "[Epoch 38/100] [Batch 169/347] [D loss: 0.415540] [G loss: 0.358383]\n",
      "[Epoch 38/100] [Batch 170/347] [D loss: 0.494240] [G loss: 0.372953]\n",
      "[Epoch 38/100] [Batch 171/347] [D loss: 0.525733] [G loss: 0.387848]\n",
      "[Epoch 38/100] [Batch 172/347] [D loss: 0.532991] [G loss: 0.395793]\n",
      "[Epoch 38/100] [Batch 173/347] [D loss: 0.483046] [G loss: 0.386457]\n",
      "[Epoch 38/100] [Batch 174/347] [D loss: 0.481736] [G loss: 0.384602]\n",
      "[Epoch 38/100] [Batch 175/347] [D loss: 0.535514] [G loss: 0.395001]\n",
      "[Epoch 38/100] [Batch 176/347] [D loss: 0.551754] [G loss: 0.409071]\n",
      "[Epoch 38/100] [Batch 177/347] [D loss: 0.553926] [G loss: 0.410606]\n",
      "[Epoch 38/100] [Batch 178/347] [D loss: 0.548720] [G loss: 0.405186]\n",
      "[Epoch 38/100] [Batch 179/347] [D loss: 0.543173] [G loss: 0.399268]\n",
      "[Epoch 38/100] [Batch 180/347] [D loss: 0.539208] [G loss: 0.393264]\n",
      "[Epoch 38/100] [Batch 181/347] [D loss: 0.540295] [G loss: 0.394301]\n",
      "[Epoch 38/100] [Batch 182/347] [D loss: 0.539891] [G loss: 0.392655]\n",
      "[Epoch 38/100] [Batch 183/347] [D loss: 0.542174] [G loss: 0.397155]\n",
      "[Epoch 38/100] [Batch 184/347] [D loss: 0.546097] [G loss: 0.401389]\n",
      "[Epoch 38/100] [Batch 185/347] [D loss: 0.546969] [G loss: 0.400321]\n",
      "[Epoch 38/100] [Batch 186/347] [D loss: 0.547394] [G loss: 0.400718]\n",
      "[Epoch 38/100] [Batch 187/347] [D loss: 0.544326] [G loss: 0.395969]\n",
      "[Epoch 38/100] [Batch 188/347] [D loss: 0.542869] [G loss: 0.392980]\n",
      "[Epoch 38/100] [Batch 189/347] [D loss: 0.541368] [G loss: 0.392679]\n",
      "[Epoch 38/100] [Batch 190/347] [D loss: 0.531606] [G loss: 0.381121]\n",
      "[Epoch 38/100] [Batch 191/347] [D loss: 0.514344] [G loss: 0.368374]\n",
      "[Epoch 38/100] [Batch 192/347] [D loss: 0.508807] [G loss: 0.369630]\n",
      "[Epoch 38/100] [Batch 193/347] [D loss: 0.519519] [G loss: 0.377167]\n",
      "[Epoch 38/100] [Batch 194/347] [D loss: 0.532070] [G loss: 0.372041]\n",
      "[Epoch 38/100] [Batch 195/347] [D loss: 0.532950] [G loss: 0.363723]\n",
      "[Epoch 38/100] [Batch 196/347] [D loss: 0.526695] [G loss: 0.357972]\n",
      "[Epoch 38/100] [Batch 197/347] [D loss: 0.509374] [G loss: 0.355148]\n",
      "[Epoch 38/100] [Batch 198/347] [D loss: 0.461848] [G loss: 0.351840]\n",
      "[Epoch 38/100] [Batch 199/347] [D loss: 0.465687] [G loss: 0.346693]\n",
      "[Epoch 38/100] [Batch 200/347] [D loss: 0.516017] [G loss: 0.347463]\n",
      "[Epoch 38/100] [Batch 201/347] [D loss: 0.519538] [G loss: 0.345972]\n",
      "[Epoch 38/100] [Batch 202/347] [D loss: 0.524246] [G loss: 0.338760]\n",
      "[Epoch 38/100] [Batch 203/347] [D loss: 0.530257] [G loss: 0.333161]\n",
      "[Epoch 38/100] [Batch 204/347] [D loss: 0.530799] [G loss: 0.332045]\n",
      "[Epoch 38/100] [Batch 205/347] [D loss: 0.529785] [G loss: 0.331666]\n",
      "[Epoch 38/100] [Batch 206/347] [D loss: 0.528581] [G loss: 0.335351]\n",
      "[Epoch 38/100] [Batch 207/347] [D loss: 0.530347] [G loss: 0.345086]\n",
      "[Epoch 38/100] [Batch 208/347] [D loss: 0.532869] [G loss: 0.345132]\n",
      "[Epoch 38/100] [Batch 209/347] [D loss: 0.521553] [G loss: 0.339095]\n",
      "[Epoch 38/100] [Batch 210/347] [D loss: 0.518651] [G loss: 0.345230]\n",
      "[Epoch 38/100] [Batch 211/347] [D loss: 0.522332] [G loss: 0.343951]\n",
      "[Epoch 38/100] [Batch 212/347] [D loss: 0.384355] [G loss: 0.337630]\n",
      "[Epoch 38/100] [Batch 213/347] [D loss: 0.359753] [G loss: 0.343006]\n",
      "[Epoch 38/100] [Batch 214/347] [D loss: 0.245618] [G loss: 0.353808]\n",
      "[Epoch 38/100] [Batch 215/347] [D loss: 0.242978] [G loss: 0.360561]\n",
      "[Epoch 38/100] [Batch 216/347] [D loss: 0.442758] [G loss: 0.360512]\n",
      "[Epoch 38/100] [Batch 217/347] [D loss: 0.498831] [G loss: 0.365641]\n",
      "[Epoch 38/100] [Batch 218/347] [D loss: 0.538110] [G loss: 0.381604]\n",
      "[Epoch 38/100] [Batch 219/347] [D loss: 0.531121] [G loss: 0.397048]\n",
      "[Epoch 38/100] [Batch 220/347] [D loss: 0.533479] [G loss: 0.415278]\n",
      "[Epoch 38/100] [Batch 221/347] [D loss: 0.538606] [G loss: 0.418846]\n",
      "[Epoch 38/100] [Batch 222/347] [D loss: 0.529838] [G loss: 0.412272]\n",
      "[Epoch 38/100] [Batch 223/347] [D loss: 0.529410] [G loss: 0.412047]\n",
      "[Epoch 38/100] [Batch 224/347] [D loss: 0.531095] [G loss: 0.408761]\n",
      "[Epoch 38/100] [Batch 225/347] [D loss: 0.512849] [G loss: 0.392188]\n",
      "[Epoch 38/100] [Batch 226/347] [D loss: 0.504993] [G loss: 0.368618]\n",
      "[Epoch 38/100] [Batch 227/347] [D loss: 0.508534] [G loss: 0.342989]\n",
      "[Epoch 38/100] [Batch 228/347] [D loss: 0.513103] [G loss: 0.342374]\n",
      "[Epoch 38/100] [Batch 229/347] [D loss: 0.522293] [G loss: 0.352015]\n",
      "[Epoch 38/100] [Batch 230/347] [D loss: 0.525416] [G loss: 0.353374]\n",
      "[Epoch 38/100] [Batch 231/347] [D loss: 0.520747] [G loss: 0.345063]\n",
      "[Epoch 38/100] [Batch 232/347] [D loss: 0.521258] [G loss: 0.344884]\n",
      "[Epoch 38/100] [Batch 233/347] [D loss: 0.512157] [G loss: 0.344318]\n",
      "[Epoch 38/100] [Batch 234/347] [D loss: 0.495408] [G loss: 0.348034]\n",
      "[Epoch 38/100] [Batch 235/347] [D loss: 0.490749] [G loss: 0.354241]\n",
      "[Epoch 38/100] [Batch 236/347] [D loss: 0.499804] [G loss: 0.356337]\n",
      "[Epoch 38/100] [Batch 237/347] [D loss: 0.516539] [G loss: 0.358196]\n",
      "[Epoch 38/100] [Batch 238/347] [D loss: 0.533402] [G loss: 0.358749]\n",
      "[Epoch 38/100] [Batch 239/347] [D loss: 0.526950] [G loss: 0.353573]\n",
      "[Epoch 38/100] [Batch 240/347] [D loss: 0.520949] [G loss: 0.347251]\n",
      "[Epoch 38/100] [Batch 241/347] [D loss: 0.518259] [G loss: 0.339144]\n",
      "[Epoch 38/100] [Batch 242/347] [D loss: 0.520554] [G loss: 0.335387]\n",
      "[Epoch 38/100] [Batch 243/347] [D loss: 0.529864] [G loss: 0.341691]\n",
      "[Epoch 38/100] [Batch 244/347] [D loss: 0.534672] [G loss: 0.349954]\n",
      "[Epoch 38/100] [Batch 245/347] [D loss: 0.509708] [G loss: 0.347983]\n",
      "[Epoch 38/100] [Batch 246/347] [D loss: 0.492652] [G loss: 0.338378]\n",
      "[Epoch 38/100] [Batch 247/347] [D loss: 0.502831] [G loss: 0.308830]\n",
      "[Epoch 38/100] [Batch 248/347] [D loss: 0.511007] [G loss: 0.300718]\n",
      "[Epoch 38/100] [Batch 249/347] [D loss: 0.505541] [G loss: 0.298767]\n",
      "[Epoch 38/100] [Batch 250/347] [D loss: 0.501672] [G loss: 0.320132]\n",
      "[Epoch 38/100] [Batch 251/347] [D loss: 0.497161] [G loss: 0.336962]\n",
      "[Epoch 38/100] [Batch 252/347] [D loss: 0.495073] [G loss: 0.339328]\n",
      "[Epoch 38/100] [Batch 253/347] [D loss: 0.504461] [G loss: 0.339097]\n",
      "[Epoch 38/100] [Batch 254/347] [D loss: 0.513202] [G loss: 0.337216]\n",
      "[Epoch 38/100] [Batch 255/347] [D loss: 0.479864] [G loss: 0.335334]\n",
      "[Epoch 38/100] [Batch 256/347] [D loss: 0.473834] [G loss: 0.340076]\n",
      "[Epoch 38/100] [Batch 257/347] [D loss: 0.491824] [G loss: 0.343236]\n",
      "[Epoch 38/100] [Batch 258/347] [D loss: 0.452691] [G loss: 0.336222]\n",
      "[Epoch 38/100] [Batch 259/347] [D loss: 0.428985] [G loss: 0.322357]\n",
      "[Epoch 38/100] [Batch 260/347] [D loss: 0.388604] [G loss: 0.319135]\n",
      "[Epoch 38/100] [Batch 261/347] [D loss: 0.398441] [G loss: 0.325996]\n",
      "[Epoch 38/100] [Batch 262/347] [D loss: 0.460120] [G loss: 0.320503]\n",
      "[Epoch 38/100] [Batch 263/347] [D loss: 0.429488] [G loss: 0.317831]\n",
      "[Epoch 38/100] [Batch 264/347] [D loss: 0.385913] [G loss: 0.319587]\n",
      "[Epoch 38/100] [Batch 265/347] [D loss: 0.395735] [G loss: 0.316884]\n",
      "[Epoch 38/100] [Batch 266/347] [D loss: 0.413275] [G loss: 0.313440]\n",
      "[Epoch 38/100] [Batch 267/347] [D loss: 0.421378] [G loss: 0.311552]\n",
      "[Epoch 38/100] [Batch 268/347] [D loss: 0.374361] [G loss: 0.316596]\n",
      "[Epoch 38/100] [Batch 269/347] [D loss: 0.370735] [G loss: 0.318811]\n",
      "[Epoch 38/100] [Batch 270/347] [D loss: 0.414963] [G loss: 0.316640]\n",
      "[Epoch 38/100] [Batch 271/347] [D loss: 0.449348] [G loss: 0.313833]\n",
      "[Epoch 38/100] [Batch 272/347] [D loss: 0.471941] [G loss: 0.316395]\n",
      "[Epoch 38/100] [Batch 273/347] [D loss: 0.406746] [G loss: 0.325452]\n",
      "[Epoch 38/100] [Batch 274/347] [D loss: 0.491810] [G loss: 0.348321]\n",
      "[Epoch 38/100] [Batch 275/347] [D loss: 0.461209] [G loss: 0.361628]\n",
      "[Epoch 38/100] [Batch 276/347] [D loss: 0.399988] [G loss: 0.357198]\n",
      "[Epoch 38/100] [Batch 277/347] [D loss: 0.414842] [G loss: 0.362912]\n",
      "[Epoch 38/100] [Batch 278/347] [D loss: 0.495647] [G loss: 0.376882]\n",
      "[Epoch 38/100] [Batch 279/347] [D loss: 0.476128] [G loss: 0.379927]\n",
      "[Epoch 38/100] [Batch 280/347] [D loss: 0.459821] [G loss: 0.386940]\n",
      "[Epoch 38/100] [Batch 281/347] [D loss: 0.463170] [G loss: 0.387551]\n",
      "[Epoch 38/100] [Batch 282/347] [D loss: 0.476002] [G loss: 0.386650]\n",
      "[Epoch 38/100] [Batch 283/347] [D loss: 0.420929] [G loss: 0.387021]\n",
      "[Epoch 38/100] [Batch 284/347] [D loss: 0.409986] [G loss: 0.388148]\n",
      "[Epoch 38/100] [Batch 285/347] [D loss: 0.471497] [G loss: 0.385198]\n",
      "[Epoch 38/100] [Batch 286/347] [D loss: 0.505889] [G loss: 0.383362]\n",
      "[Epoch 38/100] [Batch 287/347] [D loss: 0.506758] [G loss: 0.377087]\n",
      "[Epoch 38/100] [Batch 288/347] [D loss: 0.488114] [G loss: 0.357383]\n",
      "[Epoch 38/100] [Batch 289/347] [D loss: 0.485733] [G loss: 0.349093]\n",
      "[Epoch 38/100] [Batch 290/347] [D loss: 0.503330] [G loss: 0.357214]\n",
      "[Epoch 38/100] [Batch 291/347] [D loss: 0.483896] [G loss: 0.349329]\n",
      "[Epoch 38/100] [Batch 292/347] [D loss: 0.478278] [G loss: 0.352062]\n",
      "[Epoch 38/100] [Batch 293/347] [D loss: 0.445526] [G loss: 0.368569]\n",
      "[Epoch 38/100] [Batch 294/347] [D loss: 0.407629] [G loss: 0.366725]\n",
      "[Epoch 38/100] [Batch 295/347] [D loss: 0.250614] [G loss: 0.353444]\n",
      "[Epoch 38/100] [Batch 296/347] [D loss: 0.238826] [G loss: 0.353567]\n",
      "[Epoch 38/100] [Batch 297/347] [D loss: 0.473208] [G loss: 0.367905]\n",
      "[Epoch 38/100] [Batch 298/347] [D loss: 0.525428] [G loss: 0.360422]\n",
      "[Epoch 38/100] [Batch 299/347] [D loss: 0.499179] [G loss: 0.357049]\n",
      "[Epoch 38/100] [Batch 300/347] [D loss: 0.459994] [G loss: 0.349918]\n",
      "[Epoch 38/100] [Batch 301/347] [D loss: 0.462546] [G loss: 0.343018]\n",
      "[Epoch 38/100] [Batch 302/347] [D loss: 0.489576] [G loss: 0.346459]\n",
      "[Epoch 38/100] [Batch 303/347] [D loss: 0.472297] [G loss: 0.323569]\n",
      "[Epoch 38/100] [Batch 304/347] [D loss: 0.476238] [G loss: 0.303136]\n",
      "[Epoch 38/100] [Batch 305/347] [D loss: 0.485271] [G loss: 0.303174]\n",
      "[Epoch 38/100] [Batch 306/347] [D loss: 0.346982] [G loss: 0.292364]\n",
      "[Epoch 38/100] [Batch 307/347] [D loss: 0.265578] [G loss: 0.298040]\n",
      "[Epoch 38/100] [Batch 308/347] [D loss: 0.328791] [G loss: 0.299481]\n",
      "[Epoch 38/100] [Batch 309/347] [D loss: 0.486690] [G loss: 0.316033]\n",
      "[Epoch 38/100] [Batch 310/347] [D loss: 0.527885] [G loss: 0.345122]\n",
      "[Epoch 38/100] [Batch 311/347] [D loss: 0.529587] [G loss: 0.349674]\n",
      "[Epoch 38/100] [Batch 312/347] [D loss: 0.528126] [G loss: 0.351347]\n",
      "[Epoch 38/100] [Batch 313/347] [D loss: 0.521736] [G loss: 0.352475]\n",
      "[Epoch 38/100] [Batch 314/347] [D loss: 0.491300] [G loss: 0.347594]\n",
      "[Epoch 38/100] [Batch 315/347] [D loss: 0.448638] [G loss: 0.339209]\n",
      "[Epoch 38/100] [Batch 316/347] [D loss: 0.449124] [G loss: 0.323115]\n",
      "[Epoch 38/100] [Batch 317/347] [D loss: 0.480677] [G loss: 0.312330]\n",
      "[Epoch 38/100] [Batch 318/347] [D loss: 0.500904] [G loss: 0.327790]\n",
      "[Epoch 38/100] [Batch 319/347] [D loss: 0.517555] [G loss: 0.360178]\n",
      "[Epoch 38/100] [Batch 320/347] [D loss: 0.524700] [G loss: 0.373246]\n",
      "[Epoch 38/100] [Batch 321/347] [D loss: 0.507236] [G loss: 0.362026]\n",
      "[Epoch 38/100] [Batch 322/347] [D loss: 0.497926] [G loss: 0.347958]\n",
      "[Epoch 38/100] [Batch 323/347] [D loss: 0.477709] [G loss: 0.345874]\n",
      "[Epoch 38/100] [Batch 324/347] [D loss: 0.472335] [G loss: 0.347397]\n",
      "[Epoch 38/100] [Batch 325/347] [D loss: 0.385007] [G loss: 0.335690]\n",
      "[Epoch 38/100] [Batch 326/347] [D loss: 0.362022] [G loss: 0.324109]\n",
      "[Epoch 38/100] [Batch 327/347] [D loss: 0.425889] [G loss: 0.322083]\n",
      "[Epoch 38/100] [Batch 328/347] [D loss: 0.467154] [G loss: 0.319716]\n",
      "[Epoch 38/100] [Batch 329/347] [D loss: 0.391049] [G loss: 0.310340]\n",
      "[Epoch 38/100] [Batch 330/347] [D loss: 0.379759] [G loss: 0.303501]\n",
      "[Epoch 38/100] [Batch 331/347] [D loss: 0.437305] [G loss: 0.311608]\n",
      "[Epoch 38/100] [Batch 332/347] [D loss: 0.509228] [G loss: 0.331978]\n",
      "[Epoch 38/100] [Batch 333/347] [D loss: 0.525344] [G loss: 0.343305]\n",
      "[Epoch 38/100] [Batch 334/347] [D loss: 0.507475] [G loss: 0.344615]\n",
      "[Epoch 38/100] [Batch 335/347] [D loss: 0.481867] [G loss: 0.332754]\n",
      "[Epoch 38/100] [Batch 336/347] [D loss: 0.470856] [G loss: 0.319450]\n",
      "[Epoch 38/100] [Batch 337/347] [D loss: 0.473736] [G loss: 0.324279]\n",
      "[Epoch 38/100] [Batch 338/347] [D loss: 0.497109] [G loss: 0.339445]\n",
      "[Epoch 38/100] [Batch 339/347] [D loss: 0.523981] [G loss: 0.345895]\n",
      "[Epoch 38/100] [Batch 340/347] [D loss: 0.529197] [G loss: 0.347714]\n",
      "[Epoch 38/100] [Batch 341/347] [D loss: 0.510217] [G loss: 0.344811]\n",
      "[Epoch 38/100] [Batch 342/347] [D loss: 0.502016] [G loss: 0.338913]\n",
      "[Epoch 38/100] [Batch 343/347] [D loss: 0.521824] [G loss: 0.345379]\n",
      "[Epoch 38/100] [Batch 344/347] [D loss: 0.454129] [G loss: 0.335403]\n",
      "[Epoch 38/100] [Batch 345/347] [D loss: 0.405088] [G loss: 0.313467]\n",
      "[Epoch 38/100] [Batch 346/347] [D loss: 0.356012] [G loss: 0.314428]\n",
      "[Epoch 38/100] [Batch 347/347] [D loss: 0.248028] [G loss: 0.328501]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 39/100] [Batch 1/347] [D loss: 0.504587] [G loss: 0.341901]\n",
      "[Epoch 39/100] [Batch 2/347] [D loss: 0.511081] [G loss: 0.347667]\n",
      "[Epoch 39/100] [Batch 3/347] [D loss: 0.527065] [G loss: 0.360673]\n",
      "[Epoch 39/100] [Batch 4/347] [D loss: 0.528020] [G loss: 0.364284]\n",
      "[Epoch 39/100] [Batch 5/347] [D loss: 0.526851] [G loss: 0.365315]\n",
      "[Epoch 39/100] [Batch 6/347] [D loss: 0.530418] [G loss: 0.368944]\n",
      "[Epoch 39/100] [Batch 7/347] [D loss: 0.526581] [G loss: 0.365364]\n",
      "[Epoch 39/100] [Batch 8/347] [D loss: 0.516498] [G loss: 0.361489]\n",
      "[Epoch 39/100] [Batch 9/347] [D loss: 0.502295] [G loss: 0.350680]\n",
      "[Epoch 39/100] [Batch 10/347] [D loss: 0.506059] [G loss: 0.350249]\n",
      "[Epoch 39/100] [Batch 11/347] [D loss: 0.524320] [G loss: 0.363164]\n",
      "[Epoch 39/100] [Batch 12/347] [D loss: 0.529148] [G loss: 0.366247]\n",
      "[Epoch 39/100] [Batch 13/347] [D loss: 0.531842] [G loss: 0.368560]\n",
      "[Epoch 39/100] [Batch 14/347] [D loss: 0.531429] [G loss: 0.369080]\n",
      "[Epoch 39/100] [Batch 15/347] [D loss: 0.523922] [G loss: 0.363445]\n",
      "[Epoch 39/100] [Batch 16/347] [D loss: 0.516296] [G loss: 0.357376]\n",
      "[Epoch 39/100] [Batch 17/347] [D loss: 0.500213] [G loss: 0.343473]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 39/100] [Batch 18/347] [D loss: 0.480296] [G loss: 0.341208]\n",
      "[Epoch 39/100] [Batch 19/347] [D loss: 0.489751] [G loss: 0.342752]\n",
      "[Epoch 39/100] [Batch 20/347] [D loss: 0.526470] [G loss: 0.352943]\n",
      "[Epoch 39/100] [Batch 21/347] [D loss: 0.526986] [G loss: 0.346479]\n",
      "[Epoch 39/100] [Batch 22/347] [D loss: 0.519158] [G loss: 0.338997]\n",
      "[Epoch 39/100] [Batch 23/347] [D loss: 0.496913] [G loss: 0.330348]\n",
      "[Epoch 39/100] [Batch 24/347] [D loss: 0.494229] [G loss: 0.326852]\n",
      "[Epoch 39/100] [Batch 25/347] [D loss: 0.508592] [G loss: 0.324069]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 39/100] [Batch 26/347] [D loss: 0.451648] [G loss: 0.313300]\n",
      "[Epoch 39/100] [Batch 27/347] [D loss: 0.279827] [G loss: 0.328766]\n",
      "[Epoch 39/100] [Batch 28/347] [D loss: 0.288412] [G loss: 0.338442]\n",
      "[Epoch 39/100] [Batch 29/347] [D loss: 0.496735] [G loss: 0.334582]\n",
      "[Epoch 39/100] [Batch 30/347] [D loss: 0.456924] [G loss: 0.341969]\n",
      "[Epoch 39/100] [Batch 31/347] [D loss: 0.405518] [G loss: 0.344711]\n",
      "[Epoch 39/100] [Batch 32/347] [D loss: 0.332019] [G loss: 0.340927]\n",
      "[Epoch 39/100] [Batch 33/347] [D loss: 0.352591] [G loss: 0.335203]\n",
      "[Epoch 39/100] [Batch 34/347] [D loss: 0.439167] [G loss: 0.336851]\n",
      "[Epoch 39/100] [Batch 35/347] [D loss: 0.431116] [G loss: 0.335698]\n",
      "[Epoch 39/100] [Batch 36/347] [D loss: 0.479357] [G loss: 0.329046]\n",
      "[Epoch 39/100] [Batch 37/347] [D loss: 0.430320] [G loss: 0.320761]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 39/100] [Batch 38/347] [D loss: 0.395771] [G loss: 0.307540]\n",
      "[Epoch 39/100] [Batch 39/347] [D loss: 0.433965] [G loss: 0.302391]\n",
      "[Epoch 39/100] [Batch 40/347] [D loss: 0.498930] [G loss: 0.299696]\n",
      "[Epoch 39/100] [Batch 41/347] [D loss: 0.500319] [G loss: 0.295933]\n",
      "[Epoch 39/100] [Batch 42/347] [D loss: 0.499564] [G loss: 0.298179]\n",
      "[Epoch 39/100] [Batch 43/347] [D loss: 0.494700] [G loss: 0.313615]\n",
      "[Epoch 39/100] [Batch 44/347] [D loss: 0.499233] [G loss: 0.326404]\n",
      "[Epoch 39/100] [Batch 45/347] [D loss: 0.521578] [G loss: 0.342671]\n",
      "[Epoch 39/100] [Batch 46/347] [D loss: 0.519444] [G loss: 0.336809]\n",
      "[Epoch 39/100] [Batch 47/347] [D loss: 0.496642] [G loss: 0.314278]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 39/100] [Batch 48/347] [D loss: 0.382545] [G loss: 0.303805]\n",
      "[Epoch 39/100] [Batch 49/347] [D loss: 0.381051] [G loss: 0.304734]\n",
      "[Epoch 39/100] [Batch 50/347] [D loss: 0.300939] [G loss: 0.317022]\n",
      "[Epoch 39/100] [Batch 51/347] [D loss: 0.283179] [G loss: 0.333610]\n",
      "[Epoch 39/100] [Batch 52/347] [D loss: 0.385171] [G loss: 0.335959]\n",
      "[Epoch 39/100] [Batch 53/347] [D loss: 0.471323] [G loss: 0.333423]\n",
      "[Epoch 39/100] [Batch 54/347] [D loss: 0.413337] [G loss: 0.321511]\n",
      "[Epoch 39/100] [Batch 55/347] [D loss: 0.401715] [G loss: 0.313991]\n",
      "[Epoch 39/100] [Batch 56/347] [D loss: 0.403433] [G loss: 0.301384]\n",
      "[Epoch 39/100] [Batch 57/347] [D loss: 0.412726] [G loss: 0.329785]\n",
      "[Epoch 39/100] [Batch 58/347] [D loss: 0.435425] [G loss: 0.340506]\n",
      "[Epoch 39/100] [Batch 59/347] [D loss: 0.401085] [G loss: 0.339067]\n",
      "[Epoch 39/100] [Batch 60/347] [D loss: 0.379779] [G loss: 0.334958]\n",
      "[Epoch 39/100] [Batch 61/347] [D loss: 0.358468] [G loss: 0.331736]\n",
      "[Epoch 39/100] [Batch 62/347] [D loss: 0.366108] [G loss: 0.316136]\n",
      "[Epoch 39/100] [Batch 63/347] [D loss: 0.395126] [G loss: 0.301673]\n",
      "[Epoch 39/100] [Batch 64/347] [D loss: 0.426419] [G loss: 0.313766]\n",
      "[Epoch 39/100] [Batch 65/347] [D loss: 0.491658] [G loss: 0.331370]\n",
      "[Epoch 39/100] [Batch 66/347] [D loss: 0.413265] [G loss: 0.332398]\n",
      "[Epoch 39/100] [Batch 67/347] [D loss: 0.248954] [G loss: 0.328150]\n",
      "[Epoch 39/100] [Batch 68/347] [D loss: 0.273619] [G loss: 0.326225]\n",
      "[Epoch 39/100] [Batch 69/347] [D loss: 0.399582] [G loss: 0.311430]\n",
      "[Epoch 39/100] [Batch 70/347] [D loss: 0.402717] [G loss: 0.303937]\n",
      "[Epoch 39/100] [Batch 71/347] [D loss: 0.388283] [G loss: 0.317174]\n",
      "[Epoch 39/100] [Batch 72/347] [D loss: 0.383468] [G loss: 0.317299]\n",
      "[Epoch 39/100] [Batch 73/347] [D loss: 0.385459] [G loss: 0.324960]\n",
      "[Epoch 39/100] [Batch 74/347] [D loss: 0.382218] [G loss: 0.344512]\n",
      "[Epoch 39/100] [Batch 75/347] [D loss: 0.398746] [G loss: 0.335791]\n",
      "[Epoch 39/100] [Batch 76/347] [D loss: 0.420629] [G loss: 0.314862]\n",
      "[Epoch 39/100] [Batch 77/347] [D loss: 0.426857] [G loss: 0.325853]\n",
      "[Epoch 39/100] [Batch 78/347] [D loss: 0.431028] [G loss: 0.342109]\n",
      "[Epoch 39/100] [Batch 79/347] [D loss: 0.500275] [G loss: 0.349632]\n",
      "[Epoch 39/100] [Batch 80/347] [D loss: 0.518710] [G loss: 0.344092]\n",
      "[Epoch 39/100] [Batch 81/347] [D loss: 0.509765] [G loss: 0.346300]\n",
      "[Epoch 39/100] [Batch 82/347] [D loss: 0.452044] [G loss: 0.337088]\n",
      "[Epoch 39/100] [Batch 83/347] [D loss: 0.440270] [G loss: 0.332341]\n",
      "[Epoch 39/100] [Batch 84/347] [D loss: 0.496748] [G loss: 0.341686]\n",
      "[Epoch 39/100] [Batch 85/347] [D loss: 0.531484] [G loss: 0.340244]\n",
      "[Epoch 39/100] [Batch 86/347] [D loss: 0.527050] [G loss: 0.333243]\n",
      "[Epoch 39/100] [Batch 87/347] [D loss: 0.526048] [G loss: 0.330328]\n",
      "[Epoch 39/100] [Batch 88/347] [D loss: 0.531567] [G loss: 0.333427]\n",
      "[Epoch 39/100] [Batch 89/347] [D loss: 0.538031] [G loss: 0.337107]\n",
      "[Epoch 39/100] [Batch 90/347] [D loss: 0.534623] [G loss: 0.334153]\n",
      "[Epoch 39/100] [Batch 91/347] [D loss: 0.534169] [G loss: 0.333873]\n",
      "[Epoch 39/100] [Batch 92/347] [D loss: 0.537134] [G loss: 0.337018]\n",
      "[Epoch 39/100] [Batch 93/347] [D loss: 0.536146] [G loss: 0.336839]\n",
      "[Epoch 39/100] [Batch 94/347] [D loss: 0.531003] [G loss: 0.335713]\n",
      "[Epoch 39/100] [Batch 95/347] [D loss: 0.531829] [G loss: 0.338861]\n",
      "[Epoch 39/100] [Batch 96/347] [D loss: 0.527735] [G loss: 0.336647]\n",
      "[Epoch 39/100] [Batch 97/347] [D loss: 0.523672] [G loss: 0.334372]\n",
      "[Epoch 39/100] [Batch 98/347] [D loss: 0.532205] [G loss: 0.342258]\n",
      "[Epoch 39/100] [Batch 99/347] [D loss: 0.536324] [G loss: 0.349349]\n",
      "[Epoch 39/100] [Batch 100/347] [D loss: 0.524894] [G loss: 0.348606]\n",
      "[Epoch 39/100] [Batch 101/347] [D loss: 0.523602] [G loss: 0.346708]\n",
      "[Epoch 39/100] [Batch 102/347] [D loss: 0.534810] [G loss: 0.351243]\n",
      "[Epoch 39/100] [Batch 103/347] [D loss: 0.535269] [G loss: 0.355016]\n",
      "[Epoch 39/100] [Batch 104/347] [D loss: 0.529246] [G loss: 0.349350]\n",
      "[Epoch 39/100] [Batch 105/347] [D loss: 0.530465] [G loss: 0.351485]\n",
      "[Epoch 39/100] [Batch 106/347] [D loss: 0.523194] [G loss: 0.353105]\n",
      "[Epoch 39/100] [Batch 107/347] [D loss: 0.467948] [G loss: 0.344414]\n",
      "[Epoch 39/100] [Batch 108/347] [D loss: 0.235943] [G loss: 0.361667]\n",
      "[Epoch 39/100] [Batch 109/347] [D loss: 0.233661] [G loss: 0.373573]\n",
      "[Epoch 39/100] [Batch 110/347] [D loss: 0.443151] [G loss: 0.372832]\n",
      "[Epoch 39/100] [Batch 111/347] [D loss: 0.277928] [G loss: 0.379276]\n",
      "[Epoch 39/100] [Batch 112/347] [D loss: 0.224632] [G loss: 0.391351]\n",
      "[Epoch 39/100] [Batch 113/347] [D loss: 0.439540] [G loss: 0.406575]\n",
      "[Epoch 39/100] [Batch 114/347] [D loss: 0.512869] [G loss: 0.432028]\n",
      "[Epoch 39/100] [Batch 115/347] [D loss: 0.503445] [G loss: 0.436332]\n",
      "[Epoch 39/100] [Batch 116/347] [D loss: 0.517110] [G loss: 0.432735]\n",
      "[Epoch 39/100] [Batch 117/347] [D loss: 0.501349] [G loss: 0.406972]\n",
      "[Epoch 39/100] [Batch 118/347] [D loss: 0.436055] [G loss: 0.393165]\n",
      "[Epoch 39/100] [Batch 119/347] [D loss: 0.399632] [G loss: 0.384612]\n",
      "[Epoch 39/100] [Batch 120/347] [D loss: 0.332078] [G loss: 0.385752]\n",
      "[Epoch 39/100] [Batch 121/347] [D loss: 0.318449] [G loss: 0.381034]\n",
      "[Epoch 39/100] [Batch 122/347] [D loss: 0.458163] [G loss: 0.378049]\n",
      "[Epoch 39/100] [Batch 123/347] [D loss: 0.523818] [G loss: 0.375645]\n",
      "[Epoch 39/100] [Batch 124/347] [D loss: 0.521218] [G loss: 0.365742]\n",
      "[Epoch 39/100] [Batch 125/347] [D loss: 0.526904] [G loss: 0.371275]\n",
      "[Epoch 39/100] [Batch 126/347] [D loss: 0.512987] [G loss: 0.377906]\n",
      "[Epoch 39/100] [Batch 127/347] [D loss: 0.502023] [G loss: 0.372933]\n",
      "[Epoch 39/100] [Batch 128/347] [D loss: 0.499099] [G loss: 0.360885]\n",
      "[Epoch 39/100] [Batch 129/347] [D loss: 0.425318] [G loss: 0.349631]\n",
      "[Epoch 39/100] [Batch 130/347] [D loss: 0.405471] [G loss: 0.345226]\n",
      "[Epoch 39/100] [Batch 131/347] [D loss: 0.354286] [G loss: 0.340124]\n",
      "[Epoch 39/100] [Batch 132/347] [D loss: 0.258244] [G loss: 0.344532]\n",
      "[Epoch 39/100] [Batch 133/347] [D loss: 0.258463] [G loss: 0.349842]\n",
      "[Epoch 39/100] [Batch 134/347] [D loss: 0.245422] [G loss: 0.361625]\n",
      "[Epoch 39/100] [Batch 135/347] [D loss: 0.241921] [G loss: 0.383955]\n",
      "[Epoch 39/100] [Batch 136/347] [D loss: 0.228826] [G loss: 0.404856]\n",
      "[Epoch 39/100] [Batch 137/347] [D loss: 0.456861] [G loss: 0.408381]\n",
      "[Epoch 39/100] [Batch 138/347] [D loss: 0.448999] [G loss: 0.408173]\n",
      "[Epoch 39/100] [Batch 139/347] [D loss: 0.428945] [G loss: 0.401882]\n",
      "[Epoch 39/100] [Batch 140/347] [D loss: 0.412179] [G loss: 0.404870]\n",
      "[Epoch 39/100] [Batch 141/347] [D loss: 0.419534] [G loss: 0.400985]\n",
      "[Epoch 39/100] [Batch 142/347] [D loss: 0.422565] [G loss: 0.399374]\n",
      "[Epoch 39/100] [Batch 143/347] [D loss: 0.384326] [G loss: 0.395951]\n",
      "[Epoch 39/100] [Batch 144/347] [D loss: 0.377240] [G loss: 0.395087]\n",
      "[Epoch 39/100] [Batch 145/347] [D loss: 0.381172] [G loss: 0.375088]\n",
      "[Epoch 39/100] [Batch 146/347] [D loss: 0.383786] [G loss: 0.351015]\n",
      "[Epoch 39/100] [Batch 147/347] [D loss: 0.416637] [G loss: 0.353093]\n",
      "[Epoch 39/100] [Batch 148/347] [D loss: 0.423474] [G loss: 0.349128]\n",
      "[Epoch 39/100] [Batch 149/347] [D loss: 0.433664] [G loss: 0.334139]\n",
      "[Epoch 39/100] [Batch 150/347] [D loss: 0.443111] [G loss: 0.326793]\n",
      "[Epoch 39/100] [Batch 151/347] [D loss: 0.435769] [G loss: 0.327390]\n",
      "[Epoch 39/100] [Batch 152/347] [D loss: 0.392260] [G loss: 0.320837]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 39/100] [Batch 153/347] [D loss: 0.357272] [G loss: 0.299387]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 39/100] [Batch 154/347] [D loss: 0.354323] [G loss: 0.277120]\n",
      "[Epoch 39/100] [Batch 155/347] [D loss: 0.375268] [G loss: 0.272605]\n",
      "[Epoch 39/100] [Batch 156/347] [D loss: 0.413304] [G loss: 0.280852]\n",
      "[Epoch 39/100] [Batch 157/347] [D loss: 0.396567] [G loss: 0.291650]\n",
      "[Epoch 39/100] [Batch 158/347] [D loss: 0.366384] [G loss: 0.281003]\n",
      "[Epoch 39/100] [Batch 159/347] [D loss: 0.358229] [G loss: 0.270189]\n",
      "[Epoch 39/100] [Batch 160/347] [D loss: 0.312337] [G loss: 0.292837]\n",
      "[Epoch 39/100] [Batch 161/347] [D loss: 0.306349] [G loss: 0.312706]\n",
      "[Epoch 39/100] [Batch 162/347] [D loss: 0.369704] [G loss: 0.316934]\n",
      "[Epoch 39/100] [Batch 163/347] [D loss: 0.375994] [G loss: 0.312640]\n",
      "[Epoch 39/100] [Batch 164/347] [D loss: 0.352618] [G loss: 0.308957]\n",
      "[Epoch 39/100] [Batch 165/347] [D loss: 0.335478] [G loss: 0.305932]\n",
      "[Epoch 39/100] [Batch 166/347] [D loss: 0.348925] [G loss: 0.320675]\n",
      "[Epoch 39/100] [Batch 167/347] [D loss: 0.309768] [G loss: 0.345320]\n",
      "[Epoch 39/100] [Batch 168/347] [D loss: 0.272152] [G loss: 0.362167]\n",
      "[Epoch 39/100] [Batch 169/347] [D loss: 0.408613] [G loss: 0.368483]\n",
      "[Epoch 39/100] [Batch 170/347] [D loss: 0.491080] [G loss: 0.384379]\n",
      "[Epoch 39/100] [Batch 171/347] [D loss: 0.528294] [G loss: 0.399778]\n",
      "[Epoch 39/100] [Batch 172/347] [D loss: 0.536549] [G loss: 0.407865]\n",
      "[Epoch 39/100] [Batch 173/347] [D loss: 0.475122] [G loss: 0.398578]\n",
      "[Epoch 39/100] [Batch 174/347] [D loss: 0.474242] [G loss: 0.396856]\n",
      "[Epoch 39/100] [Batch 175/347] [D loss: 0.540089] [G loss: 0.407117]\n",
      "[Epoch 39/100] [Batch 176/347] [D loss: 0.557931] [G loss: 0.421020]\n",
      "[Epoch 39/100] [Batch 177/347] [D loss: 0.560323] [G loss: 0.422767]\n",
      "[Epoch 39/100] [Batch 178/347] [D loss: 0.554703] [G loss: 0.417663]\n",
      "[Epoch 39/100] [Batch 179/347] [D loss: 0.548860] [G loss: 0.411827]\n",
      "[Epoch 39/100] [Batch 180/347] [D loss: 0.544796] [G loss: 0.406078]\n",
      "[Epoch 39/100] [Batch 181/347] [D loss: 0.545909] [G loss: 0.407365]\n",
      "[Epoch 39/100] [Batch 182/347] [D loss: 0.545526] [G loss: 0.405767]\n",
      "[Epoch 39/100] [Batch 183/347] [D loss: 0.547550] [G loss: 0.410285]\n",
      "[Epoch 39/100] [Batch 184/347] [D loss: 0.551690] [G loss: 0.414696]\n",
      "[Epoch 39/100] [Batch 185/347] [D loss: 0.552869] [G loss: 0.413906]\n",
      "[Epoch 39/100] [Batch 186/347] [D loss: 0.553226] [G loss: 0.414580]\n",
      "[Epoch 39/100] [Batch 187/347] [D loss: 0.550081] [G loss: 0.409884]\n",
      "[Epoch 39/100] [Batch 188/347] [D loss: 0.548659] [G loss: 0.407153]\n",
      "[Epoch 39/100] [Batch 189/347] [D loss: 0.546796] [G loss: 0.407021]\n",
      "[Epoch 39/100] [Batch 190/347] [D loss: 0.536109] [G loss: 0.395617]\n",
      "[Epoch 39/100] [Batch 191/347] [D loss: 0.516433] [G loss: 0.383164]\n",
      "[Epoch 39/100] [Batch 192/347] [D loss: 0.509769] [G loss: 0.384433]\n",
      "[Epoch 39/100] [Batch 193/347] [D loss: 0.521324] [G loss: 0.392123]\n",
      "[Epoch 39/100] [Batch 194/347] [D loss: 0.536902] [G loss: 0.386645]\n",
      "[Epoch 39/100] [Batch 195/347] [D loss: 0.539017] [G loss: 0.378415]\n",
      "[Epoch 39/100] [Batch 196/347] [D loss: 0.532078] [G loss: 0.372606]\n",
      "[Epoch 39/100] [Batch 197/347] [D loss: 0.510966] [G loss: 0.369594]\n",
      "[Epoch 39/100] [Batch 198/347] [D loss: 0.452857] [G loss: 0.366134]\n",
      "[Epoch 39/100] [Batch 199/347] [D loss: 0.457586] [G loss: 0.360830]\n",
      "[Epoch 39/100] [Batch 200/347] [D loss: 0.518530] [G loss: 0.361589]\n",
      "[Epoch 39/100] [Batch 201/347] [D loss: 0.522080] [G loss: 0.359782]\n",
      "[Epoch 39/100] [Batch 202/347] [D loss: 0.528099] [G loss: 0.352610]\n",
      "[Epoch 39/100] [Batch 203/347] [D loss: 0.536318] [G loss: 0.346580]\n",
      "[Epoch 39/100] [Batch 204/347] [D loss: 0.536847] [G loss: 0.345033]\n",
      "[Epoch 39/100] [Batch 205/347] [D loss: 0.535437] [G loss: 0.344172]\n",
      "[Epoch 39/100] [Batch 206/347] [D loss: 0.533338] [G loss: 0.347206]\n",
      "[Epoch 39/100] [Batch 207/347] [D loss: 0.534104] [G loss: 0.356281]\n",
      "[Epoch 39/100] [Batch 208/347] [D loss: 0.537040] [G loss: 0.355964]\n",
      "[Epoch 39/100] [Batch 209/347] [D loss: 0.523788] [G loss: 0.349272]\n",
      "[Epoch 39/100] [Batch 210/347] [D loss: 0.519735] [G loss: 0.354751]\n",
      "[Epoch 39/100] [Batch 211/347] [D loss: 0.525289] [G loss: 0.352931]\n",
      "[Epoch 39/100] [Batch 212/347] [D loss: 0.369251] [G loss: 0.346388]\n",
      "[Epoch 39/100] [Batch 213/347] [D loss: 0.346722] [G loss: 0.350471]\n",
      "[Epoch 39/100] [Batch 214/347] [D loss: 0.240911] [G loss: 0.360811]\n",
      "[Epoch 39/100] [Batch 215/347] [D loss: 0.238216] [G loss: 0.367165]\n",
      "[Epoch 39/100] [Batch 216/347] [D loss: 0.432758] [G loss: 0.366824]\n",
      "[Epoch 39/100] [Batch 217/347] [D loss: 0.496381] [G loss: 0.371911]\n",
      "[Epoch 39/100] [Batch 218/347] [D loss: 0.542801] [G loss: 0.389729]\n",
      "[Epoch 39/100] [Batch 219/347] [D loss: 0.531496] [G loss: 0.405416]\n",
      "[Epoch 39/100] [Batch 220/347] [D loss: 0.532795] [G loss: 0.424202]\n",
      "[Epoch 39/100] [Batch 221/347] [D loss: 0.539625] [G loss: 0.427949]\n",
      "[Epoch 39/100] [Batch 222/347] [D loss: 0.530535] [G loss: 0.422302]\n",
      "[Epoch 39/100] [Batch 223/347] [D loss: 0.530658] [G loss: 0.422808]\n",
      "[Epoch 39/100] [Batch 224/347] [D loss: 0.533170] [G loss: 0.419887]\n",
      "[Epoch 39/100] [Batch 225/347] [D loss: 0.514319] [G loss: 0.402413]\n",
      "[Epoch 39/100] [Batch 226/347] [D loss: 0.508334] [G loss: 0.379574]\n",
      "[Epoch 39/100] [Batch 227/347] [D loss: 0.513470] [G loss: 0.354535]\n",
      "[Epoch 39/100] [Batch 228/347] [D loss: 0.518567] [G loss: 0.355834]\n",
      "[Epoch 39/100] [Batch 229/347] [D loss: 0.528360] [G loss: 0.365919]\n",
      "[Epoch 39/100] [Batch 230/347] [D loss: 0.531666] [G loss: 0.367868]\n",
      "[Epoch 39/100] [Batch 231/347] [D loss: 0.526929] [G loss: 0.360132]\n",
      "[Epoch 39/100] [Batch 232/347] [D loss: 0.527407] [G loss: 0.360177]\n",
      "[Epoch 39/100] [Batch 233/347] [D loss: 0.516723] [G loss: 0.358762]\n",
      "[Epoch 39/100] [Batch 234/347] [D loss: 0.497411] [G loss: 0.362838]\n",
      "[Epoch 39/100] [Batch 235/347] [D loss: 0.491689] [G loss: 0.369276]\n",
      "[Epoch 39/100] [Batch 236/347] [D loss: 0.500761] [G loss: 0.371209]\n",
      "[Epoch 39/100] [Batch 237/347] [D loss: 0.518510] [G loss: 0.374692]\n",
      "[Epoch 39/100] [Batch 238/347] [D loss: 0.538052] [G loss: 0.375116]\n",
      "[Epoch 39/100] [Batch 239/347] [D loss: 0.530603] [G loss: 0.369706]\n",
      "[Epoch 39/100] [Batch 240/347] [D loss: 0.524174] [G loss: 0.363094]\n",
      "[Epoch 39/100] [Batch 241/347] [D loss: 0.521876] [G loss: 0.354654]\n",
      "[Epoch 39/100] [Batch 242/347] [D loss: 0.524854] [G loss: 0.350446]\n",
      "[Epoch 39/100] [Batch 243/347] [D loss: 0.534747] [G loss: 0.356477]\n",
      "[Epoch 39/100] [Batch 244/347] [D loss: 0.539120] [G loss: 0.364257]\n",
      "[Epoch 39/100] [Batch 245/347] [D loss: 0.508846] [G loss: 0.361646]\n",
      "[Epoch 39/100] [Batch 246/347] [D loss: 0.490406] [G loss: 0.350096]\n",
      "[Epoch 39/100] [Batch 247/347] [D loss: 0.504882] [G loss: 0.319924]\n",
      "[Epoch 39/100] [Batch 248/347] [D loss: 0.516865] [G loss: 0.312564]\n",
      "[Epoch 39/100] [Batch 249/347] [D loss: 0.511068] [G loss: 0.308741]\n",
      "[Epoch 39/100] [Batch 250/347] [D loss: 0.505118] [G loss: 0.329515]\n",
      "[Epoch 39/100] [Batch 251/347] [D loss: 0.496690] [G loss: 0.345771]\n",
      "[Epoch 39/100] [Batch 252/347] [D loss: 0.493162] [G loss: 0.347561]\n",
      "[Epoch 39/100] [Batch 253/347] [D loss: 0.504192] [G loss: 0.346661]\n",
      "[Epoch 39/100] [Batch 254/347] [D loss: 0.514654] [G loss: 0.344105]\n",
      "[Epoch 39/100] [Batch 255/347] [D loss: 0.476431] [G loss: 0.341695]\n",
      "[Epoch 39/100] [Batch 256/347] [D loss: 0.468907] [G loss: 0.345923]\n",
      "[Epoch 39/100] [Batch 257/347] [D loss: 0.486742] [G loss: 0.350413]\n",
      "[Epoch 39/100] [Batch 258/347] [D loss: 0.441222] [G loss: 0.341766]\n",
      "[Epoch 39/100] [Batch 259/347] [D loss: 0.419907] [G loss: 0.328057]\n",
      "[Epoch 39/100] [Batch 260/347] [D loss: 0.379247] [G loss: 0.325394]\n",
      "[Epoch 39/100] [Batch 261/347] [D loss: 0.390009] [G loss: 0.333077]\n",
      "[Epoch 39/100] [Batch 262/347] [D loss: 0.454217] [G loss: 0.328137]\n",
      "[Epoch 39/100] [Batch 263/347] [D loss: 0.421580] [G loss: 0.326357]\n",
      "[Epoch 39/100] [Batch 264/347] [D loss: 0.376065] [G loss: 0.328868]\n",
      "[Epoch 39/100] [Batch 265/347] [D loss: 0.388178] [G loss: 0.326715]\n",
      "[Epoch 39/100] [Batch 266/347] [D loss: 0.406899] [G loss: 0.323781]\n",
      "[Epoch 39/100] [Batch 267/347] [D loss: 0.414763] [G loss: 0.322251]\n",
      "[Epoch 39/100] [Batch 268/347] [D loss: 0.366215] [G loss: 0.327793]\n",
      "[Epoch 39/100] [Batch 269/347] [D loss: 0.364267] [G loss: 0.330275]\n",
      "[Epoch 39/100] [Batch 270/347] [D loss: 0.411900] [G loss: 0.328198]\n",
      "[Epoch 39/100] [Batch 271/347] [D loss: 0.448506] [G loss: 0.325635]\n",
      "[Epoch 39/100] [Batch 272/347] [D loss: 0.473889] [G loss: 0.327995]\n",
      "[Epoch 39/100] [Batch 273/347] [D loss: 0.401700] [G loss: 0.336759]\n",
      "[Epoch 39/100] [Batch 274/347] [D loss: 0.501607] [G loss: 0.359253]\n",
      "[Epoch 39/100] [Batch 275/347] [D loss: 0.471284] [G loss: 0.372413]\n",
      "[Epoch 39/100] [Batch 276/347] [D loss: 0.396114] [G loss: 0.367678]\n",
      "[Epoch 39/100] [Batch 277/347] [D loss: 0.409025] [G loss: 0.373721]\n",
      "[Epoch 39/100] [Batch 278/347] [D loss: 0.498861] [G loss: 0.390730]\n",
      "[Epoch 39/100] [Batch 279/347] [D loss: 0.478009] [G loss: 0.390841]\n",
      "[Epoch 39/100] [Batch 280/347] [D loss: 0.460509] [G loss: 0.397813]\n",
      "[Epoch 39/100] [Batch 281/347] [D loss: 0.463636] [G loss: 0.398346]\n",
      "[Epoch 39/100] [Batch 282/347] [D loss: 0.477327] [G loss: 0.397433]\n",
      "[Epoch 39/100] [Batch 283/347] [D loss: 0.416862] [G loss: 0.397711]\n",
      "[Epoch 39/100] [Batch 284/347] [D loss: 0.404936] [G loss: 0.398701]\n",
      "[Epoch 39/100] [Batch 285/347] [D loss: 0.471895] [G loss: 0.398513]\n",
      "[Epoch 39/100] [Batch 286/347] [D loss: 0.511201] [G loss: 0.396408]\n",
      "[Epoch 39/100] [Batch 287/347] [D loss: 0.512442] [G loss: 0.390226]\n",
      "[Epoch 39/100] [Batch 288/347] [D loss: 0.494381] [G loss: 0.367830]\n",
      "[Epoch 39/100] [Batch 289/347] [D loss: 0.492319] [G loss: 0.359563]\n",
      "[Epoch 39/100] [Batch 290/347] [D loss: 0.510475] [G loss: 0.370561]\n",
      "[Epoch 39/100] [Batch 291/347] [D loss: 0.488845] [G loss: 0.362981]\n",
      "[Epoch 39/100] [Batch 292/347] [D loss: 0.482055] [G loss: 0.365918]\n",
      "[Epoch 39/100] [Batch 293/347] [D loss: 0.444179] [G loss: 0.382773]\n",
      "[Epoch 39/100] [Batch 294/347] [D loss: 0.401580] [G loss: 0.381150]\n",
      "[Epoch 39/100] [Batch 295/347] [D loss: 0.245747] [G loss: 0.365902]\n",
      "[Epoch 39/100] [Batch 296/347] [D loss: 0.234003] [G loss: 0.368565]\n",
      "[Epoch 39/100] [Batch 297/347] [D loss: 0.478874] [G loss: 0.383299]\n",
      "[Epoch 39/100] [Batch 298/347] [D loss: 0.534885] [G loss: 0.376449]\n",
      "[Epoch 39/100] [Batch 299/347] [D loss: 0.504752] [G loss: 0.373335]\n",
      "[Epoch 39/100] [Batch 300/347] [D loss: 0.461017] [G loss: 0.366547]\n",
      "[Epoch 39/100] [Batch 301/347] [D loss: 0.465087] [G loss: 0.359875]\n",
      "[Epoch 39/100] [Batch 302/347] [D loss: 0.496768] [G loss: 0.363466]\n",
      "[Epoch 39/100] [Batch 303/347] [D loss: 0.478376] [G loss: 0.338430]\n",
      "[Epoch 39/100] [Batch 304/347] [D loss: 0.483178] [G loss: 0.320609]\n",
      "[Epoch 39/100] [Batch 305/347] [D loss: 0.493883] [G loss: 0.320397]\n",
      "[Epoch 39/100] [Batch 306/347] [D loss: 0.341467] [G loss: 0.309538]\n",
      "[Epoch 39/100] [Batch 307/347] [D loss: 0.258962] [G loss: 0.313183]\n",
      "[Epoch 39/100] [Batch 308/347] [D loss: 0.326129] [G loss: 0.314355]\n",
      "[Epoch 39/100] [Batch 309/347] [D loss: 0.493584] [G loss: 0.332523]\n",
      "[Epoch 39/100] [Batch 310/347] [D loss: 0.538367] [G loss: 0.360924]\n",
      "[Epoch 39/100] [Batch 311/347] [D loss: 0.540064] [G loss: 0.365486]\n",
      "[Epoch 39/100] [Batch 312/347] [D loss: 0.538461] [G loss: 0.366943]\n",
      "[Epoch 39/100] [Batch 313/347] [D loss: 0.531339] [G loss: 0.367992]\n",
      "[Epoch 39/100] [Batch 314/347] [D loss: 0.497390] [G loss: 0.363163]\n",
      "[Epoch 39/100] [Batch 315/347] [D loss: 0.450563] [G loss: 0.354690]\n",
      "[Epoch 39/100] [Batch 316/347] [D loss: 0.451128] [G loss: 0.338491]\n",
      "[Epoch 39/100] [Batch 317/347] [D loss: 0.488466] [G loss: 0.327663]\n",
      "[Epoch 39/100] [Batch 318/347] [D loss: 0.510769] [G loss: 0.343418]\n",
      "[Epoch 39/100] [Batch 319/347] [D loss: 0.525542] [G loss: 0.375673]\n",
      "[Epoch 39/100] [Batch 320/347] [D loss: 0.531252] [G loss: 0.388850]\n",
      "[Epoch 39/100] [Batch 321/347] [D loss: 0.512909] [G loss: 0.377782]\n",
      "[Epoch 39/100] [Batch 322/347] [D loss: 0.504326] [G loss: 0.363792]\n",
      "[Epoch 39/100] [Batch 323/347] [D loss: 0.480849] [G loss: 0.361677]\n",
      "[Epoch 39/100] [Batch 324/347] [D loss: 0.474448] [G loss: 0.363413]\n",
      "[Epoch 39/100] [Batch 325/347] [D loss: 0.381460] [G loss: 0.351809]\n",
      "[Epoch 39/100] [Batch 326/347] [D loss: 0.356766] [G loss: 0.339459]\n",
      "[Epoch 39/100] [Batch 327/347] [D loss: 0.426586] [G loss: 0.337607]\n",
      "[Epoch 39/100] [Batch 328/347] [D loss: 0.471791] [G loss: 0.335280]\n",
      "[Epoch 39/100] [Batch 329/347] [D loss: 0.390022] [G loss: 0.325305]\n",
      "[Epoch 39/100] [Batch 330/347] [D loss: 0.378428] [G loss: 0.318586]\n",
      "[Epoch 39/100] [Batch 331/347] [D loss: 0.441039] [G loss: 0.326649]\n",
      "[Epoch 39/100] [Batch 332/347] [D loss: 0.517613] [G loss: 0.346517]\n",
      "[Epoch 39/100] [Batch 333/347] [D loss: 0.533909] [G loss: 0.357538]\n",
      "[Epoch 39/100] [Batch 334/347] [D loss: 0.513493] [G loss: 0.358829]\n",
      "[Epoch 39/100] [Batch 335/347] [D loss: 0.486634] [G loss: 0.346673]\n",
      "[Epoch 39/100] [Batch 336/347] [D loss: 0.476426] [G loss: 0.334034]\n",
      "[Epoch 39/100] [Batch 337/347] [D loss: 0.478019] [G loss: 0.337460]\n",
      "[Epoch 39/100] [Batch 338/347] [D loss: 0.502119] [G loss: 0.351884]\n",
      "[Epoch 39/100] [Batch 339/347] [D loss: 0.532178] [G loss: 0.357579]\n",
      "[Epoch 39/100] [Batch 340/347] [D loss: 0.538104] [G loss: 0.358918]\n",
      "[Epoch 39/100] [Batch 341/347] [D loss: 0.517492] [G loss: 0.355104]\n",
      "[Epoch 39/100] [Batch 342/347] [D loss: 0.508641] [G loss: 0.348370]\n",
      "[Epoch 39/100] [Batch 343/347] [D loss: 0.529883] [G loss: 0.354425]\n",
      "[Epoch 39/100] [Batch 344/347] [D loss: 0.453697] [G loss: 0.343906]\n",
      "[Epoch 39/100] [Batch 345/347] [D loss: 0.400819] [G loss: 0.323741]\n",
      "[Epoch 39/100] [Batch 346/347] [D loss: 0.353213] [G loss: 0.324762]\n",
      "[Epoch 39/100] [Batch 347/347] [D loss: 0.250286] [G loss: 0.338629]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 40/100] [Batch 1/347] [D loss: 0.510721] [G loss: 0.349834]\n",
      "[Epoch 40/100] [Batch 2/347] [D loss: 0.517735] [G loss: 0.355788]\n",
      "[Epoch 40/100] [Batch 3/347] [D loss: 0.535230] [G loss: 0.369382]\n",
      "[Epoch 40/100] [Batch 4/347] [D loss: 0.536128] [G loss: 0.373147]\n",
      "[Epoch 40/100] [Batch 5/347] [D loss: 0.534764] [G loss: 0.374886]\n",
      "[Epoch 40/100] [Batch 6/347] [D loss: 0.538481] [G loss: 0.378849]\n",
      "[Epoch 40/100] [Batch 7/347] [D loss: 0.534659] [G loss: 0.375829]\n",
      "[Epoch 40/100] [Batch 8/347] [D loss: 0.523311] [G loss: 0.372878]\n",
      "[Epoch 40/100] [Batch 9/347] [D loss: 0.508597] [G loss: 0.362850]\n",
      "[Epoch 40/100] [Batch 10/347] [D loss: 0.512845] [G loss: 0.363401]\n",
      "[Epoch 40/100] [Batch 11/347] [D loss: 0.532168] [G loss: 0.377212]\n",
      "[Epoch 40/100] [Batch 12/347] [D loss: 0.537174] [G loss: 0.381415]\n",
      "[Epoch 40/100] [Batch 13/347] [D loss: 0.539864] [G loss: 0.384591]\n",
      "[Epoch 40/100] [Batch 14/347] [D loss: 0.538989] [G loss: 0.386100]\n",
      "[Epoch 40/100] [Batch 15/347] [D loss: 0.530768] [G loss: 0.381420]\n",
      "[Epoch 40/100] [Batch 16/347] [D loss: 0.522875] [G loss: 0.376216]\n",
      "[Epoch 40/100] [Batch 17/347] [D loss: 0.506920] [G loss: 0.365674]\n",
      "[Epoch 40/100] [Batch 18/347] [D loss: 0.485333] [G loss: 0.364479]\n",
      "[Epoch 40/100] [Batch 19/347] [D loss: 0.494230] [G loss: 0.365305]\n",
      "[Epoch 40/100] [Batch 20/347] [D loss: 0.533823] [G loss: 0.375811]\n",
      "[Epoch 40/100] [Batch 21/347] [D loss: 0.534671] [G loss: 0.370302]\n",
      "[Epoch 40/100] [Batch 22/347] [D loss: 0.526672] [G loss: 0.363527]\n",
      "[Epoch 40/100] [Batch 23/347] [D loss: 0.503039] [G loss: 0.355350]\n",
      "[Epoch 40/100] [Batch 24/347] [D loss: 0.500253] [G loss: 0.352953]\n",
      "[Epoch 40/100] [Batch 25/347] [D loss: 0.515814] [G loss: 0.350532]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 40/100] [Batch 26/347] [D loss: 0.455367] [G loss: 0.341567]\n",
      "[Epoch 40/100] [Batch 27/347] [D loss: 0.268889] [G loss: 0.356329]\n",
      "[Epoch 40/100] [Batch 28/347] [D loss: 0.278132] [G loss: 0.364660]\n",
      "[Epoch 40/100] [Batch 29/347] [D loss: 0.500556] [G loss: 0.358270]\n",
      "[Epoch 40/100] [Batch 30/347] [D loss: 0.456056] [G loss: 0.364159]\n",
      "[Epoch 40/100] [Batch 31/347] [D loss: 0.400499] [G loss: 0.365450]\n",
      "[Epoch 40/100] [Batch 32/347] [D loss: 0.323913] [G loss: 0.360950]\n",
      "[Epoch 40/100] [Batch 33/347] [D loss: 0.345173] [G loss: 0.352689]\n",
      "[Epoch 40/100] [Batch 34/347] [D loss: 0.435283] [G loss: 0.352318]\n",
      "[Epoch 40/100] [Batch 35/347] [D loss: 0.424406] [G loss: 0.349600]\n",
      "[Epoch 40/100] [Batch 36/347] [D loss: 0.480165] [G loss: 0.341747]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 40/100] [Batch 37/347] [D loss: 0.429029] [G loss: 0.331965]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 40/100] [Batch 38/347] [D loss: 0.391106] [G loss: 0.317169]\n",
      "[Epoch 40/100] [Batch 39/347] [D loss: 0.431959] [G loss: 0.310930]\n",
      "[Epoch 40/100] [Batch 40/347] [D loss: 0.504316] [G loss: 0.306414]\n",
      "[Epoch 40/100] [Batch 41/347] [D loss: 0.506427] [G loss: 0.301822]\n",
      "[Epoch 40/100] [Batch 42/347] [D loss: 0.505126] [G loss: 0.303128]\n",
      "[Epoch 40/100] [Batch 43/347] [D loss: 0.497417] [G loss: 0.318439]\n",
      "[Epoch 40/100] [Batch 44/347] [D loss: 0.500210] [G loss: 0.330355]\n",
      "[Epoch 40/100] [Batch 45/347] [D loss: 0.523538] [G loss: 0.346138]\n",
      "[Epoch 40/100] [Batch 46/347] [D loss: 0.521720] [G loss: 0.339845]\n",
      "[Epoch 40/100] [Batch 47/347] [D loss: 0.499910] [G loss: 0.317234]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 40/100] [Batch 48/347] [D loss: 0.374307] [G loss: 0.306664]\n",
      "[Epoch 40/100] [Batch 49/347] [D loss: 0.373481] [G loss: 0.307906]\n",
      "[Epoch 40/100] [Batch 50/347] [D loss: 0.297814] [G loss: 0.320312]\n",
      "[Epoch 40/100] [Batch 51/347] [D loss: 0.280420] [G loss: 0.336887]\n",
      "[Epoch 40/100] [Batch 52/347] [D loss: 0.382438] [G loss: 0.339904]\n",
      "[Epoch 40/100] [Batch 53/347] [D loss: 0.471946] [G loss: 0.337917]\n",
      "[Epoch 40/100] [Batch 54/347] [D loss: 0.413339] [G loss: 0.326614]\n",
      "[Epoch 40/100] [Batch 55/347] [D loss: 0.402342] [G loss: 0.304631]\n",
      "[Epoch 40/100] [Batch 56/347] [D loss: 0.402806] [G loss: 0.306588]\n",
      "[Epoch 40/100] [Batch 57/347] [D loss: 0.409066] [G loss: 0.337157]\n",
      "[Epoch 40/100] [Batch 58/347] [D loss: 0.430426] [G loss: 0.348810]\n",
      "[Epoch 40/100] [Batch 59/347] [D loss: 0.397419] [G loss: 0.348252]\n",
      "[Epoch 40/100] [Batch 60/347] [D loss: 0.375893] [G loss: 0.344632]\n",
      "[Epoch 40/100] [Batch 61/347] [D loss: 0.351809] [G loss: 0.342016]\n",
      "[Epoch 40/100] [Batch 62/347] [D loss: 0.361395] [G loss: 0.326914]\n",
      "[Epoch 40/100] [Batch 63/347] [D loss: 0.394112] [G loss: 0.303963]\n",
      "[Epoch 40/100] [Batch 64/347] [D loss: 0.424024] [G loss: 0.323855]\n",
      "[Epoch 40/100] [Batch 65/347] [D loss: 0.490536] [G loss: 0.341202]\n",
      "[Epoch 40/100] [Batch 66/347] [D loss: 0.410032] [G loss: 0.341126]\n",
      "[Epoch 40/100] [Batch 67/347] [D loss: 0.241607] [G loss: 0.336036]\n",
      "[Epoch 40/100] [Batch 68/347] [D loss: 0.267149] [G loss: 0.333100]\n",
      "[Epoch 40/100] [Batch 69/347] [D loss: 0.394342] [G loss: 0.317444]\n",
      "[Epoch 40/100] [Batch 70/347] [D loss: 0.397339] [G loss: 0.308818]\n",
      "[Epoch 40/100] [Batch 71/347] [D loss: 0.381856] [G loss: 0.320870]\n",
      "[Epoch 40/100] [Batch 72/347] [D loss: 0.376732] [G loss: 0.319875]\n",
      "[Epoch 40/100] [Batch 73/347] [D loss: 0.377562] [G loss: 0.326269]\n",
      "[Epoch 40/100] [Batch 74/347] [D loss: 0.374560] [G loss: 0.344792]\n",
      "[Epoch 40/100] [Batch 75/347] [D loss: 0.392701] [G loss: 0.335204]\n",
      "[Epoch 40/100] [Batch 76/347] [D loss: 0.415374] [G loss: 0.312980]\n",
      "[Epoch 40/100] [Batch 77/347] [D loss: 0.417780] [G loss: 0.323356]\n",
      "[Epoch 40/100] [Batch 78/347] [D loss: 0.419464] [G loss: 0.338362]\n",
      "[Epoch 40/100] [Batch 79/347] [D loss: 0.495009] [G loss: 0.346221]\n",
      "[Epoch 40/100] [Batch 80/347] [D loss: 0.516854] [G loss: 0.339838]\n",
      "[Epoch 40/100] [Batch 81/347] [D loss: 0.505845] [G loss: 0.341627]\n",
      "[Epoch 40/100] [Batch 82/347] [D loss: 0.439885] [G loss: 0.331664]\n",
      "[Epoch 40/100] [Batch 83/347] [D loss: 0.426592] [G loss: 0.327200]\n",
      "[Epoch 40/100] [Batch 84/347] [D loss: 0.488425] [G loss: 0.335918]\n",
      "[Epoch 40/100] [Batch 85/347] [D loss: 0.530587] [G loss: 0.334750]\n",
      "[Epoch 40/100] [Batch 86/347] [D loss: 0.525907] [G loss: 0.327724]\n",
      "[Epoch 40/100] [Batch 87/347] [D loss: 0.524844] [G loss: 0.324658]\n",
      "[Epoch 40/100] [Batch 88/347] [D loss: 0.530831] [G loss: 0.327953]\n",
      "[Epoch 40/100] [Batch 89/347] [D loss: 0.538160] [G loss: 0.331886]\n",
      "[Epoch 40/100] [Batch 90/347] [D loss: 0.534373] [G loss: 0.329206]\n",
      "[Epoch 40/100] [Batch 91/347] [D loss: 0.533826] [G loss: 0.329174]\n",
      "[Epoch 40/100] [Batch 92/347] [D loss: 0.537042] [G loss: 0.332572]\n",
      "[Epoch 40/100] [Batch 93/347] [D loss: 0.536018] [G loss: 0.332870]\n",
      "[Epoch 40/100] [Batch 94/347] [D loss: 0.530078] [G loss: 0.331967]\n",
      "[Epoch 40/100] [Batch 95/347] [D loss: 0.530906] [G loss: 0.335407]\n",
      "[Epoch 40/100] [Batch 96/347] [D loss: 0.526522] [G loss: 0.333794]\n",
      "[Epoch 40/100] [Batch 97/347] [D loss: 0.522334] [G loss: 0.331427]\n",
      "[Epoch 40/100] [Batch 98/347] [D loss: 0.531600] [G loss: 0.339832]\n",
      "[Epoch 40/100] [Batch 99/347] [D loss: 0.535879] [G loss: 0.346876]\n",
      "[Epoch 40/100] [Batch 100/347] [D loss: 0.521635] [G loss: 0.346336]\n",
      "[Epoch 40/100] [Batch 101/347] [D loss: 0.520746] [G loss: 0.344407]\n",
      "[Epoch 40/100] [Batch 102/347] [D loss: 0.534702] [G loss: 0.349076]\n",
      "[Epoch 40/100] [Batch 103/347] [D loss: 0.535120] [G loss: 0.352920]\n",
      "[Epoch 40/100] [Batch 104/347] [D loss: 0.528921] [G loss: 0.347145]\n",
      "[Epoch 40/100] [Batch 105/347] [D loss: 0.530347] [G loss: 0.349093]\n",
      "[Epoch 40/100] [Batch 106/347] [D loss: 0.521449] [G loss: 0.350823]\n",
      "[Epoch 40/100] [Batch 107/347] [D loss: 0.461810] [G loss: 0.342149]\n",
      "[Epoch 40/100] [Batch 108/347] [D loss: 0.234693] [G loss: 0.360545]\n",
      "[Epoch 40/100] [Batch 109/347] [D loss: 0.231622] [G loss: 0.372694]\n",
      "[Epoch 40/100] [Batch 110/347] [D loss: 0.430850] [G loss: 0.371147]\n",
      "[Epoch 40/100] [Batch 111/347] [D loss: 0.274250] [G loss: 0.379194]\n",
      "[Epoch 40/100] [Batch 112/347] [D loss: 0.219522] [G loss: 0.391532]\n",
      "[Epoch 40/100] [Batch 113/347] [D loss: 0.433554] [G loss: 0.406281]\n",
      "[Epoch 40/100] [Batch 114/347] [D loss: 0.500667] [G loss: 0.431827]\n",
      "[Epoch 40/100] [Batch 115/347] [D loss: 0.488475] [G loss: 0.436539]\n",
      "[Epoch 40/100] [Batch 116/347] [D loss: 0.508058] [G loss: 0.433172]\n",
      "[Epoch 40/100] [Batch 117/347] [D loss: 0.492056] [G loss: 0.407661]\n",
      "[Epoch 40/100] [Batch 118/347] [D loss: 0.420484] [G loss: 0.395551]\n",
      "[Epoch 40/100] [Batch 119/347] [D loss: 0.378730] [G loss: 0.387724]\n",
      "[Epoch 40/100] [Batch 120/347] [D loss: 0.314605] [G loss: 0.389984]\n",
      "[Epoch 40/100] [Batch 121/347] [D loss: 0.302109] [G loss: 0.386629]\n",
      "[Epoch 40/100] [Batch 122/347] [D loss: 0.449951] [G loss: 0.383876]\n",
      "[Epoch 40/100] [Batch 123/347] [D loss: 0.523289] [G loss: 0.382392]\n",
      "[Epoch 40/100] [Batch 124/347] [D loss: 0.521242] [G loss: 0.373620]\n",
      "[Epoch 40/100] [Batch 125/347] [D loss: 0.526693] [G loss: 0.380507]\n",
      "[Epoch 40/100] [Batch 126/347] [D loss: 0.509035] [G loss: 0.388086]\n",
      "[Epoch 40/100] [Batch 127/347] [D loss: 0.496451] [G loss: 0.383624]\n",
      "[Epoch 40/100] [Batch 128/347] [D loss: 0.493667] [G loss: 0.372373]\n",
      "[Epoch 40/100] [Batch 129/347] [D loss: 0.413533] [G loss: 0.361358]\n",
      "[Epoch 40/100] [Batch 130/347] [D loss: 0.393901] [G loss: 0.357799]\n",
      "[Epoch 40/100] [Batch 131/347] [D loss: 0.342714] [G loss: 0.352381]\n",
      "[Epoch 40/100] [Batch 132/347] [D loss: 0.247871] [G loss: 0.354911]\n",
      "[Epoch 40/100] [Batch 133/347] [D loss: 0.249424] [G loss: 0.357971]\n",
      "[Epoch 40/100] [Batch 134/347] [D loss: 0.239842] [G loss: 0.367312]\n",
      "[Epoch 40/100] [Batch 135/347] [D loss: 0.241122] [G loss: 0.387429]\n",
      "[Epoch 40/100] [Batch 136/347] [D loss: 0.230137] [G loss: 0.406667]\n",
      "[Epoch 40/100] [Batch 137/347] [D loss: 0.450536] [G loss: 0.408877]\n",
      "[Epoch 40/100] [Batch 138/347] [D loss: 0.438681] [G loss: 0.407338]\n",
      "[Epoch 40/100] [Batch 139/347] [D loss: 0.417316] [G loss: 0.400020]\n",
      "[Epoch 40/100] [Batch 140/347] [D loss: 0.397006] [G loss: 0.402434]\n",
      "[Epoch 40/100] [Batch 141/347] [D loss: 0.403618] [G loss: 0.398246]\n",
      "[Epoch 40/100] [Batch 142/347] [D loss: 0.408548] [G loss: 0.396412]\n",
      "[Epoch 40/100] [Batch 143/347] [D loss: 0.367637] [G loss: 0.390978]\n",
      "[Epoch 40/100] [Batch 144/347] [D loss: 0.359835] [G loss: 0.390365]\n",
      "[Epoch 40/100] [Batch 145/347] [D loss: 0.362261] [G loss: 0.371019]\n",
      "[Epoch 40/100] [Batch 146/347] [D loss: 0.364521] [G loss: 0.350742]\n",
      "[Epoch 40/100] [Batch 147/347] [D loss: 0.400183] [G loss: 0.354554]\n",
      "[Epoch 40/100] [Batch 148/347] [D loss: 0.409025] [G loss: 0.352574]\n",
      "[Epoch 40/100] [Batch 149/347] [D loss: 0.424775] [G loss: 0.340020]\n",
      "[Epoch 40/100] [Batch 150/347] [D loss: 0.436854] [G loss: 0.334961]\n",
      "[Epoch 40/100] [Batch 151/347] [D loss: 0.427655] [G loss: 0.337460]\n",
      "[Epoch 40/100] [Batch 152/347] [D loss: 0.381208] [G loss: 0.332419]\n",
      "[Epoch 40/100] [Batch 153/347] [D loss: 0.343954] [G loss: 0.312297]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 40/100] [Batch 154/347] [D loss: 0.340737] [G loss: 0.290181]\n",
      "[Epoch 40/100] [Batch 155/347] [D loss: 0.361193] [G loss: 0.285170]\n",
      "[Epoch 40/100] [Batch 156/347] [D loss: 0.401523] [G loss: 0.292724]\n",
      "[Epoch 40/100] [Batch 157/347] [D loss: 0.384744] [G loss: 0.302361]\n",
      "[Epoch 40/100] [Batch 158/347] [D loss: 0.353205] [G loss: 0.290285]\n",
      "[Epoch 40/100] [Batch 159/347] [D loss: 0.344343] [G loss: 0.278508]\n",
      "[Epoch 40/100] [Batch 160/347] [D loss: 0.298278] [G loss: 0.300015]\n",
      "[Epoch 40/100] [Batch 161/347] [D loss: 0.292771] [G loss: 0.319259]\n",
      "[Epoch 40/100] [Batch 162/347] [D loss: 0.357166] [G loss: 0.322644]\n",
      "[Epoch 40/100] [Batch 163/347] [D loss: 0.365228] [G loss: 0.317997]\n",
      "[Epoch 40/100] [Batch 164/347] [D loss: 0.341235] [G loss: 0.313639]\n",
      "[Epoch 40/100] [Batch 165/347] [D loss: 0.322708] [G loss: 0.310042]\n",
      "[Epoch 40/100] [Batch 166/347] [D loss: 0.334593] [G loss: 0.324926]\n",
      "[Epoch 40/100] [Batch 167/347] [D loss: 0.298423] [G loss: 0.349599]\n",
      "[Epoch 40/100] [Batch 168/347] [D loss: 0.259751] [G loss: 0.366334]\n",
      "[Epoch 40/100] [Batch 169/347] [D loss: 0.397863] [G loss: 0.372945]\n",
      "[Epoch 40/100] [Batch 170/347] [D loss: 0.481548] [G loss: 0.388637]\n",
      "[Epoch 40/100] [Batch 171/347] [D loss: 0.524862] [G loss: 0.403839]\n",
      "[Epoch 40/100] [Batch 172/347] [D loss: 0.534638] [G loss: 0.411722]\n",
      "[Epoch 40/100] [Batch 173/347] [D loss: 0.460292] [G loss: 0.402103]\n",
      "[Epoch 40/100] [Batch 174/347] [D loss: 0.460015] [G loss: 0.399975]\n",
      "[Epoch 40/100] [Batch 175/347] [D loss: 0.539263] [G loss: 0.409953]\n",
      "[Epoch 40/100] [Batch 176/347] [D loss: 0.559032] [G loss: 0.423679]\n",
      "[Epoch 40/100] [Batch 177/347] [D loss: 0.561745] [G loss: 0.425216]\n",
      "[Epoch 40/100] [Batch 178/347] [D loss: 0.555737] [G loss: 0.419878]\n",
      "[Epoch 40/100] [Batch 179/347] [D loss: 0.549611] [G loss: 0.413944]\n",
      "[Epoch 40/100] [Batch 180/347] [D loss: 0.545579] [G loss: 0.407949]\n",
      "[Epoch 40/100] [Batch 181/347] [D loss: 0.546618] [G loss: 0.408826]\n",
      "[Epoch 40/100] [Batch 182/347] [D loss: 0.546319] [G loss: 0.407310]\n",
      "[Epoch 40/100] [Batch 183/347] [D loss: 0.548116] [G loss: 0.411647]\n",
      "[Epoch 40/100] [Batch 184/347] [D loss: 0.552619] [G loss: 0.415995]\n",
      "[Epoch 40/100] [Batch 185/347] [D loss: 0.554194] [G loss: 0.415356]\n",
      "[Epoch 40/100] [Batch 186/347] [D loss: 0.554662] [G loss: 0.415715]\n",
      "[Epoch 40/100] [Batch 187/347] [D loss: 0.551466] [G loss: 0.411217]\n",
      "[Epoch 40/100] [Batch 188/347] [D loss: 0.550076] [G loss: 0.408645]\n",
      "[Epoch 40/100] [Batch 189/347] [D loss: 0.547868] [G loss: 0.408633]\n",
      "[Epoch 40/100] [Batch 190/347] [D loss: 0.535829] [G loss: 0.397425]\n",
      "[Epoch 40/100] [Batch 191/347] [D loss: 0.513012] [G loss: 0.384604]\n",
      "[Epoch 40/100] [Batch 192/347] [D loss: 0.505014] [G loss: 0.385541]\n",
      "[Epoch 40/100] [Batch 193/347] [D loss: 0.517898] [G loss: 0.393164]\n",
      "[Epoch 40/100] [Batch 194/347] [D loss: 0.537355] [G loss: 0.387456]\n",
      "[Epoch 40/100] [Batch 195/347] [D loss: 0.541140] [G loss: 0.378751]\n",
      "[Epoch 40/100] [Batch 196/347] [D loss: 0.533429] [G loss: 0.372988]\n",
      "[Epoch 40/100] [Batch 197/347] [D loss: 0.507871] [G loss: 0.369561]\n",
      "[Epoch 40/100] [Batch 198/347] [D loss: 0.438282] [G loss: 0.365644]\n",
      "[Epoch 40/100] [Batch 199/347] [D loss: 0.444124] [G loss: 0.359934]\n",
      "[Epoch 40/100] [Batch 200/347] [D loss: 0.517106] [G loss: 0.360312]\n",
      "[Epoch 40/100] [Batch 201/347] [D loss: 0.520563] [G loss: 0.357769]\n",
      "[Epoch 40/100] [Batch 202/347] [D loss: 0.528489] [G loss: 0.350202]\n",
      "[Epoch 40/100] [Batch 203/347] [D loss: 0.540306] [G loss: 0.343535]\n",
      "[Epoch 40/100] [Batch 204/347] [D loss: 0.540890] [G loss: 0.341958]\n",
      "[Epoch 40/100] [Batch 205/347] [D loss: 0.539017] [G loss: 0.341276]\n",
      "[Epoch 40/100] [Batch 206/347] [D loss: 0.535773] [G loss: 0.344295]\n",
      "[Epoch 40/100] [Batch 207/347] [D loss: 0.535624] [G loss: 0.353556]\n",
      "[Epoch 40/100] [Batch 208/347] [D loss: 0.539326] [G loss: 0.353324]\n",
      "[Epoch 40/100] [Batch 209/347] [D loss: 0.523010] [G loss: 0.347023]\n",
      "[Epoch 40/100] [Batch 210/347] [D loss: 0.517225] [G loss: 0.352718]\n",
      "[Epoch 40/100] [Batch 211/347] [D loss: 0.526605] [G loss: 0.350825]\n",
      "[Epoch 40/100] [Batch 212/347] [D loss: 0.354861] [G loss: 0.345013]\n",
      "[Epoch 40/100] [Batch 213/347] [D loss: 0.335532] [G loss: 0.350022]\n",
      "[Epoch 40/100] [Batch 214/347] [D loss: 0.243426] [G loss: 0.362177]\n",
      "[Epoch 40/100] [Batch 215/347] [D loss: 0.238655] [G loss: 0.370806]\n",
      "[Epoch 40/100] [Batch 216/347] [D loss: 0.420707] [G loss: 0.372482]\n",
      "[Epoch 40/100] [Batch 217/347] [D loss: 0.492471] [G loss: 0.379238]\n",
      "[Epoch 40/100] [Batch 218/347] [D loss: 0.545605] [G loss: 0.398133]\n",
      "[Epoch 40/100] [Batch 219/347] [D loss: 0.530093] [G loss: 0.415003]\n",
      "[Epoch 40/100] [Batch 220/347] [D loss: 0.530348] [G loss: 0.434420]\n",
      "[Epoch 40/100] [Batch 221/347] [D loss: 0.539304] [G loss: 0.438859]\n",
      "[Epoch 40/100] [Batch 222/347] [D loss: 0.530111] [G loss: 0.433173]\n",
      "[Epoch 40/100] [Batch 223/347] [D loss: 0.530740] [G loss: 0.433664]\n",
      "[Epoch 40/100] [Batch 224/347] [D loss: 0.533684] [G loss: 0.431123]\n",
      "[Epoch 40/100] [Batch 225/347] [D loss: 0.514898] [G loss: 0.413507]\n",
      "[Epoch 40/100] [Batch 226/347] [D loss: 0.510406] [G loss: 0.390375]\n",
      "[Epoch 40/100] [Batch 227/347] [D loss: 0.517158] [G loss: 0.365453]\n",
      "[Epoch 40/100] [Batch 228/347] [D loss: 0.522574] [G loss: 0.366793]\n",
      "[Epoch 40/100] [Batch 229/347] [D loss: 0.533025] [G loss: 0.376801]\n",
      "[Epoch 40/100] [Batch 230/347] [D loss: 0.536481] [G loss: 0.378816]\n",
      "[Epoch 40/100] [Batch 231/347] [D loss: 0.531663] [G loss: 0.371135]\n",
      "[Epoch 40/100] [Batch 232/347] [D loss: 0.531963] [G loss: 0.371526]\n",
      "[Epoch 40/100] [Batch 233/347] [D loss: 0.519418] [G loss: 0.370037]\n",
      "[Epoch 40/100] [Batch 234/347] [D loss: 0.496493] [G loss: 0.373759]\n",
      "[Epoch 40/100] [Batch 235/347] [D loss: 0.489389] [G loss: 0.380075]\n",
      "[Epoch 40/100] [Batch 236/347] [D loss: 0.498571] [G loss: 0.382005]\n",
      "[Epoch 40/100] [Batch 237/347] [D loss: 0.517996] [G loss: 0.385025]\n",
      "[Epoch 40/100] [Batch 238/347] [D loss: 0.541281] [G loss: 0.385296]\n",
      "[Epoch 40/100] [Batch 239/347] [D loss: 0.532400] [G loss: 0.379951]\n",
      "[Epoch 40/100] [Batch 240/347] [D loss: 0.525738] [G loss: 0.373051]\n",
      "[Epoch 40/100] [Batch 241/347] [D loss: 0.524130] [G loss: 0.364627]\n",
      "[Epoch 40/100] [Batch 242/347] [D loss: 0.527943] [G loss: 0.360534]\n",
      "[Epoch 40/100] [Batch 243/347] [D loss: 0.538586] [G loss: 0.366824]\n",
      "[Epoch 40/100] [Batch 244/347] [D loss: 0.542500] [G loss: 0.374807]\n",
      "[Epoch 40/100] [Batch 245/347] [D loss: 0.506577] [G loss: 0.372485]\n",
      "[Epoch 40/100] [Batch 246/347] [D loss: 0.486703] [G loss: 0.360977]\n",
      "[Epoch 40/100] [Batch 247/347] [D loss: 0.506276] [G loss: 0.331136]\n",
      "[Epoch 40/100] [Batch 248/347] [D loss: 0.522219] [G loss: 0.324051]\n",
      "[Epoch 40/100] [Batch 249/347] [D loss: 0.516091] [G loss: 0.320623]\n",
      "[Epoch 40/100] [Batch 250/347] [D loss: 0.508398] [G loss: 0.341677]\n",
      "[Epoch 40/100] [Batch 251/347] [D loss: 0.496656] [G loss: 0.358070]\n",
      "[Epoch 40/100] [Batch 252/347] [D loss: 0.492331] [G loss: 0.360077]\n",
      "[Epoch 40/100] [Batch 253/347] [D loss: 0.504720] [G loss: 0.359549]\n",
      "[Epoch 40/100] [Batch 254/347] [D loss: 0.516971] [G loss: 0.357113]\n",
      "[Epoch 40/100] [Batch 255/347] [D loss: 0.475902] [G loss: 0.354709]\n",
      "[Epoch 40/100] [Batch 256/347] [D loss: 0.467388] [G loss: 0.358866]\n",
      "[Epoch 40/100] [Batch 257/347] [D loss: 0.484609] [G loss: 0.362897]\n",
      "[Epoch 40/100] [Batch 258/347] [D loss: 0.435042] [G loss: 0.353857]\n",
      "[Epoch 40/100] [Batch 259/347] [D loss: 0.414874] [G loss: 0.339747]\n",
      "[Epoch 40/100] [Batch 260/347] [D loss: 0.373958] [G loss: 0.336616]\n",
      "[Epoch 40/100] [Batch 261/347] [D loss: 0.385198] [G loss: 0.343634]\n",
      "[Epoch 40/100] [Batch 262/347] [D loss: 0.450906] [G loss: 0.337990]\n",
      "[Epoch 40/100] [Batch 263/347] [D loss: 0.416066] [G loss: 0.335570]\n",
      "[Epoch 40/100] [Batch 264/347] [D loss: 0.369228] [G loss: 0.337734]\n",
      "[Epoch 40/100] [Batch 265/347] [D loss: 0.382894] [G loss: 0.335492]\n",
      "[Epoch 40/100] [Batch 266/347] [D loss: 0.402806] [G loss: 0.332532]\n",
      "[Epoch 40/100] [Batch 267/347] [D loss: 0.409378] [G loss: 0.331137]\n",
      "[Epoch 40/100] [Batch 268/347] [D loss: 0.360189] [G loss: 0.336758]\n",
      "[Epoch 40/100] [Batch 269/347] [D loss: 0.359294] [G loss: 0.339610]\n",
      "[Epoch 40/100] [Batch 270/347] [D loss: 0.409385] [G loss: 0.337981]\n",
      "[Epoch 40/100] [Batch 271/347] [D loss: 0.447241] [G loss: 0.335666]\n",
      "[Epoch 40/100] [Batch 272/347] [D loss: 0.474939] [G loss: 0.338353]\n",
      "[Epoch 40/100] [Batch 273/347] [D loss: 0.395675] [G loss: 0.347414]\n",
      "[Epoch 40/100] [Batch 274/347] [D loss: 0.518168] [G loss: 0.370706]\n",
      "[Epoch 40/100] [Batch 275/347] [D loss: 0.485483] [G loss: 0.384661]\n",
      "[Epoch 40/100] [Batch 276/347] [D loss: 0.390543] [G loss: 0.380656]\n",
      "[Epoch 40/100] [Batch 277/347] [D loss: 0.401109] [G loss: 0.387048]\n",
      "[Epoch 40/100] [Batch 278/347] [D loss: 0.500505] [G loss: 0.403518]\n",
      "[Epoch 40/100] [Batch 279/347] [D loss: 0.478566] [G loss: 0.405085]\n",
      "[Epoch 40/100] [Batch 280/347] [D loss: 0.460739] [G loss: 0.412319]\n",
      "[Epoch 40/100] [Batch 281/347] [D loss: 0.463524] [G loss: 0.413121]\n",
      "[Epoch 40/100] [Batch 282/347] [D loss: 0.477897] [G loss: 0.412688]\n",
      "[Epoch 40/100] [Batch 283/347] [D loss: 0.413086] [G loss: 0.413246]\n",
      "[Epoch 40/100] [Batch 284/347] [D loss: 0.401122] [G loss: 0.414365]\n",
      "[Epoch 40/100] [Batch 285/347] [D loss: 0.472351] [G loss: 0.413790]\n",
      "[Epoch 40/100] [Batch 286/347] [D loss: 0.516387] [G loss: 0.412039]\n",
      "[Epoch 40/100] [Batch 287/347] [D loss: 0.518422] [G loss: 0.405984]\n",
      "[Epoch 40/100] [Batch 288/347] [D loss: 0.501955] [G loss: 0.383870]\n",
      "[Epoch 40/100] [Batch 289/347] [D loss: 0.500244] [G loss: 0.375942]\n",
      "[Epoch 40/100] [Batch 290/347] [D loss: 0.518075] [G loss: 0.387093]\n",
      "[Epoch 40/100] [Batch 291/347] [D loss: 0.494502] [G loss: 0.379812]\n",
      "[Epoch 40/100] [Batch 292/347] [D loss: 0.486526] [G loss: 0.383012]\n",
      "[Epoch 40/100] [Batch 293/347] [D loss: 0.443462] [G loss: 0.400055]\n",
      "[Epoch 40/100] [Batch 294/347] [D loss: 0.396571] [G loss: 0.398460]\n",
      "[Epoch 40/100] [Batch 295/347] [D loss: 0.239863] [G loss: 0.383234]\n",
      "[Epoch 40/100] [Batch 296/347] [D loss: 0.227777] [G loss: 0.385902]\n",
      "[Epoch 40/100] [Batch 297/347] [D loss: 0.483010] [G loss: 0.400552]\n",
      "[Epoch 40/100] [Batch 298/347] [D loss: 0.542421] [G loss: 0.393593]\n",
      "[Epoch 40/100] [Batch 299/347] [D loss: 0.508331] [G loss: 0.390655]\n",
      "[Epoch 40/100] [Batch 300/347] [D loss: 0.461083] [G loss: 0.383927]\n",
      "[Epoch 40/100] [Batch 301/347] [D loss: 0.466745] [G loss: 0.377116]\n",
      "[Epoch 40/100] [Batch 302/347] [D loss: 0.503255] [G loss: 0.380506]\n",
      "[Epoch 40/100] [Batch 303/347] [D loss: 0.483757] [G loss: 0.355805]\n",
      "[Epoch 40/100] [Batch 304/347] [D loss: 0.488953] [G loss: 0.337161]\n",
      "[Epoch 40/100] [Batch 305/347] [D loss: 0.500786] [G loss: 0.336913]\n",
      "[Epoch 40/100] [Batch 306/347] [D loss: 0.335051] [G loss: 0.325857]\n",
      "[Epoch 40/100] [Batch 307/347] [D loss: 0.252413] [G loss: 0.329085]\n",
      "[Epoch 40/100] [Batch 308/347] [D loss: 0.323410] [G loss: 0.329775]\n",
      "[Epoch 40/100] [Batch 309/347] [D loss: 0.497974] [G loss: 0.347026]\n",
      "[Epoch 40/100] [Batch 310/347] [D loss: 0.546375] [G loss: 0.375115]\n",
      "[Epoch 40/100] [Batch 311/347] [D loss: 0.548016] [G loss: 0.379040]\n",
      "[Epoch 40/100] [Batch 312/347] [D loss: 0.546375] [G loss: 0.380252]\n",
      "[Epoch 40/100] [Batch 313/347] [D loss: 0.538246] [G loss: 0.381088]\n",
      "[Epoch 40/100] [Batch 314/347] [D loss: 0.501012] [G loss: 0.375638]\n",
      "[Epoch 40/100] [Batch 315/347] [D loss: 0.450362] [G loss: 0.366969]\n",
      "[Epoch 40/100] [Batch 316/347] [D loss: 0.450754] [G loss: 0.350495]\n",
      "[Epoch 40/100] [Batch 317/347] [D loss: 0.493915] [G loss: 0.339541]\n",
      "[Epoch 40/100] [Batch 318/347] [D loss: 0.518559] [G loss: 0.355199]\n",
      "[Epoch 40/100] [Batch 319/347] [D loss: 0.531087] [G loss: 0.387313]\n",
      "[Epoch 40/100] [Batch 320/347] [D loss: 0.534551] [G loss: 0.400300]\n",
      "[Epoch 40/100] [Batch 321/347] [D loss: 0.515326] [G loss: 0.389164]\n",
      "[Epoch 40/100] [Batch 322/347] [D loss: 0.507952] [G loss: 0.375308]\n",
      "[Epoch 40/100] [Batch 323/347] [D loss: 0.481119] [G loss: 0.373382]\n",
      "[Epoch 40/100] [Batch 324/347] [D loss: 0.473475] [G loss: 0.375094]\n",
      "[Epoch 40/100] [Batch 325/347] [D loss: 0.376453] [G loss: 0.363403]\n",
      "[Epoch 40/100] [Batch 326/347] [D loss: 0.350632] [G loss: 0.350834]\n",
      "[Epoch 40/100] [Batch 327/347] [D loss: 0.425222] [G loss: 0.348801]\n",
      "[Epoch 40/100] [Batch 328/347] [D loss: 0.473258] [G loss: 0.346732]\n",
      "[Epoch 40/100] [Batch 329/347] [D loss: 0.386454] [G loss: 0.337293]\n",
      "[Epoch 40/100] [Batch 330/347] [D loss: 0.374291] [G loss: 0.330454]\n",
      "[Epoch 40/100] [Batch 331/347] [D loss: 0.441898] [G loss: 0.338111]\n",
      "[Epoch 40/100] [Batch 332/347] [D loss: 0.523451] [G loss: 0.357366]\n",
      "[Epoch 40/100] [Batch 333/347] [D loss: 0.539930] [G loss: 0.368512]\n",
      "[Epoch 40/100] [Batch 334/347] [D loss: 0.515842] [G loss: 0.369629]\n",
      "[Epoch 40/100] [Batch 335/347] [D loss: 0.487575] [G loss: 0.357430]\n",
      "[Epoch 40/100] [Batch 336/347] [D loss: 0.478444] [G loss: 0.345052]\n",
      "[Epoch 40/100] [Batch 337/347] [D loss: 0.478392] [G loss: 0.347865]\n",
      "[Epoch 40/100] [Batch 338/347] [D loss: 0.503552] [G loss: 0.362389]\n",
      "[Epoch 40/100] [Batch 339/347] [D loss: 0.537722] [G loss: 0.368185]\n",
      "[Epoch 40/100] [Batch 340/347] [D loss: 0.544291] [G loss: 0.369351]\n",
      "[Epoch 40/100] [Batch 341/347] [D loss: 0.522125] [G loss: 0.365799]\n",
      "[Epoch 40/100] [Batch 342/347] [D loss: 0.513170] [G loss: 0.359505]\n",
      "[Epoch 40/100] [Batch 343/347] [D loss: 0.535791] [G loss: 0.365521]\n",
      "[Epoch 40/100] [Batch 344/347] [D loss: 0.451428] [G loss: 0.355193]\n",
      "[Epoch 40/100] [Batch 345/347] [D loss: 0.394905] [G loss: 0.335714]\n",
      "[Epoch 40/100] [Batch 346/347] [D loss: 0.348987] [G loss: 0.336702]\n",
      "[Epoch 40/100] [Batch 347/347] [D loss: 0.248534] [G loss: 0.350859]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 41/100] [Batch 1/347] [D loss: 0.515627] [G loss: 0.361773]\n",
      "[Epoch 41/100] [Batch 2/347] [D loss: 0.523308] [G loss: 0.367689]\n",
      "[Epoch 41/100] [Batch 3/347] [D loss: 0.542100] [G loss: 0.381530]\n",
      "[Epoch 41/100] [Batch 4/347] [D loss: 0.543009] [G loss: 0.385571]\n",
      "[Epoch 41/100] [Batch 5/347] [D loss: 0.541626] [G loss: 0.387494]\n",
      "[Epoch 41/100] [Batch 6/347] [D loss: 0.545423] [G loss: 0.391855]\n",
      "[Epoch 41/100] [Batch 7/347] [D loss: 0.541601] [G loss: 0.389599]\n",
      "[Epoch 41/100] [Batch 8/347] [D loss: 0.529221] [G loss: 0.386869]\n",
      "[Epoch 41/100] [Batch 9/347] [D loss: 0.514299] [G loss: 0.377260]\n",
      "[Epoch 41/100] [Batch 10/347] [D loss: 0.519040] [G loss: 0.378385]\n",
      "[Epoch 41/100] [Batch 11/347] [D loss: 0.538859] [G loss: 0.392707]\n",
      "[Epoch 41/100] [Batch 12/347] [D loss: 0.543869] [G loss: 0.397417]\n",
      "[Epoch 41/100] [Batch 13/347] [D loss: 0.546464] [G loss: 0.401167]\n",
      "[Epoch 41/100] [Batch 14/347] [D loss: 0.545181] [G loss: 0.403162]\n",
      "[Epoch 41/100] [Batch 15/347] [D loss: 0.536298] [G loss: 0.398689]\n",
      "[Epoch 41/100] [Batch 16/347] [D loss: 0.528123] [G loss: 0.394111]\n",
      "[Epoch 41/100] [Batch 17/347] [D loss: 0.512344] [G loss: 0.384102]\n",
      "[Epoch 41/100] [Batch 18/347] [D loss: 0.489665] [G loss: 0.383031]\n",
      "[Epoch 41/100] [Batch 19/347] [D loss: 0.498002] [G loss: 0.384184]\n",
      "[Epoch 41/100] [Batch 20/347] [D loss: 0.539877] [G loss: 0.394584]\n",
      "[Epoch 41/100] [Batch 21/347] [D loss: 0.540855] [G loss: 0.389145]\n",
      "[Epoch 41/100] [Batch 22/347] [D loss: 0.532584] [G loss: 0.382587]\n",
      "[Epoch 41/100] [Batch 23/347] [D loss: 0.507422] [G loss: 0.374496]\n",
      "[Epoch 41/100] [Batch 24/347] [D loss: 0.504468] [G loss: 0.371854]\n",
      "[Epoch 41/100] [Batch 25/347] [D loss: 0.521420] [G loss: 0.368985]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 41/100] [Batch 26/347] [D loss: 0.458548] [G loss: 0.359977]\n",
      "[Epoch 41/100] [Batch 27/347] [D loss: 0.262652] [G loss: 0.374082]\n",
      "[Epoch 41/100] [Batch 28/347] [D loss: 0.271903] [G loss: 0.381618]\n",
      "[Epoch 41/100] [Batch 29/347] [D loss: 0.502770] [G loss: 0.374019]\n",
      "[Epoch 41/100] [Batch 30/347] [D loss: 0.454190] [G loss: 0.379031]\n",
      "[Epoch 41/100] [Batch 31/347] [D loss: 0.395401] [G loss: 0.378915]\n",
      "[Epoch 41/100] [Batch 32/347] [D loss: 0.317787] [G loss: 0.372966]\n",
      "[Epoch 41/100] [Batch 33/347] [D loss: 0.339024] [G loss: 0.363109]\n",
      "[Epoch 41/100] [Batch 34/347] [D loss: 0.429650] [G loss: 0.361436]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 41/100] [Batch 35/347] [D loss: 0.416428] [G loss: 0.356785]\n",
      "[Epoch 41/100] [Batch 36/347] [D loss: 0.479334] [G loss: 0.347612]\n",
      "[Epoch 41/100] [Batch 37/347] [D loss: 0.426388] [G loss: 0.336398]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 41/100] [Batch 38/347] [D loss: 0.385372] [G loss: 0.320605]\n",
      "[Epoch 41/100] [Batch 39/347] [D loss: 0.429163] [G loss: 0.312926]\n",
      "[Epoch 41/100] [Batch 40/347] [D loss: 0.509260] [G loss: 0.307444]\n",
      "[Epoch 41/100] [Batch 41/347] [D loss: 0.512529] [G loss: 0.302413]\n",
      "[Epoch 41/100] [Batch 42/347] [D loss: 0.510644] [G loss: 0.303824]\n",
      "[Epoch 41/100] [Batch 43/347] [D loss: 0.500059] [G loss: 0.319161]\n",
      "[Epoch 41/100] [Batch 44/347] [D loss: 0.500997] [G loss: 0.331790]\n",
      "[Epoch 41/100] [Batch 45/347] [D loss: 0.525599] [G loss: 0.348666]\n",
      "[Epoch 41/100] [Batch 46/347] [D loss: 0.523874] [G loss: 0.344260]\n",
      "[Epoch 41/100] [Batch 47/347] [D loss: 0.503666] [G loss: 0.323087]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 41/100] [Batch 48/347] [D loss: 0.368203] [G loss: 0.314656]\n",
      "[Epoch 41/100] [Batch 49/347] [D loss: 0.368608] [G loss: 0.317578]\n",
      "[Epoch 41/100] [Batch 50/347] [D loss: 0.295095] [G loss: 0.331094]\n",
      "[Epoch 41/100] [Batch 51/347] [D loss: 0.277117] [G loss: 0.348827]\n",
      "[Epoch 41/100] [Batch 52/347] [D loss: 0.381346] [G loss: 0.352127]\n",
      "[Epoch 41/100] [Batch 53/347] [D loss: 0.475457] [G loss: 0.350413]\n",
      "[Epoch 41/100] [Batch 54/347] [D loss: 0.417037] [G loss: 0.339124]\n",
      "[Epoch 41/100] [Batch 55/347] [D loss: 0.406357] [G loss: 0.314748]\n",
      "[Epoch 41/100] [Batch 56/347] [D loss: 0.405183] [G loss: 0.318441]\n",
      "[Epoch 41/100] [Batch 57/347] [D loss: 0.408449] [G loss: 0.348494]\n",
      "[Epoch 41/100] [Batch 58/347] [D loss: 0.428217] [G loss: 0.359146]\n",
      "[Epoch 41/100] [Batch 59/347] [D loss: 0.396045] [G loss: 0.357853]\n",
      "[Epoch 41/100] [Batch 60/347] [D loss: 0.373896] [G loss: 0.353642]\n",
      "[Epoch 41/100] [Batch 61/347] [D loss: 0.346849] [G loss: 0.350048]\n",
      "[Epoch 41/100] [Batch 62/347] [D loss: 0.357710] [G loss: 0.334120]\n",
      "[Epoch 41/100] [Batch 63/347] [D loss: 0.393109] [G loss: 0.310916]\n",
      "[Epoch 41/100] [Batch 64/347] [D loss: 0.421904] [G loss: 0.330495]\n",
      "[Epoch 41/100] [Batch 65/347] [D loss: 0.489881] [G loss: 0.348251]\n",
      "[Epoch 41/100] [Batch 66/347] [D loss: 0.408972] [G loss: 0.347451]\n",
      "[Epoch 41/100] [Batch 67/347] [D loss: 0.239581] [G loss: 0.341981]\n",
      "[Epoch 41/100] [Batch 68/347] [D loss: 0.265028] [G loss: 0.339122]\n",
      "[Epoch 41/100] [Batch 69/347] [D loss: 0.390756] [G loss: 0.322820]\n",
      "[Epoch 41/100] [Batch 70/347] [D loss: 0.393273] [G loss: 0.314129]\n",
      "[Epoch 41/100] [Batch 71/347] [D loss: 0.377314] [G loss: 0.326397]\n",
      "[Epoch 41/100] [Batch 72/347] [D loss: 0.372239] [G loss: 0.325560]\n",
      "[Epoch 41/100] [Batch 73/347] [D loss: 0.372833] [G loss: 0.332123]\n",
      "[Epoch 41/100] [Batch 74/347] [D loss: 0.370735] [G loss: 0.351098]\n",
      "[Epoch 41/100] [Batch 75/347] [D loss: 0.390971] [G loss: 0.341702]\n",
      "[Epoch 41/100] [Batch 76/347] [D loss: 0.414848] [G loss: 0.320099]\n",
      "[Epoch 41/100] [Batch 77/347] [D loss: 0.413536] [G loss: 0.330426]\n",
      "[Epoch 41/100] [Batch 78/347] [D loss: 0.412999] [G loss: 0.346443]\n",
      "[Epoch 41/100] [Batch 79/347] [D loss: 0.494697] [G loss: 0.354832]\n",
      "[Epoch 41/100] [Batch 80/347] [D loss: 0.519694] [G loss: 0.349118]\n",
      "[Epoch 41/100] [Batch 81/347] [D loss: 0.506972] [G loss: 0.351173]\n",
      "[Epoch 41/100] [Batch 82/347] [D loss: 0.433733] [G loss: 0.341515]\n",
      "[Epoch 41/100] [Batch 83/347] [D loss: 0.419163] [G loss: 0.337087]\n",
      "[Epoch 41/100] [Batch 84/347] [D loss: 0.484896] [G loss: 0.346247]\n",
      "[Epoch 41/100] [Batch 85/347] [D loss: 0.533746] [G loss: 0.345205]\n",
      "[Epoch 41/100] [Batch 86/347] [D loss: 0.529259] [G loss: 0.338372]\n",
      "[Epoch 41/100] [Batch 87/347] [D loss: 0.528101] [G loss: 0.335400]\n",
      "[Epoch 41/100] [Batch 88/347] [D loss: 0.534111] [G loss: 0.338678]\n",
      "[Epoch 41/100] [Batch 89/347] [D loss: 0.541566] [G loss: 0.342599]\n",
      "[Epoch 41/100] [Batch 90/347] [D loss: 0.537805] [G loss: 0.339854]\n",
      "[Epoch 41/100] [Batch 91/347] [D loss: 0.537182] [G loss: 0.339829]\n",
      "[Epoch 41/100] [Batch 92/347] [D loss: 0.540370] [G loss: 0.343296]\n",
      "[Epoch 41/100] [Batch 93/347] [D loss: 0.539302] [G loss: 0.343374]\n",
      "[Epoch 41/100] [Batch 94/347] [D loss: 0.533072] [G loss: 0.342398]\n",
      "[Epoch 41/100] [Batch 95/347] [D loss: 0.533753] [G loss: 0.345628]\n",
      "[Epoch 41/100] [Batch 96/347] [D loss: 0.529506] [G loss: 0.343738]\n",
      "[Epoch 41/100] [Batch 97/347] [D loss: 0.525392] [G loss: 0.341306]\n",
      "[Epoch 41/100] [Batch 98/347] [D loss: 0.534714] [G loss: 0.349262]\n",
      "[Epoch 41/100] [Batch 99/347] [D loss: 0.538728] [G loss: 0.356177]\n",
      "[Epoch 41/100] [Batch 100/347] [D loss: 0.522409] [G loss: 0.355581]\n",
      "[Epoch 41/100] [Batch 101/347] [D loss: 0.521901] [G loss: 0.353020]\n",
      "[Epoch 41/100] [Batch 102/347] [D loss: 0.537787] [G loss: 0.357609]\n",
      "[Epoch 41/100] [Batch 103/347] [D loss: 0.537966] [G loss: 0.361000]\n",
      "[Epoch 41/100] [Batch 104/347] [D loss: 0.532051] [G loss: 0.354820]\n",
      "[Epoch 41/100] [Batch 105/347] [D loss: 0.533534] [G loss: 0.356994]\n",
      "[Epoch 41/100] [Batch 106/347] [D loss: 0.523196] [G loss: 0.358307]\n",
      "[Epoch 41/100] [Batch 107/347] [D loss: 0.459675] [G loss: 0.349430]\n",
      "[Epoch 41/100] [Batch 108/347] [D loss: 0.230525] [G loss: 0.366695]\n",
      "[Epoch 41/100] [Batch 109/347] [D loss: 0.228053] [G loss: 0.378354]\n",
      "[Epoch 41/100] [Batch 110/347] [D loss: 0.425269] [G loss: 0.376878]\n",
      "[Epoch 41/100] [Batch 111/347] [D loss: 0.271446] [G loss: 0.383712]\n",
      "[Epoch 41/100] [Batch 112/347] [D loss: 0.216193] [G loss: 0.395318]\n",
      "[Epoch 41/100] [Batch 113/347] [D loss: 0.430453] [G loss: 0.410001]\n",
      "[Epoch 41/100] [Batch 114/347] [D loss: 0.493020] [G loss: 0.435238]\n",
      "[Epoch 41/100] [Batch 115/347] [D loss: 0.478637] [G loss: 0.439186]\n",
      "[Epoch 41/100] [Batch 116/347] [D loss: 0.502373] [G loss: 0.435547]\n",
      "[Epoch 41/100] [Batch 117/347] [D loss: 0.486675] [G loss: 0.409823]\n",
      "[Epoch 41/100] [Batch 118/347] [D loss: 0.411094] [G loss: 0.397218]\n",
      "[Epoch 41/100] [Batch 119/347] [D loss: 0.365119] [G loss: 0.389756]\n",
      "[Epoch 41/100] [Batch 120/347] [D loss: 0.303713] [G loss: 0.392479]\n",
      "[Epoch 41/100] [Batch 121/347] [D loss: 0.291659] [G loss: 0.389721]\n",
      "[Epoch 41/100] [Batch 122/347] [D loss: 0.444621] [G loss: 0.388423]\n",
      "[Epoch 41/100] [Batch 123/347] [D loss: 0.524333] [G loss: 0.388283]\n",
      "[Epoch 41/100] [Batch 124/347] [D loss: 0.522875] [G loss: 0.380593]\n",
      "[Epoch 41/100] [Batch 125/347] [D loss: 0.527841] [G loss: 0.388366]\n",
      "[Epoch 41/100] [Batch 126/347] [D loss: 0.506347] [G loss: 0.396781]\n",
      "[Epoch 41/100] [Batch 127/347] [D loss: 0.492668] [G loss: 0.393725]\n",
      "[Epoch 41/100] [Batch 128/347] [D loss: 0.490521] [G loss: 0.383323]\n",
      "[Epoch 41/100] [Batch 129/347] [D loss: 0.404910] [G loss: 0.373082]\n",
      "[Epoch 41/100] [Batch 130/347] [D loss: 0.386312] [G loss: 0.369910]\n",
      "[Epoch 41/100] [Batch 131/347] [D loss: 0.335025] [G loss: 0.364677]\n",
      "[Epoch 41/100] [Batch 132/347] [D loss: 0.238502] [G loss: 0.366269]\n",
      "[Epoch 41/100] [Batch 133/347] [D loss: 0.240672] [G loss: 0.367566]\n",
      "[Epoch 41/100] [Batch 134/347] [D loss: 0.233499] [G loss: 0.375367]\n",
      "[Epoch 41/100] [Batch 135/347] [D loss: 0.237897] [G loss: 0.393460]\n",
      "[Epoch 41/100] [Batch 136/347] [D loss: 0.229033] [G loss: 0.411061]\n",
      "[Epoch 41/100] [Batch 137/347] [D loss: 0.447778] [G loss: 0.411825]\n",
      "[Epoch 41/100] [Batch 138/347] [D loss: 0.434312] [G loss: 0.409484]\n",
      "[Epoch 41/100] [Batch 139/347] [D loss: 0.412547] [G loss: 0.401512]\n",
      "[Epoch 41/100] [Batch 140/347] [D loss: 0.388904] [G loss: 0.403351]\n",
      "[Epoch 41/100] [Batch 141/347] [D loss: 0.395169] [G loss: 0.398631]\n",
      "[Epoch 41/100] [Batch 142/347] [D loss: 0.401207] [G loss: 0.396595]\n",
      "[Epoch 41/100] [Batch 143/347] [D loss: 0.358569] [G loss: 0.388244]\n",
      "[Epoch 41/100] [Batch 144/347] [D loss: 0.349178] [G loss: 0.385019]\n",
      "[Epoch 41/100] [Batch 145/347] [D loss: 0.349584] [G loss: 0.366523]\n",
      "[Epoch 41/100] [Batch 146/347] [D loss: 0.350399] [G loss: 0.350885]\n",
      "[Epoch 41/100] [Batch 147/347] [D loss: 0.387791] [G loss: 0.355024]\n",
      "[Epoch 41/100] [Batch 148/347] [D loss: 0.397031] [G loss: 0.353440]\n",
      "[Epoch 41/100] [Batch 149/347] [D loss: 0.417002] [G loss: 0.341114]\n",
      "[Epoch 41/100] [Batch 150/347] [D loss: 0.430652] [G loss: 0.336527]\n",
      "[Epoch 41/100] [Batch 151/347] [D loss: 0.419266] [G loss: 0.339083]\n",
      "[Epoch 41/100] [Batch 152/347] [D loss: 0.370828] [G loss: 0.334715]\n",
      "[Epoch 41/100] [Batch 153/347] [D loss: 0.333224] [G loss: 0.314804]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 41/100] [Batch 154/347] [D loss: 0.330000] [G loss: 0.293241]\n",
      "[Epoch 41/100] [Batch 155/347] [D loss: 0.349461] [G loss: 0.288534]\n",
      "[Epoch 41/100] [Batch 156/347] [D loss: 0.391355] [G loss: 0.296392]\n",
      "[Epoch 41/100] [Batch 157/347] [D loss: 0.374835] [G loss: 0.306342]\n",
      "[Epoch 41/100] [Batch 158/347] [D loss: 0.342449] [G loss: 0.294829]\n",
      "[Epoch 41/100] [Batch 159/347] [D loss: 0.333106] [G loss: 0.283315]\n",
      "[Epoch 41/100] [Batch 160/347] [D loss: 0.287472] [G loss: 0.305408]\n",
      "[Epoch 41/100] [Batch 161/347] [D loss: 0.281584] [G loss: 0.325208]\n",
      "[Epoch 41/100] [Batch 162/347] [D loss: 0.346065] [G loss: 0.329341]\n",
      "[Epoch 41/100] [Batch 163/347] [D loss: 0.355337] [G loss: 0.325174]\n",
      "[Epoch 41/100] [Batch 164/347] [D loss: 0.330687] [G loss: 0.320714]\n",
      "[Epoch 41/100] [Batch 165/347] [D loss: 0.311164] [G loss: 0.317512]\n",
      "[Epoch 41/100] [Batch 166/347] [D loss: 0.321232] [G loss: 0.332387]\n",
      "[Epoch 41/100] [Batch 167/347] [D loss: 0.287420] [G loss: 0.357219]\n",
      "[Epoch 41/100] [Batch 168/347] [D loss: 0.247246] [G loss: 0.373775]\n",
      "[Epoch 41/100] [Batch 169/347] [D loss: 0.387750] [G loss: 0.380141]\n",
      "[Epoch 41/100] [Batch 170/347] [D loss: 0.472092] [G loss: 0.395576]\n",
      "[Epoch 41/100] [Batch 171/347] [D loss: 0.520266] [G loss: 0.410279]\n",
      "[Epoch 41/100] [Batch 172/347] [D loss: 0.530958] [G loss: 0.417555]\n",
      "[Epoch 41/100] [Batch 173/347] [D loss: 0.445662] [G loss: 0.407254]\n",
      "[Epoch 41/100] [Batch 174/347] [D loss: 0.445439] [G loss: 0.404360]\n",
      "[Epoch 41/100] [Batch 175/347] [D loss: 0.535886] [G loss: 0.413664]\n",
      "[Epoch 41/100] [Batch 176/347] [D loss: 0.557072] [G loss: 0.426594]\n",
      "[Epoch 41/100] [Batch 177/347] [D loss: 0.559816] [G loss: 0.427235]\n",
      "[Epoch 41/100] [Batch 178/347] [D loss: 0.553226] [G loss: 0.421026]\n",
      "[Epoch 41/100] [Batch 179/347] [D loss: 0.546728] [G loss: 0.413980]\n",
      "[Epoch 41/100] [Batch 180/347] [D loss: 0.542524] [G loss: 0.407000]\n",
      "[Epoch 41/100] [Batch 181/347] [D loss: 0.543323] [G loss: 0.406847]\n",
      "[Epoch 41/100] [Batch 182/347] [D loss: 0.542781] [G loss: 0.404111]\n",
      "[Epoch 41/100] [Batch 183/347] [D loss: 0.543990] [G loss: 0.407628]\n",
      "[Epoch 41/100] [Batch 184/347] [D loss: 0.548851] [G loss: 0.410744]\n",
      "[Epoch 41/100] [Batch 185/347] [D loss: 0.550914] [G loss: 0.408647]\n",
      "[Epoch 41/100] [Batch 186/347] [D loss: 0.551330] [G loss: 0.408024]\n",
      "[Epoch 41/100] [Batch 187/347] [D loss: 0.547959] [G loss: 0.402276]\n",
      "[Epoch 41/100] [Batch 188/347] [D loss: 0.546482] [G loss: 0.398759]\n",
      "[Epoch 41/100] [Batch 189/347] [D loss: 0.543610] [G loss: 0.397877]\n",
      "[Epoch 41/100] [Batch 190/347] [D loss: 0.529063] [G loss: 0.385358]\n",
      "[Epoch 41/100] [Batch 191/347] [D loss: 0.500973] [G loss: 0.371605]\n",
      "[Epoch 41/100] [Batch 192/347] [D loss: 0.490970] [G loss: 0.371245]\n",
      "[Epoch 41/100] [Batch 193/347] [D loss: 0.505938] [G loss: 0.377043]\n",
      "[Epoch 41/100] [Batch 194/347] [D loss: 0.531457] [G loss: 0.370221]\n",
      "[Epoch 41/100] [Batch 195/347] [D loss: 0.538146] [G loss: 0.360475]\n",
      "[Epoch 41/100] [Batch 196/347] [D loss: 0.528859] [G loss: 0.353499]\n",
      "[Epoch 41/100] [Batch 197/347] [D loss: 0.496335] [G loss: 0.349637]\n",
      "[Epoch 41/100] [Batch 198/347] [D loss: 0.414388] [G loss: 0.345790]\n",
      "[Epoch 41/100] [Batch 199/347] [D loss: 0.422052] [G loss: 0.340404]\n",
      "[Epoch 41/100] [Batch 200/347] [D loss: 0.508311] [G loss: 0.341509]\n",
      "[Epoch 41/100] [Batch 201/347] [D loss: 0.511996] [G loss: 0.339675]\n",
      "[Epoch 41/100] [Batch 202/347] [D loss: 0.522487] [G loss: 0.332945]\n",
      "[Epoch 41/100] [Batch 203/347] [D loss: 0.540206] [G loss: 0.327292]\n",
      "[Epoch 41/100] [Batch 204/347] [D loss: 0.541066] [G loss: 0.326495]\n",
      "[Epoch 41/100] [Batch 205/347] [D loss: 0.538477] [G loss: 0.326540]\n",
      "[Epoch 41/100] [Batch 206/347] [D loss: 0.533793] [G loss: 0.330532]\n",
      "[Epoch 41/100] [Batch 207/347] [D loss: 0.532409] [G loss: 0.340809]\n",
      "[Epoch 41/100] [Batch 208/347] [D loss: 0.537048] [G loss: 0.341305]\n",
      "[Epoch 41/100] [Batch 209/347] [D loss: 0.516737] [G loss: 0.335840]\n",
      "[Epoch 41/100] [Batch 210/347] [D loss: 0.509111] [G loss: 0.341948]\n",
      "[Epoch 41/100] [Batch 211/347] [D loss: 0.523596] [G loss: 0.340781]\n",
      "[Epoch 41/100] [Batch 212/347] [D loss: 0.340366] [G loss: 0.336366]\n",
      "[Epoch 41/100] [Batch 213/347] [D loss: 0.324709] [G loss: 0.343449]\n",
      "[Epoch 41/100] [Batch 214/347] [D loss: 0.249767] [G loss: 0.358228]\n",
      "[Epoch 41/100] [Batch 215/347] [D loss: 0.241624] [G loss: 0.370048]\n",
      "[Epoch 41/100] [Batch 216/347] [D loss: 0.402859] [G loss: 0.374137]\n",
      "[Epoch 41/100] [Batch 217/347] [D loss: 0.484101] [G loss: 0.383418]\n",
      "[Epoch 41/100] [Batch 218/347] [D loss: 0.545688] [G loss: 0.404303]\n",
      "[Epoch 41/100] [Batch 219/347] [D loss: 0.524742] [G loss: 0.422491]\n",
      "[Epoch 41/100] [Batch 220/347] [D loss: 0.524274] [G loss: 0.442980]\n",
      "[Epoch 41/100] [Batch 221/347] [D loss: 0.536255] [G loss: 0.448285]\n",
      "[Epoch 41/100] [Batch 222/347] [D loss: 0.527355] [G loss: 0.443388]\n",
      "[Epoch 41/100] [Batch 223/347] [D loss: 0.528933] [G loss: 0.444377]\n",
      "[Epoch 41/100] [Batch 224/347] [D loss: 0.532802] [G loss: 0.441956]\n",
      "[Epoch 41/100] [Batch 225/347] [D loss: 0.513598] [G loss: 0.424531]\n",
      "[Epoch 41/100] [Batch 226/347] [D loss: 0.510806] [G loss: 0.401513]\n",
      "[Epoch 41/100] [Batch 227/347] [D loss: 0.519168] [G loss: 0.376282]\n",
      "[Epoch 41/100] [Batch 228/347] [D loss: 0.524785] [G loss: 0.377670]\n",
      "[Epoch 41/100] [Batch 229/347] [D loss: 0.536056] [G loss: 0.387536]\n",
      "[Epoch 41/100] [Batch 230/347] [D loss: 0.539621] [G loss: 0.389250]\n",
      "[Epoch 41/100] [Batch 231/347] [D loss: 0.534736] [G loss: 0.381238]\n",
      "[Epoch 41/100] [Batch 232/347] [D loss: 0.534835] [G loss: 0.381403]\n",
      "[Epoch 41/100] [Batch 233/347] [D loss: 0.519694] [G loss: 0.379510]\n",
      "[Epoch 41/100] [Batch 234/347] [D loss: 0.492201] [G loss: 0.382900]\n",
      "[Epoch 41/100] [Batch 235/347] [D loss: 0.483780] [G loss: 0.388235]\n",
      "[Epoch 41/100] [Batch 236/347] [D loss: 0.493015] [G loss: 0.388988]\n",
      "[Epoch 41/100] [Batch 237/347] [D loss: 0.514250] [G loss: 0.391259]\n",
      "[Epoch 41/100] [Batch 238/347] [D loss: 0.542632] [G loss: 0.390447]\n",
      "[Epoch 41/100] [Batch 239/347] [D loss: 0.532029] [G loss: 0.383771]\n",
      "[Epoch 41/100] [Batch 240/347] [D loss: 0.524612] [G loss: 0.376097]\n",
      "[Epoch 41/100] [Batch 241/347] [D loss: 0.523809] [G loss: 0.366551]\n",
      "[Epoch 41/100] [Batch 242/347] [D loss: 0.528819] [G loss: 0.361331]\n",
      "[Epoch 41/100] [Batch 243/347] [D loss: 0.541222] [G loss: 0.366843]\n",
      "[Epoch 41/100] [Batch 244/347] [D loss: 0.545020] [G loss: 0.374135]\n",
      "[Epoch 41/100] [Batch 245/347] [D loss: 0.500180] [G loss: 0.371446]\n",
      "[Epoch 41/100] [Batch 246/347] [D loss: 0.476325] [G loss: 0.358959]\n",
      "[Epoch 41/100] [Batch 247/347] [D loss: 0.503522] [G loss: 0.328511]\n",
      "[Epoch 41/100] [Batch 248/347] [D loss: 0.526486] [G loss: 0.321314]\n",
      "[Epoch 41/100] [Batch 249/347] [D loss: 0.520094] [G loss: 0.316960]\n",
      "[Epoch 41/100] [Batch 250/347] [D loss: 0.508954] [G loss: 0.337856]\n",
      "[Epoch 41/100] [Batch 251/347] [D loss: 0.491777] [G loss: 0.354532]\n",
      "[Epoch 41/100] [Batch 252/347] [D loss: 0.485810] [G loss: 0.356253]\n",
      "[Epoch 41/100] [Batch 253/347] [D loss: 0.500534] [G loss: 0.355732]\n",
      "[Epoch 41/100] [Batch 254/347] [D loss: 0.516109] [G loss: 0.353845]\n",
      "[Epoch 41/100] [Batch 255/347] [D loss: 0.468178] [G loss: 0.351115]\n",
      "[Epoch 41/100] [Batch 256/347] [D loss: 0.458291] [G loss: 0.355623]\n",
      "[Epoch 41/100] [Batch 257/347] [D loss: 0.474807] [G loss: 0.360458]\n",
      "[Epoch 41/100] [Batch 258/347] [D loss: 0.419777] [G loss: 0.351843]\n",
      "[Epoch 41/100] [Batch 259/347] [D loss: 0.402218] [G loss: 0.339118]\n",
      "[Epoch 41/100] [Batch 260/347] [D loss: 0.363669] [G loss: 0.338370]\n",
      "[Epoch 41/100] [Batch 261/347] [D loss: 0.375151] [G loss: 0.348741]\n",
      "[Epoch 41/100] [Batch 262/347] [D loss: 0.440596] [G loss: 0.347598]\n",
      "[Epoch 41/100] [Batch 263/347] [D loss: 0.405586] [G loss: 0.349862]\n",
      "[Epoch 41/100] [Batch 264/347] [D loss: 0.358857] [G loss: 0.355969]\n",
      "[Epoch 41/100] [Batch 265/347] [D loss: 0.375683] [G loss: 0.356208]\n",
      "[Epoch 41/100] [Batch 266/347] [D loss: 0.398007] [G loss: 0.354569]\n",
      "[Epoch 41/100] [Batch 267/347] [D loss: 0.404546] [G loss: 0.354014]\n",
      "[Epoch 41/100] [Batch 268/347] [D loss: 0.353781] [G loss: 0.359710]\n",
      "[Epoch 41/100] [Batch 269/347] [D loss: 0.354047] [G loss: 0.362489]\n",
      "[Epoch 41/100] [Batch 270/347] [D loss: 0.408751] [G loss: 0.360111]\n",
      "[Epoch 41/100] [Batch 271/347] [D loss: 0.448980] [G loss: 0.356658]\n",
      "[Epoch 41/100] [Batch 272/347] [D loss: 0.479312] [G loss: 0.358280]\n",
      "[Epoch 41/100] [Batch 273/347] [D loss: 0.390487] [G loss: 0.366456]\n",
      "[Epoch 41/100] [Batch 274/347] [D loss: 0.505911] [G loss: 0.389862]\n",
      "[Epoch 41/100] [Batch 275/347] [D loss: 0.473248] [G loss: 0.404852]\n",
      "[Epoch 41/100] [Batch 276/347] [D loss: 0.388889] [G loss: 0.401069]\n",
      "[Epoch 41/100] [Batch 277/347] [D loss: 0.400234] [G loss: 0.407905]\n",
      "[Epoch 41/100] [Batch 278/347] [D loss: 0.507441] [G loss: 0.424652]\n",
      "[Epoch 41/100] [Batch 279/347] [D loss: 0.485324] [G loss: 0.425799]\n",
      "[Epoch 41/100] [Batch 280/347] [D loss: 0.467584] [G loss: 0.433167]\n",
      "[Epoch 41/100] [Batch 281/347] [D loss: 0.470472] [G loss: 0.433694]\n",
      "[Epoch 41/100] [Batch 282/347] [D loss: 0.484143] [G loss: 0.432597]\n",
      "[Epoch 41/100] [Batch 283/347] [D loss: 0.415740] [G loss: 0.432625]\n",
      "[Epoch 41/100] [Batch 284/347] [D loss: 0.402900] [G loss: 0.432735]\n",
      "[Epoch 41/100] [Batch 285/347] [D loss: 0.477270] [G loss: 0.431710]\n",
      "[Epoch 41/100] [Batch 286/347] [D loss: 0.525112] [G loss: 0.429334]\n",
      "[Epoch 41/100] [Batch 287/347] [D loss: 0.527402] [G loss: 0.422813]\n",
      "[Epoch 41/100] [Batch 288/347] [D loss: 0.511836] [G loss: 0.400039]\n",
      "[Epoch 41/100] [Batch 289/347] [D loss: 0.510446] [G loss: 0.391620]\n",
      "[Epoch 41/100] [Batch 290/347] [D loss: 0.528219] [G loss: 0.402640]\n",
      "[Epoch 41/100] [Batch 291/347] [D loss: 0.502199] [G loss: 0.394909]\n",
      "[Epoch 41/100] [Batch 292/347] [D loss: 0.492665] [G loss: 0.397900]\n",
      "[Epoch 41/100] [Batch 293/347] [D loss: 0.444759] [G loss: 0.414406]\n",
      "[Epoch 41/100] [Batch 294/347] [D loss: 0.393532] [G loss: 0.412255]\n",
      "[Epoch 41/100] [Batch 295/347] [D loss: 0.238155] [G loss: 0.396248]\n",
      "[Epoch 41/100] [Batch 296/347] [D loss: 0.226701] [G loss: 0.398903]\n",
      "[Epoch 41/100] [Batch 297/347] [D loss: 0.491880] [G loss: 0.413603]\n",
      "[Epoch 41/100] [Batch 298/347] [D loss: 0.554104] [G loss: 0.406868]\n",
      "[Epoch 41/100] [Batch 299/347] [D loss: 0.514683] [G loss: 0.404042]\n",
      "[Epoch 41/100] [Batch 300/347] [D loss: 0.462893] [G loss: 0.397217]\n",
      "[Epoch 41/100] [Batch 301/347] [D loss: 0.470287] [G loss: 0.390076]\n",
      "[Epoch 41/100] [Batch 302/347] [D loss: 0.512811] [G loss: 0.393517]\n",
      "[Epoch 41/100] [Batch 303/347] [D loss: 0.491474] [G loss: 0.368265]\n",
      "[Epoch 41/100] [Batch 304/347] [D loss: 0.497501] [G loss: 0.350040]\n",
      "[Epoch 41/100] [Batch 305/347] [D loss: 0.512091] [G loss: 0.349884]\n",
      "[Epoch 41/100] [Batch 306/347] [D loss: 0.334018] [G loss: 0.339164]\n",
      "[Epoch 41/100] [Batch 307/347] [D loss: 0.251894] [G loss: 0.342942]\n",
      "[Epoch 41/100] [Batch 308/347] [D loss: 0.325878] [G loss: 0.344811]\n",
      "[Epoch 41/100] [Batch 309/347] [D loss: 0.507190] [G loss: 0.363240]\n",
      "[Epoch 41/100] [Batch 310/347] [D loss: 0.559873] [G loss: 0.392513]\n",
      "[Epoch 41/100] [Batch 311/347] [D loss: 0.561009] [G loss: 0.397911]\n",
      "[Epoch 41/100] [Batch 312/347] [D loss: 0.559156] [G loss: 0.400351]\n",
      "[Epoch 41/100] [Batch 313/347] [D loss: 0.550082] [G loss: 0.402423]\n",
      "[Epoch 41/100] [Batch 314/347] [D loss: 0.510849] [G loss: 0.398272]\n",
      "[Epoch 41/100] [Batch 315/347] [D loss: 0.457578] [G loss: 0.390376]\n",
      "[Epoch 41/100] [Batch 316/347] [D loss: 0.457822] [G loss: 0.374315]\n",
      "[Epoch 41/100] [Batch 317/347] [D loss: 0.505946] [G loss: 0.363427]\n",
      "[Epoch 41/100] [Batch 318/347] [D loss: 0.531982] [G loss: 0.379314]\n",
      "[Epoch 41/100] [Batch 319/347] [D loss: 0.541899] [G loss: 0.411884]\n",
      "[Epoch 41/100] [Batch 320/347] [D loss: 0.543244] [G loss: 0.425369]\n",
      "[Epoch 41/100] [Batch 321/347] [D loss: 0.524205] [G loss: 0.414551]\n",
      "[Epoch 41/100] [Batch 322/347] [D loss: 0.518355] [G loss: 0.400829]\n",
      "[Epoch 41/100] [Batch 323/347] [D loss: 0.489469] [G loss: 0.398820]\n",
      "[Epoch 41/100] [Batch 324/347] [D loss: 0.480887] [G loss: 0.400378]\n",
      "[Epoch 41/100] [Batch 325/347] [D loss: 0.378302] [G loss: 0.388345]\n",
      "[Epoch 41/100] [Batch 326/347] [D loss: 0.351225] [G loss: 0.375305]\n",
      "[Epoch 41/100] [Batch 327/347] [D loss: 0.431700] [G loss: 0.372580]\n",
      "[Epoch 41/100] [Batch 328/347] [D loss: 0.482539] [G loss: 0.369600]\n",
      "[Epoch 41/100] [Batch 329/347] [D loss: 0.389824] [G loss: 0.359020]\n",
      "[Epoch 41/100] [Batch 330/347] [D loss: 0.377034] [G loss: 0.351217]\n",
      "[Epoch 41/100] [Batch 331/347] [D loss: 0.450249] [G loss: 0.358004]\n",
      "[Epoch 41/100] [Batch 332/347] [D loss: 0.535407] [G loss: 0.377023]\n",
      "[Epoch 41/100] [Batch 333/347] [D loss: 0.551481] [G loss: 0.387762]\n",
      "[Epoch 41/100] [Batch 334/347] [D loss: 0.524984] [G loss: 0.388601]\n",
      "[Epoch 41/100] [Batch 335/347] [D loss: 0.496231] [G loss: 0.376141]\n",
      "[Epoch 41/100] [Batch 336/347] [D loss: 0.488336] [G loss: 0.362757]\n",
      "[Epoch 41/100] [Batch 337/347] [D loss: 0.486927] [G loss: 0.366404]\n",
      "[Epoch 41/100] [Batch 338/347] [D loss: 0.512676] [G loss: 0.380819]\n",
      "[Epoch 41/100] [Batch 339/347] [D loss: 0.549693] [G loss: 0.386635]\n",
      "[Epoch 41/100] [Batch 340/347] [D loss: 0.556582] [G loss: 0.388180]\n",
      "[Epoch 41/100] [Batch 341/347] [D loss: 0.533919] [G loss: 0.385087]\n",
      "[Epoch 41/100] [Batch 342/347] [D loss: 0.525258] [G loss: 0.379326]\n",
      "[Epoch 41/100] [Batch 343/347] [D loss: 0.547925] [G loss: 0.386150]\n",
      "[Epoch 41/100] [Batch 344/347] [D loss: 0.457083] [G loss: 0.376212]\n",
      "[Epoch 41/100] [Batch 345/347] [D loss: 0.398460] [G loss: 0.355666]\n",
      "[Epoch 41/100] [Batch 346/347] [D loss: 0.350377] [G loss: 0.356902]\n",
      "[Epoch 41/100] [Batch 347/347] [D loss: 0.242054] [G loss: 0.371049]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 42/100] [Batch 1/347] [D loss: 0.527232] [G loss: 0.384070]\n",
      "[Epoch 42/100] [Batch 2/347] [D loss: 0.535019] [G loss: 0.390161]\n",
      "[Epoch 42/100] [Batch 3/347] [D loss: 0.554097] [G loss: 0.404184]\n",
      "[Epoch 42/100] [Batch 4/347] [D loss: 0.554888] [G loss: 0.409055]\n",
      "[Epoch 42/100] [Batch 5/347] [D loss: 0.553263] [G loss: 0.411382]\n",
      "[Epoch 42/100] [Batch 6/347] [D loss: 0.556837] [G loss: 0.416289]\n",
      "[Epoch 42/100] [Batch 7/347] [D loss: 0.553024] [G loss: 0.414388]\n",
      "[Epoch 42/100] [Batch 8/347] [D loss: 0.540434] [G loss: 0.412079]\n",
      "[Epoch 42/100] [Batch 9/347] [D loss: 0.526155] [G loss: 0.403178]\n",
      "[Epoch 42/100] [Batch 10/347] [D loss: 0.530630] [G loss: 0.404901]\n",
      "[Epoch 42/100] [Batch 11/347] [D loss: 0.549803] [G loss: 0.419651]\n",
      "[Epoch 42/100] [Batch 12/347] [D loss: 0.554703] [G loss: 0.424720]\n",
      "[Epoch 42/100] [Batch 13/347] [D loss: 0.557110] [G loss: 0.428776]\n",
      "[Epoch 42/100] [Batch 14/347] [D loss: 0.555444] [G loss: 0.430860]\n",
      "[Epoch 42/100] [Batch 15/347] [D loss: 0.546248] [G loss: 0.426704]\n",
      "[Epoch 42/100] [Batch 16/347] [D loss: 0.538017] [G loss: 0.422054]\n",
      "[Epoch 42/100] [Batch 17/347] [D loss: 0.522934] [G loss: 0.410061]\n",
      "[Epoch 42/100] [Batch 18/347] [D loss: 0.500012] [G loss: 0.409536]\n",
      "[Epoch 42/100] [Batch 19/347] [D loss: 0.507393] [G loss: 0.412376]\n",
      "[Epoch 42/100] [Batch 20/347] [D loss: 0.549422] [G loss: 0.424044]\n",
      "[Epoch 42/100] [Batch 21/347] [D loss: 0.550796] [G loss: 0.418943]\n",
      "[Epoch 42/100] [Batch 22/347] [D loss: 0.542228] [G loss: 0.412504]\n",
      "[Epoch 42/100] [Batch 23/347] [D loss: 0.516742] [G loss: 0.404357]\n",
      "[Epoch 42/100] [Batch 24/347] [D loss: 0.513747] [G loss: 0.402008]\n",
      "[Epoch 42/100] [Batch 25/347] [D loss: 0.531172] [G loss: 0.399901]\n",
      "[Epoch 42/100] [Batch 26/347] [D loss: 0.466498] [G loss: 0.389803]\n",
      "[Epoch 42/100] [Batch 27/347] [D loss: 0.262920] [G loss: 0.403968]\n",
      "[Epoch 42/100] [Batch 28/347] [D loss: 0.273098] [G loss: 0.410817]\n",
      "[Epoch 42/100] [Batch 29/347] [D loss: 0.510499] [G loss: 0.403635]\n",
      "[Epoch 42/100] [Batch 30/347] [D loss: 0.462637] [G loss: 0.407806]\n",
      "[Epoch 42/100] [Batch 31/347] [D loss: 0.402205] [G loss: 0.407186]\n",
      "[Epoch 42/100] [Batch 32/347] [D loss: 0.320892] [G loss: 0.399874]\n",
      "[Epoch 42/100] [Batch 33/347] [D loss: 0.341481] [G loss: 0.389114]\n",
      "[Epoch 42/100] [Batch 34/347] [D loss: 0.435101] [G loss: 0.386144]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 42/100] [Batch 35/347] [D loss: 0.420079] [G loss: 0.380673]\n",
      "[Epoch 42/100] [Batch 36/347] [D loss: 0.485837] [G loss: 0.370178]\n",
      "[Epoch 42/100] [Batch 37/347] [D loss: 0.431789] [G loss: 0.358208]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 42/100] [Batch 38/347] [D loss: 0.388940] [G loss: 0.341265]\n",
      "[Epoch 42/100] [Batch 39/347] [D loss: 0.434154] [G loss: 0.332599]\n",
      "[Epoch 42/100] [Batch 40/347] [D loss: 0.517713] [G loss: 0.326422]\n",
      "[Epoch 42/100] [Batch 41/347] [D loss: 0.521664] [G loss: 0.320442]\n",
      "[Epoch 42/100] [Batch 42/347] [D loss: 0.519537] [G loss: 0.320974]\n",
      "[Epoch 42/100] [Batch 43/347] [D loss: 0.507479] [G loss: 0.335696]\n",
      "[Epoch 42/100] [Batch 44/347] [D loss: 0.507296] [G loss: 0.347049]\n",
      "[Epoch 42/100] [Batch 45/347] [D loss: 0.531248] [G loss: 0.362459]\n",
      "[Epoch 42/100] [Batch 46/347] [D loss: 0.530042] [G loss: 0.356424]\n",
      "[Epoch 42/100] [Batch 47/347] [D loss: 0.511146] [G loss: 0.333768]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 42/100] [Batch 48/347] [D loss: 0.368019] [G loss: 0.323722]\n",
      "[Epoch 42/100] [Batch 49/347] [D loss: 0.368043] [G loss: 0.325352]\n",
      "[Epoch 42/100] [Batch 50/347] [D loss: 0.296241] [G loss: 0.337902]\n",
      "[Epoch 42/100] [Batch 51/347] [D loss: 0.279153] [G loss: 0.354944]\n",
      "[Epoch 42/100] [Batch 52/347] [D loss: 0.384076] [G loss: 0.358363]\n",
      "[Epoch 42/100] [Batch 53/347] [D loss: 0.480779] [G loss: 0.356429]\n",
      "[Epoch 42/100] [Batch 54/347] [D loss: 0.421806] [G loss: 0.345316]\n",
      "[Epoch 42/100] [Batch 55/347] [D loss: 0.411467] [G loss: 0.321296]\n",
      "[Epoch 42/100] [Batch 56/347] [D loss: 0.409274] [G loss: 0.325238]\n",
      "[Epoch 42/100] [Batch 57/347] [D loss: 0.409849] [G loss: 0.355708]\n",
      "[Epoch 42/100] [Batch 58/347] [D loss: 0.428198] [G loss: 0.366999]\n",
      "[Epoch 42/100] [Batch 59/347] [D loss: 0.398115] [G loss: 0.366044]\n",
      "[Epoch 42/100] [Batch 60/347] [D loss: 0.375588] [G loss: 0.362009]\n",
      "[Epoch 42/100] [Batch 61/347] [D loss: 0.345590] [G loss: 0.358997]\n",
      "[Epoch 42/100] [Batch 62/347] [D loss: 0.358631] [G loss: 0.343428]\n",
      "[Epoch 42/100] [Batch 63/347] [D loss: 0.397743] [G loss: 0.320788]\n",
      "[Epoch 42/100] [Batch 64/347] [D loss: 0.425530] [G loss: 0.340632]\n",
      "[Epoch 42/100] [Batch 65/347] [D loss: 0.494335] [G loss: 0.358703]\n",
      "[Epoch 42/100] [Batch 66/347] [D loss: 0.411311] [G loss: 0.358418]\n",
      "[Epoch 42/100] [Batch 67/347] [D loss: 0.238277] [G loss: 0.353009]\n",
      "[Epoch 42/100] [Batch 68/347] [D loss: 0.264837] [G loss: 0.349871]\n",
      "[Epoch 42/100] [Batch 69/347] [D loss: 0.393832] [G loss: 0.333654]\n",
      "[Epoch 42/100] [Batch 70/347] [D loss: 0.396523] [G loss: 0.324875]\n",
      "[Epoch 42/100] [Batch 71/347] [D loss: 0.380002] [G loss: 0.336832]\n",
      "[Epoch 42/100] [Batch 72/347] [D loss: 0.375031] [G loss: 0.335775]\n",
      "[Epoch 42/100] [Batch 73/347] [D loss: 0.375451] [G loss: 0.342380]\n",
      "[Epoch 42/100] [Batch 74/347] [D loss: 0.374325] [G loss: 0.361191]\n",
      "[Epoch 42/100] [Batch 75/347] [D loss: 0.396660] [G loss: 0.351805]\n",
      "[Epoch 42/100] [Batch 76/347] [D loss: 0.421791] [G loss: 0.329925]\n",
      "[Epoch 42/100] [Batch 77/347] [D loss: 0.416758] [G loss: 0.340410]\n",
      "[Epoch 42/100] [Batch 78/347] [D loss: 0.414414] [G loss: 0.356364]\n",
      "[Epoch 42/100] [Batch 79/347] [D loss: 0.500299] [G loss: 0.364005]\n",
      "[Epoch 42/100] [Batch 80/347] [D loss: 0.527880] [G loss: 0.358647]\n",
      "[Epoch 42/100] [Batch 81/347] [D loss: 0.514057] [G loss: 0.360858]\n",
      "[Epoch 42/100] [Batch 82/347] [D loss: 0.435200] [G loss: 0.351836]\n",
      "[Epoch 42/100] [Batch 83/347] [D loss: 0.419726] [G loss: 0.347520]\n",
      "[Epoch 42/100] [Batch 84/347] [D loss: 0.488349] [G loss: 0.356920]\n",
      "[Epoch 42/100] [Batch 85/347] [D loss: 0.542541] [G loss: 0.356443]\n",
      "[Epoch 42/100] [Batch 86/347] [D loss: 0.538593] [G loss: 0.350112]\n",
      "[Epoch 42/100] [Batch 87/347] [D loss: 0.537454] [G loss: 0.347939]\n",
      "[Epoch 42/100] [Batch 88/347] [D loss: 0.543224] [G loss: 0.352041]\n",
      "[Epoch 42/100] [Batch 89/347] [D loss: 0.550546] [G loss: 0.356681]\n",
      "[Epoch 42/100] [Batch 90/347] [D loss: 0.546878] [G loss: 0.354793]\n",
      "[Epoch 42/100] [Batch 91/347] [D loss: 0.546080] [G loss: 0.355833]\n",
      "[Epoch 42/100] [Batch 92/347] [D loss: 0.548873] [G loss: 0.360142]\n",
      "[Epoch 42/100] [Batch 93/347] [D loss: 0.547671] [G loss: 0.361391]\n",
      "[Epoch 42/100] [Batch 94/347] [D loss: 0.541263] [G loss: 0.361207]\n",
      "[Epoch 42/100] [Batch 95/347] [D loss: 0.541537] [G loss: 0.365554]\n",
      "[Epoch 42/100] [Batch 96/347] [D loss: 0.537566] [G loss: 0.364633]\n",
      "[Epoch 42/100] [Batch 97/347] [D loss: 0.533611] [G loss: 0.363263]\n",
      "[Epoch 42/100] [Batch 98/347] [D loss: 0.542023] [G loss: 0.371886]\n",
      "[Epoch 42/100] [Batch 99/347] [D loss: 0.544914] [G loss: 0.379472]\n",
      "[Epoch 42/100] [Batch 100/347] [D loss: 0.527909] [G loss: 0.379461]\n",
      "[Epoch 42/100] [Batch 101/347] [D loss: 0.527830] [G loss: 0.377516]\n",
      "[Epoch 42/100] [Batch 102/347] [D loss: 0.543687] [G loss: 0.382555]\n",
      "[Epoch 42/100] [Batch 103/347] [D loss: 0.543644] [G loss: 0.386199]\n",
      "[Epoch 42/100] [Batch 104/347] [D loss: 0.538320] [G loss: 0.380351]\n",
      "[Epoch 42/100] [Batch 105/347] [D loss: 0.539519] [G loss: 0.382347]\n",
      "[Epoch 42/100] [Batch 106/347] [D loss: 0.528991] [G loss: 0.383887]\n",
      "[Epoch 42/100] [Batch 107/347] [D loss: 0.463780] [G loss: 0.375002]\n",
      "[Epoch 42/100] [Batch 108/347] [D loss: 0.217691] [G loss: 0.390258]\n",
      "[Epoch 42/100] [Batch 109/347] [D loss: 0.216296] [G loss: 0.400172]\n",
      "[Epoch 42/100] [Batch 110/347] [D loss: 0.429251] [G loss: 0.398389]\n",
      "[Epoch 42/100] [Batch 111/347] [D loss: 0.266284] [G loss: 0.401818]\n",
      "[Epoch 42/100] [Batch 112/347] [D loss: 0.210302] [G loss: 0.411587]\n",
      "[Epoch 42/100] [Batch 113/347] [D loss: 0.430306] [G loss: 0.425572]\n",
      "[Epoch 42/100] [Batch 114/347] [D loss: 0.494339] [G loss: 0.448875]\n",
      "[Epoch 42/100] [Batch 115/347] [D loss: 0.478935] [G loss: 0.451316]\n",
      "[Epoch 42/100] [Batch 116/347] [D loss: 0.502761] [G loss: 0.445976]\n",
      "[Epoch 42/100] [Batch 117/347] [D loss: 0.488524] [G loss: 0.418955]\n",
      "[Epoch 42/100] [Batch 118/347] [D loss: 0.412772] [G loss: 0.403526]\n",
      "[Epoch 42/100] [Batch 119/347] [D loss: 0.364648] [G loss: 0.394589]\n",
      "[Epoch 42/100] [Batch 120/347] [D loss: 0.302587] [G loss: 0.395885]\n",
      "[Epoch 42/100] [Batch 121/347] [D loss: 0.289705] [G loss: 0.391768]\n",
      "[Epoch 42/100] [Batch 122/347] [D loss: 0.443419] [G loss: 0.390482]\n",
      "[Epoch 42/100] [Batch 123/347] [D loss: 0.525384] [G loss: 0.388858]\n",
      "[Epoch 42/100] [Batch 124/347] [D loss: 0.524195] [G loss: 0.380025]\n",
      "[Epoch 42/100] [Batch 125/347] [D loss: 0.528428] [G loss: 0.386709]\n",
      "[Epoch 42/100] [Batch 126/347] [D loss: 0.503172] [G loss: 0.394304]\n",
      "[Epoch 42/100] [Batch 127/347] [D loss: 0.487950] [G loss: 0.390209]\n",
      "[Epoch 42/100] [Batch 128/347] [D loss: 0.485848] [G loss: 0.379053]\n",
      "[Epoch 42/100] [Batch 129/347] [D loss: 0.396447] [G loss: 0.368154]\n",
      "[Epoch 42/100] [Batch 130/347] [D loss: 0.379896] [G loss: 0.363093]\n",
      "[Epoch 42/100] [Batch 131/347] [D loss: 0.335835] [G loss: 0.358255]\n",
      "[Epoch 42/100] [Batch 132/347] [D loss: 0.252103] [G loss: 0.361076]\n",
      "[Epoch 42/100] [Batch 133/347] [D loss: 0.250275] [G loss: 0.364626]\n",
      "[Epoch 42/100] [Batch 134/347] [D loss: 0.241602] [G loss: 0.374084]\n",
      "[Epoch 42/100] [Batch 135/347] [D loss: 0.245872] [G loss: 0.394100]\n",
      "[Epoch 42/100] [Batch 136/347] [D loss: 0.233687] [G loss: 0.412917]\n",
      "[Epoch 42/100] [Batch 137/347] [D loss: 0.447253] [G loss: 0.414729]\n",
      "[Epoch 42/100] [Batch 138/347] [D loss: 0.435363] [G loss: 0.412917]\n",
      "[Epoch 42/100] [Batch 139/347] [D loss: 0.415162] [G loss: 0.405311]\n",
      "[Epoch 42/100] [Batch 140/347] [D loss: 0.390001] [G loss: 0.407730]\n",
      "[Epoch 42/100] [Batch 141/347] [D loss: 0.397085] [G loss: 0.403364]\n",
      "[Epoch 42/100] [Batch 142/347] [D loss: 0.404851] [G loss: 0.401437]\n",
      "[Epoch 42/100] [Batch 143/347] [D loss: 0.360731] [G loss: 0.393427]\n",
      "[Epoch 42/100] [Batch 144/347] [D loss: 0.350300] [G loss: 0.380453]\n",
      "[Epoch 42/100] [Batch 145/347] [D loss: 0.348612] [G loss: 0.367863]\n",
      "[Epoch 42/100] [Batch 146/347] [D loss: 0.347281] [G loss: 0.356151]\n",
      "[Epoch 42/100] [Batch 147/347] [D loss: 0.385087] [G loss: 0.360196]\n",
      "[Epoch 42/100] [Batch 148/347] [D loss: 0.393609] [G loss: 0.358371]\n",
      "[Epoch 42/100] [Batch 149/347] [D loss: 0.415729] [G loss: 0.345783]\n",
      "[Epoch 42/100] [Batch 150/347] [D loss: 0.429531] [G loss: 0.340915]\n",
      "[Epoch 42/100] [Batch 151/347] [D loss: 0.414913] [G loss: 0.343223]\n",
      "[Epoch 42/100] [Batch 152/347] [D loss: 0.363352] [G loss: 0.337838]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 42/100] [Batch 153/347] [D loss: 0.324658] [G loss: 0.316999]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 42/100] [Batch 154/347] [D loss: 0.321107] [G loss: 0.294526]\n",
      "[Epoch 42/100] [Batch 155/347] [D loss: 0.339632] [G loss: 0.289072]\n",
      "[Epoch 42/100] [Batch 156/347] [D loss: 0.382346] [G loss: 0.296005]\n",
      "[Epoch 42/100] [Batch 157/347] [D loss: 0.366548] [G loss: 0.305261]\n",
      "[Epoch 42/100] [Batch 158/347] [D loss: 0.333722] [G loss: 0.293130]\n",
      "[Epoch 42/100] [Batch 159/347] [D loss: 0.324028] [G loss: 0.281147]\n",
      "[Epoch 42/100] [Batch 160/347] [D loss: 0.279983] [G loss: 0.302383]\n",
      "[Epoch 42/100] [Batch 161/347] [D loss: 0.274686] [G loss: 0.321957]\n",
      "[Epoch 42/100] [Batch 162/347] [D loss: 0.337086] [G loss: 0.325517]\n",
      "[Epoch 42/100] [Batch 163/347] [D loss: 0.346671] [G loss: 0.320761]\n",
      "[Epoch 42/100] [Batch 164/347] [D loss: 0.322105] [G loss: 0.317423]\n",
      "[Epoch 42/100] [Batch 165/347] [D loss: 0.303100] [G loss: 0.314291]\n",
      "[Epoch 42/100] [Batch 166/347] [D loss: 0.312891] [G loss: 0.326928]\n",
      "[Epoch 42/100] [Batch 167/347] [D loss: 0.283598] [G loss: 0.351424]\n",
      "[Epoch 42/100] [Batch 168/347] [D loss: 0.244801] [G loss: 0.367919]\n",
      "[Epoch 42/100] [Batch 169/347] [D loss: 0.383065] [G loss: 0.378349]\n",
      "[Epoch 42/100] [Batch 170/347] [D loss: 0.465642] [G loss: 0.393786]\n",
      "[Epoch 42/100] [Batch 171/347] [D loss: 0.518289] [G loss: 0.408428]\n",
      "[Epoch 42/100] [Batch 172/347] [D loss: 0.530651] [G loss: 0.416137]\n",
      "[Epoch 42/100] [Batch 173/347] [D loss: 0.436484] [G loss: 0.406039]\n",
      "[Epoch 42/100] [Batch 174/347] [D loss: 0.436943] [G loss: 0.403480]\n",
      "[Epoch 42/100] [Batch 175/347] [D loss: 0.537446] [G loss: 0.413134]\n",
      "[Epoch 42/100] [Batch 176/347] [D loss: 0.560435] [G loss: 0.426638]\n",
      "[Epoch 42/100] [Batch 177/347] [D loss: 0.563797] [G loss: 0.427921]\n",
      "[Epoch 42/100] [Batch 178/347] [D loss: 0.557333] [G loss: 0.422268]\n",
      "[Epoch 42/100] [Batch 179/347] [D loss: 0.551010] [G loss: 0.416105]\n",
      "[Epoch 42/100] [Batch 180/347] [D loss: 0.547082] [G loss: 0.409963]\n",
      "[Epoch 42/100] [Batch 181/347] [D loss: 0.548095] [G loss: 0.410803]\n",
      "[Epoch 42/100] [Batch 182/347] [D loss: 0.547665] [G loss: 0.409060]\n",
      "[Epoch 42/100] [Batch 183/347] [D loss: 0.548635] [G loss: 0.413473]\n",
      "[Epoch 42/100] [Batch 184/347] [D loss: 0.553468] [G loss: 0.417861]\n",
      "[Epoch 42/100] [Batch 185/347] [D loss: 0.556057] [G loss: 0.417003]\n",
      "[Epoch 42/100] [Batch 186/347] [D loss: 0.556586] [G loss: 0.417441]\n",
      "[Epoch 42/100] [Batch 187/347] [D loss: 0.553474] [G loss: 0.413097]\n",
      "[Epoch 42/100] [Batch 188/347] [D loss: 0.552171] [G loss: 0.410897]\n",
      "[Epoch 42/100] [Batch 189/347] [D loss: 0.549131] [G loss: 0.410928]\n",
      "[Epoch 42/100] [Batch 190/347] [D loss: 0.534208] [G loss: 0.399688]\n",
      "[Epoch 42/100] [Batch 191/347] [D loss: 0.505629] [G loss: 0.387080]\n",
      "[Epoch 42/100] [Batch 192/347] [D loss: 0.495654] [G loss: 0.388160]\n",
      "[Epoch 42/100] [Batch 193/347] [D loss: 0.510528] [G loss: 0.395564]\n",
      "[Epoch 42/100] [Batch 194/347] [D loss: 0.536911] [G loss: 0.389903]\n",
      "[Epoch 42/100] [Batch 195/347] [D loss: 0.545016] [G loss: 0.381478]\n",
      "[Epoch 42/100] [Batch 196/347] [D loss: 0.535790] [G loss: 0.375769]\n",
      "[Epoch 42/100] [Batch 197/347] [D loss: 0.501352] [G loss: 0.372929]\n",
      "[Epoch 42/100] [Batch 198/347] [D loss: 0.414391] [G loss: 0.369498]\n",
      "[Epoch 42/100] [Batch 199/347] [D loss: 0.422322] [G loss: 0.365026]\n",
      "[Epoch 42/100] [Batch 200/347] [D loss: 0.513939] [G loss: 0.366363]\n",
      "[Epoch 42/100] [Batch 201/347] [D loss: 0.516513] [G loss: 0.364677]\n",
      "[Epoch 42/100] [Batch 202/347] [D loss: 0.526932] [G loss: 0.357581]\n",
      "[Epoch 42/100] [Batch 203/347] [D loss: 0.545792] [G loss: 0.351850]\n",
      "[Epoch 42/100] [Batch 204/347] [D loss: 0.546322] [G loss: 0.350669]\n",
      "[Epoch 42/100] [Batch 205/347] [D loss: 0.543485] [G loss: 0.350460]\n",
      "[Epoch 42/100] [Batch 206/347] [D loss: 0.538255] [G loss: 0.354475]\n",
      "[Epoch 42/100] [Batch 207/347] [D loss: 0.535787] [G loss: 0.364269]\n",
      "[Epoch 42/100] [Batch 208/347] [D loss: 0.540060] [G loss: 0.364264]\n",
      "[Epoch 42/100] [Batch 209/347] [D loss: 0.519459] [G loss: 0.357940]\n",
      "[Epoch 42/100] [Batch 210/347] [D loss: 0.511117] [G loss: 0.363565]\n",
      "[Epoch 42/100] [Batch 211/347] [D loss: 0.525421] [G loss: 0.361842]\n",
      "[Epoch 42/100] [Batch 212/347] [D loss: 0.334296] [G loss: 0.356379]\n",
      "[Epoch 42/100] [Batch 213/347] [D loss: 0.317326] [G loss: 0.360858]\n",
      "[Epoch 42/100] [Batch 214/347] [D loss: 0.237335] [G loss: 0.372720]\n",
      "[Epoch 42/100] [Batch 215/347] [D loss: 0.232492] [G loss: 0.381074]\n",
      "[Epoch 42/100] [Batch 216/347] [D loss: 0.400725] [G loss: 0.382236]\n",
      "[Epoch 42/100] [Batch 217/347] [D loss: 0.483479] [G loss: 0.389229]\n",
      "[Epoch 42/100] [Batch 218/347] [D loss: 0.547233] [G loss: 0.409046]\n",
      "[Epoch 42/100] [Batch 219/347] [D loss: 0.521972] [G loss: 0.425969]\n",
      "[Epoch 42/100] [Batch 220/347] [D loss: 0.520151] [G loss: 0.445582]\n",
      "[Epoch 42/100] [Batch 221/347] [D loss: 0.533949] [G loss: 0.450159]\n",
      "[Epoch 42/100] [Batch 222/347] [D loss: 0.525351] [G loss: 0.444643]\n",
      "[Epoch 42/100] [Batch 223/347] [D loss: 0.527190] [G loss: 0.445418]\n",
      "[Epoch 42/100] [Batch 224/347] [D loss: 0.531515] [G loss: 0.443001]\n",
      "[Epoch 42/100] [Batch 225/347] [D loss: 0.512512] [G loss: 0.424978]\n",
      "[Epoch 42/100] [Batch 226/347] [D loss: 0.511324] [G loss: 0.402186]\n",
      "[Epoch 42/100] [Batch 227/347] [D loss: 0.520766] [G loss: 0.377500]\n",
      "[Epoch 42/100] [Batch 228/347] [D loss: 0.526578] [G loss: 0.380168]\n",
      "[Epoch 42/100] [Batch 229/347] [D loss: 0.538134] [G loss: 0.390712]\n",
      "[Epoch 42/100] [Batch 230/347] [D loss: 0.541845] [G loss: 0.393381]\n",
      "[Epoch 42/100] [Batch 231/347] [D loss: 0.537115] [G loss: 0.386032]\n",
      "[Epoch 42/100] [Batch 232/347] [D loss: 0.537149] [G loss: 0.386881]\n",
      "[Epoch 42/100] [Batch 233/347] [D loss: 0.521181] [G loss: 0.384834]\n",
      "[Epoch 42/100] [Batch 234/347] [D loss: 0.492005] [G loss: 0.388945]\n",
      "[Epoch 42/100] [Batch 235/347] [D loss: 0.483806] [G loss: 0.395076]\n",
      "[Epoch 42/100] [Batch 236/347] [D loss: 0.492661] [G loss: 0.397127]\n",
      "[Epoch 42/100] [Batch 237/347] [D loss: 0.513308] [G loss: 0.401380]\n",
      "[Epoch 42/100] [Batch 238/347] [D loss: 0.542734] [G loss: 0.401424]\n",
      "[Epoch 42/100] [Batch 239/347] [D loss: 0.531510] [G loss: 0.395403]\n",
      "[Epoch 42/100] [Batch 240/347] [D loss: 0.524436] [G loss: 0.388188]\n",
      "[Epoch 42/100] [Batch 241/347] [D loss: 0.524146] [G loss: 0.379365]\n",
      "[Epoch 42/100] [Batch 242/347] [D loss: 0.529232] [G loss: 0.374961]\n",
      "[Epoch 42/100] [Batch 243/347] [D loss: 0.540888] [G loss: 0.380748]\n",
      "[Epoch 42/100] [Batch 244/347] [D loss: 0.543690] [G loss: 0.388233]\n",
      "[Epoch 42/100] [Batch 245/347] [D loss: 0.498441] [G loss: 0.385364]\n",
      "[Epoch 42/100] [Batch 246/347] [D loss: 0.474305] [G loss: 0.371520]\n",
      "[Epoch 42/100] [Batch 247/347] [D loss: 0.502884] [G loss: 0.340977]\n",
      "[Epoch 42/100] [Batch 248/347] [D loss: 0.527808] [G loss: 0.334790]\n",
      "[Epoch 42/100] [Batch 249/347] [D loss: 0.521496] [G loss: 0.328994]\n",
      "[Epoch 42/100] [Batch 250/347] [D loss: 0.509316] [G loss: 0.349545]\n",
      "[Epoch 42/100] [Batch 251/347] [D loss: 0.490460] [G loss: 0.365574]\n",
      "[Epoch 42/100] [Batch 252/347] [D loss: 0.483625] [G loss: 0.367071]\n",
      "[Epoch 42/100] [Batch 253/347] [D loss: 0.497981] [G loss: 0.366010]\n",
      "[Epoch 42/100] [Batch 254/347] [D loss: 0.513498] [G loss: 0.364312]\n",
      "[Epoch 42/100] [Batch 255/347] [D loss: 0.465671] [G loss: 0.360594]\n",
      "[Epoch 42/100] [Batch 256/347] [D loss: 0.455323] [G loss: 0.364488]\n",
      "[Epoch 42/100] [Batch 257/347] [D loss: 0.469564] [G loss: 0.369461]\n",
      "[Epoch 42/100] [Batch 258/347] [D loss: 0.413548] [G loss: 0.359440]\n",
      "[Epoch 42/100] [Batch 259/347] [D loss: 0.396107] [G loss: 0.345716]\n",
      "[Epoch 42/100] [Batch 260/347] [D loss: 0.358750] [G loss: 0.343264]\n",
      "[Epoch 42/100] [Batch 261/347] [D loss: 0.370817] [G loss: 0.351120]\n",
      "[Epoch 42/100] [Batch 262/347] [D loss: 0.434629] [G loss: 0.346644]\n",
      "[Epoch 42/100] [Batch 263/347] [D loss: 0.398291] [G loss: 0.345195]\n",
      "[Epoch 42/100] [Batch 264/347] [D loss: 0.351946] [G loss: 0.348756]\n",
      "[Epoch 42/100] [Batch 265/347] [D loss: 0.368401] [G loss: 0.347722]\n",
      "[Epoch 42/100] [Batch 266/347] [D loss: 0.389706] [G loss: 0.345889]\n",
      "[Epoch 42/100] [Batch 267/347] [D loss: 0.394438] [G loss: 0.345531]\n",
      "[Epoch 42/100] [Batch 268/347] [D loss: 0.345542] [G loss: 0.352044]\n",
      "[Epoch 42/100] [Batch 269/347] [D loss: 0.346432] [G loss: 0.355971]\n",
      "[Epoch 42/100] [Batch 270/347] [D loss: 0.400701] [G loss: 0.355013]\n",
      "[Epoch 42/100] [Batch 271/347] [D loss: 0.439992] [G loss: 0.353089]\n",
      "[Epoch 42/100] [Batch 272/347] [D loss: 0.472012] [G loss: 0.356062]\n",
      "[Epoch 42/100] [Batch 273/347] [D loss: 0.381337] [G loss: 0.365396]\n",
      "[Epoch 42/100] [Batch 274/347] [D loss: 0.523604] [G loss: 0.388715]\n",
      "[Epoch 42/100] [Batch 275/347] [D loss: 0.490746] [G loss: 0.402391]\n",
      "[Epoch 42/100] [Batch 276/347] [D loss: 0.379014] [G loss: 0.397866]\n",
      "[Epoch 42/100] [Batch 277/347] [D loss: 0.387498] [G loss: 0.403749]\n",
      "[Epoch 42/100] [Batch 278/347] [D loss: 0.499331] [G loss: 0.420446]\n",
      "[Epoch 42/100] [Batch 279/347] [D loss: 0.476735] [G loss: 0.420528]\n",
      "[Epoch 42/100] [Batch 280/347] [D loss: 0.458245] [G loss: 0.427523]\n",
      "[Epoch 42/100] [Batch 281/347] [D loss: 0.460719] [G loss: 0.427863]\n",
      "[Epoch 42/100] [Batch 282/347] [D loss: 0.474306] [G loss: 0.426805]\n",
      "[Epoch 42/100] [Batch 283/347] [D loss: 0.401892] [G loss: 0.426832]\n",
      "[Epoch 42/100] [Batch 284/347] [D loss: 0.389246] [G loss: 0.427518]\n",
      "[Epoch 42/100] [Batch 285/347] [D loss: 0.467650] [G loss: 0.427713]\n",
      "[Epoch 42/100] [Batch 286/347] [D loss: 0.519644] [G loss: 0.425749]\n",
      "[Epoch 42/100] [Batch 287/347] [D loss: 0.522292] [G loss: 0.419573]\n",
      "[Epoch 42/100] [Batch 288/347] [D loss: 0.507600] [G loss: 0.396301]\n",
      "[Epoch 42/100] [Batch 289/347] [D loss: 0.506377] [G loss: 0.388173]\n",
      "[Epoch 42/100] [Batch 290/347] [D loss: 0.524015] [G loss: 0.400842]\n",
      "[Epoch 42/100] [Batch 291/347] [D loss: 0.495765] [G loss: 0.393700]\n",
      "[Epoch 42/100] [Batch 292/347] [D loss: 0.484541] [G loss: 0.397112]\n",
      "[Epoch 42/100] [Batch 293/347] [D loss: 0.433030] [G loss: 0.414034]\n",
      "[Epoch 42/100] [Batch 294/347] [D loss: 0.379811] [G loss: 0.412249]\n",
      "[Epoch 42/100] [Batch 295/347] [D loss: 0.231657] [G loss: 0.395219]\n",
      "[Epoch 42/100] [Batch 296/347] [D loss: 0.220658] [G loss: 0.399774]\n",
      "[Epoch 42/100] [Batch 297/347] [D loss: 0.486416] [G loss: 0.414456]\n",
      "[Epoch 42/100] [Batch 298/347] [D loss: 0.549032] [G loss: 0.407472]\n",
      "[Epoch 42/100] [Batch 299/347] [D loss: 0.505580] [G loss: 0.404527]\n",
      "[Epoch 42/100] [Batch 300/347] [D loss: 0.450172] [G loss: 0.397704]\n",
      "[Epoch 42/100] [Batch 301/347] [D loss: 0.458194] [G loss: 0.390515]\n",
      "[Epoch 42/100] [Batch 302/347] [D loss: 0.505675] [G loss: 0.393688]\n",
      "[Epoch 42/100] [Batch 303/347] [D loss: 0.481661] [G loss: 0.367773]\n",
      "[Epoch 42/100] [Batch 304/347] [D loss: 0.487737] [G loss: 0.349704]\n",
      "[Epoch 42/100] [Batch 305/347] [D loss: 0.504653] [G loss: 0.349030]\n",
      "[Epoch 42/100] [Batch 306/347] [D loss: 0.320084] [G loss: 0.337874]\n",
      "[Epoch 42/100] [Batch 307/347] [D loss: 0.244710] [G loss: 0.340720]\n",
      "[Epoch 42/100] [Batch 308/347] [D loss: 0.319021] [G loss: 0.341696]\n",
      "[Epoch 42/100] [Batch 309/347] [D loss: 0.494973] [G loss: 0.359703]\n",
      "[Epoch 42/100] [Batch 310/347] [D loss: 0.554322] [G loss: 0.388450]\n",
      "[Epoch 42/100] [Batch 311/347] [D loss: 0.555676] [G loss: 0.392631]\n",
      "[Epoch 42/100] [Batch 312/347] [D loss: 0.553519] [G loss: 0.394085]\n",
      "[Epoch 42/100] [Batch 313/347] [D loss: 0.543345] [G loss: 0.395243]\n",
      "[Epoch 42/100] [Batch 314/347] [D loss: 0.497914] [G loss: 0.390282]\n",
      "[Epoch 42/100] [Batch 315/347] [D loss: 0.439819] [G loss: 0.381769]\n",
      "[Epoch 42/100] [Batch 316/347] [D loss: 0.439148] [G loss: 0.365353]\n",
      "[Epoch 42/100] [Batch 317/347] [D loss: 0.494410] [G loss: 0.354438]\n",
      "[Epoch 42/100] [Batch 318/347] [D loss: 0.525514] [G loss: 0.370187]\n",
      "[Epoch 42/100] [Batch 319/347] [D loss: 0.533759] [G loss: 0.402432]\n",
      "[Epoch 42/100] [Batch 320/347] [D loss: 0.532823] [G loss: 0.415642]\n",
      "[Epoch 42/100] [Batch 321/347] [D loss: 0.511734] [G loss: 0.404586]\n",
      "[Epoch 42/100] [Batch 322/347] [D loss: 0.506541] [G loss: 0.390722]\n",
      "[Epoch 42/100] [Batch 323/347] [D loss: 0.472895] [G loss: 0.388667]\n",
      "[Epoch 42/100] [Batch 324/347] [D loss: 0.462497] [G loss: 0.390079]\n",
      "[Epoch 42/100] [Batch 325/347] [D loss: 0.361845] [G loss: 0.378387]\n",
      "[Epoch 42/100] [Batch 326/347] [D loss: 0.335458] [G loss: 0.365793]\n",
      "[Epoch 42/100] [Batch 327/347] [D loss: 0.416404] [G loss: 0.363775]\n",
      "[Epoch 42/100] [Batch 328/347] [D loss: 0.467306] [G loss: 0.361685]\n",
      "[Epoch 42/100] [Batch 329/347] [D loss: 0.374080] [G loss: 0.351833]\n",
      "[Epoch 42/100] [Batch 330/347] [D loss: 0.361399] [G loss: 0.345151]\n",
      "[Epoch 42/100] [Batch 331/347] [D loss: 0.437823] [G loss: 0.353101]\n",
      "[Epoch 42/100] [Batch 332/347] [D loss: 0.528124] [G loss: 0.373213]\n",
      "[Epoch 42/100] [Batch 333/347] [D loss: 0.545166] [G loss: 0.384709]\n",
      "[Epoch 42/100] [Batch 334/347] [D loss: 0.514267] [G loss: 0.386342]\n",
      "[Epoch 42/100] [Batch 335/347] [D loss: 0.482324] [G loss: 0.374378]\n",
      "[Epoch 42/100] [Batch 336/347] [D loss: 0.475357] [G loss: 0.361541]\n",
      "[Epoch 42/100] [Batch 337/347] [D loss: 0.472371] [G loss: 0.365175]\n",
      "[Epoch 42/100] [Batch 338/347] [D loss: 0.499488] [G loss: 0.379469]\n",
      "[Epoch 42/100] [Batch 339/347] [D loss: 0.542915] [G loss: 0.385374]\n",
      "[Epoch 42/100] [Batch 340/347] [D loss: 0.550889] [G loss: 0.386815]\n",
      "[Epoch 42/100] [Batch 341/347] [D loss: 0.526039] [G loss: 0.383329]\n",
      "[Epoch 42/100] [Batch 342/347] [D loss: 0.516906] [G loss: 0.376986]\n",
      "[Epoch 42/100] [Batch 343/347] [D loss: 0.541668] [G loss: 0.383496]\n",
      "[Epoch 42/100] [Batch 344/347] [D loss: 0.444682] [G loss: 0.373706]\n",
      "[Epoch 42/100] [Batch 345/347] [D loss: 0.381106] [G loss: 0.353411]\n",
      "[Epoch 42/100] [Batch 346/347] [D loss: 0.337560] [G loss: 0.354693]\n",
      "[Epoch 42/100] [Batch 347/347] [D loss: 0.243378] [G loss: 0.369023]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 43/100] [Batch 1/347] [D loss: 0.519922] [G loss: 0.382123]\n",
      "[Epoch 43/100] [Batch 2/347] [D loss: 0.529107] [G loss: 0.388690]\n",
      "[Epoch 43/100] [Batch 3/347] [D loss: 0.551309] [G loss: 0.402829]\n",
      "[Epoch 43/100] [Batch 4/347] [D loss: 0.552394] [G loss: 0.407698]\n",
      "[Epoch 43/100] [Batch 5/347] [D loss: 0.550764] [G loss: 0.410476]\n",
      "[Epoch 43/100] [Batch 6/347] [D loss: 0.554884] [G loss: 0.415774]\n",
      "[Epoch 43/100] [Batch 7/347] [D loss: 0.551123] [G loss: 0.413915]\n",
      "[Epoch 43/100] [Batch 8/347] [D loss: 0.537254] [G loss: 0.411959]\n",
      "[Epoch 43/100] [Batch 9/347] [D loss: 0.521746] [G loss: 0.403190]\n",
      "[Epoch 43/100] [Batch 10/347] [D loss: 0.526792] [G loss: 0.405037]\n",
      "[Epoch 43/100] [Batch 11/347] [D loss: 0.548099] [G loss: 0.419756]\n",
      "[Epoch 43/100] [Batch 12/347] [D loss: 0.553588] [G loss: 0.424936]\n",
      "[Epoch 43/100] [Batch 13/347] [D loss: 0.556173] [G loss: 0.429361]\n",
      "[Epoch 43/100] [Batch 14/347] [D loss: 0.554132] [G loss: 0.431720]\n",
      "[Epoch 43/100] [Batch 15/347] [D loss: 0.543711] [G loss: 0.427722]\n",
      "[Epoch 43/100] [Batch 16/347] [D loss: 0.534706] [G loss: 0.423264]\n",
      "[Epoch 43/100] [Batch 17/347] [D loss: 0.518710] [G loss: 0.411071]\n",
      "[Epoch 43/100] [Batch 18/347] [D loss: 0.492333] [G loss: 0.410462]\n",
      "[Epoch 43/100] [Batch 19/347] [D loss: 0.500072] [G loss: 0.413666]\n",
      "[Epoch 43/100] [Batch 20/347] [D loss: 0.548090] [G loss: 0.425318]\n",
      "[Epoch 43/100] [Batch 21/347] [D loss: 0.550152] [G loss: 0.420152]\n",
      "[Epoch 43/100] [Batch 22/347] [D loss: 0.540810] [G loss: 0.413796]\n",
      "[Epoch 43/100] [Batch 23/347] [D loss: 0.511443] [G loss: 0.406025]\n",
      "[Epoch 43/100] [Batch 24/347] [D loss: 0.508232] [G loss: 0.403207]\n",
      "[Epoch 43/100] [Batch 25/347] [D loss: 0.528996] [G loss: 0.400842]\n",
      "[Epoch 43/100] [Batch 26/347] [D loss: 0.460537] [G loss: 0.389734]\n",
      "[Epoch 43/100] [Batch 27/347] [D loss: 0.251638] [G loss: 0.403505]\n",
      "[Epoch 43/100] [Batch 28/347] [D loss: 0.261956] [G loss: 0.410398]\n",
      "[Epoch 43/100] [Batch 29/347] [D loss: 0.504112] [G loss: 0.404439]\n",
      "[Epoch 43/100] [Batch 30/347] [D loss: 0.450665] [G loss: 0.408394]\n",
      "[Epoch 43/100] [Batch 31/347] [D loss: 0.385073] [G loss: 0.407143]\n",
      "[Epoch 43/100] [Batch 32/347] [D loss: 0.306014] [G loss: 0.398237]\n",
      "[Epoch 43/100] [Batch 33/347] [D loss: 0.327013] [G loss: 0.388653]\n",
      "[Epoch 43/100] [Batch 34/347] [D loss: 0.418940] [G loss: 0.385334]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 43/100] [Batch 35/347] [D loss: 0.401775] [G loss: 0.379244]\n",
      "[Epoch 43/100] [Batch 36/347] [D loss: 0.476359] [G loss: 0.366752]\n",
      "[Epoch 43/100] [Batch 37/347] [D loss: 0.419966] [G loss: 0.354127]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 43/100] [Batch 38/347] [D loss: 0.373915] [G loss: 0.336980]\n",
      "[Epoch 43/100] [Batch 39/347] [D loss: 0.423335] [G loss: 0.328271]\n",
      "[Epoch 43/100] [Batch 40/347] [D loss: 0.515106] [G loss: 0.323589]\n",
      "[Epoch 43/100] [Batch 41/347] [D loss: 0.520924] [G loss: 0.317783]\n",
      "[Epoch 43/100] [Batch 42/347] [D loss: 0.518110] [G loss: 0.318663]\n",
      "[Epoch 43/100] [Batch 43/347] [D loss: 0.502255] [G loss: 0.332084]\n",
      "[Epoch 43/100] [Batch 44/347] [D loss: 0.500503] [G loss: 0.345561]\n",
      "[Epoch 43/100] [Batch 45/347] [D loss: 0.527035] [G loss: 0.362083]\n",
      "[Epoch 43/100] [Batch 46/347] [D loss: 0.526112] [G loss: 0.356678]\n",
      "[Epoch 43/100] [Batch 47/347] [D loss: 0.507913] [G loss: 0.333991]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 43/100] [Batch 48/347] [D loss: 0.355573] [G loss: 0.325150]\n",
      "[Epoch 43/100] [Batch 49/347] [D loss: 0.356059] [G loss: 0.328288]\n",
      "[Epoch 43/100] [Batch 50/347] [D loss: 0.288657] [G loss: 0.342181]\n",
      "[Epoch 43/100] [Batch 51/347] [D loss: 0.271418] [G loss: 0.360434]\n",
      "[Epoch 43/100] [Batch 52/347] [D loss: 0.378800] [G loss: 0.364764]\n",
      "[Epoch 43/100] [Batch 53/347] [D loss: 0.476546] [G loss: 0.363646]\n",
      "[Epoch 43/100] [Batch 54/347] [D loss: 0.416052] [G loss: 0.352782]\n",
      "[Epoch 43/100] [Batch 55/347] [D loss: 0.406305] [G loss: 0.328879]\n",
      "[Epoch 43/100] [Batch 56/347] [D loss: 0.402957] [G loss: 0.333061]\n",
      "[Epoch 43/100] [Batch 57/347] [D loss: 0.401677] [G loss: 0.363564]\n",
      "[Epoch 43/100] [Batch 58/347] [D loss: 0.419938] [G loss: 0.374614]\n",
      "[Epoch 43/100] [Batch 59/347] [D loss: 0.390857] [G loss: 0.373371]\n",
      "[Epoch 43/100] [Batch 60/347] [D loss: 0.367699] [G loss: 0.369494]\n",
      "[Epoch 43/100] [Batch 61/347] [D loss: 0.336177] [G loss: 0.366522]\n",
      "[Epoch 43/100] [Batch 62/347] [D loss: 0.350896] [G loss: 0.351116]\n",
      "[Epoch 43/100] [Batch 63/347] [D loss: 0.392440] [G loss: 0.328419]\n",
      "[Epoch 43/100] [Batch 64/347] [D loss: 0.420526] [G loss: 0.348129]\n",
      "[Epoch 43/100] [Batch 65/347] [D loss: 0.492108] [G loss: 0.367151]\n",
      "[Epoch 43/100] [Batch 66/347] [D loss: 0.407362] [G loss: 0.365554]\n",
      "[Epoch 43/100] [Batch 67/347] [D loss: 0.233833] [G loss: 0.360208]\n",
      "[Epoch 43/100] [Batch 68/347] [D loss: 0.260593] [G loss: 0.357394]\n",
      "[Epoch 43/100] [Batch 69/347] [D loss: 0.388405] [G loss: 0.341282]\n",
      "[Epoch 43/100] [Batch 70/347] [D loss: 0.391228] [G loss: 0.332415]\n",
      "[Epoch 43/100] [Batch 71/347] [D loss: 0.374334] [G loss: 0.344517]\n",
      "[Epoch 43/100] [Batch 72/347] [D loss: 0.369756] [G loss: 0.343546]\n",
      "[Epoch 43/100] [Batch 73/347] [D loss: 0.370988] [G loss: 0.350071]\n",
      "[Epoch 43/100] [Batch 74/347] [D loss: 0.370824] [G loss: 0.368885]\n",
      "[Epoch 43/100] [Batch 75/347] [D loss: 0.394464] [G loss: 0.359602]\n",
      "[Epoch 43/100] [Batch 76/347] [D loss: 0.421164] [G loss: 0.337808]\n",
      "[Epoch 43/100] [Batch 77/347] [D loss: 0.413330] [G loss: 0.348314]\n",
      "[Epoch 43/100] [Batch 78/347] [D loss: 0.410163] [G loss: 0.364328]\n",
      "[Epoch 43/100] [Batch 79/347] [D loss: 0.501941] [G loss: 0.372849]\n",
      "[Epoch 43/100] [Batch 80/347] [D loss: 0.533326] [G loss: 0.367579]\n",
      "[Epoch 43/100] [Batch 81/347] [D loss: 0.517907] [G loss: 0.369684]\n",
      "[Epoch 43/100] [Batch 82/347] [D loss: 0.430858] [G loss: 0.360741]\n",
      "[Epoch 43/100] [Batch 83/347] [D loss: 0.414775] [G loss: 0.356826]\n",
      "[Epoch 43/100] [Batch 84/347] [D loss: 0.487942] [G loss: 0.366679]\n",
      "[Epoch 43/100] [Batch 85/347] [D loss: 0.549311] [G loss: 0.366620]\n",
      "[Epoch 43/100] [Batch 86/347] [D loss: 0.545555] [G loss: 0.360897]\n",
      "[Epoch 43/100] [Batch 87/347] [D loss: 0.544512] [G loss: 0.359059]\n",
      "[Epoch 43/100] [Batch 88/347] [D loss: 0.550215] [G loss: 0.363537]\n",
      "[Epoch 43/100] [Batch 89/347] [D loss: 0.557809] [G loss: 0.369048]\n",
      "[Epoch 43/100] [Batch 90/347] [D loss: 0.554128] [G loss: 0.367569]\n",
      "[Epoch 43/100] [Batch 91/347] [D loss: 0.553172] [G loss: 0.369414]\n",
      "[Epoch 43/100] [Batch 92/347] [D loss: 0.555835] [G loss: 0.374486]\n",
      "[Epoch 43/100] [Batch 93/347] [D loss: 0.554566] [G loss: 0.376471]\n",
      "[Epoch 43/100] [Batch 94/347] [D loss: 0.547806] [G loss: 0.377326]\n",
      "[Epoch 43/100] [Batch 95/347] [D loss: 0.547898] [G loss: 0.382075]\n",
      "[Epoch 43/100] [Batch 96/347] [D loss: 0.544165] [G loss: 0.381905]\n",
      "[Epoch 43/100] [Batch 97/347] [D loss: 0.540420] [G loss: 0.381182]\n",
      "[Epoch 43/100] [Batch 98/347] [D loss: 0.548194] [G loss: 0.390266]\n",
      "[Epoch 43/100] [Batch 99/347] [D loss: 0.550858] [G loss: 0.398234]\n",
      "[Epoch 43/100] [Batch 100/347] [D loss: 0.532404] [G loss: 0.398654]\n",
      "[Epoch 43/100] [Batch 101/347] [D loss: 0.532665] [G loss: 0.397029]\n",
      "[Epoch 43/100] [Batch 102/347] [D loss: 0.549483] [G loss: 0.401935]\n",
      "[Epoch 43/100] [Batch 103/347] [D loss: 0.549241] [G loss: 0.405929]\n",
      "[Epoch 43/100] [Batch 104/347] [D loss: 0.544446] [G loss: 0.400211]\n",
      "[Epoch 43/100] [Batch 105/347] [D loss: 0.545422] [G loss: 0.402335]\n",
      "[Epoch 43/100] [Batch 106/347] [D loss: 0.534640] [G loss: 0.403778]\n",
      "[Epoch 43/100] [Batch 107/347] [D loss: 0.465659] [G loss: 0.394508]\n",
      "[Epoch 43/100] [Batch 108/347] [D loss: 0.208532] [G loss: 0.409706]\n",
      "[Epoch 43/100] [Batch 109/347] [D loss: 0.207725] [G loss: 0.418531]\n",
      "[Epoch 43/100] [Batch 110/347] [D loss: 0.429868] [G loss: 0.415229]\n",
      "[Epoch 43/100] [Batch 111/347] [D loss: 0.261457] [G loss: 0.418326]\n",
      "[Epoch 43/100] [Batch 112/347] [D loss: 0.204070] [G loss: 0.426631]\n",
      "[Epoch 43/100] [Batch 113/347] [D loss: 0.429876] [G loss: 0.439084]\n",
      "[Epoch 43/100] [Batch 114/347] [D loss: 0.493701] [G loss: 0.461675]\n",
      "[Epoch 43/100] [Batch 115/347] [D loss: 0.476443] [G loss: 0.463612]\n",
      "[Epoch 43/100] [Batch 116/347] [D loss: 0.502340] [G loss: 0.457945]\n",
      "[Epoch 43/100] [Batch 117/347] [D loss: 0.489177] [G loss: 0.430516]\n",
      "[Epoch 43/100] [Batch 118/347] [D loss: 0.410995] [G loss: 0.415304]\n",
      "[Epoch 43/100] [Batch 119/347] [D loss: 0.360096] [G loss: 0.406455]\n",
      "[Epoch 43/100] [Batch 120/347] [D loss: 0.298019] [G loss: 0.407730]\n",
      "[Epoch 43/100] [Batch 121/347] [D loss: 0.285103] [G loss: 0.403876]\n",
      "[Epoch 43/100] [Batch 122/347] [D loss: 0.442919] [G loss: 0.402834]\n",
      "[Epoch 43/100] [Batch 123/347] [D loss: 0.529218] [G loss: 0.401564]\n",
      "[Epoch 43/100] [Batch 124/347] [D loss: 0.528543] [G loss: 0.393118]\n",
      "[Epoch 43/100] [Batch 125/347] [D loss: 0.532214] [G loss: 0.400225]\n",
      "[Epoch 43/100] [Batch 126/347] [D loss: 0.504444] [G loss: 0.408136]\n",
      "[Epoch 43/100] [Batch 127/347] [D loss: 0.488915] [G loss: 0.404709]\n",
      "[Epoch 43/100] [Batch 128/347] [D loss: 0.487109] [G loss: 0.393996]\n",
      "[Epoch 43/100] [Batch 129/347] [D loss: 0.394136] [G loss: 0.383866]\n",
      "[Epoch 43/100] [Batch 130/347] [D loss: 0.378359] [G loss: 0.378936]\n",
      "[Epoch 43/100] [Batch 131/347] [D loss: 0.328547] [G loss: 0.373711]\n",
      "[Epoch 43/100] [Batch 132/347] [D loss: 0.242065] [G loss: 0.375118]\n",
      "[Epoch 43/100] [Batch 133/347] [D loss: 0.242971] [G loss: 0.376437]\n",
      "[Epoch 43/100] [Batch 134/347] [D loss: 0.235931] [G loss: 0.384107]\n",
      "[Epoch 43/100] [Batch 135/347] [D loss: 0.243183] [G loss: 0.402223]\n",
      "[Epoch 43/100] [Batch 136/347] [D loss: 0.233359] [G loss: 0.419514]\n",
      "[Epoch 43/100] [Batch 137/347] [D loss: 0.448376] [G loss: 0.420079]\n",
      "[Epoch 43/100] [Batch 138/347] [D loss: 0.435012] [G loss: 0.417394]\n",
      "[Epoch 43/100] [Batch 139/347] [D loss: 0.413916] [G loss: 0.408886]\n",
      "[Epoch 43/100] [Batch 140/347] [D loss: 0.385483] [G loss: 0.410460]\n",
      "[Epoch 43/100] [Batch 141/347] [D loss: 0.391833] [G loss: 0.405660]\n",
      "[Epoch 43/100] [Batch 142/347] [D loss: 0.400453] [G loss: 0.403513]\n",
      "[Epoch 43/100] [Batch 143/347] [D loss: 0.354840] [G loss: 0.395287]\n",
      "[Epoch 43/100] [Batch 144/347] [D loss: 0.343568] [G loss: 0.382330]\n",
      "[Epoch 43/100] [Batch 145/347] [D loss: 0.340241] [G loss: 0.369623]\n",
      "[Epoch 43/100] [Batch 146/347] [D loss: 0.337600] [G loss: 0.358270]\n",
      "[Epoch 43/100] [Batch 147/347] [D loss: 0.376898] [G loss: 0.362712]\n",
      "[Epoch 43/100] [Batch 148/347] [D loss: 0.385923] [G loss: 0.361392]\n",
      "[Epoch 43/100] [Batch 149/347] [D loss: 0.411596] [G loss: 0.349414]\n",
      "[Epoch 43/100] [Batch 150/347] [D loss: 0.426626] [G loss: 0.344951]\n",
      "[Epoch 43/100] [Batch 151/347] [D loss: 0.409744] [G loss: 0.348469]\n",
      "[Epoch 43/100] [Batch 152/347] [D loss: 0.355991] [G loss: 0.343628]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 43/100] [Batch 153/347] [D loss: 0.316676] [G loss: 0.323231]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 43/100] [Batch 154/347] [D loss: 0.312881] [G loss: 0.300984]\n",
      "[Epoch 43/100] [Batch 155/347] [D loss: 0.330169] [G loss: 0.295655]\n",
      "[Epoch 43/100] [Batch 156/347] [D loss: 0.374469] [G loss: 0.302714]\n",
      "[Epoch 43/100] [Batch 157/347] [D loss: 0.357905] [G loss: 0.311865]\n",
      "[Epoch 43/100] [Batch 158/347] [D loss: 0.324002] [G loss: 0.299607]\n",
      "[Epoch 43/100] [Batch 159/347] [D loss: 0.314134] [G loss: 0.287584]\n",
      "[Epoch 43/100] [Batch 160/347] [D loss: 0.270558] [G loss: 0.308857]\n",
      "[Epoch 43/100] [Batch 161/347] [D loss: 0.265311] [G loss: 0.328536]\n",
      "[Epoch 43/100] [Batch 162/347] [D loss: 0.327226] [G loss: 0.332376]\n",
      "[Epoch 43/100] [Batch 163/347] [D loss: 0.337776] [G loss: 0.327721]\n",
      "[Epoch 43/100] [Batch 164/347] [D loss: 0.312386] [G loss: 0.323564]\n",
      "[Epoch 43/100] [Batch 165/347] [D loss: 0.291716] [G loss: 0.320118]\n",
      "[Epoch 43/100] [Batch 166/347] [D loss: 0.300544] [G loss: 0.334292]\n",
      "[Epoch 43/100] [Batch 167/347] [D loss: 0.272648] [G loss: 0.359059]\n",
      "[Epoch 43/100] [Batch 168/347] [D loss: 0.232917] [G loss: 0.375694]\n",
      "[Epoch 43/100] [Batch 169/347] [D loss: 0.373140] [G loss: 0.384362]\n",
      "[Epoch 43/100] [Batch 170/347] [D loss: 0.455115] [G loss: 0.399317]\n",
      "[Epoch 43/100] [Batch 171/347] [D loss: 0.511494] [G loss: 0.413807]\n",
      "[Epoch 43/100] [Batch 172/347] [D loss: 0.525724] [G loss: 0.420837]\n",
      "[Epoch 43/100] [Batch 173/347] [D loss: 0.421184] [G loss: 0.410113]\n",
      "[Epoch 43/100] [Batch 174/347] [D loss: 0.421625] [G loss: 0.406876]\n",
      "[Epoch 43/100] [Batch 175/347] [D loss: 0.531988] [G loss: 0.415951]\n",
      "[Epoch 43/100] [Batch 176/347] [D loss: 0.555887] [G loss: 0.428606]\n",
      "[Epoch 43/100] [Batch 177/347] [D loss: 0.559343] [G loss: 0.429097]\n",
      "[Epoch 43/100] [Batch 178/347] [D loss: 0.552484] [G loss: 0.422813]\n",
      "[Epoch 43/100] [Batch 179/347] [D loss: 0.545994] [G loss: 0.415728]\n",
      "[Epoch 43/100] [Batch 180/347] [D loss: 0.541838] [G loss: 0.409002]\n",
      "[Epoch 43/100] [Batch 181/347] [D loss: 0.542811] [G loss: 0.409217]\n",
      "[Epoch 43/100] [Batch 182/347] [D loss: 0.542114] [G loss: 0.406732]\n",
      "[Epoch 43/100] [Batch 183/347] [D loss: 0.542508] [G loss: 0.410576]\n",
      "[Epoch 43/100] [Batch 184/347] [D loss: 0.547549] [G loss: 0.414136]\n",
      "[Epoch 43/100] [Batch 185/347] [D loss: 0.550741] [G loss: 0.412506]\n",
      "[Epoch 43/100] [Batch 186/347] [D loss: 0.551470] [G loss: 0.412491]\n",
      "[Epoch 43/100] [Batch 187/347] [D loss: 0.548370] [G loss: 0.407358]\n",
      "[Epoch 43/100] [Batch 188/347] [D loss: 0.546993] [G loss: 0.404539]\n",
      "[Epoch 43/100] [Batch 189/347] [D loss: 0.543603] [G loss: 0.404139]\n",
      "[Epoch 43/100] [Batch 190/347] [D loss: 0.526518] [G loss: 0.392621]\n",
      "[Epoch 43/100] [Batch 191/347] [D loss: 0.492936] [G loss: 0.379381]\n",
      "[Epoch 43/100] [Batch 192/347] [D loss: 0.481187] [G loss: 0.379350]\n",
      "[Epoch 43/100] [Batch 193/347] [D loss: 0.497941] [G loss: 0.385701]\n",
      "[Epoch 43/100] [Batch 194/347] [D loss: 0.529763] [G loss: 0.379206]\n",
      "[Epoch 43/100] [Batch 195/347] [D loss: 0.541519] [G loss: 0.369941]\n",
      "[Epoch 43/100] [Batch 196/347] [D loss: 0.531415] [G loss: 0.363552]\n",
      "[Epoch 43/100] [Batch 197/347] [D loss: 0.490640] [G loss: 0.360250]\n",
      "[Epoch 43/100] [Batch 198/347] [D loss: 0.394294] [G loss: 0.356834]\n",
      "[Epoch 43/100] [Batch 199/347] [D loss: 0.403600] [G loss: 0.352430]\n",
      "[Epoch 43/100] [Batch 200/347] [D loss: 0.505587] [G loss: 0.354113]\n",
      "[Epoch 43/100] [Batch 201/347] [D loss: 0.507980] [G loss: 0.352890]\n",
      "[Epoch 43/100] [Batch 202/347] [D loss: 0.520669] [G loss: 0.346115]\n",
      "[Epoch 43/100] [Batch 203/347] [D loss: 0.546377] [G loss: 0.340993]\n",
      "[Epoch 43/100] [Batch 204/347] [D loss: 0.547204] [G loss: 0.340573]\n",
      "[Epoch 43/100] [Batch 205/347] [D loss: 0.543913] [G loss: 0.341398]\n",
      "[Epoch 43/100] [Batch 206/347] [D loss: 0.537375] [G loss: 0.346033]\n",
      "[Epoch 43/100] [Batch 207/347] [D loss: 0.533586] [G loss: 0.356450]\n",
      "[Epoch 43/100] [Batch 208/347] [D loss: 0.538437] [G loss: 0.357236]\n",
      "[Epoch 43/100] [Batch 209/347] [D loss: 0.514208] [G loss: 0.351918]\n",
      "[Epoch 43/100] [Batch 210/347] [D loss: 0.503712] [G loss: 0.358298]\n",
      "[Epoch 43/100] [Batch 211/347] [D loss: 0.522600] [G loss: 0.357496]\n",
      "[Epoch 43/100] [Batch 212/347] [D loss: 0.323027] [G loss: 0.353084]\n",
      "[Epoch 43/100] [Batch 213/347] [D loss: 0.307582] [G loss: 0.356294]\n",
      "[Epoch 43/100] [Batch 214/347] [D loss: 0.241724] [G loss: 0.370487]\n",
      "[Epoch 43/100] [Batch 215/347] [D loss: 0.234484] [G loss: 0.381161]\n",
      "[Epoch 43/100] [Batch 216/347] [D loss: 0.388133] [G loss: 0.384804]\n",
      "[Epoch 43/100] [Batch 217/347] [D loss: 0.477518] [G loss: 0.395760]\n",
      "[Epoch 43/100] [Batch 218/347] [D loss: 0.547448] [G loss: 0.418005]\n",
      "[Epoch 43/100] [Batch 219/347] [D loss: 0.517507] [G loss: 0.436218]\n",
      "[Epoch 43/100] [Batch 220/347] [D loss: 0.515274] [G loss: 0.456894]\n",
      "[Epoch 43/100] [Batch 221/347] [D loss: 0.531684] [G loss: 0.462216]\n",
      "[Epoch 43/100] [Batch 222/347] [D loss: 0.523917] [G loss: 0.457310]\n",
      "[Epoch 43/100] [Batch 223/347] [D loss: 0.526623] [G loss: 0.458443]\n",
      "[Epoch 43/100] [Batch 224/347] [D loss: 0.531405] [G loss: 0.456388]\n",
      "[Epoch 43/100] [Batch 225/347] [D loss: 0.513063] [G loss: 0.435882]\n",
      "[Epoch 43/100] [Batch 226/347] [D loss: 0.513020] [G loss: 0.413264]\n",
      "[Epoch 43/100] [Batch 227/347] [D loss: 0.523184] [G loss: 0.388506]\n",
      "[Epoch 43/100] [Batch 228/347] [D loss: 0.528906] [G loss: 0.393590]\n",
      "[Epoch 43/100] [Batch 229/347] [D loss: 0.540798] [G loss: 0.404337]\n",
      "[Epoch 43/100] [Batch 230/347] [D loss: 0.544669] [G loss: 0.406640]\n",
      "[Epoch 43/100] [Batch 231/347] [D loss: 0.539808] [G loss: 0.399291]\n",
      "[Epoch 43/100] [Batch 232/347] [D loss: 0.539656] [G loss: 0.399970]\n",
      "[Epoch 43/100] [Batch 233/347] [D loss: 0.522671] [G loss: 0.395425]\n",
      "[Epoch 43/100] [Batch 234/347] [D loss: 0.490024] [G loss: 0.398903]\n",
      "[Epoch 43/100] [Batch 235/347] [D loss: 0.480869] [G loss: 0.404774]\n",
      "[Epoch 43/100] [Batch 236/347] [D loss: 0.489788] [G loss: 0.405904]\n",
      "[Epoch 43/100] [Batch 237/347] [D loss: 0.509966] [G loss: 0.411250]\n",
      "[Epoch 43/100] [Batch 238/347] [D loss: 0.542879] [G loss: 0.410218]\n",
      "[Epoch 43/100] [Batch 239/347] [D loss: 0.530378] [G loss: 0.403530]\n",
      "[Epoch 43/100] [Batch 240/347] [D loss: 0.523269] [G loss: 0.395307]\n",
      "[Epoch 43/100] [Batch 241/347] [D loss: 0.523367] [G loss: 0.385615]\n",
      "[Epoch 43/100] [Batch 242/347] [D loss: 0.529079] [G loss: 0.380644]\n",
      "[Epoch 43/100] [Batch 243/347] [D loss: 0.541543] [G loss: 0.385864]\n",
      "[Epoch 43/100] [Batch 244/347] [D loss: 0.543979] [G loss: 0.392969]\n",
      "[Epoch 43/100] [Batch 245/347] [D loss: 0.494258] [G loss: 0.389717]\n",
      "[Epoch 43/100] [Batch 246/347] [D loss: 0.466436] [G loss: 0.373826]\n",
      "[Epoch 43/100] [Batch 247/347] [D loss: 0.499273] [G loss: 0.344299]\n",
      "[Epoch 43/100] [Batch 248/347] [D loss: 0.530180] [G loss: 0.337728]\n",
      "[Epoch 43/100] [Batch 249/347] [D loss: 0.523764] [G loss: 0.330406]\n",
      "[Epoch 43/100] [Batch 250/347] [D loss: 0.509569] [G loss: 0.350959]\n",
      "[Epoch 43/100] [Batch 251/347] [D loss: 0.486859] [G loss: 0.366780]\n",
      "[Epoch 43/100] [Batch 252/347] [D loss: 0.479049] [G loss: 0.368172]\n",
      "[Epoch 43/100] [Batch 253/347] [D loss: 0.494839] [G loss: 0.366723]\n",
      "[Epoch 43/100] [Batch 254/347] [D loss: 0.512419] [G loss: 0.366407]\n",
      "[Epoch 43/100] [Batch 255/347] [D loss: 0.461015] [G loss: 0.360743]\n",
      "[Epoch 43/100] [Batch 256/347] [D loss: 0.450057] [G loss: 0.364695]\n",
      "[Epoch 43/100] [Batch 257/347] [D loss: 0.462634] [G loss: 0.370817]\n",
      "[Epoch 43/100] [Batch 258/347] [D loss: 0.404800] [G loss: 0.359306]\n",
      "[Epoch 43/100] [Batch 259/347] [D loss: 0.388320] [G loss: 0.345758]\n",
      "[Epoch 43/100] [Batch 260/347] [D loss: 0.352577] [G loss: 0.343803]\n",
      "[Epoch 43/100] [Batch 261/347] [D loss: 0.365132] [G loss: 0.352271]\n",
      "[Epoch 43/100] [Batch 262/347] [D loss: 0.427824] [G loss: 0.348446]\n",
      "[Epoch 43/100] [Batch 263/347] [D loss: 0.390346] [G loss: 0.347897]\n",
      "[Epoch 43/100] [Batch 264/347] [D loss: 0.344391] [G loss: 0.352368]\n",
      "[Epoch 43/100] [Batch 265/347] [D loss: 0.362275] [G loss: 0.352669]\n",
      "[Epoch 43/100] [Batch 266/347] [D loss: 0.383995] [G loss: 0.351638]\n",
      "[Epoch 43/100] [Batch 267/347] [D loss: 0.387892] [G loss: 0.352374]\n",
      "[Epoch 43/100] [Batch 268/347] [D loss: 0.338869] [G loss: 0.360361]\n",
      "[Epoch 43/100] [Batch 269/347] [D loss: 0.340322] [G loss: 0.365268]\n",
      "[Epoch 43/100] [Batch 270/347] [D loss: 0.397538] [G loss: 0.364921]\n",
      "[Epoch 43/100] [Batch 271/347] [D loss: 0.437978] [G loss: 0.363480]\n",
      "[Epoch 43/100] [Batch 272/347] [D loss: 0.471986] [G loss: 0.366722]\n",
      "[Epoch 43/100] [Batch 273/347] [D loss: 0.374130] [G loss: 0.376436]\n",
      "[Epoch 43/100] [Batch 274/347] [D loss: 0.534581] [G loss: 0.401208]\n",
      "[Epoch 43/100] [Batch 275/347] [D loss: 0.496709] [G loss: 0.416974]\n",
      "[Epoch 43/100] [Batch 276/347] [D loss: 0.376976] [G loss: 0.413571]\n",
      "[Epoch 43/100] [Batch 277/347] [D loss: 0.386262] [G loss: 0.419983]\n",
      "[Epoch 43/100] [Batch 278/347] [D loss: 0.502474] [G loss: 0.438826]\n",
      "[Epoch 43/100] [Batch 279/347] [D loss: 0.481437] [G loss: 0.438964]\n",
      "[Epoch 43/100] [Batch 280/347] [D loss: 0.464571] [G loss: 0.445095]\n",
      "[Epoch 43/100] [Batch 281/347] [D loss: 0.466772] [G loss: 0.445570]\n",
      "[Epoch 43/100] [Batch 282/347] [D loss: 0.479318] [G loss: 0.445458]\n",
      "[Epoch 43/100] [Batch 283/347] [D loss: 0.406754] [G loss: 0.444780]\n",
      "[Epoch 43/100] [Batch 284/347] [D loss: 0.394266] [G loss: 0.445325]\n",
      "[Epoch 43/100] [Batch 285/347] [D loss: 0.471184] [G loss: 0.445067]\n",
      "[Epoch 43/100] [Batch 286/347] [D loss: 0.523961] [G loss: 0.442680]\n",
      "[Epoch 43/100] [Batch 287/347] [D loss: 0.526578] [G loss: 0.436095]\n",
      "[Epoch 43/100] [Batch 288/347] [D loss: 0.513616] [G loss: 0.413672]\n",
      "[Epoch 43/100] [Batch 289/347] [D loss: 0.512452] [G loss: 0.405624]\n",
      "[Epoch 43/100] [Batch 290/347] [D loss: 0.528728] [G loss: 0.416824]\n",
      "[Epoch 43/100] [Batch 291/347] [D loss: 0.500204] [G loss: 0.409628]\n",
      "[Epoch 43/100] [Batch 292/347] [D loss: 0.488079] [G loss: 0.412977]\n",
      "[Epoch 43/100] [Batch 293/347] [D loss: 0.433656] [G loss: 0.429634]\n",
      "[Epoch 43/100] [Batch 294/347] [D loss: 0.377660] [G loss: 0.427229]\n",
      "[Epoch 43/100] [Batch 295/347] [D loss: 0.224280] [G loss: 0.411801]\n",
      "[Epoch 43/100] [Batch 296/347] [D loss: 0.213288] [G loss: 0.412809]\n",
      "[Epoch 43/100] [Batch 297/347] [D loss: 0.487281] [G loss: 0.426591]\n",
      "[Epoch 43/100] [Batch 298/347] [D loss: 0.552010] [G loss: 0.419278]\n",
      "[Epoch 43/100] [Batch 299/347] [D loss: 0.506215] [G loss: 0.415634]\n",
      "[Epoch 43/100] [Batch 300/347] [D loss: 0.447725] [G loss: 0.407678]\n",
      "[Epoch 43/100] [Batch 301/347] [D loss: 0.456113] [G loss: 0.399547]\n",
      "[Epoch 43/100] [Batch 302/347] [D loss: 0.508444] [G loss: 0.401831]\n",
      "[Epoch 43/100] [Batch 303/347] [D loss: 0.481820] [G loss: 0.376329]\n",
      "[Epoch 43/100] [Batch 304/347] [D loss: 0.487485] [G loss: 0.356045]\n",
      "[Epoch 43/100] [Batch 305/347] [D loss: 0.507934] [G loss: 0.354365]\n",
      "[Epoch 43/100] [Batch 306/347] [D loss: 0.314636] [G loss: 0.342566]\n",
      "[Epoch 43/100] [Batch 307/347] [D loss: 0.242745] [G loss: 0.346303]\n",
      "[Epoch 43/100] [Batch 308/347] [D loss: 0.319775] [G loss: 0.347666]\n",
      "[Epoch 43/100] [Batch 309/347] [D loss: 0.494364] [G loss: 0.365129]\n",
      "[Epoch 43/100] [Batch 310/347] [D loss: 0.559853] [G loss: 0.393925]\n",
      "[Epoch 43/100] [Batch 311/347] [D loss: 0.561014] [G loss: 0.398845]\n",
      "[Epoch 43/100] [Batch 312/347] [D loss: 0.558637] [G loss: 0.401301]\n",
      "[Epoch 43/100] [Batch 313/347] [D loss: 0.547738] [G loss: 0.403447]\n",
      "[Epoch 43/100] [Batch 314/347] [D loss: 0.498433] [G loss: 0.399192]\n",
      "[Epoch 43/100] [Batch 315/347] [D loss: 0.438040] [G loss: 0.391172]\n",
      "[Epoch 43/100] [Batch 316/347] [D loss: 0.436946] [G loss: 0.375178]\n",
      "[Epoch 43/100] [Batch 317/347] [D loss: 0.496604] [G loss: 0.364589]\n",
      "[Epoch 43/100] [Batch 318/347] [D loss: 0.530862] [G loss: 0.380869]\n",
      "[Epoch 43/100] [Batch 319/347] [D loss: 0.537154] [G loss: 0.413733]\n",
      "[Epoch 43/100] [Batch 320/347] [D loss: 0.534358] [G loss: 0.427485]\n",
      "[Epoch 43/100] [Batch 321/347] [D loss: 0.512946] [G loss: 0.416855]\n",
      "[Epoch 43/100] [Batch 322/347] [D loss: 0.508954] [G loss: 0.403379]\n",
      "[Epoch 43/100] [Batch 323/347] [D loss: 0.472944] [G loss: 0.401312]\n",
      "[Epoch 43/100] [Batch 324/347] [D loss: 0.461788] [G loss: 0.402835]\n",
      "[Epoch 43/100] [Batch 325/347] [D loss: 0.358216] [G loss: 0.391044]\n",
      "[Epoch 43/100] [Batch 326/347] [D loss: 0.331291] [G loss: 0.378743]\n",
      "[Epoch 43/100] [Batch 327/347] [D loss: 0.416482] [G loss: 0.376653]\n",
      "[Epoch 43/100] [Batch 328/347] [D loss: 0.468728] [G loss: 0.374287]\n",
      "[Epoch 43/100] [Batch 329/347] [D loss: 0.371743] [G loss: 0.363014]\n",
      "[Epoch 43/100] [Batch 330/347] [D loss: 0.358857] [G loss: 0.355752]\n",
      "[Epoch 43/100] [Batch 331/347] [D loss: 0.439841] [G loss: 0.363402]\n",
      "[Epoch 43/100] [Batch 332/347] [D loss: 0.533408] [G loss: 0.385002]\n",
      "[Epoch 43/100] [Batch 333/347] [D loss: 0.550279] [G loss: 0.396257]\n",
      "[Epoch 43/100] [Batch 334/347] [D loss: 0.516930] [G loss: 0.397612]\n",
      "[Epoch 43/100] [Batch 335/347] [D loss: 0.483638] [G loss: 0.385387]\n",
      "[Epoch 43/100] [Batch 336/347] [D loss: 0.477732] [G loss: 0.370706]\n",
      "[Epoch 43/100] [Batch 337/347] [D loss: 0.473324] [G loss: 0.376070]\n",
      "[Epoch 43/100] [Batch 338/347] [D loss: 0.501013] [G loss: 0.390400]\n",
      "[Epoch 43/100] [Batch 339/347] [D loss: 0.548333] [G loss: 0.396290]\n",
      "[Epoch 43/100] [Batch 340/347] [D loss: 0.557168] [G loss: 0.397956]\n",
      "[Epoch 43/100] [Batch 341/347] [D loss: 0.531464] [G loss: 0.394754]\n",
      "[Epoch 43/100] [Batch 342/347] [D loss: 0.522394] [G loss: 0.388827]\n",
      "[Epoch 43/100] [Batch 343/347] [D loss: 0.547188] [G loss: 0.395435]\n",
      "[Epoch 43/100] [Batch 344/347] [D loss: 0.445737] [G loss: 0.385888]\n",
      "[Epoch 43/100] [Batch 345/347] [D loss: 0.379033] [G loss: 0.363539]\n",
      "[Epoch 43/100] [Batch 346/347] [D loss: 0.335080] [G loss: 0.365047]\n",
      "[Epoch 43/100] [Batch 347/347] [D loss: 0.242779] [G loss: 0.379571]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 44/100] [Batch 1/347] [D loss: 0.524794] [G loss: 0.395280]\n",
      "[Epoch 44/100] [Batch 2/347] [D loss: 0.534193] [G loss: 0.401922]\n",
      "[Epoch 44/100] [Batch 3/347] [D loss: 0.557741] [G loss: 0.416617]\n",
      "[Epoch 44/100] [Batch 4/347] [D loss: 0.558731] [G loss: 0.422339]\n",
      "[Epoch 44/100] [Batch 5/347] [D loss: 0.556827] [G loss: 0.425348]\n",
      "[Epoch 44/100] [Batch 6/347] [D loss: 0.560910] [G loss: 0.431081]\n",
      "[Epoch 44/100] [Batch 7/347] [D loss: 0.557161] [G loss: 0.430027]\n",
      "[Epoch 44/100] [Batch 8/347] [D loss: 0.542895] [G loss: 0.428400]\n",
      "[Epoch 44/100] [Batch 9/347] [D loss: 0.527392] [G loss: 0.420162]\n",
      "[Epoch 44/100] [Batch 10/347] [D loss: 0.532384] [G loss: 0.422468]\n",
      "[Epoch 44/100] [Batch 11/347] [D loss: 0.553700] [G loss: 0.437983]\n",
      "[Epoch 44/100] [Batch 12/347] [D loss: 0.559407] [G loss: 0.443564]\n",
      "[Epoch 44/100] [Batch 13/347] [D loss: 0.562000] [G loss: 0.448073]\n",
      "[Epoch 44/100] [Batch 14/347] [D loss: 0.559431] [G loss: 0.450836]\n",
      "[Epoch 44/100] [Batch 15/347] [D loss: 0.548715] [G loss: 0.447255]\n",
      "[Epoch 44/100] [Batch 16/347] [D loss: 0.539196] [G loss: 0.443164]\n",
      "[Epoch 44/100] [Batch 17/347] [D loss: 0.524342] [G loss: 0.431059]\n",
      "[Epoch 44/100] [Batch 18/347] [D loss: 0.498074] [G loss: 0.428099]\n",
      "[Epoch 44/100] [Batch 19/347] [D loss: 0.505393] [G loss: 0.434087]\n",
      "[Epoch 44/100] [Batch 20/347] [D loss: 0.553356] [G loss: 0.445973]\n",
      "[Epoch 44/100] [Batch 21/347] [D loss: 0.555795] [G loss: 0.440577]\n",
      "[Epoch 44/100] [Batch 22/347] [D loss: 0.545899] [G loss: 0.434208]\n",
      "[Epoch 44/100] [Batch 23/347] [D loss: 0.516231] [G loss: 0.426062]\n",
      "[Epoch 44/100] [Batch 24/347] [D loss: 0.512818] [G loss: 0.423082]\n",
      "[Epoch 44/100] [Batch 25/347] [D loss: 0.533830] [G loss: 0.420626]\n",
      "[Epoch 44/100] [Batch 26/347] [D loss: 0.464141] [G loss: 0.406899]\n",
      "[Epoch 44/100] [Batch 27/347] [D loss: 0.250883] [G loss: 0.420374]\n",
      "[Epoch 44/100] [Batch 28/347] [D loss: 0.261964] [G loss: 0.426333]\n",
      "[Epoch 44/100] [Batch 29/347] [D loss: 0.506893] [G loss: 0.421211]\n",
      "[Epoch 44/100] [Batch 30/347] [D loss: 0.453763] [G loss: 0.424473]\n",
      "[Epoch 44/100] [Batch 31/347] [D loss: 0.386494] [G loss: 0.422336]\n",
      "[Epoch 44/100] [Batch 32/347] [D loss: 0.304474] [G loss: 0.410425]\n",
      "[Epoch 44/100] [Batch 33/347] [D loss: 0.324251] [G loss: 0.401196]\n",
      "[Epoch 44/100] [Batch 34/347] [D loss: 0.417300] [G loss: 0.396462]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 44/100] [Batch 35/347] [D loss: 0.398062] [G loss: 0.388792]\n",
      "[Epoch 44/100] [Batch 36/347] [D loss: 0.475864] [G loss: 0.373279]\n",
      "[Epoch 44/100] [Batch 37/347] [D loss: 0.418258] [G loss: 0.359020]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 44/100] [Batch 38/347] [D loss: 0.369746] [G loss: 0.340441]\n",
      "[Epoch 44/100] [Batch 39/347] [D loss: 0.421073] [G loss: 0.330611]\n",
      "[Epoch 44/100] [Batch 40/347] [D loss: 0.517121] [G loss: 0.326395]\n",
      "[Epoch 44/100] [Batch 41/347] [D loss: 0.524695] [G loss: 0.319662]\n",
      "[Epoch 44/100] [Batch 42/347] [D loss: 0.521261] [G loss: 0.319780]\n",
      "[Epoch 44/100] [Batch 43/347] [D loss: 0.501849] [G loss: 0.330963]\n",
      "[Epoch 44/100] [Batch 44/347] [D loss: 0.498474] [G loss: 0.345717]\n",
      "[Epoch 44/100] [Batch 45/347] [D loss: 0.526988] [G loss: 0.361683]\n",
      "[Epoch 44/100] [Batch 46/347] [D loss: 0.525553] [G loss: 0.356483]\n",
      "[Epoch 44/100] [Batch 47/347] [D loss: 0.508334] [G loss: 0.332567]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 44/100] [Batch 48/347] [D loss: 0.349389] [G loss: 0.325302]\n",
      "[Epoch 44/100] [Batch 49/347] [D loss: 0.349857] [G loss: 0.329709]\n",
      "[Epoch 44/100] [Batch 50/347] [D loss: 0.286517] [G loss: 0.345333]\n",
      "[Epoch 44/100] [Batch 51/347] [D loss: 0.269478] [G loss: 0.365017]\n",
      "[Epoch 44/100] [Batch 52/347] [D loss: 0.377396] [G loss: 0.370234]\n",
      "[Epoch 44/100] [Batch 53/347] [D loss: 0.476255] [G loss: 0.369958]\n",
      "[Epoch 44/100] [Batch 54/347] [D loss: 0.415658] [G loss: 0.359651]\n",
      "[Epoch 44/100] [Batch 55/347] [D loss: 0.406582] [G loss: 0.336358]\n",
      "[Epoch 44/100] [Batch 56/347] [D loss: 0.402221] [G loss: 0.340978]\n",
      "[Epoch 44/100] [Batch 57/347] [D loss: 0.399160] [G loss: 0.371765]\n",
      "[Epoch 44/100] [Batch 58/347] [D loss: 0.416933] [G loss: 0.383045]\n",
      "[Epoch 44/100] [Batch 59/347] [D loss: 0.389498] [G loss: 0.382112]\n",
      "[Epoch 44/100] [Batch 60/347] [D loss: 0.365523] [G loss: 0.378117]\n",
      "[Epoch 44/100] [Batch 61/347] [D loss: 0.331655] [G loss: 0.375201]\n",
      "[Epoch 44/100] [Batch 62/347] [D loss: 0.348392] [G loss: 0.359707]\n",
      "[Epoch 44/100] [Batch 63/347] [D loss: 0.392857] [G loss: 0.336739]\n",
      "[Epoch 44/100] [Batch 64/347] [D loss: 0.420336] [G loss: 0.356461]\n",
      "[Epoch 44/100] [Batch 65/347] [D loss: 0.492868] [G loss: 0.376967]\n",
      "[Epoch 44/100] [Batch 66/347] [D loss: 0.406246] [G loss: 0.373558]\n",
      "[Epoch 44/100] [Batch 67/347] [D loss: 0.231785] [G loss: 0.367664]\n",
      "[Epoch 44/100] [Batch 68/347] [D loss: 0.259982] [G loss: 0.364516]\n",
      "[Epoch 44/100] [Batch 69/347] [D loss: 0.387684] [G loss: 0.348359]\n",
      "[Epoch 44/100] [Batch 70/347] [D loss: 0.390686] [G loss: 0.339367]\n",
      "[Epoch 44/100] [Batch 71/347] [D loss: 0.373623] [G loss: 0.351314]\n",
      "[Epoch 44/100] [Batch 72/347] [D loss: 0.369177] [G loss: 0.350403]\n",
      "[Epoch 44/100] [Batch 73/347] [D loss: 0.370863] [G loss: 0.357067]\n",
      "[Epoch 44/100] [Batch 74/347] [D loss: 0.371852] [G loss: 0.375744]\n",
      "[Epoch 44/100] [Batch 75/347] [D loss: 0.396905] [G loss: 0.366186]\n",
      "[Epoch 44/100] [Batch 76/347] [D loss: 0.424728] [G loss: 0.344152]\n",
      "[Epoch 44/100] [Batch 77/347] [D loss: 0.413870] [G loss: 0.354586]\n",
      "[Epoch 44/100] [Batch 78/347] [D loss: 0.409911] [G loss: 0.372663]\n",
      "[Epoch 44/100] [Batch 79/347] [D loss: 0.505572] [G loss: 0.381068]\n",
      "[Epoch 44/100] [Batch 80/347] [D loss: 0.539570] [G loss: 0.375793]\n",
      "[Epoch 44/100] [Batch 81/347] [D loss: 0.523121] [G loss: 0.378540]\n",
      "[Epoch 44/100] [Batch 82/347] [D loss: 0.430545] [G loss: 0.369634]\n",
      "[Epoch 44/100] [Batch 83/347] [D loss: 0.414008] [G loss: 0.365892]\n",
      "[Epoch 44/100] [Batch 84/347] [D loss: 0.490038] [G loss: 0.375702]\n",
      "[Epoch 44/100] [Batch 85/347] [D loss: 0.556605] [G loss: 0.375814]\n",
      "[Epoch 44/100] [Batch 86/347] [D loss: 0.553340] [G loss: 0.370695]\n",
      "[Epoch 44/100] [Batch 87/347] [D loss: 0.552311] [G loss: 0.369844]\n",
      "[Epoch 44/100] [Batch 88/347] [D loss: 0.557842] [G loss: 0.375128]\n",
      "[Epoch 44/100] [Batch 89/347] [D loss: 0.565451] [G loss: 0.381129]\n",
      "[Epoch 44/100] [Batch 90/347] [D loss: 0.561784] [G loss: 0.380883]\n",
      "[Epoch 44/100] [Batch 91/347] [D loss: 0.560588] [G loss: 0.383430]\n",
      "[Epoch 44/100] [Batch 92/347] [D loss: 0.563002] [G loss: 0.389380]\n",
      "[Epoch 44/100] [Batch 93/347] [D loss: 0.561527] [G loss: 0.392248]\n",
      "[Epoch 44/100] [Batch 94/347] [D loss: 0.554587] [G loss: 0.393901]\n",
      "[Epoch 44/100] [Batch 95/347] [D loss: 0.554289] [G loss: 0.399657]\n",
      "[Epoch 44/100] [Batch 96/347] [D loss: 0.550690] [G loss: 0.399889]\n",
      "[Epoch 44/100] [Batch 97/347] [D loss: 0.547050] [G loss: 0.400106]\n",
      "[Epoch 44/100] [Batch 98/347] [D loss: 0.554020] [G loss: 0.409903]\n",
      "[Epoch 44/100] [Batch 99/347] [D loss: 0.555995] [G loss: 0.418493]\n",
      "[Epoch 44/100] [Batch 100/347] [D loss: 0.536766] [G loss: 0.419254]\n",
      "[Epoch 44/100] [Batch 101/347] [D loss: 0.537331] [G loss: 0.418194]\n",
      "[Epoch 44/100] [Batch 102/347] [D loss: 0.554401] [G loss: 0.423747]\n",
      "[Epoch 44/100] [Batch 103/347] [D loss: 0.554013] [G loss: 0.427745]\n",
      "[Epoch 44/100] [Batch 104/347] [D loss: 0.549597] [G loss: 0.422225]\n",
      "[Epoch 44/100] [Batch 105/347] [D loss: 0.550444] [G loss: 0.424315]\n",
      "[Epoch 44/100] [Batch 106/347] [D loss: 0.539445] [G loss: 0.425708]\n",
      "[Epoch 44/100] [Batch 107/347] [D loss: 0.469558] [G loss: 0.416471]\n",
      "[Epoch 44/100] [Batch 108/347] [D loss: 0.202275] [G loss: 0.427722]\n",
      "[Epoch 44/100] [Batch 109/347] [D loss: 0.202121] [G loss: 0.435586]\n",
      "[Epoch 44/100] [Batch 110/347] [D loss: 0.434599] [G loss: 0.435005]\n",
      "[Epoch 44/100] [Batch 111/347] [D loss: 0.259036] [G loss: 0.433218]\n",
      "[Epoch 44/100] [Batch 112/347] [D loss: 0.200796] [G loss: 0.440467]\n",
      "[Epoch 44/100] [Batch 113/347] [D loss: 0.430805] [G loss: 0.455171]\n",
      "[Epoch 44/100] [Batch 114/347] [D loss: 0.496196] [G loss: 0.476748]\n",
      "[Epoch 44/100] [Batch 115/347] [D loss: 0.478480] [G loss: 0.477774]\n",
      "[Epoch 44/100] [Batch 116/347] [D loss: 0.504017] [G loss: 0.471289]\n",
      "[Epoch 44/100] [Batch 117/347] [D loss: 0.491553] [G loss: 0.443239]\n",
      "[Epoch 44/100] [Batch 118/347] [D loss: 0.413187] [G loss: 0.424021]\n",
      "[Epoch 44/100] [Batch 119/347] [D loss: 0.360771] [G loss: 0.414678]\n",
      "[Epoch 44/100] [Batch 120/347] [D loss: 0.297507] [G loss: 0.415422]\n",
      "[Epoch 44/100] [Batch 121/347] [D loss: 0.283386] [G loss: 0.411105]\n",
      "[Epoch 44/100] [Batch 122/347] [D loss: 0.442887] [G loss: 0.412687]\n",
      "[Epoch 44/100] [Batch 123/347] [D loss: 0.530864] [G loss: 0.410987]\n",
      "[Epoch 44/100] [Batch 124/347] [D loss: 0.530586] [G loss: 0.401784]\n",
      "[Epoch 44/100] [Batch 125/347] [D loss: 0.533516] [G loss: 0.408692]\n",
      "[Epoch 44/100] [Batch 126/347] [D loss: 0.503196] [G loss: 0.416366]\n",
      "[Epoch 44/100] [Batch 127/347] [D loss: 0.486846] [G loss: 0.412656]\n",
      "[Epoch 44/100] [Batch 128/347] [D loss: 0.484948] [G loss: 0.401843]\n",
      "[Epoch 44/100] [Batch 129/347] [D loss: 0.389448] [G loss: 0.391170]\n",
      "[Epoch 44/100] [Batch 130/347] [D loss: 0.374657] [G loss: 0.382577]\n",
      "[Epoch 44/100] [Batch 131/347] [D loss: 0.325725] [G loss: 0.377233]\n",
      "[Epoch 44/100] [Batch 132/347] [D loss: 0.244504] [G loss: 0.378426]\n",
      "[Epoch 44/100] [Batch 133/347] [D loss: 0.244368] [G loss: 0.379603]\n",
      "[Epoch 44/100] [Batch 134/347] [D loss: 0.238376] [G loss: 0.386847]\n",
      "[Epoch 44/100] [Batch 135/347] [D loss: 0.247723] [G loss: 0.404981]\n",
      "[Epoch 44/100] [Batch 136/347] [D loss: 0.237201] [G loss: 0.422084]\n",
      "[Epoch 44/100] [Batch 137/347] [D loss: 0.447356] [G loss: 0.422431]\n",
      "[Epoch 44/100] [Batch 138/347] [D loss: 0.434579] [G loss: 0.419528]\n",
      "[Epoch 44/100] [Batch 139/347] [D loss: 0.413598] [G loss: 0.410928]\n",
      "[Epoch 44/100] [Batch 140/347] [D loss: 0.383053] [G loss: 0.412436]\n",
      "[Epoch 44/100] [Batch 141/347] [D loss: 0.389495] [G loss: 0.407596]\n",
      "[Epoch 44/100] [Batch 142/347] [D loss: 0.399238] [G loss: 0.405311]\n",
      "[Epoch 44/100] [Batch 143/347] [D loss: 0.352175] [G loss: 0.397124]\n",
      "[Epoch 44/100] [Batch 144/347] [D loss: 0.340136] [G loss: 0.384147]\n",
      "[Epoch 44/100] [Batch 145/347] [D loss: 0.335101] [G loss: 0.371562]\n",
      "[Epoch 44/100] [Batch 146/347] [D loss: 0.331650] [G loss: 0.359991]\n",
      "[Epoch 44/100] [Batch 147/347] [D loss: 0.372019] [G loss: 0.364647]\n",
      "[Epoch 44/100] [Batch 148/347] [D loss: 0.381247] [G loss: 0.363387]\n",
      "[Epoch 44/100] [Batch 149/347] [D loss: 0.409698] [G loss: 0.351518]\n",
      "[Epoch 44/100] [Batch 150/347] [D loss: 0.425472] [G loss: 0.347081]\n",
      "[Epoch 44/100] [Batch 151/347] [D loss: 0.406835] [G loss: 0.350321]\n",
      "[Epoch 44/100] [Batch 152/347] [D loss: 0.351295] [G loss: 0.345890]\n",
      "[Epoch 44/100] [Batch 153/347] [D loss: 0.311925] [G loss: 0.325603]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 44/100] [Batch 154/347] [D loss: 0.308291] [G loss: 0.303455]\n",
      "[Epoch 44/100] [Batch 155/347] [D loss: 0.324672] [G loss: 0.298313]\n",
      "[Epoch 44/100] [Batch 156/347] [D loss: 0.370174] [G loss: 0.305258]\n",
      "[Epoch 44/100] [Batch 157/347] [D loss: 0.353804] [G loss: 0.314584]\n",
      "[Epoch 44/100] [Batch 158/347] [D loss: 0.319182] [G loss: 0.301968]\n",
      "[Epoch 44/100] [Batch 159/347] [D loss: 0.309255] [G loss: 0.289941]\n",
      "[Epoch 44/100] [Batch 160/347] [D loss: 0.266556] [G loss: 0.311480]\n",
      "[Epoch 44/100] [Batch 161/347] [D loss: 0.261313] [G loss: 0.330926]\n",
      "[Epoch 44/100] [Batch 162/347] [D loss: 0.322313] [G loss: 0.334403]\n",
      "[Epoch 44/100] [Batch 163/347] [D loss: 0.333881] [G loss: 0.329334]\n",
      "[Epoch 44/100] [Batch 164/347] [D loss: 0.308327] [G loss: 0.324923]\n",
      "[Epoch 44/100] [Batch 165/347] [D loss: 0.287296] [G loss: 0.321084]\n",
      "[Epoch 44/100] [Batch 166/347] [D loss: 0.294787] [G loss: 0.335735]\n",
      "[Epoch 44/100] [Batch 167/347] [D loss: 0.268590] [G loss: 0.360803]\n",
      "[Epoch 44/100] [Batch 168/347] [D loss: 0.227732] [G loss: 0.376751]\n",
      "[Epoch 44/100] [Batch 169/347] [D loss: 0.367359] [G loss: 0.389152]\n",
      "[Epoch 44/100] [Batch 170/347] [D loss: 0.447057] [G loss: 0.403734]\n",
      "[Epoch 44/100] [Batch 171/347] [D loss: 0.506755] [G loss: 0.417752]\n",
      "[Epoch 44/100] [Batch 172/347] [D loss: 0.521936] [G loss: 0.424546]\n",
      "[Epoch 44/100] [Batch 173/347] [D loss: 0.409152] [G loss: 0.413835]\n",
      "[Epoch 44/100] [Batch 174/347] [D loss: 0.409402] [G loss: 0.410362]\n",
      "[Epoch 44/100] [Batch 175/347] [D loss: 0.527531] [G loss: 0.419474]\n",
      "[Epoch 44/100] [Batch 176/347] [D loss: 0.552333] [G loss: 0.432305]\n",
      "[Epoch 44/100] [Batch 177/347] [D loss: 0.555738] [G loss: 0.432498]\n",
      "[Epoch 44/100] [Batch 178/347] [D loss: 0.548410] [G loss: 0.426004]\n",
      "[Epoch 44/100] [Batch 179/347] [D loss: 0.541722] [G loss: 0.418707]\n",
      "[Epoch 44/100] [Batch 180/347] [D loss: 0.537524] [G loss: 0.411726]\n",
      "[Epoch 44/100] [Batch 181/347] [D loss: 0.538179] [G loss: 0.411785]\n",
      "[Epoch 44/100] [Batch 182/347] [D loss: 0.537282] [G loss: 0.409240]\n",
      "[Epoch 44/100] [Batch 183/347] [D loss: 0.536962] [G loss: 0.412817]\n",
      "[Epoch 44/100] [Batch 184/347] [D loss: 0.541858] [G loss: 0.416327]\n",
      "[Epoch 44/100] [Batch 185/347] [D loss: 0.545312] [G loss: 0.414397]\n",
      "[Epoch 44/100] [Batch 186/347] [D loss: 0.546025] [G loss: 0.414148]\n",
      "[Epoch 44/100] [Batch 187/347] [D loss: 0.542886] [G loss: 0.408800]\n",
      "[Epoch 44/100] [Batch 188/347] [D loss: 0.541405] [G loss: 0.405490]\n",
      "[Epoch 44/100] [Batch 189/347] [D loss: 0.537494] [G loss: 0.404649]\n",
      "[Epoch 44/100] [Batch 190/347] [D loss: 0.518269] [G loss: 0.392577]\n",
      "[Epoch 44/100] [Batch 191/347] [D loss: 0.480502] [G loss: 0.378740]\n",
      "[Epoch 44/100] [Batch 192/347] [D loss: 0.467794] [G loss: 0.378557]\n",
      "[Epoch 44/100] [Batch 193/347] [D loss: 0.485443] [G loss: 0.384145]\n",
      "[Epoch 44/100] [Batch 194/347] [D loss: 0.520673] [G loss: 0.377119]\n",
      "[Epoch 44/100] [Batch 195/347] [D loss: 0.535407] [G loss: 0.367153]\n",
      "[Epoch 44/100] [Batch 196/347] [D loss: 0.524187] [G loss: 0.360201]\n",
      "[Epoch 44/100] [Batch 197/347] [D loss: 0.477741] [G loss: 0.356154]\n",
      "[Epoch 44/100] [Batch 198/347] [D loss: 0.375966] [G loss: 0.352326]\n",
      "[Epoch 44/100] [Batch 199/347] [D loss: 0.385543] [G loss: 0.347519]\n",
      "[Epoch 44/100] [Batch 200/347] [D loss: 0.493059] [G loss: 0.349048]\n",
      "[Epoch 44/100] [Batch 201/347] [D loss: 0.494311] [G loss: 0.347631]\n",
      "[Epoch 44/100] [Batch 202/347] [D loss: 0.508056] [G loss: 0.340306]\n",
      "[Epoch 44/100] [Batch 203/347] [D loss: 0.540251] [G loss: 0.334773]\n",
      "[Epoch 44/100] [Batch 204/347] [D loss: 0.541081] [G loss: 0.333792]\n",
      "[Epoch 44/100] [Batch 205/347] [D loss: 0.536917] [G loss: 0.333794]\n",
      "[Epoch 44/100] [Batch 206/347] [D loss: 0.528811] [G loss: 0.337556]\n",
      "[Epoch 44/100] [Batch 207/347] [D loss: 0.523320] [G loss: 0.347325]\n",
      "[Epoch 44/100] [Batch 208/347] [D loss: 0.528922] [G loss: 0.347511]\n",
      "[Epoch 44/100] [Batch 209/347] [D loss: 0.500516] [G loss: 0.341339]\n",
      "[Epoch 44/100] [Batch 210/347] [D loss: 0.487722] [G loss: 0.347347]\n",
      "[Epoch 44/100] [Batch 211/347] [D loss: 0.512294] [G loss: 0.345656]\n",
      "[Epoch 44/100] [Batch 212/347] [D loss: 0.311143] [G loss: 0.341128]\n",
      "[Epoch 44/100] [Batch 213/347] [D loss: 0.299122] [G loss: 0.340837]\n",
      "[Epoch 44/100] [Batch 214/347] [D loss: 0.254189] [G loss: 0.355805]\n",
      "[Epoch 44/100] [Batch 215/347] [D loss: 0.244959] [G loss: 0.367099]\n",
      "[Epoch 44/100] [Batch 216/347] [D loss: 0.369035] [G loss: 0.371876]\n",
      "[Epoch 44/100] [Batch 217/347] [D loss: 0.465051] [G loss: 0.387697]\n",
      "[Epoch 44/100] [Batch 218/347] [D loss: 0.541073] [G loss: 0.411219]\n",
      "[Epoch 44/100] [Batch 219/347] [D loss: 0.503700] [G loss: 0.430221]\n",
      "[Epoch 44/100] [Batch 220/347] [D loss: 0.501296] [G loss: 0.451455]\n",
      "[Epoch 44/100] [Batch 221/347] [D loss: 0.521912] [G loss: 0.457289]\n",
      "[Epoch 44/100] [Batch 222/347] [D loss: 0.514234] [G loss: 0.452903]\n",
      "[Epoch 44/100] [Batch 223/347] [D loss: 0.517920] [G loss: 0.454308]\n",
      "[Epoch 44/100] [Batch 224/347] [D loss: 0.523741] [G loss: 0.452500]\n",
      "[Epoch 44/100] [Batch 225/347] [D loss: 0.504268] [G loss: 0.428309]\n",
      "[Epoch 44/100] [Batch 226/347] [D loss: 0.505573] [G loss: 0.405645]\n",
      "[Epoch 44/100] [Batch 227/347] [D loss: 0.517279] [G loss: 0.384695]\n",
      "[Epoch 44/100] [Batch 228/347] [D loss: 0.523616] [G loss: 0.390344]\n",
      "[Epoch 44/100] [Batch 229/347] [D loss: 0.537094] [G loss: 0.400912]\n",
      "[Epoch 44/100] [Batch 230/347] [D loss: 0.541183] [G loss: 0.403436]\n",
      "[Epoch 44/100] [Batch 231/347] [D loss: 0.536163] [G loss: 0.395994]\n",
      "[Epoch 44/100] [Batch 232/347] [D loss: 0.535958] [G loss: 0.396758]\n",
      "[Epoch 44/100] [Batch 233/347] [D loss: 0.516537] [G loss: 0.391898]\n",
      "[Epoch 44/100] [Batch 234/347] [D loss: 0.476738] [G loss: 0.391956]\n",
      "[Epoch 44/100] [Batch 235/347] [D loss: 0.466965] [G loss: 0.397364]\n",
      "[Epoch 44/100] [Batch 236/347] [D loss: 0.476296] [G loss: 0.399942]\n",
      "[Epoch 44/100] [Batch 237/347] [D loss: 0.498727] [G loss: 0.406653]\n",
      "[Epoch 44/100] [Batch 238/347] [D loss: 0.538751] [G loss: 0.405235]\n",
      "[Epoch 44/100] [Batch 239/347] [D loss: 0.523986] [G loss: 0.398089]\n",
      "[Epoch 44/100] [Batch 240/347] [D loss: 0.516049] [G loss: 0.389514]\n",
      "[Epoch 44/100] [Batch 241/347] [D loss: 0.517148] [G loss: 0.379436]\n",
      "[Epoch 44/100] [Batch 242/347] [D loss: 0.524343] [G loss: 0.373875]\n",
      "[Epoch 44/100] [Batch 243/347] [D loss: 0.538796] [G loss: 0.378682]\n",
      "[Epoch 44/100] [Batch 244/347] [D loss: 0.540923] [G loss: 0.385473]\n",
      "[Epoch 44/100] [Batch 245/347] [D loss: 0.482512] [G loss: 0.381999]\n",
      "[Epoch 44/100] [Batch 246/347] [D loss: 0.449701] [G loss: 0.363461]\n",
      "[Epoch 44/100] [Batch 247/347] [D loss: 0.490258] [G loss: 0.336626]\n",
      "[Epoch 44/100] [Batch 248/347] [D loss: 0.529740] [G loss: 0.330111]\n",
      "[Epoch 44/100] [Batch 249/347] [D loss: 0.522792] [G loss: 0.322662]\n",
      "[Epoch 44/100] [Batch 250/347] [D loss: 0.504453] [G loss: 0.341213]\n",
      "[Epoch 44/100] [Batch 251/347] [D loss: 0.477208] [G loss: 0.357633]\n",
      "[Epoch 44/100] [Batch 252/347] [D loss: 0.468692] [G loss: 0.359543]\n",
      "[Epoch 44/100] [Batch 253/347] [D loss: 0.485497] [G loss: 0.359170]\n",
      "[Epoch 44/100] [Batch 254/347] [D loss: 0.506787] [G loss: 0.361639]\n",
      "[Epoch 44/100] [Batch 255/347] [D loss: 0.450868] [G loss: 0.354938]\n",
      "[Epoch 44/100] [Batch 256/347] [D loss: 0.439974] [G loss: 0.359947]\n",
      "[Epoch 44/100] [Batch 257/347] [D loss: 0.450904] [G loss: 0.369538]\n",
      "[Epoch 44/100] [Batch 258/347] [D loss: 0.392633] [G loss: 0.358207]\n",
      "[Epoch 44/100] [Batch 259/347] [D loss: 0.377607] [G loss: 0.347156]\n",
      "[Epoch 44/100] [Batch 260/347] [D loss: 0.343666] [G loss: 0.347521]\n",
      "[Epoch 44/100] [Batch 261/347] [D loss: 0.356362] [G loss: 0.358415]\n",
      "[Epoch 44/100] [Batch 262/347] [D loss: 0.418690] [G loss: 0.356920]\n",
      "[Epoch 44/100] [Batch 263/347] [D loss: 0.381321] [G loss: 0.358093]\n",
      "[Epoch 44/100] [Batch 264/347] [D loss: 0.335297] [G loss: 0.363677]\n",
      "[Epoch 44/100] [Batch 265/347] [D loss: 0.355155] [G loss: 0.364672]\n",
      "[Epoch 44/100] [Batch 266/347] [D loss: 0.378060] [G loss: 0.364457]\n",
      "[Epoch 44/100] [Batch 267/347] [D loss: 0.381853] [G loss: 0.365432]\n",
      "[Epoch 44/100] [Batch 268/347] [D loss: 0.332158] [G loss: 0.372938]\n",
      "[Epoch 44/100] [Batch 269/347] [D loss: 0.334876] [G loss: 0.377553]\n",
      "[Epoch 44/100] [Batch 270/347] [D loss: 0.395364] [G loss: 0.376847]\n",
      "[Epoch 44/100] [Batch 271/347] [D loss: 0.437226] [G loss: 0.375025]\n",
      "[Epoch 44/100] [Batch 272/347] [D loss: 0.473022] [G loss: 0.377735]\n",
      "[Epoch 44/100] [Batch 273/347] [D loss: 0.369021] [G loss: 0.386946]\n",
      "[Epoch 44/100] [Batch 274/347] [D loss: 0.545055] [G loss: 0.410091]\n",
      "[Epoch 44/100] [Batch 275/347] [D loss: 0.512388] [G loss: 0.424177]\n",
      "[Epoch 44/100] [Batch 276/347] [D loss: 0.373961] [G loss: 0.419560]\n",
      "[Epoch 44/100] [Batch 277/347] [D loss: 0.380411] [G loss: 0.425815]\n",
      "[Epoch 44/100] [Batch 278/347] [D loss: 0.503013] [G loss: 0.446450]\n",
      "[Epoch 44/100] [Batch 279/347] [D loss: 0.480201] [G loss: 0.446326]\n",
      "[Epoch 44/100] [Batch 280/347] [D loss: 0.461735] [G loss: 0.450144]\n",
      "[Epoch 44/100] [Batch 281/347] [D loss: 0.463869] [G loss: 0.450570]\n",
      "[Epoch 44/100] [Batch 282/347] [D loss: 0.476606] [G loss: 0.452307]\n",
      "[Epoch 44/100] [Batch 283/347] [D loss: 0.397995] [G loss: 0.449708]\n",
      "[Epoch 44/100] [Batch 284/347] [D loss: 0.385360] [G loss: 0.450237]\n",
      "[Epoch 44/100] [Batch 285/347] [D loss: 0.468945] [G loss: 0.452055]\n",
      "[Epoch 44/100] [Batch 286/347] [D loss: 0.527240] [G loss: 0.449655]\n",
      "[Epoch 44/100] [Batch 287/347] [D loss: 0.530501] [G loss: 0.443374]\n",
      "[Epoch 44/100] [Batch 288/347] [D loss: 0.518165] [G loss: 0.419492]\n",
      "[Epoch 44/100] [Batch 289/347] [D loss: 0.517440] [G loss: 0.411715]\n",
      "[Epoch 44/100] [Batch 290/347] [D loss: 0.534656] [G loss: 0.424879]\n",
      "[Epoch 44/100] [Batch 291/347] [D loss: 0.503367] [G loss: 0.418207]\n",
      "[Epoch 44/100] [Batch 292/347] [D loss: 0.490002] [G loss: 0.421601]\n",
      "[Epoch 44/100] [Batch 293/347] [D loss: 0.432279] [G loss: 0.438562]\n",
      "[Epoch 44/100] [Batch 294/347] [D loss: 0.374823] [G loss: 0.436794]\n",
      "[Epoch 44/100] [Batch 295/347] [D loss: 0.225402] [G loss: 0.420541]\n",
      "[Epoch 44/100] [Batch 296/347] [D loss: 0.214745] [G loss: 0.424352]\n",
      "[Epoch 44/100] [Batch 297/347] [D loss: 0.495481] [G loss: 0.439220]\n",
      "[Epoch 44/100] [Batch 298/347] [D loss: 0.562580] [G loss: 0.433038]\n",
      "[Epoch 44/100] [Batch 299/347] [D loss: 0.513355] [G loss: 0.430709]\n",
      "[Epoch 44/100] [Batch 300/347] [D loss: 0.453580] [G loss: 0.424259]\n",
      "[Epoch 44/100] [Batch 301/347] [D loss: 0.463455] [G loss: 0.417406]\n",
      "[Epoch 44/100] [Batch 302/347] [D loss: 0.519996] [G loss: 0.420945]\n",
      "[Epoch 44/100] [Batch 303/347] [D loss: 0.492243] [G loss: 0.394795]\n",
      "[Epoch 44/100] [Batch 304/347] [D loss: 0.498180] [G loss: 0.377522]\n",
      "[Epoch 44/100] [Batch 305/347] [D loss: 0.520437] [G loss: 0.377031]\n",
      "[Epoch 44/100] [Batch 306/347] [D loss: 0.315370] [G loss: 0.365902]\n",
      "[Epoch 44/100] [Batch 307/347] [D loss: 0.238750] [G loss: 0.368213]\n",
      "[Epoch 44/100] [Batch 308/347] [D loss: 0.321427] [G loss: 0.369403]\n",
      "[Epoch 44/100] [Batch 309/347] [D loss: 0.504786] [G loss: 0.388897]\n",
      "[Epoch 44/100] [Batch 310/347] [D loss: 0.571711] [G loss: 0.417947]\n",
      "[Epoch 44/100] [Batch 311/347] [D loss: 0.572694] [G loss: 0.423196]\n",
      "[Epoch 44/100] [Batch 312/347] [D loss: 0.570124] [G loss: 0.425829]\n",
      "[Epoch 44/100] [Batch 313/347] [D loss: 0.559186] [G loss: 0.428515]\n",
      "[Epoch 44/100] [Batch 314/347] [D loss: 0.510007] [G loss: 0.424552]\n",
      "[Epoch 44/100] [Batch 315/347] [D loss: 0.449831] [G loss: 0.416844]\n",
      "[Epoch 44/100] [Batch 316/347] [D loss: 0.448431] [G loss: 0.401001]\n",
      "[Epoch 44/100] [Batch 317/347] [D loss: 0.508988] [G loss: 0.390585]\n",
      "[Epoch 44/100] [Batch 318/347] [D loss: 0.543687] [G loss: 0.406990]\n",
      "[Epoch 44/100] [Batch 319/347] [D loss: 0.547731] [G loss: 0.440375]\n",
      "[Epoch 44/100] [Batch 320/347] [D loss: 0.543044] [G loss: 0.454467]\n",
      "[Epoch 44/100] [Batch 321/347] [D loss: 0.522667] [G loss: 0.444345]\n",
      "[Epoch 44/100] [Batch 322/347] [D loss: 0.520182] [G loss: 0.431270]\n",
      "[Epoch 44/100] [Batch 323/347] [D loss: 0.484117] [G loss: 0.429720]\n",
      "[Epoch 44/100] [Batch 324/347] [D loss: 0.472823] [G loss: 0.431778]\n",
      "[Epoch 44/100] [Batch 325/347] [D loss: 0.364775] [G loss: 0.419753]\n",
      "[Epoch 44/100] [Batch 326/347] [D loss: 0.336590] [G loss: 0.406964]\n",
      "[Epoch 44/100] [Batch 327/347] [D loss: 0.426641] [G loss: 0.404232]\n",
      "[Epoch 44/100] [Batch 328/347] [D loss: 0.480529] [G loss: 0.401453]\n",
      "[Epoch 44/100] [Batch 329/347] [D loss: 0.379295] [G loss: 0.386666]\n",
      "[Epoch 44/100] [Batch 330/347] [D loss: 0.365659] [G loss: 0.378524]\n",
      "[Epoch 44/100] [Batch 331/347] [D loss: 0.450724] [G loss: 0.385093]\n",
      "[Epoch 44/100] [Batch 332/347] [D loss: 0.544100] [G loss: 0.408364]\n",
      "[Epoch 44/100] [Batch 333/347] [D loss: 0.559733] [G loss: 0.419039]\n",
      "[Epoch 44/100] [Batch 334/347] [D loss: 0.525934] [G loss: 0.420123]\n",
      "[Epoch 44/100] [Batch 335/347] [D loss: 0.493684] [G loss: 0.407596]\n",
      "[Epoch 44/100] [Batch 336/347] [D loss: 0.488649] [G loss: 0.392285]\n",
      "[Epoch 44/100] [Batch 337/347] [D loss: 0.483319] [G loss: 0.397479]\n",
      "[Epoch 44/100] [Batch 338/347] [D loss: 0.510131] [G loss: 0.411682]\n",
      "[Epoch 44/100] [Batch 339/347] [D loss: 0.557887] [G loss: 0.417463]\n",
      "[Epoch 44/100] [Batch 340/347] [D loss: 0.566720] [G loss: 0.419234]\n",
      "[Epoch 44/100] [Batch 341/347] [D loss: 0.541713] [G loss: 0.416308]\n",
      "[Epoch 44/100] [Batch 342/347] [D loss: 0.533362] [G loss: 0.410774]\n",
      "[Epoch 44/100] [Batch 343/347] [D loss: 0.556239] [G loss: 0.418139]\n",
      "[Epoch 44/100] [Batch 344/347] [D loss: 0.453724] [G loss: 0.408904]\n",
      "[Epoch 44/100] [Batch 345/347] [D loss: 0.386841] [G loss: 0.384072]\n",
      "[Epoch 44/100] [Batch 346/347] [D loss: 0.339018] [G loss: 0.385522]\n",
      "[Epoch 44/100] [Batch 347/347] [D loss: 0.236023] [G loss: 0.399485]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 45/100] [Batch 1/347] [D loss: 0.533733] [G loss: 0.416665]\n",
      "[Epoch 45/100] [Batch 2/347] [D loss: 0.542631] [G loss: 0.423237]\n",
      "[Epoch 45/100] [Batch 3/347] [D loss: 0.565480] [G loss: 0.438058]\n",
      "[Epoch 45/100] [Batch 4/347] [D loss: 0.566371] [G loss: 0.443471]\n",
      "[Epoch 45/100] [Batch 5/347] [D loss: 0.564246] [G loss: 0.446807]\n",
      "[Epoch 45/100] [Batch 6/347] [D loss: 0.568133] [G loss: 0.452612]\n",
      "[Epoch 45/100] [Batch 7/347] [D loss: 0.564401] [G loss: 0.451404]\n",
      "[Epoch 45/100] [Batch 8/347] [D loss: 0.550122] [G loss: 0.450255]\n",
      "[Epoch 45/100] [Batch 9/347] [D loss: 0.535348] [G loss: 0.442272]\n",
      "[Epoch 45/100] [Batch 10/347] [D loss: 0.539891] [G loss: 0.444732]\n",
      "[Epoch 45/100] [Batch 11/347] [D loss: 0.560542] [G loss: 0.460163]\n",
      "[Epoch 45/100] [Batch 12/347] [D loss: 0.566014] [G loss: 0.465875]\n",
      "[Epoch 45/100] [Batch 13/347] [D loss: 0.568541] [G loss: 0.470499]\n",
      "[Epoch 45/100] [Batch 14/347] [D loss: 0.565689] [G loss: 0.472965]\n",
      "[Epoch 45/100] [Batch 15/347] [D loss: 0.554509] [G loss: 0.469029]\n",
      "[Epoch 45/100] [Batch 16/347] [D loss: 0.544903] [G loss: 0.464656]\n",
      "[Epoch 45/100] [Batch 17/347] [D loss: 0.530773] [G loss: 0.452290]\n",
      "[Epoch 45/100] [Batch 18/347] [D loss: 0.504532] [G loss: 0.447581]\n",
      "[Epoch 45/100] [Batch 19/347] [D loss: 0.511140] [G loss: 0.455031]\n",
      "[Epoch 45/100] [Batch 20/347] [D loss: 0.558924] [G loss: 0.466499]\n",
      "[Epoch 45/100] [Batch 21/347] [D loss: 0.561593] [G loss: 0.461144]\n",
      "[Epoch 45/100] [Batch 22/347] [D loss: 0.551288] [G loss: 0.454605]\n",
      "[Epoch 45/100] [Batch 23/347] [D loss: 0.520853] [G loss: 0.446383]\n",
      "[Epoch 45/100] [Batch 24/347] [D loss: 0.517364] [G loss: 0.443573]\n",
      "[Epoch 45/100] [Batch 25/347] [D loss: 0.538933] [G loss: 0.441169]\n",
      "[Epoch 45/100] [Batch 26/347] [D loss: 0.469508] [G loss: 0.426578]\n",
      "[Epoch 45/100] [Batch 27/347] [D loss: 0.256113] [G loss: 0.439662]\n",
      "[Epoch 45/100] [Batch 28/347] [D loss: 0.267460] [G loss: 0.445343]\n",
      "[Epoch 45/100] [Batch 29/347] [D loss: 0.510536] [G loss: 0.440791]\n",
      "[Epoch 45/100] [Batch 30/347] [D loss: 0.460428] [G loss: 0.443993]\n",
      "[Epoch 45/100] [Batch 31/347] [D loss: 0.395055] [G loss: 0.441659]\n",
      "[Epoch 45/100] [Batch 32/347] [D loss: 0.310030] [G loss: 0.429515]\n",
      "[Epoch 45/100] [Batch 33/347] [D loss: 0.327602] [G loss: 0.420026]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 45/100] [Batch 34/347] [D loss: 0.422451] [G loss: 0.414873]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 45/100] [Batch 35/347] [D loss: 0.401954] [G loss: 0.406918]\n",
      "[Epoch 45/100] [Batch 36/347] [D loss: 0.479544] [G loss: 0.391005]\n",
      "[Epoch 45/100] [Batch 37/347] [D loss: 0.421181] [G loss: 0.376557]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 45/100] [Batch 38/347] [D loss: 0.371451] [G loss: 0.357654]\n",
      "[Epoch 45/100] [Batch 39/347] [D loss: 0.422466] [G loss: 0.346903]\n",
      "[Epoch 45/100] [Batch 40/347] [D loss: 0.519232] [G loss: 0.341702]\n",
      "[Epoch 45/100] [Batch 41/347] [D loss: 0.527193] [G loss: 0.334276]\n",
      "[Epoch 45/100] [Batch 42/347] [D loss: 0.523307] [G loss: 0.333996]\n",
      "[Epoch 45/100] [Batch 43/347] [D loss: 0.502680] [G loss: 0.345473]\n",
      "[Epoch 45/100] [Batch 44/347] [D loss: 0.498699] [G loss: 0.358999]\n",
      "[Epoch 45/100] [Batch 45/347] [D loss: 0.526397] [G loss: 0.374387]\n",
      "[Epoch 45/100] [Batch 46/347] [D loss: 0.525493] [G loss: 0.368075]\n",
      "[Epoch 45/100] [Batch 47/347] [D loss: 0.509620] [G loss: 0.343546]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 45/100] [Batch 48/347] [D loss: 0.347521] [G loss: 0.333796]\n",
      "[Epoch 45/100] [Batch 49/347] [D loss: 0.348438] [G loss: 0.336432]\n",
      "[Epoch 45/100] [Batch 50/347] [D loss: 0.286825] [G loss: 0.350141]\n",
      "[Epoch 45/100] [Batch 51/347] [D loss: 0.270552] [G loss: 0.368690]\n",
      "[Epoch 45/100] [Batch 52/347] [D loss: 0.378492] [G loss: 0.373422]\n",
      "[Epoch 45/100] [Batch 53/347] [D loss: 0.476038] [G loss: 0.373018]\n",
      "[Epoch 45/100] [Batch 54/347] [D loss: 0.416164] [G loss: 0.363195]\n",
      "[Epoch 45/100] [Batch 55/347] [D loss: 0.407229] [G loss: 0.340236]\n",
      "[Epoch 45/100] [Batch 56/347] [D loss: 0.402119] [G loss: 0.344881]\n",
      "[Epoch 45/100] [Batch 57/347] [D loss: 0.396783] [G loss: 0.376170]\n",
      "[Epoch 45/100] [Batch 58/347] [D loss: 0.413668] [G loss: 0.387893]\n",
      "[Epoch 45/100] [Batch 59/347] [D loss: 0.388801] [G loss: 0.387288]\n",
      "[Epoch 45/100] [Batch 60/347] [D loss: 0.364030] [G loss: 0.383762]\n",
      "[Epoch 45/100] [Batch 61/347] [D loss: 0.328025] [G loss: 0.380950]\n",
      "[Epoch 45/100] [Batch 62/347] [D loss: 0.346195] [G loss: 0.365714]\n",
      "[Epoch 45/100] [Batch 63/347] [D loss: 0.393096] [G loss: 0.342854]\n",
      "[Epoch 45/100] [Batch 64/347] [D loss: 0.419123] [G loss: 0.362460]\n",
      "[Epoch 45/100] [Batch 65/347] [D loss: 0.491345] [G loss: 0.381669]\n",
      "[Epoch 45/100] [Batch 66/347] [D loss: 0.405190] [G loss: 0.379597]\n",
      "[Epoch 45/100] [Batch 67/347] [D loss: 0.232988] [G loss: 0.374493]\n",
      "[Epoch 45/100] [Batch 68/347] [D loss: 0.260624] [G loss: 0.372211]\n",
      "[Epoch 45/100] [Batch 69/347] [D loss: 0.386307] [G loss: 0.356489]\n",
      "[Epoch 45/100] [Batch 70/347] [D loss: 0.389582] [G loss: 0.347906]\n",
      "[Epoch 45/100] [Batch 71/347] [D loss: 0.372686] [G loss: 0.359978]\n",
      "[Epoch 45/100] [Batch 72/347] [D loss: 0.368214] [G loss: 0.359099]\n",
      "[Epoch 45/100] [Batch 73/347] [D loss: 0.370179] [G loss: 0.365610]\n",
      "[Epoch 45/100] [Batch 74/347] [D loss: 0.371953] [G loss: 0.384045]\n",
      "[Epoch 45/100] [Batch 75/347] [D loss: 0.397962] [G loss: 0.374442]\n",
      "[Epoch 45/100] [Batch 76/347] [D loss: 0.426508] [G loss: 0.352197]\n",
      "[Epoch 45/100] [Batch 77/347] [D loss: 0.412544] [G loss: 0.362234]\n",
      "[Epoch 45/100] [Batch 78/347] [D loss: 0.407704] [G loss: 0.378059]\n",
      "[Epoch 45/100] [Batch 79/347] [D loss: 0.506123] [G loss: 0.386451]\n",
      "[Epoch 45/100] [Batch 80/347] [D loss: 0.542071] [G loss: 0.381492]\n",
      "[Epoch 45/100] [Batch 81/347] [D loss: 0.524651] [G loss: 0.384456]\n",
      "[Epoch 45/100] [Batch 82/347] [D loss: 0.428320] [G loss: 0.375535]\n",
      "[Epoch 45/100] [Batch 83/347] [D loss: 0.412177] [G loss: 0.372128]\n",
      "[Epoch 45/100] [Batch 84/347] [D loss: 0.489873] [G loss: 0.382590]\n",
      "[Epoch 45/100] [Batch 85/347] [D loss: 0.560558] [G loss: 0.383224]\n",
      "[Epoch 45/100] [Batch 86/347] [D loss: 0.557691] [G loss: 0.378203]\n",
      "[Epoch 45/100] [Batch 87/347] [D loss: 0.556872] [G loss: 0.377659]\n",
      "[Epoch 45/100] [Batch 88/347] [D loss: 0.562312] [G loss: 0.383546]\n",
      "[Epoch 45/100] [Batch 89/347] [D loss: 0.570090] [G loss: 0.390406]\n",
      "[Epoch 45/100] [Batch 90/347] [D loss: 0.566342] [G loss: 0.390691]\n",
      "[Epoch 45/100] [Batch 91/347] [D loss: 0.564999] [G loss: 0.393763]\n",
      "[Epoch 45/100] [Batch 92/347] [D loss: 0.567067] [G loss: 0.401005]\n",
      "[Epoch 45/100] [Batch 93/347] [D loss: 0.565338] [G loss: 0.404607]\n",
      "[Epoch 45/100] [Batch 94/347] [D loss: 0.558111] [G loss: 0.406902]\n",
      "[Epoch 45/100] [Batch 95/347] [D loss: 0.557555] [G loss: 0.413314]\n",
      "[Epoch 45/100] [Batch 96/347] [D loss: 0.554066] [G loss: 0.414521]\n",
      "[Epoch 45/100] [Batch 97/347] [D loss: 0.550444] [G loss: 0.414958]\n",
      "[Epoch 45/100] [Batch 98/347] [D loss: 0.556915] [G loss: 0.425495]\n",
      "[Epoch 45/100] [Batch 99/347] [D loss: 0.558327] [G loss: 0.434340]\n",
      "[Epoch 45/100] [Batch 100/347] [D loss: 0.538246] [G loss: 0.435305]\n",
      "[Epoch 45/100] [Batch 101/347] [D loss: 0.539153] [G loss: 0.434254]\n",
      "[Epoch 45/100] [Batch 102/347] [D loss: 0.557052] [G loss: 0.439696]\n",
      "[Epoch 45/100] [Batch 103/347] [D loss: 0.556646] [G loss: 0.443985]\n",
      "[Epoch 45/100] [Batch 104/347] [D loss: 0.552513] [G loss: 0.438195]\n",
      "[Epoch 45/100] [Batch 105/347] [D loss: 0.553350] [G loss: 0.440053]\n",
      "[Epoch 45/100] [Batch 106/347] [D loss: 0.542104] [G loss: 0.441308]\n",
      "[Epoch 45/100] [Batch 107/347] [D loss: 0.471452] [G loss: 0.431875]\n",
      "[Epoch 45/100] [Batch 108/347] [D loss: 0.198970] [G loss: 0.443991]\n",
      "[Epoch 45/100] [Batch 109/347] [D loss: 0.199096] [G loss: 0.451175]\n",
      "[Epoch 45/100] [Batch 110/347] [D loss: 0.437096] [G loss: 0.448774]\n",
      "[Epoch 45/100] [Batch 111/347] [D loss: 0.257728] [G loss: 0.447555]\n",
      "[Epoch 45/100] [Batch 112/347] [D loss: 0.198766] [G loss: 0.453832]\n",
      "[Epoch 45/100] [Batch 113/347] [D loss: 0.430508] [G loss: 0.466696]\n",
      "[Epoch 45/100] [Batch 114/347] [D loss: 0.496760] [G loss: 0.487428]\n",
      "[Epoch 45/100] [Batch 115/347] [D loss: 0.478503] [G loss: 0.487881]\n",
      "[Epoch 45/100] [Batch 116/347] [D loss: 0.503904] [G loss: 0.480836]\n",
      "[Epoch 45/100] [Batch 117/347] [D loss: 0.492327] [G loss: 0.452371]\n",
      "[Epoch 45/100] [Batch 118/347] [D loss: 0.414196] [G loss: 0.434283]\n",
      "[Epoch 45/100] [Batch 119/347] [D loss: 0.360425] [G loss: 0.424599]\n",
      "[Epoch 45/100] [Batch 120/347] [D loss: 0.296282] [G loss: 0.424970]\n",
      "[Epoch 45/100] [Batch 121/347] [D loss: 0.281483] [G loss: 0.420320]\n",
      "[Epoch 45/100] [Batch 122/347] [D loss: 0.442001] [G loss: 0.420353]\n",
      "[Epoch 45/100] [Batch 123/347] [D loss: 0.531319] [G loss: 0.417873]\n",
      "[Epoch 45/100] [Batch 124/347] [D loss: 0.531162] [G loss: 0.408581]\n",
      "[Epoch 45/100] [Batch 125/347] [D loss: 0.533407] [G loss: 0.415375]\n",
      "[Epoch 45/100] [Batch 126/347] [D loss: 0.501182] [G loss: 0.422665]\n",
      "[Epoch 45/100] [Batch 127/347] [D loss: 0.483990] [G loss: 0.418376]\n",
      "[Epoch 45/100] [Batch 128/347] [D loss: 0.481849] [G loss: 0.406955]\n",
      "[Epoch 45/100] [Batch 129/347] [D loss: 0.384055] [G loss: 0.395760]\n",
      "[Epoch 45/100] [Batch 130/347] [D loss: 0.369956] [G loss: 0.388737]\n",
      "[Epoch 45/100] [Batch 131/347] [D loss: 0.322327] [G loss: 0.382454]\n",
      "[Epoch 45/100] [Batch 132/347] [D loss: 0.246825] [G loss: 0.383144]\n",
      "[Epoch 45/100] [Batch 133/347] [D loss: 0.246185] [G loss: 0.383858]\n",
      "[Epoch 45/100] [Batch 134/347] [D loss: 0.241702] [G loss: 0.391003]\n",
      "[Epoch 45/100] [Batch 135/347] [D loss: 0.253156] [G loss: 0.408757]\n",
      "[Epoch 45/100] [Batch 136/347] [D loss: 0.242636] [G loss: 0.425555]\n",
      "[Epoch 45/100] [Batch 137/347] [D loss: 0.444166] [G loss: 0.425637]\n",
      "[Epoch 45/100] [Batch 138/347] [D loss: 0.430577] [G loss: 0.422586]\n",
      "[Epoch 45/100] [Batch 139/347] [D loss: 0.409576] [G loss: 0.413942]\n",
      "[Epoch 45/100] [Batch 140/347] [D loss: 0.376596] [G loss: 0.415296]\n",
      "[Epoch 45/100] [Batch 141/347] [D loss: 0.382869] [G loss: 0.410362]\n",
      "[Epoch 45/100] [Batch 142/347] [D loss: 0.393417] [G loss: 0.408073]\n",
      "[Epoch 45/100] [Batch 143/347] [D loss: 0.345457] [G loss: 0.400019]\n",
      "[Epoch 45/100] [Batch 144/347] [D loss: 0.332891] [G loss: 0.387090]\n",
      "[Epoch 45/100] [Batch 145/347] [D loss: 0.326543] [G loss: 0.374705]\n",
      "[Epoch 45/100] [Batch 146/347] [D loss: 0.322523] [G loss: 0.363611]\n",
      "[Epoch 45/100] [Batch 147/347] [D loss: 0.363542] [G loss: 0.368415]\n",
      "[Epoch 45/100] [Batch 148/347] [D loss: 0.373041] [G loss: 0.367331]\n",
      "[Epoch 45/100] [Batch 149/347] [D loss: 0.403793] [G loss: 0.355677]\n",
      "[Epoch 45/100] [Batch 150/347] [D loss: 0.420243] [G loss: 0.351750]\n",
      "[Epoch 45/100] [Batch 151/347] [D loss: 0.400260] [G loss: 0.354813]\n",
      "[Epoch 45/100] [Batch 152/347] [D loss: 0.344019] [G loss: 0.350498]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 45/100] [Batch 153/347] [D loss: 0.305111] [G loss: 0.330432]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 45/100] [Batch 154/347] [D loss: 0.301907] [G loss: 0.308579]\n",
      "[Epoch 45/100] [Batch 155/347] [D loss: 0.317431] [G loss: 0.303638]\n",
      "[Epoch 45/100] [Batch 156/347] [D loss: 0.363762] [G loss: 0.310873]\n",
      "[Epoch 45/100] [Batch 157/347] [D loss: 0.347832] [G loss: 0.320592]\n",
      "[Epoch 45/100] [Batch 158/347] [D loss: 0.312828] [G loss: 0.308699]\n",
      "[Epoch 45/100] [Batch 159/347] [D loss: 0.302843] [G loss: 0.296637]\n",
      "[Epoch 45/100] [Batch 160/347] [D loss: 0.261274] [G loss: 0.318286]\n",
      "[Epoch 45/100] [Batch 161/347] [D loss: 0.256306] [G loss: 0.338159]\n",
      "[Epoch 45/100] [Batch 162/347] [D loss: 0.315866] [G loss: 0.341858]\n",
      "[Epoch 45/100] [Batch 163/347] [D loss: 0.328167] [G loss: 0.337188]\n",
      "[Epoch 45/100] [Batch 164/347] [D loss: 0.302557] [G loss: 0.333137]\n",
      "[Epoch 45/100] [Batch 165/347] [D loss: 0.281210] [G loss: 0.329511]\n",
      "[Epoch 45/100] [Batch 166/347] [D loss: 0.288378] [G loss: 0.344105]\n",
      "[Epoch 45/100] [Batch 167/347] [D loss: 0.263889] [G loss: 0.368688]\n",
      "[Epoch 45/100] [Batch 168/347] [D loss: 0.222984] [G loss: 0.384894]\n",
      "[Epoch 45/100] [Batch 169/347] [D loss: 0.362490] [G loss: 0.394351]\n",
      "[Epoch 45/100] [Batch 170/347] [D loss: 0.440993] [G loss: 0.409103]\n",
      "[Epoch 45/100] [Batch 171/347] [D loss: 0.503676] [G loss: 0.423230]\n",
      "[Epoch 45/100] [Batch 172/347] [D loss: 0.520292] [G loss: 0.430032]\n",
      "[Epoch 45/100] [Batch 173/347] [D loss: 0.401457] [G loss: 0.419284]\n",
      "[Epoch 45/100] [Batch 174/347] [D loss: 0.402019] [G loss: 0.416165]\n",
      "[Epoch 45/100] [Batch 175/347] [D loss: 0.526278] [G loss: 0.424973]\n",
      "[Epoch 45/100] [Batch 176/347] [D loss: 0.552027] [G loss: 0.437710]\n",
      "[Epoch 45/100] [Batch 177/347] [D loss: 0.555841] [G loss: 0.438291]\n",
      "[Epoch 45/100] [Batch 178/347] [D loss: 0.548526] [G loss: 0.431962]\n",
      "[Epoch 45/100] [Batch 179/347] [D loss: 0.542153] [G loss: 0.425046]\n",
      "[Epoch 45/100] [Batch 180/347] [D loss: 0.538213] [G loss: 0.418466]\n",
      "[Epoch 45/100] [Batch 181/347] [D loss: 0.538870] [G loss: 0.418652]\n",
      "[Epoch 45/100] [Batch 182/347] [D loss: 0.537933] [G loss: 0.416524]\n",
      "[Epoch 45/100] [Batch 183/347] [D loss: 0.537321] [G loss: 0.420474]\n",
      "[Epoch 45/100] [Batch 184/347] [D loss: 0.542268] [G loss: 0.424328]\n",
      "[Epoch 45/100] [Batch 185/347] [D loss: 0.546179] [G loss: 0.423023]\n",
      "[Epoch 45/100] [Batch 186/347] [D loss: 0.547107] [G loss: 0.422966]\n",
      "[Epoch 45/100] [Batch 187/347] [D loss: 0.544247] [G loss: 0.418085]\n",
      "[Epoch 45/100] [Batch 188/347] [D loss: 0.542929] [G loss: 0.415154]\n",
      "[Epoch 45/100] [Batch 189/347] [D loss: 0.538819] [G loss: 0.415099]\n",
      "[Epoch 45/100] [Batch 190/347] [D loss: 0.518767] [G loss: 0.403443]\n",
      "[Epoch 45/100] [Batch 191/347] [D loss: 0.479598] [G loss: 0.390106]\n",
      "[Epoch 45/100] [Batch 192/347] [D loss: 0.467234] [G loss: 0.390159]\n",
      "[Epoch 45/100] [Batch 193/347] [D loss: 0.485097] [G loss: 0.396399]\n",
      "[Epoch 45/100] [Batch 194/347] [D loss: 0.521630] [G loss: 0.389489]\n",
      "[Epoch 45/100] [Batch 195/347] [D loss: 0.538391] [G loss: 0.380181]\n",
      "[Epoch 45/100] [Batch 196/347] [D loss: 0.527003] [G loss: 0.373651]\n",
      "[Epoch 45/100] [Batch 197/347] [D loss: 0.478458] [G loss: 0.369958]\n",
      "[Epoch 45/100] [Batch 198/347] [D loss: 0.372338] [G loss: 0.366157]\n",
      "[Epoch 45/100] [Batch 199/347] [D loss: 0.382054] [G loss: 0.361838]\n",
      "[Epoch 45/100] [Batch 200/347] [D loss: 0.494605] [G loss: 0.363245]\n",
      "[Epoch 45/100] [Batch 201/347] [D loss: 0.495193] [G loss: 0.361283]\n",
      "[Epoch 45/100] [Batch 202/347] [D loss: 0.508585] [G loss: 0.354004]\n",
      "[Epoch 45/100] [Batch 203/347] [D loss: 0.544544] [G loss: 0.348283]\n",
      "[Epoch 45/100] [Batch 204/347] [D loss: 0.545347] [G loss: 0.347324]\n",
      "[Epoch 45/100] [Batch 205/347] [D loss: 0.540893] [G loss: 0.347203]\n",
      "[Epoch 45/100] [Batch 206/347] [D loss: 0.532315] [G loss: 0.350632]\n",
      "[Epoch 45/100] [Batch 207/347] [D loss: 0.526071] [G loss: 0.360368]\n",
      "[Epoch 45/100] [Batch 208/347] [D loss: 0.531762] [G loss: 0.360413]\n",
      "[Epoch 45/100] [Batch 209/347] [D loss: 0.502021] [G loss: 0.354163]\n",
      "[Epoch 45/100] [Batch 210/347] [D loss: 0.488503] [G loss: 0.359908]\n",
      "[Epoch 45/100] [Batch 211/347] [D loss: 0.514728] [G loss: 0.358401]\n",
      "[Epoch 45/100] [Batch 212/347] [D loss: 0.307389] [G loss: 0.353304]\n",
      "[Epoch 45/100] [Batch 213/347] [D loss: 0.295513] [G loss: 0.352049]\n",
      "[Epoch 45/100] [Batch 214/347] [D loss: 0.250324] [G loss: 0.366055]\n",
      "[Epoch 45/100] [Batch 215/347] [D loss: 0.242750] [G loss: 0.377135]\n",
      "[Epoch 45/100] [Batch 216/347] [D loss: 0.367661] [G loss: 0.381080]\n",
      "[Epoch 45/100] [Batch 217/347] [D loss: 0.466734] [G loss: 0.397730]\n",
      "[Epoch 45/100] [Batch 218/347] [D loss: 0.544040] [G loss: 0.420649]\n",
      "[Epoch 45/100] [Batch 219/347] [D loss: 0.503233] [G loss: 0.439308]\n",
      "[Epoch 45/100] [Batch 220/347] [D loss: 0.500652] [G loss: 0.460140]\n",
      "[Epoch 45/100] [Batch 221/347] [D loss: 0.522879] [G loss: 0.465607]\n",
      "[Epoch 45/100] [Batch 222/347] [D loss: 0.515604] [G loss: 0.460582]\n",
      "[Epoch 45/100] [Batch 223/347] [D loss: 0.519681] [G loss: 0.461955]\n",
      "[Epoch 45/100] [Batch 224/347] [D loss: 0.525732] [G loss: 0.459957]\n",
      "[Epoch 45/100] [Batch 225/347] [D loss: 0.506635] [G loss: 0.434207]\n",
      "[Epoch 45/100] [Batch 226/347] [D loss: 0.508709] [G loss: 0.411763]\n",
      "[Epoch 45/100] [Batch 227/347] [D loss: 0.521100] [G loss: 0.392393]\n",
      "[Epoch 45/100] [Batch 228/347] [D loss: 0.527266] [G loss: 0.398310]\n",
      "[Epoch 45/100] [Batch 229/347] [D loss: 0.541144] [G loss: 0.409464]\n",
      "[Epoch 45/100] [Batch 230/347] [D loss: 0.545326] [G loss: 0.412487]\n",
      "[Epoch 45/100] [Batch 231/347] [D loss: 0.540420] [G loss: 0.405833]\n",
      "[Epoch 45/100] [Batch 232/347] [D loss: 0.540171] [G loss: 0.407346]\n",
      "[Epoch 45/100] [Batch 233/347] [D loss: 0.519777] [G loss: 0.403450]\n",
      "[Epoch 45/100] [Batch 234/347] [D loss: 0.478086] [G loss: 0.403185]\n",
      "[Epoch 45/100] [Batch 235/347] [D loss: 0.469363] [G loss: 0.409830]\n",
      "[Epoch 45/100] [Batch 236/347] [D loss: 0.479105] [G loss: 0.415182]\n",
      "[Epoch 45/100] [Batch 237/347] [D loss: 0.500914] [G loss: 0.423683]\n",
      "[Epoch 45/100] [Batch 238/347] [D loss: 0.540684] [G loss: 0.423624]\n",
      "[Epoch 45/100] [Batch 239/347] [D loss: 0.525902] [G loss: 0.418243]\n",
      "[Epoch 45/100] [Batch 240/347] [D loss: 0.518853] [G loss: 0.410922]\n",
      "[Epoch 45/100] [Batch 241/347] [D loss: 0.520264] [G loss: 0.402131]\n",
      "[Epoch 45/100] [Batch 242/347] [D loss: 0.526944] [G loss: 0.397509]\n",
      "[Epoch 45/100] [Batch 243/347] [D loss: 0.539641] [G loss: 0.403079]\n",
      "[Epoch 45/100] [Batch 244/347] [D loss: 0.540666] [G loss: 0.410611]\n",
      "[Epoch 45/100] [Batch 245/347] [D loss: 0.484044] [G loss: 0.407604]\n",
      "[Epoch 45/100] [Batch 246/347] [D loss: 0.452188] [G loss: 0.388225]\n",
      "[Epoch 45/100] [Batch 247/347] [D loss: 0.492319] [G loss: 0.362567]\n",
      "[Epoch 45/100] [Batch 248/347] [D loss: 0.531756] [G loss: 0.356082]\n",
      "[Epoch 45/100] [Batch 249/347] [D loss: 0.525146] [G loss: 0.348113]\n",
      "[Epoch 45/100] [Batch 250/347] [D loss: 0.506459] [G loss: 0.365528]\n",
      "[Epoch 45/100] [Batch 251/347] [D loss: 0.479372] [G loss: 0.381310]\n",
      "[Epoch 45/100] [Batch 252/347] [D loss: 0.470365] [G loss: 0.382453]\n",
      "[Epoch 45/100] [Batch 253/347] [D loss: 0.485896] [G loss: 0.381010]\n",
      "[Epoch 45/100] [Batch 254/347] [D loss: 0.506414] [G loss: 0.383399]\n",
      "[Epoch 45/100] [Batch 255/347] [D loss: 0.452596] [G loss: 0.374453]\n",
      "[Epoch 45/100] [Batch 256/347] [D loss: 0.441102] [G loss: 0.377921]\n",
      "[Epoch 45/100] [Batch 257/347] [D loss: 0.450132] [G loss: 0.386538]\n",
      "[Epoch 45/100] [Batch 258/347] [D loss: 0.389521] [G loss: 0.371828]\n",
      "[Epoch 45/100] [Batch 259/347] [D loss: 0.374405] [G loss: 0.357912]\n",
      "[Epoch 45/100] [Batch 260/347] [D loss: 0.340505] [G loss: 0.355462]\n",
      "[Epoch 45/100] [Batch 261/347] [D loss: 0.353538] [G loss: 0.363471]\n",
      "[Epoch 45/100] [Batch 262/347] [D loss: 0.415128] [G loss: 0.359087]\n",
      "[Epoch 45/100] [Batch 263/347] [D loss: 0.377922] [G loss: 0.358104]\n",
      "[Epoch 45/100] [Batch 264/347] [D loss: 0.332172] [G loss: 0.362427]\n",
      "[Epoch 45/100] [Batch 265/347] [D loss: 0.352785] [G loss: 0.362633]\n",
      "[Epoch 45/100] [Batch 266/347] [D loss: 0.375467] [G loss: 0.361948]\n",
      "[Epoch 45/100] [Batch 267/347] [D loss: 0.378000] [G loss: 0.362636]\n",
      "[Epoch 45/100] [Batch 268/347] [D loss: 0.329598] [G loss: 0.370440]\n",
      "[Epoch 45/100] [Batch 269/347] [D loss: 0.332249] [G loss: 0.375300]\n",
      "[Epoch 45/100] [Batch 270/347] [D loss: 0.392266] [G loss: 0.375233]\n",
      "[Epoch 45/100] [Batch 271/347] [D loss: 0.433444] [G loss: 0.374099]\n",
      "[Epoch 45/100] [Batch 272/347] [D loss: 0.469653] [G loss: 0.377518]\n",
      "[Epoch 45/100] [Batch 273/347] [D loss: 0.366054] [G loss: 0.387948]\n",
      "[Epoch 45/100] [Batch 274/347] [D loss: 0.576248] [G loss: 0.413093]\n",
      "[Epoch 45/100] [Batch 275/347] [D loss: 0.534397] [G loss: 0.429635]\n",
      "[Epoch 45/100] [Batch 276/347] [D loss: 0.372375] [G loss: 0.426765]\n",
      "[Epoch 45/100] [Batch 277/347] [D loss: 0.380054] [G loss: 0.434864]\n",
      "[Epoch 45/100] [Batch 278/347] [D loss: 0.501615] [G loss: 0.455934]\n",
      "[Epoch 45/100] [Batch 279/347] [D loss: 0.481192] [G loss: 0.456289]\n",
      "[Epoch 45/100] [Batch 280/347] [D loss: 0.465478] [G loss: 0.458661]\n",
      "[Epoch 45/100] [Batch 281/347] [D loss: 0.466995] [G loss: 0.459672]\n",
      "[Epoch 45/100] [Batch 282/347] [D loss: 0.479000] [G loss: 0.462660]\n",
      "[Epoch 45/100] [Batch 283/347] [D loss: 0.404781] [G loss: 0.458978]\n",
      "[Epoch 45/100] [Batch 284/347] [D loss: 0.392294] [G loss: 0.459675]\n",
      "[Epoch 45/100] [Batch 285/347] [D loss: 0.470525] [G loss: 0.462335]\n",
      "[Epoch 45/100] [Batch 286/347] [D loss: 0.525727] [G loss: 0.459866]\n",
      "[Epoch 45/100] [Batch 287/347] [D loss: 0.528443] [G loss: 0.453533]\n",
      "[Epoch 45/100] [Batch 288/347] [D loss: 0.517607] [G loss: 0.429155]\n",
      "[Epoch 45/100] [Batch 289/347] [D loss: 0.516697] [G loss: 0.421687]\n",
      "[Epoch 45/100] [Batch 290/347] [D loss: 0.531692] [G loss: 0.434823]\n",
      "[Epoch 45/100] [Batch 291/347] [D loss: 0.501539] [G loss: 0.427709]\n",
      "[Epoch 45/100] [Batch 292/347] [D loss: 0.487545] [G loss: 0.431116]\n",
      "[Epoch 45/100] [Batch 293/347] [D loss: 0.429443] [G loss: 0.447599]\n",
      "[Epoch 45/100] [Batch 294/347] [D loss: 0.370958] [G loss: 0.445215]\n",
      "[Epoch 45/100] [Batch 295/347] [D loss: 0.218189] [G loss: 0.428620]\n",
      "[Epoch 45/100] [Batch 296/347] [D loss: 0.207021] [G loss: 0.430699]\n",
      "[Epoch 45/100] [Batch 297/347] [D loss: 0.487178] [G loss: 0.444284]\n",
      "[Epoch 45/100] [Batch 298/347] [D loss: 0.554236] [G loss: 0.436417]\n",
      "[Epoch 45/100] [Batch 299/347] [D loss: 0.502949] [G loss: 0.432489]\n",
      "[Epoch 45/100] [Batch 300/347] [D loss: 0.441617] [G loss: 0.424486]\n",
      "[Epoch 45/100] [Batch 301/347] [D loss: 0.450655] [G loss: 0.416178]\n",
      "[Epoch 45/100] [Batch 302/347] [D loss: 0.510212] [G loss: 0.417982]\n",
      "[Epoch 45/100] [Batch 303/347] [D loss: 0.479188] [G loss: 0.390930]\n",
      "[Epoch 45/100] [Batch 304/347] [D loss: 0.484442] [G loss: 0.371105]\n",
      "[Epoch 45/100] [Batch 305/347] [D loss: 0.510138] [G loss: 0.368950]\n",
      "[Epoch 45/100] [Batch 306/347] [D loss: 0.305598] [G loss: 0.356603]\n",
      "[Epoch 45/100] [Batch 307/347] [D loss: 0.237973] [G loss: 0.359627]\n",
      "[Epoch 45/100] [Batch 308/347] [D loss: 0.316933] [G loss: 0.361329]\n",
      "[Epoch 45/100] [Batch 309/347] [D loss: 0.488252] [G loss: 0.379530]\n",
      "[Epoch 45/100] [Batch 310/347] [D loss: 0.564865] [G loss: 0.408292]\n",
      "[Epoch 45/100] [Batch 311/347] [D loss: 0.565767] [G loss: 0.414052]\n",
      "[Epoch 45/100] [Batch 312/347] [D loss: 0.562752] [G loss: 0.417246]\n",
      "[Epoch 45/100] [Batch 313/347] [D loss: 0.550329] [G loss: 0.419704]\n",
      "[Epoch 45/100] [Batch 314/347] [D loss: 0.495259] [G loss: 0.415965]\n",
      "[Epoch 45/100] [Batch 315/347] [D loss: 0.433030] [G loss: 0.408353]\n",
      "[Epoch 45/100] [Batch 316/347] [D loss: 0.431072] [G loss: 0.392615]\n",
      "[Epoch 45/100] [Batch 317/347] [D loss: 0.497021] [G loss: 0.382159]\n",
      "[Epoch 45/100] [Batch 318/347] [D loss: 0.536354] [G loss: 0.398769]\n",
      "[Epoch 45/100] [Batch 319/347] [D loss: 0.539032] [G loss: 0.431970]\n",
      "[Epoch 45/100] [Batch 320/347] [D loss: 0.531863] [G loss: 0.445846]\n",
      "[Epoch 45/100] [Batch 321/347] [D loss: 0.510129] [G loss: 0.435585]\n",
      "[Epoch 45/100] [Batch 322/347] [D loss: 0.508697] [G loss: 0.422281]\n",
      "[Epoch 45/100] [Batch 323/347] [D loss: 0.468751] [G loss: 0.420556]\n",
      "[Epoch 45/100] [Batch 324/347] [D loss: 0.456250] [G loss: 0.422299]\n",
      "[Epoch 45/100] [Batch 325/347] [D loss: 0.351701] [G loss: 0.410330]\n",
      "[Epoch 45/100] [Batch 326/347] [D loss: 0.324026] [G loss: 0.398118]\n",
      "[Epoch 45/100] [Batch 327/347] [D loss: 0.413262] [G loss: 0.396189]\n",
      "[Epoch 45/100] [Batch 328/347] [D loss: 0.466879] [G loss: 0.393718]\n",
      "[Epoch 45/100] [Batch 329/347] [D loss: 0.366640] [G loss: 0.380821]\n",
      "[Epoch 45/100] [Batch 330/347] [D loss: 0.353186] [G loss: 0.373655]\n",
      "[Epoch 45/100] [Batch 331/347] [D loss: 0.440535] [G loss: 0.380986]\n",
      "[Epoch 45/100] [Batch 332/347] [D loss: 0.538283] [G loss: 0.403976]\n",
      "[Epoch 45/100] [Batch 333/347] [D loss: 0.554555] [G loss: 0.415455]\n",
      "[Epoch 45/100] [Batch 334/347] [D loss: 0.516832] [G loss: 0.417382]\n",
      "[Epoch 45/100] [Batch 335/347] [D loss: 0.483059] [G loss: 0.405505]\n",
      "[Epoch 45/100] [Batch 336/347] [D loss: 0.478713] [G loss: 0.390947]\n",
      "[Epoch 45/100] [Batch 337/347] [D loss: 0.472786] [G loss: 0.396707]\n",
      "[Epoch 45/100] [Batch 338/347] [D loss: 0.501821] [G loss: 0.411385]\n",
      "[Epoch 45/100] [Batch 339/347] [D loss: 0.553419] [G loss: 0.418024]\n",
      "[Epoch 45/100] [Batch 340/347] [D loss: 0.563130] [G loss: 0.420357]\n",
      "[Epoch 45/100] [Batch 341/347] [D loss: 0.537285] [G loss: 0.417797]\n",
      "[Epoch 45/100] [Batch 342/347] [D loss: 0.529106] [G loss: 0.412647]\n",
      "[Epoch 45/100] [Batch 343/347] [D loss: 0.552600] [G loss: 0.420286]\n",
      "[Epoch 45/100] [Batch 344/347] [D loss: 0.446579] [G loss: 0.411861]\n",
      "[Epoch 45/100] [Batch 345/347] [D loss: 0.377600] [G loss: 0.389170]\n",
      "[Epoch 45/100] [Batch 346/347] [D loss: 0.333246] [G loss: 0.390990]\n",
      "[Epoch 45/100] [Batch 347/347] [D loss: 0.235981] [G loss: 0.405924]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 46/100] [Batch 1/347] [D loss: 0.529853] [G loss: 0.422576]\n",
      "[Epoch 46/100] [Batch 2/347] [D loss: 0.539525] [G loss: 0.429676]\n",
      "[Epoch 46/100] [Batch 3/347] [D loss: 0.563983] [G loss: 0.444768]\n",
      "[Epoch 46/100] [Batch 4/347] [D loss: 0.564922] [G loss: 0.450672]\n",
      "[Epoch 46/100] [Batch 5/347] [D loss: 0.562981] [G loss: 0.454099]\n",
      "[Epoch 46/100] [Batch 6/347] [D loss: 0.566755] [G loss: 0.460334]\n",
      "[Epoch 46/100] [Batch 7/347] [D loss: 0.563494] [G loss: 0.459388]\n",
      "[Epoch 46/100] [Batch 8/347] [D loss: 0.548957] [G loss: 0.458321]\n",
      "[Epoch 46/100] [Batch 9/347] [D loss: 0.534320] [G loss: 0.450308]\n",
      "[Epoch 46/100] [Batch 10/347] [D loss: 0.538841] [G loss: 0.453066]\n",
      "[Epoch 46/100] [Batch 11/347] [D loss: 0.559777] [G loss: 0.468574]\n",
      "[Epoch 46/100] [Batch 12/347] [D loss: 0.565343] [G loss: 0.474197]\n",
      "[Epoch 46/100] [Batch 13/347] [D loss: 0.567800] [G loss: 0.478797]\n",
      "[Epoch 46/100] [Batch 14/347] [D loss: 0.564792] [G loss: 0.481137]\n",
      "[Epoch 46/100] [Batch 15/347] [D loss: 0.553226] [G loss: 0.477304]\n",
      "[Epoch 46/100] [Batch 16/347] [D loss: 0.543518] [G loss: 0.472819]\n",
      "[Epoch 46/100] [Batch 17/347] [D loss: 0.529857] [G loss: 0.460190]\n",
      "[Epoch 46/100] [Batch 18/347] [D loss: 0.502647] [G loss: 0.456512]\n",
      "[Epoch 46/100] [Batch 19/347] [D loss: 0.509263] [G loss: 0.462573]\n",
      "[Epoch 46/100] [Batch 20/347] [D loss: 0.557890] [G loss: 0.473903]\n",
      "[Epoch 46/100] [Batch 21/347] [D loss: 0.560968] [G loss: 0.468420]\n",
      "[Epoch 46/100] [Batch 22/347] [D loss: 0.550323] [G loss: 0.461559]\n",
      "[Epoch 46/100] [Batch 23/347] [D loss: 0.518909] [G loss: 0.453199]\n",
      "[Epoch 46/100] [Batch 24/347] [D loss: 0.515346] [G loss: 0.450099]\n",
      "[Epoch 46/100] [Batch 25/347] [D loss: 0.537797] [G loss: 0.447173]\n",
      "[Epoch 46/100] [Batch 26/347] [D loss: 0.467091] [G loss: 0.433592]\n",
      "[Epoch 46/100] [Batch 27/347] [D loss: 0.251123] [G loss: 0.446386]\n",
      "[Epoch 46/100] [Batch 28/347] [D loss: 0.262543] [G loss: 0.451653]\n",
      "[Epoch 46/100] [Batch 29/347] [D loss: 0.507577] [G loss: 0.445537]\n",
      "[Epoch 46/100] [Batch 30/347] [D loss: 0.455247] [G loss: 0.448056]\n",
      "[Epoch 46/100] [Batch 31/347] [D loss: 0.387786] [G loss: 0.445202]\n",
      "[Epoch 46/100] [Batch 32/347] [D loss: 0.302369] [G loss: 0.432980]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 46/100] [Batch 33/347] [D loss: 0.319355] [G loss: 0.422163]\n",
      "[Epoch 46/100] [Batch 34/347] [D loss: 0.412540] [G loss: 0.416354]\n",
      "[Epoch 46/100] [Batch 35/347] [D loss: 0.390699] [G loss: 0.407398]\n",
      "[Epoch 46/100] [Batch 36/347] [D loss: 0.473396] [G loss: 0.391418]\n",
      "[Epoch 46/100] [Batch 37/347] [D loss: 0.413227] [G loss: 0.375864]\n",
      "[Epoch 46/100] [Batch 38/347] [D loss: 0.362038] [G loss: 0.356177]\n",
      "[Epoch 46/100] [Batch 39/347] [D loss: 0.415132] [G loss: 0.345624]\n",
      "[Epoch 46/100] [Batch 40/347] [D loss: 0.516036] [G loss: 0.339985]\n",
      "[Epoch 46/100] [Batch 41/347] [D loss: 0.525664] [G loss: 0.333443]\n",
      "[Epoch 46/100] [Batch 42/347] [D loss: 0.521844] [G loss: 0.333920]\n",
      "[Epoch 46/100] [Batch 43/347] [D loss: 0.498448] [G loss: 0.346721]\n",
      "[Epoch 46/100] [Batch 44/347] [D loss: 0.493696] [G loss: 0.359993]\n",
      "[Epoch 46/100] [Batch 45/347] [D loss: 0.522927] [G loss: 0.375984]\n",
      "[Epoch 46/100] [Batch 46/347] [D loss: 0.521900] [G loss: 0.369901]\n",
      "[Epoch 46/100] [Batch 47/347] [D loss: 0.506681] [G loss: 0.345544]\n",
      "[Epoch 46/100] [Batch 48/347] [D loss: 0.340228] [G loss: 0.336146]\n",
      "[Epoch 46/100] [Batch 49/347] [D loss: 0.341062] [G loss: 0.338683]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 46/100] [Batch 50/347] [D loss: 0.283489] [G loss: 0.353428]\n",
      "[Epoch 46/100] [Batch 51/347] [D loss: 0.267399] [G loss: 0.372329]\n",
      "[Epoch 46/100] [Batch 52/347] [D loss: 0.374980] [G loss: 0.377922]\n",
      "[Epoch 46/100] [Batch 53/347] [D loss: 0.472042] [G loss: 0.378105]\n",
      "[Epoch 46/100] [Batch 54/347] [D loss: 0.411104] [G loss: 0.368583]\n",
      "[Epoch 46/100] [Batch 55/347] [D loss: 0.402779] [G loss: 0.346248]\n",
      "[Epoch 46/100] [Batch 56/347] [D loss: 0.396997] [G loss: 0.351552]\n",
      "[Epoch 46/100] [Batch 57/347] [D loss: 0.390237] [G loss: 0.383005]\n",
      "[Epoch 46/100] [Batch 58/347] [D loss: 0.407200] [G loss: 0.395117]\n",
      "[Epoch 46/100] [Batch 59/347] [D loss: 0.383806] [G loss: 0.394917]\n",
      "[Epoch 46/100] [Batch 60/347] [D loss: 0.358593] [G loss: 0.391816]\n",
      "[Epoch 46/100] [Batch 61/347] [D loss: 0.320640] [G loss: 0.389513]\n",
      "[Epoch 46/100] [Batch 62/347] [D loss: 0.340267] [G loss: 0.374783]\n",
      "[Epoch 46/100] [Batch 63/347] [D loss: 0.389835] [G loss: 0.352584]\n",
      "[Epoch 46/100] [Batch 64/347] [D loss: 0.415412] [G loss: 0.372542]\n",
      "[Epoch 46/100] [Batch 65/347] [D loss: 0.489102] [G loss: 0.391426]\n",
      "[Epoch 46/100] [Batch 66/347] [D loss: 0.402826] [G loss: 0.390321]\n",
      "[Epoch 46/100] [Batch 67/347] [D loss: 0.227959] [G loss: 0.385207]\n",
      "[Epoch 46/100] [Batch 68/347] [D loss: 0.255841] [G loss: 0.382237]\n",
      "[Epoch 46/100] [Batch 69/347] [D loss: 0.383231] [G loss: 0.366257]\n",
      "[Epoch 46/100] [Batch 70/347] [D loss: 0.386769] [G loss: 0.357202]\n",
      "[Epoch 46/100] [Batch 71/347] [D loss: 0.369893] [G loss: 0.369004]\n",
      "[Epoch 46/100] [Batch 72/347] [D loss: 0.365469] [G loss: 0.368122]\n",
      "[Epoch 46/100] [Batch 73/347] [D loss: 0.367838] [G loss: 0.374594]\n",
      "[Epoch 46/100] [Batch 74/347] [D loss: 0.370429] [G loss: 0.393048]\n",
      "[Epoch 46/100] [Batch 75/347] [D loss: 0.397375] [G loss: 0.383378]\n",
      "[Epoch 46/100] [Batch 76/347] [D loss: 0.426826] [G loss: 0.361303]\n",
      "[Epoch 46/100] [Batch 77/347] [D loss: 0.411136] [G loss: 0.371331]\n",
      "[Epoch 46/100] [Batch 78/347] [D loss: 0.405930] [G loss: 0.386980]\n",
      "[Epoch 46/100] [Batch 79/347] [D loss: 0.507028] [G loss: 0.394344]\n",
      "[Epoch 46/100] [Batch 80/347] [D loss: 0.544994] [G loss: 0.389488]\n",
      "[Epoch 46/100] [Batch 81/347] [D loss: 0.526683] [G loss: 0.392301]\n",
      "[Epoch 46/100] [Batch 82/347] [D loss: 0.426852] [G loss: 0.384428]\n",
      "[Epoch 46/100] [Batch 83/347] [D loss: 0.410446] [G loss: 0.380388]\n",
      "[Epoch 46/100] [Batch 84/347] [D loss: 0.489890] [G loss: 0.390843]\n",
      "[Epoch 46/100] [Batch 85/347] [D loss: 0.564495] [G loss: 0.391829]\n",
      "[Epoch 46/100] [Batch 86/347] [D loss: 0.562053] [G loss: 0.387437]\n",
      "[Epoch 46/100] [Batch 87/347] [D loss: 0.561318] [G loss: 0.387688]\n",
      "[Epoch 46/100] [Batch 88/347] [D loss: 0.566643] [G loss: 0.394402]\n",
      "[Epoch 46/100] [Batch 89/347] [D loss: 0.574244] [G loss: 0.402302]\n",
      "[Epoch 46/100] [Batch 90/347] [D loss: 0.570441] [G loss: 0.403720]\n",
      "[Epoch 46/100] [Batch 91/347] [D loss: 0.568857] [G loss: 0.408211]\n",
      "[Epoch 46/100] [Batch 92/347] [D loss: 0.570427] [G loss: 0.415637]\n",
      "[Epoch 46/100] [Batch 93/347] [D loss: 0.568639] [G loss: 0.420534]\n",
      "[Epoch 46/100] [Batch 94/347] [D loss: 0.561160] [G loss: 0.423675]\n",
      "[Epoch 46/100] [Batch 95/347] [D loss: 0.560338] [G loss: 0.431051]\n",
      "[Epoch 46/100] [Batch 96/347] [D loss: 0.556929] [G loss: 0.432919]\n",
      "[Epoch 46/100] [Batch 97/347] [D loss: 0.553566] [G loss: 0.433765]\n",
      "[Epoch 46/100] [Batch 98/347] [D loss: 0.559398] [G loss: 0.444213]\n",
      "[Epoch 46/100] [Batch 99/347] [D loss: 0.560348] [G loss: 0.453299]\n",
      "[Epoch 46/100] [Batch 100/347] [D loss: 0.540075] [G loss: 0.454518]\n",
      "[Epoch 46/100] [Batch 101/347] [D loss: 0.541139] [G loss: 0.453352]\n",
      "[Epoch 46/100] [Batch 102/347] [D loss: 0.559279] [G loss: 0.458910]\n",
      "[Epoch 46/100] [Batch 103/347] [D loss: 0.558908] [G loss: 0.462783]\n",
      "[Epoch 46/100] [Batch 104/347] [D loss: 0.555204] [G loss: 0.456929]\n",
      "[Epoch 46/100] [Batch 105/347] [D loss: 0.555981] [G loss: 0.458622]\n",
      "[Epoch 46/100] [Batch 106/347] [D loss: 0.544721] [G loss: 0.459458]\n",
      "[Epoch 46/100] [Batch 107/347] [D loss: 0.474455] [G loss: 0.449824]\n",
      "[Epoch 46/100] [Batch 108/347] [D loss: 0.196995] [G loss: 0.459967]\n",
      "[Epoch 46/100] [Batch 109/347] [D loss: 0.197578] [G loss: 0.466421]\n",
      "[Epoch 46/100] [Batch 110/347] [D loss: 0.442072] [G loss: 0.464372]\n",
      "[Epoch 46/100] [Batch 111/347] [D loss: 0.257647] [G loss: 0.460988]\n",
      "[Epoch 46/100] [Batch 112/347] [D loss: 0.198158] [G loss: 0.466336]\n",
      "[Epoch 46/100] [Batch 113/347] [D loss: 0.430690] [G loss: 0.479327]\n",
      "[Epoch 46/100] [Batch 114/347] [D loss: 0.498099] [G loss: 0.499343]\n",
      "[Epoch 46/100] [Batch 115/347] [D loss: 0.480031] [G loss: 0.499249]\n",
      "[Epoch 46/100] [Batch 116/347] [D loss: 0.504448] [G loss: 0.491645]\n",
      "[Epoch 46/100] [Batch 117/347] [D loss: 0.493772] [G loss: 0.462708]\n",
      "[Epoch 46/100] [Batch 118/347] [D loss: 0.416562] [G loss: 0.442903]\n",
      "[Epoch 46/100] [Batch 119/347] [D loss: 0.361713] [G loss: 0.432839]\n",
      "[Epoch 46/100] [Batch 120/347] [D loss: 0.296417] [G loss: 0.432941]\n",
      "[Epoch 46/100] [Batch 121/347] [D loss: 0.280404] [G loss: 0.427934]\n",
      "[Epoch 46/100] [Batch 122/347] [D loss: 0.440790] [G loss: 0.428489]\n",
      "[Epoch 46/100] [Batch 123/347] [D loss: 0.531088] [G loss: 0.426098]\n",
      "[Epoch 46/100] [Batch 124/347] [D loss: 0.531324] [G loss: 0.416567]\n",
      "[Epoch 46/100] [Batch 125/347] [D loss: 0.532814] [G loss: 0.422877]\n",
      "[Epoch 46/100] [Batch 126/347] [D loss: 0.498505] [G loss: 0.429802]\n",
      "[Epoch 46/100] [Batch 127/347] [D loss: 0.480385] [G loss: 0.425104]\n",
      "[Epoch 46/100] [Batch 128/347] [D loss: 0.478035] [G loss: 0.413454]\n",
      "[Epoch 46/100] [Batch 129/347] [D loss: 0.378650] [G loss: 0.401886]\n",
      "[Epoch 46/100] [Batch 130/347] [D loss: 0.365177] [G loss: 0.393422]\n",
      "[Epoch 46/100] [Batch 131/347] [D loss: 0.319591] [G loss: 0.386548]\n",
      "[Epoch 46/100] [Batch 132/347] [D loss: 0.250217] [G loss: 0.387003]\n",
      "[Epoch 46/100] [Batch 133/347] [D loss: 0.248158] [G loss: 0.387450]\n",
      "[Epoch 46/100] [Batch 134/347] [D loss: 0.245086] [G loss: 0.394488]\n",
      "[Epoch 46/100] [Batch 135/347] [D loss: 0.258764] [G loss: 0.412452]\n",
      "[Epoch 46/100] [Batch 136/347] [D loss: 0.247624] [G loss: 0.429038]\n",
      "[Epoch 46/100] [Batch 137/347] [D loss: 0.441202] [G loss: 0.428818]\n",
      "[Epoch 46/100] [Batch 138/347] [D loss: 0.427889] [G loss: 0.425416]\n",
      "[Epoch 46/100] [Batch 139/347] [D loss: 0.407017] [G loss: 0.416402]\n",
      "[Epoch 46/100] [Batch 140/347] [D loss: 0.371623] [G loss: 0.417631]\n",
      "[Epoch 46/100] [Batch 141/347] [D loss: 0.377740] [G loss: 0.412628]\n",
      "[Epoch 46/100] [Batch 142/347] [D loss: 0.389506] [G loss: 0.410153]\n",
      "[Epoch 46/100] [Batch 143/347] [D loss: 0.340320] [G loss: 0.402109]\n",
      "[Epoch 46/100] [Batch 144/347] [D loss: 0.326908] [G loss: 0.389343]\n",
      "[Epoch 46/100] [Batch 145/347] [D loss: 0.319356] [G loss: 0.376881]\n",
      "[Epoch 46/100] [Batch 146/347] [D loss: 0.314180] [G loss: 0.365979]\n",
      "[Epoch 46/100] [Batch 147/347] [D loss: 0.355550] [G loss: 0.370822]\n",
      "[Epoch 46/100] [Batch 148/347] [D loss: 0.365026] [G loss: 0.369754]\n",
      "[Epoch 46/100] [Batch 149/347] [D loss: 0.397513] [G loss: 0.358199]\n",
      "[Epoch 46/100] [Batch 150/347] [D loss: 0.414346] [G loss: 0.354092]\n",
      "[Epoch 46/100] [Batch 151/347] [D loss: 0.392674] [G loss: 0.357526]\n",
      "[Epoch 46/100] [Batch 152/347] [D loss: 0.335272] [G loss: 0.353076]\n",
      "[Epoch 46/100] [Batch 153/347] [D loss: 0.296705] [G loss: 0.333114]\n",
      "[Epoch 46/100] [Batch 154/347] [D loss: 0.293702] [G loss: 0.311287]\n",
      "[Epoch 46/100] [Batch 155/347] [D loss: 0.308069] [G loss: 0.306459]\n",
      "[Epoch 46/100] [Batch 156/347] [D loss: 0.354887] [G loss: 0.313702]\n",
      "[Epoch 46/100] [Batch 157/347] [D loss: 0.339238] [G loss: 0.323734]\n",
      "[Epoch 46/100] [Batch 158/347] [D loss: 0.303999] [G loss: 0.311821]\n",
      "[Epoch 46/100] [Batch 159/347] [D loss: 0.294095] [G loss: 0.300534]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 46/100] [Batch 160/347] [D loss: 0.254330] [G loss: 0.322651]\n",
      "[Epoch 46/100] [Batch 161/347] [D loss: 0.249523] [G loss: 0.342772]\n",
      "[Epoch 46/100] [Batch 162/347] [D loss: 0.306432] [G loss: 0.346999]\n",
      "[Epoch 46/100] [Batch 163/347] [D loss: 0.319220] [G loss: 0.342715]\n",
      "[Epoch 46/100] [Batch 164/347] [D loss: 0.293782] [G loss: 0.338636]\n",
      "[Epoch 46/100] [Batch 165/347] [D loss: 0.272264] [G loss: 0.335048]\n",
      "[Epoch 46/100] [Batch 166/347] [D loss: 0.279405] [G loss: 0.349860]\n",
      "[Epoch 46/100] [Batch 167/347] [D loss: 0.257113] [G loss: 0.374289]\n",
      "[Epoch 46/100] [Batch 168/347] [D loss: 0.216154] [G loss: 0.390675]\n",
      "[Epoch 46/100] [Batch 169/347] [D loss: 0.355012] [G loss: 0.399211]\n",
      "[Epoch 46/100] [Batch 170/347] [D loss: 0.431934] [G loss: 0.413521]\n",
      "[Epoch 46/100] [Batch 171/347] [D loss: 0.498040] [G loss: 0.427240]\n",
      "[Epoch 46/100] [Batch 172/347] [D loss: 0.515894] [G loss: 0.433709]\n",
      "[Epoch 46/100] [Batch 173/347] [D loss: 0.390274] [G loss: 0.422590]\n",
      "[Epoch 46/100] [Batch 174/347] [D loss: 0.390533] [G loss: 0.419143]\n",
      "[Epoch 46/100] [Batch 175/347] [D loss: 0.521550] [G loss: 0.427743]\n",
      "[Epoch 46/100] [Batch 176/347] [D loss: 0.548527] [G loss: 0.440009]\n",
      "[Epoch 46/100] [Batch 177/347] [D loss: 0.552434] [G loss: 0.440121]\n",
      "[Epoch 46/100] [Batch 178/347] [D loss: 0.544904] [G loss: 0.433546]\n",
      "[Epoch 46/100] [Batch 179/347] [D loss: 0.538447] [G loss: 0.426216]\n",
      "[Epoch 46/100] [Batch 180/347] [D loss: 0.534482] [G loss: 0.419031]\n",
      "[Epoch 46/100] [Batch 181/347] [D loss: 0.535000] [G loss: 0.418938]\n",
      "[Epoch 46/100] [Batch 182/347] [D loss: 0.533843] [G loss: 0.416466]\n",
      "[Epoch 46/100] [Batch 183/347] [D loss: 0.532740] [G loss: 0.419977]\n",
      "[Epoch 46/100] [Batch 184/347] [D loss: 0.537913] [G loss: 0.423310]\n",
      "[Epoch 46/100] [Batch 185/347] [D loss: 0.542535] [G loss: 0.421525]\n",
      "[Epoch 46/100] [Batch 186/347] [D loss: 0.543711] [G loss: 0.421142]\n",
      "[Epoch 46/100] [Batch 187/347] [D loss: 0.540941] [G loss: 0.415793]\n",
      "[Epoch 46/100] [Batch 188/347] [D loss: 0.539700] [G loss: 0.412837]\n",
      "[Epoch 46/100] [Batch 189/347] [D loss: 0.535107] [G loss: 0.412277]\n",
      "[Epoch 46/100] [Batch 190/347] [D loss: 0.512076] [G loss: 0.400279]\n",
      "[Epoch 46/100] [Batch 191/347] [D loss: 0.468096] [G loss: 0.386629]\n",
      "[Epoch 46/100] [Batch 192/347] [D loss: 0.455517] [G loss: 0.386565]\n",
      "[Epoch 46/100] [Batch 193/347] [D loss: 0.474971] [G loss: 0.392455]\n",
      "[Epoch 46/100] [Batch 194/347] [D loss: 0.516017] [G loss: 0.385263]\n",
      "[Epoch 46/100] [Batch 195/347] [D loss: 0.537216] [G loss: 0.375837]\n",
      "[Epoch 46/100] [Batch 196/347] [D loss: 0.524521] [G loss: 0.368940]\n",
      "[Epoch 46/100] [Batch 197/347] [D loss: 0.471363] [G loss: 0.365032]\n",
      "[Epoch 46/100] [Batch 198/347] [D loss: 0.361640] [G loss: 0.361539]\n",
      "[Epoch 46/100] [Batch 199/347] [D loss: 0.372098] [G loss: 0.357435]\n",
      "[Epoch 46/100] [Batch 200/347] [D loss: 0.489312] [G loss: 0.359380]\n",
      "[Epoch 46/100] [Batch 201/347] [D loss: 0.489413] [G loss: 0.358254]\n",
      "[Epoch 46/100] [Batch 202/347] [D loss: 0.503856] [G loss: 0.351634]\n",
      "[Epoch 46/100] [Batch 203/347] [D loss: 0.547489] [G loss: 0.346304]\n",
      "[Epoch 46/100] [Batch 204/347] [D loss: 0.548698] [G loss: 0.346078]\n",
      "[Epoch 46/100] [Batch 205/347] [D loss: 0.543804] [G loss: 0.346741]\n",
      "[Epoch 46/100] [Batch 206/347] [D loss: 0.534286] [G loss: 0.351226]\n",
      "[Epoch 46/100] [Batch 207/347] [D loss: 0.526994] [G loss: 0.361847]\n",
      "[Epoch 46/100] [Batch 208/347] [D loss: 0.533363] [G loss: 0.362797]\n",
      "[Epoch 46/100] [Batch 209/347] [D loss: 0.500778] [G loss: 0.357074]\n",
      "[Epoch 46/100] [Batch 210/347] [D loss: 0.486653] [G loss: 0.363574]\n",
      "[Epoch 46/100] [Batch 211/347] [D loss: 0.516792] [G loss: 0.362847]\n",
      "[Epoch 46/100] [Batch 212/347] [D loss: 0.304947] [G loss: 0.359220]\n",
      "[Epoch 46/100] [Batch 213/347] [D loss: 0.293869] [G loss: 0.358317]\n",
      "[Epoch 46/100] [Batch 214/347] [D loss: 0.253049] [G loss: 0.373758]\n",
      "[Epoch 46/100] [Batch 215/347] [D loss: 0.244086] [G loss: 0.386012]\n",
      "[Epoch 46/100] [Batch 216/347] [D loss: 0.365216] [G loss: 0.391285]\n",
      "[Epoch 46/100] [Batch 217/347] [D loss: 0.468525] [G loss: 0.409144]\n",
      "[Epoch 46/100] [Batch 218/347] [D loss: 0.548411] [G loss: 0.433077]\n",
      "[Epoch 46/100] [Batch 219/347] [D loss: 0.504736] [G loss: 0.452347]\n",
      "[Epoch 46/100] [Batch 220/347] [D loss: 0.502591] [G loss: 0.473719]\n",
      "[Epoch 46/100] [Batch 221/347] [D loss: 0.526131] [G loss: 0.479539]\n",
      "[Epoch 46/100] [Batch 222/347] [D loss: 0.519602] [G loss: 0.475264]\n",
      "[Epoch 46/100] [Batch 223/347] [D loss: 0.524276] [G loss: 0.476933]\n",
      "[Epoch 46/100] [Batch 224/347] [D loss: 0.530304] [G loss: 0.475528]\n",
      "[Epoch 46/100] [Batch 225/347] [D loss: 0.512635] [G loss: 0.449890]\n",
      "[Epoch 46/100] [Batch 226/347] [D loss: 0.515545] [G loss: 0.428085]\n",
      "[Epoch 46/100] [Batch 227/347] [D loss: 0.527772] [G loss: 0.409579]\n",
      "[Epoch 46/100] [Batch 228/347] [D loss: 0.533475] [G loss: 0.416108]\n",
      "[Epoch 46/100] [Batch 229/347] [D loss: 0.547052] [G loss: 0.427706]\n",
      "[Epoch 46/100] [Batch 230/347] [D loss: 0.550957] [G loss: 0.431308]\n",
      "[Epoch 46/100] [Batch 231/347] [D loss: 0.546411] [G loss: 0.424989]\n",
      "[Epoch 46/100] [Batch 232/347] [D loss: 0.545982] [G loss: 0.426669]\n",
      "[Epoch 46/100] [Batch 233/347] [D loss: 0.525926] [G loss: 0.423179]\n",
      "[Epoch 46/100] [Batch 234/347] [D loss: 0.484979] [G loss: 0.422704]\n",
      "[Epoch 46/100] [Batch 235/347] [D loss: 0.476925] [G loss: 0.430004]\n",
      "[Epoch 46/100] [Batch 236/347] [D loss: 0.486311] [G loss: 0.436070]\n",
      "[Epoch 46/100] [Batch 237/347] [D loss: 0.506441] [G loss: 0.444579]\n",
      "[Epoch 46/100] [Batch 238/347] [D loss: 0.543946] [G loss: 0.444897]\n",
      "[Epoch 46/100] [Batch 239/347] [D loss: 0.529602] [G loss: 0.439471]\n",
      "[Epoch 46/100] [Batch 240/347] [D loss: 0.523238] [G loss: 0.432467]\n",
      "[Epoch 46/100] [Batch 241/347] [D loss: 0.524817] [G loss: 0.423696]\n",
      "[Epoch 46/100] [Batch 242/347] [D loss: 0.530930] [G loss: 0.419123]\n",
      "[Epoch 46/100] [Batch 243/347] [D loss: 0.542312] [G loss: 0.424620]\n",
      "[Epoch 46/100] [Batch 244/347] [D loss: 0.542326] [G loss: 0.431903]\n",
      "[Epoch 46/100] [Batch 245/347] [D loss: 0.486865] [G loss: 0.428563]\n",
      "[Epoch 46/100] [Batch 246/347] [D loss: 0.455020] [G loss: 0.408240]\n",
      "[Epoch 46/100] [Batch 247/347] [D loss: 0.494765] [G loss: 0.382212]\n",
      "[Epoch 46/100] [Batch 248/347] [D loss: 0.535152] [G loss: 0.375120]\n",
      "[Epoch 46/100] [Batch 249/347] [D loss: 0.528833] [G loss: 0.366538]\n",
      "[Epoch 46/100] [Batch 250/347] [D loss: 0.509578] [G loss: 0.382810]\n",
      "[Epoch 46/100] [Batch 251/347] [D loss: 0.481250] [G loss: 0.397793]\n",
      "[Epoch 46/100] [Batch 252/347] [D loss: 0.471604] [G loss: 0.398117]\n",
      "[Epoch 46/100] [Batch 253/347] [D loss: 0.486036] [G loss: 0.395197]\n",
      "[Epoch 46/100] [Batch 254/347] [D loss: 0.506587] [G loss: 0.396573]\n",
      "[Epoch 46/100] [Batch 255/347] [D loss: 0.452014] [G loss: 0.386430]\n",
      "[Epoch 46/100] [Batch 256/347] [D loss: 0.439798] [G loss: 0.388777]\n",
      "[Epoch 46/100] [Batch 257/347] [D loss: 0.447195] [G loss: 0.395968]\n",
      "[Epoch 46/100] [Batch 258/347] [D loss: 0.384103] [G loss: 0.380498]\n",
      "[Epoch 46/100] [Batch 259/347] [D loss: 0.369512] [G loss: 0.365672]\n",
      "[Epoch 46/100] [Batch 260/347] [D loss: 0.336206] [G loss: 0.362530]\n",
      "[Epoch 46/100] [Batch 261/347] [D loss: 0.349484] [G loss: 0.369687]\n",
      "[Epoch 46/100] [Batch 262/347] [D loss: 0.410552] [G loss: 0.365057]\n",
      "[Epoch 46/100] [Batch 263/347] [D loss: 0.373824] [G loss: 0.363839]\n",
      "[Epoch 46/100] [Batch 264/347] [D loss: 0.328254] [G loss: 0.367638]\n",
      "[Epoch 46/100] [Batch 265/347] [D loss: 0.350164] [G loss: 0.367422]\n",
      "[Epoch 46/100] [Batch 266/347] [D loss: 0.372991] [G loss: 0.366780]\n",
      "[Epoch 46/100] [Batch 267/347] [D loss: 0.375045] [G loss: 0.367389]\n",
      "[Epoch 46/100] [Batch 268/347] [D loss: 0.327021] [G loss: 0.375310]\n",
      "[Epoch 46/100] [Batch 269/347] [D loss: 0.330050] [G loss: 0.380460]\n",
      "[Epoch 46/100] [Batch 270/347] [D loss: 0.390574] [G loss: 0.380591]\n",
      "[Epoch 46/100] [Batch 271/347] [D loss: 0.431819] [G loss: 0.379847]\n",
      "[Epoch 46/100] [Batch 272/347] [D loss: 0.469095] [G loss: 0.383600]\n",
      "[Epoch 46/100] [Batch 273/347] [D loss: 0.364222] [G loss: 0.394015]\n",
      "[Epoch 46/100] [Batch 274/347] [D loss: 0.593920] [G loss: 0.418553]\n",
      "[Epoch 46/100] [Batch 275/347] [D loss: 0.554454] [G loss: 0.434032]\n",
      "[Epoch 46/100] [Batch 276/347] [D loss: 0.369300] [G loss: 0.430315]\n",
      "[Epoch 46/100] [Batch 277/347] [D loss: 0.375065] [G loss: 0.436857]\n",
      "[Epoch 46/100] [Batch 278/347] [D loss: 0.498779] [G loss: 0.457559]\n",
      "[Epoch 46/100] [Batch 279/347] [D loss: 0.477892] [G loss: 0.457615]\n",
      "[Epoch 46/100] [Batch 280/347] [D loss: 0.462241] [G loss: 0.461466]\n",
      "[Epoch 46/100] [Batch 281/347] [D loss: 0.464317] [G loss: 0.462016]\n",
      "[Epoch 46/100] [Batch 282/347] [D loss: 0.475683] [G loss: 0.463796]\n",
      "[Epoch 46/100] [Batch 283/347] [D loss: 0.399054] [G loss: 0.461535]\n",
      "[Epoch 46/100] [Batch 284/347] [D loss: 0.386799] [G loss: 0.462165]\n",
      "[Epoch 46/100] [Batch 285/347] [D loss: 0.467511] [G loss: 0.463839]\n",
      "[Epoch 46/100] [Batch 286/347] [D loss: 0.524926] [G loss: 0.461557]\n",
      "[Epoch 46/100] [Batch 287/347] [D loss: 0.527695] [G loss: 0.455503]\n",
      "[Epoch 46/100] [Batch 288/347] [D loss: 0.518063] [G loss: 0.431955]\n",
      "[Epoch 46/100] [Batch 289/347] [D loss: 0.517430] [G loss: 0.424403]\n",
      "[Epoch 46/100] [Batch 290/347] [D loss: 0.532043] [G loss: 0.437622]\n",
      "[Epoch 46/100] [Batch 291/347] [D loss: 0.500173] [G loss: 0.431038]\n",
      "[Epoch 46/100] [Batch 292/347] [D loss: 0.485197] [G loss: 0.434863]\n",
      "[Epoch 46/100] [Batch 293/347] [D loss: 0.425714] [G loss: 0.451942]\n",
      "[Epoch 46/100] [Batch 294/347] [D loss: 0.366715] [G loss: 0.450336]\n",
      "[Epoch 46/100] [Batch 295/347] [D loss: 0.217669] [G loss: 0.433984]\n",
      "[Epoch 46/100] [Batch 296/347] [D loss: 0.206657] [G loss: 0.436925]\n",
      "[Epoch 46/100] [Batch 297/347] [D loss: 0.487648] [G loss: 0.451091]\n",
      "[Epoch 46/100] [Batch 298/347] [D loss: 0.555489] [G loss: 0.444013]\n",
      "[Epoch 46/100] [Batch 299/347] [D loss: 0.501818] [G loss: 0.441045]\n",
      "[Epoch 46/100] [Batch 300/347] [D loss: 0.440688] [G loss: 0.433883]\n",
      "[Epoch 46/100] [Batch 301/347] [D loss: 0.450010] [G loss: 0.426480]\n",
      "[Epoch 46/100] [Batch 302/347] [D loss: 0.512276] [G loss: 0.429287]\n",
      "[Epoch 46/100] [Batch 303/347] [D loss: 0.480024] [G loss: 0.402884]\n",
      "[Epoch 46/100] [Batch 304/347] [D loss: 0.485591] [G loss: 0.384227]\n",
      "[Epoch 46/100] [Batch 305/347] [D loss: 0.512686] [G loss: 0.383012]\n",
      "[Epoch 46/100] [Batch 306/347] [D loss: 0.301797] [G loss: 0.371245]\n",
      "[Epoch 46/100] [Batch 307/347] [D loss: 0.231774] [G loss: 0.373387]\n",
      "[Epoch 46/100] [Batch 308/347] [D loss: 0.312603] [G loss: 0.374087]\n",
      "[Epoch 46/100] [Batch 309/347] [D loss: 0.488099] [G loss: 0.392361]\n",
      "[Epoch 46/100] [Batch 310/347] [D loss: 0.566113] [G loss: 0.420715]\n",
      "[Epoch 46/100] [Batch 311/347] [D loss: 0.566902] [G loss: 0.425429]\n",
      "[Epoch 46/100] [Batch 312/347] [D loss: 0.564108] [G loss: 0.427746]\n",
      "[Epoch 46/100] [Batch 313/347] [D loss: 0.550999] [G loss: 0.429765]\n",
      "[Epoch 46/100] [Batch 314/347] [D loss: 0.495221] [G loss: 0.425492]\n",
      "[Epoch 46/100] [Batch 315/347] [D loss: 0.432256] [G loss: 0.417572]\n",
      "[Epoch 46/100] [Batch 316/347] [D loss: 0.429934] [G loss: 0.401540]\n",
      "[Epoch 46/100] [Batch 317/347] [D loss: 0.497871] [G loss: 0.390995]\n",
      "[Epoch 46/100] [Batch 318/347] [D loss: 0.538919] [G loss: 0.407424]\n",
      "[Epoch 46/100] [Batch 319/347] [D loss: 0.539979] [G loss: 0.440626]\n",
      "[Epoch 46/100] [Batch 320/347] [D loss: 0.530670] [G loss: 0.454630]\n",
      "[Epoch 46/100] [Batch 321/347] [D loss: 0.509239] [G loss: 0.443993]\n",
      "[Epoch 46/100] [Batch 322/347] [D loss: 0.508902] [G loss: 0.430627]\n",
      "[Epoch 46/100] [Batch 323/347] [D loss: 0.466959] [G loss: 0.428830]\n",
      "[Epoch 46/100] [Batch 324/347] [D loss: 0.454037] [G loss: 0.430286]\n",
      "[Epoch 46/100] [Batch 325/347] [D loss: 0.348990] [G loss: 0.418442]\n",
      "[Epoch 46/100] [Batch 326/347] [D loss: 0.321249] [G loss: 0.405929]\n",
      "[Epoch 46/100] [Batch 327/347] [D loss: 0.411667] [G loss: 0.403941]\n",
      "[Epoch 46/100] [Batch 328/347] [D loss: 0.465644] [G loss: 0.401547]\n",
      "[Epoch 46/100] [Batch 329/347] [D loss: 0.364186] [G loss: 0.388097]\n",
      "[Epoch 46/100] [Batch 330/347] [D loss: 0.350420] [G loss: 0.380717]\n",
      "[Epoch 46/100] [Batch 331/347] [D loss: 0.440307] [G loss: 0.388151]\n",
      "[Epoch 46/100] [Batch 332/347] [D loss: 0.540335] [G loss: 0.411442]\n",
      "[Epoch 46/100] [Batch 333/347] [D loss: 0.556032] [G loss: 0.423220]\n",
      "[Epoch 46/100] [Batch 334/347] [D loss: 0.516445] [G loss: 0.425060]\n",
      "[Epoch 46/100] [Batch 335/347] [D loss: 0.482044] [G loss: 0.413410]\n",
      "[Epoch 46/100] [Batch 336/347] [D loss: 0.478423] [G loss: 0.399195]\n",
      "[Epoch 46/100] [Batch 337/347] [D loss: 0.471756] [G loss: 0.405224]\n",
      "[Epoch 46/100] [Batch 338/347] [D loss: 0.501586] [G loss: 0.420267]\n",
      "[Epoch 46/100] [Batch 339/347] [D loss: 0.555208] [G loss: 0.427169]\n",
      "[Epoch 46/100] [Batch 340/347] [D loss: 0.565173] [G loss: 0.429848]\n",
      "[Epoch 46/100] [Batch 341/347] [D loss: 0.539554] [G loss: 0.428025]\n",
      "[Epoch 46/100] [Batch 342/347] [D loss: 0.531761] [G loss: 0.423478]\n",
      "[Epoch 46/100] [Batch 343/347] [D loss: 0.554756] [G loss: 0.431852]\n",
      "[Epoch 46/100] [Batch 344/347] [D loss: 0.446521] [G loss: 0.423652]\n",
      "[Epoch 46/100] [Batch 345/347] [D loss: 0.376518] [G loss: 0.400882]\n",
      "[Epoch 46/100] [Batch 346/347] [D loss: 0.332166] [G loss: 0.403119]\n",
      "[Epoch 46/100] [Batch 347/347] [D loss: 0.233047] [G loss: 0.417707]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 47/100] [Batch 1/347] [D loss: 0.531904] [G loss: 0.434771]\n",
      "[Epoch 47/100] [Batch 2/347] [D loss: 0.541656] [G loss: 0.441781]\n",
      "[Epoch 47/100] [Batch 3/347] [D loss: 0.565997] [G loss: 0.457045]\n",
      "[Epoch 47/100] [Batch 4/347] [D loss: 0.566737] [G loss: 0.462838]\n",
      "[Epoch 47/100] [Batch 5/347] [D loss: 0.564777] [G loss: 0.466101]\n",
      "[Epoch 47/100] [Batch 6/347] [D loss: 0.568565] [G loss: 0.472175]\n",
      "[Epoch 47/100] [Batch 7/347] [D loss: 0.565340] [G loss: 0.471040]\n",
      "[Epoch 47/100] [Batch 8/347] [D loss: 0.550881] [G loss: 0.469768]\n",
      "[Epoch 47/100] [Batch 9/347] [D loss: 0.536612] [G loss: 0.461442]\n",
      "[Epoch 47/100] [Batch 10/347] [D loss: 0.540984] [G loss: 0.463950]\n",
      "[Epoch 47/100] [Batch 11/347] [D loss: 0.561525] [G loss: 0.479504]\n",
      "[Epoch 47/100] [Batch 12/347] [D loss: 0.567110] [G loss: 0.485241]\n",
      "[Epoch 47/100] [Batch 13/347] [D loss: 0.569544] [G loss: 0.489476]\n",
      "[Epoch 47/100] [Batch 14/347] [D loss: 0.566015] [G loss: 0.492015]\n",
      "[Epoch 47/100] [Batch 15/347] [D loss: 0.554470] [G loss: 0.488085]\n",
      "[Epoch 47/100] [Batch 16/347] [D loss: 0.544449] [G loss: 0.483650]\n",
      "[Epoch 47/100] [Batch 17/347] [D loss: 0.531293] [G loss: 0.471178]\n",
      "[Epoch 47/100] [Batch 18/347] [D loss: 0.504374] [G loss: 0.467280]\n",
      "[Epoch 47/100] [Batch 19/347] [D loss: 0.510857] [G loss: 0.473953]\n",
      "[Epoch 47/100] [Batch 20/347] [D loss: 0.559429] [G loss: 0.485689]\n",
      "[Epoch 47/100] [Batch 21/347] [D loss: 0.562837] [G loss: 0.480205]\n",
      "[Epoch 47/100] [Batch 22/347] [D loss: 0.552001] [G loss: 0.473594]\n",
      "[Epoch 47/100] [Batch 23/347] [D loss: 0.520285] [G loss: 0.465369]\n",
      "[Epoch 47/100] [Batch 24/347] [D loss: 0.516902] [G loss: 0.462259]\n",
      "[Epoch 47/100] [Batch 25/347] [D loss: 0.539596] [G loss: 0.459585]\n",
      "[Epoch 47/100] [Batch 26/347] [D loss: 0.468925] [G loss: 0.445611]\n",
      "[Epoch 47/100] [Batch 27/347] [D loss: 0.252633] [G loss: 0.458438]\n",
      "[Epoch 47/100] [Batch 28/347] [D loss: 0.264148] [G loss: 0.463570]\n",
      "[Epoch 47/100] [Batch 29/347] [D loss: 0.508878] [G loss: 0.457885]\n",
      "[Epoch 47/100] [Batch 30/347] [D loss: 0.458778] [G loss: 0.460349]\n",
      "[Epoch 47/100] [Batch 31/347] [D loss: 0.392429] [G loss: 0.457247]\n",
      "[Epoch 47/100] [Batch 32/347] [D loss: 0.303977] [G loss: 0.444268]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 47/100] [Batch 33/347] [D loss: 0.319169] [G loss: 0.433527]\n",
      "[Epoch 47/100] [Batch 34/347] [D loss: 0.413186] [G loss: 0.427123]\n",
      "[Epoch 47/100] [Batch 35/347] [D loss: 0.389721] [G loss: 0.417153]\n",
      "[Epoch 47/100] [Batch 36/347] [D loss: 0.472645] [G loss: 0.399583]\n",
      "[Epoch 47/100] [Batch 37/347] [D loss: 0.411386] [G loss: 0.382962]\n",
      "[Epoch 47/100] [Batch 38/347] [D loss: 0.358537] [G loss: 0.361245]\n",
      "[Epoch 47/100] [Batch 39/347] [D loss: 0.412120] [G loss: 0.348931]\n",
      "[Epoch 47/100] [Batch 40/347] [D loss: 0.515650] [G loss: 0.342425]\n",
      "[Epoch 47/100] [Batch 41/347] [D loss: 0.526799] [G loss: 0.335107]\n",
      "[Epoch 47/100] [Batch 42/347] [D loss: 0.522261] [G loss: 0.334722]\n",
      "[Epoch 47/100] [Batch 43/347] [D loss: 0.496044] [G loss: 0.346750]\n",
      "[Epoch 47/100] [Batch 44/347] [D loss: 0.490611] [G loss: 0.361134]\n",
      "[Epoch 47/100] [Batch 45/347] [D loss: 0.520776] [G loss: 0.377322]\n",
      "[Epoch 47/100] [Batch 46/347] [D loss: 0.519606] [G loss: 0.371662]\n",
      "[Epoch 47/100] [Batch 47/347] [D loss: 0.505993] [G loss: 0.347214]\n",
      "[Epoch 47/100] [Batch 48/347] [D loss: 0.336729] [G loss: 0.338558]\n",
      "[Epoch 47/100] [Batch 49/347] [D loss: 0.337674] [G loss: 0.341437]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 47/100] [Batch 50/347] [D loss: 0.283108] [G loss: 0.355936]\n",
      "[Epoch 47/100] [Batch 51/347] [D loss: 0.267143] [G loss: 0.375057]\n",
      "[Epoch 47/100] [Batch 52/347] [D loss: 0.374636] [G loss: 0.380975]\n",
      "[Epoch 47/100] [Batch 53/347] [D loss: 0.471245] [G loss: 0.381236]\n",
      "[Epoch 47/100] [Batch 54/347] [D loss: 0.410419] [G loss: 0.372149]\n",
      "[Epoch 47/100] [Batch 55/347] [D loss: 0.402368] [G loss: 0.349614]\n",
      "[Epoch 47/100] [Batch 56/347] [D loss: 0.395877] [G loss: 0.355271]\n",
      "[Epoch 47/100] [Batch 57/347] [D loss: 0.387808] [G loss: 0.386996]\n",
      "[Epoch 47/100] [Batch 58/347] [D loss: 0.404384] [G loss: 0.399619]\n",
      "[Epoch 47/100] [Batch 59/347] [D loss: 0.382704] [G loss: 0.399763]\n",
      "[Epoch 47/100] [Batch 60/347] [D loss: 0.357037] [G loss: 0.396787]\n",
      "[Epoch 47/100] [Batch 61/347] [D loss: 0.317330] [G loss: 0.394947]\n",
      "[Epoch 47/100] [Batch 62/347] [D loss: 0.337943] [G loss: 0.380443]\n",
      "[Epoch 47/100] [Batch 63/347] [D loss: 0.389634] [G loss: 0.358267]\n",
      "[Epoch 47/100] [Batch 64/347] [D loss: 0.413983] [G loss: 0.378635]\n",
      "[Epoch 47/100] [Batch 65/347] [D loss: 0.488299] [G loss: 0.397902]\n",
      "[Epoch 47/100] [Batch 66/347] [D loss: 0.402583] [G loss: 0.397098]\n",
      "[Epoch 47/100] [Batch 67/347] [D loss: 0.226952] [G loss: 0.391904]\n",
      "[Epoch 47/100] [Batch 68/347] [D loss: 0.254469] [G loss: 0.389157]\n",
      "[Epoch 47/100] [Batch 69/347] [D loss: 0.382037] [G loss: 0.373334]\n",
      "[Epoch 47/100] [Batch 70/347] [D loss: 0.385900] [G loss: 0.364720]\n",
      "[Epoch 47/100] [Batch 71/347] [D loss: 0.369575] [G loss: 0.376688]\n",
      "[Epoch 47/100] [Batch 72/347] [D loss: 0.365318] [G loss: 0.375799]\n",
      "[Epoch 47/100] [Batch 73/347] [D loss: 0.368062] [G loss: 0.381815]\n",
      "[Epoch 47/100] [Batch 74/347] [D loss: 0.370938] [G loss: 0.400430]\n",
      "[Epoch 47/100] [Batch 75/347] [D loss: 0.398501] [G loss: 0.390694]\n",
      "[Epoch 47/100] [Batch 76/347] [D loss: 0.428249] [G loss: 0.368245]\n",
      "[Epoch 47/100] [Batch 77/347] [D loss: 0.410311] [G loss: 0.378287]\n",
      "[Epoch 47/100] [Batch 78/347] [D loss: 0.404550] [G loss: 0.393826]\n",
      "[Epoch 47/100] [Batch 79/347] [D loss: 0.507636] [G loss: 0.400859]\n",
      "[Epoch 47/100] [Batch 80/347] [D loss: 0.546921] [G loss: 0.395866]\n",
      "[Epoch 47/100] [Batch 81/347] [D loss: 0.527724] [G loss: 0.398971]\n",
      "[Epoch 47/100] [Batch 82/347] [D loss: 0.424773] [G loss: 0.391459]\n",
      "[Epoch 47/100] [Batch 83/347] [D loss: 0.408461] [G loss: 0.387506]\n",
      "[Epoch 47/100] [Batch 84/347] [D loss: 0.489041] [G loss: 0.398141]\n",
      "[Epoch 47/100] [Batch 85/347] [D loss: 0.566480] [G loss: 0.399449]\n",
      "[Epoch 47/100] [Batch 86/347] [D loss: 0.564381] [G loss: 0.395541]\n",
      "[Epoch 47/100] [Batch 87/347] [D loss: 0.563566] [G loss: 0.395937]\n",
      "[Epoch 47/100] [Batch 88/347] [D loss: 0.568575] [G loss: 0.402977]\n",
      "[Epoch 47/100] [Batch 89/347] [D loss: 0.576146] [G loss: 0.411452]\n",
      "[Epoch 47/100] [Batch 90/347] [D loss: 0.572220] [G loss: 0.413140]\n",
      "[Epoch 47/100] [Batch 91/347] [D loss: 0.570565] [G loss: 0.417627]\n",
      "[Epoch 47/100] [Batch 92/347] [D loss: 0.571929] [G loss: 0.425987]\n",
      "[Epoch 47/100] [Batch 93/347] [D loss: 0.569860] [G loss: 0.430750]\n",
      "[Epoch 47/100] [Batch 94/347] [D loss: 0.562242] [G loss: 0.434208]\n",
      "[Epoch 47/100] [Batch 95/347] [D loss: 0.561286] [G loss: 0.441508]\n",
      "[Epoch 47/100] [Batch 96/347] [D loss: 0.558229] [G loss: 0.443064]\n",
      "[Epoch 47/100] [Batch 97/347] [D loss: 0.555029] [G loss: 0.444089]\n",
      "[Epoch 47/100] [Batch 98/347] [D loss: 0.560487] [G loss: 0.454719]\n",
      "[Epoch 47/100] [Batch 99/347] [D loss: 0.561054] [G loss: 0.463524]\n",
      "[Epoch 47/100] [Batch 100/347] [D loss: 0.539784] [G loss: 0.464469]\n",
      "[Epoch 47/100] [Batch 101/347] [D loss: 0.541168] [G loss: 0.463156]\n",
      "[Epoch 47/100] [Batch 102/347] [D loss: 0.560343] [G loss: 0.468265]\n",
      "[Epoch 47/100] [Batch 103/347] [D loss: 0.559891] [G loss: 0.472256]\n",
      "[Epoch 47/100] [Batch 104/347] [D loss: 0.556518] [G loss: 0.465962]\n",
      "[Epoch 47/100] [Batch 105/347] [D loss: 0.557294] [G loss: 0.467468]\n",
      "[Epoch 47/100] [Batch 106/347] [D loss: 0.545357] [G loss: 0.468239]\n",
      "[Epoch 47/100] [Batch 107/347] [D loss: 0.474564] [G loss: 0.458327]\n",
      "[Epoch 47/100] [Batch 108/347] [D loss: 0.195660] [G loss: 0.468578]\n",
      "[Epoch 47/100] [Batch 109/347] [D loss: 0.196190] [G loss: 0.474838]\n",
      "[Epoch 47/100] [Batch 110/347] [D loss: 0.442486] [G loss: 0.472270]\n",
      "[Epoch 47/100] [Batch 111/347] [D loss: 0.256541] [G loss: 0.469128]\n",
      "[Epoch 47/100] [Batch 112/347] [D loss: 0.196723] [G loss: 0.474221]\n",
      "[Epoch 47/100] [Batch 113/347] [D loss: 0.429596] [G loss: 0.486785]\n",
      "[Epoch 47/100] [Batch 114/347] [D loss: 0.497473] [G loss: 0.506534]\n",
      "[Epoch 47/100] [Batch 115/347] [D loss: 0.479143] [G loss: 0.506322]\n",
      "[Epoch 47/100] [Batch 116/347] [D loss: 0.503462] [G loss: 0.498609]\n",
      "[Epoch 47/100] [Batch 117/347] [D loss: 0.493434] [G loss: 0.469696]\n",
      "[Epoch 47/100] [Batch 118/347] [D loss: 0.416705] [G loss: 0.450222]\n",
      "[Epoch 47/100] [Batch 119/347] [D loss: 0.361830] [G loss: 0.440216]\n",
      "[Epoch 47/100] [Batch 120/347] [D loss: 0.295958] [G loss: 0.440578]\n",
      "[Epoch 47/100] [Batch 121/347] [D loss: 0.279368] [G loss: 0.435665]\n",
      "[Epoch 47/100] [Batch 122/347] [D loss: 0.440420] [G loss: 0.436535]\n",
      "[Epoch 47/100] [Batch 123/347] [D loss: 0.531246] [G loss: 0.434355]\n",
      "[Epoch 47/100] [Batch 124/347] [D loss: 0.531692] [G loss: 0.424866]\n",
      "[Epoch 47/100] [Batch 125/347] [D loss: 0.532547] [G loss: 0.431087]\n",
      "[Epoch 47/100] [Batch 126/347] [D loss: 0.497358] [G loss: 0.438270]\n",
      "[Epoch 47/100] [Batch 127/347] [D loss: 0.479142] [G loss: 0.433667]\n",
      "[Epoch 47/100] [Batch 128/347] [D loss: 0.476552] [G loss: 0.422042]\n",
      "[Epoch 47/100] [Batch 129/347] [D loss: 0.375935] [G loss: 0.410275]\n",
      "[Epoch 47/100] [Batch 130/347] [D loss: 0.362634] [G loss: 0.401557]\n",
      "[Epoch 47/100] [Batch 131/347] [D loss: 0.315757] [G loss: 0.394380]\n",
      "[Epoch 47/100] [Batch 132/347] [D loss: 0.246718] [G loss: 0.394099]\n",
      "[Epoch 47/100] [Batch 133/347] [D loss: 0.245473] [G loss: 0.393697]\n",
      "[Epoch 47/100] [Batch 134/347] [D loss: 0.243546] [G loss: 0.399242]\n",
      "[Epoch 47/100] [Batch 135/347] [D loss: 0.260949] [G loss: 0.416072]\n",
      "[Epoch 47/100] [Batch 136/347] [D loss: 0.250812] [G loss: 0.431914]\n",
      "[Epoch 47/100] [Batch 137/347] [D loss: 0.438517] [G loss: 0.430908]\n",
      "[Epoch 47/100] [Batch 138/347] [D loss: 0.424167] [G loss: 0.426766]\n",
      "[Epoch 47/100] [Batch 139/347] [D loss: 0.403019] [G loss: 0.417393]\n",
      "[Epoch 47/100] [Batch 140/347] [D loss: 0.364906] [G loss: 0.418242]\n",
      "[Epoch 47/100] [Batch 141/347] [D loss: 0.370401] [G loss: 0.412957]\n",
      "[Epoch 47/100] [Batch 142/347] [D loss: 0.382825] [G loss: 0.410384]\n",
      "[Epoch 47/100] [Batch 143/347] [D loss: 0.333195] [G loss: 0.402232]\n",
      "[Epoch 47/100] [Batch 144/347] [D loss: 0.319276] [G loss: 0.389432]\n",
      "[Epoch 47/100] [Batch 145/347] [D loss: 0.310874] [G loss: 0.376956]\n",
      "[Epoch 47/100] [Batch 146/347] [D loss: 0.305282] [G loss: 0.366255]\n",
      "[Epoch 47/100] [Batch 147/347] [D loss: 0.346893] [G loss: 0.371276]\n",
      "[Epoch 47/100] [Batch 148/347] [D loss: 0.356676] [G loss: 0.370632]\n",
      "[Epoch 47/100] [Batch 149/347] [D loss: 0.391072] [G loss: 0.359470]\n",
      "[Epoch 47/100] [Batch 150/347] [D loss: 0.408461] [G loss: 0.355557]\n",
      "[Epoch 47/100] [Batch 151/347] [D loss: 0.385651] [G loss: 0.359139]\n",
      "[Epoch 47/100] [Batch 152/347] [D loss: 0.328134] [G loss: 0.355280]\n",
      "[Epoch 47/100] [Batch 153/347] [D loss: 0.290196] [G loss: 0.335515]\n",
      "[Epoch 47/100] [Batch 154/347] [D loss: 0.287214] [G loss: 0.314214]\n",
      "[Epoch 47/100] [Batch 155/347] [D loss: 0.300474] [G loss: 0.309649]\n",
      "[Epoch 47/100] [Batch 156/347] [D loss: 0.347596] [G loss: 0.317354]\n",
      "[Epoch 47/100] [Batch 157/347] [D loss: 0.332220] [G loss: 0.327313]\n",
      "[Epoch 47/100] [Batch 158/347] [D loss: 0.296408] [G loss: 0.315260]\n",
      "[Epoch 47/100] [Batch 159/347] [D loss: 0.286467] [G loss: 0.303720]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 47/100] [Batch 160/347] [D loss: 0.248766] [G loss: 0.326035]\n",
      "[Epoch 47/100] [Batch 161/347] [D loss: 0.243614] [G loss: 0.345775]\n",
      "[Epoch 47/100] [Batch 162/347] [D loss: 0.298320] [G loss: 0.350218]\n",
      "[Epoch 47/100] [Batch 163/347] [D loss: 0.310995] [G loss: 0.345754]\n",
      "[Epoch 47/100] [Batch 164/347] [D loss: 0.285866] [G loss: 0.341751]\n",
      "[Epoch 47/100] [Batch 165/347] [D loss: 0.264314] [G loss: 0.337719]\n",
      "[Epoch 47/100] [Batch 166/347] [D loss: 0.270879] [G loss: 0.352583]\n",
      "[Epoch 47/100] [Batch 167/347] [D loss: 0.251161] [G loss: 0.376809]\n",
      "[Epoch 47/100] [Batch 168/347] [D loss: 0.210235] [G loss: 0.392584]\n",
      "[Epoch 47/100] [Batch 169/347] [D loss: 0.346355] [G loss: 0.400861]\n",
      "[Epoch 47/100] [Batch 170/347] [D loss: 0.420915] [G loss: 0.414993]\n",
      "[Epoch 47/100] [Batch 171/347] [D loss: 0.491146] [G loss: 0.428518]\n",
      "[Epoch 47/100] [Batch 172/347] [D loss: 0.510527] [G loss: 0.434632]\n",
      "[Epoch 47/100] [Batch 173/347] [D loss: 0.376983] [G loss: 0.423358]\n",
      "[Epoch 47/100] [Batch 174/347] [D loss: 0.377167] [G loss: 0.419761]\n",
      "[Epoch 47/100] [Batch 175/347] [D loss: 0.515265] [G loss: 0.427960]\n",
      "[Epoch 47/100] [Batch 176/347] [D loss: 0.544019] [G loss: 0.440153]\n",
      "[Epoch 47/100] [Batch 177/347] [D loss: 0.548078] [G loss: 0.439915]\n",
      "[Epoch 47/100] [Batch 178/347] [D loss: 0.540149] [G loss: 0.432796]\n",
      "[Epoch 47/100] [Batch 179/347] [D loss: 0.533413] [G loss: 0.425162]\n",
      "[Epoch 47/100] [Batch 180/347] [D loss: 0.529271] [G loss: 0.417370]\n",
      "[Epoch 47/100] [Batch 181/347] [D loss: 0.529571] [G loss: 0.416675]\n",
      "[Epoch 47/100] [Batch 182/347] [D loss: 0.528029] [G loss: 0.413324]\n",
      "[Epoch 47/100] [Batch 183/347] [D loss: 0.525997] [G loss: 0.416253]\n",
      "[Epoch 47/100] [Batch 184/347] [D loss: 0.531497] [G loss: 0.418737]\n",
      "[Epoch 47/100] [Batch 185/347] [D loss: 0.536935] [G loss: 0.416027]\n",
      "[Epoch 47/100] [Batch 186/347] [D loss: 0.538392] [G loss: 0.414866]\n",
      "[Epoch 47/100] [Batch 187/347] [D loss: 0.535604] [G loss: 0.408921]\n",
      "[Epoch 47/100] [Batch 188/347] [D loss: 0.534387] [G loss: 0.405092]\n",
      "[Epoch 47/100] [Batch 189/347] [D loss: 0.528930] [G loss: 0.403488]\n",
      "[Epoch 47/100] [Batch 190/347] [D loss: 0.501178] [G loss: 0.390569]\n",
      "[Epoch 47/100] [Batch 191/347] [D loss: 0.451881] [G loss: 0.376110]\n",
      "[Epoch 47/100] [Batch 192/347] [D loss: 0.439317] [G loss: 0.374992]\n",
      "[Epoch 47/100] [Batch 193/347] [D loss: 0.459666] [G loss: 0.380379]\n",
      "[Epoch 47/100] [Batch 194/347] [D loss: 0.506426] [G loss: 0.372653]\n",
      "[Epoch 47/100] [Batch 195/347] [D loss: 0.533379] [G loss: 0.362740]\n",
      "[Epoch 47/100] [Batch 196/347] [D loss: 0.518537] [G loss: 0.355248]\n",
      "[Epoch 47/100] [Batch 197/347] [D loss: 0.460495] [G loss: 0.351316]\n",
      "[Epoch 47/100] [Batch 198/347] [D loss: 0.349622] [G loss: 0.348415]\n",
      "[Epoch 47/100] [Batch 199/347] [D loss: 0.360835] [G loss: 0.344884]\n",
      "[Epoch 47/100] [Batch 200/347] [D loss: 0.479713] [G loss: 0.347740]\n",
      "[Epoch 47/100] [Batch 201/347] [D loss: 0.479015] [G loss: 0.347474]\n",
      "[Epoch 47/100] [Batch 202/347] [D loss: 0.494270] [G loss: 0.341777]\n",
      "[Epoch 47/100] [Batch 203/347] [D loss: 0.547630] [G loss: 0.337555]\n",
      "[Epoch 47/100] [Batch 204/347] [D loss: 0.549003] [G loss: 0.337971]\n",
      "[Epoch 47/100] [Batch 205/347] [D loss: 0.543436] [G loss: 0.339630]\n",
      "[Epoch 47/100] [Batch 206/347] [D loss: 0.532399] [G loss: 0.344897]\n",
      "[Epoch 47/100] [Batch 207/347] [D loss: 0.523899] [G loss: 0.356474]\n",
      "[Epoch 47/100] [Batch 208/347] [D loss: 0.531164] [G loss: 0.358242]\n",
      "[Epoch 47/100] [Batch 209/347] [D loss: 0.495028] [G loss: 0.353718]\n",
      "[Epoch 47/100] [Batch 210/347] [D loss: 0.479653] [G loss: 0.360792]\n",
      "[Epoch 47/100] [Batch 211/347] [D loss: 0.514815] [G loss: 0.360568]\n",
      "[Epoch 47/100] [Batch 212/347] [D loss: 0.300952] [G loss: 0.357974]\n",
      "[Epoch 47/100] [Batch 213/347] [D loss: 0.291733] [G loss: 0.359769]\n",
      "[Epoch 47/100] [Batch 214/347] [D loss: 0.257787] [G loss: 0.376733]\n",
      "[Epoch 47/100] [Batch 215/347] [D loss: 0.246644] [G loss: 0.390298]\n",
      "[Epoch 47/100] [Batch 216/347] [D loss: 0.358147] [G loss: 0.396856]\n",
      "[Epoch 47/100] [Batch 217/347] [D loss: 0.466073] [G loss: 0.414559]\n",
      "[Epoch 47/100] [Batch 218/347] [D loss: 0.549586] [G loss: 0.439678]\n",
      "[Epoch 47/100] [Batch 219/347] [D loss: 0.501056] [G loss: 0.459634]\n",
      "[Epoch 47/100] [Batch 220/347] [D loss: 0.499709] [G loss: 0.481352]\n",
      "[Epoch 47/100] [Batch 221/347] [D loss: 0.525338] [G loss: 0.487824]\n",
      "[Epoch 47/100] [Batch 222/347] [D loss: 0.519467] [G loss: 0.483557]\n",
      "[Epoch 47/100] [Batch 223/347] [D loss: 0.524865] [G loss: 0.485651]\n",
      "[Epoch 47/100] [Batch 224/347] [D loss: 0.531506] [G loss: 0.484355]\n",
      "[Epoch 47/100] [Batch 225/347] [D loss: 0.513969] [G loss: 0.460122]\n",
      "[Epoch 47/100] [Batch 226/347] [D loss: 0.517676] [G loss: 0.438457]\n",
      "[Epoch 47/100] [Batch 227/347] [D loss: 0.530322] [G loss: 0.419252]\n",
      "[Epoch 47/100] [Batch 228/347] [D loss: 0.536035] [G loss: 0.425786]\n",
      "[Epoch 47/100] [Batch 229/347] [D loss: 0.550037] [G loss: 0.437550]\n",
      "[Epoch 47/100] [Batch 230/347] [D loss: 0.553900] [G loss: 0.441396]\n",
      "[Epoch 47/100] [Batch 231/347] [D loss: 0.549585] [G loss: 0.435369]\n",
      "[Epoch 47/100] [Batch 232/347] [D loss: 0.549119] [G loss: 0.437249]\n",
      "[Epoch 47/100] [Batch 233/347] [D loss: 0.528097] [G loss: 0.433950]\n",
      "[Epoch 47/100] [Batch 234/347] [D loss: 0.485781] [G loss: 0.434646]\n",
      "[Epoch 47/100] [Batch 235/347] [D loss: 0.477967] [G loss: 0.441841]\n",
      "[Epoch 47/100] [Batch 236/347] [D loss: 0.487626] [G loss: 0.446936]\n",
      "[Epoch 47/100] [Batch 237/347] [D loss: 0.507264] [G loss: 0.455219]\n",
      "[Epoch 47/100] [Batch 238/347] [D loss: 0.545559] [G loss: 0.455250]\n",
      "[Epoch 47/100] [Batch 239/347] [D loss: 0.530962] [G loss: 0.449642]\n",
      "[Epoch 47/100] [Batch 240/347] [D loss: 0.524760] [G loss: 0.442163]\n",
      "[Epoch 47/100] [Batch 241/347] [D loss: 0.526642] [G loss: 0.433031]\n",
      "[Epoch 47/100] [Batch 242/347] [D loss: 0.533188] [G loss: 0.428233]\n",
      "[Epoch 47/100] [Batch 243/347] [D loss: 0.544558] [G loss: 0.433538]\n",
      "[Epoch 47/100] [Batch 244/347] [D loss: 0.543938] [G loss: 0.440796]\n",
      "[Epoch 47/100] [Batch 245/347] [D loss: 0.486410] [G loss: 0.437432]\n",
      "[Epoch 47/100] [Batch 246/347] [D loss: 0.452657] [G loss: 0.417674]\n",
      "[Epoch 47/100] [Batch 247/347] [D loss: 0.494712] [G loss: 0.390317]\n",
      "[Epoch 47/100] [Batch 248/347] [D loss: 0.538816] [G loss: 0.383049]\n",
      "[Epoch 47/100] [Batch 249/347] [D loss: 0.532616] [G loss: 0.374038]\n",
      "[Epoch 47/100] [Batch 250/347] [D loss: 0.512024] [G loss: 0.390869]\n",
      "[Epoch 47/100] [Batch 251/347] [D loss: 0.482167] [G loss: 0.405673]\n",
      "[Epoch 47/100] [Batch 252/347] [D loss: 0.471969] [G loss: 0.405530]\n",
      "[Epoch 47/100] [Batch 253/347] [D loss: 0.486645] [G loss: 0.402336]\n",
      "[Epoch 47/100] [Batch 254/347] [D loss: 0.508793] [G loss: 0.402914]\n",
      "[Epoch 47/100] [Batch 255/347] [D loss: 0.452337] [G loss: 0.392779]\n",
      "[Epoch 47/100] [Batch 256/347] [D loss: 0.440125] [G loss: 0.394642]\n",
      "[Epoch 47/100] [Batch 257/347] [D loss: 0.446500] [G loss: 0.401169]\n",
      "[Epoch 47/100] [Batch 258/347] [D loss: 0.381736] [G loss: 0.385428]\n",
      "[Epoch 47/100] [Batch 259/347] [D loss: 0.367955] [G loss: 0.370287]\n",
      "[Epoch 47/100] [Batch 260/347] [D loss: 0.335463] [G loss: 0.366669]\n",
      "[Epoch 47/100] [Batch 261/347] [D loss: 0.348869] [G loss: 0.374208]\n",
      "[Epoch 47/100] [Batch 262/347] [D loss: 0.409411] [G loss: 0.369460]\n",
      "[Epoch 47/100] [Batch 263/347] [D loss: 0.372823] [G loss: 0.368221]\n",
      "[Epoch 47/100] [Batch 264/347] [D loss: 0.327701] [G loss: 0.372683]\n",
      "[Epoch 47/100] [Batch 265/347] [D loss: 0.350659] [G loss: 0.373157]\n",
      "[Epoch 47/100] [Batch 266/347] [D loss: 0.373830] [G loss: 0.372651]\n",
      "[Epoch 47/100] [Batch 267/347] [D loss: 0.375390] [G loss: 0.374049]\n",
      "[Epoch 47/100] [Batch 268/347] [D loss: 0.326894] [G loss: 0.382690]\n",
      "[Epoch 47/100] [Batch 269/347] [D loss: 0.330552] [G loss: 0.388378]\n",
      "[Epoch 47/100] [Batch 270/347] [D loss: 0.392744] [G loss: 0.388948]\n",
      "[Epoch 47/100] [Batch 271/347] [D loss: 0.434344] [G loss: 0.388569]\n",
      "[Epoch 47/100] [Batch 272/347] [D loss: 0.473352] [G loss: 0.393025]\n",
      "[Epoch 47/100] [Batch 273/347] [D loss: 0.365514] [G loss: 0.403646]\n",
      "[Epoch 47/100] [Batch 274/347] [D loss: 0.603651] [G loss: 0.428832]\n",
      "[Epoch 47/100] [Batch 275/347] [D loss: 0.562771] [G loss: 0.444523]\n",
      "[Epoch 47/100] [Batch 276/347] [D loss: 0.370532] [G loss: 0.441017]\n",
      "[Epoch 47/100] [Batch 277/347] [D loss: 0.375354] [G loss: 0.447665]\n",
      "[Epoch 47/100] [Batch 278/347] [D loss: 0.501686] [G loss: 0.468311]\n",
      "[Epoch 47/100] [Batch 279/347] [D loss: 0.480989] [G loss: 0.468330]\n",
      "[Epoch 47/100] [Batch 280/347] [D loss: 0.465573] [G loss: 0.472319]\n",
      "[Epoch 47/100] [Batch 281/347] [D loss: 0.467369] [G loss: 0.473144]\n",
      "[Epoch 47/100] [Batch 282/347] [D loss: 0.478245] [G loss: 0.475075]\n",
      "[Epoch 47/100] [Batch 283/347] [D loss: 0.400532] [G loss: 0.473160]\n",
      "[Epoch 47/100] [Batch 284/347] [D loss: 0.389116] [G loss: 0.474169]\n",
      "[Epoch 47/100] [Batch 285/347] [D loss: 0.470813] [G loss: 0.476657]\n",
      "[Epoch 47/100] [Batch 286/347] [D loss: 0.529507] [G loss: 0.475019]\n",
      "[Epoch 47/100] [Batch 287/347] [D loss: 0.532488] [G loss: 0.469375]\n",
      "[Epoch 47/100] [Batch 288/347] [D loss: 0.524435] [G loss: 0.446385]\n",
      "[Epoch 47/100] [Batch 289/347] [D loss: 0.524200] [G loss: 0.439605]\n",
      "[Epoch 47/100] [Batch 290/347] [D loss: 0.537777] [G loss: 0.453901]\n",
      "[Epoch 47/100] [Batch 291/347] [D loss: 0.507123] [G loss: 0.448127]\n",
      "[Epoch 47/100] [Batch 292/347] [D loss: 0.493020] [G loss: 0.452677]\n",
      "[Epoch 47/100] [Batch 293/347] [D loss: 0.433943] [G loss: 0.470702]\n",
      "[Epoch 47/100] [Batch 294/347] [D loss: 0.375036] [G loss: 0.469995]\n",
      "[Epoch 47/100] [Batch 295/347] [D loss: 0.215483] [G loss: 0.453696]\n",
      "[Epoch 47/100] [Batch 296/347] [D loss: 0.203048] [G loss: 0.456973]\n",
      "[Epoch 47/100] [Batch 297/347] [D loss: 0.490627] [G loss: 0.471102]\n",
      "[Epoch 47/100] [Batch 298/347] [D loss: 0.560201] [G loss: 0.463935]\n",
      "[Epoch 47/100] [Batch 299/347] [D loss: 0.508485] [G loss: 0.460980]\n",
      "[Epoch 47/100] [Batch 300/347] [D loss: 0.450056] [G loss: 0.453800]\n",
      "[Epoch 47/100] [Batch 301/347] [D loss: 0.458859] [G loss: 0.446155]\n",
      "[Epoch 47/100] [Batch 302/347] [D loss: 0.520540] [G loss: 0.449239]\n",
      "[Epoch 47/100] [Batch 303/347] [D loss: 0.489169] [G loss: 0.422252]\n",
      "[Epoch 47/100] [Batch 304/347] [D loss: 0.494070] [G loss: 0.404319]\n",
      "[Epoch 47/100] [Batch 305/347] [D loss: 0.520652] [G loss: 0.403384]\n",
      "[Epoch 47/100] [Batch 306/347] [D loss: 0.302148] [G loss: 0.391348]\n",
      "[Epoch 47/100] [Batch 307/347] [D loss: 0.226466] [G loss: 0.391487]\n",
      "[Epoch 47/100] [Batch 308/347] [D loss: 0.310667] [G loss: 0.391299]\n",
      "[Epoch 47/100] [Batch 309/347] [D loss: 0.494526] [G loss: 0.409655]\n",
      "[Epoch 47/100] [Batch 310/347] [D loss: 0.570760] [G loss: 0.437387]\n",
      "[Epoch 47/100] [Batch 311/347] [D loss: 0.571242] [G loss: 0.441528]\n",
      "[Epoch 47/100] [Batch 312/347] [D loss: 0.568522] [G loss: 0.443171]\n",
      "[Epoch 47/100] [Batch 313/347] [D loss: 0.555332] [G loss: 0.445031]\n",
      "[Epoch 47/100] [Batch 314/347] [D loss: 0.501080] [G loss: 0.440377]\n",
      "[Epoch 47/100] [Batch 315/347] [D loss: 0.438284] [G loss: 0.432166]\n",
      "[Epoch 47/100] [Batch 316/347] [D loss: 0.435525] [G loss: 0.415674]\n",
      "[Epoch 47/100] [Batch 317/347] [D loss: 0.503222] [G loss: 0.405002]\n",
      "[Epoch 47/100] [Batch 318/347] [D loss: 0.544872] [G loss: 0.421137]\n",
      "[Epoch 47/100] [Batch 319/347] [D loss: 0.544455] [G loss: 0.454251]\n",
      "[Epoch 47/100] [Batch 320/347] [D loss: 0.533771] [G loss: 0.468000]\n",
      "[Epoch 47/100] [Batch 321/347] [D loss: 0.513211] [G loss: 0.457595]\n",
      "[Epoch 47/100] [Batch 322/347] [D loss: 0.513785] [G loss: 0.444279]\n",
      "[Epoch 47/100] [Batch 323/347] [D loss: 0.471231] [G loss: 0.442401]\n",
      "[Epoch 47/100] [Batch 324/347] [D loss: 0.458018] [G loss: 0.444210]\n",
      "[Epoch 47/100] [Batch 325/347] [D loss: 0.351666] [G loss: 0.432413]\n",
      "[Epoch 47/100] [Batch 326/347] [D loss: 0.323560] [G loss: 0.419733]\n",
      "[Epoch 47/100] [Batch 327/347] [D loss: 0.415758] [G loss: 0.417325]\n",
      "[Epoch 47/100] [Batch 328/347] [D loss: 0.469992] [G loss: 0.414468]\n",
      "[Epoch 47/100] [Batch 329/347] [D loss: 0.366758] [G loss: 0.398566]\n",
      "[Epoch 47/100] [Batch 330/347] [D loss: 0.352875] [G loss: 0.390672]\n",
      "[Epoch 47/100] [Batch 331/347] [D loss: 0.444594] [G loss: 0.397411]\n",
      "[Epoch 47/100] [Batch 332/347] [D loss: 0.544717] [G loss: 0.422614]\n",
      "[Epoch 47/100] [Batch 333/347] [D loss: 0.559372] [G loss: 0.433890]\n",
      "[Epoch 47/100] [Batch 334/347] [D loss: 0.519242] [G loss: 0.435760]\n",
      "[Epoch 47/100] [Batch 335/347] [D loss: 0.484952] [G loss: 0.423879]\n",
      "[Epoch 47/100] [Batch 336/347] [D loss: 0.481575] [G loss: 0.409145]\n",
      "[Epoch 47/100] [Batch 337/347] [D loss: 0.473978] [G loss: 0.414874]\n",
      "[Epoch 47/100] [Batch 338/347] [D loss: 0.503580] [G loss: 0.429599]\n",
      "[Epoch 47/100] [Batch 339/347] [D loss: 0.558096] [G loss: 0.435621]\n",
      "[Epoch 47/100] [Batch 340/347] [D loss: 0.568116] [G loss: 0.438345]\n",
      "[Epoch 47/100] [Batch 341/347] [D loss: 0.543122] [G loss: 0.436337]\n",
      "[Epoch 47/100] [Batch 342/347] [D loss: 0.535568] [G loss: 0.431630]\n",
      "[Epoch 47/100] [Batch 343/347] [D loss: 0.557732] [G loss: 0.439676]\n",
      "[Epoch 47/100] [Batch 344/347] [D loss: 0.448666] [G loss: 0.431482]\n",
      "[Epoch 47/100] [Batch 345/347] [D loss: 0.378082] [G loss: 0.405955]\n",
      "[Epoch 47/100] [Batch 346/347] [D loss: 0.333572] [G loss: 0.407832]\n",
      "[Epoch 47/100] [Batch 347/347] [D loss: 0.234126] [G loss: 0.422493]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 1/347] [D loss: 0.533798] [G loss: 0.442523]\n",
      "[Epoch 48/100] [Batch 2/347] [D loss: 0.543780] [G loss: 0.449211]\n",
      "[Epoch 48/100] [Batch 3/347] [D loss: 0.568099] [G loss: 0.464488]\n",
      "[Epoch 48/100] [Batch 4/347] [D loss: 0.568596] [G loss: 0.470484]\n",
      "[Epoch 48/100] [Batch 5/347] [D loss: 0.566305] [G loss: 0.474288]\n",
      "[Epoch 48/100] [Batch 6/347] [D loss: 0.569755] [G loss: 0.480679]\n",
      "[Epoch 48/100] [Batch 7/347] [D loss: 0.566541] [G loss: 0.479659]\n",
      "[Epoch 48/100] [Batch 8/347] [D loss: 0.551804] [G loss: 0.478650]\n",
      "[Epoch 48/100] [Batch 9/347] [D loss: 0.537834] [G loss: 0.470670]\n",
      "[Epoch 48/100] [Batch 10/347] [D loss: 0.542136] [G loss: 0.473382]\n",
      "[Epoch 48/100] [Batch 11/347] [D loss: 0.562121] [G loss: 0.489173]\n",
      "[Epoch 48/100] [Batch 12/347] [D loss: 0.567643] [G loss: 0.494739]\n",
      "[Epoch 48/100] [Batch 13/347] [D loss: 0.569869] [G loss: 0.499561]\n",
      "[Epoch 48/100] [Batch 14/347] [D loss: 0.566270] [G loss: 0.502105]\n",
      "[Epoch 48/100] [Batch 15/347] [D loss: 0.554464] [G loss: 0.498134]\n",
      "[Epoch 48/100] [Batch 16/347] [D loss: 0.544587] [G loss: 0.493648]\n",
      "[Epoch 48/100] [Batch 17/347] [D loss: 0.531936] [G loss: 0.481320]\n",
      "[Epoch 48/100] [Batch 18/347] [D loss: 0.505610] [G loss: 0.474206]\n",
      "[Epoch 48/100] [Batch 19/347] [D loss: 0.511899] [G loss: 0.484520]\n",
      "[Epoch 48/100] [Batch 20/347] [D loss: 0.559832] [G loss: 0.496106]\n",
      "[Epoch 48/100] [Batch 21/347] [D loss: 0.563255] [G loss: 0.490784]\n",
      "[Epoch 48/100] [Batch 22/347] [D loss: 0.552448] [G loss: 0.484133]\n",
      "[Epoch 48/100] [Batch 23/347] [D loss: 0.520956] [G loss: 0.476029]\n",
      "[Epoch 48/100] [Batch 24/347] [D loss: 0.517628] [G loss: 0.473151]\n",
      "[Epoch 48/100] [Batch 25/347] [D loss: 0.540430] [G loss: 0.470562]\n",
      "[Epoch 48/100] [Batch 26/347] [D loss: 0.470500] [G loss: 0.453899]\n",
      "[Epoch 48/100] [Batch 27/347] [D loss: 0.255685] [G loss: 0.466641]\n",
      "[Epoch 48/100] [Batch 28/347] [D loss: 0.266884] [G loss: 0.471949]\n",
      "[Epoch 48/100] [Batch 29/347] [D loss: 0.509897] [G loss: 0.469111]\n",
      "[Epoch 48/100] [Batch 30/347] [D loss: 0.462749] [G loss: 0.471629]\n",
      "[Epoch 48/100] [Batch 31/347] [D loss: 0.398208] [G loss: 0.468739]\n",
      "[Epoch 48/100] [Batch 32/347] [D loss: 0.308303] [G loss: 0.455692]\n",
      "[Epoch 48/100] [Batch 33/347] [D loss: 0.321441] [G loss: 0.444959]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 34/347] [D loss: 0.416026] [G loss: 0.438625]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 35/347] [D loss: 0.391296] [G loss: 0.429073]\n",
      "[Epoch 48/100] [Batch 36/347] [D loss: 0.473189] [G loss: 0.411136]\n",
      "[Epoch 48/100] [Batch 37/347] [D loss: 0.411873] [G loss: 0.392786]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 38/347] [D loss: 0.356799] [G loss: 0.371068]\n",
      "[Epoch 48/100] [Batch 39/347] [D loss: 0.408840] [G loss: 0.357812]\n",
      "[Epoch 48/100] [Batch 40/347] [D loss: 0.513410] [G loss: 0.351852]\n",
      "[Epoch 48/100] [Batch 41/347] [D loss: 0.525068] [G loss: 0.342618]\n",
      "[Epoch 48/100] [Batch 42/347] [D loss: 0.520975] [G loss: 0.341132]\n",
      "[Epoch 48/100] [Batch 43/347] [D loss: 0.491664] [G loss: 0.351206]\n",
      "[Epoch 48/100] [Batch 44/347] [D loss: 0.484979] [G loss: 0.365453]\n",
      "[Epoch 48/100] [Batch 45/347] [D loss: 0.515919] [G loss: 0.381392]\n",
      "[Epoch 48/100] [Batch 46/347] [D loss: 0.514786] [G loss: 0.375193]\n",
      "[Epoch 48/100] [Batch 47/347] [D loss: 0.502307] [G loss: 0.348981]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 48/347] [D loss: 0.331215] [G loss: 0.339084]\n",
      "[Epoch 48/100] [Batch 49/347] [D loss: 0.332504] [G loss: 0.341298]\n",
      "[Epoch 48/100] [Batch 50/347] [D loss: 0.281725] [G loss: 0.355080]\n",
      "[Epoch 48/100] [Batch 51/347] [D loss: 0.267100] [G loss: 0.373792]\n",
      "[Epoch 48/100] [Batch 52/347] [D loss: 0.372708] [G loss: 0.379168]\n",
      "[Epoch 48/100] [Batch 53/347] [D loss: 0.466619] [G loss: 0.379505]\n",
      "[Epoch 48/100] [Batch 54/347] [D loss: 0.405288] [G loss: 0.370456]\n",
      "[Epoch 48/100] [Batch 55/347] [D loss: 0.397470] [G loss: 0.348461]\n",
      "[Epoch 48/100] [Batch 56/347] [D loss: 0.390377] [G loss: 0.354217]\n",
      "[Epoch 48/100] [Batch 57/347] [D loss: 0.380963] [G loss: 0.386297]\n",
      "[Epoch 48/100] [Batch 58/347] [D loss: 0.396926] [G loss: 0.399373]\n",
      "[Epoch 48/100] [Batch 59/347] [D loss: 0.376933] [G loss: 0.400083]\n",
      "[Epoch 48/100] [Batch 60/347] [D loss: 0.351370] [G loss: 0.397684]\n",
      "[Epoch 48/100] [Batch 61/347] [D loss: 0.310507] [G loss: 0.396079]\n",
      "[Epoch 48/100] [Batch 62/347] [D loss: 0.331519] [G loss: 0.382202]\n",
      "[Epoch 48/100] [Batch 63/347] [D loss: 0.384373] [G loss: 0.360564]\n",
      "[Epoch 48/100] [Batch 64/347] [D loss: 0.407874] [G loss: 0.381496]\n",
      "[Epoch 48/100] [Batch 65/347] [D loss: 0.482715] [G loss: 0.401656]\n",
      "[Epoch 48/100] [Batch 66/347] [D loss: 0.398405] [G loss: 0.400263]\n",
      "[Epoch 48/100] [Batch 67/347] [D loss: 0.224204] [G loss: 0.395225]\n",
      "[Epoch 48/100] [Batch 68/347] [D loss: 0.250508] [G loss: 0.392438]\n",
      "[Epoch 48/100] [Batch 69/347] [D loss: 0.375309] [G loss: 0.376052]\n",
      "[Epoch 48/100] [Batch 70/347] [D loss: 0.379188] [G loss: 0.367303]\n",
      "[Epoch 48/100] [Batch 71/347] [D loss: 0.363253] [G loss: 0.379191]\n",
      "[Epoch 48/100] [Batch 72/347] [D loss: 0.358621] [G loss: 0.378023]\n",
      "[Epoch 48/100] [Batch 73/347] [D loss: 0.361571] [G loss: 0.384174]\n",
      "[Epoch 48/100] [Batch 74/347] [D loss: 0.364791] [G loss: 0.402499]\n",
      "[Epoch 48/100] [Batch 75/347] [D loss: 0.392131] [G loss: 0.392322]\n",
      "[Epoch 48/100] [Batch 76/347] [D loss: 0.421500] [G loss: 0.369677]\n",
      "[Epoch 48/100] [Batch 77/347] [D loss: 0.401655] [G loss: 0.379297]\n",
      "[Epoch 48/100] [Batch 78/347] [D loss: 0.395285] [G loss: 0.394513]\n",
      "[Epoch 48/100] [Batch 79/347] [D loss: 0.501385] [G loss: 0.402064]\n",
      "[Epoch 48/100] [Batch 80/347] [D loss: 0.542760] [G loss: 0.396907]\n",
      "[Epoch 48/100] [Batch 81/347] [D loss: 0.521729] [G loss: 0.399359]\n",
      "[Epoch 48/100] [Batch 82/347] [D loss: 0.413533] [G loss: 0.391017]\n",
      "[Epoch 48/100] [Batch 83/347] [D loss: 0.397343] [G loss: 0.387160]\n",
      "[Epoch 48/100] [Batch 84/347] [D loss: 0.480315] [G loss: 0.397515]\n",
      "[Epoch 48/100] [Batch 85/347] [D loss: 0.562226] [G loss: 0.398344]\n",
      "[Epoch 48/100] [Batch 86/347] [D loss: 0.560157] [G loss: 0.393717]\n",
      "[Epoch 48/100] [Batch 87/347] [D loss: 0.559378] [G loss: 0.393795]\n",
      "[Epoch 48/100] [Batch 88/347] [D loss: 0.564656] [G loss: 0.400639]\n",
      "[Epoch 48/100] [Batch 89/347] [D loss: 0.572833] [G loss: 0.408314]\n",
      "[Epoch 48/100] [Batch 90/347] [D loss: 0.569190] [G loss: 0.409557]\n",
      "[Epoch 48/100] [Batch 91/347] [D loss: 0.567533] [G loss: 0.414365]\n",
      "[Epoch 48/100] [Batch 92/347] [D loss: 0.568905] [G loss: 0.422349]\n",
      "[Epoch 48/100] [Batch 93/347] [D loss: 0.566877] [G loss: 0.427120]\n",
      "[Epoch 48/100] [Batch 94/347] [D loss: 0.558998] [G loss: 0.430621]\n",
      "[Epoch 48/100] [Batch 95/347] [D loss: 0.557908] [G loss: 0.438036]\n",
      "[Epoch 48/100] [Batch 96/347] [D loss: 0.554961] [G loss: 0.440038]\n",
      "[Epoch 48/100] [Batch 97/347] [D loss: 0.551705] [G loss: 0.441177]\n",
      "[Epoch 48/100] [Batch 98/347] [D loss: 0.557153] [G loss: 0.451986]\n",
      "[Epoch 48/100] [Batch 99/347] [D loss: 0.557272] [G loss: 0.461256]\n",
      "[Epoch 48/100] [Batch 100/347] [D loss: 0.534451] [G loss: 0.462438]\n",
      "[Epoch 48/100] [Batch 101/347] [D loss: 0.536233] [G loss: 0.461396]\n",
      "[Epoch 48/100] [Batch 102/347] [D loss: 0.556737] [G loss: 0.466755]\n",
      "[Epoch 48/100] [Batch 103/347] [D loss: 0.556335] [G loss: 0.470848]\n",
      "[Epoch 48/100] [Batch 104/347] [D loss: 0.553203] [G loss: 0.464977]\n",
      "[Epoch 48/100] [Batch 105/347] [D loss: 0.553957] [G loss: 0.466485]\n",
      "[Epoch 48/100] [Batch 106/347] [D loss: 0.541378] [G loss: 0.467537]\n",
      "[Epoch 48/100] [Batch 107/347] [D loss: 0.469967] [G loss: 0.457765]\n",
      "[Epoch 48/100] [Batch 108/347] [D loss: 0.192241] [G loss: 0.467272]\n",
      "[Epoch 48/100] [Batch 109/347] [D loss: 0.192551] [G loss: 0.473735]\n",
      "[Epoch 48/100] [Batch 110/347] [D loss: 0.435505] [G loss: 0.472300]\n",
      "[Epoch 48/100] [Batch 111/347] [D loss: 0.252633] [G loss: 0.468340]\n",
      "[Epoch 48/100] [Batch 112/347] [D loss: 0.192649] [G loss: 0.473521]\n",
      "[Epoch 48/100] [Batch 113/347] [D loss: 0.425119] [G loss: 0.487214]\n",
      "[Epoch 48/100] [Batch 114/347] [D loss: 0.491758] [G loss: 0.507118]\n",
      "[Epoch 48/100] [Batch 115/347] [D loss: 0.473261] [G loss: 0.506610]\n",
      "[Epoch 48/100] [Batch 116/347] [D loss: 0.498416] [G loss: 0.498891]\n",
      "[Epoch 48/100] [Batch 117/347] [D loss: 0.488672] [G loss: 0.469812]\n",
      "[Epoch 48/100] [Batch 118/347] [D loss: 0.408619] [G loss: 0.448981]\n",
      "[Epoch 48/100] [Batch 119/347] [D loss: 0.351271] [G loss: 0.438988]\n",
      "[Epoch 48/100] [Batch 120/347] [D loss: 0.287236] [G loss: 0.439208]\n",
      "[Epoch 48/100] [Batch 121/347] [D loss: 0.270685] [G loss: 0.434376]\n",
      "[Epoch 48/100] [Batch 122/347] [D loss: 0.433838] [G loss: 0.436178]\n",
      "[Epoch 48/100] [Batch 123/347] [D loss: 0.528065] [G loss: 0.433917]\n",
      "[Epoch 48/100] [Batch 124/347] [D loss: 0.528772] [G loss: 0.424139]\n",
      "[Epoch 48/100] [Batch 125/347] [D loss: 0.529333] [G loss: 0.430199]\n",
      "[Epoch 48/100] [Batch 126/347] [D loss: 0.491000] [G loss: 0.437374]\n",
      "[Epoch 48/100] [Batch 127/347] [D loss: 0.470818] [G loss: 0.432442]\n",
      "[Epoch 48/100] [Batch 128/347] [D loss: 0.468265] [G loss: 0.420382]\n",
      "[Epoch 48/100] [Batch 129/347] [D loss: 0.364731] [G loss: 0.408248]\n",
      "[Epoch 48/100] [Batch 130/347] [D loss: 0.352835] [G loss: 0.397881]\n",
      "[Epoch 48/100] [Batch 131/347] [D loss: 0.312934] [G loss: 0.390785]\n",
      "[Epoch 48/100] [Batch 132/347] [D loss: 0.253656] [G loss: 0.390849]\n",
      "[Epoch 48/100] [Batch 133/347] [D loss: 0.249358] [G loss: 0.390823]\n",
      "[Epoch 48/100] [Batch 134/347] [D loss: 0.249205] [G loss: 0.397612]\n",
      "[Epoch 48/100] [Batch 135/347] [D loss: 0.267103] [G loss: 0.414710]\n",
      "[Epoch 48/100] [Batch 136/347] [D loss: 0.256151] [G loss: 0.431487]\n",
      "[Epoch 48/100] [Batch 137/347] [D loss: 0.433553] [G loss: 0.430817]\n",
      "[Epoch 48/100] [Batch 138/347] [D loss: 0.418191] [G loss: 0.426989]\n",
      "[Epoch 48/100] [Batch 139/347] [D loss: 0.397246] [G loss: 0.417706]\n",
      "[Epoch 48/100] [Batch 140/347] [D loss: 0.357110] [G loss: 0.418841]\n",
      "[Epoch 48/100] [Batch 141/347] [D loss: 0.362902] [G loss: 0.413736]\n",
      "[Epoch 48/100] [Batch 142/347] [D loss: 0.376478] [G loss: 0.411566]\n",
      "[Epoch 48/100] [Batch 143/347] [D loss: 0.327046] [G loss: 0.403584]\n",
      "[Epoch 48/100] [Batch 144/347] [D loss: 0.312971] [G loss: 0.391010]\n",
      "[Epoch 48/100] [Batch 145/347] [D loss: 0.303849] [G loss: 0.378768]\n",
      "[Epoch 48/100] [Batch 146/347] [D loss: 0.297932] [G loss: 0.368062]\n",
      "[Epoch 48/100] [Batch 147/347] [D loss: 0.339727] [G loss: 0.373480]\n",
      "[Epoch 48/100] [Batch 148/347] [D loss: 0.349614] [G loss: 0.373088]\n",
      "[Epoch 48/100] [Batch 149/347] [D loss: 0.385238] [G loss: 0.361978]\n",
      "[Epoch 48/100] [Batch 150/347] [D loss: 0.402866] [G loss: 0.357852]\n",
      "[Epoch 48/100] [Batch 151/347] [D loss: 0.378238] [G loss: 0.361626]\n",
      "[Epoch 48/100] [Batch 152/347] [D loss: 0.320175] [G loss: 0.357421]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 153/347] [D loss: 0.282280] [G loss: 0.337363]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 154/347] [D loss: 0.279414] [G loss: 0.315573]\n",
      "[Epoch 48/100] [Batch 155/347] [D loss: 0.291808] [G loss: 0.310659]\n",
      "[Epoch 48/100] [Batch 156/347] [D loss: 0.338926] [G loss: 0.318235]\n",
      "[Epoch 48/100] [Batch 157/347] [D loss: 0.324049] [G loss: 0.327806]\n",
      "[Epoch 48/100] [Batch 158/347] [D loss: 0.288380] [G loss: 0.315629]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 48/100] [Batch 159/347] [D loss: 0.278623] [G loss: 0.303868]\n",
      "[Epoch 48/100] [Batch 160/347] [D loss: 0.242789] [G loss: 0.325509]\n",
      "[Epoch 48/100] [Batch 161/347] [D loss: 0.238342] [G loss: 0.345392]\n",
      "[Epoch 48/100] [Batch 162/347] [D loss: 0.289898] [G loss: 0.349233]\n",
      "[Epoch 48/100] [Batch 163/347] [D loss: 0.302589] [G loss: 0.344608]\n",
      "[Epoch 48/100] [Batch 164/347] [D loss: 0.278199] [G loss: 0.340339]\n",
      "[Epoch 48/100] [Batch 165/347] [D loss: 0.256818] [G loss: 0.336624]\n",
      "[Epoch 48/100] [Batch 166/347] [D loss: 0.262636] [G loss: 0.351293]\n",
      "[Epoch 48/100] [Batch 167/347] [D loss: 0.245484] [G loss: 0.375604]\n",
      "[Epoch 48/100] [Batch 168/347] [D loss: 0.204762] [G loss: 0.391714]\n",
      "[Epoch 48/100] [Batch 169/347] [D loss: 0.336279] [G loss: 0.402308]\n",
      "[Epoch 48/100] [Batch 170/347] [D loss: 0.408763] [G loss: 0.416300]\n",
      "[Epoch 48/100] [Batch 171/347] [D loss: 0.483713] [G loss: 0.429741]\n",
      "[Epoch 48/100] [Batch 172/347] [D loss: 0.504310] [G loss: 0.435674]\n",
      "[Epoch 48/100] [Batch 173/347] [D loss: 0.363516] [G loss: 0.424144]\n",
      "[Epoch 48/100] [Batch 174/347] [D loss: 0.363486] [G loss: 0.420488]\n",
      "[Epoch 48/100] [Batch 175/347] [D loss: 0.508573] [G loss: 0.428590]\n",
      "[Epoch 48/100] [Batch 176/347] [D loss: 0.539227] [G loss: 0.440470]\n",
      "[Epoch 48/100] [Batch 177/347] [D loss: 0.543407] [G loss: 0.440008]\n",
      "[Epoch 48/100] [Batch 178/347] [D loss: 0.534922] [G loss: 0.432631]\n",
      "[Epoch 48/100] [Batch 179/347] [D loss: 0.527966] [G loss: 0.424621]\n",
      "[Epoch 48/100] [Batch 180/347] [D loss: 0.523708] [G loss: 0.416503]\n",
      "[Epoch 48/100] [Batch 181/347] [D loss: 0.523804] [G loss: 0.415452]\n",
      "[Epoch 48/100] [Batch 182/347] [D loss: 0.521833] [G loss: 0.411661]\n",
      "[Epoch 48/100] [Batch 183/347] [D loss: 0.519076] [G loss: 0.413955]\n",
      "[Epoch 48/100] [Batch 184/347] [D loss: 0.525022] [G loss: 0.416023]\n",
      "[Epoch 48/100] [Batch 185/347] [D loss: 0.531271] [G loss: 0.412629]\n",
      "[Epoch 48/100] [Batch 186/347] [D loss: 0.532981] [G loss: 0.410652]\n",
      "[Epoch 48/100] [Batch 187/347] [D loss: 0.530238] [G loss: 0.403944]\n",
      "[Epoch 48/100] [Batch 188/347] [D loss: 0.529034] [G loss: 0.399533]\n",
      "[Epoch 48/100] [Batch 189/347] [D loss: 0.522510] [G loss: 0.397441]\n",
      "[Epoch 48/100] [Batch 190/347] [D loss: 0.490802] [G loss: 0.383974]\n",
      "[Epoch 48/100] [Batch 191/347] [D loss: 0.437448] [G loss: 0.369200]\n",
      "[Epoch 48/100] [Batch 192/347] [D loss: 0.425518] [G loss: 0.368252]\n",
      "[Epoch 48/100] [Batch 193/347] [D loss: 0.446779] [G loss: 0.373185]\n",
      "[Epoch 48/100] [Batch 194/347] [D loss: 0.497992] [G loss: 0.365877]\n",
      "[Epoch 48/100] [Batch 195/347] [D loss: 0.530172] [G loss: 0.355650]\n",
      "[Epoch 48/100] [Batch 196/347] [D loss: 0.513545] [G loss: 0.348526]\n",
      "[Epoch 48/100] [Batch 197/347] [D loss: 0.451743] [G loss: 0.344641]\n",
      "[Epoch 48/100] [Batch 198/347] [D loss: 0.340605] [G loss: 0.342058]\n",
      "[Epoch 48/100] [Batch 199/347] [D loss: 0.351852] [G loss: 0.339595]\n",
      "[Epoch 48/100] [Batch 200/347] [D loss: 0.471326] [G loss: 0.342992]\n",
      "[Epoch 48/100] [Batch 201/347] [D loss: 0.469901] [G loss: 0.343590]\n",
      "[Epoch 48/100] [Batch 202/347] [D loss: 0.485642] [G loss: 0.338776]\n",
      "[Epoch 48/100] [Batch 203/347] [D loss: 0.546855] [G loss: 0.334896]\n",
      "[Epoch 48/100] [Batch 204/347] [D loss: 0.548269] [G loss: 0.335825]\n",
      "[Epoch 48/100] [Batch 205/347] [D loss: 0.541657] [G loss: 0.337630]\n",
      "[Epoch 48/100] [Batch 206/347] [D loss: 0.528974] [G loss: 0.342898]\n",
      "[Epoch 48/100] [Batch 207/347] [D loss: 0.519006] [G loss: 0.354558]\n",
      "[Epoch 48/100] [Batch 208/347] [D loss: 0.526578] [G loss: 0.355698]\n",
      "[Epoch 48/100] [Batch 209/347] [D loss: 0.487094] [G loss: 0.350890]\n",
      "[Epoch 48/100] [Batch 210/347] [D loss: 0.470488] [G loss: 0.358241]\n",
      "[Epoch 48/100] [Batch 211/347] [D loss: 0.509996] [G loss: 0.358070]\n",
      "[Epoch 48/100] [Batch 212/347] [D loss: 0.295964] [G loss: 0.355206]\n",
      "[Epoch 48/100] [Batch 213/347] [D loss: 0.289585] [G loss: 0.355307]\n",
      "[Epoch 48/100] [Batch 214/347] [D loss: 0.265744] [G loss: 0.370744]\n",
      "[Epoch 48/100] [Batch 215/347] [D loss: 0.253382] [G loss: 0.384945]\n",
      "[Epoch 48/100] [Batch 216/347] [D loss: 0.348128] [G loss: 0.392740]\n",
      "[Epoch 48/100] [Batch 217/347] [D loss: 0.460687] [G loss: 0.414457]\n",
      "[Epoch 48/100] [Batch 218/347] [D loss: 0.548371] [G loss: 0.440067]\n",
      "[Epoch 48/100] [Batch 219/347] [D loss: 0.492616] [G loss: 0.460721]\n",
      "[Epoch 48/100] [Batch 220/347] [D loss: 0.492399] [G loss: 0.482829]\n",
      "[Epoch 48/100] [Batch 221/347] [D loss: 0.521033] [G loss: 0.489225]\n",
      "[Epoch 48/100] [Batch 222/347] [D loss: 0.515593] [G loss: 0.485143]\n",
      "[Epoch 48/100] [Batch 223/347] [D loss: 0.522024] [G loss: 0.487204]\n",
      "[Epoch 48/100] [Batch 224/347] [D loss: 0.529324] [G loss: 0.485782]\n",
      "[Epoch 48/100] [Batch 225/347] [D loss: 0.510851] [G loss: 0.459339]\n",
      "[Epoch 48/100] [Batch 226/347] [D loss: 0.515312] [G loss: 0.437083]\n",
      "[Epoch 48/100] [Batch 227/347] [D loss: 0.529166] [G loss: 0.420300]\n",
      "[Epoch 48/100] [Batch 228/347] [D loss: 0.535125] [G loss: 0.426827]\n",
      "[Epoch 48/100] [Batch 229/347] [D loss: 0.550252] [G loss: 0.438697]\n",
      "[Epoch 48/100] [Batch 230/347] [D loss: 0.554467] [G loss: 0.442335]\n",
      "[Epoch 48/100] [Batch 231/347] [D loss: 0.550223] [G loss: 0.436622]\n",
      "[Epoch 48/100] [Batch 232/347] [D loss: 0.549727] [G loss: 0.438884]\n",
      "[Epoch 48/100] [Batch 233/347] [D loss: 0.526298] [G loss: 0.435778]\n",
      "[Epoch 48/100] [Batch 234/347] [D loss: 0.478978] [G loss: 0.434372]\n",
      "[Epoch 48/100] [Batch 235/347] [D loss: 0.471298] [G loss: 0.441478]\n",
      "[Epoch 48/100] [Batch 236/347] [D loss: 0.482096] [G loss: 0.448045]\n",
      "[Epoch 48/100] [Batch 237/347] [D loss: 0.503293] [G loss: 0.456242]\n",
      "[Epoch 48/100] [Batch 238/347] [D loss: 0.546205] [G loss: 0.456054]\n",
      "[Epoch 48/100] [Batch 239/347] [D loss: 0.530521] [G loss: 0.450202]\n",
      "[Epoch 48/100] [Batch 240/347] [D loss: 0.524501] [G loss: 0.442847]\n",
      "[Epoch 48/100] [Batch 241/347] [D loss: 0.527284] [G loss: 0.433895]\n",
      "[Epoch 48/100] [Batch 242/347] [D loss: 0.534847] [G loss: 0.429340]\n",
      "[Epoch 48/100] [Batch 243/347] [D loss: 0.547096] [G loss: 0.435134]\n",
      "[Epoch 48/100] [Batch 244/347] [D loss: 0.546296] [G loss: 0.442492]\n",
      "[Epoch 48/100] [Batch 245/347] [D loss: 0.483256] [G loss: 0.439621]\n",
      "[Epoch 48/100] [Batch 246/347] [D loss: 0.446059] [G loss: 0.418368]\n",
      "[Epoch 48/100] [Batch 247/347] [D loss: 0.493425] [G loss: 0.394483]\n",
      "[Epoch 48/100] [Batch 248/347] [D loss: 0.543871] [G loss: 0.387661]\n",
      "[Epoch 48/100] [Batch 249/347] [D loss: 0.537814] [G loss: 0.379728]\n",
      "[Epoch 48/100] [Batch 250/347] [D loss: 0.515370] [G loss: 0.394915]\n",
      "[Epoch 48/100] [Batch 251/347] [D loss: 0.483381] [G loss: 0.410414]\n",
      "[Epoch 48/100] [Batch 252/347] [D loss: 0.473013] [G loss: 0.413398]\n",
      "[Epoch 48/100] [Batch 253/347] [D loss: 0.488387] [G loss: 0.410837]\n",
      "[Epoch 48/100] [Batch 254/347] [D loss: 0.512642] [G loss: 0.412679]\n",
      "[Epoch 48/100] [Batch 255/347] [D loss: 0.453845] [G loss: 0.401024]\n",
      "[Epoch 48/100] [Batch 256/347] [D loss: 0.442139] [G loss: 0.403623]\n",
      "[Epoch 48/100] [Batch 257/347] [D loss: 0.447560] [G loss: 0.412995]\n",
      "[Epoch 48/100] [Batch 258/347] [D loss: 0.380578] [G loss: 0.396118]\n",
      "[Epoch 48/100] [Batch 259/347] [D loss: 0.367296] [G loss: 0.381571]\n",
      "[Epoch 48/100] [Batch 260/347] [D loss: 0.334666] [G loss: 0.378599]\n",
      "[Epoch 48/100] [Batch 261/347] [D loss: 0.348381] [G loss: 0.386070]\n",
      "[Epoch 48/100] [Batch 262/347] [D loss: 0.410059] [G loss: 0.381372]\n",
      "[Epoch 48/100] [Batch 263/347] [D loss: 0.373103] [G loss: 0.380317]\n",
      "[Epoch 48/100] [Batch 264/347] [D loss: 0.327362] [G loss: 0.384598]\n",
      "[Epoch 48/100] [Batch 265/347] [D loss: 0.351663] [G loss: 0.384242]\n",
      "[Epoch 48/100] [Batch 266/347] [D loss: 0.376524] [G loss: 0.383361]\n",
      "[Epoch 48/100] [Batch 267/347] [D loss: 0.377680] [G loss: 0.384552]\n",
      "[Epoch 48/100] [Batch 268/347] [D loss: 0.328297] [G loss: 0.392499]\n",
      "[Epoch 48/100] [Batch 269/347] [D loss: 0.332705] [G loss: 0.397784]\n",
      "[Epoch 48/100] [Batch 270/347] [D loss: 0.396985] [G loss: 0.398154]\n",
      "[Epoch 48/100] [Batch 271/347] [D loss: 0.439138] [G loss: 0.397472]\n",
      "[Epoch 48/100] [Batch 272/347] [D loss: 0.479653] [G loss: 0.401896]\n",
      "[Epoch 48/100] [Batch 273/347] [D loss: 0.368996] [G loss: 0.412725]\n",
      "[Epoch 48/100] [Batch 274/347] [D loss: 0.609754] [G loss: 0.438032]\n",
      "[Epoch 48/100] [Batch 275/347] [D loss: 0.568035] [G loss: 0.454847]\n",
      "[Epoch 48/100] [Batch 276/347] [D loss: 0.374577] [G loss: 0.452479]\n",
      "[Epoch 48/100] [Batch 277/347] [D loss: 0.379568] [G loss: 0.460557]\n",
      "[Epoch 48/100] [Batch 278/347] [D loss: 0.506510] [G loss: 0.482229]\n",
      "[Epoch 48/100] [Batch 279/347] [D loss: 0.487368] [G loss: 0.483095]\n",
      "[Epoch 48/100] [Batch 280/347] [D loss: 0.473351] [G loss: 0.487166]\n",
      "[Epoch 48/100] [Batch 281/347] [D loss: 0.475713] [G loss: 0.488292]\n",
      "[Epoch 48/100] [Batch 282/347] [D loss: 0.485498] [G loss: 0.491094]\n",
      "[Epoch 48/100] [Batch 283/347] [D loss: 0.410031] [G loss: 0.489114]\n",
      "[Epoch 48/100] [Batch 284/347] [D loss: 0.399096] [G loss: 0.490044]\n",
      "[Epoch 48/100] [Batch 285/347] [D loss: 0.477463] [G loss: 0.492358]\n",
      "[Epoch 48/100] [Batch 286/347] [D loss: 0.534038] [G loss: 0.490520]\n",
      "[Epoch 48/100] [Batch 287/347] [D loss: 0.536840] [G loss: 0.484625]\n",
      "[Epoch 48/100] [Batch 288/347] [D loss: 0.530109] [G loss: 0.461663]\n",
      "[Epoch 48/100] [Batch 289/347] [D loss: 0.529946] [G loss: 0.454595]\n",
      "[Epoch 48/100] [Batch 290/347] [D loss: 0.542282] [G loss: 0.468574]\n",
      "[Epoch 48/100] [Batch 291/347] [D loss: 0.512949] [G loss: 0.462506]\n",
      "[Epoch 48/100] [Batch 292/347] [D loss: 0.499786] [G loss: 0.466965]\n",
      "[Epoch 48/100] [Batch 293/347] [D loss: 0.440799] [G loss: 0.484851]\n",
      "[Epoch 48/100] [Batch 294/347] [D loss: 0.381643] [G loss: 0.483418]\n",
      "[Epoch 48/100] [Batch 295/347] [D loss: 0.215379] [G loss: 0.466873]\n",
      "[Epoch 48/100] [Batch 296/347] [D loss: 0.202740] [G loss: 0.469195]\n",
      "[Epoch 48/100] [Batch 297/347] [D loss: 0.493544] [G loss: 0.483084]\n",
      "[Epoch 48/100] [Batch 298/347] [D loss: 0.564051] [G loss: 0.475297]\n",
      "[Epoch 48/100] [Batch 299/347] [D loss: 0.512280] [G loss: 0.471970]\n",
      "[Epoch 48/100] [Batch 300/347] [D loss: 0.454737] [G loss: 0.464344]\n",
      "[Epoch 48/100] [Batch 301/347] [D loss: 0.463279] [G loss: 0.456241]\n",
      "[Epoch 48/100] [Batch 302/347] [D loss: 0.526272] [G loss: 0.458964]\n",
      "[Epoch 48/100] [Batch 303/347] [D loss: 0.494494] [G loss: 0.432321]\n",
      "[Epoch 48/100] [Batch 304/347] [D loss: 0.499205] [G loss: 0.413630]\n",
      "[Epoch 48/100] [Batch 305/347] [D loss: 0.527537] [G loss: 0.412723]\n",
      "[Epoch 48/100] [Batch 306/347] [D loss: 0.305238] [G loss: 0.401260]\n",
      "[Epoch 48/100] [Batch 307/347] [D loss: 0.227591] [G loss: 0.402946]\n",
      "[Epoch 48/100] [Batch 308/347] [D loss: 0.312451] [G loss: 0.402914]\n",
      "[Epoch 48/100] [Batch 309/347] [D loss: 0.500327] [G loss: 0.422038]\n",
      "[Epoch 48/100] [Batch 310/347] [D loss: 0.576559] [G loss: 0.450351]\n",
      "[Epoch 48/100] [Batch 311/347] [D loss: 0.576517] [G loss: 0.455299]\n",
      "[Epoch 48/100] [Batch 312/347] [D loss: 0.573467] [G loss: 0.457880]\n",
      "[Epoch 48/100] [Batch 313/347] [D loss: 0.560066] [G loss: 0.460425]\n",
      "[Epoch 48/100] [Batch 314/347] [D loss: 0.508336] [G loss: 0.456569]\n",
      "[Epoch 48/100] [Batch 315/347] [D loss: 0.446547] [G loss: 0.448756]\n",
      "[Epoch 48/100] [Batch 316/347] [D loss: 0.443850] [G loss: 0.432795]\n",
      "[Epoch 48/100] [Batch 317/347] [D loss: 0.510392] [G loss: 0.422378]\n",
      "[Epoch 48/100] [Batch 318/347] [D loss: 0.550947] [G loss: 0.439088]\n",
      "[Epoch 48/100] [Batch 319/347] [D loss: 0.549464] [G loss: 0.472966]\n",
      "[Epoch 48/100] [Batch 320/347] [D loss: 0.538131] [G loss: 0.487538]\n",
      "[Epoch 48/100] [Batch 321/347] [D loss: 0.519856] [G loss: 0.477618]\n",
      "[Epoch 48/100] [Batch 322/347] [D loss: 0.520987] [G loss: 0.464752]\n",
      "[Epoch 48/100] [Batch 323/347] [D loss: 0.479386] [G loss: 0.463482]\n",
      "[Epoch 48/100] [Batch 324/347] [D loss: 0.466845] [G loss: 0.465506]\n",
      "[Epoch 48/100] [Batch 325/347] [D loss: 0.357495] [G loss: 0.453572]\n",
      "[Epoch 48/100] [Batch 326/347] [D loss: 0.329193] [G loss: 0.440586]\n",
      "[Epoch 48/100] [Batch 327/347] [D loss: 0.423659] [G loss: 0.437513]\n",
      "[Epoch 48/100] [Batch 328/347] [D loss: 0.478001] [G loss: 0.434111]\n",
      "[Epoch 48/100] [Batch 329/347] [D loss: 0.372255] [G loss: 0.416609]\n",
      "[Epoch 48/100] [Batch 330/347] [D loss: 0.357678] [G loss: 0.407950]\n",
      "[Epoch 48/100] [Batch 331/347] [D loss: 0.451473] [G loss: 0.413595]\n",
      "[Epoch 48/100] [Batch 332/347] [D loss: 0.549195] [G loss: 0.438710]\n",
      "[Epoch 48/100] [Batch 333/347] [D loss: 0.562068] [G loss: 0.449395]\n",
      "[Epoch 48/100] [Batch 334/347] [D loss: 0.522835] [G loss: 0.450195]\n",
      "[Epoch 48/100] [Batch 335/347] [D loss: 0.489773] [G loss: 0.437484]\n",
      "[Epoch 48/100] [Batch 336/347] [D loss: 0.486300] [G loss: 0.422029]\n",
      "[Epoch 48/100] [Batch 337/347] [D loss: 0.477894] [G loss: 0.427126]\n",
      "[Epoch 48/100] [Batch 338/347] [D loss: 0.506845] [G loss: 0.441372]\n",
      "[Epoch 48/100] [Batch 339/347] [D loss: 0.560975] [G loss: 0.447404]\n",
      "[Epoch 48/100] [Batch 340/347] [D loss: 0.570485] [G loss: 0.449773]\n",
      "[Epoch 48/100] [Batch 341/347] [D loss: 0.546861] [G loss: 0.447433]\n",
      "[Epoch 48/100] [Batch 342/347] [D loss: 0.539673] [G loss: 0.442522]\n",
      "[Epoch 48/100] [Batch 343/347] [D loss: 0.560603] [G loss: 0.450564]\n",
      "[Epoch 48/100] [Batch 344/347] [D loss: 0.450574] [G loss: 0.442483]\n",
      "[Epoch 48/100] [Batch 345/347] [D loss: 0.380812] [G loss: 0.415247]\n",
      "[Epoch 48/100] [Batch 346/347] [D loss: 0.336242] [G loss: 0.417247]\n",
      "[Epoch 48/100] [Batch 347/347] [D loss: 0.232439] [G loss: 0.431563]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 49/100] [Batch 1/347] [D loss: 0.535601] [G loss: 0.452633]\n",
      "[Epoch 49/100] [Batch 2/347] [D loss: 0.545650] [G loss: 0.459541]\n",
      "[Epoch 49/100] [Batch 3/347] [D loss: 0.568905] [G loss: 0.474501]\n",
      "[Epoch 49/100] [Batch 4/347] [D loss: 0.569216] [G loss: 0.480186]\n",
      "[Epoch 49/100] [Batch 5/347] [D loss: 0.566889] [G loss: 0.483797]\n",
      "[Epoch 49/100] [Batch 6/347] [D loss: 0.570092] [G loss: 0.489829]\n",
      "[Epoch 49/100] [Batch 7/347] [D loss: 0.566819] [G loss: 0.488853]\n",
      "[Epoch 49/100] [Batch 8/347] [D loss: 0.552025] [G loss: 0.487449]\n",
      "[Epoch 49/100] [Batch 9/347] [D loss: 0.538571] [G loss: 0.479407]\n",
      "[Epoch 49/100] [Batch 10/347] [D loss: 0.542660] [G loss: 0.481913]\n",
      "[Epoch 49/100] [Batch 11/347] [D loss: 0.562502] [G loss: 0.497479]\n",
      "[Epoch 49/100] [Batch 12/347] [D loss: 0.567792] [G loss: 0.502817]\n",
      "[Epoch 49/100] [Batch 13/347] [D loss: 0.570128] [G loss: 0.507344]\n",
      "[Epoch 49/100] [Batch 14/347] [D loss: 0.566064] [G loss: 0.509761]\n",
      "[Epoch 49/100] [Batch 15/347] [D loss: 0.553947] [G loss: 0.505580]\n",
      "[Epoch 49/100] [Batch 16/347] [D loss: 0.543943] [G loss: 0.500764]\n",
      "[Epoch 49/100] [Batch 17/347] [D loss: 0.531589] [G loss: 0.488220]\n",
      "[Epoch 49/100] [Batch 18/347] [D loss: 0.505293] [G loss: 0.479795]\n",
      "[Epoch 49/100] [Batch 19/347] [D loss: 0.511493] [G loss: 0.491064]\n",
      "[Epoch 49/100] [Batch 20/347] [D loss: 0.559529] [G loss: 0.502830]\n",
      "[Epoch 49/100] [Batch 21/347] [D loss: 0.563288] [G loss: 0.497554]\n",
      "[Epoch 49/100] [Batch 22/347] [D loss: 0.552091] [G loss: 0.490877]\n",
      "[Epoch 49/100] [Batch 23/347] [D loss: 0.520210] [G loss: 0.482696]\n",
      "[Epoch 49/100] [Batch 24/347] [D loss: 0.516893] [G loss: 0.479870]\n",
      "[Epoch 49/100] [Batch 25/347] [D loss: 0.540216] [G loss: 0.477583]\n",
      "[Epoch 49/100] [Batch 26/347] [D loss: 0.470545] [G loss: 0.460947]\n",
      "[Epoch 49/100] [Batch 27/347] [D loss: 0.257723] [G loss: 0.473019]\n",
      "[Epoch 49/100] [Batch 28/347] [D loss: 0.269218] [G loss: 0.478638]\n",
      "[Epoch 49/100] [Batch 29/347] [D loss: 0.509837] [G loss: 0.476914]\n",
      "[Epoch 49/100] [Batch 30/347] [D loss: 0.464889] [G loss: 0.479901]\n",
      "[Epoch 49/100] [Batch 31/347] [D loss: 0.402855] [G loss: 0.477540]\n",
      "[Epoch 49/100] [Batch 32/347] [D loss: 0.313655] [G loss: 0.465121]\n",
      "[Epoch 49/100] [Batch 33/347] [D loss: 0.326305] [G loss: 0.455094]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 49/100] [Batch 34/347] [D loss: 0.421082] [G loss: 0.449817]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 49/100] [Batch 35/347] [D loss: 0.397495] [G loss: 0.441283]\n",
      "[Epoch 49/100] [Batch 36/347] [D loss: 0.476463] [G loss: 0.424933]\n",
      "[Epoch 49/100] [Batch 37/347] [D loss: 0.416689] [G loss: 0.406950]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 49/100] [Batch 38/347] [D loss: 0.361253] [G loss: 0.386211]\n",
      "[Epoch 49/100] [Batch 39/347] [D loss: 0.410645] [G loss: 0.373516]\n",
      "[Epoch 49/100] [Batch 40/347] [D loss: 0.513181] [G loss: 0.368177]\n",
      "[Epoch 49/100] [Batch 41/347] [D loss: 0.524098] [G loss: 0.358866]\n",
      "[Epoch 49/100] [Batch 42/347] [D loss: 0.519893] [G loss: 0.356500]\n",
      "[Epoch 49/100] [Batch 43/347] [D loss: 0.490396] [G loss: 0.364219]\n",
      "[Epoch 49/100] [Batch 44/347] [D loss: 0.483215] [G loss: 0.377327]\n",
      "[Epoch 49/100] [Batch 45/347] [D loss: 0.512952] [G loss: 0.390747]\n",
      "[Epoch 49/100] [Batch 46/347] [D loss: 0.511125] [G loss: 0.381981]\n",
      "[Epoch 49/100] [Batch 47/347] [D loss: 0.499873] [G loss: 0.353289]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 49/100] [Batch 48/347] [D loss: 0.326695] [G loss: 0.341752]\n",
      "[Epoch 49/100] [Batch 49/347] [D loss: 0.328259] [G loss: 0.343403]\n",
      "[Epoch 49/100] [Batch 50/347] [D loss: 0.280298] [G loss: 0.356623]\n",
      "[Epoch 49/100] [Batch 51/347] [D loss: 0.266290] [G loss: 0.374759]\n",
      "[Epoch 49/100] [Batch 52/347] [D loss: 0.369861] [G loss: 0.379900]\n",
      "[Epoch 49/100] [Batch 53/347] [D loss: 0.463047] [G loss: 0.379648]\n",
      "[Epoch 49/100] [Batch 54/347] [D loss: 0.402124] [G loss: 0.370246]\n",
      "[Epoch 49/100] [Batch 55/347] [D loss: 0.394789] [G loss: 0.347904]\n",
      "[Epoch 49/100] [Batch 56/347] [D loss: 0.386926] [G loss: 0.353784]\n",
      "[Epoch 49/100] [Batch 57/347] [D loss: 0.376249] [G loss: 0.385759]\n",
      "[Epoch 49/100] [Batch 58/347] [D loss: 0.391415] [G loss: 0.398815]\n",
      "[Epoch 49/100] [Batch 59/347] [D loss: 0.373166] [G loss: 0.399296]\n",
      "[Epoch 49/100] [Batch 60/347] [D loss: 0.347482] [G loss: 0.396961]\n",
      "[Epoch 49/100] [Batch 61/347] [D loss: 0.305543] [G loss: 0.395437]\n",
      "[Epoch 49/100] [Batch 62/347] [D loss: 0.326270] [G loss: 0.381604]\n",
      "[Epoch 49/100] [Batch 63/347] [D loss: 0.380043] [G loss: 0.360257]\n",
      "[Epoch 49/100] [Batch 64/347] [D loss: 0.402118] [G loss: 0.381121]\n",
      "[Epoch 49/100] [Batch 65/347] [D loss: 0.476074] [G loss: 0.401913]\n",
      "[Epoch 49/100] [Batch 66/347] [D loss: 0.395068] [G loss: 0.399737]\n",
      "[Epoch 49/100] [Batch 67/347] [D loss: 0.224510] [G loss: 0.394556]\n",
      "[Epoch 49/100] [Batch 68/347] [D loss: 0.248535] [G loss: 0.391702]\n",
      "[Epoch 49/100] [Batch 69/347] [D loss: 0.368178] [G loss: 0.375545]\n",
      "[Epoch 49/100] [Batch 70/347] [D loss: 0.372043] [G loss: 0.366816]\n",
      "[Epoch 49/100] [Batch 71/347] [D loss: 0.356795] [G loss: 0.378745]\n",
      "[Epoch 49/100] [Batch 72/347] [D loss: 0.351783] [G loss: 0.377627]\n",
      "[Epoch 49/100] [Batch 73/347] [D loss: 0.354836] [G loss: 0.383802]\n",
      "[Epoch 49/100] [Batch 74/347] [D loss: 0.358133] [G loss: 0.402278]\n",
      "[Epoch 49/100] [Batch 75/347] [D loss: 0.384778] [G loss: 0.391910]\n",
      "[Epoch 49/100] [Batch 76/347] [D loss: 0.413474] [G loss: 0.369251]\n",
      "[Epoch 49/100] [Batch 77/347] [D loss: 0.391830] [G loss: 0.379037]\n",
      "[Epoch 49/100] [Batch 78/347] [D loss: 0.384937] [G loss: 0.394288]\n",
      "[Epoch 49/100] [Batch 79/347] [D loss: 0.492400] [G loss: 0.401678]\n",
      "[Epoch 49/100] [Batch 80/347] [D loss: 0.535078] [G loss: 0.395986]\n",
      "[Epoch 49/100] [Batch 81/347] [D loss: 0.512237] [G loss: 0.398146]\n",
      "[Epoch 49/100] [Batch 82/347] [D loss: 0.399981] [G loss: 0.388948]\n",
      "[Epoch 49/100] [Batch 83/347] [D loss: 0.383963] [G loss: 0.384854]\n",
      "[Epoch 49/100] [Batch 84/347] [D loss: 0.468291] [G loss: 0.394899]\n",
      "[Epoch 49/100] [Batch 85/347] [D loss: 0.553721] [G loss: 0.395335]\n",
      "[Epoch 49/100] [Batch 86/347] [D loss: 0.551438] [G loss: 0.390124]\n",
      "[Epoch 49/100] [Batch 87/347] [D loss: 0.550498] [G loss: 0.389497]\n",
      "[Epoch 49/100] [Batch 88/347] [D loss: 0.556069] [G loss: 0.395245]\n",
      "[Epoch 49/100] [Batch 89/347] [D loss: 0.565272] [G loss: 0.402142]\n",
      "[Epoch 49/100] [Batch 90/347] [D loss: 0.561683] [G loss: 0.402714]\n",
      "[Epoch 49/100] [Batch 91/347] [D loss: 0.560253] [G loss: 0.406394]\n",
      "[Epoch 49/100] [Batch 92/347] [D loss: 0.562204] [G loss: 0.413241]\n",
      "[Epoch 49/100] [Batch 93/347] [D loss: 0.560477] [G loss: 0.417357]\n",
      "[Epoch 49/100] [Batch 94/347] [D loss: 0.552170] [G loss: 0.420201]\n",
      "[Epoch 49/100] [Batch 95/347] [D loss: 0.551444] [G loss: 0.427054]\n",
      "[Epoch 49/100] [Batch 96/347] [D loss: 0.548686] [G loss: 0.428659]\n",
      "[Epoch 49/100] [Batch 97/347] [D loss: 0.545517] [G loss: 0.429872]\n",
      "[Epoch 49/100] [Batch 98/347] [D loss: 0.551228] [G loss: 0.440735]\n",
      "[Epoch 49/100] [Batch 99/347] [D loss: 0.550605] [G loss: 0.450056]\n",
      "[Epoch 49/100] [Batch 100/347] [D loss: 0.525250] [G loss: 0.451220]\n",
      "[Epoch 49/100] [Batch 101/347] [D loss: 0.527826] [G loss: 0.450196]\n",
      "[Epoch 49/100] [Batch 102/347] [D loss: 0.550664] [G loss: 0.455621]\n",
      "[Epoch 49/100] [Batch 103/347] [D loss: 0.550231] [G loss: 0.459616]\n",
      "[Epoch 49/100] [Batch 104/347] [D loss: 0.547158] [G loss: 0.453838]\n",
      "[Epoch 49/100] [Batch 105/347] [D loss: 0.548143] [G loss: 0.455727]\n",
      "[Epoch 49/100] [Batch 106/347] [D loss: 0.533925] [G loss: 0.456890]\n",
      "[Epoch 49/100] [Batch 107/347] [D loss: 0.461010] [G loss: 0.447085]\n",
      "[Epoch 49/100] [Batch 108/347] [D loss: 0.191296] [G loss: 0.457821]\n",
      "[Epoch 49/100] [Batch 109/347] [D loss: 0.191043] [G loss: 0.464729]\n",
      "[Epoch 49/100] [Batch 110/347] [D loss: 0.422137] [G loss: 0.462871]\n",
      "[Epoch 49/100] [Batch 111/347] [D loss: 0.249365] [G loss: 0.459939]\n",
      "[Epoch 49/100] [Batch 112/347] [D loss: 0.189761] [G loss: 0.465865]\n",
      "[Epoch 49/100] [Batch 113/347] [D loss: 0.418405] [G loss: 0.479625]\n",
      "[Epoch 49/100] [Batch 114/347] [D loss: 0.479428] [G loss: 0.499793]\n",
      "[Epoch 49/100] [Batch 115/347] [D loss: 0.459862] [G loss: 0.499573]\n",
      "[Epoch 49/100] [Batch 116/347] [D loss: 0.488407] [G loss: 0.491809]\n",
      "[Epoch 49/100] [Batch 117/347] [D loss: 0.478302] [G loss: 0.462318]\n",
      "[Epoch 49/100] [Batch 118/347] [D loss: 0.392620] [G loss: 0.441334]\n",
      "[Epoch 49/100] [Batch 119/347] [D loss: 0.331660] [G loss: 0.431047]\n",
      "[Epoch 49/100] [Batch 120/347] [D loss: 0.272451] [G loss: 0.431315]\n",
      "[Epoch 49/100] [Batch 121/347] [D loss: 0.257349] [G loss: 0.426340]\n",
      "[Epoch 49/100] [Batch 122/347] [D loss: 0.421940] [G loss: 0.427788]\n",
      "[Epoch 49/100] [Batch 123/347] [D loss: 0.522991] [G loss: 0.425484]\n",
      "[Epoch 49/100] [Batch 124/347] [D loss: 0.524226] [G loss: 0.415958]\n",
      "[Epoch 49/100] [Batch 125/347] [D loss: 0.524588] [G loss: 0.421882]\n",
      "[Epoch 49/100] [Batch 126/347] [D loss: 0.479240] [G loss: 0.429007]\n",
      "[Epoch 49/100] [Batch 127/347] [D loss: 0.457331] [G loss: 0.423891]\n",
      "[Epoch 49/100] [Batch 128/347] [D loss: 0.455072] [G loss: 0.411899]\n",
      "[Epoch 49/100] [Batch 129/347] [D loss: 0.350651] [G loss: 0.400291]\n",
      "[Epoch 49/100] [Batch 130/347] [D loss: 0.341140] [G loss: 0.390133]\n",
      "[Epoch 49/100] [Batch 131/347] [D loss: 0.313717] [G loss: 0.384619]\n",
      "[Epoch 49/100] [Batch 132/347] [D loss: 0.267699] [G loss: 0.386388]\n",
      "[Epoch 49/100] [Batch 133/347] [D loss: 0.257734] [G loss: 0.388639]\n",
      "[Epoch 49/100] [Batch 134/347] [D loss: 0.257477] [G loss: 0.397309]\n",
      "[Epoch 49/100] [Batch 135/347] [D loss: 0.275349] [G loss: 0.416591]\n",
      "[Epoch 49/100] [Batch 136/347] [D loss: 0.260636] [G loss: 0.434471]\n",
      "[Epoch 49/100] [Batch 137/347] [D loss: 0.428834] [G loss: 0.435061]\n",
      "[Epoch 49/100] [Batch 138/347] [D loss: 0.413819] [G loss: 0.431927]\n",
      "[Epoch 49/100] [Batch 139/347] [D loss: 0.393771] [G loss: 0.423192]\n",
      "[Epoch 49/100] [Batch 140/347] [D loss: 0.352170] [G loss: 0.424846]\n",
      "[Epoch 49/100] [Batch 141/347] [D loss: 0.359010] [G loss: 0.420280]\n",
      "[Epoch 49/100] [Batch 142/347] [D loss: 0.374096] [G loss: 0.418598]\n",
      "[Epoch 49/100] [Batch 143/347] [D loss: 0.324548] [G loss: 0.411068]\n",
      "[Epoch 49/100] [Batch 144/347] [D loss: 0.310112] [G loss: 0.398795]\n",
      "[Epoch 49/100] [Batch 145/347] [D loss: 0.300175] [G loss: 0.386839]\n",
      "[Epoch 49/100] [Batch 146/347] [D loss: 0.293685] [G loss: 0.376255]\n",
      "[Epoch 49/100] [Batch 147/347] [D loss: 0.336055] [G loss: 0.381876]\n",
      "[Epoch 49/100] [Batch 148/347] [D loss: 0.345759] [G loss: 0.381236]\n",
      "[Epoch 49/100] [Batch 149/347] [D loss: 0.382531] [G loss: 0.369804]\n",
      "[Epoch 49/100] [Batch 150/347] [D loss: 0.399810] [G loss: 0.365939]\n",
      "[Epoch 49/100] [Batch 151/347] [D loss: 0.373223] [G loss: 0.368795]\n",
      "[Epoch 49/100] [Batch 152/347] [D loss: 0.313571] [G loss: 0.363886]\n",
      "[Epoch 49/100] [Batch 153/347] [D loss: 0.274991] [G loss: 0.343240]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 49/100] [Batch 154/347] [D loss: 0.271938] [G loss: 0.320638]\n",
      "[Epoch 49/100] [Batch 155/347] [D loss: 0.283350] [G loss: 0.315151]\n",
      "[Epoch 49/100] [Batch 156/347] [D loss: 0.330366] [G loss: 0.321587]\n",
      "[Epoch 49/100] [Batch 157/347] [D loss: 0.316433] [G loss: 0.330391]\n",
      "[Epoch 49/100] [Batch 158/347] [D loss: 0.280878] [G loss: 0.317517]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 49/100] [Batch 159/347] [D loss: 0.271254] [G loss: 0.305164]\n",
      "[Epoch 49/100] [Batch 160/347] [D loss: 0.237818] [G loss: 0.326183]\n",
      "[Epoch 49/100] [Batch 161/347] [D loss: 0.233857] [G loss: 0.345332]\n",
      "[Epoch 49/100] [Batch 162/347] [D loss: 0.281689] [G loss: 0.348745]\n",
      "[Epoch 49/100] [Batch 163/347] [D loss: 0.294064] [G loss: 0.344021]\n",
      "[Epoch 49/100] [Batch 164/347] [D loss: 0.270560] [G loss: 0.339336]\n",
      "[Epoch 49/100] [Batch 165/347] [D loss: 0.249502] [G loss: 0.335620]\n",
      "[Epoch 49/100] [Batch 166/347] [D loss: 0.254326] [G loss: 0.349981]\n",
      "[Epoch 49/100] [Batch 167/347] [D loss: 0.240661] [G loss: 0.375178]\n",
      "[Epoch 49/100] [Batch 168/347] [D loss: 0.199896] [G loss: 0.391018]\n",
      "[Epoch 49/100] [Batch 169/347] [D loss: 0.324648] [G loss: 0.403167]\n",
      "[Epoch 49/100] [Batch 170/347] [D loss: 0.394862] [G loss: 0.417285]\n",
      "[Epoch 49/100] [Batch 171/347] [D loss: 0.475402] [G loss: 0.430476]\n",
      "[Epoch 49/100] [Batch 172/347] [D loss: 0.497321] [G loss: 0.436243]\n",
      "[Epoch 49/100] [Batch 173/347] [D loss: 0.348784] [G loss: 0.424874]\n",
      "[Epoch 49/100] [Batch 174/347] [D loss: 0.348828] [G loss: 0.420975]\n",
      "[Epoch 49/100] [Batch 175/347] [D loss: 0.501019] [G loss: 0.429070]\n",
      "[Epoch 49/100] [Batch 176/347] [D loss: 0.534623] [G loss: 0.440710]\n",
      "[Epoch 49/100] [Batch 177/347] [D loss: 0.538972] [G loss: 0.439814]\n",
      "[Epoch 49/100] [Batch 178/347] [D loss: 0.529656] [G loss: 0.431958]\n",
      "[Epoch 49/100] [Batch 179/347] [D loss: 0.522192] [G loss: 0.423519]\n",
      "[Epoch 49/100] [Batch 180/347] [D loss: 0.517614] [G loss: 0.414943]\n",
      "[Epoch 49/100] [Batch 181/347] [D loss: 0.517391] [G loss: 0.413049]\n",
      "[Epoch 49/100] [Batch 182/347] [D loss: 0.514590] [G loss: 0.408474]\n",
      "[Epoch 49/100] [Batch 183/347] [D loss: 0.510650] [G loss: 0.409497]\n",
      "[Epoch 49/100] [Batch 184/347] [D loss: 0.517310] [G loss: 0.410317]\n",
      "[Epoch 49/100] [Batch 185/347] [D loss: 0.524803] [G loss: 0.405717]\n",
      "[Epoch 49/100] [Batch 186/347] [D loss: 0.526914] [G loss: 0.402595]\n",
      "[Epoch 49/100] [Batch 187/347] [D loss: 0.523951] [G loss: 0.394423]\n",
      "[Epoch 49/100] [Batch 188/347] [D loss: 0.522432] [G loss: 0.388634]\n",
      "[Epoch 49/100] [Batch 189/347] [D loss: 0.514111] [G loss: 0.385085]\n",
      "[Epoch 49/100] [Batch 190/347] [D loss: 0.477397] [G loss: 0.370135]\n",
      "[Epoch 49/100] [Batch 191/347] [D loss: 0.420330] [G loss: 0.354507]\n",
      "[Epoch 49/100] [Batch 192/347] [D loss: 0.409446] [G loss: 0.352914]\n",
      "[Epoch 49/100] [Batch 193/347] [D loss: 0.431199] [G loss: 0.358065]\n",
      "[Epoch 49/100] [Batch 194/347] [D loss: 0.487591] [G loss: 0.350767]\n",
      "[Epoch 49/100] [Batch 195/347] [D loss: 0.525757] [G loss: 0.340510]\n",
      "[Epoch 49/100] [Batch 196/347] [D loss: 0.506606] [G loss: 0.333202]\n",
      "[Epoch 49/100] [Batch 197/347] [D loss: 0.442327] [G loss: 0.329634]\n",
      "[Epoch 49/100] [Batch 198/347] [D loss: 0.334686] [G loss: 0.328110]\n",
      "[Epoch 49/100] [Batch 199/347] [D loss: 0.345699] [G loss: 0.327004]\n",
      "[Epoch 49/100] [Batch 200/347] [D loss: 0.462226] [G loss: 0.332225]\n",
      "[Epoch 49/100] [Batch 201/347] [D loss: 0.460189] [G loss: 0.334629]\n",
      "[Epoch 49/100] [Batch 202/347] [D loss: 0.476395] [G loss: 0.331109]\n",
      "[Epoch 49/100] [Batch 203/347] [D loss: 0.546907] [G loss: 0.328828]\n",
      "[Epoch 49/100] [Batch 204/347] [D loss: 0.548459] [G loss: 0.331105]\n",
      "[Epoch 49/100] [Batch 205/347] [D loss: 0.540568] [G loss: 0.334077]\n",
      "[Epoch 49/100] [Batch 206/347] [D loss: 0.526140] [G loss: 0.340589]\n",
      "[Epoch 49/100] [Batch 207/347] [D loss: 0.514771] [G loss: 0.352608]\n",
      "[Epoch 49/100] [Batch 208/347] [D loss: 0.523017] [G loss: 0.355022]\n",
      "[Epoch 49/100] [Batch 209/347] [D loss: 0.480416] [G loss: 0.350608]\n",
      "[Epoch 49/100] [Batch 210/347] [D loss: 0.463131] [G loss: 0.358621]\n",
      "[Epoch 49/100] [Batch 211/347] [D loss: 0.506948] [G loss: 0.358487]\n",
      "[Epoch 49/100] [Batch 212/347] [D loss: 0.292229] [G loss: 0.356695]\n",
      "[Epoch 49/100] [Batch 213/347] [D loss: 0.287533] [G loss: 0.359166]\n",
      "[Epoch 49/100] [Batch 214/347] [D loss: 0.267706] [G loss: 0.377410]\n",
      "[Epoch 49/100] [Batch 215/347] [D loss: 0.254078] [G loss: 0.392812]\n",
      "[Epoch 49/100] [Batch 216/347] [D loss: 0.341221] [G loss: 0.401610]\n",
      "[Epoch 49/100] [Batch 217/347] [D loss: 0.459030] [G loss: 0.420980]\n",
      "[Epoch 49/100] [Batch 218/347] [D loss: 0.550322] [G loss: 0.447748]\n",
      "[Epoch 49/100] [Batch 219/347] [D loss: 0.489141] [G loss: 0.468617]\n",
      "[Epoch 49/100] [Batch 220/347] [D loss: 0.489572] [G loss: 0.491262]\n",
      "[Epoch 49/100] [Batch 221/347] [D loss: 0.520586] [G loss: 0.497758]\n",
      "[Epoch 49/100] [Batch 222/347] [D loss: 0.515790] [G loss: 0.493834]\n",
      "[Epoch 49/100] [Batch 223/347] [D loss: 0.523699] [G loss: 0.495635]\n",
      "[Epoch 49/100] [Batch 224/347] [D loss: 0.531200] [G loss: 0.494648]\n",
      "[Epoch 49/100] [Batch 225/347] [D loss: 0.512661] [G loss: 0.470098]\n",
      "[Epoch 49/100] [Batch 226/347] [D loss: 0.517887] [G loss: 0.448249]\n",
      "[Epoch 49/100] [Batch 227/347] [D loss: 0.532442] [G loss: 0.429159]\n",
      "[Epoch 49/100] [Batch 228/347] [D loss: 0.538361] [G loss: 0.435677]\n",
      "[Epoch 49/100] [Batch 229/347] [D loss: 0.554359] [G loss: 0.447789]\n",
      "[Epoch 49/100] [Batch 230/347] [D loss: 0.558677] [G loss: 0.451932]\n",
      "[Epoch 49/100] [Batch 231/347] [D loss: 0.554589] [G loss: 0.446144]\n",
      "[Epoch 49/100] [Batch 232/347] [D loss: 0.554112] [G loss: 0.448813]\n",
      "[Epoch 49/100] [Batch 233/347] [D loss: 0.528592] [G loss: 0.445985]\n",
      "[Epoch 49/100] [Batch 234/347] [D loss: 0.478993] [G loss: 0.446448]\n",
      "[Epoch 49/100] [Batch 235/347] [D loss: 0.472012] [G loss: 0.453281]\n",
      "[Epoch 49/100] [Batch 236/347] [D loss: 0.483254] [G loss: 0.458404]\n",
      "[Epoch 49/100] [Batch 237/347] [D loss: 0.505873] [G loss: 0.466519]\n",
      "[Epoch 49/100] [Batch 238/347] [D loss: 0.550015] [G loss: 0.466131]\n",
      "[Epoch 49/100] [Batch 239/347] [D loss: 0.533872] [G loss: 0.460274]\n",
      "[Epoch 49/100] [Batch 240/347] [D loss: 0.528289] [G loss: 0.452995]\n",
      "[Epoch 49/100] [Batch 241/347] [D loss: 0.532020] [G loss: 0.443929]\n",
      "[Epoch 49/100] [Batch 242/347] [D loss: 0.540182] [G loss: 0.439574]\n",
      "[Epoch 49/100] [Batch 243/347] [D loss: 0.552609] [G loss: 0.445529]\n",
      "[Epoch 49/100] [Batch 244/347] [D loss: 0.551336] [G loss: 0.453659]\n",
      "[Epoch 49/100] [Batch 245/347] [D loss: 0.485247] [G loss: 0.451060]\n",
      "[Epoch 49/100] [Batch 246/347] [D loss: 0.446741] [G loss: 0.430878]\n",
      "[Epoch 49/100] [Batch 247/347] [D loss: 0.497793] [G loss: 0.405910]\n",
      "[Epoch 49/100] [Batch 248/347] [D loss: 0.551719] [G loss: 0.399781]\n",
      "[Epoch 49/100] [Batch 249/347] [D loss: 0.545718] [G loss: 0.392171]\n",
      "[Epoch 49/100] [Batch 250/347] [D loss: 0.522118] [G loss: 0.408904]\n",
      "[Epoch 49/100] [Batch 251/347] [D loss: 0.489883] [G loss: 0.424830]\n",
      "[Epoch 49/100] [Batch 252/347] [D loss: 0.479550] [G loss: 0.427030]\n",
      "[Epoch 49/100] [Batch 253/347] [D loss: 0.495009] [G loss: 0.425019]\n",
      "[Epoch 49/100] [Batch 254/347] [D loss: 0.520540] [G loss: 0.427387]\n",
      "[Epoch 49/100] [Batch 255/347] [D loss: 0.460706] [G loss: 0.416912]\n",
      "[Epoch 49/100] [Batch 256/347] [D loss: 0.449471] [G loss: 0.419950]\n",
      "[Epoch 49/100] [Batch 257/347] [D loss: 0.454008] [G loss: 0.428192]\n",
      "[Epoch 49/100] [Batch 258/347] [D loss: 0.384656] [G loss: 0.412222]\n",
      "[Epoch 49/100] [Batch 259/347] [D loss: 0.371725] [G loss: 0.397815]\n",
      "[Epoch 49/100] [Batch 260/347] [D loss: 0.338524] [G loss: 0.394697]\n",
      "[Epoch 49/100] [Batch 261/347] [D loss: 0.352522] [G loss: 0.402115]\n",
      "[Epoch 49/100] [Batch 262/347] [D loss: 0.416240] [G loss: 0.397440]\n",
      "[Epoch 49/100] [Batch 263/347] [D loss: 0.379157] [G loss: 0.396120]\n",
      "[Epoch 49/100] [Batch 264/347] [D loss: 0.332002] [G loss: 0.399832]\n",
      "[Epoch 49/100] [Batch 265/347] [D loss: 0.358086] [G loss: 0.399821]\n",
      "[Epoch 49/100] [Batch 266/347] [D loss: 0.384930] [G loss: 0.399164]\n",
      "[Epoch 49/100] [Batch 267/347] [D loss: 0.386074] [G loss: 0.399877]\n",
      "[Epoch 49/100] [Batch 268/347] [D loss: 0.334955] [G loss: 0.407814]\n",
      "[Epoch 49/100] [Batch 269/347] [D loss: 0.340022] [G loss: 0.413030]\n",
      "[Epoch 49/100] [Batch 270/347] [D loss: 0.407493] [G loss: 0.413031]\n",
      "[Epoch 49/100] [Batch 271/347] [D loss: 0.451284] [G loss: 0.412680]\n",
      "[Epoch 49/100] [Batch 272/347] [D loss: 0.493081] [G loss: 0.416993]\n",
      "[Epoch 49/100] [Batch 273/347] [D loss: 0.377689] [G loss: 0.427881]\n",
      "[Epoch 49/100] [Batch 274/347] [D loss: 0.603053] [G loss: 0.453726]\n",
      "[Epoch 49/100] [Batch 275/347] [D loss: 0.561473] [G loss: 0.470880]\n",
      "[Epoch 49/100] [Batch 276/347] [D loss: 0.384118] [G loss: 0.468542]\n",
      "[Epoch 49/100] [Batch 277/347] [D loss: 0.388944] [G loss: 0.476329]\n",
      "[Epoch 49/100] [Batch 278/347] [D loss: 0.515454] [G loss: 0.497839]\n",
      "[Epoch 49/100] [Batch 279/347] [D loss: 0.496815] [G loss: 0.498922]\n",
      "[Epoch 49/100] [Batch 280/347] [D loss: 0.483682] [G loss: 0.504390]\n",
      "[Epoch 49/100] [Batch 281/347] [D loss: 0.486025] [G loss: 0.506351]\n",
      "[Epoch 49/100] [Batch 282/347] [D loss: 0.494803] [G loss: 0.508750]\n",
      "[Epoch 49/100] [Batch 283/347] [D loss: 0.421489] [G loss: 0.508036]\n",
      "[Epoch 49/100] [Batch 284/347] [D loss: 0.411646] [G loss: 0.509723]\n",
      "[Epoch 49/100] [Batch 285/347] [D loss: 0.488532] [G loss: 0.512150]\n",
      "[Epoch 49/100] [Batch 286/347] [D loss: 0.542783] [G loss: 0.510872]\n",
      "[Epoch 49/100] [Batch 287/347] [D loss: 0.545447] [G loss: 0.505927]\n",
      "[Epoch 49/100] [Batch 288/347] [D loss: 0.540218] [G loss: 0.484064]\n",
      "[Epoch 49/100] [Batch 289/347] [D loss: 0.540160] [G loss: 0.477943]\n",
      "[Epoch 49/100] [Batch 290/347] [D loss: 0.551519] [G loss: 0.492443]\n",
      "[Epoch 49/100] [Batch 291/347] [D loss: 0.524404] [G loss: 0.487393]\n",
      "[Epoch 49/100] [Batch 292/347] [D loss: 0.513397] [G loss: 0.493180]\n",
      "[Epoch 49/100] [Batch 293/347] [D loss: 0.458592] [G loss: 0.512500]\n",
      "[Epoch 49/100] [Batch 294/347] [D loss: 0.404122] [G loss: 0.512024]\n",
      "[Epoch 49/100] [Batch 295/347] [D loss: 0.219661] [G loss: 0.496337]\n",
      "[Epoch 49/100] [Batch 296/347] [D loss: 0.204553] [G loss: 0.498299]\n",
      "[Epoch 49/100] [Batch 297/347] [D loss: 0.499785] [G loss: 0.511758]\n",
      "[Epoch 49/100] [Batch 298/347] [D loss: 0.570910] [G loss: 0.504113]\n",
      "[Epoch 49/100] [Batch 299/347] [D loss: 0.524620] [G loss: 0.500453]\n",
      "[Epoch 49/100] [Batch 300/347] [D loss: 0.475226] [G loss: 0.492792]\n",
      "[Epoch 49/100] [Batch 301/347] [D loss: 0.482399] [G loss: 0.484708]\n",
      "[Epoch 49/100] [Batch 302/347] [D loss: 0.537658] [G loss: 0.487362]\n",
      "[Epoch 49/100] [Batch 303/347] [D loss: 0.510482] [G loss: 0.461391]\n",
      "[Epoch 49/100] [Batch 304/347] [D loss: 0.514265] [G loss: 0.442825]\n",
      "[Epoch 49/100] [Batch 305/347] [D loss: 0.537749] [G loss: 0.442467]\n",
      "[Epoch 49/100] [Batch 306/347] [D loss: 0.314581] [G loss: 0.430708]\n",
      "[Epoch 49/100] [Batch 307/347] [D loss: 0.224884] [G loss: 0.431724]\n",
      "[Epoch 49/100] [Batch 308/347] [D loss: 0.313220] [G loss: 0.431126]\n",
      "[Epoch 49/100] [Batch 309/347] [D loss: 0.513811] [G loss: 0.448588]\n",
      "[Epoch 49/100] [Batch 310/347] [D loss: 0.581139] [G loss: 0.476243]\n",
      "[Epoch 49/100] [Batch 311/347] [D loss: 0.580781] [G loss: 0.480704]\n",
      "[Epoch 49/100] [Batch 312/347] [D loss: 0.577703] [G loss: 0.482659]\n",
      "[Epoch 49/100] [Batch 313/347] [D loss: 0.564899] [G loss: 0.484535]\n",
      "[Epoch 49/100] [Batch 314/347] [D loss: 0.519232] [G loss: 0.480541]\n",
      "[Epoch 49/100] [Batch 315/347] [D loss: 0.462215] [G loss: 0.472367]\n",
      "[Epoch 49/100] [Batch 316/347] [D loss: 0.459474] [G loss: 0.456054]\n",
      "[Epoch 49/100] [Batch 317/347] [D loss: 0.520650] [G loss: 0.445308]\n",
      "[Epoch 49/100] [Batch 318/347] [D loss: 0.556412] [G loss: 0.461838]\n",
      "[Epoch 49/100] [Batch 319/347] [D loss: 0.553827] [G loss: 0.495452]\n",
      "[Epoch 49/100] [Batch 320/347] [D loss: 0.542374] [G loss: 0.509885]\n",
      "[Epoch 49/100] [Batch 321/347] [D loss: 0.526589] [G loss: 0.499816]\n",
      "[Epoch 49/100] [Batch 322/347] [D loss: 0.528065] [G loss: 0.486918]\n",
      "[Epoch 49/100] [Batch 323/347] [D loss: 0.489801] [G loss: 0.485707]\n",
      "[Epoch 49/100] [Batch 324/347] [D loss: 0.478304] [G loss: 0.487809]\n",
      "[Epoch 49/100] [Batch 325/347] [D loss: 0.367962] [G loss: 0.475693]\n",
      "[Epoch 49/100] [Batch 326/347] [D loss: 0.339590] [G loss: 0.462302]\n",
      "[Epoch 49/100] [Batch 327/347] [D loss: 0.434184] [G loss: 0.458621]\n",
      "[Epoch 49/100] [Batch 328/347] [D loss: 0.487637] [G loss: 0.455102]\n",
      "[Epoch 49/100] [Batch 329/347] [D loss: 0.381127] [G loss: 0.437281]\n",
      "[Epoch 49/100] [Batch 330/347] [D loss: 0.365706] [G loss: 0.427439]\n",
      "[Epoch 49/100] [Batch 331/347] [D loss: 0.459193] [G loss: 0.432004]\n",
      "[Epoch 49/100] [Batch 332/347] [D loss: 0.551573] [G loss: 0.455513]\n",
      "[Epoch 49/100] [Batch 333/347] [D loss: 0.562346] [G loss: 0.465048]\n",
      "[Epoch 49/100] [Batch 334/347] [D loss: 0.525128] [G loss: 0.464991]\n",
      "[Epoch 49/100] [Batch 335/347] [D loss: 0.494770] [G loss: 0.451618]\n",
      "[Epoch 49/100] [Batch 336/347] [D loss: 0.491359] [G loss: 0.435531]\n",
      "[Epoch 49/100] [Batch 337/347] [D loss: 0.482311] [G loss: 0.440305]\n",
      "[Epoch 49/100] [Batch 338/347] [D loss: 0.509800] [G loss: 0.453849]\n",
      "[Epoch 49/100] [Batch 339/347] [D loss: 0.561099] [G loss: 0.459777]\n",
      "[Epoch 49/100] [Batch 340/347] [D loss: 0.570013] [G loss: 0.462029]\n",
      "[Epoch 49/100] [Batch 341/347] [D loss: 0.548119] [G loss: 0.459654]\n",
      "[Epoch 49/100] [Batch 342/347] [D loss: 0.541594] [G loss: 0.454732]\n",
      "[Epoch 49/100] [Batch 343/347] [D loss: 0.560583] [G loss: 0.463434]\n",
      "[Epoch 49/100] [Batch 344/347] [D loss: 0.452286] [G loss: 0.454903]\n",
      "[Epoch 49/100] [Batch 345/347] [D loss: 0.384929] [G loss: 0.428929]\n",
      "[Epoch 49/100] [Batch 346/347] [D loss: 0.339242] [G loss: 0.430423]\n",
      "[Epoch 49/100] [Batch 347/347] [D loss: 0.227609] [G loss: 0.444343]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 50/100] [Batch 1/347] [D loss: 0.534981] [G loss: 0.463938]\n",
      "[Epoch 50/100] [Batch 2/347] [D loss: 0.544827] [G loss: 0.470188]\n",
      "[Epoch 50/100] [Batch 3/347] [D loss: 0.567225] [G loss: 0.484767]\n",
      "[Epoch 50/100] [Batch 4/347] [D loss: 0.567601] [G loss: 0.489902]\n",
      "[Epoch 50/100] [Batch 5/347] [D loss: 0.565421] [G loss: 0.492780]\n",
      "[Epoch 50/100] [Batch 6/347] [D loss: 0.568548] [G loss: 0.498118]\n",
      "[Epoch 50/100] [Batch 7/347] [D loss: 0.565698] [G loss: 0.496584]\n",
      "[Epoch 50/100] [Batch 8/347] [D loss: 0.550875] [G loss: 0.494509]\n",
      "[Epoch 50/100] [Batch 9/347] [D loss: 0.537883] [G loss: 0.485911]\n",
      "[Epoch 50/100] [Batch 10/347] [D loss: 0.541891] [G loss: 0.488058]\n",
      "[Epoch 50/100] [Batch 11/347] [D loss: 0.561661] [G loss: 0.502920]\n",
      "[Epoch 50/100] [Batch 12/347] [D loss: 0.566768] [G loss: 0.508085]\n",
      "[Epoch 50/100] [Batch 13/347] [D loss: 0.569169] [G loss: 0.512142]\n",
      "[Epoch 50/100] [Batch 14/347] [D loss: 0.564996] [G loss: 0.514138]\n",
      "[Epoch 50/100] [Batch 15/347] [D loss: 0.552569] [G loss: 0.509497]\n",
      "[Epoch 50/100] [Batch 16/347] [D loss: 0.542456] [G loss: 0.504530]\n",
      "[Epoch 50/100] [Batch 17/347] [D loss: 0.530457] [G loss: 0.491648]\n",
      "[Epoch 50/100] [Batch 18/347] [D loss: 0.504097] [G loss: 0.483657]\n",
      "[Epoch 50/100] [Batch 19/347] [D loss: 0.510204] [G loss: 0.494199]\n",
      "[Epoch 50/100] [Batch 20/347] [D loss: 0.558401] [G loss: 0.505910]\n",
      "[Epoch 50/100] [Batch 21/347] [D loss: 0.562309] [G loss: 0.500315]\n",
      "[Epoch 50/100] [Batch 22/347] [D loss: 0.550794] [G loss: 0.493484]\n",
      "[Epoch 50/100] [Batch 23/347] [D loss: 0.518649] [G loss: 0.485482]\n",
      "[Epoch 50/100] [Batch 24/347] [D loss: 0.515374] [G loss: 0.482466]\n",
      "[Epoch 50/100] [Batch 25/347] [D loss: 0.539118] [G loss: 0.480111]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 50/100] [Batch 26/347] [D loss: 0.469408] [G loss: 0.463410]\n",
      "[Epoch 50/100] [Batch 27/347] [D loss: 0.259656] [G loss: 0.475251]\n",
      "[Epoch 50/100] [Batch 28/347] [D loss: 0.270590] [G loss: 0.480769]\n",
      "[Epoch 50/100] [Batch 29/347] [D loss: 0.508383] [G loss: 0.479174]\n",
      "[Epoch 50/100] [Batch 30/347] [D loss: 0.463818] [G loss: 0.481758]\n",
      "[Epoch 50/100] [Batch 31/347] [D loss: 0.402250] [G loss: 0.479373]\n",
      "[Epoch 50/100] [Batch 32/347] [D loss: 0.314047] [G loss: 0.467045]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 50/100] [Batch 33/347] [D loss: 0.326527] [G loss: 0.456645]\n",
      "[Epoch 50/100] [Batch 34/347] [D loss: 0.418807] [G loss: 0.451176]\n",
      "[Epoch 50/100] [Batch 35/347] [D loss: 0.395292] [G loss: 0.442696]\n",
      "[Epoch 50/100] [Batch 36/347] [D loss: 0.475139] [G loss: 0.425776]\n",
      "[Epoch 50/100] [Batch 37/347] [D loss: 0.415123] [G loss: 0.407053]\n",
      "[Epoch 50/100] [Batch 38/347] [D loss: 0.360418] [G loss: 0.386155]\n",
      "[Epoch 50/100] [Batch 39/347] [D loss: 0.409474] [G loss: 0.373542]\n",
      "[Epoch 50/100] [Batch 40/347] [D loss: 0.512782] [G loss: 0.369310]\n",
      "[Epoch 50/100] [Batch 41/347] [D loss: 0.524434] [G loss: 0.360616]\n",
      "[Epoch 50/100] [Batch 42/347] [D loss: 0.519923] [G loss: 0.358945]\n",
      "[Epoch 50/100] [Batch 43/347] [D loss: 0.490093] [G loss: 0.367066]\n",
      "[Epoch 50/100] [Batch 44/347] [D loss: 0.482470] [G loss: 0.381534]\n",
      "[Epoch 50/100] [Batch 45/347] [D loss: 0.511990] [G loss: 0.395431]\n",
      "[Epoch 50/100] [Batch 46/347] [D loss: 0.509895] [G loss: 0.387671]\n",
      "[Epoch 50/100] [Batch 47/347] [D loss: 0.500093] [G loss: 0.358726]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 50/100] [Batch 48/347] [D loss: 0.325993] [G loss: 0.347775]\n",
      "[Epoch 50/100] [Batch 49/347] [D loss: 0.327548] [G loss: 0.349183]\n",
      "[Epoch 50/100] [Batch 50/347] [D loss: 0.279257] [G loss: 0.362265]\n",
      "[Epoch 50/100] [Batch 51/347] [D loss: 0.264861] [G loss: 0.380609]\n",
      "[Epoch 50/100] [Batch 52/347] [D loss: 0.368450] [G loss: 0.385184]\n",
      "[Epoch 50/100] [Batch 53/347] [D loss: 0.464070] [G loss: 0.384928]\n",
      "[Epoch 50/100] [Batch 54/347] [D loss: 0.403122] [G loss: 0.375087]\n",
      "[Epoch 50/100] [Batch 55/347] [D loss: 0.396096] [G loss: 0.352534]\n",
      "[Epoch 50/100] [Batch 56/347] [D loss: 0.388137] [G loss: 0.357634]\n",
      "[Epoch 50/100] [Batch 57/347] [D loss: 0.376128] [G loss: 0.389797]\n",
      "[Epoch 50/100] [Batch 58/347] [D loss: 0.390438] [G loss: 0.402577]\n",
      "[Epoch 50/100] [Batch 59/347] [D loss: 0.373739] [G loss: 0.402749]\n",
      "[Epoch 50/100] [Batch 60/347] [D loss: 0.348171] [G loss: 0.400020]\n",
      "[Epoch 50/100] [Batch 61/347] [D loss: 0.304278] [G loss: 0.398479]\n",
      "[Epoch 50/100] [Batch 62/347] [D loss: 0.325211] [G loss: 0.384402]\n",
      "[Epoch 50/100] [Batch 63/347] [D loss: 0.380181] [G loss: 0.362915]\n",
      "[Epoch 50/100] [Batch 64/347] [D loss: 0.401270] [G loss: 0.383925]\n",
      "[Epoch 50/100] [Batch 65/347] [D loss: 0.474654] [G loss: 0.404560]\n",
      "[Epoch 50/100] [Batch 66/347] [D loss: 0.395989] [G loss: 0.402455]\n",
      "[Epoch 50/100] [Batch 67/347] [D loss: 0.225721] [G loss: 0.397352]\n",
      "[Epoch 50/100] [Batch 68/347] [D loss: 0.248102] [G loss: 0.394667]\n",
      "[Epoch 50/100] [Batch 69/347] [D loss: 0.366732] [G loss: 0.378369]\n",
      "[Epoch 50/100] [Batch 70/347] [D loss: 0.370718] [G loss: 0.369970]\n",
      "[Epoch 50/100] [Batch 71/347] [D loss: 0.356280] [G loss: 0.381948]\n",
      "[Epoch 50/100] [Batch 72/347] [D loss: 0.351070] [G loss: 0.381123]\n",
      "[Epoch 50/100] [Batch 73/347] [D loss: 0.354169] [G loss: 0.387403]\n",
      "[Epoch 50/100] [Batch 74/347] [D loss: 0.357694] [G loss: 0.405661]\n",
      "[Epoch 50/100] [Batch 75/347] [D loss: 0.384127] [G loss: 0.395528]\n",
      "[Epoch 50/100] [Batch 76/347] [D loss: 0.412889] [G loss: 0.372912]\n",
      "[Epoch 50/100] [Batch 77/347] [D loss: 0.389527] [G loss: 0.382928]\n",
      "[Epoch 50/100] [Batch 78/347] [D loss: 0.382288] [G loss: 0.398450]\n",
      "[Epoch 50/100] [Batch 79/347] [D loss: 0.490202] [G loss: 0.406031]\n",
      "[Epoch 50/100] [Batch 80/347] [D loss: 0.533250] [G loss: 0.400112]\n",
      "[Epoch 50/100] [Batch 81/347] [D loss: 0.509667] [G loss: 0.402324]\n",
      "[Epoch 50/100] [Batch 82/347] [D loss: 0.396187] [G loss: 0.393526]\n",
      "[Epoch 50/100] [Batch 83/347] [D loss: 0.380565] [G loss: 0.389364]\n",
      "[Epoch 50/100] [Batch 84/347] [D loss: 0.464435] [G loss: 0.399622]\n",
      "[Epoch 50/100] [Batch 85/347] [D loss: 0.551077] [G loss: 0.400157]\n",
      "[Epoch 50/100] [Batch 86/347] [D loss: 0.549097] [G loss: 0.395115]\n",
      "[Epoch 50/100] [Batch 87/347] [D loss: 0.547974] [G loss: 0.394532]\n",
      "[Epoch 50/100] [Batch 88/347] [D loss: 0.553314] [G loss: 0.400473]\n",
      "[Epoch 50/100] [Batch 89/347] [D loss: 0.562570] [G loss: 0.407544]\n",
      "[Epoch 50/100] [Batch 90/347] [D loss: 0.558899] [G loss: 0.408040]\n",
      "[Epoch 50/100] [Batch 91/347] [D loss: 0.557498] [G loss: 0.411841]\n",
      "[Epoch 50/100] [Batch 92/347] [D loss: 0.559391] [G loss: 0.418921]\n",
      "[Epoch 50/100] [Batch 93/347] [D loss: 0.557557] [G loss: 0.422588]\n",
      "[Epoch 50/100] [Batch 94/347] [D loss: 0.549120] [G loss: 0.425511]\n",
      "[Epoch 50/100] [Batch 95/347] [D loss: 0.548397] [G loss: 0.432333]\n",
      "[Epoch 50/100] [Batch 96/347] [D loss: 0.545961] [G loss: 0.433686]\n",
      "[Epoch 50/100] [Batch 97/347] [D loss: 0.543060] [G loss: 0.434095]\n",
      "[Epoch 50/100] [Batch 98/347] [D loss: 0.548907] [G loss: 0.444581]\n",
      "[Epoch 50/100] [Batch 99/347] [D loss: 0.547792] [G loss: 0.453401]\n",
      "[Epoch 50/100] [Batch 100/347] [D loss: 0.521199] [G loss: 0.454068]\n",
      "[Epoch 50/100] [Batch 101/347] [D loss: 0.524139] [G loss: 0.452756]\n",
      "[Epoch 50/100] [Batch 102/347] [D loss: 0.548429] [G loss: 0.457778]\n",
      "[Epoch 50/100] [Batch 103/347] [D loss: 0.547936] [G loss: 0.461378]\n",
      "[Epoch 50/100] [Batch 104/347] [D loss: 0.545170] [G loss: 0.455319]\n",
      "[Epoch 50/100] [Batch 105/347] [D loss: 0.546021] [G loss: 0.456850]\n",
      "[Epoch 50/100] [Batch 106/347] [D loss: 0.530906] [G loss: 0.457697]\n",
      "[Epoch 50/100] [Batch 107/347] [D loss: 0.457176] [G loss: 0.447638]\n",
      "[Epoch 50/100] [Batch 108/347] [D loss: 0.190629] [G loss: 0.457938]\n",
      "[Epoch 50/100] [Batch 109/347] [D loss: 0.190292] [G loss: 0.464457]\n",
      "[Epoch 50/100] [Batch 110/347] [D loss: 0.417503] [G loss: 0.462444]\n",
      "[Epoch 50/100] [Batch 111/347] [D loss: 0.248180] [G loss: 0.459291]\n",
      "[Epoch 50/100] [Batch 112/347] [D loss: 0.188934] [G loss: 0.465064]\n",
      "[Epoch 50/100] [Batch 113/347] [D loss: 0.414725] [G loss: 0.478789]\n",
      "[Epoch 50/100] [Batch 114/347] [D loss: 0.473175] [G loss: 0.498730]\n",
      "[Epoch 50/100] [Batch 115/347] [D loss: 0.452763] [G loss: 0.498267]\n",
      "[Epoch 50/100] [Batch 116/347] [D loss: 0.482676] [G loss: 0.490224]\n",
      "[Epoch 50/100] [Batch 117/347] [D loss: 0.472063] [G loss: 0.460640]\n",
      "[Epoch 50/100] [Batch 118/347] [D loss: 0.385596] [G loss: 0.439409]\n",
      "[Epoch 50/100] [Batch 119/347] [D loss: 0.323884] [G loss: 0.429055]\n",
      "[Epoch 50/100] [Batch 120/347] [D loss: 0.266783] [G loss: 0.429274]\n",
      "[Epoch 50/100] [Batch 121/347] [D loss: 0.252106] [G loss: 0.424333]\n",
      "[Epoch 50/100] [Batch 122/347] [D loss: 0.415658] [G loss: 0.426436]\n",
      "[Epoch 50/100] [Batch 123/347] [D loss: 0.519801] [G loss: 0.424028]\n",
      "[Epoch 50/100] [Batch 124/347] [D loss: 0.521381] [G loss: 0.414336]\n",
      "[Epoch 50/100] [Batch 125/347] [D loss: 0.521248] [G loss: 0.420484]\n",
      "[Epoch 50/100] [Batch 126/347] [D loss: 0.472399] [G loss: 0.427368]\n",
      "[Epoch 50/100] [Batch 127/347] [D loss: 0.449795] [G loss: 0.422003]\n",
      "[Epoch 50/100] [Batch 128/347] [D loss: 0.447384] [G loss: 0.409854]\n",
      "[Epoch 50/100] [Batch 129/347] [D loss: 0.343781] [G loss: 0.398173]\n",
      "[Epoch 50/100] [Batch 130/347] [D loss: 0.335588] [G loss: 0.388052]\n",
      "[Epoch 50/100] [Batch 131/347] [D loss: 0.314264] [G loss: 0.382258]\n",
      "[Epoch 50/100] [Batch 132/347] [D loss: 0.275024] [G loss: 0.384768]\n",
      "[Epoch 50/100] [Batch 133/347] [D loss: 0.261797] [G loss: 0.387385]\n",
      "[Epoch 50/100] [Batch 134/347] [D loss: 0.261986] [G loss: 0.396672]\n",
      "[Epoch 50/100] [Batch 135/347] [D loss: 0.280716] [G loss: 0.416317]\n",
      "[Epoch 50/100] [Batch 136/347] [D loss: 0.264928] [G loss: 0.434670]\n",
      "[Epoch 50/100] [Batch 137/347] [D loss: 0.424706] [G loss: 0.435510]\n",
      "[Epoch 50/100] [Batch 138/347] [D loss: 0.409568] [G loss: 0.432514]\n",
      "[Epoch 50/100] [Batch 139/347] [D loss: 0.390063] [G loss: 0.424070]\n",
      "[Epoch 50/100] [Batch 140/347] [D loss: 0.346969] [G loss: 0.425785]\n",
      "[Epoch 50/100] [Batch 141/347] [D loss: 0.354165] [G loss: 0.421216]\n",
      "[Epoch 50/100] [Batch 142/347] [D loss: 0.369896] [G loss: 0.419694]\n",
      "[Epoch 50/100] [Batch 143/347] [D loss: 0.320785] [G loss: 0.412540]\n",
      "[Epoch 50/100] [Batch 144/347] [D loss: 0.306412] [G loss: 0.400200]\n",
      "[Epoch 50/100] [Batch 145/347] [D loss: 0.295848] [G loss: 0.388682]\n",
      "[Epoch 50/100] [Batch 146/347] [D loss: 0.289317] [G loss: 0.378249]\n",
      "[Epoch 50/100] [Batch 147/347] [D loss: 0.331803] [G loss: 0.384145]\n",
      "[Epoch 50/100] [Batch 148/347] [D loss: 0.341595] [G loss: 0.385409]\n",
      "[Epoch 50/100] [Batch 149/347] [D loss: 0.379280] [G loss: 0.372379]\n",
      "[Epoch 50/100] [Batch 150/347] [D loss: 0.396155] [G loss: 0.368639]\n",
      "[Epoch 50/100] [Batch 151/347] [D loss: 0.367694] [G loss: 0.371978]\n",
      "[Epoch 50/100] [Batch 152/347] [D loss: 0.307621] [G loss: 0.367055]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 50/100] [Batch 153/347] [D loss: 0.268648] [G loss: 0.346166]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 50/100] [Batch 154/347] [D loss: 0.265403] [G loss: 0.323298]\n",
      "[Epoch 50/100] [Batch 155/347] [D loss: 0.275809] [G loss: 0.316965]\n",
      "[Epoch 50/100] [Batch 156/347] [D loss: 0.322578] [G loss: 0.322870]\n",
      "[Epoch 50/100] [Batch 157/347] [D loss: 0.309266] [G loss: 0.331399]\n",
      "[Epoch 50/100] [Batch 158/347] [D loss: 0.273590] [G loss: 0.318080]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 50/100] [Batch 159/347] [D loss: 0.264127] [G loss: 0.304926]\n",
      "[Epoch 50/100] [Batch 160/347] [D loss: 0.232811] [G loss: 0.325824]\n",
      "[Epoch 50/100] [Batch 161/347] [D loss: 0.229005] [G loss: 0.344839]\n",
      "[Epoch 50/100] [Batch 162/347] [D loss: 0.273754] [G loss: 0.347690]\n",
      "[Epoch 50/100] [Batch 163/347] [D loss: 0.285848] [G loss: 0.342661]\n",
      "[Epoch 50/100] [Batch 164/347] [D loss: 0.263259] [G loss: 0.344749]\n",
      "[Epoch 50/100] [Batch 165/347] [D loss: 0.243359] [G loss: 0.341689]\n",
      "[Epoch 50/100] [Batch 166/347] [D loss: 0.249374] [G loss: 0.348107]\n",
      "[Epoch 50/100] [Batch 167/347] [D loss: 0.239393] [G loss: 0.374988]\n",
      "[Epoch 50/100] [Batch 168/347] [D loss: 0.200079] [G loss: 0.390702]\n",
      "[Epoch 50/100] [Batch 169/347] [D loss: 0.320591] [G loss: 0.402961]\n",
      "[Epoch 50/100] [Batch 170/347] [D loss: 0.389382] [G loss: 0.417281]\n",
      "[Epoch 50/100] [Batch 171/347] [D loss: 0.473422] [G loss: 0.430750]\n",
      "[Epoch 50/100] [Batch 172/347] [D loss: 0.496970] [G loss: 0.436666]\n",
      "[Epoch 50/100] [Batch 173/347] [D loss: 0.345194] [G loss: 0.425646]\n",
      "[Epoch 50/100] [Batch 174/347] [D loss: 0.346165] [G loss: 0.422385]\n",
      "[Epoch 50/100] [Batch 175/347] [D loss: 0.502580] [G loss: 0.430742]\n",
      "[Epoch 50/100] [Batch 176/347] [D loss: 0.538849] [G loss: 0.443007]\n",
      "[Epoch 50/100] [Batch 177/347] [D loss: 0.544045] [G loss: 0.443044]\n",
      "[Epoch 50/100] [Batch 178/347] [D loss: 0.535083] [G loss: 0.435963]\n",
      "[Epoch 50/100] [Batch 179/347] [D loss: 0.528436] [G loss: 0.427931]\n",
      "[Epoch 50/100] [Batch 180/347] [D loss: 0.524628] [G loss: 0.420104]\n",
      "[Epoch 50/100] [Batch 181/347] [D loss: 0.525060] [G loss: 0.419129]\n",
      "[Epoch 50/100] [Batch 182/347] [D loss: 0.522913] [G loss: 0.415544]\n",
      "[Epoch 50/100] [Batch 183/347] [D loss: 0.519535] [G loss: 0.417853]\n",
      "[Epoch 50/100] [Batch 184/347] [D loss: 0.526871] [G loss: 0.419728]\n",
      "[Epoch 50/100] [Batch 185/347] [D loss: 0.535068] [G loss: 0.416530]\n",
      "[Epoch 50/100] [Batch 186/347] [D loss: 0.537858] [G loss: 0.414725]\n",
      "[Epoch 50/100] [Batch 187/347] [D loss: 0.535893] [G loss: 0.408630]\n",
      "[Epoch 50/100] [Batch 188/347] [D loss: 0.535063] [G loss: 0.404451]\n",
      "[Epoch 50/100] [Batch 189/347] [D loss: 0.527238] [G loss: 0.402654]\n",
      "[Epoch 50/100] [Batch 190/347] [D loss: 0.491962] [G loss: 0.389701]\n",
      "[Epoch 50/100] [Batch 191/347] [D loss: 0.434942] [G loss: 0.375448]\n",
      "[Epoch 50/100] [Batch 192/347] [D loss: 0.424842] [G loss: 0.375045]\n",
      "[Epoch 50/100] [Batch 193/347] [D loss: 0.446939] [G loss: 0.381382]\n",
      "[Epoch 50/100] [Batch 194/347] [D loss: 0.503182] [G loss: 0.374612]\n",
      "[Epoch 50/100] [Batch 195/347] [D loss: 0.541826] [G loss: 0.365462]\n",
      "[Epoch 50/100] [Batch 196/347] [D loss: 0.524016] [G loss: 0.359104]\n",
      "[Epoch 50/100] [Batch 197/347] [D loss: 0.458576] [G loss: 0.356216]\n",
      "[Epoch 50/100] [Batch 198/347] [D loss: 0.342228] [G loss: 0.354761]\n",
      "[Epoch 50/100] [Batch 199/347] [D loss: 0.353308] [G loss: 0.353240]\n",
      "[Epoch 50/100] [Batch 200/347] [D loss: 0.479265] [G loss: 0.357488]\n",
      "[Epoch 50/100] [Batch 201/347] [D loss: 0.476474] [G loss: 0.359091]\n",
      "[Epoch 50/100] [Batch 202/347] [D loss: 0.491721] [G loss: 0.354735]\n",
      "[Epoch 50/100] [Batch 203/347] [D loss: 0.562377] [G loss: 0.352315]\n",
      "[Epoch 50/100] [Batch 204/347] [D loss: 0.563686] [G loss: 0.354410]\n",
      "[Epoch 50/100] [Batch 205/347] [D loss: 0.556286] [G loss: 0.357755]\n",
      "[Epoch 50/100] [Batch 206/347] [D loss: 0.542282] [G loss: 0.364400]\n",
      "[Epoch 50/100] [Batch 207/347] [D loss: 0.531204] [G loss: 0.377095]\n",
      "[Epoch 50/100] [Batch 208/347] [D loss: 0.538622] [G loss: 0.379783]\n",
      "[Epoch 50/100] [Batch 209/347] [D loss: 0.495527] [G loss: 0.375808]\n",
      "[Epoch 50/100] [Batch 210/347] [D loss: 0.478639] [G loss: 0.384111]\n",
      "[Epoch 50/100] [Batch 211/347] [D loss: 0.520185] [G loss: 0.384189]\n",
      "[Epoch 50/100] [Batch 212/347] [D loss: 0.294072] [G loss: 0.381347]\n",
      "[Epoch 50/100] [Batch 213/347] [D loss: 0.287175] [G loss: 0.383908]\n",
      "[Epoch 50/100] [Batch 214/347] [D loss: 0.250101] [G loss: 0.400709]\n",
      "[Epoch 50/100] [Batch 215/347] [D loss: 0.239516] [G loss: 0.413927]\n",
      "[Epoch 50/100] [Batch 216/347] [D loss: 0.353628] [G loss: 0.420355]\n",
      "[Epoch 50/100] [Batch 217/347] [D loss: 0.470063] [G loss: 0.437023]\n",
      "[Epoch 50/100] [Batch 218/347] [D loss: 0.557193] [G loss: 0.462145]\n",
      "[Epoch 50/100] [Batch 219/347] [D loss: 0.500468] [G loss: 0.481891]\n",
      "[Epoch 50/100] [Batch 220/347] [D loss: 0.499839] [G loss: 0.503828]\n",
      "[Epoch 50/100] [Batch 221/347] [D loss: 0.527449] [G loss: 0.509988]\n",
      "[Epoch 50/100] [Batch 222/347] [D loss: 0.523044] [G loss: 0.505790]\n",
      "[Epoch 50/100] [Batch 223/347] [D loss: 0.530219] [G loss: 0.507864]\n",
      "[Epoch 50/100] [Batch 224/347] [D loss: 0.536469] [G loss: 0.506691]\n",
      "[Epoch 50/100] [Batch 225/347] [D loss: 0.519944] [G loss: 0.483529]\n",
      "[Epoch 50/100] [Batch 226/347] [D loss: 0.524874] [G loss: 0.462222]\n",
      "[Epoch 50/100] [Batch 227/347] [D loss: 0.537787] [G loss: 0.442481]\n",
      "[Epoch 50/100] [Batch 228/347] [D loss: 0.542825] [G loss: 0.449645]\n",
      "[Epoch 50/100] [Batch 229/347] [D loss: 0.558176] [G loss: 0.462558]\n",
      "[Epoch 50/100] [Batch 230/347] [D loss: 0.562068] [G loss: 0.467092]\n",
      "[Epoch 50/100] [Batch 231/347] [D loss: 0.558197] [G loss: 0.461891]\n",
      "[Epoch 50/100] [Batch 232/347] [D loss: 0.557416] [G loss: 0.464568]\n",
      "[Epoch 50/100] [Batch 233/347] [D loss: 0.533939] [G loss: 0.461882]\n",
      "[Epoch 50/100] [Batch 234/347] [D loss: 0.489833] [G loss: 0.463601]\n",
      "[Epoch 50/100] [Batch 235/347] [D loss: 0.484243] [G loss: 0.471279]\n",
      "[Epoch 50/100] [Batch 236/347] [D loss: 0.494208] [G loss: 0.476340]\n",
      "[Epoch 50/100] [Batch 237/347] [D loss: 0.513864] [G loss: 0.485128]\n",
      "[Epoch 50/100] [Batch 238/347] [D loss: 0.550364] [G loss: 0.485785]\n",
      "[Epoch 50/100] [Batch 239/347] [D loss: 0.535049] [G loss: 0.480360]\n",
      "[Epoch 50/100] [Batch 240/347] [D loss: 0.530389] [G loss: 0.473373]\n",
      "[Epoch 50/100] [Batch 241/347] [D loss: 0.533278] [G loss: 0.465062]\n",
      "[Epoch 50/100] [Batch 242/347] [D loss: 0.539950] [G loss: 0.461030]\n",
      "[Epoch 50/100] [Batch 243/347] [D loss: 0.549937] [G loss: 0.467498]\n",
      "[Epoch 50/100] [Batch 244/347] [D loss: 0.547595] [G loss: 0.475204]\n",
      "[Epoch 50/100] [Batch 245/347] [D loss: 0.490387] [G loss: 0.471888]\n",
      "[Epoch 50/100] [Batch 246/347] [D loss: 0.456906] [G loss: 0.452677]\n",
      "[Epoch 50/100] [Batch 247/347] [D loss: 0.500893] [G loss: 0.425210]\n",
      "[Epoch 50/100] [Batch 248/347] [D loss: 0.547372] [G loss: 0.417995]\n",
      "[Epoch 50/100] [Batch 249/347] [D loss: 0.541658] [G loss: 0.409292]\n",
      "[Epoch 50/100] [Batch 250/347] [D loss: 0.519582] [G loss: 0.426628]\n",
      "[Epoch 50/100] [Batch 251/347] [D loss: 0.490603] [G loss: 0.441588]\n",
      "[Epoch 50/100] [Batch 252/347] [D loss: 0.480030] [G loss: 0.441078]\n",
      "[Epoch 50/100] [Batch 253/347] [D loss: 0.492069] [G loss: 0.437743]\n",
      "[Epoch 50/100] [Batch 254/347] [D loss: 0.513864] [G loss: 0.438080]\n",
      "[Epoch 50/100] [Batch 255/347] [D loss: 0.458414] [G loss: 0.427335]\n",
      "[Epoch 50/100] [Batch 256/347] [D loss: 0.446153] [G loss: 0.428378]\n",
      "[Epoch 50/100] [Batch 257/347] [D loss: 0.447173] [G loss: 0.433731]\n",
      "[Epoch 50/100] [Batch 258/347] [D loss: 0.377217] [G loss: 0.416695]\n",
      "[Epoch 50/100] [Batch 259/347] [D loss: 0.363082] [G loss: 0.399730]\n",
      "[Epoch 50/100] [Batch 260/347] [D loss: 0.329651] [G loss: 0.394200]\n",
      "[Epoch 50/100] [Batch 261/347] [D loss: 0.342577] [G loss: 0.399262]\n",
      "[Epoch 50/100] [Batch 262/347] [D loss: 0.403611] [G loss: 0.392562]\n",
      "[Epoch 50/100] [Batch 263/347] [D loss: 0.367194] [G loss: 0.389492]\n",
      "[Epoch 50/100] [Batch 264/347] [D loss: 0.321583] [G loss: 0.391741]\n",
      "[Epoch 50/100] [Batch 265/347] [D loss: 0.346675] [G loss: 0.390032]\n",
      "[Epoch 50/100] [Batch 266/347] [D loss: 0.371924] [G loss: 0.388039]\n",
      "[Epoch 50/100] [Batch 267/347] [D loss: 0.371913] [G loss: 0.387598]\n",
      "[Epoch 50/100] [Batch 268/347] [D loss: 0.322867] [G loss: 0.394935]\n",
      "[Epoch 50/100] [Batch 269/347] [D loss: 0.327155] [G loss: 0.399664]\n",
      "[Epoch 50/100] [Batch 270/347] [D loss: 0.390622] [G loss: 0.399179]\n",
      "[Epoch 50/100] [Batch 271/347] [D loss: 0.431290] [G loss: 0.398444]\n",
      "[Epoch 50/100] [Batch 272/347] [D loss: 0.471799] [G loss: 0.402212]\n",
      "[Epoch 50/100] [Batch 273/347] [D loss: 0.365466] [G loss: 0.412877]\n",
      "[Epoch 50/100] [Batch 274/347] [D loss: 0.648948] [G loss: 0.438095]\n",
      "[Epoch 50/100] [Batch 275/347] [D loss: 0.605548] [G loss: 0.454330]\n",
      "[Epoch 50/100] [Batch 276/347] [D loss: 0.365208] [G loss: 0.451649]\n",
      "[Epoch 50/100] [Batch 277/347] [D loss: 0.366494] [G loss: 0.460748]\n",
      "[Epoch 50/100] [Batch 278/347] [D loss: 0.495787] [G loss: 0.482319]\n",
      "[Epoch 50/100] [Batch 279/347] [D loss: 0.475951] [G loss: 0.482817]\n",
      "[Epoch 50/100] [Batch 280/347] [D loss: 0.462138] [G loss: 0.484726]\n",
      "[Epoch 50/100] [Batch 281/347] [D loss: 0.463928] [G loss: 0.486318]\n",
      "[Epoch 50/100] [Batch 282/347] [D loss: 0.473110] [G loss: 0.489377]\n",
      "[Epoch 50/100] [Batch 283/347] [D loss: 0.392912] [G loss: 0.485323]\n",
      "[Epoch 50/100] [Batch 284/347] [D loss: 0.381868] [G loss: 0.486475]\n",
      "[Epoch 50/100] [Batch 285/347] [D loss: 0.467300] [G loss: 0.490757]\n",
      "[Epoch 50/100] [Batch 286/347] [D loss: 0.527716] [G loss: 0.488993]\n",
      "[Epoch 50/100] [Batch 287/347] [D loss: 0.530248] [G loss: 0.483604]\n",
      "[Epoch 50/100] [Batch 288/347] [D loss: 0.524990] [G loss: 0.458426]\n",
      "[Epoch 50/100] [Batch 289/347] [D loss: 0.524823] [G loss: 0.451700]\n",
      "[Epoch 50/100] [Batch 290/347] [D loss: 0.536941] [G loss: 0.468371]\n",
      "[Epoch 50/100] [Batch 291/347] [D loss: 0.503332] [G loss: 0.462688]\n",
      "[Epoch 50/100] [Batch 292/347] [D loss: 0.489225] [G loss: 0.467112]\n",
      "[Epoch 50/100] [Batch 293/347] [D loss: 0.427644] [G loss: 0.485555]\n",
      "[Epoch 50/100] [Batch 294/347] [D loss: 0.367762] [G loss: 0.484528]\n",
      "[Epoch 50/100] [Batch 295/347] [D loss: 0.210131] [G loss: 0.467546]\n",
      "[Epoch 50/100] [Batch 296/347] [D loss: 0.198231] [G loss: 0.471508]\n",
      "[Epoch 50/100] [Batch 297/347] [D loss: 0.488864] [G loss: 0.485856]\n",
      "[Epoch 50/100] [Batch 298/347] [D loss: 0.559038] [G loss: 0.478964]\n",
      "[Epoch 50/100] [Batch 299/347] [D loss: 0.502201] [G loss: 0.475996]\n",
      "[Epoch 50/100] [Batch 300/347] [D loss: 0.443665] [G loss: 0.469069]\n",
      "[Epoch 50/100] [Batch 301/347] [D loss: 0.452156] [G loss: 0.461627]\n",
      "[Epoch 50/100] [Batch 302/347] [D loss: 0.519441] [G loss: 0.464814]\n",
      "[Epoch 50/100] [Batch 303/347] [D loss: 0.484744] [G loss: 0.436451]\n",
      "[Epoch 50/100] [Batch 304/347] [D loss: 0.489601] [G loss: 0.420070]\n",
      "[Epoch 50/100] [Batch 305/347] [D loss: 0.520723] [G loss: 0.419294]\n",
      "[Epoch 50/100] [Batch 306/347] [D loss: 0.297941] [G loss: 0.407418]\n",
      "[Epoch 50/100] [Batch 307/347] [D loss: 0.220989] [G loss: 0.406536]\n",
      "[Epoch 50/100] [Batch 308/347] [D loss: 0.302886] [G loss: 0.406266]\n",
      "[Epoch 50/100] [Batch 309/347] [D loss: 0.487748] [G loss: 0.426098]\n",
      "[Epoch 50/100] [Batch 310/347] [D loss: 0.571963] [G loss: 0.453592]\n",
      "[Epoch 50/100] [Batch 311/347] [D loss: 0.571527] [G loss: 0.457571]\n",
      "[Epoch 50/100] [Batch 312/347] [D loss: 0.568475] [G loss: 0.458888]\n",
      "[Epoch 50/100] [Batch 313/347] [D loss: 0.552665] [G loss: 0.460318]\n",
      "[Epoch 50/100] [Batch 314/347] [D loss: 0.495822] [G loss: 0.455472]\n",
      "[Epoch 50/100] [Batch 315/347] [D loss: 0.432436] [G loss: 0.447088]\n",
      "[Epoch 50/100] [Batch 316/347] [D loss: 0.428764] [G loss: 0.430553]\n",
      "[Epoch 50/100] [Batch 317/347] [D loss: 0.500668] [G loss: 0.419313]\n",
      "[Epoch 50/100] [Batch 318/347] [D loss: 0.546293] [G loss: 0.435765]\n",
      "[Epoch 50/100] [Batch 319/347] [D loss: 0.542638] [G loss: 0.469096]\n",
      "[Epoch 50/100] [Batch 320/347] [D loss: 0.526493] [G loss: 0.482777]\n",
      "[Epoch 50/100] [Batch 321/347] [D loss: 0.506951] [G loss: 0.472042]\n",
      "[Epoch 50/100] [Batch 322/347] [D loss: 0.509802] [G loss: 0.458291]\n",
      "[Epoch 50/100] [Batch 323/347] [D loss: 0.462978] [G loss: 0.456230]\n",
      "[Epoch 50/100] [Batch 324/347] [D loss: 0.448472] [G loss: 0.457636]\n",
      "[Epoch 50/100] [Batch 325/347] [D loss: 0.343620] [G loss: 0.445704]\n",
      "[Epoch 50/100] [Batch 326/347] [D loss: 0.316419] [G loss: 0.432981]\n",
      "[Epoch 50/100] [Batch 327/347] [D loss: 0.408735] [G loss: 0.430352]\n",
      "[Epoch 50/100] [Batch 328/347] [D loss: 0.462393] [G loss: 0.427577]\n",
      "[Epoch 50/100] [Batch 329/347] [D loss: 0.358798] [G loss: 0.410965]\n",
      "[Epoch 50/100] [Batch 330/347] [D loss: 0.344513] [G loss: 0.403160]\n",
      "[Epoch 50/100] [Batch 331/347] [D loss: 0.440020] [G loss: 0.410008]\n",
      "[Epoch 50/100] [Batch 332/347] [D loss: 0.543682] [G loss: 0.436194]\n",
      "[Epoch 50/100] [Batch 333/347] [D loss: 0.556229] [G loss: 0.447597]\n",
      "[Epoch 50/100] [Batch 334/347] [D loss: 0.512011] [G loss: 0.449142]\n",
      "[Epoch 50/100] [Batch 335/347] [D loss: 0.476476] [G loss: 0.437272]\n",
      "[Epoch 50/100] [Batch 336/347] [D loss: 0.473370] [G loss: 0.422206]\n",
      "[Epoch 50/100] [Batch 337/347] [D loss: 0.463867] [G loss: 0.427774]\n",
      "[Epoch 50/100] [Batch 338/347] [D loss: 0.495896] [G loss: 0.442280]\n",
      "[Epoch 50/100] [Batch 339/347] [D loss: 0.553603] [G loss: 0.448584]\n",
      "[Epoch 50/100] [Batch 340/347] [D loss: 0.564222] [G loss: 0.450843]\n",
      "[Epoch 50/100] [Batch 341/347] [D loss: 0.539301] [G loss: 0.448445]\n",
      "[Epoch 50/100] [Batch 342/347] [D loss: 0.532411] [G loss: 0.443224]\n",
      "[Epoch 50/100] [Batch 343/347] [D loss: 0.554303] [G loss: 0.451472]\n",
      "[Epoch 50/100] [Batch 344/347] [D loss: 0.440982] [G loss: 0.442864]\n",
      "[Epoch 50/100] [Batch 345/347] [D loss: 0.367949] [G loss: 0.416843]\n",
      "[Epoch 50/100] [Batch 346/347] [D loss: 0.329399] [G loss: 0.419120]\n",
      "[Epoch 50/100] [Batch 347/347] [D loss: 0.234329] [G loss: 0.433987]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 1/347] [D loss: 0.684902] [G loss: 0.924981]\n",
      "[Epoch 51/100] [Batch 2/347] [D loss: 0.711521] [G loss: 0.891451]\n",
      "[Epoch 51/100] [Batch 3/347] [D loss: 0.709902] [G loss: 0.879879]\n",
      "[Epoch 51/100] [Batch 4/347] [D loss: 0.707216] [G loss: 0.871715]\n",
      "[Epoch 51/100] [Batch 5/347] [D loss: 0.704015] [G loss: 0.861242]\n",
      "[Epoch 51/100] [Batch 6/347] [D loss: 0.700639] [G loss: 0.851522]\n",
      "[Epoch 51/100] [Batch 7/347] [D loss: 0.697058] [G loss: 0.836137]\n",
      "[Epoch 51/100] [Batch 8/347] [D loss: 0.693314] [G loss: 0.827564]\n",
      "[Epoch 51/100] [Batch 9/347] [D loss: 0.689416] [G loss: 0.821163]\n",
      "[Epoch 51/100] [Batch 10/347] [D loss: 0.685488] [G loss: 0.814580]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 11/347] [D loss: 0.681475] [G loss: 0.815987]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 12/347] [D loss: 0.677400] [G loss: 0.810380]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 13/347] [D loss: 0.673349] [G loss: 0.801531]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 14/347] [D loss: 0.669146] [G loss: 0.793048]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 15/347] [D loss: 0.665107] [G loss: 0.775694]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 16/347] [D loss: 0.661221] [G loss: 0.761995]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 17/347] [D loss: 0.657337] [G loss: 0.756278]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 18/347] [D loss: 0.653440] [G loss: 0.748694]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 19/347] [D loss: 0.649768] [G loss: 0.745743]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 20/347] [D loss: 0.646053] [G loss: 0.742476]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 21/347] [D loss: 0.642496] [G loss: 0.729955]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 22/347] [D loss: 0.638964] [G loss: 0.720274]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 23/347] [D loss: 0.635227] [G loss: 0.709457]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 24/347] [D loss: 0.631338] [G loss: 0.693665]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 25/347] [D loss: 0.627586] [G loss: 0.684405]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 26/347] [D loss: 0.623707] [G loss: 0.674733]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 27/347] [D loss: 0.619417] [G loss: 0.671910]\n",
      "[Epoch 51/100] [Batch 28/347] [D loss: 0.615119] [G loss: 0.673747]\n",
      "[Epoch 51/100] [Batch 29/347] [D loss: 0.610914] [G loss: 0.675994]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 30/347] [D loss: 0.606970] [G loss: 0.669560]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 31/347] [D loss: 0.603294] [G loss: 0.661785]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 32/347] [D loss: 0.599813] [G loss: 0.651085]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 33/347] [D loss: 0.596381] [G loss: 0.641893]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 34/347] [D loss: 0.593069] [G loss: 0.630231]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 35/347] [D loss: 0.589934] [G loss: 0.608875]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 36/347] [D loss: 0.586738] [G loss: 0.591339]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 37/347] [D loss: 0.583620] [G loss: 0.579884]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 38/347] [D loss: 0.580841] [G loss: 0.568967]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 39/347] [D loss: 0.578181] [G loss: 0.566754]\n",
      "[Epoch 51/100] [Batch 40/347] [D loss: 0.575662] [G loss: 0.566967]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 41/347] [D loss: 0.573163] [G loss: 0.564757]\n",
      "[Epoch 51/100] [Batch 42/347] [D loss: 0.570991] [G loss: 0.568913]\n",
      "[Epoch 51/100] [Batch 43/347] [D loss: 0.569040] [G loss: 0.579228]\n",
      "[Epoch 51/100] [Batch 44/347] [D loss: 0.567346] [G loss: 0.580492]\n",
      "[Epoch 51/100] [Batch 45/347] [D loss: 0.565916] [G loss: 0.568445]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 46/347] [D loss: 0.564810] [G loss: 0.543972]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 47/347] [D loss: 0.564306] [G loss: 0.526537]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 48/347] [D loss: 0.564087] [G loss: 0.502196]\n",
      "[Epoch 51/100] [Batch 49/347] [D loss: 0.563943] [G loss: 0.503751]\n",
      "[Epoch 51/100] [Batch 50/347] [D loss: 0.563815] [G loss: 0.514491]\n",
      "[Epoch 51/100] [Batch 51/347] [D loss: 0.563666] [G loss: 0.513231]\n",
      "[Epoch 51/100] [Batch 52/347] [D loss: 0.563507] [G loss: 0.503516]\n",
      "[Epoch 51/100] [Batch 53/347] [D loss: 0.563332] [G loss: 0.512396]\n",
      "[Epoch 51/100] [Batch 54/347] [D loss: 0.563173] [G loss: 0.523889]\n",
      "[Epoch 51/100] [Batch 55/347] [D loss: 0.563054] [G loss: 0.520620]\n",
      "[Epoch 51/100] [Batch 56/347] [D loss: 0.562968] [G loss: 0.512372]\n",
      "[Epoch 51/100] [Batch 57/347] [D loss: 0.562875] [G loss: 0.503759]\n",
      "[Epoch 51/100] [Batch 58/347] [D loss: 0.562769] [G loss: 0.505704]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 59/347] [D loss: 0.562626] [G loss: 0.498476]\n",
      "[Epoch 51/100] [Batch 60/347] [D loss: 0.562465] [G loss: 0.506938]\n",
      "[Epoch 51/100] [Batch 61/347] [D loss: 0.562334] [G loss: 0.516096]\n",
      "[Epoch 51/100] [Batch 62/347] [D loss: 0.562249] [G loss: 0.510443]\n",
      "[Epoch 51/100] [Batch 63/347] [D loss: 0.562168] [G loss: 0.503002]\n",
      "[Epoch 51/100] [Batch 64/347] [D loss: 0.562095] [G loss: 0.498619]\n",
      "[Epoch 51/100] [Batch 65/347] [D loss: 0.562022] [G loss: 0.511761]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 66/347] [D loss: 0.561884] [G loss: 0.494983]\n",
      "[Epoch 51/100] [Batch 67/347] [D loss: 0.561733] [G loss: 0.503870]\n",
      "[Epoch 51/100] [Batch 68/347] [D loss: 0.561611] [G loss: 0.510602]\n",
      "[Epoch 51/100] [Batch 69/347] [D loss: 0.561473] [G loss: 0.515553]\n",
      "[Epoch 51/100] [Batch 70/347] [D loss: 0.561375] [G loss: 0.520239]\n",
      "[Epoch 51/100] [Batch 71/347] [D loss: 0.561311] [G loss: 0.508560]\n",
      "[Epoch 51/100] [Batch 72/347] [D loss: 0.561216] [G loss: 0.497316]\n",
      "[Epoch 51/100] [Batch 73/347] [D loss: 0.561114] [G loss: 0.499210]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 74/347] [D loss: 0.561036] [G loss: 0.494661]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 75/347] [D loss: 0.560948] [G loss: 0.488962]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 76/347] [D loss: 0.560867] [G loss: 0.483629]\n",
      "[Epoch 51/100] [Batch 77/347] [D loss: 0.560826] [G loss: 0.507391]\n",
      "[Epoch 51/100] [Batch 78/347] [D loss: 0.560761] [G loss: 0.524999]\n",
      "[Epoch 51/100] [Batch 79/347] [D loss: 0.560683] [G loss: 0.533209]\n",
      "[Epoch 51/100] [Batch 80/347] [D loss: 0.560569] [G loss: 0.527173]\n",
      "[Epoch 51/100] [Batch 81/347] [D loss: 0.560473] [G loss: 0.528800]\n",
      "[Epoch 51/100] [Batch 82/347] [D loss: 0.560380] [G loss: 0.530417]\n",
      "[Epoch 51/100] [Batch 83/347] [D loss: 0.560270] [G loss: 0.528636]\n",
      "[Epoch 51/100] [Batch 84/347] [D loss: 0.560174] [G loss: 0.531449]\n",
      "[Epoch 51/100] [Batch 85/347] [D loss: 0.560070] [G loss: 0.530525]\n",
      "[Epoch 51/100] [Batch 86/347] [D loss: 0.559969] [G loss: 0.528968]\n",
      "[Epoch 51/100] [Batch 87/347] [D loss: 0.559867] [G loss: 0.528698]\n",
      "[Epoch 51/100] [Batch 88/347] [D loss: 0.559766] [G loss: 0.528069]\n",
      "[Epoch 51/100] [Batch 89/347] [D loss: 0.559666] [G loss: 0.528769]\n",
      "[Epoch 51/100] [Batch 90/347] [D loss: 0.559559] [G loss: 0.527048]\n",
      "[Epoch 51/100] [Batch 91/347] [D loss: 0.559452] [G loss: 0.524467]\n",
      "[Epoch 51/100] [Batch 92/347] [D loss: 0.559346] [G loss: 0.523454]\n",
      "[Epoch 51/100] [Batch 93/347] [D loss: 0.559246] [G loss: 0.522246]\n",
      "[Epoch 51/100] [Batch 94/347] [D loss: 0.559134] [G loss: 0.517153]\n",
      "[Epoch 51/100] [Batch 95/347] [D loss: 0.559026] [G loss: 0.514926]\n",
      "[Epoch 51/100] [Batch 96/347] [D loss: 0.558922] [G loss: 0.515099]\n",
      "[Epoch 51/100] [Batch 97/347] [D loss: 0.558810] [G loss: 0.513382]\n",
      "[Epoch 51/100] [Batch 98/347] [D loss: 0.558706] [G loss: 0.513719]\n",
      "[Epoch 51/100] [Batch 99/347] [D loss: 0.558599] [G loss: 0.512951]\n",
      "[Epoch 51/100] [Batch 100/347] [D loss: 0.558486] [G loss: 0.511599]\n",
      "[Epoch 51/100] [Batch 101/347] [D loss: 0.558372] [G loss: 0.508434]\n",
      "[Epoch 51/100] [Batch 102/347] [D loss: 0.558252] [G loss: 0.504509]\n",
      "[Epoch 51/100] [Batch 103/347] [D loss: 0.558144] [G loss: 0.504354]\n",
      "[Epoch 51/100] [Batch 104/347] [D loss: 0.558020] [G loss: 0.498196]\n",
      "[Epoch 51/100] [Batch 105/347] [D loss: 0.557904] [G loss: 0.490568]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 106/347] [D loss: 0.557777] [G loss: 0.480772]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 107/347] [D loss: 0.557671] [G loss: 0.479318]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 108/347] [D loss: 0.557564] [G loss: 0.479080]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 109/347] [D loss: 0.557433] [G loss: 0.471448]\n",
      "[Epoch 51/100] [Batch 110/347] [D loss: 0.557349] [G loss: 0.483630]\n",
      "[Epoch 51/100] [Batch 111/347] [D loss: 0.557247] [G loss: 0.489100]\n",
      "[Epoch 51/100] [Batch 112/347] [D loss: 0.557149] [G loss: 0.493320]\n",
      "[Epoch 51/100] [Batch 113/347] [D loss: 0.557079] [G loss: 0.511302]\n",
      "[Epoch 51/100] [Batch 114/347] [D loss: 0.556964] [G loss: 0.517286]\n",
      "[Epoch 51/100] [Batch 115/347] [D loss: 0.556810] [G loss: 0.499639]\n",
      "[Epoch 51/100] [Batch 116/347] [D loss: 0.556641] [G loss: 0.481713]\n",
      "[Epoch 51/100] [Batch 117/347] [D loss: 0.556477] [G loss: 0.484018]\n",
      "[Epoch 51/100] [Batch 118/347] [D loss: 0.556314] [G loss: 0.488414]\n",
      "[Epoch 51/100] [Batch 119/347] [D loss: 0.556181] [G loss: 0.492019]\n",
      "[Epoch 51/100] [Batch 120/347] [D loss: 0.556086] [G loss: 0.489921]\n",
      "[Epoch 51/100] [Batch 121/347] [D loss: 0.555959] [G loss: 0.489234]\n",
      "[Epoch 51/100] [Batch 122/347] [D loss: 0.555855] [G loss: 0.489618]\n",
      "[Epoch 51/100] [Batch 123/347] [D loss: 0.555755] [G loss: 0.486807]\n",
      "[Epoch 51/100] [Batch 124/347] [D loss: 0.555645] [G loss: 0.482625]\n",
      "[Epoch 51/100] [Batch 125/347] [D loss: 0.555539] [G loss: 0.481779]\n",
      "[Epoch 51/100] [Batch 126/347] [D loss: 0.555423] [G loss: 0.485403]\n",
      "[Epoch 51/100] [Batch 127/347] [D loss: 0.555299] [G loss: 0.483555]\n",
      "[Epoch 51/100] [Batch 128/347] [D loss: 0.555141] [G loss: 0.474832]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 129/347] [D loss: 0.554977] [G loss: 0.467832]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 130/347] [D loss: 0.554788] [G loss: 0.463932]\n",
      "[Epoch 51/100] [Batch 131/347] [D loss: 0.554606] [G loss: 0.466427]\n",
      "[Epoch 51/100] [Batch 132/347] [D loss: 0.554405] [G loss: 0.467439]\n",
      "[Epoch 51/100] [Batch 133/347] [D loss: 0.554237] [G loss: 0.472860]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 134/347] [D loss: 0.554166] [G loss: 0.458202]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 135/347] [D loss: 0.554033] [G loss: 0.454893]\n",
      "[Epoch 51/100] [Batch 136/347] [D loss: 0.553915] [G loss: 0.458675]\n",
      "[Epoch 51/100] [Batch 137/347] [D loss: 0.553750] [G loss: 0.463692]\n",
      "[Epoch 51/100] [Batch 138/347] [D loss: 0.553502] [G loss: 0.469607]\n",
      "[Epoch 51/100] [Batch 139/347] [D loss: 0.553287] [G loss: 0.478806]\n",
      "[Epoch 51/100] [Batch 140/347] [D loss: 0.553092] [G loss: 0.489287]\n",
      "[Epoch 51/100] [Batch 141/347] [D loss: 0.552848] [G loss: 0.503525]\n",
      "[Epoch 51/100] [Batch 142/347] [D loss: 0.552666] [G loss: 0.506136]\n",
      "[Epoch 51/100] [Batch 143/347] [D loss: 0.552467] [G loss: 0.508750]\n",
      "[Epoch 51/100] [Batch 144/347] [D loss: 0.552323] [G loss: 0.500867]\n",
      "[Epoch 51/100] [Batch 145/347] [D loss: 0.552259] [G loss: 0.494080]\n",
      "[Epoch 51/100] [Batch 146/347] [D loss: 0.552141] [G loss: 0.493545]\n",
      "[Epoch 51/100] [Batch 147/347] [D loss: 0.552022] [G loss: 0.490201]\n",
      "[Epoch 51/100] [Batch 148/347] [D loss: 0.551914] [G loss: 0.481520]\n",
      "[Epoch 51/100] [Batch 149/347] [D loss: 0.551744] [G loss: 0.474785]\n",
      "[Epoch 51/100] [Batch 150/347] [D loss: 0.551560] [G loss: 0.468742]\n",
      "[Epoch 51/100] [Batch 151/347] [D loss: 0.551357] [G loss: 0.466101]\n",
      "[Epoch 51/100] [Batch 152/347] [D loss: 0.551136] [G loss: 0.470459]\n",
      "[Epoch 51/100] [Batch 153/347] [D loss: 0.550932] [G loss: 0.472928]\n",
      "[Epoch 51/100] [Batch 154/347] [D loss: 0.550792] [G loss: 0.471546]\n",
      "[Epoch 51/100] [Batch 155/347] [D loss: 0.550636] [G loss: 0.465393]\n",
      "[Epoch 51/100] [Batch 156/347] [D loss: 0.550425] [G loss: 0.468945]\n",
      "[Epoch 51/100] [Batch 157/347] [D loss: 0.550265] [G loss: 0.468010]\n",
      "[Epoch 51/100] [Batch 158/347] [D loss: 0.550076] [G loss: 0.469363]\n",
      "[Epoch 51/100] [Batch 159/347] [D loss: 0.549915] [G loss: 0.466869]\n",
      "[Epoch 51/100] [Batch 160/347] [D loss: 0.549824] [G loss: 0.457880]\n",
      "[Epoch 51/100] [Batch 161/347] [D loss: 0.549599] [G loss: 0.464222]\n",
      "[Epoch 51/100] [Batch 162/347] [D loss: 0.549342] [G loss: 0.474247]\n",
      "[Epoch 51/100] [Batch 163/347] [D loss: 0.549108] [G loss: 0.476000]\n",
      "[Epoch 51/100] [Batch 164/347] [D loss: 0.548994] [G loss: 0.464868]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 165/347] [D loss: 0.548925] [G loss: 0.448444]\n",
      "[Epoch 51/100] [Batch 166/347] [D loss: 0.548938] [G loss: 0.430755]\n",
      "[Epoch 51/100] [Batch 167/347] [D loss: 0.548914] [G loss: 0.453230]\n",
      "[Epoch 51/100] [Batch 168/347] [D loss: 0.548768] [G loss: 0.462335]\n",
      "[Epoch 51/100] [Batch 169/347] [D loss: 0.548648] [G loss: 0.471027]\n",
      "[Epoch 51/100] [Batch 170/347] [D loss: 0.548502] [G loss: 0.477243]\n",
      "[Epoch 51/100] [Batch 171/347] [D loss: 0.548317] [G loss: 0.476860]\n",
      "[Epoch 51/100] [Batch 172/347] [D loss: 0.548147] [G loss: 0.477823]\n",
      "[Epoch 51/100] [Batch 173/347] [D loss: 0.547954] [G loss: 0.476697]\n",
      "[Epoch 51/100] [Batch 174/347] [D loss: 0.547817] [G loss: 0.480478]\n",
      "[Epoch 51/100] [Batch 175/347] [D loss: 0.547667] [G loss: 0.485253]\n",
      "[Epoch 51/100] [Batch 176/347] [D loss: 0.547502] [G loss: 0.488109]\n",
      "[Epoch 51/100] [Batch 177/347] [D loss: 0.547301] [G loss: 0.484856]\n",
      "[Epoch 51/100] [Batch 178/347] [D loss: 0.547074] [G loss: 0.478575]\n",
      "[Epoch 51/100] [Batch 179/347] [D loss: 0.546871] [G loss: 0.474617]\n",
      "[Epoch 51/100] [Batch 180/347] [D loss: 0.546644] [G loss: 0.470111]\n",
      "[Epoch 51/100] [Batch 181/347] [D loss: 0.546477] [G loss: 0.472166]\n",
      "[Epoch 51/100] [Batch 182/347] [D loss: 0.546300] [G loss: 0.472168]\n",
      "[Epoch 51/100] [Batch 183/347] [D loss: 0.546120] [G loss: 0.472883]\n",
      "[Epoch 51/100] [Batch 184/347] [D loss: 0.545958] [G loss: 0.474363]\n",
      "[Epoch 51/100] [Batch 185/347] [D loss: 0.545733] [G loss: 0.470416]\n",
      "[Epoch 51/100] [Batch 186/347] [D loss: 0.545519] [G loss: 0.468306]\n",
      "[Epoch 51/100] [Batch 187/347] [D loss: 0.545322] [G loss: 0.464449]\n",
      "[Epoch 51/100] [Batch 188/347] [D loss: 0.545023] [G loss: 0.455588]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 189/347] [D loss: 0.544786] [G loss: 0.448364]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 190/347] [D loss: 0.544565] [G loss: 0.444590]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 191/347] [D loss: 0.544307] [G loss: 0.440738]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 192/347] [D loss: 0.544130] [G loss: 0.439419]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 193/347] [D loss: 0.543898] [G loss: 0.438476]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 194/347] [D loss: 0.543664] [G loss: 0.434628]\n",
      "[Epoch 51/100] [Batch 195/347] [D loss: 0.543442] [G loss: 0.435807]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 196/347] [D loss: 0.543207] [G loss: 0.432251]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 197/347] [D loss: 0.543043] [G loss: 0.429790]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 198/347] [D loss: 0.542872] [G loss: 0.426055]\n",
      "[Epoch 51/100] [Batch 199/347] [D loss: 0.542662] [G loss: 0.427292]\n",
      "[Epoch 51/100] [Batch 200/347] [D loss: 0.542436] [G loss: 0.432669]\n",
      "[Epoch 51/100] [Batch 201/347] [D loss: 0.542229] [G loss: 0.436375]\n",
      "[Epoch 51/100] [Batch 202/347] [D loss: 0.541970] [G loss: 0.440828]\n",
      "[Epoch 51/100] [Batch 203/347] [D loss: 0.541760] [G loss: 0.440482]\n",
      "[Epoch 51/100] [Batch 204/347] [D loss: 0.541630] [G loss: 0.430841]\n",
      "[Epoch 51/100] [Batch 205/347] [D loss: 0.541490] [G loss: 0.426858]\n",
      "[Epoch 51/100] [Batch 206/347] [D loss: 0.541299] [G loss: 0.429429]\n",
      "[Epoch 51/100] [Batch 207/347] [D loss: 0.541118] [G loss: 0.430983]\n",
      "[Epoch 51/100] [Batch 208/347] [D loss: 0.540950] [G loss: 0.433924]\n",
      "[Epoch 51/100] [Batch 209/347] [D loss: 0.540690] [G loss: 0.428791]\n",
      "[Epoch 51/100] [Batch 210/347] [D loss: 0.540480] [G loss: 0.427554]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 211/347] [D loss: 0.540217] [G loss: 0.420464]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 212/347] [D loss: 0.539845] [G loss: 0.404148]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 213/347] [D loss: 0.539595] [G loss: 0.403548]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 214/347] [D loss: 0.539343] [G loss: 0.402494]\n",
      "[Epoch 51/100] [Batch 215/347] [D loss: 0.539149] [G loss: 0.402873]\n",
      "[Epoch 51/100] [Batch 216/347] [D loss: 0.539083] [G loss: 0.417944]\n",
      "[Epoch 51/100] [Batch 217/347] [D loss: 0.539007] [G loss: 0.431404]\n",
      "[Epoch 51/100] [Batch 218/347] [D loss: 0.538916] [G loss: 0.444989]\n",
      "[Epoch 51/100] [Batch 219/347] [D loss: 0.538765] [G loss: 0.450639]\n",
      "[Epoch 51/100] [Batch 220/347] [D loss: 0.538590] [G loss: 0.454100]\n",
      "[Epoch 51/100] [Batch 221/347] [D loss: 0.538386] [G loss: 0.453797]\n",
      "[Epoch 51/100] [Batch 222/347] [D loss: 0.538101] [G loss: 0.445086]\n",
      "[Epoch 51/100] [Batch 223/347] [D loss: 0.537688] [G loss: 0.426201]\n",
      "[Epoch 51/100] [Batch 224/347] [D loss: 0.537179] [G loss: 0.404290]\n",
      "[Epoch 51/100] [Batch 225/347] [D loss: 0.536739] [G loss: 0.403669]\n",
      "[Epoch 51/100] [Batch 226/347] [D loss: 0.536301] [G loss: 0.422246]\n",
      "[Epoch 51/100] [Batch 227/347] [D loss: 0.536005] [G loss: 0.432194]\n",
      "[Epoch 51/100] [Batch 228/347] [D loss: 0.535779] [G loss: 0.434838]\n",
      "[Epoch 51/100] [Batch 229/347] [D loss: 0.535609] [G loss: 0.431321]\n",
      "[Epoch 51/100] [Batch 230/347] [D loss: 0.535449] [G loss: 0.426329]\n",
      "[Epoch 51/100] [Batch 231/347] [D loss: 0.535178] [G loss: 0.420622]\n",
      "[Epoch 51/100] [Batch 232/347] [D loss: 0.534994] [G loss: 0.413529]\n",
      "[Epoch 51/100] [Batch 233/347] [D loss: 0.534859] [G loss: 0.402770]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 234/347] [D loss: 0.534733] [G loss: 0.394411]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 235/347] [D loss: 0.534637] [G loss: 0.392453]\n",
      "[Epoch 51/100] [Batch 236/347] [D loss: 0.534521] [G loss: 0.401518]\n",
      "[Epoch 51/100] [Batch 237/347] [D loss: 0.534338] [G loss: 0.406630]\n",
      "[Epoch 51/100] [Batch 238/347] [D loss: 0.534105] [G loss: 0.404953]\n",
      "[Epoch 51/100] [Batch 239/347] [D loss: 0.533832] [G loss: 0.399933]\n",
      "[Epoch 51/100] [Batch 240/347] [D loss: 0.533595] [G loss: 0.397034]\n",
      "[Epoch 51/100] [Batch 241/347] [D loss: 0.533375] [G loss: 0.396822]\n",
      "[Epoch 51/100] [Batch 242/347] [D loss: 0.533206] [G loss: 0.398624]\n",
      "[Epoch 51/100] [Batch 243/347] [D loss: 0.533052] [G loss: 0.399676]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 244/347] [D loss: 0.532732] [G loss: 0.390657]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 245/347] [D loss: 0.532359] [G loss: 0.382834]\n",
      "[Epoch 51/100] [Batch 246/347] [D loss: 0.531926] [G loss: 0.390604]\n",
      "[Epoch 51/100] [Batch 247/347] [D loss: 0.531493] [G loss: 0.404639]\n",
      "[Epoch 51/100] [Batch 248/347] [D loss: 0.531375] [G loss: 0.396395]\n",
      "[Epoch 51/100] [Batch 249/347] [D loss: 0.531303] [G loss: 0.384594]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 250/347] [D loss: 0.531285] [G loss: 0.372487]\n",
      "[Epoch 51/100] [Batch 251/347] [D loss: 0.531290] [G loss: 0.382440]\n",
      "[Epoch 51/100] [Batch 252/347] [D loss: 0.531167] [G loss: 0.388938]\n",
      "[Epoch 51/100] [Batch 253/347] [D loss: 0.530889] [G loss: 0.383037]\n",
      "[Epoch 51/100] [Batch 254/347] [D loss: 0.530764] [G loss: 0.387723]\n",
      "[Epoch 51/100] [Batch 255/347] [D loss: 0.530579] [G loss: 0.388275]\n",
      "[Epoch 51/100] [Batch 256/347] [D loss: 0.530260] [G loss: 0.379971]\n",
      "[Epoch 51/100] [Batch 257/347] [D loss: 0.529966] [G loss: 0.377095]\n",
      "[Epoch 51/100] [Batch 258/347] [D loss: 0.529562] [G loss: 0.373403]\n",
      "[Epoch 51/100] [Batch 259/347] [D loss: 0.529242] [G loss: 0.379213]\n",
      "[Epoch 51/100] [Batch 260/347] [D loss: 0.529000] [G loss: 0.379094]\n",
      "[Epoch 51/100] [Batch 261/347] [D loss: 0.528847] [G loss: 0.375481]\n",
      "[Epoch 51/100] [Batch 262/347] [D loss: 0.528641] [G loss: 0.374371]\n",
      "[Epoch 51/100] [Batch 263/347] [D loss: 0.528381] [G loss: 0.375993]\n",
      "[Epoch 51/100] [Batch 264/347] [D loss: 0.528150] [G loss: 0.377454]\n",
      "[Epoch 51/100] [Batch 265/347] [D loss: 0.527933] [G loss: 0.376914]\n",
      "[Epoch 51/100] [Batch 266/347] [D loss: 0.527738] [G loss: 0.376339]\n",
      "[Epoch 51/100] [Batch 267/347] [D loss: 0.527512] [G loss: 0.378199]\n",
      "[Epoch 51/100] [Batch 268/347] [D loss: 0.527318] [G loss: 0.377625]\n",
      "[Epoch 51/100] [Batch 269/347] [D loss: 0.527120] [G loss: 0.376750]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 270/347] [D loss: 0.526995] [G loss: 0.370620]\n",
      "[Epoch 51/100] [Batch 271/347] [D loss: 0.526786] [G loss: 0.372450]\n",
      "[Epoch 51/100] [Batch 272/347] [D loss: 0.526382] [G loss: 0.384550]\n",
      "[Epoch 51/100] [Batch 273/347] [D loss: 0.526203] [G loss: 0.384911]\n",
      "[Epoch 51/100] [Batch 274/347] [D loss: 0.525954] [G loss: 0.385574]\n",
      "[Epoch 51/100] [Batch 275/347] [D loss: 0.525897] [G loss: 0.377421]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 276/347] [D loss: 0.526027] [G loss: 0.358817]\n",
      "[Epoch 51/100] [Batch 277/347] [D loss: 0.525908] [G loss: 0.359045]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 278/347] [D loss: 0.525791] [G loss: 0.358684]\n",
      "[Epoch 51/100] [Batch 279/347] [D loss: 0.525582] [G loss: 0.359789]\n",
      "[Epoch 51/100] [Batch 280/347] [D loss: 0.525359] [G loss: 0.359664]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 281/347] [D loss: 0.525126] [G loss: 0.358335]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 282/347] [D loss: 0.524959] [G loss: 0.357369]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 283/347] [D loss: 0.524755] [G loss: 0.354081]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 284/347] [D loss: 0.524557] [G loss: 0.351239]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 285/347] [D loss: 0.524343] [G loss: 0.349966]\n",
      "[Epoch 51/100] [Batch 286/347] [D loss: 0.523850] [G loss: 0.356055]\n",
      "[Epoch 51/100] [Batch 287/347] [D loss: 0.523587] [G loss: 0.357963]\n",
      "[Epoch 51/100] [Batch 288/347] [D loss: 0.523335] [G loss: 0.359542]\n",
      "[Epoch 51/100] [Batch 289/347] [D loss: 0.523059] [G loss: 0.362843]\n",
      "[Epoch 51/100] [Batch 290/347] [D loss: 0.523231] [G loss: 0.350019]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 291/347] [D loss: 0.523265] [G loss: 0.348442]\n",
      "[Epoch 51/100] [Batch 292/347] [D loss: 0.523243] [G loss: 0.353237]\n",
      "[Epoch 51/100] [Batch 293/347] [D loss: 0.523248] [G loss: 0.359568]\n",
      "[Epoch 51/100] [Batch 294/347] [D loss: 0.523216] [G loss: 0.365873]\n",
      "[Epoch 51/100] [Batch 295/347] [D loss: 0.523026] [G loss: 0.366627]\n",
      "[Epoch 51/100] [Batch 296/347] [D loss: 0.522844] [G loss: 0.366894]\n",
      "[Epoch 51/100] [Batch 297/347] [D loss: 0.522754] [G loss: 0.373146]\n",
      "[Epoch 51/100] [Batch 298/347] [D loss: 0.522512] [G loss: 0.368232]\n",
      "[Epoch 51/100] [Batch 299/347] [D loss: 0.522334] [G loss: 0.364843]\n",
      "[Epoch 51/100] [Batch 300/347] [D loss: 0.522195] [G loss: 0.363636]\n",
      "[Epoch 51/100] [Batch 301/347] [D loss: 0.521722] [G loss: 0.351177]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 302/347] [D loss: 0.521392] [G loss: 0.342650]\n",
      "[Epoch 51/100] [Batch 303/347] [D loss: 0.520910] [G loss: 0.344379]\n",
      "[Epoch 51/100] [Batch 304/347] [D loss: 0.520477] [G loss: 0.354479]\n",
      "[Epoch 51/100] [Batch 305/347] [D loss: 0.520235] [G loss: 0.354754]\n",
      "[Epoch 51/100] [Batch 306/347] [D loss: 0.520095] [G loss: 0.354008]\n",
      "[Epoch 51/100] [Batch 307/347] [D loss: 0.520115] [G loss: 0.346882]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 308/347] [D loss: 0.520156] [G loss: 0.340068]\n",
      "[Epoch 51/100] [Batch 309/347] [D loss: 0.520222] [G loss: 0.347457]\n",
      "[Epoch 51/100] [Batch 310/347] [D loss: 0.520273] [G loss: 0.361620]\n",
      "[Epoch 51/100] [Batch 311/347] [D loss: 0.520115] [G loss: 0.361146]\n",
      "[Epoch 51/100] [Batch 312/347] [D loss: 0.519991] [G loss: 0.357939]\n",
      "[Epoch 51/100] [Batch 313/347] [D loss: 0.519761] [G loss: 0.350543]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 314/347] [D loss: 0.519360] [G loss: 0.337575]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 315/347] [D loss: 0.519017] [G loss: 0.335899]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 316/347] [D loss: 0.518919] [G loss: 0.334523]\n",
      "[Epoch 51/100] [Batch 317/347] [D loss: 0.518870] [G loss: 0.335518]\n",
      "[Epoch 51/100] [Batch 318/347] [D loss: 0.519043] [G loss: 0.349986]\n",
      "[Epoch 51/100] [Batch 319/347] [D loss: 0.519161] [G loss: 0.363129]\n",
      "[Epoch 51/100] [Batch 320/347] [D loss: 0.518984] [G loss: 0.362842]\n",
      "[Epoch 51/100] [Batch 321/347] [D loss: 0.518760] [G loss: 0.357353]\n",
      "[Epoch 51/100] [Batch 322/347] [D loss: 0.518520] [G loss: 0.351453]\n",
      "[Epoch 51/100] [Batch 323/347] [D loss: 0.518259] [G loss: 0.344208]\n",
      "[Epoch 51/100] [Batch 324/347] [D loss: 0.518050] [G loss: 0.339397]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 325/347] [D loss: 0.517788] [G loss: 0.333040]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 326/347] [D loss: 0.517487] [G loss: 0.325765]\n",
      "[Epoch 51/100] [Batch 327/347] [D loss: 0.517068] [G loss: 0.333960]\n",
      "[Epoch 51/100] [Batch 328/347] [D loss: 0.516770] [G loss: 0.341287]\n",
      "[Epoch 51/100] [Batch 329/347] [D loss: 0.516644] [G loss: 0.339316]\n",
      "[Epoch 51/100] [Batch 330/347] [D loss: 0.516588] [G loss: 0.333697]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 331/347] [D loss: 0.516725] [G loss: 0.322354]\n",
      "[Epoch 51/100] [Batch 332/347] [D loss: 0.516922] [G loss: 0.342226]\n",
      "[Epoch 51/100] [Batch 333/347] [D loss: 0.516785] [G loss: 0.341012]\n",
      "[Epoch 51/100] [Batch 334/347] [D loss: 0.516598] [G loss: 0.334712]\n",
      "[Epoch 51/100] [Batch 335/347] [D loss: 0.516448] [G loss: 0.333168]\n",
      "[Epoch 51/100] [Batch 336/347] [D loss: 0.516313] [G loss: 0.332479]\n",
      "[Epoch 51/100] [Batch 337/347] [D loss: 0.516221] [G loss: 0.336754]\n",
      "[Epoch 51/100] [Batch 338/347] [D loss: 0.516214] [G loss: 0.344614]\n",
      "[Epoch 51/100] [Batch 339/347] [D loss: 0.516112] [G loss: 0.344814]\n",
      "[Epoch 51/100] [Batch 340/347] [D loss: 0.515914] [G loss: 0.340983]\n",
      "[Epoch 51/100] [Batch 341/347] [D loss: 0.515773] [G loss: 0.340905]\n",
      "[Epoch 51/100] [Batch 342/347] [D loss: 0.515421] [G loss: 0.328510]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 51/100] [Batch 343/347] [D loss: 0.515020] [G loss: 0.320097]\n",
      "[Epoch 51/100] [Batch 344/347] [D loss: 0.514633] [G loss: 0.329175]\n",
      "[Epoch 51/100] [Batch 345/347] [D loss: 0.514262] [G loss: 0.343604]\n",
      "[Epoch 51/100] [Batch 346/347] [D loss: 0.514169] [G loss: 0.343136]\n",
      "[Epoch 51/100] [Batch 347/347] [D loss: 0.514128] [G loss: 0.337153]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 1/347] [D loss: 0.514525] [G loss: 0.323900]\n",
      "[Epoch 52/100] [Batch 2/347] [D loss: 0.514382] [G loss: 0.326579]\n",
      "[Epoch 52/100] [Batch 3/347] [D loss: 0.514340] [G loss: 0.326444]\n",
      "[Epoch 52/100] [Batch 4/347] [D loss: 0.514208] [G loss: 0.326777]\n",
      "[Epoch 52/100] [Batch 5/347] [D loss: 0.514043] [G loss: 0.326392]\n",
      "[Epoch 52/100] [Batch 6/347] [D loss: 0.513929] [G loss: 0.324233]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 7/347] [D loss: 0.513686] [G loss: 0.323884]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 8/347] [D loss: 0.513573] [G loss: 0.322825]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 9/347] [D loss: 0.513479] [G loss: 0.322242]\n",
      "[Epoch 52/100] [Batch 10/347] [D loss: 0.513376] [G loss: 0.323202]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 11/347] [D loss: 0.513427] [G loss: 0.321870]\n",
      "[Epoch 52/100] [Batch 12/347] [D loss: 0.513363] [G loss: 0.324003]\n",
      "[Epoch 52/100] [Batch 13/347] [D loss: 0.513263] [G loss: 0.322671]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 14/347] [D loss: 0.513193] [G loss: 0.321516]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 15/347] [D loss: 0.512942] [G loss: 0.311728]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 16/347] [D loss: 0.512774] [G loss: 0.309414]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 17/347] [D loss: 0.512723] [G loss: 0.307512]\n",
      "[Epoch 52/100] [Batch 18/347] [D loss: 0.512627] [G loss: 0.307666]\n",
      "[Epoch 52/100] [Batch 19/347] [D loss: 0.512599] [G loss: 0.312003]\n",
      "[Epoch 52/100] [Batch 20/347] [D loss: 0.512536] [G loss: 0.315668]\n",
      "[Epoch 52/100] [Batch 21/347] [D loss: 0.512341] [G loss: 0.309991]\n",
      "[Epoch 52/100] [Batch 22/347] [D loss: 0.512221] [G loss: 0.308326]\n",
      "[Epoch 52/100] [Batch 23/347] [D loss: 0.512067] [G loss: 0.307925]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 24/347] [D loss: 0.511852] [G loss: 0.306878]\n",
      "[Epoch 52/100] [Batch 25/347] [D loss: 0.511832] [G loss: 0.307426]\n",
      "[Epoch 52/100] [Batch 26/347] [D loss: 0.511733] [G loss: 0.307631]\n",
      "[Epoch 52/100] [Batch 27/347] [D loss: 0.511793] [G loss: 0.309354]\n",
      "[Epoch 52/100] [Batch 28/347] [D loss: 0.511932] [G loss: 0.316265]\n",
      "[Epoch 52/100] [Batch 29/347] [D loss: 0.511967] [G loss: 0.319669]\n",
      "[Epoch 52/100] [Batch 30/347] [D loss: 0.511919] [G loss: 0.321054]\n",
      "[Epoch 52/100] [Batch 31/347] [D loss: 0.511812] [G loss: 0.320818]\n",
      "[Epoch 52/100] [Batch 32/347] [D loss: 0.511675] [G loss: 0.317458]\n",
      "[Epoch 52/100] [Batch 33/347] [D loss: 0.511508] [G loss: 0.315144]\n",
      "[Epoch 52/100] [Batch 34/347] [D loss: 0.511331] [G loss: 0.310029]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 35/347] [D loss: 0.511005] [G loss: 0.304103]\n",
      "[Epoch 52/100] [Batch 36/347] [D loss: 0.510696] [G loss: 0.310912]\n",
      "[Epoch 52/100] [Batch 37/347] [D loss: 0.510463] [G loss: 0.315547]\n",
      "[Epoch 52/100] [Batch 38/347] [D loss: 0.510228] [G loss: 0.319750]\n",
      "[Epoch 52/100] [Batch 39/347] [D loss: 0.510184] [G loss: 0.315698]\n",
      "[Epoch 52/100] [Batch 40/347] [D loss: 0.510208] [G loss: 0.314208]\n",
      "[Epoch 52/100] [Batch 41/347] [D loss: 0.510282] [G loss: 0.304512]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 42/347] [D loss: 0.510441] [G loss: 0.296979]\n",
      "[Epoch 52/100] [Batch 43/347] [D loss: 0.510670] [G loss: 0.311386]\n",
      "[Epoch 52/100] [Batch 44/347] [D loss: 0.510701] [G loss: 0.317025]\n",
      "[Epoch 52/100] [Batch 45/347] [D loss: 0.510500] [G loss: 0.308831]\n",
      "[Epoch 52/100] [Batch 46/347] [D loss: 0.510085] [G loss: 0.303839]\n",
      "[Epoch 52/100] [Batch 47/347] [D loss: 0.509718] [G loss: 0.315486]\n",
      "[Epoch 52/100] [Batch 48/347] [D loss: 0.509290] [G loss: 0.337424]\n",
      "[Epoch 52/100] [Batch 49/347] [D loss: 0.509320] [G loss: 0.333188]\n",
      "[Epoch 52/100] [Batch 50/347] [D loss: 0.509500] [G loss: 0.319615]\n",
      "[Epoch 52/100] [Batch 51/347] [D loss: 0.509464] [G loss: 0.317970]\n",
      "[Epoch 52/100] [Batch 52/347] [D loss: 0.509245] [G loss: 0.324717]\n",
      "[Epoch 52/100] [Batch 53/347] [D loss: 0.508814] [G loss: 0.340508]\n",
      "[Epoch 52/100] [Batch 54/347] [D loss: 0.508486] [G loss: 0.350766]\n",
      "[Epoch 52/100] [Batch 55/347] [D loss: 0.508501] [G loss: 0.347156]\n",
      "[Epoch 52/100] [Batch 56/347] [D loss: 0.508776] [G loss: 0.329379]\n",
      "[Epoch 52/100] [Batch 57/347] [D loss: 0.509025] [G loss: 0.314156]\n",
      "[Epoch 52/100] [Batch 58/347] [D loss: 0.509116] [G loss: 0.307531]\n",
      "[Epoch 52/100] [Batch 59/347] [D loss: 0.508853] [G loss: 0.321011]\n",
      "[Epoch 52/100] [Batch 60/347] [D loss: 0.508358] [G loss: 0.342834]\n",
      "[Epoch 52/100] [Batch 61/347] [D loss: 0.508118] [G loss: 0.347519]\n",
      "[Epoch 52/100] [Batch 62/347] [D loss: 0.508224] [G loss: 0.338530]\n",
      "[Epoch 52/100] [Batch 63/347] [D loss: 0.508425] [G loss: 0.323586]\n",
      "[Epoch 52/100] [Batch 64/347] [D loss: 0.508664] [G loss: 0.305862]\n",
      "[Epoch 52/100] [Batch 65/347] [D loss: 0.508919] [G loss: 0.304579]\n",
      "[Epoch 52/100] [Batch 66/347] [D loss: 0.508602] [G loss: 0.304960]\n",
      "[Epoch 52/100] [Batch 67/347] [D loss: 0.508110] [G loss: 0.325525]\n",
      "[Epoch 52/100] [Batch 68/347] [D loss: 0.507878] [G loss: 0.331286]\n",
      "[Epoch 52/100] [Batch 69/347] [D loss: 0.507595] [G loss: 0.342263]\n",
      "[Epoch 52/100] [Batch 70/347] [D loss: 0.507501] [G loss: 0.340936]\n",
      "[Epoch 52/100] [Batch 71/347] [D loss: 0.507738] [G loss: 0.328346]\n",
      "[Epoch 52/100] [Batch 72/347] [D loss: 0.507796] [G loss: 0.326259]\n",
      "[Epoch 52/100] [Batch 73/347] [D loss: 0.507698] [G loss: 0.327126]\n",
      "[Epoch 52/100] [Batch 74/347] [D loss: 0.507787] [G loss: 0.319196]\n",
      "[Epoch 52/100] [Batch 75/347] [D loss: 0.507820] [G loss: 0.315222]\n",
      "[Epoch 52/100] [Batch 76/347] [D loss: 0.507935] [G loss: 0.305400]\n",
      "[Epoch 52/100] [Batch 77/347] [D loss: 0.508309] [G loss: 0.301719]\n",
      "[Epoch 52/100] [Batch 78/347] [D loss: 0.508561] [G loss: 0.306316]\n",
      "[Epoch 52/100] [Batch 79/347] [D loss: 0.508684] [G loss: 0.315108]\n",
      "[Epoch 52/100] [Batch 80/347] [D loss: 0.508538] [G loss: 0.310291]\n",
      "[Epoch 52/100] [Batch 81/347] [D loss: 0.508511] [G loss: 0.311936]\n",
      "[Epoch 52/100] [Batch 82/347] [D loss: 0.508494] [G loss: 0.314249]\n",
      "[Epoch 52/100] [Batch 83/347] [D loss: 0.508377] [G loss: 0.313068]\n",
      "[Epoch 52/100] [Batch 84/347] [D loss: 0.508325] [G loss: 0.316367]\n",
      "[Epoch 52/100] [Batch 85/347] [D loss: 0.508244] [G loss: 0.315944]\n",
      "[Epoch 52/100] [Batch 86/347] [D loss: 0.508166] [G loss: 0.314931]\n",
      "[Epoch 52/100] [Batch 87/347] [D loss: 0.508097] [G loss: 0.315094]\n",
      "[Epoch 52/100] [Batch 88/347] [D loss: 0.508042] [G loss: 0.314904]\n",
      "[Epoch 52/100] [Batch 89/347] [D loss: 0.507990] [G loss: 0.316165]\n",
      "[Epoch 52/100] [Batch 90/347] [D loss: 0.507917] [G loss: 0.314957]\n",
      "[Epoch 52/100] [Batch 91/347] [D loss: 0.507821] [G loss: 0.312961]\n",
      "[Epoch 52/100] [Batch 92/347] [D loss: 0.507764] [G loss: 0.312420]\n",
      "[Epoch 52/100] [Batch 93/347] [D loss: 0.507706] [G loss: 0.311655]\n",
      "[Epoch 52/100] [Batch 94/347] [D loss: 0.507590] [G loss: 0.307083]\n",
      "[Epoch 52/100] [Batch 95/347] [D loss: 0.507512] [G loss: 0.305396]\n",
      "[Epoch 52/100] [Batch 96/347] [D loss: 0.507469] [G loss: 0.305973]\n",
      "[Epoch 52/100] [Batch 97/347] [D loss: 0.507401] [G loss: 0.304723]\n",
      "[Epoch 52/100] [Batch 98/347] [D loss: 0.507366] [G loss: 0.305597]\n",
      "[Epoch 52/100] [Batch 99/347] [D loss: 0.507307] [G loss: 0.305300]\n",
      "[Epoch 52/100] [Batch 100/347] [D loss: 0.507257] [G loss: 0.304355]\n",
      "[Epoch 52/100] [Batch 101/347] [D loss: 0.507172] [G loss: 0.301680]\n",
      "[Epoch 52/100] [Batch 102/347] [D loss: 0.507068] [G loss: 0.298221]\n",
      "[Epoch 52/100] [Batch 103/347] [D loss: 0.507025] [G loss: 0.298507]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 104/347] [D loss: 0.506896] [G loss: 0.292829]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 105/347] [D loss: 0.506799] [G loss: 0.285613]\n",
      "[Epoch 52/100] [Batch 106/347] [D loss: 0.506689] [G loss: 0.287662]\n",
      "[Epoch 52/100] [Batch 107/347] [D loss: 0.506667] [G loss: 0.291151]\n",
      "[Epoch 52/100] [Batch 108/347] [D loss: 0.506645] [G loss: 0.292683]\n",
      "[Epoch 52/100] [Batch 109/347] [D loss: 0.506543] [G loss: 0.296321]\n",
      "[Epoch 52/100] [Batch 110/347] [D loss: 0.506660] [G loss: 0.292162]\n",
      "[Epoch 52/100] [Batch 111/347] [D loss: 0.506698] [G loss: 0.291879]\n",
      "[Epoch 52/100] [Batch 112/347] [D loss: 0.506740] [G loss: 0.294146]\n",
      "[Epoch 52/100] [Batch 113/347] [D loss: 0.506892] [G loss: 0.310417]\n",
      "[Epoch 52/100] [Batch 114/347] [D loss: 0.506908] [G loss: 0.316999]\n",
      "[Epoch 52/100] [Batch 115/347] [D loss: 0.506669] [G loss: 0.300003]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 116/347] [D loss: 0.506375] [G loss: 0.282803]\n",
      "[Epoch 52/100] [Batch 117/347] [D loss: 0.506127] [G loss: 0.285510]\n",
      "[Epoch 52/100] [Batch 118/347] [D loss: 0.505879] [G loss: 0.297981]\n",
      "[Epoch 52/100] [Batch 119/347] [D loss: 0.505796] [G loss: 0.298051]\n",
      "[Epoch 52/100] [Batch 120/347] [D loss: 0.505867] [G loss: 0.290913]\n",
      "[Epoch 52/100] [Batch 121/347] [D loss: 0.505833] [G loss: 0.289658]\n",
      "[Epoch 52/100] [Batch 122/347] [D loss: 0.505852] [G loss: 0.289010]\n",
      "[Epoch 52/100] [Batch 123/347] [D loss: 0.505926] [G loss: 0.286895]\n",
      "[Epoch 52/100] [Batch 124/347] [D loss: 0.505949] [G loss: 0.283534]\n",
      "[Epoch 52/100] [Batch 125/347] [D loss: 0.506014] [G loss: 0.286068]\n",
      "[Epoch 52/100] [Batch 126/347] [D loss: 0.506049] [G loss: 0.289962]\n",
      "[Epoch 52/100] [Batch 127/347] [D loss: 0.506041] [G loss: 0.288441]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 128/347] [D loss: 0.505905] [G loss: 0.280066]\n",
      "[Epoch 52/100] [Batch 129/347] [D loss: 0.505719] [G loss: 0.283720]\n",
      "[Epoch 52/100] [Batch 130/347] [D loss: 0.505490] [G loss: 0.299292]\n",
      "[Epoch 52/100] [Batch 131/347] [D loss: 0.505264] [G loss: 0.310233]\n",
      "[Epoch 52/100] [Batch 132/347] [D loss: 0.504955] [G loss: 0.329441]\n",
      "[Epoch 52/100] [Batch 133/347] [D loss: 0.504834] [G loss: 0.334780]\n",
      "[Epoch 52/100] [Batch 134/347] [D loss: 0.505039] [G loss: 0.320092]\n",
      "[Epoch 52/100] [Batch 135/347] [D loss: 0.505071] [G loss: 0.316788]\n",
      "[Epoch 52/100] [Batch 136/347] [D loss: 0.505116] [G loss: 0.308767]\n",
      "[Epoch 52/100] [Batch 137/347] [D loss: 0.505035] [G loss: 0.309949]\n",
      "[Epoch 52/100] [Batch 138/347] [D loss: 0.504690] [G loss: 0.327956]\n",
      "[Epoch 52/100] [Batch 139/347] [D loss: 0.504391] [G loss: 0.341113]\n",
      "[Epoch 52/100] [Batch 140/347] [D loss: 0.504207] [G loss: 0.351727]\n",
      "[Epoch 52/100] [Batch 141/347] [D loss: 0.503886] [G loss: 0.366146]\n",
      "[Epoch 52/100] [Batch 142/347] [D loss: 0.503776] [G loss: 0.368876]\n",
      "[Epoch 52/100] [Batch 143/347] [D loss: 0.503624] [G loss: 0.371599]\n",
      "[Epoch 52/100] [Batch 144/347] [D loss: 0.503636] [G loss: 0.363908]\n",
      "[Epoch 52/100] [Batch 145/347] [D loss: 0.503931] [G loss: 0.343104]\n",
      "[Epoch 52/100] [Batch 146/347] [D loss: 0.504061] [G loss: 0.330369]\n",
      "[Epoch 52/100] [Batch 147/347] [D loss: 0.504185] [G loss: 0.321140]\n",
      "[Epoch 52/100] [Batch 148/347] [D loss: 0.504340] [G loss: 0.313734]\n",
      "[Epoch 52/100] [Batch 149/347] [D loss: 0.504334] [G loss: 0.315866]\n",
      "[Epoch 52/100] [Batch 150/347] [D loss: 0.504247] [G loss: 0.323419]\n",
      "[Epoch 52/100] [Batch 151/347] [D loss: 0.504151] [G loss: 0.328696]\n",
      "[Epoch 52/100] [Batch 152/347] [D loss: 0.503972] [G loss: 0.335713]\n",
      "[Epoch 52/100] [Batch 153/347] [D loss: 0.503851] [G loss: 0.338189]\n",
      "[Epoch 52/100] [Batch 154/347] [D loss: 0.503902] [G loss: 0.332734]\n",
      "[Epoch 52/100] [Batch 155/347] [D loss: 0.503941] [G loss: 0.331482]\n",
      "[Epoch 52/100] [Batch 156/347] [D loss: 0.503854] [G loss: 0.335265]\n",
      "[Epoch 52/100] [Batch 157/347] [D loss: 0.503855] [G loss: 0.334637]\n",
      "[Epoch 52/100] [Batch 158/347] [D loss: 0.503832] [G loss: 0.336393]\n",
      "[Epoch 52/100] [Batch 159/347] [D loss: 0.503853] [G loss: 0.334323]\n",
      "[Epoch 52/100] [Batch 160/347] [D loss: 0.504041] [G loss: 0.325740]\n",
      "[Epoch 52/100] [Batch 161/347] [D loss: 0.503938] [G loss: 0.332571]\n",
      "[Epoch 52/100] [Batch 162/347] [D loss: 0.503709] [G loss: 0.343119]\n",
      "[Epoch 52/100] [Batch 163/347] [D loss: 0.503554] [G loss: 0.345382]\n",
      "[Epoch 52/100] [Batch 164/347] [D loss: 0.503696] [G loss: 0.334858]\n",
      "[Epoch 52/100] [Batch 165/347] [D loss: 0.503977] [G loss: 0.318927]\n",
      "[Epoch 52/100] [Batch 166/347] [D loss: 0.504424] [G loss: 0.292915]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 167/347] [D loss: 0.504806] [G loss: 0.279855]\n",
      "[Epoch 52/100] [Batch 168/347] [D loss: 0.504963] [G loss: 0.283862]\n",
      "[Epoch 52/100] [Batch 169/347] [D loss: 0.505083] [G loss: 0.286049]\n",
      "[Epoch 52/100] [Batch 170/347] [D loss: 0.505142] [G loss: 0.293250]\n",
      "[Epoch 52/100] [Batch 171/347] [D loss: 0.505112] [G loss: 0.293824]\n",
      "[Epoch 52/100] [Batch 172/347] [D loss: 0.505121] [G loss: 0.295657]\n",
      "[Epoch 52/100] [Batch 173/347] [D loss: 0.505060] [G loss: 0.295299]\n",
      "[Epoch 52/100] [Batch 174/347] [D loss: 0.505113] [G loss: 0.299881]\n",
      "[Epoch 52/100] [Batch 175/347] [D loss: 0.505151] [G loss: 0.305398]\n",
      "[Epoch 52/100] [Batch 176/347] [D loss: 0.505183] [G loss: 0.309050]\n",
      "[Epoch 52/100] [Batch 177/347] [D loss: 0.505124] [G loss: 0.306577]\n",
      "[Epoch 52/100] [Batch 178/347] [D loss: 0.505002] [G loss: 0.301021]\n",
      "[Epoch 52/100] [Batch 179/347] [D loss: 0.504918] [G loss: 0.297932]\n",
      "[Epoch 52/100] [Batch 180/347] [D loss: 0.504823] [G loss: 0.294235]\n",
      "[Epoch 52/100] [Batch 181/347] [D loss: 0.504839] [G loss: 0.297022]\n",
      "[Epoch 52/100] [Batch 182/347] [D loss: 0.504804] [G loss: 0.297749]\n",
      "[Epoch 52/100] [Batch 183/347] [D loss: 0.504809] [G loss: 0.299205]\n",
      "[Epoch 52/100] [Batch 184/347] [D loss: 0.504841] [G loss: 0.301401]\n",
      "[Epoch 52/100] [Batch 185/347] [D loss: 0.504764] [G loss: 0.298278]\n",
      "[Epoch 52/100] [Batch 186/347] [D loss: 0.504727] [G loss: 0.296903]\n",
      "[Epoch 52/100] [Batch 187/347] [D loss: 0.504654] [G loss: 0.293824]\n",
      "[Epoch 52/100] [Batch 188/347] [D loss: 0.504469] [G loss: 0.285760]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 189/347] [D loss: 0.504318] [G loss: 0.279365]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 190/347] [D loss: 0.504279] [G loss: 0.276310]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 191/347] [D loss: 0.504171] [G loss: 0.276303]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 192/347] [D loss: 0.504154] [G loss: 0.276179]\n",
      "[Epoch 52/100] [Batch 193/347] [D loss: 0.504135] [G loss: 0.276911]\n",
      "[Epoch 52/100] [Batch 194/347] [D loss: 0.504034] [G loss: 0.280325]\n",
      "[Epoch 52/100] [Batch 195/347] [D loss: 0.503965] [G loss: 0.281189]\n",
      "[Epoch 52/100] [Batch 196/347] [D loss: 0.503949] [G loss: 0.277462]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 197/347] [D loss: 0.503942] [G loss: 0.274963]\n",
      "[Epoch 52/100] [Batch 198/347] [D loss: 0.503992] [G loss: 0.271192]\n",
      "[Epoch 52/100] [Batch 199/347] [D loss: 0.503968] [G loss: 0.272435]\n",
      "[Epoch 52/100] [Batch 200/347] [D loss: 0.503909] [G loss: 0.277987]\n",
      "[Epoch 52/100] [Batch 201/347] [D loss: 0.503832] [G loss: 0.281959]\n",
      "[Epoch 52/100] [Batch 202/347] [D loss: 0.503762] [G loss: 0.286812]\n",
      "[Epoch 52/100] [Batch 203/347] [D loss: 0.503732] [G loss: 0.286859]\n",
      "[Epoch 52/100] [Batch 204/347] [D loss: 0.503857] [G loss: 0.277682]\n",
      "[Epoch 52/100] [Batch 205/347] [D loss: 0.503994] [G loss: 0.272777]\n",
      "[Epoch 52/100] [Batch 206/347] [D loss: 0.504047] [G loss: 0.276110]\n",
      "[Epoch 52/100] [Batch 207/347] [D loss: 0.504092] [G loss: 0.278403]\n",
      "[Epoch 52/100] [Batch 208/347] [D loss: 0.504182] [G loss: 0.282170]\n",
      "[Epoch 52/100] [Batch 209/347] [D loss: 0.504078] [G loss: 0.277977]\n",
      "[Epoch 52/100] [Batch 210/347] [D loss: 0.504112] [G loss: 0.278710]\n",
      "[Epoch 52/100] [Batch 211/347] [D loss: 0.504041] [G loss: 0.281780]\n",
      "[Epoch 52/100] [Batch 212/347] [D loss: 0.503809] [G loss: 0.283753]\n",
      "[Epoch 52/100] [Batch 213/347] [D loss: 0.503742] [G loss: 0.285971]\n",
      "[Epoch 52/100] [Batch 214/347] [D loss: 0.503733] [G loss: 0.285561]\n",
      "[Epoch 52/100] [Batch 215/347] [D loss: 0.503752] [G loss: 0.286644]\n",
      "[Epoch 52/100] [Batch 216/347] [D loss: 0.503984] [G loss: 0.282243]\n",
      "[Epoch 52/100] [Batch 217/347] [D loss: 0.504217] [G loss: 0.287867]\n",
      "[Epoch 52/100] [Batch 218/347] [D loss: 0.504400] [G loss: 0.302368]\n",
      "[Epoch 52/100] [Batch 219/347] [D loss: 0.504512] [G loss: 0.308943]\n",
      "[Epoch 52/100] [Batch 220/347] [D loss: 0.504598] [G loss: 0.313369]\n",
      "[Epoch 52/100] [Batch 221/347] [D loss: 0.504591] [G loss: 0.314109]\n",
      "[Epoch 52/100] [Batch 222/347] [D loss: 0.504472] [G loss: 0.306413]\n",
      "[Epoch 52/100] [Batch 223/347] [D loss: 0.504228] [G loss: 0.296176]\n",
      "[Epoch 52/100] [Batch 224/347] [D loss: 0.503841] [G loss: 0.286201]\n",
      "[Epoch 52/100] [Batch 225/347] [D loss: 0.503435] [G loss: 0.283234]\n",
      "[Epoch 52/100] [Batch 226/347] [D loss: 0.503105] [G loss: 0.292713]\n",
      "[Epoch 52/100] [Batch 227/347] [D loss: 0.503000] [G loss: 0.294627]\n",
      "[Epoch 52/100] [Batch 228/347] [D loss: 0.502982] [G loss: 0.298017]\n",
      "[Epoch 52/100] [Batch 229/347] [D loss: 0.503040] [G loss: 0.295206]\n",
      "[Epoch 52/100] [Batch 230/347] [D loss: 0.503098] [G loss: 0.290970]\n",
      "[Epoch 52/100] [Batch 231/347] [D loss: 0.503065] [G loss: 0.286142]\n",
      "[Epoch 52/100] [Batch 232/347] [D loss: 0.503086] [G loss: 0.286467]\n",
      "[Epoch 52/100] [Batch 233/347] [D loss: 0.503242] [G loss: 0.281700]\n",
      "[Epoch 52/100] [Batch 234/347] [D loss: 0.503330] [G loss: 0.277207]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 235/347] [D loss: 0.503536] [G loss: 0.271383]\n",
      "[Epoch 52/100] [Batch 236/347] [D loss: 0.503654] [G loss: 0.274307]\n",
      "[Epoch 52/100] [Batch 237/347] [D loss: 0.503700] [G loss: 0.280293]\n",
      "[Epoch 52/100] [Batch 238/347] [D loss: 0.503662] [G loss: 0.279497]\n",
      "[Epoch 52/100] [Batch 239/347] [D loss: 0.503582] [G loss: 0.275424]\n",
      "[Epoch 52/100] [Batch 240/347] [D loss: 0.503540] [G loss: 0.273427]\n",
      "[Epoch 52/100] [Batch 241/347] [D loss: 0.503530] [G loss: 0.274142]\n",
      "[Epoch 52/100] [Batch 242/347] [D loss: 0.503584] [G loss: 0.276739]\n",
      "[Epoch 52/100] [Batch 243/347] [D loss: 0.503662] [G loss: 0.278681]\n",
      "[Epoch 52/100] [Batch 244/347] [D loss: 0.503511] [G loss: 0.272255]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 245/347] [D loss: 0.503306] [G loss: 0.269810]\n",
      "[Epoch 52/100] [Batch 246/347] [D loss: 0.503036] [G loss: 0.282380]\n",
      "[Epoch 52/100] [Batch 247/347] [D loss: 0.502778] [G loss: 0.291214]\n",
      "[Epoch 52/100] [Batch 248/347] [D loss: 0.502855] [G loss: 0.288513]\n",
      "[Epoch 52/100] [Batch 249/347] [D loss: 0.503022] [G loss: 0.282476]\n",
      "[Epoch 52/100] [Batch 250/347] [D loss: 0.503236] [G loss: 0.272910]\n",
      "[Epoch 52/100] [Batch 251/347] [D loss: 0.503465] [G loss: 0.278400]\n",
      "[Epoch 52/100] [Batch 252/347] [D loss: 0.503563] [G loss: 0.279623]\n",
      "[Epoch 52/100] [Batch 253/347] [D loss: 0.503488] [G loss: 0.279843]\n",
      "[Epoch 52/100] [Batch 254/347] [D loss: 0.503567] [G loss: 0.282196]\n",
      "[Epoch 52/100] [Batch 255/347] [D loss: 0.503575] [G loss: 0.283267]\n",
      "[Epoch 52/100] [Batch 256/347] [D loss: 0.503466] [G loss: 0.281980]\n",
      "[Epoch 52/100] [Batch 257/347] [D loss: 0.503344] [G loss: 0.279597]\n",
      "[Epoch 52/100] [Batch 258/347] [D loss: 0.503124] [G loss: 0.277935]\n",
      "[Epoch 52/100] [Batch 259/347] [D loss: 0.503000] [G loss: 0.284293]\n",
      "[Epoch 52/100] [Batch 260/347] [D loss: 0.502954] [G loss: 0.284676]\n",
      "[Epoch 52/100] [Batch 261/347] [D loss: 0.503000] [G loss: 0.281610]\n",
      "[Epoch 52/100] [Batch 262/347] [D loss: 0.502970] [G loss: 0.281065]\n",
      "[Epoch 52/100] [Batch 263/347] [D loss: 0.502918] [G loss: 0.283187]\n",
      "[Epoch 52/100] [Batch 264/347] [D loss: 0.502862] [G loss: 0.285260]\n",
      "[Epoch 52/100] [Batch 265/347] [D loss: 0.502842] [G loss: 0.285423]\n",
      "[Epoch 52/100] [Batch 266/347] [D loss: 0.502842] [G loss: 0.285478]\n",
      "[Epoch 52/100] [Batch 267/347] [D loss: 0.502805] [G loss: 0.288017]\n",
      "[Epoch 52/100] [Batch 268/347] [D loss: 0.502801] [G loss: 0.288117]\n",
      "[Epoch 52/100] [Batch 269/347] [D loss: 0.502793] [G loss: 0.287972]\n",
      "[Epoch 52/100] [Batch 270/347] [D loss: 0.502852] [G loss: 0.282502]\n",
      "[Epoch 52/100] [Batch 271/347] [D loss: 0.502839] [G loss: 0.285012]\n",
      "[Epoch 52/100] [Batch 272/347] [D loss: 0.502666] [G loss: 0.297838]\n",
      "[Epoch 52/100] [Batch 273/347] [D loss: 0.502661] [G loss: 0.298922]\n",
      "[Epoch 52/100] [Batch 274/347] [D loss: 0.502616] [G loss: 0.300283]\n",
      "[Epoch 52/100] [Batch 275/347] [D loss: 0.502697] [G loss: 0.292950]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 276/347] [D loss: 0.502955] [G loss: 0.269526]\n",
      "[Epoch 52/100] [Batch 277/347] [D loss: 0.503016] [G loss: 0.269889]\n",
      "[Epoch 52/100] [Batch 278/347] [D loss: 0.503070] [G loss: 0.270319]\n",
      "[Epoch 52/100] [Batch 279/347] [D loss: 0.503047] [G loss: 0.272157]\n",
      "[Epoch 52/100] [Batch 280/347] [D loss: 0.503008] [G loss: 0.272734]\n",
      "[Epoch 52/100] [Batch 281/347] [D loss: 0.502970] [G loss: 0.272166]\n",
      "[Epoch 52/100] [Batch 282/347] [D loss: 0.502977] [G loss: 0.271904]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 283/347] [D loss: 0.502940] [G loss: 0.269407]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 284/347] [D loss: 0.502922] [G loss: 0.267247]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 285/347] [D loss: 0.502898] [G loss: 0.264473]\n",
      "[Epoch 52/100] [Batch 286/347] [D loss: 0.502625] [G loss: 0.276936]\n",
      "[Epoch 52/100] [Batch 287/347] [D loss: 0.502556] [G loss: 0.279327]\n",
      "[Epoch 52/100] [Batch 288/347] [D loss: 0.502498] [G loss: 0.281332]\n",
      "[Epoch 52/100] [Batch 289/347] [D loss: 0.502397] [G loss: 0.285097]\n",
      "[Epoch 52/100] [Batch 290/347] [D loss: 0.502680] [G loss: 0.268330]\n",
      "[Epoch 52/100] [Batch 291/347] [D loss: 0.502876] [G loss: 0.266790]\n",
      "[Epoch 52/100] [Batch 292/347] [D loss: 0.502995] [G loss: 0.273265]\n",
      "[Epoch 52/100] [Batch 293/347] [D loss: 0.503140] [G loss: 0.279813]\n",
      "[Epoch 52/100] [Batch 294/347] [D loss: 0.503258] [G loss: 0.283259]\n",
      "[Epoch 52/100] [Batch 295/347] [D loss: 0.503237] [G loss: 0.284784]\n",
      "[Epoch 52/100] [Batch 296/347] [D loss: 0.503202] [G loss: 0.285735]\n",
      "[Epoch 52/100] [Batch 297/347] [D loss: 0.503264] [G loss: 0.292723]\n",
      "[Epoch 52/100] [Batch 298/347] [D loss: 0.503195] [G loss: 0.288557]\n",
      "[Epoch 52/100] [Batch 299/347] [D loss: 0.503186] [G loss: 0.285924]\n",
      "[Epoch 52/100] [Batch 300/347] [D loss: 0.503205] [G loss: 0.285405]\n",
      "[Epoch 52/100] [Batch 301/347] [D loss: 0.502948] [G loss: 0.275413]\n",
      "[Epoch 52/100] [Batch 302/347] [D loss: 0.502799] [G loss: 0.267396]\n",
      "[Epoch 52/100] [Batch 303/347] [D loss: 0.502539] [G loss: 0.271095]\n",
      "[Epoch 52/100] [Batch 304/347] [D loss: 0.502310] [G loss: 0.281748]\n",
      "[Epoch 52/100] [Batch 305/347] [D loss: 0.502226] [G loss: 0.283279]\n",
      "[Epoch 52/100] [Batch 306/347] [D loss: 0.502239] [G loss: 0.283319]\n",
      "[Epoch 52/100] [Batch 307/347] [D loss: 0.502384] [G loss: 0.276589]\n",
      "[Epoch 52/100] [Batch 308/347] [D loss: 0.502541] [G loss: 0.269637]\n",
      "[Epoch 52/100] [Batch 309/347] [D loss: 0.502719] [G loss: 0.274869]\n",
      "[Epoch 52/100] [Batch 310/347] [D loss: 0.502893] [G loss: 0.289619]\n",
      "[Epoch 52/100] [Batch 311/347] [D loss: 0.502897] [G loss: 0.289773]\n",
      "[Epoch 52/100] [Batch 312/347] [D loss: 0.502903] [G loss: 0.287230]\n",
      "[Epoch 52/100] [Batch 313/347] [D loss: 0.502847] [G loss: 0.280452]\n",
      "[Epoch 52/100] [Batch 314/347] [D loss: 0.502651] [G loss: 0.268145]\n",
      "[Epoch 52/100] [Batch 315/347] [D loss: 0.502494] [G loss: 0.269898]\n",
      "[Epoch 52/100] [Batch 316/347] [D loss: 0.502531] [G loss: 0.269086]\n",
      "[Epoch 52/100] [Batch 317/347] [D loss: 0.502609] [G loss: 0.267859]\n",
      "[Epoch 52/100] [Batch 318/347] [D loss: 0.502864] [G loss: 0.282855]\n",
      "[Epoch 52/100] [Batch 319/347] [D loss: 0.503076] [G loss: 0.296580]\n",
      "[Epoch 52/100] [Batch 320/347] [D loss: 0.503054] [G loss: 0.296901]\n",
      "[Epoch 52/100] [Batch 321/347] [D loss: 0.502993] [G loss: 0.292078]\n",
      "[Epoch 52/100] [Batch 322/347] [D loss: 0.502917] [G loss: 0.286792]\n",
      "[Epoch 52/100] [Batch 323/347] [D loss: 0.502826] [G loss: 0.280171]\n",
      "[Epoch 52/100] [Batch 324/347] [D loss: 0.502768] [G loss: 0.275904]\n",
      "[Epoch 52/100] [Batch 325/347] [D loss: 0.502671] [G loss: 0.270240]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 52/100] [Batch 326/347] [D loss: 0.502546] [G loss: 0.263589]\n",
      "[Epoch 52/100] [Batch 327/347] [D loss: 0.502323] [G loss: 0.273127]\n",
      "[Epoch 52/100] [Batch 328/347] [D loss: 0.502189] [G loss: 0.280843]\n",
      "[Epoch 52/100] [Batch 329/347] [D loss: 0.502188] [G loss: 0.279305]\n",
      "[Epoch 52/100] [Batch 330/347] [D loss: 0.502257] [G loss: 0.274133]\n",
      "[Epoch 52/100] [Batch 331/347] [D loss: 0.502460] [G loss: 0.264267]\n",
      "[Epoch 52/100] [Batch 332/347] [D loss: 0.502733] [G loss: 0.283156]\n",
      "[Epoch 52/100] [Batch 333/347] [D loss: 0.502736] [G loss: 0.282444]\n",
      "[Epoch 52/100] [Batch 334/347] [D loss: 0.502679] [G loss: 0.276754]\n",
      "[Epoch 52/100] [Batch 335/347] [D loss: 0.502669] [G loss: 0.275754]\n",
      "[Epoch 52/100] [Batch 336/347] [D loss: 0.502653] [G loss: 0.275727]\n",
      "[Epoch 52/100] [Batch 337/347] [D loss: 0.502691] [G loss: 0.280532]\n",
      "[Epoch 52/100] [Batch 338/347] [D loss: 0.502780] [G loss: 0.288902]\n",
      "[Epoch 52/100] [Batch 339/347] [D loss: 0.502801] [G loss: 0.289688]\n",
      "[Epoch 52/100] [Batch 340/347] [D loss: 0.502744] [G loss: 0.286483]\n",
      "[Epoch 52/100] [Batch 341/347] [D loss: 0.502720] [G loss: 0.286994]\n",
      "[Epoch 52/100] [Batch 342/347] [D loss: 0.502551] [G loss: 0.275101]\n",
      "[Epoch 52/100] [Batch 343/347] [D loss: 0.502321] [G loss: 0.267710]\n",
      "[Epoch 52/100] [Batch 344/347] [D loss: 0.502109] [G loss: 0.275995]\n",
      "[Epoch 52/100] [Batch 345/347] [D loss: 0.501906] [G loss: 0.290748]\n",
      "[Epoch 52/100] [Batch 346/347] [D loss: 0.501908] [G loss: 0.290756]\n",
      "[Epoch 52/100] [Batch 347/347] [D loss: 0.501984] [G loss: 0.285179]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 53/100] [Batch 1/347] [D loss: 0.502370] [G loss: 0.273629]\n",
      "[Epoch 53/100] [Batch 2/347] [D loss: 0.502344] [G loss: 0.276818]\n",
      "[Epoch 53/100] [Batch 3/347] [D loss: 0.502395] [G loss: 0.276879]\n",
      "[Epoch 53/100] [Batch 4/347] [D loss: 0.502385] [G loss: 0.277716]\n",
      "[Epoch 53/100] [Batch 5/347] [D loss: 0.502347] [G loss: 0.277634]\n",
      "[Epoch 53/100] [Batch 6/347] [D loss: 0.502330] [G loss: 0.275632]\n",
      "[Epoch 53/100] [Batch 7/347] [D loss: 0.502231] [G loss: 0.275519]\n",
      "[Epoch 53/100] [Batch 8/347] [D loss: 0.502220] [G loss: 0.274676]\n",
      "[Epoch 53/100] [Batch 9/347] [D loss: 0.502235] [G loss: 0.274337]\n",
      "[Epoch 53/100] [Batch 10/347] [D loss: 0.502235] [G loss: 0.275585]\n",
      "[Epoch 53/100] [Batch 11/347] [D loss: 0.502361] [G loss: 0.276447]\n",
      "[Epoch 53/100] [Batch 12/347] [D loss: 0.502394] [G loss: 0.279054]\n",
      "[Epoch 53/100] [Batch 13/347] [D loss: 0.502394] [G loss: 0.278157]\n",
      "[Epoch 53/100] [Batch 14/347] [D loss: 0.502419] [G loss: 0.277506]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 53/100] [Batch 15/347] [D loss: 0.502304] [G loss: 0.268096]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 53/100] [Batch 16/347] [D loss: 0.502240] [G loss: 0.263972]\n",
      "[Epoch 53/100] [Batch 17/347] [D loss: 0.502284] [G loss: 0.264498]\n",
      "[Epoch 53/100] [Batch 18/347] [D loss: 0.502272] [G loss: 0.264895]\n",
      "[Epoch 53/100] [Batch 19/347] [D loss: 0.502315] [G loss: 0.269516]\n",
      "[Epoch 53/100] [Batch 20/347] [D loss: 0.502336] [G loss: 0.273477]\n",
      "[Epoch 53/100] [Batch 21/347] [D loss: 0.502260] [G loss: 0.268090]\n",
      "[Epoch 53/100] [Batch 22/347] [D loss: 0.502236] [G loss: 0.266125]\n",
      "[Epoch 53/100] [Batch 23/347] [D loss: 0.502176] [G loss: 0.266490]\n",
      "[Epoch 53/100] [Batch 24/347] [D loss: 0.502076] [G loss: 0.266076]\n",
      "[Epoch 53/100] [Batch 25/347] [D loss: 0.502123] [G loss: 0.265818]\n",
      "[Epoch 53/100] [Batch 26/347] [D loss: 0.502114] [G loss: 0.266624]\n",
      "[Epoch 53/100] [Batch 27/347] [D loss: 0.502231] [G loss: 0.266530]\n",
      "[Epoch 53/100] [Batch 28/347] [D loss: 0.502410] [G loss: 0.273549]\n",
      "[Epoch 53/100] [Batch 29/347] [D loss: 0.502513] [G loss: 0.278606]\n",
      "[Epoch 53/100] [Batch 30/347] [D loss: 0.502538] [G loss: 0.280153]\n",
      "[Epoch 53/100] [Batch 31/347] [D loss: 0.502519] [G loss: 0.280067]\n",
      "[Epoch 53/100] [Batch 32/347] [D loss: 0.502474] [G loss: 0.276959]\n",
      "[Epoch 53/100] [Batch 33/347] [D loss: 0.502410] [G loss: 0.274863]\n",
      "[Epoch 53/100] [Batch 34/347] [D loss: 0.502325] [G loss: 0.270038]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 53/100] [Batch 35/347] [D loss: 0.502122] [G loss: 0.262781]\n",
      "[Epoch 53/100] [Batch 36/347] [D loss: 0.501929] [G loss: 0.273716]\n",
      "[Epoch 53/100] [Batch 37/347] [D loss: 0.501801] [G loss: 0.278473]\n",
      "[Epoch 53/100] [Batch 38/347] [D loss: 0.501665] [G loss: 0.282813]\n",
      "[Epoch 53/100] [Batch 39/347] [D loss: 0.501687] [G loss: 0.280550]\n",
      "[Epoch 53/100] [Batch 40/347] [D loss: 0.501773] [G loss: 0.279145]\n",
      "[Epoch 53/100] [Batch 41/347] [D loss: 0.501897] [G loss: 0.269647]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 53/100] [Batch 42/347] [D loss: 0.502107] [G loss: 0.259173]\n",
      "[Epoch 53/100] [Batch 43/347] [D loss: 0.502371] [G loss: 0.274678]\n",
      "[Epoch 53/100] [Batch 44/347] [D loss: 0.502464] [G loss: 0.280663]\n",
      "[Epoch 53/100] [Batch 45/347] [D loss: 0.502358] [G loss: 0.272761]\n",
      "[Epoch 53/100] [Batch 46/347] [D loss: 0.502067] [G loss: 0.267002]\n",
      "[Epoch 53/100] [Batch 47/347] [D loss: 0.501812] [G loss: 0.280482]\n",
      "[Epoch 53/100] [Batch 48/347] [D loss: 0.501513] [G loss: 0.302580]\n",
      "[Epoch 53/100] [Batch 49/347] [D loss: 0.501594] [G loss: 0.298630]\n",
      "[Epoch 53/100] [Batch 50/347] [D loss: 0.501807] [G loss: 0.285367]\n",
      "[Epoch 53/100] [Batch 51/347] [D loss: 0.501828] [G loss: 0.284004]\n",
      "[Epoch 53/100] [Batch 52/347] [D loss: 0.501688] [G loss: 0.290956]\n",
      "[Epoch 53/100] [Batch 53/347] [D loss: 0.501374] [G loss: 0.307083]\n",
      "[Epoch 53/100] [Batch 54/347] [D loss: 0.501148] [G loss: 0.317682]\n",
      "[Epoch 53/100] [Batch 55/347] [D loss: 0.501210] [G loss: 0.314413]\n",
      "[Epoch 53/100] [Batch 56/347] [D loss: 0.501503] [G loss: 0.296925]\n",
      "[Epoch 53/100] [Batch 57/347] [D loss: 0.501766] [G loss: 0.282092]\n",
      "[Epoch 53/100] [Batch 58/347] [D loss: 0.501900] [G loss: 0.275808]\n",
      "[Epoch 53/100] [Batch 59/347] [D loss: 0.501722] [G loss: 0.289609]\n",
      "[Epoch 53/100] [Batch 60/347] [D loss: 0.501352] [G loss: 0.311803]\n",
      "[Epoch 53/100] [Batch 61/347] [D loss: 0.501192] [G loss: 0.316890]\n",
      "[Epoch 53/100] [Batch 62/347] [D loss: 0.501332] [G loss: 0.308222]\n",
      "[Epoch 53/100] [Batch 63/347] [D loss: 0.501560] [G loss: 0.293681]\n",
      "[Epoch 53/100] [Batch 64/347] [D loss: 0.501805] [G loss: 0.276317]\n",
      "[Epoch 53/100] [Batch 65/347] [D loss: 0.502071] [G loss: 0.272913]\n",
      "[Epoch 53/100] [Batch 66/347] [D loss: 0.501859] [G loss: 0.276059]\n",
      "[Epoch 53/100] [Batch 67/347] [D loss: 0.501473] [G loss: 0.296958]\n",
      "[Epoch 53/100] [Batch 68/347] [D loss: 0.501318] [G loss: 0.303139]\n",
      "[Epoch 53/100] [Batch 69/347] [D loss: 0.501119] [G loss: 0.314371]\n",
      "[Epoch 53/100] [Batch 70/347] [D loss: 0.501072] [G loss: 0.313423]\n",
      "[Epoch 53/100] [Batch 71/347] [D loss: 0.501319] [G loss: 0.301203]\n",
      "[Epoch 53/100] [Batch 72/347] [D loss: 0.501425] [G loss: 0.299464]\n",
      "[Epoch 53/100] [Batch 73/347] [D loss: 0.501374] [G loss: 0.300579]\n",
      "[Epoch 53/100] [Batch 74/347] [D loss: 0.501495] [G loss: 0.293074]\n",
      "[Epoch 53/100] [Batch 75/347] [D loss: 0.501572] [G loss: 0.289419]\n",
      "[Epoch 53/100] [Batch 76/347] [D loss: 0.501715] [G loss: 0.280006]\n",
      "[Epoch 53/100] [Batch 77/347] [D loss: 0.502077] [G loss: 0.272114]\n",
      "[Epoch 53/100] [Batch 78/347] [D loss: 0.502340] [G loss: 0.276881]\n",
      "[Epoch 53/100] [Batch 79/347] [D loss: 0.502486] [G loss: 0.285735]\n",
      "[Epoch 53/100] [Batch 80/347] [D loss: 0.502408] [G loss: 0.281195]\n",
      "[Epoch 53/100] [Batch 81/347] [D loss: 0.502424] [G loss: 0.282890]\n",
      "[Epoch 53/100] [Batch 82/347] [D loss: 0.502444] [G loss: 0.285410]\n",
      "[Epoch 53/100] [Batch 83/347] [D loss: 0.502380] [G loss: 0.284449]\n",
      "[Epoch 53/100] [Batch 84/347] [D loss: 0.502368] [G loss: 0.287948]\n",
      "[Epoch 53/100] [Batch 85/347] [D loss: 0.502336] [G loss: 0.287750]\n",
      "[Epoch 53/100] [Batch 86/347] [D loss: 0.502306] [G loss: 0.286957]\n",
      "[Epoch 53/100] [Batch 87/347] [D loss: 0.502296] [G loss: 0.287379]\n",
      "[Epoch 53/100] [Batch 88/347] [D loss: 0.502276] [G loss: 0.287438]\n",
      "[Epoch 53/100] [Batch 89/347] [D loss: 0.502277] [G loss: 0.288905]\n",
      "[Epoch 53/100] [Batch 90/347] [D loss: 0.502255] [G loss: 0.287881]\n",
      "[Epoch 53/100] [Batch 91/347] [D loss: 0.502216] [G loss: 0.286065]\n",
      "[Epoch 53/100] [Batch 92/347] [D loss: 0.502200] [G loss: 0.285776]\n",
      "[Epoch 53/100] [Batch 93/347] [D loss: 0.502189] [G loss: 0.285272]\n",
      "[Epoch 53/100] [Batch 94/347] [D loss: 0.502127] [G loss: 0.280936]\n",
      "[Epoch 53/100] [Batch 95/347] [D loss: 0.502102] [G loss: 0.279442]\n",
      "[Epoch 53/100] [Batch 96/347] [D loss: 0.502098] [G loss: 0.280288]\n",
      "[Epoch 53/100] [Batch 97/347] [D loss: 0.502076] [G loss: 0.279313]\n",
      "[Epoch 53/100] [Batch 98/347] [D loss: 0.502076] [G loss: 0.280324]\n",
      "[Epoch 53/100] [Batch 99/347] [D loss: 0.502063] [G loss: 0.280278]\n",
      "[Epoch 53/100] [Batch 100/347] [D loss: 0.502053] [G loss: 0.279656]\n",
      "[Epoch 53/100] [Batch 101/347] [D loss: 0.502017] [G loss: 0.277198]\n",
      "[Epoch 53/100] [Batch 102/347] [D loss: 0.501962] [G loss: 0.274025]\n",
      "[Epoch 53/100] [Batch 103/347] [D loss: 0.501960] [G loss: 0.274572]\n",
      "[Epoch 53/100] [Batch 104/347] [D loss: 0.501882] [G loss: 0.269098]\n",
      "[Epoch 53/100] [Batch 105/347] [D loss: 0.501831] [G loss: 0.262194]\n",
      "[Epoch 53/100] [Batch 106/347] [D loss: 0.501776] [G loss: 0.264352]\n",
      "[Epoch 53/100] [Batch 107/347] [D loss: 0.501796] [G loss: 0.268082]\n",
      "[Epoch 53/100] [Batch 108/347] [D loss: 0.501809] [G loss: 0.269878]\n",
      "[Epoch 53/100] [Batch 109/347] [D loss: 0.501753] [G loss: 0.273703]\n",
      "[Epoch 53/100] [Batch 110/347] [D loss: 0.501880] [G loss: 0.269810]\n",
      "[Epoch 53/100] [Batch 111/347] [D loss: 0.501946] [G loss: 0.269807]\n",
      "[Epoch 53/100] [Batch 112/347] [D loss: 0.502019] [G loss: 0.272366]\n",
      "[Epoch 53/100] [Batch 113/347] [D loss: 0.502191] [G loss: 0.289109]\n",
      "[Epoch 53/100] [Batch 114/347] [D loss: 0.502236] [G loss: 0.295921]\n",
      "[Epoch 53/100] [Batch 115/347] [D loss: 0.502056] [G loss: 0.279162]\n",
      "[Epoch 53/100] [Batch 116/347] [D loss: 0.501824] [G loss: 0.262103]\n",
      "[Epoch 53/100] [Batch 117/347] [D loss: 0.501630] [G loss: 0.265328]\n",
      "[Epoch 53/100] [Batch 118/347] [D loss: 0.501438] [G loss: 0.277932]\n",
      "[Epoch 53/100] [Batch 119/347] [D loss: 0.501400] [G loss: 0.278072]\n",
      "[Epoch 53/100] [Batch 120/347] [D loss: 0.501486] [G loss: 0.271104]\n",
      "[Epoch 53/100] [Batch 121/347] [D loss: 0.501493] [G loss: 0.269990]\n",
      "[Epoch 53/100] [Batch 122/347] [D loss: 0.501535] [G loss: 0.269270]\n",
      "[Epoch 53/100] [Batch 123/347] [D loss: 0.501628] [G loss: 0.267278]\n",
      "[Epoch 53/100] [Batch 124/347] [D loss: 0.501681] [G loss: 0.264073]\n",
      "[Epoch 53/100] [Batch 125/347] [D loss: 0.501767] [G loss: 0.267015]\n",
      "[Epoch 53/100] [Batch 126/347] [D loss: 0.501819] [G loss: 0.271051]\n",
      "[Epoch 53/100] [Batch 127/347] [D loss: 0.501842] [G loss: 0.269672]\n",
      "[Epoch 53/100] [Batch 128/347] [D loss: 0.501746] [G loss: 0.261407]\n",
      "[Epoch 53/100] [Batch 129/347] [D loss: 0.501618] [G loss: 0.265358]\n",
      "[Epoch 53/100] [Batch 130/347] [D loss: 0.501439] [G loss: 0.281085]\n",
      "[Epoch 53/100] [Batch 131/347] [D loss: 0.501265] [G loss: 0.292184]\n",
      "[Epoch 53/100] [Batch 132/347] [D loss: 0.501019] [G loss: 0.311531]\n",
      "[Epoch 53/100] [Batch 133/347] [D loss: 0.500940] [G loss: 0.317028]\n",
      "[Epoch 53/100] [Batch 134/347] [D loss: 0.501150] [G loss: 0.302523]\n",
      "[Epoch 53/100] [Batch 135/347] [D loss: 0.501199] [G loss: 0.299387]\n",
      "[Epoch 53/100] [Batch 136/347] [D loss: 0.501262] [G loss: 0.291554]\n",
      "[Epoch 53/100] [Batch 137/347] [D loss: 0.501205] [G loss: 0.292976]\n",
      "[Epoch 53/100] [Batch 138/347] [D loss: 0.500921] [G loss: 0.311179]\n",
      "[Epoch 53/100] [Batch 139/347] [D loss: 0.500664] [G loss: 0.324523]\n",
      "[Epoch 53/100] [Batch 140/347] [D loss: 0.500524] [G loss: 0.335345]\n",
      "[Epoch 53/100] [Batch 141/347] [D loss: 0.500261] [G loss: 0.349950]\n",
      "[Epoch 53/100] [Batch 142/347] [D loss: 0.500173] [G loss: 0.352851]\n",
      "[Epoch 53/100] [Batch 143/347] [D loss: 0.500054] [G loss: 0.355765]\n",
      "[Epoch 53/100] [Batch 144/347] [D loss: 0.500084] [G loss: 0.348290]\n",
      "[Epoch 53/100] [Batch 145/347] [D loss: 0.500374] [G loss: 0.327682]\n",
      "[Epoch 53/100] [Batch 146/347] [D loss: 0.500519] [G loss: 0.315132]\n",
      "[Epoch 53/100] [Batch 147/347] [D loss: 0.500652] [G loss: 0.306064]\n",
      "[Epoch 53/100] [Batch 148/347] [D loss: 0.500812] [G loss: 0.298873]\n",
      "[Epoch 53/100] [Batch 149/347] [D loss: 0.500827] [G loss: 0.301198]\n",
      "[Epoch 53/100] [Batch 150/347] [D loss: 0.500767] [G loss: 0.308975]\n",
      "[Epoch 53/100] [Batch 151/347] [D loss: 0.500701] [G loss: 0.314464]\n",
      "[Epoch 53/100] [Batch 152/347] [D loss: 0.500555] [G loss: 0.321632]\n",
      "[Epoch 53/100] [Batch 153/347] [D loss: 0.500458] [G loss: 0.324348]\n",
      "[Epoch 53/100] [Batch 154/347] [D loss: 0.500519] [G loss: 0.319084]\n",
      "[Epoch 53/100] [Batch 155/347] [D loss: 0.500575] [G loss: 0.317978]\n",
      "[Epoch 53/100] [Batch 156/347] [D loss: 0.500508] [G loss: 0.321994]\n",
      "[Epoch 53/100] [Batch 157/347] [D loss: 0.500529] [G loss: 0.321552]\n",
      "[Epoch 53/100] [Batch 158/347] [D loss: 0.500530] [G loss: 0.323452]\n",
      "[Epoch 53/100] [Batch 159/347] [D loss: 0.500565] [G loss: 0.321553]\n",
      "[Epoch 53/100] [Batch 160/347] [D loss: 0.500754] [G loss: 0.313164]\n",
      "[Epoch 53/100] [Batch 161/347] [D loss: 0.500675] [G loss: 0.320151]\n",
      "[Epoch 53/100] [Batch 162/347] [D loss: 0.500478] [G loss: 0.330841]\n",
      "[Epoch 53/100] [Batch 163/347] [D loss: 0.500349] [G loss: 0.333265]\n",
      "[Epoch 53/100] [Batch 164/347] [D loss: 0.500499] [G loss: 0.322906]\n",
      "[Epoch 53/100] [Batch 165/347] [D loss: 0.500779] [G loss: 0.307144]\n",
      "[Epoch 53/100] [Batch 166/347] [D loss: 0.501205] [G loss: 0.281267]\n",
      "[Epoch 53/100] [Batch 167/347] [D loss: 0.501580] [G loss: 0.263822]\n",
      "[Epoch 53/100] [Batch 168/347] [D loss: 0.501741] [G loss: 0.267891]\n",
      "[Epoch 53/100] [Batch 169/347] [D loss: 0.501866] [G loss: 0.268809]\n",
      "[Epoch 53/100] [Batch 170/347] [D loss: 0.501938] [G loss: 0.275995]\n",
      "[Epoch 53/100] [Batch 171/347] [D loss: 0.501923] [G loss: 0.276626]\n",
      "[Epoch 53/100] [Batch 172/347] [D loss: 0.501947] [G loss: 0.278489]\n",
      "[Epoch 53/100] [Batch 173/347] [D loss: 0.501913] [G loss: 0.278195]\n",
      "[Epoch 53/100] [Batch 174/347] [D loss: 0.501982] [G loss: 0.282858]\n",
      "[Epoch 53/100] [Batch 175/347] [D loss: 0.502028] [G loss: 0.288425]\n",
      "[Epoch 53/100] [Batch 176/347] [D loss: 0.502079] [G loss: 0.292166]\n",
      "[Epoch 53/100] [Batch 177/347] [D loss: 0.502038] [G loss: 0.289770]\n",
      "[Epoch 53/100] [Batch 178/347] [D loss: 0.501948] [G loss: 0.284394]\n",
      "[Epoch 53/100] [Batch 179/347] [D loss: 0.501884] [G loss: 0.281338]\n",
      "[Epoch 53/100] [Batch 180/347] [D loss: 0.501810] [G loss: 0.277762]\n",
      "[Epoch 53/100] [Batch 181/347] [D loss: 0.501844] [G loss: 0.280713]\n",
      "[Epoch 53/100] [Batch 182/347] [D loss: 0.501831] [G loss: 0.281561]\n",
      "[Epoch 53/100] [Batch 183/347] [D loss: 0.501848] [G loss: 0.283159]\n",
      "[Epoch 53/100] [Batch 184/347] [D loss: 0.501888] [G loss: 0.285557]\n",
      "[Epoch 53/100] [Batch 185/347] [D loss: 0.501843] [G loss: 0.282565]\n",
      "[Epoch 53/100] [Batch 186/347] [D loss: 0.501825] [G loss: 0.281342]\n",
      "[Epoch 53/100] [Batch 187/347] [D loss: 0.501777] [G loss: 0.278412]\n",
      "[Epoch 53/100] [Batch 188/347] [D loss: 0.501611] [G loss: 0.270501]\n",
      "[Epoch 53/100] [Batch 189/347] [D loss: 0.501491] [G loss: 0.264217]\n",
      "[Epoch 53/100] [Batch 190/347] [D loss: 0.501451] [G loss: 0.262333]\n",
      "[Epoch 53/100] [Batch 191/347] [D loss: 0.501391] [G loss: 0.264789]\n",
      "[Epoch 53/100] [Batch 192/347] [D loss: 0.501390] [G loss: 0.264493]\n",
      "[Epoch 53/100] [Batch 193/347] [D loss: 0.501388] [G loss: 0.265072]\n",
      "[Epoch 53/100] [Batch 194/347] [D loss: 0.501307] [G loss: 0.268338]\n",
      "[Epoch 53/100] [Batch 195/347] [D loss: 0.501265] [G loss: 0.269067]\n",
      "[Epoch 53/100] [Batch 196/347] [D loss: 0.501265] [G loss: 0.265224]\n",
      "[Epoch 53/100] [Batch 197/347] [D loss: 0.501277] [G loss: 0.262640]\n",
      "[Epoch 53/100] [Batch 198/347] [D loss: 0.501344] [G loss: 0.259237]\n",
      "[Epoch 53/100] [Batch 199/347] [D loss: 0.501334] [G loss: 0.260102]\n",
      "[Epoch 53/100] [Batch 200/347] [D loss: 0.501285] [G loss: 0.265723]\n",
      "[Epoch 53/100] [Batch 201/347] [D loss: 0.501238] [G loss: 0.269733]\n",
      "[Epoch 53/100] [Batch 202/347] [D loss: 0.501177] [G loss: 0.274622]\n",
      "[Epoch 53/100] [Batch 203/347] [D loss: 0.501164] [G loss: 0.274756]\n",
      "[Epoch 53/100] [Batch 204/347] [D loss: 0.501290] [G loss: 0.265632]\n",
      "[Epoch 53/100] [Batch 205/347] [D loss: 0.501442] [G loss: 0.260477]\n",
      "[Epoch 53/100] [Batch 206/347] [D loss: 0.501500] [G loss: 0.263903]\n",
      "[Epoch 53/100] [Batch 207/347] [D loss: 0.501574] [G loss: 0.266282]\n",
      "[Epoch 53/100] [Batch 208/347] [D loss: 0.501660] [G loss: 0.270132]\n",
      "[Epoch 53/100] [Batch 209/347] [D loss: 0.501565] [G loss: 0.266031]\n",
      "[Epoch 53/100] [Batch 210/347] [D loss: 0.501623] [G loss: 0.267542]\n",
      "[Epoch 53/100] [Batch 211/347] [D loss: 0.501566] [G loss: 0.270668]\n",
      "[Epoch 53/100] [Batch 212/347] [D loss: 0.501372] [G loss: 0.272722]\n",
      "[Epoch 53/100] [Batch 213/347] [D loss: 0.501315] [G loss: 0.275050]\n",
      "[Epoch 53/100] [Batch 214/347] [D loss: 0.501315] [G loss: 0.274694]\n",
      "[Epoch 53/100] [Batch 215/347] [D loss: 0.501352] [G loss: 0.275837]\n",
      "[Epoch 53/100] [Batch 216/347] [D loss: 0.501596] [G loss: 0.271545]\n",
      "[Epoch 53/100] [Batch 217/347] [D loss: 0.501820] [G loss: 0.276755]\n",
      "[Epoch 53/100] [Batch 218/347] [D loss: 0.502024] [G loss: 0.291368]\n",
      "[Epoch 53/100] [Batch 219/347] [D loss: 0.502142] [G loss: 0.298102]\n",
      "[Epoch 53/100] [Batch 220/347] [D loss: 0.502229] [G loss: 0.302674]\n",
      "[Epoch 53/100] [Batch 221/347] [D loss: 0.502245] [G loss: 0.303506]\n",
      "[Epoch 53/100] [Batch 222/347] [D loss: 0.502152] [G loss: 0.295940]\n",
      "[Epoch 53/100] [Batch 223/347] [D loss: 0.501905] [G loss: 0.286306]\n",
      "[Epoch 53/100] [Batch 224/347] [D loss: 0.501541] [G loss: 0.276440]\n",
      "[Epoch 53/100] [Batch 225/347] [D loss: 0.501156] [G loss: 0.272275]\n",
      "[Epoch 53/100] [Batch 226/347] [D loss: 0.500845] [G loss: 0.281791]\n",
      "[Epoch 53/100] [Batch 227/347] [D loss: 0.500753] [G loss: 0.283214]\n",
      "[Epoch 53/100] [Batch 228/347] [D loss: 0.500755] [G loss: 0.286643]\n",
      "[Epoch 53/100] [Batch 229/347] [D loss: 0.500820] [G loss: 0.283834]\n",
      "[Epoch 53/100] [Batch 230/347] [D loss: 0.500887] [G loss: 0.279626]\n",
      "[Epoch 53/100] [Batch 231/347] [D loss: 0.500865] [G loss: 0.275297]\n",
      "[Epoch 53/100] [Batch 232/347] [D loss: 0.500909] [G loss: 0.275709]\n",
      "[Epoch 53/100] [Batch 233/347] [D loss: 0.501055] [G loss: 0.270995]\n",
      "[Epoch 53/100] [Batch 234/347] [D loss: 0.501171] [G loss: 0.266564]\n",
      "[Epoch 53/100] [Batch 235/347] [D loss: 0.501358] [G loss: 0.262266]\n",
      "[Epoch 53/100] [Batch 236/347] [D loss: 0.501493] [G loss: 0.265084]\n",
      "[Epoch 53/100] [Batch 237/347] [D loss: 0.501553] [G loss: 0.271107]\n",
      "[Epoch 53/100] [Batch 238/347] [D loss: 0.501525] [G loss: 0.270373]\n",
      "[Epoch 53/100] [Batch 239/347] [D loss: 0.501455] [G loss: 0.266325]\n",
      "[Epoch 53/100] [Batch 240/347] [D loss: 0.501419] [G loss: 0.264381]\n",
      "[Epoch 53/100] [Batch 241/347] [D loss: 0.501423] [G loss: 0.265199]\n",
      "[Epoch 53/100] [Batch 242/347] [D loss: 0.501479] [G loss: 0.267882]\n",
      "[Epoch 53/100] [Batch 243/347] [D loss: 0.501561] [G loss: 0.269873]\n",
      "[Epoch 53/100] [Batch 244/347] [D loss: 0.501429] [G loss: 0.263282]\n",
      "[Epoch 53/100] [Batch 245/347] [D loss: 0.501234] [G loss: 0.259435]\n",
      "[Epoch 53/100] [Batch 246/347] [D loss: 0.500987] [G loss: 0.272018]\n",
      "[Epoch 53/100] [Batch 247/347] [D loss: 0.500724] [G loss: 0.280878]\n",
      "[Epoch 53/100] [Batch 248/347] [D loss: 0.500824] [G loss: 0.278163]\n",
      "[Epoch 53/100] [Batch 249/347] [D loss: 0.500993] [G loss: 0.272161]\n",
      "[Epoch 53/100] [Batch 250/347] [D loss: 0.501214] [G loss: 0.262618]\n",
      "[Epoch 53/100] [Batch 251/347] [D loss: 0.501453] [G loss: 0.269719]\n",
      "[Epoch 53/100] [Batch 252/347] [D loss: 0.501560] [G loss: 0.271010]\n",
      "[Epoch 53/100] [Batch 253/347] [D loss: 0.501492] [G loss: 0.271308]\n",
      "[Epoch 53/100] [Batch 254/347] [D loss: 0.501583] [G loss: 0.273647]\n",
      "[Epoch 53/100] [Batch 255/347] [D loss: 0.501603] [G loss: 0.274757]\n",
      "[Epoch 53/100] [Batch 256/347] [D loss: 0.501500] [G loss: 0.273517]\n",
      "[Epoch 53/100] [Batch 257/347] [D loss: 0.501385] [G loss: 0.271170]\n",
      "[Epoch 53/100] [Batch 258/347] [D loss: 0.501184] [G loss: 0.267972]\n",
      "[Epoch 53/100] [Batch 259/347] [D loss: 0.501053] [G loss: 0.274298]\n",
      "[Epoch 53/100] [Batch 260/347] [D loss: 0.501013] [G loss: 0.274695]\n",
      "[Epoch 53/100] [Batch 261/347] [D loss: 0.501073] [G loss: 0.271636]\n",
      "[Epoch 53/100] [Batch 262/347] [D loss: 0.501058] [G loss: 0.271105]\n",
      "[Epoch 53/100] [Batch 263/347] [D loss: 0.501005] [G loss: 0.273275]\n",
      "[Epoch 53/100] [Batch 264/347] [D loss: 0.500962] [G loss: 0.275390]\n",
      "[Epoch 53/100] [Batch 265/347] [D loss: 0.500944] [G loss: 0.275640]\n",
      "[Epoch 53/100] [Batch 266/347] [D loss: 0.500952] [G loss: 0.275776]\n",
      "[Epoch 53/100] [Batch 267/347] [D loss: 0.500925] [G loss: 0.278374]\n",
      "[Epoch 53/100] [Batch 268/347] [D loss: 0.500926] [G loss: 0.278539]\n",
      "[Epoch 53/100] [Batch 269/347] [D loss: 0.500923] [G loss: 0.278456]\n",
      "[Epoch 53/100] [Batch 270/347] [D loss: 0.500993] [G loss: 0.273066]\n",
      "[Epoch 53/100] [Batch 271/347] [D loss: 0.500982] [G loss: 0.275692]\n",
      "[Epoch 53/100] [Batch 272/347] [D loss: 0.500831] [G loss: 0.288588]\n",
      "[Epoch 53/100] [Batch 273/347] [D loss: 0.500833] [G loss: 0.289734]\n",
      "[Epoch 53/100] [Batch 274/347] [D loss: 0.500793] [G loss: 0.291215]\n",
      "[Epoch 53/100] [Batch 275/347] [D loss: 0.500886] [G loss: 0.283944]\n",
      "[Epoch 53/100] [Batch 276/347] [D loss: 0.501142] [G loss: 0.260649]\n",
      "[Epoch 53/100] [Batch 277/347] [D loss: 0.501211] [G loss: 0.261551]\n",
      "[Epoch 53/100] [Batch 278/347] [D loss: 0.501276] [G loss: 0.261974]\n",
      "[Epoch 53/100] [Batch 279/347] [D loss: 0.501264] [G loss: 0.263770]\n",
      "[Epoch 53/100] [Batch 280/347] [D loss: 0.501233] [G loss: 0.264440]\n",
      "[Epoch 53/100] [Batch 281/347] [D loss: 0.501194] [G loss: 0.263877]\n",
      "[Epoch 53/100] [Batch 282/347] [D loss: 0.501213] [G loss: 0.263658]\n",
      "[Epoch 53/100] [Batch 283/347] [D loss: 0.501183] [G loss: 0.261192]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 53/100] [Batch 284/347] [D loss: 0.501177] [G loss: 0.259105]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 53/100] [Batch 285/347] [D loss: 0.501153] [G loss: 0.256356]\n",
      "[Epoch 53/100] [Batch 286/347] [D loss: 0.500882] [G loss: 0.268568]\n",
      "[Epoch 53/100] [Batch 287/347] [D loss: 0.500818] [G loss: 0.270994]\n",
      "[Epoch 53/100] [Batch 288/347] [D loss: 0.500765] [G loss: 0.272995]\n",
      "[Epoch 53/100] [Batch 289/347] [D loss: 0.500673] [G loss: 0.276848]\n",
      "[Epoch 53/100] [Batch 290/347] [D loss: 0.500963] [G loss: 0.260179]\n",
      "[Epoch 53/100] [Batch 291/347] [D loss: 0.501176] [G loss: 0.258985]\n",
      "[Epoch 53/100] [Batch 292/347] [D loss: 0.501303] [G loss: 0.265493]\n",
      "[Epoch 53/100] [Batch 293/347] [D loss: 0.501464] [G loss: 0.272084]\n",
      "[Epoch 53/100] [Batch 294/347] [D loss: 0.501585] [G loss: 0.275912]\n",
      "[Epoch 53/100] [Batch 295/347] [D loss: 0.501574] [G loss: 0.277516]\n",
      "[Epoch 53/100] [Batch 296/347] [D loss: 0.501537] [G loss: 0.278614]\n",
      "[Epoch 53/100] [Batch 297/347] [D loss: 0.501609] [G loss: 0.285635]\n",
      "[Epoch 53/100] [Batch 298/347] [D loss: 0.501546] [G loss: 0.281527]\n",
      "[Epoch 53/100] [Batch 299/347] [D loss: 0.501544] [G loss: 0.278945]\n",
      "[Epoch 53/100] [Batch 300/347] [D loss: 0.501571] [G loss: 0.278559]\n",
      "[Epoch 53/100] [Batch 301/347] [D loss: 0.501324] [G loss: 0.268244]\n",
      "[Epoch 53/100] [Batch 302/347] [D loss: 0.501172] [G loss: 0.260316]\n",
      "[Epoch 53/100] [Batch 303/347] [D loss: 0.500914] [G loss: 0.263715]\n",
      "[Epoch 53/100] [Batch 304/347] [D loss: 0.500689] [G loss: 0.274406]\n",
      "[Epoch 53/100] [Batch 305/347] [D loss: 0.500609] [G loss: 0.275595]\n",
      "[Epoch 53/100] [Batch 306/347] [D loss: 0.500629] [G loss: 0.275639]\n",
      "[Epoch 53/100] [Batch 307/347] [D loss: 0.500779] [G loss: 0.268921]\n",
      "[Epoch 53/100] [Batch 308/347] [D loss: 0.500948] [G loss: 0.262362]\n",
      "[Epoch 53/100] [Batch 309/347] [D loss: 0.501141] [G loss: 0.268616]\n",
      "[Epoch 53/100] [Batch 310/347] [D loss: 0.501325] [G loss: 0.283421]\n",
      "[Epoch 53/100] [Batch 311/347] [D loss: 0.501331] [G loss: 0.283592]\n",
      "[Epoch 53/100] [Batch 312/347] [D loss: 0.501347] [G loss: 0.281063]\n",
      "[Epoch 53/100] [Batch 313/347] [D loss: 0.501297] [G loss: 0.274356]\n",
      "[Epoch 53/100] [Batch 314/347] [D loss: 0.501099] [G loss: 0.262122]\n",
      "[Epoch 53/100] [Batch 315/347] [D loss: 0.500943] [G loss: 0.262895]\n",
      "[Epoch 53/100] [Batch 316/347] [D loss: 0.500985] [G loss: 0.262098]\n",
      "[Epoch 53/100] [Batch 317/347] [D loss: 0.501078] [G loss: 0.261981]\n",
      "[Epoch 53/100] [Batch 318/347] [D loss: 0.501346] [G loss: 0.277032]\n",
      "[Epoch 53/100] [Batch 319/347] [D loss: 0.501561] [G loss: 0.290808]\n",
      "[Epoch 53/100] [Batch 320/347] [D loss: 0.501556] [G loss: 0.291189]\n",
      "[Epoch 53/100] [Batch 321/347] [D loss: 0.501505] [G loss: 0.286388]\n",
      "[Epoch 53/100] [Batch 322/347] [D loss: 0.501433] [G loss: 0.281143]\n",
      "[Epoch 53/100] [Batch 323/347] [D loss: 0.501346] [G loss: 0.274613]\n",
      "[Epoch 53/100] [Batch 324/347] [D loss: 0.501289] [G loss: 0.270389]\n",
      "[Epoch 53/100] [Batch 325/347] [D loss: 0.501194] [G loss: 0.264802]\n",
      "[Epoch 53/100] [Batch 326/347] [D loss: 0.501072] [G loss: 0.258203]\n",
      "[Epoch 53/100] [Batch 327/347] [D loss: 0.500851] [G loss: 0.265861]\n",
      "[Epoch 53/100] [Batch 328/347] [D loss: 0.500713] [G loss: 0.273659]\n",
      "[Epoch 53/100] [Batch 329/347] [D loss: 0.500725] [G loss: 0.272105]\n",
      "[Epoch 53/100] [Batch 330/347] [D loss: 0.500798] [G loss: 0.266970]\n",
      "[Epoch 53/100] [Batch 331/347] [D loss: 0.501021] [G loss: 0.257448]\n",
      "[Epoch 53/100] [Batch 332/347] [D loss: 0.501305] [G loss: 0.278017]\n",
      "[Epoch 53/100] [Batch 333/347] [D loss: 0.501307] [G loss: 0.277132]\n",
      "[Epoch 53/100] [Batch 334/347] [D loss: 0.501250] [G loss: 0.271312]\n",
      "[Epoch 53/100] [Batch 335/347] [D loss: 0.501242] [G loss: 0.270220]\n",
      "[Epoch 53/100] [Batch 336/347] [D loss: 0.501224] [G loss: 0.270091]\n",
      "[Epoch 53/100] [Batch 337/347] [D loss: 0.501265] [G loss: 0.274821]\n",
      "[Epoch 53/100] [Batch 338/347] [D loss: 0.501366] [G loss: 0.283160]\n",
      "[Epoch 53/100] [Batch 339/347] [D loss: 0.501389] [G loss: 0.283852]\n",
      "[Epoch 53/100] [Batch 340/347] [D loss: 0.501334] [G loss: 0.280623]\n",
      "[Epoch 53/100] [Batch 341/347] [D loss: 0.501318] [G loss: 0.281096]\n",
      "[Epoch 53/100] [Batch 342/347] [D loss: 0.501145] [G loss: 0.269210]\n",
      "[Epoch 53/100] [Batch 343/347] [D loss: 0.500909] [G loss: 0.262820]\n",
      "[Epoch 53/100] [Batch 344/347] [D loss: 0.500695] [G loss: 0.270510]\n",
      "[Epoch 53/100] [Batch 345/347] [D loss: 0.500488] [G loss: 0.285360]\n",
      "[Epoch 53/100] [Batch 346/347] [D loss: 0.500489] [G loss: 0.285395]\n",
      "[Epoch 53/100] [Batch 347/347] [D loss: 0.500568] [G loss: 0.279838]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 54/100] [Batch 1/347] [D loss: 0.500981] [G loss: 0.269112]\n",
      "[Epoch 54/100] [Batch 2/347] [D loss: 0.500961] [G loss: 0.272367]\n",
      "[Epoch 54/100] [Batch 3/347] [D loss: 0.501017] [G loss: 0.272262]\n",
      "[Epoch 54/100] [Batch 4/347] [D loss: 0.501011] [G loss: 0.273094]\n",
      "[Epoch 54/100] [Batch 5/347] [D loss: 0.500983] [G loss: 0.272824]\n",
      "[Epoch 54/100] [Batch 6/347] [D loss: 0.500975] [G loss: 0.270693]\n",
      "[Epoch 54/100] [Batch 7/347] [D loss: 0.500872] [G loss: 0.270471]\n",
      "[Epoch 54/100] [Batch 8/347] [D loss: 0.500871] [G loss: 0.269469]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 54/100] [Batch 9/347] [D loss: 0.500897] [G loss: 0.269032]\n",
      "[Epoch 54/100] [Batch 10/347] [D loss: 0.500902] [G loss: 0.270204]\n",
      "[Epoch 54/100] [Batch 11/347] [D loss: 0.501043] [G loss: 0.271481]\n",
      "[Epoch 54/100] [Batch 12/347] [D loss: 0.501090] [G loss: 0.274208]\n",
      "[Epoch 54/100] [Batch 13/347] [D loss: 0.501094] [G loss: 0.273375]\n",
      "[Epoch 54/100] [Batch 14/347] [D loss: 0.501129] [G loss: 0.272815]\n",
      "[Epoch 54/100] [Batch 15/347] [D loss: 0.501013] [G loss: 0.263460]\n",
      "[Epoch 54/100] [Batch 16/347] [D loss: 0.500954] [G loss: 0.258281]\n",
      "[Epoch 54/100] [Batch 17/347] [D loss: 0.501001] [G loss: 0.260023]\n",
      "[Epoch 54/100] [Batch 18/347] [D loss: 0.500996] [G loss: 0.260491]\n",
      "[Epoch 54/100] [Batch 19/347] [D loss: 0.501049] [G loss: 0.265157]\n",
      "[Epoch 54/100] [Batch 20/347] [D loss: 0.501079] [G loss: 0.269197]\n",
      "[Epoch 54/100] [Batch 21/347] [D loss: 0.501002] [G loss: 0.263883]\n",
      "[Epoch 54/100] [Batch 22/347] [D loss: 0.500981] [G loss: 0.261356]\n",
      "[Epoch 54/100] [Batch 23/347] [D loss: 0.500922] [G loss: 0.260830]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 54/100] [Batch 24/347] [D loss: 0.500813] [G loss: 0.260635]\n",
      "[Epoch 54/100] [Batch 25/347] [D loss: 0.500865] [G loss: 0.260121]\n",
      "[Epoch 54/100] [Batch 26/347] [D loss: 0.500859] [G loss: 0.261120]\n",
      "[Epoch 54/100] [Batch 27/347] [D loss: 0.500987] [G loss: 0.261308]\n",
      "[Epoch 54/100] [Batch 28/347] [D loss: 0.501178] [G loss: 0.268235]\n",
      "[Epoch 54/100] [Batch 29/347] [D loss: 0.501290] [G loss: 0.273805]\n",
      "[Epoch 54/100] [Batch 30/347] [D loss: 0.501321] [G loss: 0.275282]\n",
      "[Epoch 54/100] [Batch 31/347] [D loss: 0.501305] [G loss: 0.275213]\n",
      "[Epoch 54/100] [Batch 32/347] [D loss: 0.501258] [G loss: 0.272055]\n",
      "[Epoch 54/100] [Batch 33/347] [D loss: 0.501192] [G loss: 0.270011]\n",
      "[Epoch 54/100] [Batch 34/347] [D loss: 0.501102] [G loss: 0.265192]\n",
      "[Epoch 54/100] [Batch 35/347] [D loss: 0.500890] [G loss: 0.258327]\n",
      "[Epoch 54/100] [Batch 36/347] [D loss: 0.500684] [G loss: 0.269344]\n",
      "[Epoch 54/100] [Batch 37/347] [D loss: 0.500550] [G loss: 0.274191]\n",
      "[Epoch 54/100] [Batch 38/347] [D loss: 0.500405] [G loss: 0.278605]\n",
      "[Epoch 54/100] [Batch 39/347] [D loss: 0.500434] [G loss: 0.277081]\n",
      "[Epoch 54/100] [Batch 40/347] [D loss: 0.500528] [G loss: 0.275722]\n",
      "[Epoch 54/100] [Batch 41/347] [D loss: 0.500662] [G loss: 0.266308]\n",
      "[Epoch 54/100] [Batch 42/347] [D loss: 0.500895] [G loss: 0.254607]\n",
      "[Epoch 54/100] [Batch 43/347] [D loss: 0.501191] [G loss: 0.270087]\n",
      "[Epoch 54/100] [Batch 44/347] [D loss: 0.501298] [G loss: 0.276275]\n",
      "[Epoch 54/100] [Batch 45/347] [D loss: 0.501193] [G loss: 0.268553]\n",
      "[Epoch 54/100] [Batch 46/347] [D loss: 0.500888] [G loss: 0.262341]\n",
      "[Epoch 54/100] [Batch 47/347] [D loss: 0.500626] [G loss: 0.275786]\n",
      "[Epoch 54/100] [Batch 48/347] [D loss: 0.500311] [G loss: 0.297824]\n",
      "[Epoch 54/100] [Batch 49/347] [D loss: 0.500408] [G loss: 0.293782]\n",
      "[Epoch 54/100] [Batch 50/347] [D loss: 0.500640] [G loss: 0.280426]\n",
      "[Epoch 54/100] [Batch 51/347] [D loss: 0.500673] [G loss: 0.279007]\n",
      "[Epoch 54/100] [Batch 52/347] [D loss: 0.500528] [G loss: 0.285912]\n",
      "[Epoch 54/100] [Batch 53/347] [D loss: 0.500196] [G loss: 0.302024]\n",
      "[Epoch 54/100] [Batch 54/347] [D loss: 0.499955] [G loss: 0.312606]\n",
      "[Epoch 54/100] [Batch 55/347] [D loss: 0.500029] [G loss: 0.309332]\n",
      "[Epoch 54/100] [Batch 56/347] [D loss: 0.500346] [G loss: 0.291834]\n",
      "[Epoch 54/100] [Batch 57/347] [D loss: 0.500631] [G loss: 0.276981]\n",
      "[Epoch 54/100] [Batch 58/347] [D loss: 0.500782] [G loss: 0.270714]\n",
      "[Epoch 54/100] [Batch 59/347] [D loss: 0.500600] [G loss: 0.284557]\n",
      "[Epoch 54/100] [Batch 60/347] [D loss: 0.500208] [G loss: 0.306794]\n",
      "[Epoch 54/100] [Batch 61/347] [D loss: 0.500038] [G loss: 0.311925]\n",
      "[Epoch 54/100] [Batch 62/347] [D loss: 0.500181] [G loss: 0.303332]\n",
      "[Epoch 54/100] [Batch 63/347] [D loss: 0.500427] [G loss: 0.288841]\n",
      "[Epoch 54/100] [Batch 64/347] [D loss: 0.500699] [G loss: 0.271487]\n",
      "[Epoch 54/100] [Batch 65/347] [D loss: 0.500986] [G loss: 0.269566]\n",
      "[Epoch 54/100] [Batch 66/347] [D loss: 0.500767] [G loss: 0.271332]\n",
      "[Epoch 54/100] [Batch 67/347] [D loss: 0.500356] [G loss: 0.292305]\n",
      "[Epoch 54/100] [Batch 68/347] [D loss: 0.500191] [G loss: 0.298551]\n",
      "[Epoch 54/100] [Batch 69/347] [D loss: 0.499979] [G loss: 0.309869]\n",
      "[Epoch 54/100] [Batch 70/347] [D loss: 0.499929] [G loss: 0.308953]\n",
      "[Epoch 54/100] [Batch 71/347] [D loss: 0.500200] [G loss: 0.296761]\n",
      "[Epoch 54/100] [Batch 72/347] [D loss: 0.500322] [G loss: 0.295070]\n",
      "[Epoch 54/100] [Batch 73/347] [D loss: 0.500269] [G loss: 0.296251]\n",
      "[Epoch 54/100] [Batch 74/347] [D loss: 0.500398] [G loss: 0.288766]\n",
      "[Epoch 54/100] [Batch 75/347] [D loss: 0.500484] [G loss: 0.285188]\n",
      "[Epoch 54/100] [Batch 76/347] [D loss: 0.500638] [G loss: 0.275840]\n",
      "[Epoch 54/100] [Batch 77/347] [D loss: 0.501021] [G loss: 0.268676]\n",
      "[Epoch 54/100] [Batch 78/347] [D loss: 0.501312] [G loss: 0.273613]\n",
      "[Epoch 54/100] [Batch 79/347] [D loss: 0.501473] [G loss: 0.282483]\n",
      "[Epoch 54/100] [Batch 80/347] [D loss: 0.501389] [G loss: 0.277768]\n",
      "[Epoch 54/100] [Batch 81/347] [D loss: 0.501410] [G loss: 0.279694]\n",
      "[Epoch 54/100] [Batch 82/347] [D loss: 0.501431] [G loss: 0.282223]\n",
      "[Epoch 54/100] [Batch 83/347] [D loss: 0.501365] [G loss: 0.281253]\n",
      "[Epoch 54/100] [Batch 84/347] [D loss: 0.501360] [G loss: 0.284756]\n",
      "[Epoch 54/100] [Batch 85/347] [D loss: 0.501319] [G loss: 0.284620]\n",
      "[Epoch 54/100] [Batch 86/347] [D loss: 0.501295] [G loss: 0.283860]\n",
      "[Epoch 54/100] [Batch 87/347] [D loss: 0.501285] [G loss: 0.284287]\n",
      "[Epoch 54/100] [Batch 88/347] [D loss: 0.501272] [G loss: 0.284410]\n",
      "[Epoch 54/100] [Batch 89/347] [D loss: 0.501283] [G loss: 0.285891]\n",
      "[Epoch 54/100] [Batch 90/347] [D loss: 0.501261] [G loss: 0.284927]\n",
      "[Epoch 54/100] [Batch 91/347] [D loss: 0.501222] [G loss: 0.283133]\n",
      "[Epoch 54/100] [Batch 92/347] [D loss: 0.501212] [G loss: 0.282850]\n",
      "[Epoch 54/100] [Batch 93/347] [D loss: 0.501201] [G loss: 0.282419]\n",
      "[Epoch 54/100] [Batch 94/347] [D loss: 0.501141] [G loss: 0.278103]\n",
      "[Epoch 54/100] [Batch 95/347] [D loss: 0.501116] [G loss: 0.276634]\n",
      "[Epoch 54/100] [Batch 96/347] [D loss: 0.501119] [G loss: 0.277544]\n",
      "[Epoch 54/100] [Batch 97/347] [D loss: 0.501104] [G loss: 0.276597]\n",
      "[Epoch 54/100] [Batch 98/347] [D loss: 0.501104] [G loss: 0.277659]\n",
      "[Epoch 54/100] [Batch 99/347] [D loss: 0.501097] [G loss: 0.277639]\n",
      "[Epoch 54/100] [Batch 100/347] [D loss: 0.501093] [G loss: 0.277016]\n",
      "[Epoch 54/100] [Batch 101/347] [D loss: 0.501053] [G loss: 0.274599]\n",
      "[Epoch 54/100] [Batch 102/347] [D loss: 0.501000] [G loss: 0.271428]\n",
      "[Epoch 54/100] [Batch 103/347] [D loss: 0.500997] [G loss: 0.272010]\n",
      "[Epoch 54/100] [Batch 104/347] [D loss: 0.500924] [G loss: 0.266569]\n",
      "[Epoch 54/100] [Batch 105/347] [D loss: 0.500870] [G loss: 0.259682]\n",
      "[Epoch 54/100] [Batch 106/347] [D loss: 0.500820] [G loss: 0.261739]\n",
      "[Epoch 54/100] [Batch 107/347] [D loss: 0.500841] [G loss: 0.265519]\n",
      "[Epoch 54/100] [Batch 108/347] [D loss: 0.500860] [G loss: 0.267311]\n",
      "[Epoch 54/100] [Batch 109/347] [D loss: 0.500807] [G loss: 0.271199]\n",
      "[Epoch 54/100] [Batch 110/347] [D loss: 0.500949] [G loss: 0.267385]\n",
      "[Epoch 54/100] [Batch 111/347] [D loss: 0.501024] [G loss: 0.267412]\n",
      "[Epoch 54/100] [Batch 112/347] [D loss: 0.501109] [G loss: 0.270012]\n",
      "[Epoch 54/100] [Batch 113/347] [D loss: 0.501297] [G loss: 0.286886]\n",
      "[Epoch 54/100] [Batch 114/347] [D loss: 0.501350] [G loss: 0.293742]\n",
      "[Epoch 54/100] [Batch 115/347] [D loss: 0.501159] [G loss: 0.277018]\n",
      "[Epoch 54/100] [Batch 116/347] [D loss: 0.500907] [G loss: 0.260004]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 54/100] [Batch 117/347] [D loss: 0.500705] [G loss: 0.259926]\n",
      "[Epoch 54/100] [Batch 118/347] [D loss: 0.500500] [G loss: 0.272475]\n",
      "[Epoch 54/100] [Batch 119/347] [D loss: 0.500452] [G loss: 0.272559]\n",
      "[Epoch 54/100] [Batch 120/347] [D loss: 0.500555] [G loss: 0.265518]\n",
      "[Epoch 54/100] [Batch 121/347] [D loss: 0.500562] [G loss: 0.264392]\n",
      "[Epoch 54/100] [Batch 122/347] [D loss: 0.500606] [G loss: 0.263703]\n",
      "[Epoch 54/100] [Batch 123/347] [D loss: 0.500716] [G loss: 0.261710]\n",
      "[Epoch 54/100] [Batch 124/347] [D loss: 0.500776] [G loss: 0.258725]\n",
      "[Epoch 54/100] [Batch 125/347] [D loss: 0.500867] [G loss: 0.264871]\n",
      "[Epoch 54/100] [Batch 126/347] [D loss: 0.500926] [G loss: 0.268730]\n",
      "[Epoch 54/100] [Batch 127/347] [D loss: 0.500946] [G loss: 0.267233]\n",
      "[Epoch 54/100] [Batch 128/347] [D loss: 0.500845] [G loss: 0.258864]\n",
      "[Epoch 54/100] [Batch 129/347] [D loss: 0.500704] [G loss: 0.260751]\n",
      "[Epoch 54/100] [Batch 130/347] [D loss: 0.500505] [G loss: 0.276609]\n",
      "[Epoch 54/100] [Batch 131/347] [D loss: 0.500321] [G loss: 0.287808]\n",
      "[Epoch 54/100] [Batch 132/347] [D loss: 0.500054] [G loss: 0.307268]\n",
      "[Epoch 54/100] [Batch 133/347] [D loss: 0.499970] [G loss: 0.312885]\n",
      "[Epoch 54/100] [Batch 134/347] [D loss: 0.500200] [G loss: 0.298465]\n",
      "[Epoch 54/100] [Batch 135/347] [D loss: 0.500256] [G loss: 0.295461]\n",
      "[Epoch 54/100] [Batch 136/347] [D loss: 0.500324] [G loss: 0.287710]\n",
      "[Epoch 54/100] [Batch 137/347] [D loss: 0.500264] [G loss: 0.289225]\n",
      "[Epoch 54/100] [Batch 138/347] [D loss: 0.499961] [G loss: 0.307524]\n",
      "[Epoch 54/100] [Batch 139/347] [D loss: 0.499686] [G loss: 0.320996]\n",
      "[Epoch 54/100] [Batch 140/347] [D loss: 0.499530] [G loss: 0.331888]\n",
      "[Epoch 54/100] [Batch 141/347] [D loss: 0.499259] [G loss: 0.346595]\n",
      "[Epoch 54/100] [Batch 142/347] [D loss: 0.499168] [G loss: 0.349603]\n",
      "[Epoch 54/100] [Batch 143/347] [D loss: 0.499044] [G loss: 0.352580]\n",
      "[Epoch 54/100] [Batch 144/347] [D loss: 0.499077] [G loss: 0.345149]\n",
      "[Epoch 54/100] [Batch 145/347] [D loss: 0.499386] [G loss: 0.324666]\n",
      "[Epoch 54/100] [Batch 146/347] [D loss: 0.499540] [G loss: 0.312219]\n",
      "[Epoch 54/100] [Batch 147/347] [D loss: 0.499687] [G loss: 0.303226]\n",
      "[Epoch 54/100] [Batch 148/347] [D loss: 0.499861] [G loss: 0.296133]\n",
      "[Epoch 54/100] [Batch 149/347] [D loss: 0.499879] [G loss: 0.298583]\n",
      "[Epoch 54/100] [Batch 150/347] [D loss: 0.499815] [G loss: 0.306465]\n",
      "[Epoch 54/100] [Batch 151/347] [D loss: 0.499743] [G loss: 0.312067]\n",
      "[Epoch 54/100] [Batch 152/347] [D loss: 0.499589] [G loss: 0.319374]\n",
      "[Epoch 54/100] [Batch 153/347] [D loss: 0.499487] [G loss: 0.322177]\n",
      "[Epoch 54/100] [Batch 154/347] [D loss: 0.499554] [G loss: 0.317002]\n",
      "[Epoch 54/100] [Batch 155/347] [D loss: 0.499614] [G loss: 0.316017]\n",
      "[Epoch 54/100] [Batch 156/347] [D loss: 0.499549] [G loss: 0.320128]\n",
      "[Epoch 54/100] [Batch 157/347] [D loss: 0.499573] [G loss: 0.319757]\n",
      "[Epoch 54/100] [Batch 158/347] [D loss: 0.499578] [G loss: 0.321796]\n",
      "[Epoch 54/100] [Batch 159/347] [D loss: 0.499616] [G loss: 0.320009]\n",
      "[Epoch 54/100] [Batch 160/347] [D loss: 0.499823] [G loss: 0.311725]\n",
      "[Epoch 54/100] [Batch 161/347] [D loss: 0.499739] [G loss: 0.318813]\n",
      "[Epoch 54/100] [Batch 162/347] [D loss: 0.499537] [G loss: 0.329636]\n",
      "[Epoch 54/100] [Batch 163/347] [D loss: 0.499393] [G loss: 0.332185]\n",
      "[Epoch 54/100] [Batch 164/347] [D loss: 0.499554] [G loss: 0.321931]\n",
      "[Epoch 54/100] [Batch 165/347] [D loss: 0.499852] [G loss: 0.306280]\n",
      "[Epoch 54/100] [Batch 166/347] [D loss: 0.500304] [G loss: 0.280502]\n",
      "[Epoch 54/100] [Batch 167/347] [D loss: 0.500705] [G loss: 0.259564]\n",
      "[Epoch 54/100] [Batch 168/347] [D loss: 0.500877] [G loss: 0.263627]\n",
      "[Epoch 54/100] [Batch 169/347] [D loss: 0.501012] [G loss: 0.264932]\n",
      "[Epoch 54/100] [Batch 170/347] [D loss: 0.501092] [G loss: 0.272134]\n",
      "[Epoch 54/100] [Batch 171/347] [D loss: 0.501073] [G loss: 0.272759]\n",
      "[Epoch 54/100] [Batch 172/347] [D loss: 0.501094] [G loss: 0.274656]\n",
      "[Epoch 54/100] [Batch 173/347] [D loss: 0.501060] [G loss: 0.274389]\n",
      "[Epoch 54/100] [Batch 174/347] [D loss: 0.501131] [G loss: 0.279075]\n",
      "[Epoch 54/100] [Batch 175/347] [D loss: 0.501190] [G loss: 0.284694]\n",
      "[Epoch 54/100] [Batch 176/347] [D loss: 0.501243] [G loss: 0.288463]\n",
      "[Epoch 54/100] [Batch 177/347] [D loss: 0.501204] [G loss: 0.286121]\n",
      "[Epoch 54/100] [Batch 178/347] [D loss: 0.501105] [G loss: 0.280756]\n",
      "[Epoch 54/100] [Batch 179/347] [D loss: 0.501044] [G loss: 0.277761]\n",
      "[Epoch 54/100] [Batch 180/347] [D loss: 0.500970] [G loss: 0.274193]\n",
      "[Epoch 54/100] [Batch 181/347] [D loss: 0.501007] [G loss: 0.277152]\n",
      "[Epoch 54/100] [Batch 182/347] [D loss: 0.500994] [G loss: 0.278043]\n",
      "[Epoch 54/100] [Batch 183/347] [D loss: 0.501022] [G loss: 0.279599]\n",
      "[Epoch 54/100] [Batch 184/347] [D loss: 0.501070] [G loss: 0.281993]\n",
      "[Epoch 54/100] [Batch 185/347] [D loss: 0.501021] [G loss: 0.279000]\n",
      "[Epoch 54/100] [Batch 186/347] [D loss: 0.501005] [G loss: 0.277787]\n",
      "[Epoch 54/100] [Batch 187/347] [D loss: 0.500957] [G loss: 0.274869]\n",
      "[Epoch 54/100] [Batch 188/347] [D loss: 0.500782] [G loss: 0.266940]\n",
      "[Epoch 54/100] [Batch 189/347] [D loss: 0.500658] [G loss: 0.261780]\n",
      "[Epoch 54/100] [Batch 190/347] [D loss: 0.500624] [G loss: 0.261574]\n",
      "[Epoch 54/100] [Batch 191/347] [D loss: 0.500570] [G loss: 0.263743]\n",
      "[Epoch 54/100] [Batch 192/347] [D loss: 0.500571] [G loss: 0.263142]\n",
      "[Epoch 54/100] [Batch 193/347] [D loss: 0.500581] [G loss: 0.263456]\n",
      "[Epoch 54/100] [Batch 194/347] [D loss: 0.500501] [G loss: 0.266483]\n",
      "[Epoch 54/100] [Batch 195/347] [D loss: 0.500457] [G loss: 0.267054]\n",
      "[Epoch 54/100] [Batch 196/347] [D loss: 0.500467] [G loss: 0.263039]\n",
      "[Epoch 54/100] [Batch 197/347] [D loss: 0.500483] [G loss: 0.260304]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 54/100] [Batch 198/347] [D loss: 0.500565] [G loss: 0.256661]\n",
      "[Epoch 54/100] [Batch 199/347] [D loss: 0.500560] [G loss: 0.257529]\n",
      "[Epoch 54/100] [Batch 200/347] [D loss: 0.500507] [G loss: 0.263045]\n",
      "[Epoch 54/100] [Batch 201/347] [D loss: 0.500457] [G loss: 0.267001]\n",
      "[Epoch 54/100] [Batch 202/347] [D loss: 0.500401] [G loss: 0.271852]\n",
      "[Epoch 54/100] [Batch 203/347] [D loss: 0.500391] [G loss: 0.271941]\n",
      "[Epoch 54/100] [Batch 204/347] [D loss: 0.500535] [G loss: 0.262774]\n",
      "[Epoch 54/100] [Batch 205/347] [D loss: 0.500700] [G loss: 0.258218]\n",
      "[Epoch 54/100] [Batch 206/347] [D loss: 0.500768] [G loss: 0.261663]\n",
      "[Epoch 54/100] [Batch 207/347] [D loss: 0.500848] [G loss: 0.264086]\n",
      "[Epoch 54/100] [Batch 208/347] [D loss: 0.500953] [G loss: 0.267973]\n",
      "[Epoch 54/100] [Batch 209/347] [D loss: 0.500852] [G loss: 0.263886]\n",
      "[Epoch 54/100] [Batch 210/347] [D loss: 0.500915] [G loss: 0.265404]\n",
      "[Epoch 54/100] [Batch 211/347] [D loss: 0.500858] [G loss: 0.268609]\n",
      "[Epoch 54/100] [Batch 212/347] [D loss: 0.500657] [G loss: 0.270698]\n",
      "[Epoch 54/100] [Batch 213/347] [D loss: 0.500600] [G loss: 0.273072]\n",
      "[Epoch 54/100] [Batch 214/347] [D loss: 0.500595] [G loss: 0.272816]\n",
      "[Epoch 54/100] [Batch 215/347] [D loss: 0.500641] [G loss: 0.274034]\n",
      "[Epoch 54/100] [Batch 216/347] [D loss: 0.500900] [G loss: 0.269807]\n",
      "[Epoch 54/100] [Batch 217/347] [D loss: 0.501149] [G loss: 0.275096]\n",
      "[Epoch 54/100] [Batch 218/347] [D loss: 0.501374] [G loss: 0.289799]\n",
      "[Epoch 54/100] [Batch 219/347] [D loss: 0.501500] [G loss: 0.296537]\n",
      "[Epoch 54/100] [Batch 220/347] [D loss: 0.501603] [G loss: 0.301163]\n",
      "[Epoch 54/100] [Batch 221/347] [D loss: 0.501622] [G loss: 0.302020]\n",
      "[Epoch 54/100] [Batch 222/347] [D loss: 0.501522] [G loss: 0.294497]\n",
      "[Epoch 54/100] [Batch 223/347] [D loss: 0.501257] [G loss: 0.284931]\n",
      "[Epoch 54/100] [Batch 224/347] [D loss: 0.500867] [G loss: 0.275106]\n",
      "[Epoch 54/100] [Batch 225/347] [D loss: 0.500457] [G loss: 0.269001]\n",
      "[Epoch 54/100] [Batch 226/347] [D loss: 0.500126] [G loss: 0.278461]\n",
      "[Epoch 54/100] [Batch 227/347] [D loss: 0.500020] [G loss: 0.279768]\n",
      "[Epoch 54/100] [Batch 228/347] [D loss: 0.500032] [G loss: 0.283161]\n",
      "[Epoch 54/100] [Batch 229/347] [D loss: 0.500104] [G loss: 0.280322]\n",
      "[Epoch 54/100] [Batch 230/347] [D loss: 0.500182] [G loss: 0.276087]\n",
      "[Epoch 54/100] [Batch 231/347] [D loss: 0.500163] [G loss: 0.271772]\n",
      "[Epoch 54/100] [Batch 232/347] [D loss: 0.500211] [G loss: 0.272189]\n",
      "[Epoch 54/100] [Batch 233/347] [D loss: 0.500371] [G loss: 0.267524]\n",
      "[Epoch 54/100] [Batch 234/347] [D loss: 0.500496] [G loss: 0.263104]\n",
      "[Epoch 54/100] [Batch 235/347] [D loss: 0.500700] [G loss: 0.261068]\n",
      "[Epoch 54/100] [Batch 236/347] [D loss: 0.500843] [G loss: 0.263852]\n",
      "[Epoch 54/100] [Batch 237/347] [D loss: 0.500913] [G loss: 0.269887]\n",
      "[Epoch 54/100] [Batch 238/347] [D loss: 0.500884] [G loss: 0.269168]\n",
      "[Epoch 54/100] [Batch 239/347] [D loss: 0.500811] [G loss: 0.265129]\n",
      "[Epoch 54/100] [Batch 240/347] [D loss: 0.500769] [G loss: 0.263204]\n",
      "[Epoch 54/100] [Batch 241/347] [D loss: 0.500779] [G loss: 0.264032]\n",
      "[Epoch 54/100] [Batch 242/347] [D loss: 0.500841] [G loss: 0.266769]\n",
      "[Epoch 54/100] [Batch 243/347] [D loss: 0.500933] [G loss: 0.268788]\n",
      "[Epoch 54/100] [Batch 244/347] [D loss: 0.500800] [G loss: 0.262296]\n",
      "[Epoch 54/100] [Batch 245/347] [D loss: 0.500593] [G loss: 0.256915]\n",
      "[Epoch 54/100] [Batch 246/347] [D loss: 0.500320] [G loss: 0.268825]\n",
      "[Epoch 54/100] [Batch 247/347] [D loss: 0.500030] [G loss: 0.277902]\n",
      "[Epoch 54/100] [Batch 248/347] [D loss: 0.500140] [G loss: 0.275364]\n",
      "[Epoch 54/100] [Batch 249/347] [D loss: 0.500321] [G loss: 0.269520]\n",
      "[Epoch 54/100] [Batch 250/347] [D loss: 0.500557] [G loss: 0.260320]\n",
      "[Epoch 54/100] [Batch 251/347] [D loss: 0.500817] [G loss: 0.267550]\n",
      "[Epoch 54/100] [Batch 252/347] [D loss: 0.500918] [G loss: 0.268496]\n",
      "[Epoch 54/100] [Batch 253/347] [D loss: 0.500845] [G loss: 0.268499]\n",
      "[Epoch 54/100] [Batch 254/347] [D loss: 0.500929] [G loss: 0.270550]\n",
      "[Epoch 54/100] [Batch 255/347] [D loss: 0.500951] [G loss: 0.271421]\n",
      "[Epoch 54/100] [Batch 256/347] [D loss: 0.500837] [G loss: 0.269949]\n",
      "[Epoch 54/100] [Batch 257/347] [D loss: 0.500713] [G loss: 0.267466]\n",
      "[Epoch 54/100] [Batch 258/347] [D loss: 0.500494] [G loss: 0.267433]\n",
      "[Epoch 54/100] [Batch 259/347] [D loss: 0.500351] [G loss: 0.273886]\n",
      "[Epoch 54/100] [Batch 260/347] [D loss: 0.500305] [G loss: 0.274414]\n",
      "[Epoch 54/100] [Batch 261/347] [D loss: 0.500369] [G loss: 0.271454]\n",
      "[Epoch 54/100] [Batch 262/347] [D loss: 0.500359] [G loss: 0.271013]\n",
      "[Epoch 54/100] [Batch 263/347] [D loss: 0.500302] [G loss: 0.273283]\n",
      "[Epoch 54/100] [Batch 264/347] [D loss: 0.500256] [G loss: 0.275519]\n",
      "[Epoch 54/100] [Batch 265/347] [D loss: 0.500235] [G loss: 0.275843]\n",
      "[Epoch 54/100] [Batch 266/347] [D loss: 0.500242] [G loss: 0.276094]\n",
      "[Epoch 54/100] [Batch 267/347] [D loss: 0.500213] [G loss: 0.278755]\n",
      "[Epoch 54/100] [Batch 268/347] [D loss: 0.500215] [G loss: 0.279002]\n",
      "[Epoch 54/100] [Batch 269/347] [D loss: 0.500208] [G loss: 0.279005]\n",
      "[Epoch 54/100] [Batch 270/347] [D loss: 0.500283] [G loss: 0.273704]\n",
      "[Epoch 54/100] [Batch 271/347] [D loss: 0.500277] [G loss: 0.276415]\n",
      "[Epoch 54/100] [Batch 272/347] [D loss: 0.500112] [G loss: 0.289404]\n",
      "[Epoch 54/100] [Batch 273/347] [D loss: 0.500114] [G loss: 0.290637]\n",
      "[Epoch 54/100] [Batch 274/347] [D loss: 0.500071] [G loss: 0.292179]\n",
      "[Epoch 54/100] [Batch 275/347] [D loss: 0.500170] [G loss: 0.284992]\n",
      "[Epoch 54/100] [Batch 276/347] [D loss: 0.500444] [G loss: 0.261744]\n",
      "[Epoch 54/100] [Batch 277/347] [D loss: 0.500524] [G loss: 0.257501]\n",
      "[Epoch 54/100] [Batch 278/347] [D loss: 0.500593] [G loss: 0.256651]\n",
      "[Epoch 54/100] [Batch 279/347] [D loss: 0.500588] [G loss: 0.258651]\n",
      "[Epoch 54/100] [Batch 280/347] [D loss: 0.500559] [G loss: 0.259489]\n",
      "[Epoch 54/100] [Batch 281/347] [D loss: 0.500526] [G loss: 0.259070]\n",
      "[Epoch 54/100] [Batch 282/347] [D loss: 0.500550] [G loss: 0.258994]\n",
      "[Epoch 54/100] [Batch 283/347] [D loss: 0.500525] [G loss: 0.256781]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 54/100] [Batch 284/347] [D loss: 0.500527] [G loss: 0.255014]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 54/100] [Batch 285/347] [D loss: 0.500515] [G loss: 0.254091]\n",
      "[Epoch 54/100] [Batch 286/347] [D loss: 0.500239] [G loss: 0.267506]\n",
      "[Epoch 54/100] [Batch 287/347] [D loss: 0.500192] [G loss: 0.269334]\n",
      "[Epoch 54/100] [Batch 288/347] [D loss: 0.500147] [G loss: 0.270813]\n",
      "[Epoch 54/100] [Batch 289/347] [D loss: 0.500061] [G loss: 0.274179]\n",
      "[Epoch 54/100] [Batch 290/347] [D loss: 0.500390] [G loss: 0.257055]\n",
      "[Epoch 54/100] [Batch 291/347] [D loss: 0.500627] [G loss: 0.259039]\n",
      "[Epoch 54/100] [Batch 292/347] [D loss: 0.500774] [G loss: 0.265939]\n",
      "[Epoch 54/100] [Batch 293/347] [D loss: 0.500957] [G loss: 0.272919]\n",
      "[Epoch 54/100] [Batch 294/347] [D loss: 0.501093] [G loss: 0.276560]\n",
      "[Epoch 54/100] [Batch 295/347] [D loss: 0.501086] [G loss: 0.278388]\n",
      "[Epoch 54/100] [Batch 296/347] [D loss: 0.501055] [G loss: 0.279727]\n",
      "[Epoch 54/100] [Batch 297/347] [D loss: 0.501138] [G loss: 0.286983]\n",
      "[Epoch 54/100] [Batch 298/347] [D loss: 0.501077] [G loss: 0.283073]\n",
      "[Epoch 54/100] [Batch 299/347] [D loss: 0.501085] [G loss: 0.280690]\n",
      "[Epoch 54/100] [Batch 300/347] [D loss: 0.501118] [G loss: 0.280427]\n",
      "[Epoch 54/100] [Batch 301/347] [D loss: 0.500851] [G loss: 0.270560]\n",
      "[Epoch 54/100] [Batch 302/347] [D loss: 0.500700] [G loss: 0.262736]\n",
      "[Epoch 54/100] [Batch 303/347] [D loss: 0.500422] [G loss: 0.257059]\n",
      "[Epoch 54/100] [Batch 304/347] [D loss: 0.500181] [G loss: 0.267621]\n",
      "[Epoch 54/100] [Batch 305/347] [D loss: 0.500099] [G loss: 0.268946]\n",
      "[Epoch 54/100] [Batch 306/347] [D loss: 0.500126] [G loss: 0.268885]\n",
      "[Epoch 54/100] [Batch 307/347] [D loss: 0.500294] [G loss: 0.262076]\n",
      "[Epoch 54/100] [Batch 308/347] [D loss: 0.500478] [G loss: 0.255206]\n",
      "[Epoch 54/100] [Batch 309/347] [D loss: 0.500691] [G loss: 0.271486]\n",
      "[Epoch 54/100] [Batch 310/347] [D loss: 0.500887] [G loss: 0.286334]\n",
      "[Epoch 54/100] [Batch 311/347] [D loss: 0.500900] [G loss: 0.286536]\n",
      "[Epoch 54/100] [Batch 312/347] [D loss: 0.500920] [G loss: 0.284053]\n",
      "[Epoch 54/100] [Batch 313/347] [D loss: 0.500866] [G loss: 0.277373]\n",
      "[Epoch 54/100] [Batch 314/347] [D loss: 0.500656] [G loss: 0.265153]\n",
      "[Epoch 54/100] [Batch 315/347] [D loss: 0.500489] [G loss: 0.256008]\n",
      "[Epoch 54/100] [Batch 316/347] [D loss: 0.500535] [G loss: 0.259007]\n",
      "[Epoch 54/100] [Batch 317/347] [D loss: 0.500622] [G loss: 0.264574]\n",
      "[Epoch 54/100] [Batch 318/347] [D loss: 0.500908] [G loss: 0.279327]\n",
      "[Epoch 54/100] [Batch 319/347] [D loss: 0.501133] [G loss: 0.292865]\n",
      "[Epoch 54/100] [Batch 320/347] [D loss: 0.501125] [G loss: 0.292990]\n",
      "[Epoch 54/100] [Batch 321/347] [D loss: 0.501063] [G loss: 0.287988]\n",
      "[Epoch 54/100] [Batch 322/347] [D loss: 0.500980] [G loss: 0.282561]\n",
      "[Epoch 54/100] [Batch 323/347] [D loss: 0.500884] [G loss: 0.275846]\n",
      "[Epoch 54/100] [Batch 324/347] [D loss: 0.500816] [G loss: 0.271459]\n",
      "[Epoch 54/100] [Batch 325/347] [D loss: 0.500716] [G loss: 0.265740]\n",
      "[Epoch 54/100] [Batch 326/347] [D loss: 0.500583] [G loss: 0.259058]\n",
      "[Epoch 54/100] [Batch 327/347] [D loss: 0.500345] [G loss: 0.261180]\n",
      "[Epoch 54/100] [Batch 328/347] [D loss: 0.500198] [G loss: 0.269016]\n",
      "[Epoch 54/100] [Batch 329/347] [D loss: 0.500206] [G loss: 0.267561]\n",
      "[Epoch 54/100] [Batch 330/347] [D loss: 0.500286] [G loss: 0.262490]\n",
      "[Epoch 54/100] [Batch 331/347] [D loss: 0.500520] [G loss: 0.257822]\n",
      "[Epoch 54/100] [Batch 332/347] [D loss: 0.500827] [G loss: 0.278325]\n",
      "[Epoch 54/100] [Batch 333/347] [D loss: 0.500834] [G loss: 0.277375]\n",
      "[Epoch 54/100] [Batch 334/347] [D loss: 0.500773] [G loss: 0.271508]\n",
      "[Epoch 54/100] [Batch 335/347] [D loss: 0.500759] [G loss: 0.270373]\n",
      "[Epoch 54/100] [Batch 336/347] [D loss: 0.500742] [G loss: 0.270176]\n",
      "[Epoch 54/100] [Batch 337/347] [D loss: 0.500791] [G loss: 0.274902]\n",
      "[Epoch 54/100] [Batch 338/347] [D loss: 0.500898] [G loss: 0.283209]\n",
      "[Epoch 54/100] [Batch 339/347] [D loss: 0.500927] [G loss: 0.283928]\n",
      "[Epoch 54/100] [Batch 340/347] [D loss: 0.500865] [G loss: 0.280658]\n",
      "[Epoch 54/100] [Batch 341/347] [D loss: 0.500847] [G loss: 0.281143]\n",
      "[Epoch 54/100] [Batch 342/347] [D loss: 0.500665] [G loss: 0.269260]\n",
      "[Epoch 54/100] [Batch 343/347] [D loss: 0.500410] [G loss: 0.259440]\n",
      "[Epoch 54/100] [Batch 344/347] [D loss: 0.500178] [G loss: 0.266389]\n",
      "[Epoch 54/100] [Batch 345/347] [D loss: 0.499955] [G loss: 0.281219]\n",
      "[Epoch 54/100] [Batch 346/347] [D loss: 0.499962] [G loss: 0.281273]\n",
      "[Epoch 54/100] [Batch 347/347] [D loss: 0.500050] [G loss: 0.275719]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 55/100] [Batch 1/347] [D loss: 0.500490] [G loss: 0.265727]\n",
      "[Epoch 55/100] [Batch 2/347] [D loss: 0.500467] [G loss: 0.269003]\n",
      "[Epoch 55/100] [Batch 3/347] [D loss: 0.500533] [G loss: 0.270969]\n",
      "[Epoch 55/100] [Batch 4/347] [D loss: 0.500531] [G loss: 0.271661]\n",
      "[Epoch 55/100] [Batch 5/347] [D loss: 0.500481] [G loss: 0.270347]\n",
      "[Epoch 55/100] [Batch 6/347] [D loss: 0.500465] [G loss: 0.268689]\n",
      "[Epoch 55/100] [Batch 7/347] [D loss: 0.500355] [G loss: 0.268918]\n",
      "[Epoch 55/100] [Batch 8/347] [D loss: 0.500343] [G loss: 0.268349]\n",
      "[Epoch 55/100] [Batch 9/347] [D loss: 0.500361] [G loss: 0.268297]\n",
      "[Epoch 55/100] [Batch 10/347] [D loss: 0.500362] [G loss: 0.269804]\n",
      "[Epoch 55/100] [Batch 11/347] [D loss: 0.500510] [G loss: 0.269280]\n",
      "[Epoch 55/100] [Batch 12/347] [D loss: 0.500558] [G loss: 0.271776]\n",
      "[Epoch 55/100] [Batch 13/347] [D loss: 0.500564] [G loss: 0.270801]\n",
      "[Epoch 55/100] [Batch 14/347] [D loss: 0.500594] [G loss: 0.270079]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 55/100] [Batch 15/347] [D loss: 0.500466] [G loss: 0.260822]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 55/100] [Batch 16/347] [D loss: 0.500404] [G loss: 0.259011]\n",
      "[Epoch 55/100] [Batch 17/347] [D loss: 0.500461] [G loss: 0.257353]\n",
      "[Epoch 55/100] [Batch 18/347] [D loss: 0.500466] [G loss: 0.257886]\n",
      "[Epoch 55/100] [Batch 19/347] [D loss: 0.500520] [G loss: 0.262620]\n",
      "[Epoch 55/100] [Batch 20/347] [D loss: 0.500558] [G loss: 0.266719]\n",
      "[Epoch 55/100] [Batch 21/347] [D loss: 0.500481] [G loss: 0.261532]\n",
      "[Epoch 55/100] [Batch 22/347] [D loss: 0.500461] [G loss: 0.260194]\n",
      "[Epoch 55/100] [Batch 23/347] [D loss: 0.500412] [G loss: 0.260229]\n",
      "[Epoch 55/100] [Batch 24/347] [D loss: 0.500307] [G loss: 0.259555]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 55/100] [Batch 25/347] [D loss: 0.500372] [G loss: 0.257645]\n",
      "[Epoch 55/100] [Batch 26/347] [D loss: 0.500379] [G loss: 0.258328]\n",
      "[Epoch 55/100] [Batch 27/347] [D loss: 0.500525] [G loss: 0.260065]\n",
      "[Epoch 55/100] [Batch 28/347] [D loss: 0.500745] [G loss: 0.267320]\n",
      "[Epoch 55/100] [Batch 29/347] [D loss: 0.500877] [G loss: 0.273867]\n",
      "[Epoch 55/100] [Batch 30/347] [D loss: 0.500915] [G loss: 0.275561]\n",
      "[Epoch 55/100] [Batch 31/347] [D loss: 0.500908] [G loss: 0.275690]\n",
      "[Epoch 55/100] [Batch 32/347] [D loss: 0.500862] [G loss: 0.272705]\n",
      "[Epoch 55/100] [Batch 33/347] [D loss: 0.500796] [G loss: 0.270811]\n",
      "[Epoch 55/100] [Batch 34/347] [D loss: 0.500702] [G loss: 0.266112]\n",
      "[Epoch 55/100] [Batch 35/347] [D loss: 0.500476] [G loss: 0.257686]\n",
      "[Epoch 55/100] [Batch 36/347] [D loss: 0.500251] [G loss: 0.264760]\n",
      "[Epoch 55/100] [Batch 37/347] [D loss: 0.500103] [G loss: 0.269678]\n",
      "[Epoch 55/100] [Batch 38/347] [D loss: 0.499948] [G loss: 0.274141]\n",
      "[Epoch 55/100] [Batch 39/347] [D loss: 0.499972] [G loss: 0.273219]\n",
      "[Epoch 55/100] [Batch 40/347] [D loss: 0.500080] [G loss: 0.271925]\n",
      "[Epoch 55/100] [Batch 41/347] [D loss: 0.500232] [G loss: 0.262591]\n",
      "[Epoch 55/100] [Batch 42/347] [D loss: 0.500479] [G loss: 0.255023]\n",
      "[Epoch 55/100] [Batch 43/347] [D loss: 0.500798] [G loss: 0.270481]\n",
      "[Epoch 55/100] [Batch 44/347] [D loss: 0.500914] [G loss: 0.276455]\n",
      "[Epoch 55/100] [Batch 45/347] [D loss: 0.500793] [G loss: 0.268515]\n",
      "[Epoch 55/100] [Batch 46/347] [D loss: 0.500460] [G loss: 0.261371]\n",
      "[Epoch 55/100] [Batch 47/347] [D loss: 0.500164] [G loss: 0.272707]\n",
      "[Epoch 55/100] [Batch 48/347] [D loss: 0.499813] [G loss: 0.294900]\n",
      "[Epoch 55/100] [Batch 49/347] [D loss: 0.499917] [G loss: 0.291019]\n",
      "[Epoch 55/100] [Batch 50/347] [D loss: 0.500164] [G loss: 0.277773]\n",
      "[Epoch 55/100] [Batch 51/347] [D loss: 0.500209] [G loss: 0.276433]\n",
      "[Epoch 55/100] [Batch 52/347] [D loss: 0.500052] [G loss: 0.283451]\n",
      "[Epoch 55/100] [Batch 53/347] [D loss: 0.499687] [G loss: 0.299662]\n",
      "[Epoch 55/100] [Batch 54/347] [D loss: 0.499413] [G loss: 0.310340]\n",
      "[Epoch 55/100] [Batch 55/347] [D loss: 0.499496] [G loss: 0.307189]\n",
      "[Epoch 55/100] [Batch 56/347] [D loss: 0.499836] [G loss: 0.289793]\n",
      "[Epoch 55/100] [Batch 57/347] [D loss: 0.500151] [G loss: 0.275016]\n",
      "[Epoch 55/100] [Batch 58/347] [D loss: 0.500322] [G loss: 0.268808]\n",
      "[Epoch 55/100] [Batch 59/347] [D loss: 0.500124] [G loss: 0.282751]\n",
      "[Epoch 55/100] [Batch 60/347] [D loss: 0.499694] [G loss: 0.305073]\n",
      "[Epoch 55/100] [Batch 61/347] [D loss: 0.499503] [G loss: 0.310315]\n",
      "[Epoch 55/100] [Batch 62/347] [D loss: 0.499653] [G loss: 0.301784]\n",
      "[Epoch 55/100] [Batch 63/347] [D loss: 0.499924] [G loss: 0.287351]\n",
      "[Epoch 55/100] [Batch 64/347] [D loss: 0.500214] [G loss: 0.270069]\n",
      "[Epoch 55/100] [Batch 65/347] [D loss: 0.500537] [G loss: 0.266687]\n",
      "[Epoch 55/100] [Batch 66/347] [D loss: 0.500302] [G loss: 0.270043]\n",
      "[Epoch 55/100] [Batch 67/347] [D loss: 0.499846] [G loss: 0.291074]\n",
      "[Epoch 55/100] [Batch 68/347] [D loss: 0.499668] [G loss: 0.297416]\n",
      "[Epoch 55/100] [Batch 69/347] [D loss: 0.499434] [G loss: 0.308781]\n",
      "[Epoch 55/100] [Batch 70/347] [D loss: 0.499377] [G loss: 0.307931]\n",
      "[Epoch 55/100] [Batch 71/347] [D loss: 0.499672] [G loss: 0.295776]\n",
      "[Epoch 55/100] [Batch 72/347] [D loss: 0.499809] [G loss: 0.294128]\n",
      "[Epoch 55/100] [Batch 73/347] [D loss: 0.499754] [G loss: 0.295352]\n",
      "[Epoch 55/100] [Batch 74/347] [D loss: 0.499893] [G loss: 0.287931]\n",
      "[Epoch 55/100] [Batch 75/347] [D loss: 0.499984] [G loss: 0.284430]\n",
      "[Epoch 55/100] [Batch 76/347] [D loss: 0.500149] [G loss: 0.275145]\n",
      "[Epoch 55/100] [Batch 77/347] [D loss: 0.500567] [G loss: 0.265406]\n",
      "[Epoch 55/100] [Batch 78/347] [D loss: 0.500886] [G loss: 0.271308]\n",
      "[Epoch 55/100] [Batch 79/347] [D loss: 0.501058] [G loss: 0.280158]\n",
      "[Epoch 55/100] [Batch 80/347] [D loss: 0.500969] [G loss: 0.274831]\n",
      "[Epoch 55/100] [Batch 81/347] [D loss: 0.500991] [G loss: 0.277247]\n",
      "[Epoch 55/100] [Batch 82/347] [D loss: 0.501015] [G loss: 0.279711]\n",
      "[Epoch 55/100] [Batch 83/347] [D loss: 0.500942] [G loss: 0.278693]\n",
      "[Epoch 55/100] [Batch 84/347] [D loss: 0.500934] [G loss: 0.282213]\n",
      "[Epoch 55/100] [Batch 85/347] [D loss: 0.500900] [G loss: 0.282022]\n",
      "[Epoch 55/100] [Batch 86/347] [D loss: 0.500876] [G loss: 0.281227]\n",
      "[Epoch 55/100] [Batch 87/347] [D loss: 0.500869] [G loss: 0.281663]\n",
      "[Epoch 55/100] [Batch 88/347] [D loss: 0.500859] [G loss: 0.281740]\n",
      "[Epoch 55/100] [Batch 89/347] [D loss: 0.500867] [G loss: 0.283189]\n",
      "[Epoch 55/100] [Batch 90/347] [D loss: 0.500846] [G loss: 0.282213]\n",
      "[Epoch 55/100] [Batch 91/347] [D loss: 0.500810] [G loss: 0.280394]\n",
      "[Epoch 55/100] [Batch 92/347] [D loss: 0.500798] [G loss: 0.280117]\n",
      "[Epoch 55/100] [Batch 93/347] [D loss: 0.500787] [G loss: 0.279690]\n",
      "[Epoch 55/100] [Batch 94/347] [D loss: 0.500727] [G loss: 0.275372]\n",
      "[Epoch 55/100] [Batch 95/347] [D loss: 0.500700] [G loss: 0.273885]\n",
      "[Epoch 55/100] [Batch 96/347] [D loss: 0.500707] [G loss: 0.274828]\n",
      "[Epoch 55/100] [Batch 97/347] [D loss: 0.500689] [G loss: 0.273893]\n",
      "[Epoch 55/100] [Batch 98/347] [D loss: 0.500697] [G loss: 0.274981]\n",
      "[Epoch 55/100] [Batch 99/347] [D loss: 0.500691] [G loss: 0.274979]\n",
      "[Epoch 55/100] [Batch 100/347] [D loss: 0.500682] [G loss: 0.274381]\n",
      "[Epoch 55/100] [Batch 101/347] [D loss: 0.500645] [G loss: 0.272027]\n",
      "[Epoch 55/100] [Batch 102/347] [D loss: 0.500586] [G loss: 0.268859]\n",
      "[Epoch 55/100] [Batch 103/347] [D loss: 0.500588] [G loss: 0.269490]\n",
      "[Epoch 55/100] [Batch 104/347] [D loss: 0.500508] [G loss: 0.264060]\n",
      "[Epoch 55/100] [Batch 105/347] [D loss: 0.500450] [G loss: 0.257204]\n",
      "[Epoch 55/100] [Batch 106/347] [D loss: 0.500390] [G loss: 0.259094]\n",
      "[Epoch 55/100] [Batch 107/347] [D loss: 0.500421] [G loss: 0.262908]\n",
      "[Epoch 55/100] [Batch 108/347] [D loss: 0.500442] [G loss: 0.264765]\n",
      "[Epoch 55/100] [Batch 109/347] [D loss: 0.500386] [G loss: 0.268693]\n",
      "[Epoch 55/100] [Batch 110/347] [D loss: 0.500541] [G loss: 0.264900]\n",
      "[Epoch 55/100] [Batch 111/347] [D loss: 0.500630] [G loss: 0.264985]\n",
      "[Epoch 55/100] [Batch 112/347] [D loss: 0.500724] [G loss: 0.267577]\n",
      "[Epoch 55/100] [Batch 113/347] [D loss: 0.500933] [G loss: 0.284670]\n",
      "[Epoch 55/100] [Batch 114/347] [D loss: 0.500998] [G loss: 0.291605]\n",
      "[Epoch 55/100] [Batch 115/347] [D loss: 0.500785] [G loss: 0.274912]\n",
      "[Epoch 55/100] [Batch 116/347] [D loss: 0.500509] [G loss: 0.257927]\n",
      "[Epoch 55/100] [Batch 117/347] [D loss: 0.500286] [G loss: 0.258300]\n",
      "[Epoch 55/100] [Batch 118/347] [D loss: 0.500058] [G loss: 0.270866]\n",
      "[Epoch 55/100] [Batch 119/347] [D loss: 0.500008] [G loss: 0.270926]\n",
      "[Epoch 55/100] [Batch 120/347] [D loss: 0.500124] [G loss: 0.263891]\n",
      "[Epoch 55/100] [Batch 121/347] [D loss: 0.500136] [G loss: 0.262743]\n",
      "[Epoch 55/100] [Batch 122/347] [D loss: 0.500192] [G loss: 0.262209]\n",
      "[Epoch 55/100] [Batch 123/347] [D loss: 0.500309] [G loss: 0.260217]\n",
      "[Epoch 55/100] [Batch 124/347] [D loss: 0.500378] [G loss: 0.257017]\n",
      "[Epoch 55/100] [Batch 125/347] [D loss: 0.500486] [G loss: 0.263281]\n",
      "[Epoch 55/100] [Batch 126/347] [D loss: 0.500563] [G loss: 0.267332]\n",
      "[Epoch 55/100] [Batch 127/347] [D loss: 0.500591] [G loss: 0.266010]\n",
      "[Epoch 55/100] [Batch 128/347] [D loss: 0.500479] [G loss: 0.257828]\n",
      "[Epoch 55/100] [Batch 129/347] [D loss: 0.500327] [G loss: 0.258305]\n",
      "[Epoch 55/100] [Batch 130/347] [D loss: 0.500112] [G loss: 0.274065]\n",
      "[Epoch 55/100] [Batch 131/347] [D loss: 0.499914] [G loss: 0.285186]\n",
      "[Epoch 55/100] [Batch 132/347] [D loss: 0.499619] [G loss: 0.304569]\n",
      "[Epoch 55/100] [Batch 133/347] [D loss: 0.499528] [G loss: 0.310107]\n",
      "[Epoch 55/100] [Batch 134/347] [D loss: 0.499781] [G loss: 0.295617]\n",
      "[Epoch 55/100] [Batch 135/347] [D loss: 0.499855] [G loss: 0.292540]\n",
      "[Epoch 55/100] [Batch 136/347] [D loss: 0.499928] [G loss: 0.284724]\n",
      "[Epoch 55/100] [Batch 137/347] [D loss: 0.499869] [G loss: 0.286187]\n",
      "[Epoch 55/100] [Batch 138/347] [D loss: 0.499532] [G loss: 0.304486]\n",
      "[Epoch 55/100] [Batch 139/347] [D loss: 0.499232] [G loss: 0.317934]\n",
      "[Epoch 55/100] [Batch 140/347] [D loss: 0.499060] [G loss: 0.328847]\n",
      "[Epoch 55/100] [Batch 141/347] [D loss: 0.498762] [G loss: 0.343522]\n",
      "[Epoch 55/100] [Batch 142/347] [D loss: 0.498663] [G loss: 0.346494]\n",
      "[Epoch 55/100] [Batch 143/347] [D loss: 0.498530] [G loss: 0.349474]\n",
      "[Epoch 55/100] [Batch 144/347] [D loss: 0.498570] [G loss: 0.342104]\n",
      "[Epoch 55/100] [Batch 145/347] [D loss: 0.498913] [G loss: 0.321601]\n",
      "[Epoch 55/100] [Batch 146/347] [D loss: 0.499091] [G loss: 0.309174]\n",
      "[Epoch 55/100] [Batch 147/347] [D loss: 0.499255] [G loss: 0.300193]\n",
      "[Epoch 55/100] [Batch 148/347] [D loss: 0.499448] [G loss: 0.293138]\n",
      "[Epoch 55/100] [Batch 149/347] [D loss: 0.499470] [G loss: 0.295627]\n",
      "[Epoch 55/100] [Batch 150/347] [D loss: 0.499398] [G loss: 0.303569]\n",
      "[Epoch 55/100] [Batch 151/347] [D loss: 0.499321] [G loss: 0.309213]\n",
      "[Epoch 55/100] [Batch 152/347] [D loss: 0.499150] [G loss: 0.316546]\n",
      "[Epoch 55/100] [Batch 153/347] [D loss: 0.499038] [G loss: 0.319387]\n",
      "[Epoch 55/100] [Batch 154/347] [D loss: 0.499110] [G loss: 0.314275]\n",
      "[Epoch 55/100] [Batch 155/347] [D loss: 0.499182] [G loss: 0.313282]\n",
      "[Epoch 55/100] [Batch 156/347] [D loss: 0.499111] [G loss: 0.317413]\n",
      "[Epoch 55/100] [Batch 157/347] [D loss: 0.499138] [G loss: 0.317074]\n",
      "[Epoch 55/100] [Batch 158/347] [D loss: 0.499143] [G loss: 0.319138]\n",
      "[Epoch 55/100] [Batch 159/347] [D loss: 0.499182] [G loss: 0.317398]\n",
      "[Epoch 55/100] [Batch 160/347] [D loss: 0.499408] [G loss: 0.309118]\n",
      "[Epoch 55/100] [Batch 161/347] [D loss: 0.499326] [G loss: 0.316245]\n",
      "[Epoch 55/100] [Batch 162/347] [D loss: 0.499097] [G loss: 0.327092]\n",
      "[Epoch 55/100] [Batch 163/347] [D loss: 0.498945] [G loss: 0.329665]\n",
      "[Epoch 55/100] [Batch 164/347] [D loss: 0.499115] [G loss: 0.319454]\n",
      "[Epoch 55/100] [Batch 165/347] [D loss: 0.499445] [G loss: 0.303842]\n",
      "[Epoch 55/100] [Batch 166/347] [D loss: 0.499942] [G loss: 0.278094]\n",
      "[Epoch 55/100] [Batch 167/347] [D loss: 0.500386] [G loss: 0.259922]\n",
      "[Epoch 55/100] [Batch 168/347] [D loss: 0.500572] [G loss: 0.263988]\n",
      "[Epoch 55/100] [Batch 169/347] [D loss: 0.500719] [G loss: 0.264880]\n",
      "[Epoch 55/100] [Batch 170/347] [D loss: 0.500803] [G loss: 0.272065]\n",
      "[Epoch 55/100] [Batch 171/347] [D loss: 0.500784] [G loss: 0.272684]\n",
      "[Epoch 55/100] [Batch 172/347] [D loss: 0.500814] [G loss: 0.274569]\n",
      "[Epoch 55/100] [Batch 173/347] [D loss: 0.500769] [G loss: 0.274281]\n",
      "[Epoch 55/100] [Batch 174/347] [D loss: 0.500850] [G loss: 0.278978]\n",
      "[Epoch 55/100] [Batch 175/347] [D loss: 0.500914] [G loss: 0.284640]\n",
      "[Epoch 55/100] [Batch 176/347] [D loss: 0.500976] [G loss: 0.288430]\n",
      "[Epoch 55/100] [Batch 177/347] [D loss: 0.500932] [G loss: 0.286082]\n",
      "[Epoch 55/100] [Batch 178/347] [D loss: 0.500828] [G loss: 0.280723]\n",
      "[Epoch 55/100] [Batch 179/347] [D loss: 0.500764] [G loss: 0.277722]\n",
      "[Epoch 55/100] [Batch 180/347] [D loss: 0.500683] [G loss: 0.274171]\n",
      "[Epoch 55/100] [Batch 181/347] [D loss: 0.500726] [G loss: 0.277113]\n",
      "[Epoch 55/100] [Batch 182/347] [D loss: 0.500717] [G loss: 0.278031]\n",
      "[Epoch 55/100] [Batch 183/347] [D loss: 0.500745] [G loss: 0.279641]\n",
      "[Epoch 55/100] [Batch 184/347] [D loss: 0.500800] [G loss: 0.282044]\n",
      "[Epoch 55/100] [Batch 185/347] [D loss: 0.500752] [G loss: 0.279040]\n",
      "[Epoch 55/100] [Batch 186/347] [D loss: 0.500731] [G loss: 0.277838]\n",
      "[Epoch 55/100] [Batch 187/347] [D loss: 0.500689] [G loss: 0.274905]\n",
      "[Epoch 55/100] [Batch 188/347] [D loss: 0.500499] [G loss: 0.266989]\n",
      "[Epoch 55/100] [Batch 189/347] [D loss: 0.500364] [G loss: 0.260720]\n",
      "[Epoch 55/100] [Batch 190/347] [D loss: 0.500323] [G loss: 0.258718]\n",
      "[Epoch 55/100] [Batch 191/347] [D loss: 0.500261] [G loss: 0.261058]\n",
      "[Epoch 55/100] [Batch 192/347] [D loss: 0.500260] [G loss: 0.260627]\n",
      "[Epoch 55/100] [Batch 193/347] [D loss: 0.500268] [G loss: 0.261105]\n",
      "[Epoch 55/100] [Batch 194/347] [D loss: 0.500181] [G loss: 0.264305]\n",
      "[Epoch 55/100] [Batch 195/347] [D loss: 0.500126] [G loss: 0.264983]\n",
      "[Epoch 55/100] [Batch 196/347] [D loss: 0.500134] [G loss: 0.261093]\n",
      "[Epoch 55/100] [Batch 197/347] [D loss: 0.500147] [G loss: 0.258489]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 55/100] [Batch 198/347] [D loss: 0.500236] [G loss: 0.255147]\n",
      "[Epoch 55/100] [Batch 199/347] [D loss: 0.500227] [G loss: 0.255953]\n",
      "[Epoch 55/100] [Batch 200/347] [D loss: 0.500175] [G loss: 0.261557]\n",
      "[Epoch 55/100] [Batch 201/347] [D loss: 0.500119] [G loss: 0.265616]\n",
      "[Epoch 55/100] [Batch 202/347] [D loss: 0.500055] [G loss: 0.270555]\n",
      "[Epoch 55/100] [Batch 203/347] [D loss: 0.500042] [G loss: 0.270685]\n",
      "[Epoch 55/100] [Batch 204/347] [D loss: 0.500193] [G loss: 0.261604]\n",
      "[Epoch 55/100] [Batch 205/347] [D loss: 0.500378] [G loss: 0.256473]\n",
      "[Epoch 55/100] [Batch 206/347] [D loss: 0.500444] [G loss: 0.259857]\n",
      "[Epoch 55/100] [Batch 207/347] [D loss: 0.500534] [G loss: 0.262224]\n",
      "[Epoch 55/100] [Batch 208/347] [D loss: 0.500647] [G loss: 0.266083]\n",
      "[Epoch 55/100] [Batch 209/347] [D loss: 0.500537] [G loss: 0.261973]\n",
      "[Epoch 55/100] [Batch 210/347] [D loss: 0.500606] [G loss: 0.263520]\n",
      "[Epoch 55/100] [Batch 211/347] [D loss: 0.500547] [G loss: 0.266700]\n",
      "[Epoch 55/100] [Batch 212/347] [D loss: 0.500321] [G loss: 0.268788]\n",
      "[Epoch 55/100] [Batch 213/347] [D loss: 0.500256] [G loss: 0.271184]\n",
      "[Epoch 55/100] [Batch 214/347] [D loss: 0.500251] [G loss: 0.270938]\n",
      "[Epoch 55/100] [Batch 215/347] [D loss: 0.500306] [G loss: 0.272170]\n",
      "[Epoch 55/100] [Batch 216/347] [D loss: 0.500594] [G loss: 0.267966]\n",
      "[Epoch 55/100] [Batch 217/347] [D loss: 0.500863] [G loss: 0.273268]\n",
      "[Epoch 55/100] [Batch 218/347] [D loss: 0.501111] [G loss: 0.287978]\n",
      "[Epoch 55/100] [Batch 219/347] [D loss: 0.501254] [G loss: 0.294762]\n",
      "[Epoch 55/100] [Batch 220/347] [D loss: 0.501363] [G loss: 0.299421]\n",
      "[Epoch 55/100] [Batch 221/347] [D loss: 0.501384] [G loss: 0.300334]\n",
      "[Epoch 55/100] [Batch 222/347] [D loss: 0.501278] [G loss: 0.292839]\n",
      "[Epoch 55/100] [Batch 223/347] [D loss: 0.500989] [G loss: 0.283297]\n",
      "[Epoch 55/100] [Batch 224/347] [D loss: 0.500562] [G loss: 0.273489]\n",
      "[Epoch 55/100] [Batch 225/347] [D loss: 0.500115] [G loss: 0.268370]\n",
      "[Epoch 55/100] [Batch 226/347] [D loss: 0.499759] [G loss: 0.277806]\n",
      "[Epoch 55/100] [Batch 227/347] [D loss: 0.499650] [G loss: 0.279116]\n",
      "[Epoch 55/100] [Batch 228/347] [D loss: 0.499664] [G loss: 0.282428]\n",
      "[Epoch 55/100] [Batch 229/347] [D loss: 0.499740] [G loss: 0.279551]\n",
      "[Epoch 55/100] [Batch 230/347] [D loss: 0.499825] [G loss: 0.275277]\n",
      "[Epoch 55/100] [Batch 231/347] [D loss: 0.499799] [G loss: 0.270944]\n",
      "[Epoch 55/100] [Batch 232/347] [D loss: 0.499854] [G loss: 0.271328]\n",
      "[Epoch 55/100] [Batch 233/347] [D loss: 0.500032] [G loss: 0.266645]\n",
      "[Epoch 55/100] [Batch 234/347] [D loss: 0.500168] [G loss: 0.262235]\n",
      "[Epoch 55/100] [Batch 235/347] [D loss: 0.500392] [G loss: 0.259417]\n",
      "[Epoch 55/100] [Batch 236/347] [D loss: 0.500555] [G loss: 0.262202]\n",
      "[Epoch 55/100] [Batch 237/347] [D loss: 0.500633] [G loss: 0.268238]\n",
      "[Epoch 55/100] [Batch 238/347] [D loss: 0.500599] [G loss: 0.267532]\n",
      "[Epoch 55/100] [Batch 239/347] [D loss: 0.500520] [G loss: 0.263517]\n",
      "[Epoch 55/100] [Batch 240/347] [D loss: 0.500476] [G loss: 0.261628]\n",
      "[Epoch 55/100] [Batch 241/347] [D loss: 0.500493] [G loss: 0.262475]\n",
      "[Epoch 55/100] [Batch 242/347] [D loss: 0.500548] [G loss: 0.265221]\n",
      "[Epoch 55/100] [Batch 243/347] [D loss: 0.500654] [G loss: 0.267289]\n",
      "[Epoch 55/100] [Batch 244/347] [D loss: 0.500507] [G loss: 0.260859]\n",
      "[Epoch 55/100] [Batch 245/347] [D loss: 0.500275] [G loss: 0.255513]\n",
      "[Epoch 55/100] [Batch 246/347] [D loss: 0.499985] [G loss: 0.268142]\n",
      "[Epoch 55/100] [Batch 247/347] [D loss: 0.499677] [G loss: 0.277219]\n",
      "[Epoch 55/100] [Batch 248/347] [D loss: 0.499790] [G loss: 0.274686]\n",
      "[Epoch 55/100] [Batch 249/347] [D loss: 0.499987] [G loss: 0.268821]\n",
      "[Epoch 55/100] [Batch 250/347] [D loss: 0.500246] [G loss: 0.259430]\n",
      "[Epoch 55/100] [Batch 251/347] [D loss: 0.500537] [G loss: 0.266551]\n",
      "[Epoch 55/100] [Batch 252/347] [D loss: 0.500661] [G loss: 0.267714]\n",
      "[Epoch 55/100] [Batch 253/347] [D loss: 0.500581] [G loss: 0.267905]\n",
      "[Epoch 55/100] [Batch 254/347] [D loss: 0.500677] [G loss: 0.270143]\n",
      "[Epoch 55/100] [Batch 255/347] [D loss: 0.500705] [G loss: 0.271174]\n",
      "[Epoch 55/100] [Batch 256/347] [D loss: 0.500588] [G loss: 0.269856]\n",
      "[Epoch 55/100] [Batch 257/347] [D loss: 0.500452] [G loss: 0.267502]\n",
      "[Epoch 55/100] [Batch 258/347] [D loss: 0.500216] [G loss: 0.265470]\n",
      "[Epoch 55/100] [Batch 259/347] [D loss: 0.500067] [G loss: 0.271835]\n",
      "[Epoch 55/100] [Batch 260/347] [D loss: 0.500016] [G loss: 0.272274]\n",
      "[Epoch 55/100] [Batch 261/347] [D loss: 0.500092] [G loss: 0.269233]\n",
      "[Epoch 55/100] [Batch 262/347] [D loss: 0.500078] [G loss: 0.268711]\n",
      "[Epoch 55/100] [Batch 263/347] [D loss: 0.500019] [G loss: 0.270905]\n",
      "[Epoch 55/100] [Batch 264/347] [D loss: 0.499970] [G loss: 0.273054]\n",
      "[Epoch 55/100] [Batch 265/347] [D loss: 0.499949] [G loss: 0.273341]\n",
      "[Epoch 55/100] [Batch 266/347] [D loss: 0.499962] [G loss: 0.273553]\n",
      "[Epoch 55/100] [Batch 267/347] [D loss: 0.499935] [G loss: 0.276203]\n",
      "[Epoch 55/100] [Batch 268/347] [D loss: 0.499936] [G loss: 0.276440]\n",
      "[Epoch 55/100] [Batch 269/347] [D loss: 0.499935] [G loss: 0.276450]\n",
      "[Epoch 55/100] [Batch 270/347] [D loss: 0.500019] [G loss: 0.271163]\n",
      "[Epoch 55/100] [Batch 271/347] [D loss: 0.500006] [G loss: 0.273862]\n",
      "[Epoch 55/100] [Batch 272/347] [D loss: 0.499818] [G loss: 0.286864]\n",
      "[Epoch 55/100] [Batch 273/347] [D loss: 0.499818] [G loss: 0.288106]\n",
      "[Epoch 55/100] [Batch 274/347] [D loss: 0.499777] [G loss: 0.289674]\n",
      "[Epoch 55/100] [Batch 275/347] [D loss: 0.499879] [G loss: 0.282524]\n",
      "[Epoch 55/100] [Batch 276/347] [D loss: 0.500196] [G loss: 0.259344]\n",
      "[Epoch 55/100] [Batch 277/347] [D loss: 0.500281] [G loss: 0.257180]\n",
      "[Epoch 55/100] [Batch 278/347] [D loss: 0.500355] [G loss: 0.257597]\n",
      "[Epoch 55/100] [Batch 279/347] [D loss: 0.500346] [G loss: 0.259430]\n",
      "[Epoch 55/100] [Batch 280/347] [D loss: 0.500304] [G loss: 0.260079]\n",
      "[Epoch 55/100] [Batch 281/347] [D loss: 0.500264] [G loss: 0.259517]\n",
      "[Epoch 55/100] [Batch 282/347] [D loss: 0.500282] [G loss: 0.259314]\n",
      "[Epoch 55/100] [Batch 283/347] [D loss: 0.500255] [G loss: 0.256840]\n",
      "[Epoch 55/100] [Batch 284/347] [D loss: 0.500250] [G loss: 0.254765]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 55/100] [Batch 285/347] [D loss: 0.500226] [G loss: 0.253614]\n",
      "[Epoch 55/100] [Batch 286/347] [D loss: 0.499908] [G loss: 0.267470]\n",
      "[Epoch 55/100] [Batch 287/347] [D loss: 0.499840] [G loss: 0.269675]\n",
      "[Epoch 55/100] [Batch 288/347] [D loss: 0.499788] [G loss: 0.271498]\n",
      "[Epoch 55/100] [Batch 289/347] [D loss: 0.499682] [G loss: 0.275184]\n",
      "[Epoch 55/100] [Batch 290/347] [D loss: 0.500033] [G loss: 0.258330]\n",
      "[Epoch 55/100] [Batch 291/347] [D loss: 0.500282] [G loss: 0.255758]\n",
      "[Epoch 55/100] [Batch 292/347] [D loss: 0.500443] [G loss: 0.262355]\n",
      "[Epoch 55/100] [Batch 293/347] [D loss: 0.500633] [G loss: 0.269064]\n",
      "[Epoch 55/100] [Batch 294/347] [D loss: 0.500776] [G loss: 0.272752]\n",
      "[Epoch 55/100] [Batch 295/347] [D loss: 0.500766] [G loss: 0.274383]\n",
      "[Epoch 55/100] [Batch 296/347] [D loss: 0.500735] [G loss: 0.275545]\n",
      "[Epoch 55/100] [Batch 297/347] [D loss: 0.500827] [G loss: 0.282632]\n",
      "[Epoch 55/100] [Batch 298/347] [D loss: 0.500756] [G loss: 0.278603]\n",
      "[Epoch 55/100] [Batch 299/347] [D loss: 0.500755] [G loss: 0.276088]\n",
      "[Epoch 55/100] [Batch 300/347] [D loss: 0.500792] [G loss: 0.275736]\n",
      "[Epoch 55/100] [Batch 301/347] [D loss: 0.500500] [G loss: 0.265805]\n",
      "[Epoch 55/100] [Batch 302/347] [D loss: 0.500329] [G loss: 0.257927]\n",
      "[Epoch 55/100] [Batch 303/347] [D loss: 0.500030] [G loss: 0.260083]\n",
      "[Epoch 55/100] [Batch 304/347] [D loss: 0.499764] [G loss: 0.270677]\n",
      "[Epoch 55/100] [Batch 305/347] [D loss: 0.499674] [G loss: 0.272140]\n",
      "[Epoch 55/100] [Batch 306/347] [D loss: 0.499702] [G loss: 0.272108]\n",
      "[Epoch 55/100] [Batch 307/347] [D loss: 0.499884] [G loss: 0.265311]\n",
      "[Epoch 55/100] [Batch 308/347] [D loss: 0.500088] [G loss: 0.258266]\n",
      "[Epoch 55/100] [Batch 309/347] [D loss: 0.500323] [G loss: 0.266042]\n",
      "[Epoch 55/100] [Batch 310/347] [D loss: 0.500556] [G loss: 0.280889]\n",
      "[Epoch 55/100] [Batch 311/347] [D loss: 0.500561] [G loss: 0.281046]\n",
      "[Epoch 55/100] [Batch 312/347] [D loss: 0.500576] [G loss: 0.278535]\n",
      "[Epoch 55/100] [Batch 313/347] [D loss: 0.500517] [G loss: 0.271860]\n",
      "[Epoch 55/100] [Batch 314/347] [D loss: 0.500283] [G loss: 0.259652]\n",
      "[Epoch 55/100] [Batch 315/347] [D loss: 0.500098] [G loss: 0.258661]\n",
      "[Epoch 55/100] [Batch 316/347] [D loss: 0.500157] [G loss: 0.257864]\n",
      "[Epoch 55/100] [Batch 317/347] [D loss: 0.500265] [G loss: 0.259672]\n",
      "[Epoch 55/100] [Batch 318/347] [D loss: 0.500588] [G loss: 0.274781]\n",
      "[Epoch 55/100] [Batch 319/347] [D loss: 0.500851] [G loss: 0.288637]\n",
      "[Epoch 55/100] [Batch 320/347] [D loss: 0.500855] [G loss: 0.289048]\n",
      "[Epoch 55/100] [Batch 321/347] [D loss: 0.500792] [G loss: 0.284297]\n",
      "[Epoch 55/100] [Batch 322/347] [D loss: 0.500706] [G loss: 0.279084]\n",
      "[Epoch 55/100] [Batch 323/347] [D loss: 0.500604] [G loss: 0.272575]\n",
      "[Epoch 55/100] [Batch 324/347] [D loss: 0.500541] [G loss: 0.268395]\n",
      "[Epoch 55/100] [Batch 325/347] [D loss: 0.500436] [G loss: 0.262850]\n",
      "[Epoch 55/100] [Batch 326/347] [D loss: 0.500295] [G loss: 0.256337]\n",
      "[Epoch 55/100] [Batch 327/347] [D loss: 0.500035] [G loss: 0.261730]\n",
      "[Epoch 55/100] [Batch 328/347] [D loss: 0.499876] [G loss: 0.269431]\n",
      "[Epoch 55/100] [Batch 329/347] [D loss: 0.499887] [G loss: 0.267852]\n",
      "[Epoch 55/100] [Batch 330/347] [D loss: 0.499980] [G loss: 0.262686]\n",
      "[Epoch 55/100] [Batch 331/347] [D loss: 0.500246] [G loss: 0.255733]\n",
      "[Epoch 55/100] [Batch 332/347] [D loss: 0.500588] [G loss: 0.276360]\n",
      "[Epoch 55/100] [Batch 333/347] [D loss: 0.500604] [G loss: 0.275510]\n",
      "[Epoch 55/100] [Batch 334/347] [D loss: 0.500533] [G loss: 0.269739]\n",
      "[Epoch 55/100] [Batch 335/347] [D loss: 0.500525] [G loss: 0.268695]\n",
      "[Epoch 55/100] [Batch 336/347] [D loss: 0.500501] [G loss: 0.268558]\n",
      "[Epoch 55/100] [Batch 337/347] [D loss: 0.500561] [G loss: 0.273332]\n",
      "[Epoch 55/100] [Batch 338/347] [D loss: 0.500680] [G loss: 0.281710]\n",
      "[Epoch 55/100] [Batch 339/347] [D loss: 0.500715] [G loss: 0.282469]\n",
      "[Epoch 55/100] [Batch 340/347] [D loss: 0.500653] [G loss: 0.279298]\n",
      "[Epoch 55/100] [Batch 341/347] [D loss: 0.500632] [G loss: 0.279828]\n",
      "[Epoch 55/100] [Batch 342/347] [D loss: 0.500435] [G loss: 0.267965]\n",
      "[Epoch 55/100] [Batch 343/347] [D loss: 0.500151] [G loss: 0.257656]\n",
      "[Epoch 55/100] [Batch 344/347] [D loss: 0.499900] [G loss: 0.265803]\n",
      "[Epoch 55/100] [Batch 345/347] [D loss: 0.499653] [G loss: 0.280605]\n",
      "[Epoch 55/100] [Batch 346/347] [D loss: 0.499657] [G loss: 0.280612]\n",
      "[Epoch 55/100] [Batch 347/347] [D loss: 0.499763] [G loss: 0.275021]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 56/100] [Batch 1/347] [D loss: 0.500253] [G loss: 0.264278]\n",
      "[Epoch 56/100] [Batch 2/347] [D loss: 0.500225] [G loss: 0.267244]\n",
      "[Epoch 56/100] [Batch 3/347] [D loss: 0.500292] [G loss: 0.269507]\n",
      "[Epoch 56/100] [Batch 4/347] [D loss: 0.500284] [G loss: 0.270080]\n",
      "[Epoch 56/100] [Batch 5/347] [D loss: 0.500231] [G loss: 0.269229]\n",
      "[Epoch 56/100] [Batch 6/347] [D loss: 0.500208] [G loss: 0.267772]\n",
      "[Epoch 56/100] [Batch 7/347] [D loss: 0.500079] [G loss: 0.268133]\n",
      "[Epoch 56/100] [Batch 8/347] [D loss: 0.500065] [G loss: 0.267730]\n",
      "[Epoch 56/100] [Batch 9/347] [D loss: 0.500086] [G loss: 0.267809]\n",
      "[Epoch 56/100] [Batch 10/347] [D loss: 0.500085] [G loss: 0.269444]\n",
      "[Epoch 56/100] [Batch 11/347] [D loss: 0.500249] [G loss: 0.267875]\n",
      "[Epoch 56/100] [Batch 12/347] [D loss: 0.500301] [G loss: 0.269710]\n",
      "[Epoch 56/100] [Batch 13/347] [D loss: 0.500310] [G loss: 0.268865]\n",
      "[Epoch 56/100] [Batch 14/347] [D loss: 0.500349] [G loss: 0.268263]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 56/100] [Batch 15/347] [D loss: 0.500213] [G loss: 0.260027]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 56/100] [Batch 16/347] [D loss: 0.500148] [G loss: 0.258105]\n",
      "[Epoch 56/100] [Batch 17/347] [D loss: 0.500211] [G loss: 0.255763]\n",
      "[Epoch 56/100] [Batch 18/347] [D loss: 0.500218] [G loss: 0.256767]\n",
      "[Epoch 56/100] [Batch 19/347] [D loss: 0.500290] [G loss: 0.261385]\n",
      "[Epoch 56/100] [Batch 20/347] [D loss: 0.500340] [G loss: 0.265743]\n",
      "[Epoch 56/100] [Batch 21/347] [D loss: 0.500263] [G loss: 0.260716]\n",
      "[Epoch 56/100] [Batch 22/347] [D loss: 0.500241] [G loss: 0.258454]\n",
      "[Epoch 56/100] [Batch 23/347] [D loss: 0.500183] [G loss: 0.258584]\n",
      "[Epoch 56/100] [Batch 24/347] [D loss: 0.500062] [G loss: 0.258151]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 56/100] [Batch 25/347] [D loss: 0.500125] [G loss: 0.257482]\n",
      "[Epoch 56/100] [Batch 26/347] [D loss: 0.500129] [G loss: 0.258323]\n",
      "[Epoch 56/100] [Batch 27/347] [D loss: 0.500285] [G loss: 0.259464]\n",
      "[Epoch 56/100] [Batch 28/347] [D loss: 0.500520] [G loss: 0.266566]\n",
      "[Epoch 56/100] [Batch 29/347] [D loss: 0.500665] [G loss: 0.272077]\n",
      "[Epoch 56/100] [Batch 30/347] [D loss: 0.500703] [G loss: 0.273699]\n",
      "[Epoch 56/100] [Batch 31/347] [D loss: 0.500690] [G loss: 0.273723]\n",
      "[Epoch 56/100] [Batch 32/347] [D loss: 0.500642] [G loss: 0.270649]\n",
      "[Epoch 56/100] [Batch 33/347] [D loss: 0.500571] [G loss: 0.268673]\n",
      "[Epoch 56/100] [Batch 34/347] [D loss: 0.500465] [G loss: 0.263912]\n",
      "[Epoch 56/100] [Batch 35/347] [D loss: 0.500219] [G loss: 0.256225]\n",
      "[Epoch 56/100] [Batch 36/347] [D loss: 0.499967] [G loss: 0.265573]\n",
      "[Epoch 56/100] [Batch 37/347] [D loss: 0.499807] [G loss: 0.270498]\n",
      "[Epoch 56/100] [Batch 38/347] [D loss: 0.499636] [G loss: 0.274989]\n",
      "[Epoch 56/100] [Batch 39/347] [D loss: 0.499671] [G loss: 0.273357]\n",
      "[Epoch 56/100] [Batch 40/347] [D loss: 0.499784] [G loss: 0.272096]\n",
      "[Epoch 56/100] [Batch 41/347] [D loss: 0.499945] [G loss: 0.262758]\n",
      "[Epoch 56/100] [Batch 42/347] [D loss: 0.500221] [G loss: 0.252514]\n",
      "[Epoch 56/100] [Batch 43/347] [D loss: 0.500570] [G loss: 0.267965]\n",
      "[Epoch 56/100] [Batch 44/347] [D loss: 0.500699] [G loss: 0.273922]\n",
      "[Epoch 56/100] [Batch 45/347] [D loss: 0.500564] [G loss: 0.265979]\n",
      "[Epoch 56/100] [Batch 46/347] [D loss: 0.500194] [G loss: 0.259499]\n",
      "[Epoch 56/100] [Batch 47/347] [D loss: 0.499865] [G loss: 0.273820]\n",
      "[Epoch 56/100] [Batch 48/347] [D loss: 0.499480] [G loss: 0.296030]\n",
      "[Epoch 56/100] [Batch 49/347] [D loss: 0.499594] [G loss: 0.292161]\n",
      "[Epoch 56/100] [Batch 50/347] [D loss: 0.499865] [G loss: 0.278931]\n",
      "[Epoch 56/100] [Batch 51/347] [D loss: 0.499915] [G loss: 0.277612]\n",
      "[Epoch 56/100] [Batch 52/347] [D loss: 0.499744] [G loss: 0.284629]\n",
      "[Epoch 56/100] [Batch 53/347] [D loss: 0.499342] [G loss: 0.300861]\n",
      "[Epoch 56/100] [Batch 54/347] [D loss: 0.499050] [G loss: 0.311593]\n",
      "[Epoch 56/100] [Batch 55/347] [D loss: 0.499130] [G loss: 0.308437]\n",
      "[Epoch 56/100] [Batch 56/347] [D loss: 0.499507] [G loss: 0.291059]\n",
      "[Epoch 56/100] [Batch 57/347] [D loss: 0.499858] [G loss: 0.276265]\n",
      "[Epoch 56/100] [Batch 58/347] [D loss: 0.500046] [G loss: 0.270070]\n",
      "[Epoch 56/100] [Batch 59/347] [D loss: 0.499823] [G loss: 0.284017]\n",
      "[Epoch 56/100] [Batch 60/347] [D loss: 0.499349] [G loss: 0.306365]\n",
      "[Epoch 56/100] [Batch 61/347] [D loss: 0.499136] [G loss: 0.311630]\n",
      "[Epoch 56/100] [Batch 62/347] [D loss: 0.499302] [G loss: 0.303151]\n",
      "[Epoch 56/100] [Batch 63/347] [D loss: 0.499598] [G loss: 0.288734]\n",
      "[Epoch 56/100] [Batch 64/347] [D loss: 0.499924] [G loss: 0.271478]\n",
      "[Epoch 56/100] [Batch 65/347] [D loss: 0.500277] [G loss: 0.264597]\n",
      "[Epoch 56/100] [Batch 66/347] [D loss: 0.500013] [G loss: 0.271497]\n",
      "[Epoch 56/100] [Batch 67/347] [D loss: 0.499515] [G loss: 0.292562]\n",
      "[Epoch 56/100] [Batch 68/347] [D loss: 0.499316] [G loss: 0.298917]\n",
      "[Epoch 56/100] [Batch 69/347] [D loss: 0.499062] [G loss: 0.310337]\n",
      "[Epoch 56/100] [Batch 70/347] [D loss: 0.499002] [G loss: 0.309469]\n",
      "[Epoch 56/100] [Batch 71/347] [D loss: 0.499323] [G loss: 0.297307]\n",
      "[Epoch 56/100] [Batch 72/347] [D loss: 0.499473] [G loss: 0.295696]\n",
      "[Epoch 56/100] [Batch 73/347] [D loss: 0.499413] [G loss: 0.296919]\n",
      "[Epoch 56/100] [Batch 74/347] [D loss: 0.499565] [G loss: 0.289502]\n",
      "[Epoch 56/100] [Batch 75/347] [D loss: 0.499665] [G loss: 0.286036]\n",
      "[Epoch 56/100] [Batch 76/347] [D loss: 0.499845] [G loss: 0.276786]\n",
      "[Epoch 56/100] [Batch 77/347] [D loss: 0.500306] [G loss: 0.262996]\n",
      "[Epoch 56/100] [Batch 78/347] [D loss: 0.500663] [G loss: 0.268097]\n",
      "[Epoch 56/100] [Batch 79/347] [D loss: 0.500849] [G loss: 0.276931]\n",
      "[Epoch 56/100] [Batch 80/347] [D loss: 0.500752] [G loss: 0.272029]\n",
      "[Epoch 56/100] [Batch 81/347] [D loss: 0.500772] [G loss: 0.274061]\n",
      "[Epoch 56/100] [Batch 82/347] [D loss: 0.500800] [G loss: 0.276565]\n",
      "[Epoch 56/100] [Batch 83/347] [D loss: 0.500732] [G loss: 0.275578]\n",
      "[Epoch 56/100] [Batch 84/347] [D loss: 0.500710] [G loss: 0.279131]\n",
      "[Epoch 56/100] [Batch 85/347] [D loss: 0.500676] [G loss: 0.278969]\n",
      "[Epoch 56/100] [Batch 86/347] [D loss: 0.500651] [G loss: 0.278192]\n",
      "[Epoch 56/100] [Batch 87/347] [D loss: 0.500644] [G loss: 0.278651]\n",
      "[Epoch 56/100] [Batch 88/347] [D loss: 0.500634] [G loss: 0.278784]\n",
      "[Epoch 56/100] [Batch 89/347] [D loss: 0.500648] [G loss: 0.280276]\n",
      "[Epoch 56/100] [Batch 90/347] [D loss: 0.500624] [G loss: 0.279327]\n",
      "[Epoch 56/100] [Batch 91/347] [D loss: 0.500585] [G loss: 0.277537]\n",
      "[Epoch 56/100] [Batch 92/347] [D loss: 0.500576] [G loss: 0.277281]\n",
      "[Epoch 56/100] [Batch 93/347] [D loss: 0.500565] [G loss: 0.276867]\n",
      "[Epoch 56/100] [Batch 94/347] [D loss: 0.500495] [G loss: 0.272571]\n",
      "[Epoch 56/100] [Batch 95/347] [D loss: 0.500467] [G loss: 0.271124]\n",
      "[Epoch 56/100] [Batch 96/347] [D loss: 0.500473] [G loss: 0.272074]\n",
      "[Epoch 56/100] [Batch 97/347] [D loss: 0.500454] [G loss: 0.271154]\n",
      "[Epoch 56/100] [Batch 98/347] [D loss: 0.500461] [G loss: 0.272276]\n",
      "[Epoch 56/100] [Batch 99/347] [D loss: 0.500461] [G loss: 0.272298]\n",
      "[Epoch 56/100] [Batch 100/347] [D loss: 0.500451] [G loss: 0.271720]\n",
      "[Epoch 56/100] [Batch 101/347] [D loss: 0.500414] [G loss: 0.269381]\n",
      "[Epoch 56/100] [Batch 102/347] [D loss: 0.500349] [G loss: 0.266257]\n",
      "[Epoch 56/100] [Batch 103/347] [D loss: 0.500353] [G loss: 0.266890]\n",
      "[Epoch 56/100] [Batch 104/347] [D loss: 0.500266] [G loss: 0.261506]\n",
      "[Epoch 56/100] [Batch 105/347] [D loss: 0.500199] [G loss: 0.254944]\n",
      "[Epoch 56/100] [Batch 106/347] [D loss: 0.500137] [G loss: 0.257355]\n",
      "[Epoch 56/100] [Batch 107/347] [D loss: 0.500179] [G loss: 0.260988]\n",
      "[Epoch 56/100] [Batch 108/347] [D loss: 0.500218] [G loss: 0.263283]\n",
      "[Epoch 56/100] [Batch 109/347] [D loss: 0.500157] [G loss: 0.267623]\n",
      "[Epoch 56/100] [Batch 110/347] [D loss: 0.500344] [G loss: 0.264192]\n",
      "[Epoch 56/100] [Batch 111/347] [D loss: 0.500451] [G loss: 0.264577]\n",
      "[Epoch 56/100] [Batch 112/347] [D loss: 0.500562] [G loss: 0.267526]\n",
      "[Epoch 56/100] [Batch 113/347] [D loss: 0.500806] [G loss: 0.284543]\n",
      "[Epoch 56/100] [Batch 114/347] [D loss: 0.500883] [G loss: 0.291673]\n",
      "[Epoch 56/100] [Batch 115/347] [D loss: 0.500658] [G loss: 0.275189]\n",
      "[Epoch 56/100] [Batch 116/347] [D loss: 0.500355] [G loss: 0.258535]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 56/100] [Batch 117/347] [D loss: 0.500112] [G loss: 0.256231]\n",
      "[Epoch 56/100] [Batch 118/347] [D loss: 0.499867] [G loss: 0.268643]\n",
      "[Epoch 56/100] [Batch 119/347] [D loss: 0.499816] [G loss: 0.268555]\n",
      "[Epoch 56/100] [Batch 120/347] [D loss: 0.499943] [G loss: 0.261352]\n",
      "[Epoch 56/100] [Batch 121/347] [D loss: 0.499958] [G loss: 0.260068]\n",
      "[Epoch 56/100] [Batch 122/347] [D loss: 0.500022] [G loss: 0.259161]\n",
      "[Epoch 56/100] [Batch 123/347] [D loss: 0.500158] [G loss: 0.257096]\n",
      "[Epoch 56/100] [Batch 124/347] [D loss: 0.500235] [G loss: 0.258349]\n",
      "[Epoch 56/100] [Batch 125/347] [D loss: 0.500347] [G loss: 0.264586]\n",
      "[Epoch 56/100] [Batch 126/347] [D loss: 0.500431] [G loss: 0.268551]\n",
      "[Epoch 56/100] [Batch 127/347] [D loss: 0.500454] [G loss: 0.267153]\n",
      "[Epoch 56/100] [Batch 128/347] [D loss: 0.500333] [G loss: 0.258882]\n",
      "[Epoch 56/100] [Batch 129/347] [D loss: 0.500158] [G loss: 0.258502]\n",
      "[Epoch 56/100] [Batch 130/347] [D loss: 0.499901] [G loss: 0.272077]\n",
      "[Epoch 56/100] [Batch 131/347] [D loss: 0.499672] [G loss: 0.283457]\n",
      "[Epoch 56/100] [Batch 132/347] [D loss: 0.499334] [G loss: 0.303036]\n",
      "[Epoch 56/100] [Batch 133/347] [D loss: 0.499221] [G loss: 0.308773]\n",
      "[Epoch 56/100] [Batch 134/347] [D loss: 0.499504] [G loss: 0.294464]\n",
      "[Epoch 56/100] [Batch 135/347] [D loss: 0.499581] [G loss: 0.291528]\n",
      "[Epoch 56/100] [Batch 136/347] [D loss: 0.499659] [G loss: 0.283873]\n",
      "[Epoch 56/100] [Batch 137/347] [D loss: 0.499597] [G loss: 0.285476]\n",
      "[Epoch 56/100] [Batch 138/347] [D loss: 0.499216] [G loss: 0.303898]\n",
      "[Epoch 56/100] [Batch 139/347] [D loss: 0.498880] [G loss: 0.317476]\n",
      "[Epoch 56/100] [Batch 140/347] [D loss: 0.498686] [G loss: 0.328502]\n",
      "[Epoch 56/100] [Batch 141/347] [D loss: 0.498349] [G loss: 0.343264]\n",
      "[Epoch 56/100] [Batch 142/347] [D loss: 0.498236] [G loss: 0.346347]\n",
      "[Epoch 56/100] [Batch 143/347] [D loss: 0.498087] [G loss: 0.349379]\n",
      "[Epoch 56/100] [Batch 144/347] [D loss: 0.498126] [G loss: 0.342064]\n",
      "[Epoch 56/100] [Batch 145/347] [D loss: 0.498511] [G loss: 0.321616]\n",
      "[Epoch 56/100] [Batch 146/347] [D loss: 0.498707] [G loss: 0.309257]\n",
      "[Epoch 56/100] [Batch 147/347] [D loss: 0.498890] [G loss: 0.300357]\n",
      "[Epoch 56/100] [Batch 148/347] [D loss: 0.499102] [G loss: 0.293365]\n",
      "[Epoch 56/100] [Batch 149/347] [D loss: 0.499128] [G loss: 0.295919]\n",
      "[Epoch 56/100] [Batch 150/347] [D loss: 0.499043] [G loss: 0.303921]\n",
      "[Epoch 56/100] [Batch 151/347] [D loss: 0.498950] [G loss: 0.309613]\n",
      "[Epoch 56/100] [Batch 152/347] [D loss: 0.498762] [G loss: 0.316986]\n",
      "[Epoch 56/100] [Batch 153/347] [D loss: 0.498640] [G loss: 0.319886]\n",
      "[Epoch 56/100] [Batch 154/347] [D loss: 0.498717] [G loss: 0.314788]\n",
      "[Epoch 56/100] [Batch 155/347] [D loss: 0.498792] [G loss: 0.313852]\n",
      "[Epoch 56/100] [Batch 156/347] [D loss: 0.498710] [G loss: 0.318021]\n",
      "[Epoch 56/100] [Batch 157/347] [D loss: 0.498736] [G loss: 0.317726]\n",
      "[Epoch 56/100] [Batch 158/347] [D loss: 0.498737] [G loss: 0.319836]\n",
      "[Epoch 56/100] [Batch 159/347] [D loss: 0.498784] [G loss: 0.318154]\n",
      "[Epoch 56/100] [Batch 160/347] [D loss: 0.499033] [G loss: 0.309906]\n",
      "[Epoch 56/100] [Batch 161/347] [D loss: 0.498937] [G loss: 0.317073]\n",
      "[Epoch 56/100] [Batch 162/347] [D loss: 0.498679] [G loss: 0.327985]\n",
      "[Epoch 56/100] [Batch 163/347] [D loss: 0.498514] [G loss: 0.330592]\n",
      "[Epoch 56/100] [Batch 164/347] [D loss: 0.498703] [G loss: 0.320411]\n",
      "[Epoch 56/100] [Batch 165/347] [D loss: 0.499069] [G loss: 0.304855]\n",
      "[Epoch 56/100] [Batch 166/347] [D loss: 0.499624] [G loss: 0.279151]\n",
      "[Epoch 56/100] [Batch 167/347] [D loss: 0.500118] [G loss: 0.256768]\n",
      "[Epoch 56/100] [Batch 168/347] [D loss: 0.500334] [G loss: 0.260824]\n",
      "[Epoch 56/100] [Batch 169/347] [D loss: 0.500491] [G loss: 0.262763]\n",
      "[Epoch 56/100] [Batch 170/347] [D loss: 0.500588] [G loss: 0.269916]\n",
      "[Epoch 56/100] [Batch 171/347] [D loss: 0.500564] [G loss: 0.270501]\n",
      "[Epoch 56/100] [Batch 172/347] [D loss: 0.500592] [G loss: 0.272387]\n",
      "[Epoch 56/100] [Batch 173/347] [D loss: 0.500550] [G loss: 0.272115]\n",
      "[Epoch 56/100] [Batch 174/347] [D loss: 0.500639] [G loss: 0.276800]\n",
      "[Epoch 56/100] [Batch 175/347] [D loss: 0.500715] [G loss: 0.282477]\n",
      "[Epoch 56/100] [Batch 176/347] [D loss: 0.500780] [G loss: 0.286276]\n",
      "[Epoch 56/100] [Batch 177/347] [D loss: 0.500733] [G loss: 0.283934]\n",
      "[Epoch 56/100] [Batch 178/347] [D loss: 0.500623] [G loss: 0.278578]\n",
      "[Epoch 56/100] [Batch 179/347] [D loss: 0.500551] [G loss: 0.275573]\n",
      "[Epoch 56/100] [Batch 180/347] [D loss: 0.500455] [G loss: 0.272043]\n",
      "[Epoch 56/100] [Batch 181/347] [D loss: 0.500509] [G loss: 0.274981]\n",
      "[Epoch 56/100] [Batch 182/347] [D loss: 0.500500] [G loss: 0.275904]\n",
      "[Epoch 56/100] [Batch 183/347] [D loss: 0.500530] [G loss: 0.277491]\n",
      "[Epoch 56/100] [Batch 184/347] [D loss: 0.500595] [G loss: 0.279901]\n",
      "[Epoch 56/100] [Batch 185/347] [D loss: 0.500543] [G loss: 0.276915]\n",
      "[Epoch 56/100] [Batch 186/347] [D loss: 0.500521] [G loss: 0.275748]\n",
      "[Epoch 56/100] [Batch 187/347] [D loss: 0.500471] [G loss: 0.272835]\n",
      "[Epoch 56/100] [Batch 188/347] [D loss: 0.500264] [G loss: 0.264914]\n",
      "[Epoch 56/100] [Batch 189/347] [D loss: 0.500114] [G loss: 0.260694]\n",
      "[Epoch 56/100] [Batch 190/347] [D loss: 0.500073] [G loss: 0.260407]\n",
      "[Epoch 56/100] [Batch 191/347] [D loss: 0.500013] [G loss: 0.262508]\n",
      "[Epoch 56/100] [Batch 192/347] [D loss: 0.500018] [G loss: 0.261837]\n",
      "[Epoch 56/100] [Batch 193/347] [D loss: 0.500031] [G loss: 0.262097]\n",
      "[Epoch 56/100] [Batch 194/347] [D loss: 0.499935] [G loss: 0.265098]\n",
      "[Epoch 56/100] [Batch 195/347] [D loss: 0.499880] [G loss: 0.265595]\n",
      "[Epoch 56/100] [Batch 196/347] [D loss: 0.499892] [G loss: 0.261547]\n",
      "[Epoch 56/100] [Batch 197/347] [D loss: 0.499907] [G loss: 0.258817]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 56/100] [Batch 198/347] [D loss: 0.500012] [G loss: 0.254842]\n",
      "[Epoch 56/100] [Batch 199/347] [D loss: 0.500006] [G loss: 0.255971]\n",
      "[Epoch 56/100] [Batch 200/347] [D loss: 0.499949] [G loss: 0.261429]\n",
      "[Epoch 56/100] [Batch 201/347] [D loss: 0.499888] [G loss: 0.265385]\n",
      "[Epoch 56/100] [Batch 202/347] [D loss: 0.499819] [G loss: 0.270225]\n",
      "[Epoch 56/100] [Batch 203/347] [D loss: 0.499808] [G loss: 0.270271]\n",
      "[Epoch 56/100] [Batch 204/347] [D loss: 0.499978] [G loss: 0.261110]\n",
      "[Epoch 56/100] [Batch 205/347] [D loss: 0.500186] [G loss: 0.255678]\n",
      "[Epoch 56/100] [Batch 206/347] [D loss: 0.500268] [G loss: 0.259109]\n",
      "[Epoch 56/100] [Batch 207/347] [D loss: 0.500371] [G loss: 0.261496]\n",
      "[Epoch 56/100] [Batch 208/347] [D loss: 0.500499] [G loss: 0.265367]\n",
      "[Epoch 56/100] [Batch 209/347] [D loss: 0.500373] [G loss: 0.261294]\n",
      "[Epoch 56/100] [Batch 210/347] [D loss: 0.500451] [G loss: 0.262785]\n",
      "[Epoch 56/100] [Batch 211/347] [D loss: 0.500382] [G loss: 0.266068]\n",
      "[Epoch 56/100] [Batch 212/347] [D loss: 0.500121] [G loss: 0.268226]\n",
      "[Epoch 56/100] [Batch 213/347] [D loss: 0.500044] [G loss: 0.270677]\n",
      "[Epoch 56/100] [Batch 214/347] [D loss: 0.500043] [G loss: 0.270492]\n",
      "[Epoch 56/100] [Batch 215/347] [D loss: 0.500104] [G loss: 0.271788]\n",
      "[Epoch 56/100] [Batch 216/347] [D loss: 0.500440] [G loss: 0.267673]\n",
      "[Epoch 56/100] [Batch 217/347] [D loss: 0.500745] [G loss: 0.272961]\n",
      "[Epoch 56/100] [Batch 218/347] [D loss: 0.501025] [G loss: 0.287746]\n",
      "[Epoch 56/100] [Batch 219/347] [D loss: 0.501186] [G loss: 0.294570]\n",
      "[Epoch 56/100] [Batch 220/347] [D loss: 0.501308] [G loss: 0.299238]\n",
      "[Epoch 56/100] [Batch 221/347] [D loss: 0.501335] [G loss: 0.300171]\n",
      "[Epoch 56/100] [Batch 222/347] [D loss: 0.501210] [G loss: 0.292694]\n",
      "[Epoch 56/100] [Batch 223/347] [D loss: 0.500887] [G loss: 0.283401]\n",
      "[Epoch 56/100] [Batch 224/347] [D loss: 0.500409] [G loss: 0.273628]\n",
      "[Epoch 56/100] [Batch 225/347] [D loss: 0.499905] [G loss: 0.267581]\n",
      "[Epoch 56/100] [Batch 226/347] [D loss: 0.499509] [G loss: 0.277000]\n",
      "[Epoch 56/100] [Batch 227/347] [D loss: 0.499393] [G loss: 0.277991]\n",
      "[Epoch 56/100] [Batch 228/347] [D loss: 0.499408] [G loss: 0.281279]\n",
      "[Epoch 56/100] [Batch 229/347] [D loss: 0.499494] [G loss: 0.278328]\n",
      "[Epoch 56/100] [Batch 230/347] [D loss: 0.499587] [G loss: 0.273999]\n",
      "[Epoch 56/100] [Batch 231/347] [D loss: 0.499557] [G loss: 0.269888]\n",
      "[Epoch 56/100] [Batch 232/347] [D loss: 0.499614] [G loss: 0.270251]\n",
      "[Epoch 56/100] [Batch 233/347] [D loss: 0.499817] [G loss: 0.265548]\n",
      "[Epoch 56/100] [Batch 234/347] [D loss: 0.499968] [G loss: 0.261115]\n",
      "[Epoch 56/100] [Batch 235/347] [D loss: 0.500229] [G loss: 0.259560]\n",
      "[Epoch 56/100] [Batch 236/347] [D loss: 0.500413] [G loss: 0.262059]\n",
      "[Epoch 56/100] [Batch 237/347] [D loss: 0.500497] [G loss: 0.268080]\n",
      "[Epoch 56/100] [Batch 238/347] [D loss: 0.500465] [G loss: 0.267363]\n",
      "[Epoch 56/100] [Batch 239/347] [D loss: 0.500372] [G loss: 0.263346]\n",
      "[Epoch 56/100] [Batch 240/347] [D loss: 0.500323] [G loss: 0.261445]\n",
      "[Epoch 56/100] [Batch 241/347] [D loss: 0.500334] [G loss: 0.262342]\n",
      "[Epoch 56/100] [Batch 242/347] [D loss: 0.500412] [G loss: 0.265121]\n",
      "[Epoch 56/100] [Batch 243/347] [D loss: 0.500523] [G loss: 0.267238]\n",
      "[Epoch 56/100] [Batch 244/347] [D loss: 0.500354] [G loss: 0.261151]\n",
      "[Epoch 56/100] [Batch 245/347] [D loss: 0.500099] [G loss: 0.255847]\n",
      "[Epoch 56/100] [Batch 246/347] [D loss: 0.499770] [G loss: 0.267081]\n",
      "[Epoch 56/100] [Batch 247/347] [D loss: 0.499420] [G loss: 0.276160]\n",
      "[Epoch 56/100] [Batch 248/347] [D loss: 0.499548] [G loss: 0.273615]\n",
      "[Epoch 56/100] [Batch 249/347] [D loss: 0.499769] [G loss: 0.267739]\n",
      "[Epoch 56/100] [Batch 250/347] [D loss: 0.500064] [G loss: 0.259489]\n",
      "[Epoch 56/100] [Batch 251/347] [D loss: 0.500394] [G loss: 0.266771]\n",
      "[Epoch 56/100] [Batch 252/347] [D loss: 0.500521] [G loss: 0.267749]\n",
      "[Epoch 56/100] [Batch 253/347] [D loss: 0.500425] [G loss: 0.267755]\n",
      "[Epoch 56/100] [Batch 254/347] [D loss: 0.500529] [G loss: 0.269844]\n",
      "[Epoch 56/100] [Batch 255/347] [D loss: 0.500556] [G loss: 0.270730]\n",
      "[Epoch 56/100] [Batch 256/347] [D loss: 0.500421] [G loss: 0.269288]\n",
      "[Epoch 56/100] [Batch 257/347] [D loss: 0.500264] [G loss: 0.266838]\n",
      "[Epoch 56/100] [Batch 258/347] [D loss: 0.499993] [G loss: 0.265504]\n",
      "[Epoch 56/100] [Batch 259/347] [D loss: 0.499822] [G loss: 0.271951]\n",
      "[Epoch 56/100] [Batch 260/347] [D loss: 0.499765] [G loss: 0.272420]\n",
      "[Epoch 56/100] [Batch 261/347] [D loss: 0.499848] [G loss: 0.269420]\n",
      "[Epoch 56/100] [Batch 262/347] [D loss: 0.499834] [G loss: 0.268942]\n",
      "[Epoch 56/100] [Batch 263/347] [D loss: 0.499763] [G loss: 0.271174]\n",
      "[Epoch 56/100] [Batch 264/347] [D loss: 0.499710] [G loss: 0.273381]\n",
      "[Epoch 56/100] [Batch 265/347] [D loss: 0.499681] [G loss: 0.273699]\n",
      "[Epoch 56/100] [Batch 266/347] [D loss: 0.499693] [G loss: 0.273931]\n",
      "[Epoch 56/100] [Batch 267/347] [D loss: 0.499659] [G loss: 0.276615]\n",
      "[Epoch 56/100] [Batch 268/347] [D loss: 0.499660] [G loss: 0.276889]\n",
      "[Epoch 56/100] [Batch 269/347] [D loss: 0.499656] [G loss: 0.276922]\n",
      "[Epoch 56/100] [Batch 270/347] [D loss: 0.499751] [G loss: 0.271633]\n",
      "[Epoch 56/100] [Batch 271/347] [D loss: 0.499735] [G loss: 0.274381]\n",
      "[Epoch 56/100] [Batch 272/347] [D loss: 0.499494] [G loss: 0.287413]\n",
      "[Epoch 56/100] [Batch 273/347] [D loss: 0.499495] [G loss: 0.288708]\n",
      "[Epoch 56/100] [Batch 274/347] [D loss: 0.499442] [G loss: 0.290309]\n",
      "[Epoch 56/100] [Batch 275/347] [D loss: 0.499562] [G loss: 0.283188]\n",
      "[Epoch 56/100] [Batch 276/347] [D loss: 0.499950] [G loss: 0.259996]\n",
      "[Epoch 56/100] [Batch 277/347] [D loss: 0.500047] [G loss: 0.255822]\n",
      "[Epoch 56/100] [Batch 278/347] [D loss: 0.500138] [G loss: 0.256027]\n",
      "[Epoch 56/100] [Batch 279/347] [D loss: 0.500130] [G loss: 0.258053]\n",
      "[Epoch 56/100] [Batch 280/347] [D loss: 0.500087] [G loss: 0.258868]\n",
      "[Epoch 56/100] [Batch 281/347] [D loss: 0.500046] [G loss: 0.258464]\n",
      "[Epoch 56/100] [Batch 282/347] [D loss: 0.500074] [G loss: 0.258408]\n",
      "[Epoch 56/100] [Batch 283/347] [D loss: 0.500047] [G loss: 0.256065]\n",
      "[Epoch 56/100] [Batch 284/347] [D loss: 0.500042] [G loss: 0.254131]\n",
      "[Epoch 56/100] [Batch 285/347] [D loss: 0.500018] [G loss: 0.253235]\n",
      "[Epoch 56/100] [Batch 286/347] [D loss: 0.499662] [G loss: 0.266999]\n",
      "[Epoch 56/100] [Batch 287/347] [D loss: 0.499587] [G loss: 0.269121]\n",
      "[Epoch 56/100] [Batch 288/347] [D loss: 0.499522] [G loss: 0.270873]\n",
      "[Epoch 56/100] [Batch 289/347] [D loss: 0.499405] [G loss: 0.274482]\n",
      "[Epoch 56/100] [Batch 290/347] [D loss: 0.499811] [G loss: 0.257564]\n",
      "[Epoch 56/100] [Batch 291/347] [D loss: 0.500096] [G loss: 0.255713]\n",
      "[Epoch 56/100] [Batch 292/347] [D loss: 0.500276] [G loss: 0.262364]\n",
      "[Epoch 56/100] [Batch 293/347] [D loss: 0.500498] [G loss: 0.269155]\n",
      "[Epoch 56/100] [Batch 294/347] [D loss: 0.500666] [G loss: 0.272614]\n",
      "[Epoch 56/100] [Batch 295/347] [D loss: 0.500649] [G loss: 0.274112]\n",
      "[Epoch 56/100] [Batch 296/347] [D loss: 0.500616] [G loss: 0.275333]\n",
      "[Epoch 56/100] [Batch 297/347] [D loss: 0.500720] [G loss: 0.282479]\n",
      "[Epoch 56/100] [Batch 298/347] [D loss: 0.500645] [G loss: 0.278524]\n",
      "[Epoch 56/100] [Batch 299/347] [D loss: 0.500642] [G loss: 0.276064]\n",
      "[Epoch 56/100] [Batch 300/347] [D loss: 0.500681] [G loss: 0.275783]\n",
      "[Epoch 56/100] [Batch 301/347] [D loss: 0.500347] [G loss: 0.265904]\n",
      "[Epoch 56/100] [Batch 302/347] [D loss: 0.500158] [G loss: 0.258042]\n",
      "[Epoch 56/100] [Batch 303/347] [D loss: 0.499819] [G loss: 0.258924]\n",
      "[Epoch 56/100] [Batch 304/347] [D loss: 0.499524] [G loss: 0.269498]\n",
      "[Epoch 56/100] [Batch 305/347] [D loss: 0.499416] [G loss: 0.270810]\n",
      "[Epoch 56/100] [Batch 306/347] [D loss: 0.499442] [G loss: 0.270723]\n",
      "[Epoch 56/100] [Batch 307/347] [D loss: 0.499656] [G loss: 0.263870]\n",
      "[Epoch 56/100] [Batch 308/347] [D loss: 0.499887] [G loss: 0.256983]\n",
      "[Epoch 56/100] [Batch 309/347] [D loss: 0.500159] [G loss: 0.266369]\n",
      "[Epoch 56/100] [Batch 310/347] [D loss: 0.500420] [G loss: 0.281203]\n",
      "[Epoch 56/100] [Batch 311/347] [D loss: 0.500432] [G loss: 0.281382]\n",
      "[Epoch 56/100] [Batch 312/347] [D loss: 0.500451] [G loss: 0.278901]\n",
      "[Epoch 56/100] [Batch 313/347] [D loss: 0.500383] [G loss: 0.272254]\n",
      "[Epoch 56/100] [Batch 314/347] [D loss: 0.500110] [G loss: 0.260064]\n",
      "[Epoch 56/100] [Batch 315/347] [D loss: 0.499901] [G loss: 0.257504]\n",
      "[Epoch 56/100] [Batch 316/347] [D loss: 0.499969] [G loss: 0.256700]\n",
      "[Epoch 56/100] [Batch 317/347] [D loss: 0.500094] [G loss: 0.260139]\n",
      "[Epoch 56/100] [Batch 318/347] [D loss: 0.500461] [G loss: 0.275278]\n",
      "[Epoch 56/100] [Batch 319/347] [D loss: 0.500764] [G loss: 0.289166]\n",
      "[Epoch 56/100] [Batch 320/347] [D loss: 0.500767] [G loss: 0.289613]\n",
      "[Epoch 56/100] [Batch 321/347] [D loss: 0.500696] [G loss: 0.284888]\n",
      "[Epoch 56/100] [Batch 322/347] [D loss: 0.500597] [G loss: 0.279670]\n",
      "[Epoch 56/100] [Batch 323/347] [D loss: 0.500487] [G loss: 0.273157]\n",
      "[Epoch 56/100] [Batch 324/347] [D loss: 0.500410] [G loss: 0.268991]\n",
      "[Epoch 56/100] [Batch 325/347] [D loss: 0.500294] [G loss: 0.263473]\n",
      "[Epoch 56/100] [Batch 326/347] [D loss: 0.500132] [G loss: 0.256968]\n",
      "[Epoch 56/100] [Batch 327/347] [D loss: 0.499837] [G loss: 0.260109]\n",
      "[Epoch 56/100] [Batch 328/347] [D loss: 0.499660] [G loss: 0.267776]\n",
      "[Epoch 56/100] [Batch 329/347] [D loss: 0.499668] [G loss: 0.266155]\n",
      "[Epoch 56/100] [Batch 330/347] [D loss: 0.499774] [G loss: 0.260944]\n",
      "[Epoch 56/100] [Batch 331/347] [D loss: 0.500088] [G loss: 0.256371]\n",
      "[Epoch 56/100] [Batch 332/347] [D loss: 0.500478] [G loss: 0.277013]\n",
      "[Epoch 56/100] [Batch 333/347] [D loss: 0.500491] [G loss: 0.276152]\n",
      "[Epoch 56/100] [Batch 334/347] [D loss: 0.500411] [G loss: 0.270385]\n",
      "[Epoch 56/100] [Batch 335/347] [D loss: 0.500403] [G loss: 0.269334]\n",
      "[Epoch 56/100] [Batch 336/347] [D loss: 0.500376] [G loss: 0.269200]\n",
      "[Epoch 56/100] [Batch 337/347] [D loss: 0.500444] [G loss: 0.274006]\n",
      "[Epoch 56/100] [Batch 338/347] [D loss: 0.500583] [G loss: 0.282435]\n",
      "[Epoch 56/100] [Batch 339/347] [D loss: 0.500625] [G loss: 0.283233]\n",
      "[Epoch 56/100] [Batch 340/347] [D loss: 0.500552] [G loss: 0.280087]\n",
      "[Epoch 56/100] [Batch 341/347] [D loss: 0.500530] [G loss: 0.280650]\n",
      "[Epoch 56/100] [Batch 342/347] [D loss: 0.500305] [G loss: 0.268826]\n",
      "[Epoch 56/100] [Batch 343/347] [D loss: 0.499984] [G loss: 0.256191]\n",
      "[Epoch 56/100] [Batch 344/347] [D loss: 0.499695] [G loss: 0.264006]\n",
      "[Epoch 56/100] [Batch 345/347] [D loss: 0.499407] [G loss: 0.278769]\n",
      "[Epoch 56/100] [Batch 346/347] [D loss: 0.499417] [G loss: 0.278735]\n",
      "[Epoch 56/100] [Batch 347/347] [D loss: 0.499535] [G loss: 0.273094]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 57/100] [Batch 1/347] [D loss: 0.500102] [G loss: 0.265119]\n",
      "[Epoch 57/100] [Batch 2/347] [D loss: 0.500071] [G loss: 0.265866]\n",
      "[Epoch 57/100] [Batch 3/347] [D loss: 0.500145] [G loss: 0.270163]\n",
      "[Epoch 57/100] [Batch 4/347] [D loss: 0.500131] [G loss: 0.270543]\n",
      "[Epoch 57/100] [Batch 5/347] [D loss: 0.500061] [G loss: 0.268221]\n",
      "[Epoch 57/100] [Batch 6/347] [D loss: 0.500033] [G loss: 0.266946]\n",
      "[Epoch 57/100] [Batch 7/347] [D loss: 0.499882] [G loss: 0.267472]\n",
      "[Epoch 57/100] [Batch 8/347] [D loss: 0.499858] [G loss: 0.267212]\n",
      "[Epoch 57/100] [Batch 9/347] [D loss: 0.499878] [G loss: 0.267421]\n",
      "[Epoch 57/100] [Batch 10/347] [D loss: 0.499876] [G loss: 0.269184]\n",
      "[Epoch 57/100] [Batch 11/347] [D loss: 0.500059] [G loss: 0.267744]\n",
      "[Epoch 57/100] [Batch 12/347] [D loss: 0.500124] [G loss: 0.269287]\n",
      "[Epoch 57/100] [Batch 13/347] [D loss: 0.500128] [G loss: 0.268360]\n",
      "[Epoch 57/100] [Batch 14/347] [D loss: 0.500170] [G loss: 0.267696]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 57/100] [Batch 15/347] [D loss: 0.500011] [G loss: 0.260265]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 57/100] [Batch 16/347] [D loss: 0.499935] [G loss: 0.258409]\n",
      "[Epoch 57/100] [Batch 17/347] [D loss: 0.500003] [G loss: 0.256060]\n",
      "[Epoch 57/100] [Batch 18/347] [D loss: 0.500016] [G loss: 0.256947]\n",
      "[Epoch 57/100] [Batch 19/347] [D loss: 0.500102] [G loss: 0.260993]\n",
      "[Epoch 57/100] [Batch 20/347] [D loss: 0.500169] [G loss: 0.265467]\n",
      "[Epoch 57/100] [Batch 21/347] [D loss: 0.500085] [G loss: 0.260530]\n",
      "[Epoch 57/100] [Batch 22/347] [D loss: 0.500064] [G loss: 0.258375]\n",
      "[Epoch 57/100] [Batch 23/347] [D loss: 0.499998] [G loss: 0.258040]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 57/100] [Batch 24/347] [D loss: 0.499861] [G loss: 0.257505]\n",
      "[Epoch 57/100] [Batch 25/347] [D loss: 0.499936] [G loss: 0.256217]\n",
      "[Epoch 57/100] [Batch 26/347] [D loss: 0.499943] [G loss: 0.256972]\n",
      "[Epoch 57/100] [Batch 27/347] [D loss: 0.500123] [G loss: 0.259252]\n",
      "[Epoch 57/100] [Batch 28/347] [D loss: 0.500394] [G loss: 0.266417]\n",
      "[Epoch 57/100] [Batch 29/347] [D loss: 0.500561] [G loss: 0.272473]\n",
      "[Epoch 57/100] [Batch 30/347] [D loss: 0.500610] [G loss: 0.274158]\n",
      "[Epoch 57/100] [Batch 31/347] [D loss: 0.500598] [G loss: 0.274251]\n",
      "[Epoch 57/100] [Batch 32/347] [D loss: 0.500538] [G loss: 0.271218]\n",
      "[Epoch 57/100] [Batch 33/347] [D loss: 0.500461] [G loss: 0.269292]\n",
      "[Epoch 57/100] [Batch 34/347] [D loss: 0.500342] [G loss: 0.264588]\n",
      "[Epoch 57/100] [Batch 35/347] [D loss: 0.500058] [G loss: 0.256531]\n",
      "[Epoch 57/100] [Batch 36/347] [D loss: 0.499776] [G loss: 0.263871]\n",
      "[Epoch 57/100] [Batch 37/347] [D loss: 0.499593] [G loss: 0.268752]\n",
      "[Epoch 57/100] [Batch 38/347] [D loss: 0.499403] [G loss: 0.273203]\n",
      "[Epoch 57/100] [Batch 39/347] [D loss: 0.499441] [G loss: 0.271914]\n",
      "[Epoch 57/100] [Batch 40/347] [D loss: 0.499570] [G loss: 0.270607]\n",
      "[Epoch 57/100] [Batch 41/347] [D loss: 0.499757] [G loss: 0.261259]\n",
      "[Epoch 57/100] [Batch 42/347] [D loss: 0.500070] [G loss: 0.253406]\n",
      "[Epoch 57/100] [Batch 43/347] [D loss: 0.500472] [G loss: 0.268862]\n",
      "[Epoch 57/100] [Batch 44/347] [D loss: 0.500621] [G loss: 0.274847]\n",
      "[Epoch 57/100] [Batch 45/347] [D loss: 0.500464] [G loss: 0.266909]\n",
      "[Epoch 57/100] [Batch 46/347] [D loss: 0.500042] [G loss: 0.260064]\n",
      "[Epoch 57/100] [Batch 47/347] [D loss: 0.499661] [G loss: 0.271894]\n",
      "[Epoch 57/100] [Batch 48/347] [D loss: 0.499217] [G loss: 0.294098]\n",
      "[Epoch 57/100] [Batch 49/347] [D loss: 0.499346] [G loss: 0.290219]\n",
      "[Epoch 57/100] [Batch 50/347] [D loss: 0.499656] [G loss: 0.276979]\n",
      "[Epoch 57/100] [Batch 51/347] [D loss: 0.499716] [G loss: 0.275628]\n",
      "[Epoch 57/100] [Batch 52/347] [D loss: 0.499516] [G loss: 0.282655]\n",
      "[Epoch 57/100] [Batch 53/347] [D loss: 0.499060] [G loss: 0.298891]\n",
      "[Epoch 57/100] [Batch 54/347] [D loss: 0.498728] [G loss: 0.309595]\n",
      "[Epoch 57/100] [Batch 55/347] [D loss: 0.498818] [G loss: 0.306470]\n",
      "[Epoch 57/100] [Batch 56/347] [D loss: 0.499251] [G loss: 0.289072]\n",
      "[Epoch 57/100] [Batch 57/347] [D loss: 0.499652] [G loss: 0.274266]\n",
      "[Epoch 57/100] [Batch 58/347] [D loss: 0.499870] [G loss: 0.268064]\n",
      "[Epoch 57/100] [Batch 59/347] [D loss: 0.499613] [G loss: 0.282039]\n",
      "[Epoch 57/100] [Batch 60/347] [D loss: 0.499065] [G loss: 0.304420]\n",
      "[Epoch 57/100] [Batch 61/347] [D loss: 0.498822] [G loss: 0.309704]\n",
      "[Epoch 57/100] [Batch 62/347] [D loss: 0.499008] [G loss: 0.301241]\n",
      "[Epoch 57/100] [Batch 63/347] [D loss: 0.499348] [G loss: 0.286841]\n",
      "[Epoch 57/100] [Batch 64/347] [D loss: 0.499728] [G loss: 0.269561]\n",
      "[Epoch 57/100] [Batch 65/347] [D loss: 0.500132] [G loss: 0.265216]\n",
      "[Epoch 57/100] [Batch 66/347] [D loss: 0.499830] [G loss: 0.269596]\n",
      "[Epoch 57/100] [Batch 67/347] [D loss: 0.499257] [G loss: 0.290710]\n",
      "[Epoch 57/100] [Batch 68/347] [D loss: 0.499026] [G loss: 0.297090]\n",
      "[Epoch 57/100] [Batch 69/347] [D loss: 0.498734] [G loss: 0.308536]\n",
      "[Epoch 57/100] [Batch 70/347] [D loss: 0.498664] [G loss: 0.307672]\n",
      "[Epoch 57/100] [Batch 71/347] [D loss: 0.499036] [G loss: 0.295480]\n",
      "[Epoch 57/100] [Batch 72/347] [D loss: 0.499204] [G loss: 0.293862]\n",
      "[Epoch 57/100] [Batch 73/347] [D loss: 0.499137] [G loss: 0.295087]\n",
      "[Epoch 57/100] [Batch 74/347] [D loss: 0.499312] [G loss: 0.287652]\n",
      "[Epoch 57/100] [Batch 75/347] [D loss: 0.499422] [G loss: 0.284204]\n",
      "[Epoch 57/100] [Batch 76/347] [D loss: 0.499629] [G loss: 0.274992]\n",
      "[Epoch 57/100] [Batch 77/347] [D loss: 0.500166] [G loss: 0.263443]\n",
      "[Epoch 57/100] [Batch 78/347] [D loss: 0.500574] [G loss: 0.268964]\n",
      "[Epoch 57/100] [Batch 79/347] [D loss: 0.500791] [G loss: 0.277814]\n",
      "[Epoch 57/100] [Batch 80/347] [D loss: 0.500676] [G loss: 0.272479]\n",
      "[Epoch 57/100] [Batch 81/347] [D loss: 0.500702] [G loss: 0.274892]\n",
      "[Epoch 57/100] [Batch 82/347] [D loss: 0.500735] [G loss: 0.277353]\n",
      "[Epoch 57/100] [Batch 83/347] [D loss: 0.500649] [G loss: 0.276362]\n",
      "[Epoch 57/100] [Batch 84/347] [D loss: 0.500639] [G loss: 0.279887]\n",
      "[Epoch 57/100] [Batch 85/347] [D loss: 0.500603] [G loss: 0.279712]\n",
      "[Epoch 57/100] [Batch 86/347] [D loss: 0.500571] [G loss: 0.278914]\n",
      "[Epoch 57/100] [Batch 87/347] [D loss: 0.500567] [G loss: 0.279386]\n",
      "[Epoch 57/100] [Batch 88/347] [D loss: 0.500556] [G loss: 0.279491]\n",
      "[Epoch 57/100] [Batch 89/347] [D loss: 0.500571] [G loss: 0.280969]\n",
      "[Epoch 57/100] [Batch 90/347] [D loss: 0.500543] [G loss: 0.280020]\n",
      "[Epoch 57/100] [Batch 91/347] [D loss: 0.500499] [G loss: 0.278244]\n",
      "[Epoch 57/100] [Batch 92/347] [D loss: 0.500488] [G loss: 0.277986]\n",
      "[Epoch 57/100] [Batch 93/347] [D loss: 0.500479] [G loss: 0.277569]\n",
      "[Epoch 57/100] [Batch 94/347] [D loss: 0.500401] [G loss: 0.273269]\n",
      "[Epoch 57/100] [Batch 95/347] [D loss: 0.500371] [G loss: 0.271827]\n",
      "[Epoch 57/100] [Batch 96/347] [D loss: 0.500378] [G loss: 0.272790]\n",
      "[Epoch 57/100] [Batch 97/347] [D loss: 0.500361] [G loss: 0.271903]\n",
      "[Epoch 57/100] [Batch 98/347] [D loss: 0.500370] [G loss: 0.273040]\n",
      "[Epoch 57/100] [Batch 99/347] [D loss: 0.500364] [G loss: 0.273079]\n",
      "[Epoch 57/100] [Batch 100/347] [D loss: 0.500356] [G loss: 0.272549]\n",
      "[Epoch 57/100] [Batch 101/347] [D loss: 0.500311] [G loss: 0.270206]\n",
      "[Epoch 57/100] [Batch 102/347] [D loss: 0.500238] [G loss: 0.267094]\n",
      "[Epoch 57/100] [Batch 103/347] [D loss: 0.500244] [G loss: 0.267765]\n",
      "[Epoch 57/100] [Batch 104/347] [D loss: 0.500142] [G loss: 0.262429]\n",
      "[Epoch 57/100] [Batch 105/347] [D loss: 0.500071] [G loss: 0.255638]\n",
      "[Epoch 57/100] [Batch 106/347] [D loss: 0.499985] [G loss: 0.258015]\n",
      "[Epoch 57/100] [Batch 107/347] [D loss: 0.500020] [G loss: 0.261886]\n",
      "[Epoch 57/100] [Batch 108/347] [D loss: 0.500050] [G loss: 0.263819]\n",
      "[Epoch 57/100] [Batch 109/347] [D loss: 0.499973] [G loss: 0.267838]\n",
      "[Epoch 57/100] [Batch 110/347] [D loss: 0.500189] [G loss: 0.264130]\n",
      "[Epoch 57/100] [Batch 111/347] [D loss: 0.500297] [G loss: 0.264278]\n",
      "[Epoch 57/100] [Batch 112/347] [D loss: 0.500417] [G loss: 0.266987]\n",
      "[Epoch 57/100] [Batch 113/347] [D loss: 0.500697] [G loss: 0.283669]\n",
      "[Epoch 57/100] [Batch 114/347] [D loss: 0.500780] [G loss: 0.290639]\n",
      "[Epoch 57/100] [Batch 115/347] [D loss: 0.500515] [G loss: 0.273998]\n",
      "[Epoch 57/100] [Batch 116/347] [D loss: 0.500160] [G loss: 0.257206]\n",
      "[Epoch 57/100] [Batch 117/347] [D loss: 0.499879] [G loss: 0.257165]\n",
      "[Epoch 57/100] [Batch 118/347] [D loss: 0.499592] [G loss: 0.269638]\n",
      "[Epoch 57/100] [Batch 119/347] [D loss: 0.499531] [G loss: 0.269598]\n",
      "[Epoch 57/100] [Batch 120/347] [D loss: 0.499677] [G loss: 0.262439]\n",
      "[Epoch 57/100] [Batch 121/347] [D loss: 0.499694] [G loss: 0.261197]\n",
      "[Epoch 57/100] [Batch 122/347] [D loss: 0.499768] [G loss: 0.260437]\n",
      "[Epoch 57/100] [Batch 123/347] [D loss: 0.499921] [G loss: 0.258440]\n",
      "[Epoch 57/100] [Batch 124/347] [D loss: 0.500006] [G loss: 0.256158]\n",
      "[Epoch 57/100] [Batch 125/347] [D loss: 0.500137] [G loss: 0.262317]\n",
      "[Epoch 57/100] [Batch 126/347] [D loss: 0.500229] [G loss: 0.266217]\n",
      "[Epoch 57/100] [Batch 127/347] [D loss: 0.500254] [G loss: 0.264763]\n",
      "[Epoch 57/100] [Batch 128/347] [D loss: 0.500107] [G loss: 0.256482]\n",
      "[Epoch 57/100] [Batch 129/347] [D loss: 0.499902] [G loss: 0.257453]\n",
      "[Epoch 57/100] [Batch 130/347] [D loss: 0.499609] [G loss: 0.273333]\n",
      "[Epoch 57/100] [Batch 131/347] [D loss: 0.499341] [G loss: 0.284562]\n",
      "[Epoch 57/100] [Batch 132/347] [D loss: 0.498953] [G loss: 0.304038]\n",
      "[Epoch 57/100] [Batch 133/347] [D loss: 0.498819] [G loss: 0.309635]\n",
      "[Epoch 57/100] [Batch 134/347] [D loss: 0.499147] [G loss: 0.295182]\n",
      "[Epoch 57/100] [Batch 135/347] [D loss: 0.499242] [G loss: 0.292151]\n",
      "[Epoch 57/100] [Batch 136/347] [D loss: 0.499346] [G loss: 0.284371]\n",
      "[Epoch 57/100] [Batch 137/347] [D loss: 0.499287] [G loss: 0.285908]\n",
      "[Epoch 57/100] [Batch 138/347] [D loss: 0.498850] [G loss: 0.304266]\n",
      "[Epoch 57/100] [Batch 139/347] [D loss: 0.498463] [G loss: 0.317764]\n",
      "[Epoch 57/100] [Batch 140/347] [D loss: 0.498241] [G loss: 0.328753]\n",
      "[Epoch 57/100] [Batch 141/347] [D loss: 0.497856] [G loss: 0.343454]\n",
      "[Epoch 57/100] [Batch 142/347] [D loss: 0.497727] [G loss: 0.346475]\n",
      "[Epoch 57/100] [Batch 143/347] [D loss: 0.497559] [G loss: 0.349476]\n",
      "[Epoch 57/100] [Batch 144/347] [D loss: 0.497609] [G loss: 0.342112]\n",
      "[Epoch 57/100] [Batch 145/347] [D loss: 0.498050] [G loss: 0.321618]\n",
      "[Epoch 57/100] [Batch 146/347] [D loss: 0.498282] [G loss: 0.309240]\n",
      "[Epoch 57/100] [Batch 147/347] [D loss: 0.498496] [G loss: 0.300306]\n",
      "[Epoch 57/100] [Batch 148/347] [D loss: 0.498739] [G loss: 0.293288]\n",
      "[Epoch 57/100] [Batch 149/347] [D loss: 0.498763] [G loss: 0.295874]\n",
      "[Epoch 57/100] [Batch 150/347] [D loss: 0.498662] [G loss: 0.303896]\n",
      "[Epoch 57/100] [Batch 151/347] [D loss: 0.498555] [G loss: 0.309615]\n",
      "[Epoch 57/100] [Batch 152/347] [D loss: 0.498332] [G loss: 0.317047]\n",
      "[Epoch 57/100] [Batch 153/347] [D loss: 0.498193] [G loss: 0.319986]\n",
      "[Epoch 57/100] [Batch 154/347] [D loss: 0.498286] [G loss: 0.314924]\n",
      "[Epoch 57/100] [Batch 155/347] [D loss: 0.498367] [G loss: 0.313993]\n",
      "[Epoch 57/100] [Batch 156/347] [D loss: 0.498272] [G loss: 0.318164]\n",
      "[Epoch 57/100] [Batch 157/347] [D loss: 0.498301] [G loss: 0.317874]\n",
      "[Epoch 57/100] [Batch 158/347] [D loss: 0.498300] [G loss: 0.320004]\n",
      "[Epoch 57/100] [Batch 159/347] [D loss: 0.498348] [G loss: 0.318320]\n",
      "[Epoch 57/100] [Batch 160/347] [D loss: 0.498634] [G loss: 0.310102]\n",
      "[Epoch 57/100] [Batch 161/347] [D loss: 0.498515] [G loss: 0.317269]\n",
      "[Epoch 57/100] [Batch 162/347] [D loss: 0.498220] [G loss: 0.328193]\n",
      "[Epoch 57/100] [Batch 163/347] [D loss: 0.498035] [G loss: 0.330791]\n",
      "[Epoch 57/100] [Batch 164/347] [D loss: 0.498254] [G loss: 0.320624]\n",
      "[Epoch 57/100] [Batch 165/347] [D loss: 0.498673] [G loss: 0.305046]\n",
      "[Epoch 57/100] [Batch 166/347] [D loss: 0.499326] [G loss: 0.279313]\n",
      "[Epoch 57/100] [Batch 167/347] [D loss: 0.499897] [G loss: 0.256284]\n",
      "[Epoch 57/100] [Batch 168/347] [D loss: 0.500152] [G loss: 0.260099]\n",
      "[Epoch 57/100] [Batch 169/347] [D loss: 0.500346] [G loss: 0.261811]\n",
      "[Epoch 57/100] [Batch 170/347] [D loss: 0.500465] [G loss: 0.269112]\n",
      "[Epoch 57/100] [Batch 171/347] [D loss: 0.500443] [G loss: 0.269812]\n",
      "[Epoch 57/100] [Batch 172/347] [D loss: 0.500486] [G loss: 0.271806]\n",
      "[Epoch 57/100] [Batch 173/347] [D loss: 0.500443] [G loss: 0.271674]\n",
      "[Epoch 57/100] [Batch 174/347] [D loss: 0.500552] [G loss: 0.276480]\n",
      "[Epoch 57/100] [Batch 175/347] [D loss: 0.500642] [G loss: 0.282258]\n",
      "[Epoch 57/100] [Batch 176/347] [D loss: 0.500723] [G loss: 0.286161]\n",
      "[Epoch 57/100] [Batch 177/347] [D loss: 0.500670] [G loss: 0.283914]\n",
      "[Epoch 57/100] [Batch 178/347] [D loss: 0.500543] [G loss: 0.278704]\n",
      "[Epoch 57/100] [Batch 179/347] [D loss: 0.500463] [G loss: 0.275769]\n",
      "[Epoch 57/100] [Batch 180/347] [D loss: 0.500358] [G loss: 0.272279]\n",
      "[Epoch 57/100] [Batch 181/347] [D loss: 0.500418] [G loss: 0.275274]\n",
      "[Epoch 57/100] [Batch 182/347] [D loss: 0.500409] [G loss: 0.276250]\n",
      "[Epoch 57/100] [Batch 183/347] [D loss: 0.500450] [G loss: 0.277932]\n",
      "[Epoch 57/100] [Batch 184/347] [D loss: 0.500526] [G loss: 0.280377]\n",
      "[Epoch 57/100] [Batch 185/347] [D loss: 0.500472] [G loss: 0.277450]\n",
      "[Epoch 57/100] [Batch 186/347] [D loss: 0.500447] [G loss: 0.276301]\n",
      "[Epoch 57/100] [Batch 187/347] [D loss: 0.500386] [G loss: 0.273423]\n",
      "[Epoch 57/100] [Batch 188/347] [D loss: 0.500144] [G loss: 0.265511]\n",
      "[Epoch 57/100] [Batch 189/347] [D loss: 0.499975] [G loss: 0.259284]\n",
      "[Epoch 57/100] [Batch 190/347] [D loss: 0.499924] [G loss: 0.258140]\n",
      "[Epoch 57/100] [Batch 191/347] [D loss: 0.499844] [G loss: 0.260403]\n",
      "[Epoch 57/100] [Batch 192/347] [D loss: 0.499844] [G loss: 0.259919]\n",
      "[Epoch 57/100] [Batch 193/347] [D loss: 0.499858] [G loss: 0.260318]\n",
      "[Epoch 57/100] [Batch 194/347] [D loss: 0.499745] [G loss: 0.263460]\n",
      "[Epoch 57/100] [Batch 195/347] [D loss: 0.499676] [G loss: 0.264120]\n",
      "[Epoch 57/100] [Batch 196/347] [D loss: 0.499686] [G loss: 0.260224]\n",
      "[Epoch 57/100] [Batch 197/347] [D loss: 0.499707] [G loss: 0.257616]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 57/100] [Batch 198/347] [D loss: 0.499827] [G loss: 0.253927]\n",
      "[Epoch 57/100] [Batch 199/347] [D loss: 0.499817] [G loss: 0.255130]\n",
      "[Epoch 57/100] [Batch 200/347] [D loss: 0.499749] [G loss: 0.260791]\n",
      "[Epoch 57/100] [Batch 201/347] [D loss: 0.499683] [G loss: 0.264894]\n",
      "[Epoch 57/100] [Batch 202/347] [D loss: 0.499604] [G loss: 0.269901]\n",
      "[Epoch 57/100] [Batch 203/347] [D loss: 0.499585] [G loss: 0.270103]\n",
      "[Epoch 57/100] [Batch 204/347] [D loss: 0.499783] [G loss: 0.261096]\n",
      "[Epoch 57/100] [Batch 205/347] [D loss: 0.500018] [G loss: 0.255576]\n",
      "[Epoch 57/100] [Batch 206/347] [D loss: 0.500112] [G loss: 0.259035]\n",
      "[Epoch 57/100] [Batch 207/347] [D loss: 0.500223] [G loss: 0.261491]\n",
      "[Epoch 57/100] [Batch 208/347] [D loss: 0.500368] [G loss: 0.265396]\n",
      "[Epoch 57/100] [Batch 209/347] [D loss: 0.500225] [G loss: 0.261319]\n",
      "[Epoch 57/100] [Batch 210/347] [D loss: 0.500308] [G loss: 0.262503]\n",
      "[Epoch 57/100] [Batch 211/347] [D loss: 0.500223] [G loss: 0.265742]\n",
      "[Epoch 57/100] [Batch 212/347] [D loss: 0.499920] [G loss: 0.267837]\n",
      "[Epoch 57/100] [Batch 213/347] [D loss: 0.499835] [G loss: 0.270299]\n",
      "[Epoch 57/100] [Batch 214/347] [D loss: 0.499833] [G loss: 0.270073]\n",
      "[Epoch 57/100] [Batch 215/347] [D loss: 0.499903] [G loss: 0.271312]\n",
      "[Epoch 57/100] [Batch 216/347] [D loss: 0.500300] [G loss: 0.267144]\n",
      "[Epoch 57/100] [Batch 217/347] [D loss: 0.500655] [G loss: 0.272842]\n",
      "[Epoch 57/100] [Batch 218/347] [D loss: 0.500979] [G loss: 0.287575]\n",
      "[Epoch 57/100] [Batch 219/347] [D loss: 0.501164] [G loss: 0.294353]\n",
      "[Epoch 57/100] [Batch 220/347] [D loss: 0.501309] [G loss: 0.298964]\n",
      "[Epoch 57/100] [Batch 221/347] [D loss: 0.501341] [G loss: 0.299835]\n",
      "[Epoch 57/100] [Batch 222/347] [D loss: 0.501198] [G loss: 0.292275]\n",
      "[Epoch 57/100] [Batch 223/347] [D loss: 0.500820] [G loss: 0.282383]\n",
      "[Epoch 57/100] [Batch 224/347] [D loss: 0.500265] [G loss: 0.272582]\n",
      "[Epoch 57/100] [Batch 225/347] [D loss: 0.499685] [G loss: 0.267155]\n",
      "[Epoch 57/100] [Batch 226/347] [D loss: 0.499229] [G loss: 0.276486]\n",
      "[Epoch 57/100] [Batch 227/347] [D loss: 0.499091] [G loss: 0.277980]\n",
      "[Epoch 57/100] [Batch 228/347] [D loss: 0.499112] [G loss: 0.281169]\n",
      "[Epoch 57/100] [Batch 229/347] [D loss: 0.499215] [G loss: 0.278149]\n",
      "[Epoch 57/100] [Batch 230/347] [D loss: 0.499335] [G loss: 0.273772]\n",
      "[Epoch 57/100] [Batch 231/347] [D loss: 0.499298] [G loss: 0.269044]\n",
      "[Epoch 57/100] [Batch 232/347] [D loss: 0.499361] [G loss: 0.269423]\n",
      "[Epoch 57/100] [Batch 233/347] [D loss: 0.499598] [G loss: 0.264718]\n",
      "[Epoch 57/100] [Batch 234/347] [D loss: 0.499776] [G loss: 0.260365]\n",
      "[Epoch 57/100] [Batch 235/347] [D loss: 0.500074] [G loss: 0.258367]\n",
      "[Epoch 57/100] [Batch 236/347] [D loss: 0.500290] [G loss: 0.261489]\n",
      "[Epoch 57/100] [Batch 237/347] [D loss: 0.500391] [G loss: 0.267540]\n",
      "[Epoch 57/100] [Batch 238/347] [D loss: 0.500353] [G loss: 0.266878]\n",
      "[Epoch 57/100] [Batch 239/347] [D loss: 0.500246] [G loss: 0.262909]\n",
      "[Epoch 57/100] [Batch 240/347] [D loss: 0.500184] [G loss: 0.261087]\n",
      "[Epoch 57/100] [Batch 241/347] [D loss: 0.500197] [G loss: 0.262046]\n",
      "[Epoch 57/100] [Batch 242/347] [D loss: 0.500282] [G loss: 0.264904]\n",
      "[Epoch 57/100] [Batch 243/347] [D loss: 0.500412] [G loss: 0.267099]\n",
      "[Epoch 57/100] [Batch 244/347] [D loss: 0.500221] [G loss: 0.260454]\n",
      "[Epoch 57/100] [Batch 245/347] [D loss: 0.499928] [G loss: 0.255216]\n",
      "[Epoch 57/100] [Batch 246/347] [D loss: 0.499542] [G loss: 0.266861]\n",
      "[Epoch 57/100] [Batch 247/347] [D loss: 0.499148] [G loss: 0.275942]\n",
      "[Epoch 57/100] [Batch 248/347] [D loss: 0.499297] [G loss: 0.273377]\n",
      "[Epoch 57/100] [Batch 249/347] [D loss: 0.499548] [G loss: 0.267488]\n",
      "[Epoch 57/100] [Batch 250/347] [D loss: 0.499886] [G loss: 0.258961]\n",
      "[Epoch 57/100] [Batch 251/347] [D loss: 0.500261] [G loss: 0.266242]\n",
      "[Epoch 57/100] [Batch 252/347] [D loss: 0.500410] [G loss: 0.267170]\n",
      "[Epoch 57/100] [Batch 253/347] [D loss: 0.500296] [G loss: 0.267154]\n",
      "[Epoch 57/100] [Batch 254/347] [D loss: 0.500417] [G loss: 0.269219]\n",
      "[Epoch 57/100] [Batch 255/347] [D loss: 0.500450] [G loss: 0.270074]\n",
      "[Epoch 57/100] [Batch 256/347] [D loss: 0.500293] [G loss: 0.268614]\n",
      "[Epoch 57/100] [Batch 257/347] [D loss: 0.500112] [G loss: 0.266176]\n",
      "[Epoch 57/100] [Batch 258/347] [D loss: 0.499797] [G loss: 0.264960]\n",
      "[Epoch 57/100] [Batch 259/347] [D loss: 0.499600] [G loss: 0.271380]\n",
      "[Epoch 57/100] [Batch 260/347] [D loss: 0.499534] [G loss: 0.271839]\n",
      "[Epoch 57/100] [Batch 261/347] [D loss: 0.499633] [G loss: 0.268782]\n",
      "[Epoch 57/100] [Batch 262/347] [D loss: 0.499610] [G loss: 0.268282]\n",
      "[Epoch 57/100] [Batch 263/347] [D loss: 0.499532] [G loss: 0.270511]\n",
      "[Epoch 57/100] [Batch 264/347] [D loss: 0.499470] [G loss: 0.272706]\n",
      "[Epoch 57/100] [Batch 265/347] [D loss: 0.499437] [G loss: 0.273039]\n",
      "[Epoch 57/100] [Batch 266/347] [D loss: 0.499456] [G loss: 0.273311]\n",
      "[Epoch 57/100] [Batch 267/347] [D loss: 0.499417] [G loss: 0.276010]\n",
      "[Epoch 57/100] [Batch 268/347] [D loss: 0.499418] [G loss: 0.276305]\n",
      "[Epoch 57/100] [Batch 269/347] [D loss: 0.499411] [G loss: 0.276362]\n",
      "[Epoch 57/100] [Batch 270/347] [D loss: 0.499524] [G loss: 0.271139]\n",
      "[Epoch 57/100] [Batch 271/347] [D loss: 0.499493] [G loss: 0.273904]\n",
      "[Epoch 57/100] [Batch 272/347] [D loss: 0.499171] [G loss: 0.286945]\n",
      "[Epoch 57/100] [Batch 273/347] [D loss: 0.499170] [G loss: 0.288251]\n",
      "[Epoch 57/100] [Batch 274/347] [D loss: 0.499112] [G loss: 0.289863]\n",
      "[Epoch 57/100] [Batch 275/347] [D loss: 0.499253] [G loss: 0.282749]\n",
      "[Epoch 57/100] [Batch 276/347] [D loss: 0.499750] [G loss: 0.259576]\n",
      "[Epoch 57/100] [Batch 277/347] [D loss: 0.499862] [G loss: 0.255398]\n",
      "[Epoch 57/100] [Batch 278/347] [D loss: 0.499965] [G loss: 0.255390]\n",
      "[Epoch 57/100] [Batch 279/347] [D loss: 0.499959] [G loss: 0.257373]\n",
      "[Epoch 57/100] [Batch 280/347] [D loss: 0.499910] [G loss: 0.258169]\n",
      "[Epoch 57/100] [Batch 281/347] [D loss: 0.499858] [G loss: 0.257741]\n",
      "[Epoch 57/100] [Batch 282/347] [D loss: 0.499893] [G loss: 0.257672]\n",
      "[Epoch 57/100] [Batch 283/347] [D loss: 0.499860] [G loss: 0.255342]\n",
      "[Epoch 57/100] [Batch 284/347] [D loss: 0.499858] [G loss: 0.253413]\n",
      "[Epoch 57/100] [Batch 285/347] [D loss: 0.499827] [G loss: 0.252781]\n",
      "[Epoch 57/100] [Batch 286/347] [D loss: 0.499412] [G loss: 0.266509]\n",
      "[Epoch 57/100] [Batch 287/347] [D loss: 0.499325] [G loss: 0.268630]\n",
      "[Epoch 57/100] [Batch 288/347] [D loss: 0.499253] [G loss: 0.270377]\n",
      "[Epoch 57/100] [Batch 289/347] [D loss: 0.499121] [G loss: 0.273980]\n",
      "[Epoch 57/100] [Batch 290/347] [D loss: 0.499587] [G loss: 0.257041]\n",
      "[Epoch 57/100] [Batch 291/347] [D loss: 0.499915] [G loss: 0.254966]\n",
      "[Epoch 57/100] [Batch 292/347] [D loss: 0.500123] [G loss: 0.261633]\n",
      "[Epoch 57/100] [Batch 293/347] [D loss: 0.500378] [G loss: 0.268439]\n",
      "[Epoch 57/100] [Batch 294/347] [D loss: 0.500568] [G loss: 0.272269]\n",
      "[Epoch 57/100] [Batch 295/347] [D loss: 0.500559] [G loss: 0.273968]\n",
      "[Epoch 57/100] [Batch 296/347] [D loss: 0.500521] [G loss: 0.275181]\n",
      "[Epoch 57/100] [Batch 297/347] [D loss: 0.500645] [G loss: 0.282321]\n",
      "[Epoch 57/100] [Batch 298/347] [D loss: 0.500552] [G loss: 0.278307]\n",
      "[Epoch 57/100] [Batch 299/347] [D loss: 0.500551] [G loss: 0.275831]\n",
      "[Epoch 57/100] [Batch 300/347] [D loss: 0.500597] [G loss: 0.275554]\n",
      "[Epoch 57/100] [Batch 301/347] [D loss: 0.500210] [G loss: 0.265669]\n",
      "[Epoch 57/100] [Batch 302/347] [D loss: 0.499993] [G loss: 0.257861]\n",
      "[Epoch 57/100] [Batch 303/347] [D loss: 0.499602] [G loss: 0.258533]\n",
      "[Epoch 57/100] [Batch 304/347] [D loss: 0.499262] [G loss: 0.269042]\n",
      "[Epoch 57/100] [Batch 305/347] [D loss: 0.499140] [G loss: 0.270455]\n",
      "[Epoch 57/100] [Batch 306/347] [D loss: 0.499172] [G loss: 0.270353]\n",
      "[Epoch 57/100] [Batch 307/347] [D loss: 0.499416] [G loss: 0.263464]\n",
      "[Epoch 57/100] [Batch 308/347] [D loss: 0.499693] [G loss: 0.256296]\n",
      "[Epoch 57/100] [Batch 309/347] [D loss: 0.500011] [G loss: 0.266102]\n",
      "[Epoch 57/100] [Batch 310/347] [D loss: 0.500315] [G loss: 0.280960]\n",
      "[Epoch 57/100] [Batch 311/347] [D loss: 0.500327] [G loss: 0.281174]\n",
      "[Epoch 57/100] [Batch 312/347] [D loss: 0.500342] [G loss: 0.278702]\n",
      "[Epoch 57/100] [Batch 313/347] [D loss: 0.500260] [G loss: 0.272078]\n",
      "[Epoch 57/100] [Batch 314/347] [D loss: 0.499951] [G loss: 0.259933]\n",
      "[Epoch 57/100] [Batch 315/347] [D loss: 0.499707] [G loss: 0.256897]\n",
      "[Epoch 57/100] [Batch 316/347] [D loss: 0.499788] [G loss: 0.256100]\n",
      "[Epoch 57/100] [Batch 317/347] [D loss: 0.499933] [G loss: 0.260068]\n",
      "[Epoch 57/100] [Batch 318/347] [D loss: 0.500360] [G loss: 0.275229]\n",
      "[Epoch 57/100] [Batch 319/347] [D loss: 0.500713] [G loss: 0.289150]\n",
      "[Epoch 57/100] [Batch 320/347] [D loss: 0.500714] [G loss: 0.289622]\n",
      "[Epoch 57/100] [Batch 321/347] [D loss: 0.500632] [G loss: 0.284907]\n",
      "[Epoch 57/100] [Batch 322/347] [D loss: 0.500517] [G loss: 0.279670]\n",
      "[Epoch 57/100] [Batch 323/347] [D loss: 0.500388] [G loss: 0.273125]\n",
      "[Epoch 57/100] [Batch 324/347] [D loss: 0.500301] [G loss: 0.268948]\n",
      "[Epoch 57/100] [Batch 325/347] [D loss: 0.500163] [G loss: 0.263414]\n",
      "[Epoch 57/100] [Batch 326/347] [D loss: 0.499974] [G loss: 0.256895]\n",
      "[Epoch 57/100] [Batch 327/347] [D loss: 0.499633] [G loss: 0.259689]\n",
      "[Epoch 57/100] [Batch 328/347] [D loss: 0.499426] [G loss: 0.267308]\n",
      "[Epoch 57/100] [Batch 329/347] [D loss: 0.499443] [G loss: 0.265630]\n",
      "[Epoch 57/100] [Batch 330/347] [D loss: 0.499568] [G loss: 0.260400]\n",
      "[Epoch 57/100] [Batch 331/347] [D loss: 0.499930] [G loss: 0.256304]\n",
      "[Epoch 57/100] [Batch 332/347] [D loss: 0.500391] [G loss: 0.276968]\n",
      "[Epoch 57/100] [Batch 333/347] [D loss: 0.500407] [G loss: 0.276162]\n",
      "[Epoch 57/100] [Batch 334/347] [D loss: 0.500314] [G loss: 0.270425]\n",
      "[Epoch 57/100] [Batch 335/347] [D loss: 0.500300] [G loss: 0.269408]\n",
      "[Epoch 57/100] [Batch 336/347] [D loss: 0.500273] [G loss: 0.269292]\n",
      "[Epoch 57/100] [Batch 337/347] [D loss: 0.500351] [G loss: 0.274133]\n",
      "[Epoch 57/100] [Batch 338/347] [D loss: 0.500515] [G loss: 0.282599]\n",
      "[Epoch 57/100] [Batch 339/347] [D loss: 0.500563] [G loss: 0.283442]\n",
      "[Epoch 57/100] [Batch 340/347] [D loss: 0.500483] [G loss: 0.280312]\n",
      "[Epoch 57/100] [Batch 341/347] [D loss: 0.500459] [G loss: 0.280902]\n",
      "[Epoch 57/100] [Batch 342/347] [D loss: 0.500192] [G loss: 0.269073]\n",
      "[Epoch 57/100] [Batch 343/347] [D loss: 0.499822] [G loss: 0.255135]\n",
      "[Epoch 57/100] [Batch 344/347] [D loss: 0.499481] [G loss: 0.263437]\n",
      "[Epoch 57/100] [Batch 345/347] [D loss: 0.499153] [G loss: 0.278202]\n",
      "[Epoch 57/100] [Batch 346/347] [D loss: 0.499160] [G loss: 0.278114]\n",
      "[Epoch 57/100] [Batch 347/347] [D loss: 0.499298] [G loss: 0.272393]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 58/100] [Batch 1/347] [D loss: 0.499967] [G loss: 0.265318]\n",
      "[Epoch 58/100] [Batch 2/347] [D loss: 0.499938] [G loss: 0.266054]\n",
      "[Epoch 58/100] [Batch 3/347] [D loss: 0.500017] [G loss: 0.270370]\n",
      "[Epoch 58/100] [Batch 4/347] [D loss: 0.500005] [G loss: 0.270767]\n",
      "[Epoch 58/100] [Batch 5/347] [D loss: 0.499927] [G loss: 0.267426]\n",
      "[Epoch 58/100] [Batch 6/347] [D loss: 0.499885] [G loss: 0.265877]\n",
      "[Epoch 58/100] [Batch 7/347] [D loss: 0.499698] [G loss: 0.266657]\n",
      "[Epoch 58/100] [Batch 8/347] [D loss: 0.499669] [G loss: 0.266619]\n",
      "[Epoch 58/100] [Batch 9/347] [D loss: 0.499686] [G loss: 0.267041]\n",
      "[Epoch 58/100] [Batch 10/347] [D loss: 0.499684] [G loss: 0.268963]\n",
      "[Epoch 58/100] [Batch 11/347] [D loss: 0.499892] [G loss: 0.267669]\n",
      "[Epoch 58/100] [Batch 12/347] [D loss: 0.499962] [G loss: 0.268685]\n",
      "[Epoch 58/100] [Batch 13/347] [D loss: 0.499961] [G loss: 0.267671]\n",
      "[Epoch 58/100] [Batch 14/347] [D loss: 0.500006] [G loss: 0.266923]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 58/100] [Batch 15/347] [D loss: 0.499820] [G loss: 0.260607]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 58/100] [Batch 16/347] [D loss: 0.499730] [G loss: 0.258850]\n",
      "[Epoch 58/100] [Batch 17/347] [D loss: 0.499804] [G loss: 0.256549]\n",
      "[Epoch 58/100] [Batch 18/347] [D loss: 0.499817] [G loss: 0.257508]\n",
      "[Epoch 58/100] [Batch 19/347] [D loss: 0.499921] [G loss: 0.259869]\n",
      "[Epoch 58/100] [Batch 20/347] [D loss: 0.499997] [G loss: 0.264292]\n",
      "[Epoch 58/100] [Batch 21/347] [D loss: 0.499896] [G loss: 0.259959]\n",
      "[Epoch 58/100] [Batch 22/347] [D loss: 0.499880] [G loss: 0.258298]\n",
      "[Epoch 58/100] [Batch 23/347] [D loss: 0.499816] [G loss: 0.258075]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 58/100] [Batch 24/347] [D loss: 0.499669] [G loss: 0.257172]\n",
      "[Epoch 58/100] [Batch 25/347] [D loss: 0.499766] [G loss: 0.255923]\n",
      "[Epoch 58/100] [Batch 26/347] [D loss: 0.499788] [G loss: 0.256443]\n",
      "[Epoch 58/100] [Batch 27/347] [D loss: 0.500001] [G loss: 0.260013]\n",
      "[Epoch 58/100] [Batch 28/347] [D loss: 0.500318] [G loss: 0.267432]\n",
      "[Epoch 58/100] [Batch 29/347] [D loss: 0.500526] [G loss: 0.273169]\n",
      "[Epoch 58/100] [Batch 30/347] [D loss: 0.500584] [G loss: 0.275046]\n",
      "[Epoch 58/100] [Batch 31/347] [D loss: 0.500577] [G loss: 0.275278]\n",
      "[Epoch 58/100] [Batch 32/347] [D loss: 0.500514] [G loss: 0.272382]\n",
      "[Epoch 58/100] [Batch 33/347] [D loss: 0.500432] [G loss: 0.270558]\n",
      "[Epoch 58/100] [Batch 34/347] [D loss: 0.500297] [G loss: 0.265951]\n",
      "[Epoch 58/100] [Batch 35/347] [D loss: 0.499968] [G loss: 0.258738]\n",
      "[Epoch 58/100] [Batch 36/347] [D loss: 0.499646] [G loss: 0.261909]\n",
      "[Epoch 58/100] [Batch 37/347] [D loss: 0.499442] [G loss: 0.266690]\n",
      "[Epoch 58/100] [Batch 38/347] [D loss: 0.499238] [G loss: 0.271048]\n",
      "[Epoch 58/100] [Batch 39/347] [D loss: 0.499287] [G loss: 0.268841]\n",
      "[Epoch 58/100] [Batch 40/347] [D loss: 0.499438] [G loss: 0.267421]\n",
      "[Epoch 58/100] [Batch 41/347] [D loss: 0.499657] [G loss: 0.257982]\n",
      "[Epoch 58/100] [Batch 42/347] [D loss: 0.500017] [G loss: 0.255325]\n",
      "[Epoch 58/100] [Batch 43/347] [D loss: 0.500481] [G loss: 0.270820]\n",
      "[Epoch 58/100] [Batch 44/347] [D loss: 0.500651] [G loss: 0.276833]\n",
      "[Epoch 58/100] [Batch 45/347] [D loss: 0.500472] [G loss: 0.268963]\n",
      "[Epoch 58/100] [Batch 46/347] [D loss: 0.499975] [G loss: 0.263043]\n",
      "[Epoch 58/100] [Batch 47/347] [D loss: 0.499542] [G loss: 0.269335]\n",
      "[Epoch 58/100] [Batch 48/347] [D loss: 0.499029] [G loss: 0.291539]\n",
      "[Epoch 58/100] [Batch 49/347] [D loss: 0.499172] [G loss: 0.287617]\n",
      "[Epoch 58/100] [Batch 50/347] [D loss: 0.499528] [G loss: 0.274296]\n",
      "[Epoch 58/100] [Batch 51/347] [D loss: 0.499595] [G loss: 0.272885]\n",
      "[Epoch 58/100] [Batch 52/347] [D loss: 0.499376] [G loss: 0.279849]\n",
      "[Epoch 58/100] [Batch 53/347] [D loss: 0.498851] [G loss: 0.296079]\n",
      "[Epoch 58/100] [Batch 54/347] [D loss: 0.498474] [G loss: 0.306785]\n",
      "[Epoch 58/100] [Batch 55/347] [D loss: 0.498578] [G loss: 0.303638]\n",
      "[Epoch 58/100] [Batch 56/347] [D loss: 0.499076] [G loss: 0.286224]\n",
      "[Epoch 58/100] [Batch 57/347] [D loss: 0.499541] [G loss: 0.271399]\n",
      "[Epoch 58/100] [Batch 58/347] [D loss: 0.499795] [G loss: 0.265811]\n",
      "[Epoch 58/100] [Batch 59/347] [D loss: 0.499489] [G loss: 0.279369]\n",
      "[Epoch 58/100] [Batch 60/347] [D loss: 0.498844] [G loss: 0.301969]\n",
      "[Epoch 58/100] [Batch 61/347] [D loss: 0.498564] [G loss: 0.307436]\n",
      "[Epoch 58/100] [Batch 62/347] [D loss: 0.498769] [G loss: 0.299151]\n",
      "[Epoch 58/100] [Batch 63/347] [D loss: 0.499151] [G loss: 0.284878]\n",
      "[Epoch 58/100] [Batch 64/347] [D loss: 0.499590] [G loss: 0.267707]\n",
      "[Epoch 58/100] [Batch 65/347] [D loss: 0.500053] [G loss: 0.267226]\n",
      "[Epoch 58/100] [Batch 66/347] [D loss: 0.499691] [G loss: 0.267968]\n",
      "[Epoch 58/100] [Batch 67/347] [D loss: 0.499029] [G loss: 0.289172]\n",
      "[Epoch 58/100] [Batch 68/347] [D loss: 0.498766] [G loss: 0.295655]\n",
      "[Epoch 58/100] [Batch 69/347] [D loss: 0.498429] [G loss: 0.307187]\n",
      "[Epoch 58/100] [Batch 70/347] [D loss: 0.498354] [G loss: 0.306370]\n",
      "[Epoch 58/100] [Batch 71/347] [D loss: 0.498776] [G loss: 0.294200]\n",
      "[Epoch 58/100] [Batch 72/347] [D loss: 0.498958] [G loss: 0.292578]\n",
      "[Epoch 58/100] [Batch 73/347] [D loss: 0.498887] [G loss: 0.293823]\n",
      "[Epoch 58/100] [Batch 74/347] [D loss: 0.499083] [G loss: 0.286443]\n",
      "[Epoch 58/100] [Batch 75/347] [D loss: 0.499209] [G loss: 0.283040]\n",
      "[Epoch 58/100] [Batch 76/347] [D loss: 0.499449] [G loss: 0.273862]\n",
      "[Epoch 58/100] [Batch 77/347] [D loss: 0.500072] [G loss: 0.264508]\n",
      "[Epoch 58/100] [Batch 78/347] [D loss: 0.500547] [G loss: 0.269403]\n",
      "[Epoch 58/100] [Batch 79/347] [D loss: 0.500791] [G loss: 0.278238]\n",
      "[Epoch 58/100] [Batch 80/347] [D loss: 0.500656] [G loss: 0.273480]\n",
      "[Epoch 58/100] [Batch 81/347] [D loss: 0.500683] [G loss: 0.275299]\n",
      "[Epoch 58/100] [Batch 82/347] [D loss: 0.500719] [G loss: 0.277751]\n",
      "[Epoch 58/100] [Batch 83/347] [D loss: 0.500622] [G loss: 0.276741]\n",
      "[Epoch 58/100] [Batch 84/347] [D loss: 0.500620] [G loss: 0.280299]\n",
      "[Epoch 58/100] [Batch 85/347] [D loss: 0.500573] [G loss: 0.280141]\n",
      "[Epoch 58/100] [Batch 86/347] [D loss: 0.500538] [G loss: 0.279338]\n",
      "[Epoch 58/100] [Batch 87/347] [D loss: 0.500531] [G loss: 0.279812]\n",
      "[Epoch 58/100] [Batch 88/347] [D loss: 0.500517] [G loss: 0.279939]\n",
      "[Epoch 58/100] [Batch 89/347] [D loss: 0.500539] [G loss: 0.281422]\n",
      "[Epoch 58/100] [Batch 90/347] [D loss: 0.500507] [G loss: 0.280456]\n",
      "[Epoch 58/100] [Batch 91/347] [D loss: 0.500452] [G loss: 0.278684]\n",
      "[Epoch 58/100] [Batch 92/347] [D loss: 0.500441] [G loss: 0.278419]\n",
      "[Epoch 58/100] [Batch 93/347] [D loss: 0.500424] [G loss: 0.278008]\n",
      "[Epoch 58/100] [Batch 94/347] [D loss: 0.500335] [G loss: 0.273719]\n",
      "[Epoch 58/100] [Batch 95/347] [D loss: 0.500304] [G loss: 0.272300]\n",
      "[Epoch 58/100] [Batch 96/347] [D loss: 0.500310] [G loss: 0.273286]\n",
      "[Epoch 58/100] [Batch 97/347] [D loss: 0.500288] [G loss: 0.272411]\n",
      "[Epoch 58/100] [Batch 98/347] [D loss: 0.500306] [G loss: 0.273583]\n",
      "[Epoch 58/100] [Batch 99/347] [D loss: 0.500305] [G loss: 0.273663]\n",
      "[Epoch 58/100] [Batch 100/347] [D loss: 0.500297] [G loss: 0.273168]\n",
      "[Epoch 58/100] [Batch 101/347] [D loss: 0.500245] [G loss: 0.270880]\n",
      "[Epoch 58/100] [Batch 102/347] [D loss: 0.500166] [G loss: 0.267828]\n",
      "[Epoch 58/100] [Batch 103/347] [D loss: 0.500163] [G loss: 0.268540]\n",
      "[Epoch 58/100] [Batch 104/347] [D loss: 0.500054] [G loss: 0.263217]\n",
      "[Epoch 58/100] [Batch 105/347] [D loss: 0.499965] [G loss: 0.256459]\n",
      "[Epoch 58/100] [Batch 106/347] [D loss: 0.499854] [G loss: 0.258687]\n",
      "[Epoch 58/100] [Batch 107/347] [D loss: 0.499897] [G loss: 0.262588]\n",
      "[Epoch 58/100] [Batch 108/347] [D loss: 0.499933] [G loss: 0.264540]\n",
      "[Epoch 58/100] [Batch 109/347] [D loss: 0.499835] [G loss: 0.268562]\n",
      "[Epoch 58/100] [Batch 110/347] [D loss: 0.500096] [G loss: 0.264860]\n",
      "[Epoch 58/100] [Batch 111/347] [D loss: 0.500227] [G loss: 0.265012]\n",
      "[Epoch 58/100] [Batch 112/347] [D loss: 0.500370] [G loss: 0.267704]\n",
      "[Epoch 58/100] [Batch 113/347] [D loss: 0.500693] [G loss: 0.284579]\n",
      "[Epoch 58/100] [Batch 114/347] [D loss: 0.500800] [G loss: 0.291558]\n",
      "[Epoch 58/100] [Batch 115/347] [D loss: 0.500483] [G loss: 0.274924]\n",
      "[Epoch 58/100] [Batch 116/347] [D loss: 0.500074] [G loss: 0.257986]\n",
      "[Epoch 58/100] [Batch 117/347] [D loss: 0.499751] [G loss: 0.255462]\n",
      "[Epoch 58/100] [Batch 118/347] [D loss: 0.499422] [G loss: 0.267908]\n",
      "[Epoch 58/100] [Batch 119/347] [D loss: 0.499357] [G loss: 0.267839]\n",
      "[Epoch 58/100] [Batch 120/347] [D loss: 0.499526] [G loss: 0.260671]\n",
      "[Epoch 58/100] [Batch 121/347] [D loss: 0.499550] [G loss: 0.259416]\n",
      "[Epoch 58/100] [Batch 122/347] [D loss: 0.499638] [G loss: 0.258769]\n",
      "[Epoch 58/100] [Batch 123/347] [D loss: 0.499817] [G loss: 0.256802]\n",
      "[Epoch 58/100] [Batch 124/347] [D loss: 0.499908] [G loss: 0.257305]\n",
      "[Epoch 58/100] [Batch 125/347] [D loss: 0.500057] [G loss: 0.263502]\n",
      "[Epoch 58/100] [Batch 126/347] [D loss: 0.500164] [G loss: 0.267450]\n",
      "[Epoch 58/100] [Batch 127/347] [D loss: 0.500194] [G loss: 0.266016]\n",
      "[Epoch 58/100] [Batch 128/347] [D loss: 0.500021] [G loss: 0.257744]\n",
      "[Epoch 58/100] [Batch 129/347] [D loss: 0.499776] [G loss: 0.257081]\n",
      "[Epoch 58/100] [Batch 130/347] [D loss: 0.499416] [G loss: 0.271914]\n",
      "[Epoch 58/100] [Batch 131/347] [D loss: 0.499093] [G loss: 0.283308]\n",
      "[Epoch 58/100] [Batch 132/347] [D loss: 0.498628] [G loss: 0.302901]\n",
      "[Epoch 58/100] [Batch 133/347] [D loss: 0.498451] [G loss: 0.308625]\n",
      "[Epoch 58/100] [Batch 134/347] [D loss: 0.498832] [G loss: 0.294266]\n",
      "[Epoch 58/100] [Batch 135/347] [D loss: 0.498941] [G loss: 0.291304]\n",
      "[Epoch 58/100] [Batch 136/347] [D loss: 0.499066] [G loss: 0.283590]\n",
      "[Epoch 58/100] [Batch 137/347] [D loss: 0.499017] [G loss: 0.285193]\n",
      "[Epoch 58/100] [Batch 138/347] [D loss: 0.498509] [G loss: 0.303632]\n",
      "[Epoch 58/100] [Batch 139/347] [D loss: 0.498062] [G loss: 0.317232]\n",
      "[Epoch 58/100] [Batch 140/347] [D loss: 0.497803] [G loss: 0.328229]\n",
      "[Epoch 58/100] [Batch 141/347] [D loss: 0.497344] [G loss: 0.343033]\n",
      "[Epoch 58/100] [Batch 142/347] [D loss: 0.497198] [G loss: 0.346073]\n",
      "[Epoch 58/100] [Batch 143/347] [D loss: 0.497002] [G loss: 0.349108]\n",
      "[Epoch 58/100] [Batch 144/347] [D loss: 0.497064] [G loss: 0.341752]\n",
      "[Epoch 58/100] [Batch 145/347] [D loss: 0.497580] [G loss: 0.321247]\n",
      "[Epoch 58/100] [Batch 146/347] [D loss: 0.497853] [G loss: 0.308897]\n",
      "[Epoch 58/100] [Batch 147/347] [D loss: 0.498100] [G loss: 0.299987]\n",
      "[Epoch 58/100] [Batch 148/347] [D loss: 0.498381] [G loss: 0.292990]\n",
      "[Epoch 58/100] [Batch 149/347] [D loss: 0.498404] [G loss: 0.295619]\n",
      "[Epoch 58/100] [Batch 150/347] [D loss: 0.498279] [G loss: 0.303688]\n",
      "[Epoch 58/100] [Batch 151/347] [D loss: 0.498148] [G loss: 0.309435]\n",
      "[Epoch 58/100] [Batch 152/347] [D loss: 0.497884] [G loss: 0.316868]\n",
      "[Epoch 58/100] [Batch 153/347] [D loss: 0.497724] [G loss: 0.319821]\n",
      "[Epoch 58/100] [Batch 154/347] [D loss: 0.497828] [G loss: 0.314773]\n",
      "[Epoch 58/100] [Batch 155/347] [D loss: 0.497920] [G loss: 0.313871]\n",
      "[Epoch 58/100] [Batch 156/347] [D loss: 0.497802] [G loss: 0.318088]\n",
      "[Epoch 58/100] [Batch 157/347] [D loss: 0.497829] [G loss: 0.317792]\n",
      "[Epoch 58/100] [Batch 158/347] [D loss: 0.497818] [G loss: 0.319929]\n",
      "[Epoch 58/100] [Batch 159/347] [D loss: 0.497871] [G loss: 0.318265]\n",
      "[Epoch 58/100] [Batch 160/347] [D loss: 0.498209] [G loss: 0.310046]\n",
      "[Epoch 58/100] [Batch 161/347] [D loss: 0.498060] [G loss: 0.317243]\n",
      "[Epoch 58/100] [Batch 162/347] [D loss: 0.497712] [G loss: 0.328181]\n",
      "[Epoch 58/100] [Batch 163/347] [D loss: 0.497497] [G loss: 0.330806]\n",
      "[Epoch 58/100] [Batch 164/347] [D loss: 0.497750] [G loss: 0.320640]\n",
      "[Epoch 58/100] [Batch 165/347] [D loss: 0.498241] [G loss: 0.305064]\n",
      "[Epoch 58/100] [Batch 166/347] [D loss: 0.499015] [G loss: 0.279371]\n",
      "[Epoch 58/100] [Batch 167/347] [D loss: 0.499694] [G loss: 0.256356]\n",
      "[Epoch 58/100] [Batch 168/347] [D loss: 0.499995] [G loss: 0.258241]\n",
      "[Epoch 58/100] [Batch 169/347] [D loss: 0.500225] [G loss: 0.260497]\n",
      "[Epoch 58/100] [Batch 170/347] [D loss: 0.500366] [G loss: 0.267799]\n",
      "[Epoch 58/100] [Batch 171/347] [D loss: 0.500343] [G loss: 0.268542]\n",
      "[Epoch 58/100] [Batch 172/347] [D loss: 0.500390] [G loss: 0.270581]\n",
      "[Epoch 58/100] [Batch 173/347] [D loss: 0.500336] [G loss: 0.270503]\n",
      "[Epoch 58/100] [Batch 174/347] [D loss: 0.500460] [G loss: 0.275366]\n",
      "[Epoch 58/100] [Batch 175/347] [D loss: 0.500568] [G loss: 0.281245]\n",
      "[Epoch 58/100] [Batch 176/347] [D loss: 0.500664] [G loss: 0.285193]\n",
      "[Epoch 58/100] [Batch 177/347] [D loss: 0.500604] [G loss: 0.283017]\n",
      "[Epoch 58/100] [Batch 178/347] [D loss: 0.500454] [G loss: 0.277822]\n",
      "[Epoch 58/100] [Batch 179/347] [D loss: 0.500361] [G loss: 0.274920]\n",
      "[Epoch 58/100] [Batch 180/347] [D loss: 0.500245] [G loss: 0.271472]\n",
      "[Epoch 58/100] [Batch 181/347] [D loss: 0.500314] [G loss: 0.274510]\n",
      "[Epoch 58/100] [Batch 182/347] [D loss: 0.500308] [G loss: 0.275494]\n",
      "[Epoch 58/100] [Batch 183/347] [D loss: 0.500354] [G loss: 0.277169]\n",
      "[Epoch 58/100] [Batch 184/347] [D loss: 0.500445] [G loss: 0.279638]\n",
      "[Epoch 58/100] [Batch 185/347] [D loss: 0.500378] [G loss: 0.276671]\n",
      "[Epoch 58/100] [Batch 186/347] [D loss: 0.500353] [G loss: 0.275533]\n",
      "[Epoch 58/100] [Batch 187/347] [D loss: 0.500280] [G loss: 0.272639]\n",
      "[Epoch 58/100] [Batch 188/347] [D loss: 0.500001] [G loss: 0.264752]\n",
      "[Epoch 58/100] [Batch 189/347] [D loss: 0.499796] [G loss: 0.259189]\n",
      "[Epoch 58/100] [Batch 190/347] [D loss: 0.499741] [G loss: 0.258816]\n",
      "[Epoch 58/100] [Batch 191/347] [D loss: 0.499662] [G loss: 0.260841]\n",
      "[Epoch 58/100] [Batch 192/347] [D loss: 0.499675] [G loss: 0.260097]\n",
      "[Epoch 58/100] [Batch 193/347] [D loss: 0.499697] [G loss: 0.260333]\n",
      "[Epoch 58/100] [Batch 194/347] [D loss: 0.499568] [G loss: 0.263309]\n",
      "[Epoch 58/100] [Batch 195/347] [D loss: 0.499495] [G loss: 0.263816]\n",
      "[Epoch 58/100] [Batch 196/347] [D loss: 0.499506] [G loss: 0.259796]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 58/100] [Batch 197/347] [D loss: 0.499536] [G loss: 0.257090]\n",
      "[Epoch 58/100] [Batch 198/347] [D loss: 0.499678] [G loss: 0.253149]\n",
      "[Epoch 58/100] [Batch 199/347] [D loss: 0.499672] [G loss: 0.254362]\n",
      "[Epoch 58/100] [Batch 200/347] [D loss: 0.499599] [G loss: 0.259902]\n",
      "[Epoch 58/100] [Batch 201/347] [D loss: 0.499528] [G loss: 0.263899]\n",
      "[Epoch 58/100] [Batch 202/347] [D loss: 0.499438] [G loss: 0.268823]\n",
      "[Epoch 58/100] [Batch 203/347] [D loss: 0.499419] [G loss: 0.268984]\n",
      "[Epoch 58/100] [Batch 204/347] [D loss: 0.499648] [G loss: 0.259884]\n",
      "[Epoch 58/100] [Batch 205/347] [D loss: 0.499923] [G loss: 0.256271]\n",
      "[Epoch 58/100] [Batch 206/347] [D loss: 0.500034] [G loss: 0.259780]\n",
      "[Epoch 58/100] [Batch 207/347] [D loss: 0.500168] [G loss: 0.262280]\n",
      "[Epoch 58/100] [Batch 208/347] [D loss: 0.500332] [G loss: 0.266234]\n",
      "[Epoch 58/100] [Batch 209/347] [D loss: 0.500168] [G loss: 0.262152]\n",
      "[Epoch 58/100] [Batch 210/347] [D loss: 0.500263] [G loss: 0.263729]\n",
      "[Epoch 58/100] [Batch 211/347] [D loss: 0.500161] [G loss: 0.267019]\n",
      "[Epoch 58/100] [Batch 212/347] [D loss: 0.499787] [G loss: 0.269175]\n",
      "[Epoch 58/100] [Batch 213/347] [D loss: 0.499684] [G loss: 0.271670]\n",
      "[Epoch 58/100] [Batch 214/347] [D loss: 0.499686] [G loss: 0.271445]\n",
      "[Epoch 58/100] [Batch 215/347] [D loss: 0.499772] [G loss: 0.272721]\n",
      "[Epoch 58/100] [Batch 216/347] [D loss: 0.500262] [G loss: 0.268596]\n",
      "[Epoch 58/100] [Batch 217/347] [D loss: 0.500680] [G loss: 0.273768]\n",
      "[Epoch 58/100] [Batch 218/347] [D loss: 0.501059] [G loss: 0.288508]\n",
      "[Epoch 58/100] [Batch 219/347] [D loss: 0.501279] [G loss: 0.295307]\n",
      "[Epoch 58/100] [Batch 220/347] [D loss: 0.501443] [G loss: 0.299935]\n",
      "[Epoch 58/100] [Batch 221/347] [D loss: 0.501479] [G loss: 0.300801]\n",
      "[Epoch 58/100] [Batch 222/347] [D loss: 0.501311] [G loss: 0.293282]\n",
      "[Epoch 58/100] [Batch 223/347] [D loss: 0.500862] [G loss: 0.284020]\n",
      "[Epoch 58/100] [Batch 224/347] [D loss: 0.500211] [G loss: 0.274229]\n",
      "[Epoch 58/100] [Batch 225/347] [D loss: 0.499540] [G loss: 0.265733]\n",
      "[Epoch 58/100] [Batch 226/347] [D loss: 0.499016] [G loss: 0.274995]\n",
      "[Epoch 58/100] [Batch 227/347] [D loss: 0.498868] [G loss: 0.275717]\n",
      "[Epoch 58/100] [Batch 228/347] [D loss: 0.498895] [G loss: 0.278856]\n",
      "[Epoch 58/100] [Batch 229/347] [D loss: 0.499016] [G loss: 0.275743]\n",
      "[Epoch 58/100] [Batch 230/347] [D loss: 0.499155] [G loss: 0.271309]\n",
      "[Epoch 58/100] [Batch 231/347] [D loss: 0.499113] [G loss: 0.267292]\n",
      "[Epoch 58/100] [Batch 232/347] [D loss: 0.499191] [G loss: 0.267649]\n",
      "[Epoch 58/100] [Batch 233/347] [D loss: 0.499456] [G loss: 0.262969]\n",
      "[Epoch 58/100] [Batch 234/347] [D loss: 0.499663] [G loss: 0.258604]\n",
      "[Epoch 58/100] [Batch 235/347] [D loss: 0.500015] [G loss: 0.260119]\n",
      "[Epoch 58/100] [Batch 236/347] [D loss: 0.500270] [G loss: 0.262536]\n",
      "[Epoch 58/100] [Batch 237/347] [D loss: 0.500389] [G loss: 0.268600]\n",
      "[Epoch 58/100] [Batch 238/347] [D loss: 0.500342] [G loss: 0.267973]\n",
      "[Epoch 58/100] [Batch 239/347] [D loss: 0.500215] [G loss: 0.264037]\n",
      "[Epoch 58/100] [Batch 240/347] [D loss: 0.500148] [G loss: 0.262231]\n",
      "[Epoch 58/100] [Batch 241/347] [D loss: 0.500161] [G loss: 0.263211]\n",
      "[Epoch 58/100] [Batch 242/347] [D loss: 0.500266] [G loss: 0.266126]\n",
      "[Epoch 58/100] [Batch 243/347] [D loss: 0.500415] [G loss: 0.268350]\n",
      "[Epoch 58/100] [Batch 244/347] [D loss: 0.500182] [G loss: 0.262480]\n",
      "[Epoch 58/100] [Batch 245/347] [D loss: 0.499845] [G loss: 0.257255]\n",
      "[Epoch 58/100] [Batch 246/347] [D loss: 0.499399] [G loss: 0.265258]\n",
      "[Epoch 58/100] [Batch 247/347] [D loss: 0.498944] [G loss: 0.274312]\n",
      "[Epoch 58/100] [Batch 248/347] [D loss: 0.499111] [G loss: 0.271692]\n",
      "[Epoch 58/100] [Batch 249/347] [D loss: 0.499403] [G loss: 0.265735]\n",
      "[Epoch 58/100] [Batch 250/347] [D loss: 0.499795] [G loss: 0.260927]\n",
      "[Epoch 58/100] [Batch 251/347] [D loss: 0.500236] [G loss: 0.268229]\n",
      "[Epoch 58/100] [Batch 252/347] [D loss: 0.500417] [G loss: 0.269158]\n",
      "[Epoch 58/100] [Batch 253/347] [D loss: 0.500282] [G loss: 0.269154]\n",
      "[Epoch 58/100] [Batch 254/347] [D loss: 0.500422] [G loss: 0.271201]\n",
      "[Epoch 58/100] [Batch 255/347] [D loss: 0.500458] [G loss: 0.272075]\n",
      "[Epoch 58/100] [Batch 256/347] [D loss: 0.500263] [G loss: 0.270652]\n",
      "[Epoch 58/100] [Batch 257/347] [D loss: 0.500056] [G loss: 0.268252]\n",
      "[Epoch 58/100] [Batch 258/347] [D loss: 0.499685] [G loss: 0.264651]\n",
      "[Epoch 58/100] [Batch 259/347] [D loss: 0.499454] [G loss: 0.269673]\n",
      "[Epoch 58/100] [Batch 260/347] [D loss: 0.499380] [G loss: 0.270306]\n",
      "[Epoch 58/100] [Batch 261/347] [D loss: 0.499484] [G loss: 0.267437]\n",
      "[Epoch 58/100] [Batch 262/347] [D loss: 0.499449] [G loss: 0.267060]\n",
      "[Epoch 58/100] [Batch 263/347] [D loss: 0.499348] [G loss: 0.269410]\n",
      "[Epoch 58/100] [Batch 264/347] [D loss: 0.499276] [G loss: 0.271732]\n",
      "[Epoch 58/100] [Batch 265/347] [D loss: 0.499232] [G loss: 0.272208]\n",
      "[Epoch 58/100] [Batch 266/347] [D loss: 0.499248] [G loss: 0.272549]\n",
      "[Epoch 58/100] [Batch 267/347] [D loss: 0.499200] [G loss: 0.275323]\n",
      "[Epoch 58/100] [Batch 268/347] [D loss: 0.499201] [G loss: 0.275705]\n",
      "[Epoch 58/100] [Batch 269/347] [D loss: 0.499192] [G loss: 0.275835]\n",
      "[Epoch 58/100] [Batch 270/347] [D loss: 0.499322] [G loss: 0.270638]\n",
      "[Epoch 58/100] [Batch 271/347] [D loss: 0.499264] [G loss: 0.273477]\n",
      "[Epoch 58/100] [Batch 272/347] [D loss: 0.498785] [G loss: 0.286583]\n",
      "[Epoch 58/100] [Batch 273/347] [D loss: 0.498788] [G loss: 0.287922]\n",
      "[Epoch 58/100] [Batch 274/347] [D loss: 0.498709] [G loss: 0.289529]\n",
      "[Epoch 58/100] [Batch 275/347] [D loss: 0.498880] [G loss: 0.282422]\n",
      "[Epoch 58/100] [Batch 276/347] [D loss: 0.499572] [G loss: 0.259250]\n",
      "[Epoch 58/100] [Batch 277/347] [D loss: 0.499708] [G loss: 0.255094]\n",
      "[Epoch 58/100] [Batch 278/347] [D loss: 0.499832] [G loss: 0.255627]\n",
      "[Epoch 58/100] [Batch 279/347] [D loss: 0.499814] [G loss: 0.257576]\n",
      "[Epoch 58/100] [Batch 280/347] [D loss: 0.499758] [G loss: 0.258349]\n",
      "[Epoch 58/100] [Batch 281/347] [D loss: 0.499694] [G loss: 0.257934]\n",
      "[Epoch 58/100] [Batch 282/347] [D loss: 0.499732] [G loss: 0.257882]\n",
      "[Epoch 58/100] [Batch 283/347] [D loss: 0.499696] [G loss: 0.255557]\n",
      "[Epoch 58/100] [Batch 284/347] [D loss: 0.499693] [G loss: 0.253631]\n",
      "[Epoch 58/100] [Batch 285/347] [D loss: 0.499656] [G loss: 0.252727]\n",
      "[Epoch 58/100] [Batch 286/347] [D loss: 0.499161] [G loss: 0.266473]\n",
      "[Epoch 58/100] [Batch 287/347] [D loss: 0.499060] [G loss: 0.268560]\n",
      "[Epoch 58/100] [Batch 288/347] [D loss: 0.498973] [G loss: 0.270315]\n",
      "[Epoch 58/100] [Batch 289/347] [D loss: 0.498822] [G loss: 0.273901]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 58/100] [Batch 290/347] [D loss: 0.499375] [G loss: 0.256934]\n",
      "[Epoch 58/100] [Batch 291/347] [D loss: 0.499757] [G loss: 0.255151]\n",
      "[Epoch 58/100] [Batch 292/347] [D loss: 0.499998] [G loss: 0.261821]\n",
      "[Epoch 58/100] [Batch 293/347] [D loss: 0.500296] [G loss: 0.268663]\n",
      "[Epoch 58/100] [Batch 294/347] [D loss: 0.500518] [G loss: 0.272111]\n",
      "[Epoch 58/100] [Batch 295/347] [D loss: 0.500511] [G loss: 0.273398]\n",
      "[Epoch 58/100] [Batch 296/347] [D loss: 0.500473] [G loss: 0.274637]\n",
      "[Epoch 58/100] [Batch 297/347] [D loss: 0.500623] [G loss: 0.281815]\n",
      "[Epoch 58/100] [Batch 298/347] [D loss: 0.500515] [G loss: 0.277862]\n",
      "[Epoch 58/100] [Batch 299/347] [D loss: 0.500511] [G loss: 0.275447]\n",
      "[Epoch 58/100] [Batch 300/347] [D loss: 0.500557] [G loss: 0.275216]\n",
      "[Epoch 58/100] [Batch 301/347] [D loss: 0.500098] [G loss: 0.265675]\n",
      "[Epoch 58/100] [Batch 302/347] [D loss: 0.499841] [G loss: 0.257831]\n",
      "[Epoch 58/100] [Batch 303/347] [D loss: 0.499389] [G loss: 0.258072]\n",
      "[Epoch 58/100] [Batch 304/347] [D loss: 0.498992] [G loss: 0.268574]\n",
      "[Epoch 58/100] [Batch 305/347] [D loss: 0.498844] [G loss: 0.270117]\n",
      "[Epoch 58/100] [Batch 306/347] [D loss: 0.498881] [G loss: 0.269951]\n",
      "[Epoch 58/100] [Batch 307/347] [D loss: 0.499165] [G loss: 0.263040]\n",
      "[Epoch 58/100] [Batch 308/347] [D loss: 0.499496] [G loss: 0.255717]\n",
      "[Epoch 58/100] [Batch 309/347] [D loss: 0.499888] [G loss: 0.265824]\n",
      "[Epoch 58/100] [Batch 310/347] [D loss: 0.500253] [G loss: 0.280699]\n",
      "[Epoch 58/100] [Batch 311/347] [D loss: 0.500271] [G loss: 0.280918]\n",
      "[Epoch 58/100] [Batch 312/347] [D loss: 0.500284] [G loss: 0.278475]\n",
      "[Epoch 58/100] [Batch 313/347] [D loss: 0.500179] [G loss: 0.271878]\n",
      "[Epoch 58/100] [Batch 314/347] [D loss: 0.499808] [G loss: 0.259731]\n",
      "[Epoch 58/100] [Batch 315/347] [D loss: 0.499519] [G loss: 0.256483]\n",
      "[Epoch 58/100] [Batch 316/347] [D loss: 0.499615] [G loss: 0.255718]\n",
      "[Epoch 58/100] [Batch 317/347] [D loss: 0.499788] [G loss: 0.259967]\n",
      "[Epoch 58/100] [Batch 318/347] [D loss: 0.500294] [G loss: 0.275161]\n",
      "[Epoch 58/100] [Batch 319/347] [D loss: 0.500713] [G loss: 0.289096]\n",
      "[Epoch 58/100] [Batch 320/347] [D loss: 0.500720] [G loss: 0.289551]\n",
      "[Epoch 58/100] [Batch 321/347] [D loss: 0.500618] [G loss: 0.284860]\n",
      "[Epoch 58/100] [Batch 322/347] [D loss: 0.500482] [G loss: 0.279606]\n",
      "[Epoch 58/100] [Batch 323/347] [D loss: 0.500328] [G loss: 0.273063]\n",
      "[Epoch 58/100] [Batch 324/347] [D loss: 0.500220] [G loss: 0.268884]\n",
      "[Epoch 58/100] [Batch 325/347] [D loss: 0.500060] [G loss: 0.263384]\n",
      "[Epoch 58/100] [Batch 326/347] [D loss: 0.499842] [G loss: 0.256863]\n",
      "[Epoch 58/100] [Batch 327/347] [D loss: 0.499432] [G loss: 0.259079]\n",
      "[Epoch 58/100] [Batch 328/347] [D loss: 0.499183] [G loss: 0.266677]\n",
      "[Epoch 58/100] [Batch 329/347] [D loss: 0.499212] [G loss: 0.265003]\n",
      "[Epoch 58/100] [Batch 330/347] [D loss: 0.499359] [G loss: 0.259760]\n",
      "[Epoch 58/100] [Batch 331/347] [D loss: 0.499788] [G loss: 0.256399]\n",
      "[Epoch 58/100] [Batch 332/347] [D loss: 0.500344] [G loss: 0.277082]\n",
      "[Epoch 58/100] [Batch 333/347] [D loss: 0.500361] [G loss: 0.276300]\n",
      "[Epoch 58/100] [Batch 334/347] [D loss: 0.500249] [G loss: 0.270568]\n",
      "[Epoch 58/100] [Batch 335/347] [D loss: 0.500229] [G loss: 0.269608]\n",
      "[Epoch 58/100] [Batch 336/347] [D loss: 0.500202] [G loss: 0.269498]\n",
      "[Epoch 58/100] [Batch 337/347] [D loss: 0.500299] [G loss: 0.274354]\n",
      "[Epoch 58/100] [Batch 338/347] [D loss: 0.500499] [G loss: 0.282835]\n",
      "[Epoch 58/100] [Batch 339/347] [D loss: 0.500555] [G loss: 0.283700]\n",
      "[Epoch 58/100] [Batch 340/347] [D loss: 0.500459] [G loss: 0.280586]\n",
      "[Epoch 58/100] [Batch 341/347] [D loss: 0.500435] [G loss: 0.281174]\n",
      "[Epoch 58/100] [Batch 342/347] [D loss: 0.500114] [G loss: 0.269344]\n",
      "[Epoch 58/100] [Batch 343/347] [D loss: 0.499671] [G loss: 0.254512]\n",
      "[Epoch 58/100] [Batch 344/347] [D loss: 0.499254] [G loss: 0.262659]\n",
      "[Epoch 58/100] [Batch 345/347] [D loss: 0.498852] [G loss: 0.277395]\n",
      "[Epoch 58/100] [Batch 346/347] [D loss: 0.498868] [G loss: 0.277313]\n",
      "[Epoch 58/100] [Batch 347/347] [D loss: 0.499034] [G loss: 0.271563]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 1/347] [D loss: 0.499858] [G loss: 0.265601]\n",
      "[Epoch 59/100] [Batch 2/347] [D loss: 0.499824] [G loss: 0.266338]\n",
      "[Epoch 59/100] [Batch 3/347] [D loss: 0.499926] [G loss: 0.270667]\n",
      "[Epoch 59/100] [Batch 4/347] [D loss: 0.499910] [G loss: 0.271095]\n",
      "[Epoch 59/100] [Batch 5/347] [D loss: 0.499820] [G loss: 0.267771]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 6/347] [D loss: 0.499766] [G loss: 0.265095]\n",
      "[Epoch 59/100] [Batch 7/347] [D loss: 0.499544] [G loss: 0.265887]\n",
      "[Epoch 59/100] [Batch 8/347] [D loss: 0.499509] [G loss: 0.265857]\n",
      "[Epoch 59/100] [Batch 9/347] [D loss: 0.499529] [G loss: 0.266275]\n",
      "[Epoch 59/100] [Batch 10/347] [D loss: 0.499525] [G loss: 0.268208]\n",
      "[Epoch 59/100] [Batch 11/347] [D loss: 0.499778] [G loss: 0.266915]\n",
      "[Epoch 59/100] [Batch 12/347] [D loss: 0.499859] [G loss: 0.269165]\n",
      "[Epoch 59/100] [Batch 13/347] [D loss: 0.499862] [G loss: 0.268159]\n",
      "[Epoch 59/100] [Batch 14/347] [D loss: 0.499910] [G loss: 0.267390]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 15/347] [D loss: 0.499685] [G loss: 0.259844]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 16/347] [D loss: 0.499574] [G loss: 0.258059]\n",
      "[Epoch 59/100] [Batch 17/347] [D loss: 0.499663] [G loss: 0.255740]\n",
      "[Epoch 59/100] [Batch 18/347] [D loss: 0.499680] [G loss: 0.256689]\n",
      "[Epoch 59/100] [Batch 19/347] [D loss: 0.499806] [G loss: 0.260244]\n",
      "[Epoch 59/100] [Batch 20/347] [D loss: 0.499899] [G loss: 0.264680]\n",
      "[Epoch 59/100] [Batch 21/347] [D loss: 0.499778] [G loss: 0.259685]\n",
      "[Epoch 59/100] [Batch 22/347] [D loss: 0.499747] [G loss: 0.257724]\n",
      "[Epoch 59/100] [Batch 23/347] [D loss: 0.499661] [G loss: 0.257715]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 24/347] [D loss: 0.499474] [G loss: 0.256997]\n",
      "[Epoch 59/100] [Batch 25/347] [D loss: 0.499577] [G loss: 0.255649]\n",
      "[Epoch 59/100] [Batch 26/347] [D loss: 0.499591] [G loss: 0.256301]\n",
      "[Epoch 59/100] [Batch 27/347] [D loss: 0.499842] [G loss: 0.259163]\n",
      "[Epoch 59/100] [Batch 28/347] [D loss: 0.500217] [G loss: 0.266497]\n",
      "[Epoch 59/100] [Batch 29/347] [D loss: 0.500459] [G loss: 0.272520]\n",
      "[Epoch 59/100] [Batch 30/347] [D loss: 0.500524] [G loss: 0.274284]\n",
      "[Epoch 59/100] [Batch 31/347] [D loss: 0.500513] [G loss: 0.274465]\n",
      "[Epoch 59/100] [Batch 32/347] [D loss: 0.500437] [G loss: 0.271504]\n",
      "[Epoch 59/100] [Batch 33/347] [D loss: 0.500335] [G loss: 0.269640]\n",
      "[Epoch 59/100] [Batch 34/347] [D loss: 0.500171] [G loss: 0.265005]\n",
      "[Epoch 59/100] [Batch 35/347] [D loss: 0.499775] [G loss: 0.257276]\n",
      "[Epoch 59/100] [Batch 36/347] [D loss: 0.499396] [G loss: 0.262523]\n",
      "[Epoch 59/100] [Batch 37/347] [D loss: 0.499158] [G loss: 0.267333]\n",
      "[Epoch 59/100] [Batch 38/347] [D loss: 0.498918] [G loss: 0.271693]\n",
      "[Epoch 59/100] [Batch 39/347] [D loss: 0.498976] [G loss: 0.270013]\n",
      "[Epoch 59/100] [Batch 40/347] [D loss: 0.499164] [G loss: 0.268585]\n",
      "[Epoch 59/100] [Batch 41/347] [D loss: 0.499416] [G loss: 0.259152]\n",
      "[Epoch 59/100] [Batch 42/347] [D loss: 0.499840] [G loss: 0.254143]\n",
      "[Epoch 59/100] [Batch 43/347] [D loss: 0.500391] [G loss: 0.269622]\n",
      "[Epoch 59/100] [Batch 44/347] [D loss: 0.500592] [G loss: 0.275608]\n",
      "[Epoch 59/100] [Batch 45/347] [D loss: 0.500374] [G loss: 0.267707]\n",
      "[Epoch 59/100] [Batch 46/347] [D loss: 0.499771] [G loss: 0.261229]\n",
      "[Epoch 59/100] [Batch 47/347] [D loss: 0.499247] [G loss: 0.270052]\n",
      "[Epoch 59/100] [Batch 48/347] [D loss: 0.498617] [G loss: 0.292265]\n",
      "[Epoch 59/100] [Batch 49/347] [D loss: 0.498781] [G loss: 0.288334]\n",
      "[Epoch 59/100] [Batch 50/347] [D loss: 0.499213] [G loss: 0.275035]\n",
      "[Epoch 59/100] [Batch 51/347] [D loss: 0.499290] [G loss: 0.273616]\n",
      "[Epoch 59/100] [Batch 52/347] [D loss: 0.499034] [G loss: 0.280569]\n",
      "[Epoch 59/100] [Batch 53/347] [D loss: 0.498407] [G loss: 0.296769]\n",
      "[Epoch 59/100] [Batch 54/347] [D loss: 0.497963] [G loss: 0.307489]\n",
      "[Epoch 59/100] [Batch 55/347] [D loss: 0.498084] [G loss: 0.304347]\n",
      "[Epoch 59/100] [Batch 56/347] [D loss: 0.498679] [G loss: 0.286897]\n",
      "[Epoch 59/100] [Batch 57/347] [D loss: 0.499242] [G loss: 0.272037]\n",
      "[Epoch 59/100] [Batch 58/347] [D loss: 0.499549] [G loss: 0.265827]\n",
      "[Epoch 59/100] [Batch 59/347] [D loss: 0.499184] [G loss: 0.279828]\n",
      "[Epoch 59/100] [Batch 60/347] [D loss: 0.498407] [G loss: 0.302288]\n",
      "[Epoch 59/100] [Batch 61/347] [D loss: 0.498084] [G loss: 0.307647]\n",
      "[Epoch 59/100] [Batch 62/347] [D loss: 0.498333] [G loss: 0.299247]\n",
      "[Epoch 59/100] [Batch 63/347] [D loss: 0.498795] [G loss: 0.284852]\n",
      "[Epoch 59/100] [Batch 64/347] [D loss: 0.499336] [G loss: 0.267559]\n",
      "[Epoch 59/100] [Batch 65/347] [D loss: 0.499898] [G loss: 0.266508]\n",
      "[Epoch 59/100] [Batch 66/347] [D loss: 0.499456] [G loss: 0.267675]\n",
      "[Epoch 59/100] [Batch 67/347] [D loss: 0.498664] [G loss: 0.288836]\n",
      "[Epoch 59/100] [Batch 68/347] [D loss: 0.498353] [G loss: 0.295265]\n",
      "[Epoch 59/100] [Batch 69/347] [D loss: 0.497955] [G loss: 0.306720]\n",
      "[Epoch 59/100] [Batch 70/347] [D loss: 0.497873] [G loss: 0.305832]\n",
      "[Epoch 59/100] [Batch 71/347] [D loss: 0.498374] [G loss: 0.293596]\n",
      "[Epoch 59/100] [Batch 72/347] [D loss: 0.498589] [G loss: 0.291928]\n",
      "[Epoch 59/100] [Batch 73/347] [D loss: 0.498510] [G loss: 0.293141]\n",
      "[Epoch 59/100] [Batch 74/347] [D loss: 0.498754] [G loss: 0.285726]\n",
      "[Epoch 59/100] [Batch 75/347] [D loss: 0.498899] [G loss: 0.282292]\n",
      "[Epoch 59/100] [Batch 76/347] [D loss: 0.499190] [G loss: 0.273096]\n",
      "[Epoch 59/100] [Batch 77/347] [D loss: 0.499953] [G loss: 0.264417]\n",
      "[Epoch 59/100] [Batch 78/347] [D loss: 0.500531] [G loss: 0.269546]\n",
      "[Epoch 59/100] [Batch 79/347] [D loss: 0.500827] [G loss: 0.278456]\n",
      "[Epoch 59/100] [Batch 80/347] [D loss: 0.500660] [G loss: 0.273513]\n",
      "[Epoch 59/100] [Batch 81/347] [D loss: 0.500689] [G loss: 0.275580]\n",
      "[Epoch 59/100] [Batch 82/347] [D loss: 0.500738] [G loss: 0.278054]\n",
      "[Epoch 59/100] [Batch 83/347] [D loss: 0.500624] [G loss: 0.277063]\n",
      "[Epoch 59/100] [Batch 84/347] [D loss: 0.500630] [G loss: 0.280666]\n",
      "[Epoch 59/100] [Batch 85/347] [D loss: 0.500581] [G loss: 0.280562]\n",
      "[Epoch 59/100] [Batch 86/347] [D loss: 0.500541] [G loss: 0.279806]\n",
      "[Epoch 59/100] [Batch 87/347] [D loss: 0.500532] [G loss: 0.280309]\n",
      "[Epoch 59/100] [Batch 88/347] [D loss: 0.500518] [G loss: 0.280473]\n",
      "[Epoch 59/100] [Batch 89/347] [D loss: 0.500544] [G loss: 0.281987]\n",
      "[Epoch 59/100] [Batch 90/347] [D loss: 0.500507] [G loss: 0.281067]\n",
      "[Epoch 59/100] [Batch 91/347] [D loss: 0.500445] [G loss: 0.279275]\n",
      "[Epoch 59/100] [Batch 92/347] [D loss: 0.500431] [G loss: 0.279053]\n",
      "[Epoch 59/100] [Batch 93/347] [D loss: 0.500414] [G loss: 0.278687]\n",
      "[Epoch 59/100] [Batch 94/347] [D loss: 0.500306] [G loss: 0.274414]\n",
      "[Epoch 59/100] [Batch 95/347] [D loss: 0.500265] [G loss: 0.273001]\n",
      "[Epoch 59/100] [Batch 96/347] [D loss: 0.500278] [G loss: 0.273988]\n",
      "[Epoch 59/100] [Batch 97/347] [D loss: 0.500252] [G loss: 0.273136]\n",
      "[Epoch 59/100] [Batch 98/347] [D loss: 0.500274] [G loss: 0.274333]\n",
      "[Epoch 59/100] [Batch 99/347] [D loss: 0.500275] [G loss: 0.274445]\n",
      "[Epoch 59/100] [Batch 100/347] [D loss: 0.500264] [G loss: 0.273983]\n",
      "[Epoch 59/100] [Batch 101/347] [D loss: 0.500208] [G loss: 0.271708]\n",
      "[Epoch 59/100] [Batch 102/347] [D loss: 0.500109] [G loss: 0.268652]\n",
      "[Epoch 59/100] [Batch 103/347] [D loss: 0.500114] [G loss: 0.269390]\n",
      "[Epoch 59/100] [Batch 104/347] [D loss: 0.499974] [G loss: 0.264090]\n",
      "[Epoch 59/100] [Batch 105/347] [D loss: 0.499866] [G loss: 0.257340]\n",
      "[Epoch 59/100] [Batch 106/347] [D loss: 0.499705] [G loss: 0.259507]\n",
      "[Epoch 59/100] [Batch 107/347] [D loss: 0.499746] [G loss: 0.263431]\n",
      "[Epoch 59/100] [Batch 108/347] [D loss: 0.499789] [G loss: 0.265389]\n",
      "[Epoch 59/100] [Batch 109/347] [D loss: 0.499660] [G loss: 0.269453]\n",
      "[Epoch 59/100] [Batch 110/347] [D loss: 0.500004] [G loss: 0.265757]\n",
      "[Epoch 59/100] [Batch 111/347] [D loss: 0.500166] [G loss: 0.265932]\n",
      "[Epoch 59/100] [Batch 112/347] [D loss: 0.500335] [G loss: 0.268701]\n",
      "[Epoch 59/100] [Batch 113/347] [D loss: 0.500747] [G loss: 0.285646]\n",
      "[Epoch 59/100] [Batch 114/347] [D loss: 0.500884] [G loss: 0.292654]\n",
      "[Epoch 59/100] [Batch 115/347] [D loss: 0.500492] [G loss: 0.276055]\n",
      "[Epoch 59/100] [Batch 116/347] [D loss: 0.499995] [G loss: 0.259159]\n",
      "[Epoch 59/100] [Batch 117/347] [D loss: 0.499608] [G loss: 0.254137]\n",
      "[Epoch 59/100] [Batch 118/347] [D loss: 0.499212] [G loss: 0.266566]\n",
      "[Epoch 59/100] [Batch 119/347] [D loss: 0.499136] [G loss: 0.266447]\n",
      "[Epoch 59/100] [Batch 120/347] [D loss: 0.499349] [G loss: 0.259224]\n",
      "[Epoch 59/100] [Batch 121/347] [D loss: 0.499377] [G loss: 0.257930]\n",
      "[Epoch 59/100] [Batch 122/347] [D loss: 0.499488] [G loss: 0.257196]\n",
      "[Epoch 59/100] [Batch 123/347] [D loss: 0.499707] [G loss: 0.255799]\n",
      "[Epoch 59/100] [Batch 124/347] [D loss: 0.499811] [G loss: 0.258295]\n",
      "[Epoch 59/100] [Batch 125/347] [D loss: 0.499981] [G loss: 0.264333]\n",
      "[Epoch 59/100] [Batch 126/347] [D loss: 0.500105] [G loss: 0.268159]\n",
      "[Epoch 59/100] [Batch 127/347] [D loss: 0.500124] [G loss: 0.266623]\n",
      "[Epoch 59/100] [Batch 128/347] [D loss: 0.499911] [G loss: 0.258255]\n",
      "[Epoch 59/100] [Batch 129/347] [D loss: 0.499589] [G loss: 0.257352]\n",
      "[Epoch 59/100] [Batch 130/347] [D loss: 0.499117] [G loss: 0.271367]\n",
      "[Epoch 59/100] [Batch 131/347] [D loss: 0.498705] [G loss: 0.282824]\n",
      "[Epoch 59/100] [Batch 132/347] [D loss: 0.498119] [G loss: 0.302430]\n",
      "[Epoch 59/100] [Batch 133/347] [D loss: 0.497862] [G loss: 0.308153]\n",
      "[Epoch 59/100] [Batch 134/347] [D loss: 0.498333] [G loss: 0.293775]\n",
      "[Epoch 59/100] [Batch 135/347] [D loss: 0.498477] [G loss: 0.290829]\n",
      "[Epoch 59/100] [Batch 136/347] [D loss: 0.498650] [G loss: 0.283083]\n",
      "[Epoch 59/100] [Batch 137/347] [D loss: 0.498637] [G loss: 0.284645]\n",
      "[Epoch 59/100] [Batch 138/347] [D loss: 0.498011] [G loss: 0.303107]\n",
      "[Epoch 59/100] [Batch 139/347] [D loss: 0.497484] [G loss: 0.316743]\n",
      "[Epoch 59/100] [Batch 140/347] [D loss: 0.497164] [G loss: 0.327732]\n",
      "[Epoch 59/100] [Batch 141/347] [D loss: 0.496596] [G loss: 0.342487]\n",
      "[Epoch 59/100] [Batch 142/347] [D loss: 0.496420] [G loss: 0.345511]\n",
      "[Epoch 59/100] [Batch 143/347] [D loss: 0.496186] [G loss: 0.348483]\n",
      "[Epoch 59/100] [Batch 144/347] [D loss: 0.496263] [G loss: 0.341151]\n",
      "[Epoch 59/100] [Batch 145/347] [D loss: 0.496899] [G loss: 0.320588]\n",
      "[Epoch 59/100] [Batch 146/347] [D loss: 0.497231] [G loss: 0.308191]\n",
      "[Epoch 59/100] [Batch 147/347] [D loss: 0.497542] [G loss: 0.299235]\n",
      "[Epoch 59/100] [Batch 148/347] [D loss: 0.497882] [G loss: 0.292282]\n",
      "[Epoch 59/100] [Batch 149/347] [D loss: 0.497898] [G loss: 0.294897]\n",
      "[Epoch 59/100] [Batch 150/347] [D loss: 0.497741] [G loss: 0.302982]\n",
      "[Epoch 59/100] [Batch 151/347] [D loss: 0.497567] [G loss: 0.308754]\n",
      "[Epoch 59/100] [Batch 152/347] [D loss: 0.497234] [G loss: 0.316187]\n",
      "[Epoch 59/100] [Batch 153/347] [D loss: 0.497038] [G loss: 0.319166]\n",
      "[Epoch 59/100] [Batch 154/347] [D loss: 0.497169] [G loss: 0.314110]\n",
      "[Epoch 59/100] [Batch 155/347] [D loss: 0.497264] [G loss: 0.313220]\n",
      "[Epoch 59/100] [Batch 156/347] [D loss: 0.497111] [G loss: 0.317432]\n",
      "[Epoch 59/100] [Batch 157/347] [D loss: 0.497135] [G loss: 0.317170]\n",
      "[Epoch 59/100] [Batch 158/347] [D loss: 0.497099] [G loss: 0.319321]\n",
      "[Epoch 59/100] [Batch 159/347] [D loss: 0.497160] [G loss: 0.317693]\n",
      "[Epoch 59/100] [Batch 160/347] [D loss: 0.497571] [G loss: 0.309490]\n",
      "[Epoch 59/100] [Batch 161/347] [D loss: 0.497367] [G loss: 0.316660]\n",
      "[Epoch 59/100] [Batch 162/347] [D loss: 0.496932] [G loss: 0.327620]\n",
      "[Epoch 59/100] [Batch 163/347] [D loss: 0.496679] [G loss: 0.330279]\n",
      "[Epoch 59/100] [Batch 164/347] [D loss: 0.496985] [G loss: 0.320136]\n",
      "[Epoch 59/100] [Batch 165/347] [D loss: 0.497591] [G loss: 0.304553]\n",
      "[Epoch 59/100] [Batch 166/347] [D loss: 0.498571] [G loss: 0.278838]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 167/347] [D loss: 0.499448] [G loss: 0.255785]\n",
      "[Epoch 59/100] [Batch 168/347] [D loss: 0.499824] [G loss: 0.256356]\n",
      "[Epoch 59/100] [Batch 169/347] [D loss: 0.500131] [G loss: 0.258915]\n",
      "[Epoch 59/100] [Batch 170/347] [D loss: 0.500311] [G loss: 0.266249]\n",
      "[Epoch 59/100] [Batch 171/347] [D loss: 0.500282] [G loss: 0.266962]\n",
      "[Epoch 59/100] [Batch 172/347] [D loss: 0.500342] [G loss: 0.269042]\n",
      "[Epoch 59/100] [Batch 173/347] [D loss: 0.500282] [G loss: 0.268983]\n",
      "[Epoch 59/100] [Batch 174/347] [D loss: 0.500443] [G loss: 0.273923]\n",
      "[Epoch 59/100] [Batch 175/347] [D loss: 0.500579] [G loss: 0.279860]\n",
      "[Epoch 59/100] [Batch 176/347] [D loss: 0.500703] [G loss: 0.283887]\n",
      "[Epoch 59/100] [Batch 177/347] [D loss: 0.500629] [G loss: 0.281829]\n",
      "[Epoch 59/100] [Batch 178/347] [D loss: 0.500436] [G loss: 0.276734]\n",
      "[Epoch 59/100] [Batch 179/347] [D loss: 0.500313] [G loss: 0.273962]\n",
      "[Epoch 59/100] [Batch 180/347] [D loss: 0.500170] [G loss: 0.270610]\n",
      "[Epoch 59/100] [Batch 181/347] [D loss: 0.500256] [G loss: 0.273767]\n",
      "[Epoch 59/100] [Batch 182/347] [D loss: 0.500252] [G loss: 0.274912]\n",
      "[Epoch 59/100] [Batch 183/347] [D loss: 0.500312] [G loss: 0.276676]\n",
      "[Epoch 59/100] [Batch 184/347] [D loss: 0.500432] [G loss: 0.279277]\n",
      "[Epoch 59/100] [Batch 185/347] [D loss: 0.500343] [G loss: 0.276403]\n",
      "[Epoch 59/100] [Batch 186/347] [D loss: 0.500310] [G loss: 0.275332]\n",
      "[Epoch 59/100] [Batch 187/347] [D loss: 0.500220] [G loss: 0.272531]\n",
      "[Epoch 59/100] [Batch 188/347] [D loss: 0.499866] [G loss: 0.264674]\n",
      "[Epoch 59/100] [Batch 189/347] [D loss: 0.499610] [G loss: 0.260140]\n",
      "[Epoch 59/100] [Batch 190/347] [D loss: 0.499541] [G loss: 0.259740]\n",
      "[Epoch 59/100] [Batch 191/347] [D loss: 0.499439] [G loss: 0.261695]\n",
      "[Epoch 59/100] [Batch 192/347] [D loss: 0.499454] [G loss: 0.260904]\n",
      "[Epoch 59/100] [Batch 193/347] [D loss: 0.499479] [G loss: 0.261058]\n",
      "[Epoch 59/100] [Batch 194/347] [D loss: 0.499315] [G loss: 0.263944]\n",
      "[Epoch 59/100] [Batch 195/347] [D loss: 0.499222] [G loss: 0.264358]\n",
      "[Epoch 59/100] [Batch 196/347] [D loss: 0.499228] [G loss: 0.260220]\n",
      "[Epoch 59/100] [Batch 197/347] [D loss: 0.499265] [G loss: 0.257430]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 198/347] [D loss: 0.499437] [G loss: 0.253389]\n",
      "[Epoch 59/100] [Batch 199/347] [D loss: 0.499439] [G loss: 0.254503]\n",
      "[Epoch 59/100] [Batch 200/347] [D loss: 0.499356] [G loss: 0.259956]\n",
      "[Epoch 59/100] [Batch 201/347] [D loss: 0.499265] [G loss: 0.263867]\n",
      "[Epoch 59/100] [Batch 202/347] [D loss: 0.499156] [G loss: 0.268752]\n",
      "[Epoch 59/100] [Batch 203/347] [D loss: 0.499137] [G loss: 0.268835]\n",
      "[Epoch 59/100] [Batch 204/347] [D loss: 0.499418] [G loss: 0.259696]\n",
      "[Epoch 59/100] [Batch 205/347] [D loss: 0.499763] [G loss: 0.255289]\n",
      "[Epoch 59/100] [Batch 206/347] [D loss: 0.499909] [G loss: 0.258759]\n",
      "[Epoch 59/100] [Batch 207/347] [D loss: 0.500075] [G loss: 0.261256]\n",
      "[Epoch 59/100] [Batch 208/347] [D loss: 0.500284] [G loss: 0.265205]\n",
      "[Epoch 59/100] [Batch 209/347] [D loss: 0.500072] [G loss: 0.261181]\n",
      "[Epoch 59/100] [Batch 210/347] [D loss: 0.500185] [G loss: 0.262594]\n",
      "[Epoch 59/100] [Batch 211/347] [D loss: 0.500029] [G loss: 0.265909]\n",
      "[Epoch 59/100] [Batch 212/347] [D loss: 0.499513] [G loss: 0.268150]\n",
      "[Epoch 59/100] [Batch 213/347] [D loss: 0.499375] [G loss: 0.270725]\n",
      "[Epoch 59/100] [Batch 214/347] [D loss: 0.499381] [G loss: 0.270603]\n",
      "[Epoch 59/100] [Batch 215/347] [D loss: 0.499495] [G loss: 0.271948]\n",
      "[Epoch 59/100] [Batch 216/347] [D loss: 0.500172] [G loss: 0.267912]\n",
      "[Epoch 59/100] [Batch 217/347] [D loss: 0.500709] [G loss: 0.273435]\n",
      "[Epoch 59/100] [Batch 218/347] [D loss: 0.501194] [G loss: 0.288256]\n",
      "[Epoch 59/100] [Batch 219/347] [D loss: 0.501473] [G loss: 0.295126]\n",
      "[Epoch 59/100] [Batch 220/347] [D loss: 0.501681] [G loss: 0.299817]\n",
      "[Epoch 59/100] [Batch 221/347] [D loss: 0.501723] [G loss: 0.300753]\n",
      "[Epoch 59/100] [Batch 222/347] [D loss: 0.501503] [G loss: 0.293304]\n",
      "[Epoch 59/100] [Batch 223/347] [D loss: 0.500923] [G loss: 0.283907]\n",
      "[Epoch 59/100] [Batch 224/347] [D loss: 0.500093] [G loss: 0.274237]\n",
      "[Epoch 59/100] [Batch 225/347] [D loss: 0.499261] [G loss: 0.266070]\n",
      "[Epoch 59/100] [Batch 226/347] [D loss: 0.498626] [G loss: 0.275361]\n",
      "[Epoch 59/100] [Batch 227/347] [D loss: 0.498453] [G loss: 0.276273]\n",
      "[Epoch 59/100] [Batch 228/347] [D loss: 0.498499] [G loss: 0.279361]\n",
      "[Epoch 59/100] [Batch 229/347] [D loss: 0.498653] [G loss: 0.276216]\n",
      "[Epoch 59/100] [Batch 230/347] [D loss: 0.498821] [G loss: 0.271643]\n",
      "[Epoch 59/100] [Batch 231/347] [D loss: 0.498760] [G loss: 0.267285]\n",
      "[Epoch 59/100] [Batch 232/347] [D loss: 0.498841] [G loss: 0.267523]\n",
      "[Epoch 59/100] [Batch 233/347] [D loss: 0.499167] [G loss: 0.262707]\n",
      "[Epoch 59/100] [Batch 234/347] [D loss: 0.499421] [G loss: 0.258250]\n",
      "[Epoch 59/100] [Batch 235/347] [D loss: 0.499871] [G loss: 0.259740]\n",
      "[Epoch 59/100] [Batch 236/347] [D loss: 0.500203] [G loss: 0.262328]\n",
      "[Epoch 59/100] [Batch 237/347] [D loss: 0.500358] [G loss: 0.268354]\n",
      "[Epoch 59/100] [Batch 238/347] [D loss: 0.500306] [G loss: 0.267690]\n",
      "[Epoch 59/100] [Batch 239/347] [D loss: 0.500147] [G loss: 0.263733]\n",
      "[Epoch 59/100] [Batch 240/347] [D loss: 0.500063] [G loss: 0.261927]\n",
      "[Epoch 59/100] [Batch 241/347] [D loss: 0.500079] [G loss: 0.262917]\n",
      "[Epoch 59/100] [Batch 242/347] [D loss: 0.500213] [G loss: 0.265862]\n",
      "[Epoch 59/100] [Batch 243/347] [D loss: 0.500387] [G loss: 0.268154]\n",
      "[Epoch 59/100] [Batch 244/347] [D loss: 0.500095] [G loss: 0.262205]\n",
      "[Epoch 59/100] [Batch 245/347] [D loss: 0.499663] [G loss: 0.257040]\n",
      "[Epoch 59/100] [Batch 246/347] [D loss: 0.499100] [G loss: 0.264765]\n",
      "[Epoch 59/100] [Batch 247/347] [D loss: 0.498545] [G loss: 0.273841]\n",
      "[Epoch 59/100] [Batch 248/347] [D loss: 0.498751] [G loss: 0.271202]\n",
      "[Epoch 59/100] [Batch 249/347] [D loss: 0.499106] [G loss: 0.265236]\n",
      "[Epoch 59/100] [Batch 250/347] [D loss: 0.499605] [G loss: 0.260874]\n",
      "[Epoch 59/100] [Batch 251/347] [D loss: 0.500163] [G loss: 0.268219]\n",
      "[Epoch 59/100] [Batch 252/347] [D loss: 0.500391] [G loss: 0.269167]\n",
      "[Epoch 59/100] [Batch 253/347] [D loss: 0.500210] [G loss: 0.269171]\n",
      "[Epoch 59/100] [Batch 254/347] [D loss: 0.500382] [G loss: 0.271234]\n",
      "[Epoch 59/100] [Batch 255/347] [D loss: 0.500426] [G loss: 0.272085]\n",
      "[Epoch 59/100] [Batch 256/347] [D loss: 0.500184] [G loss: 0.270684]\n",
      "[Epoch 59/100] [Batch 257/347] [D loss: 0.499929] [G loss: 0.268330]\n",
      "[Epoch 59/100] [Batch 258/347] [D loss: 0.499457] [G loss: 0.264748]\n",
      "[Epoch 59/100] [Batch 259/347] [D loss: 0.499170] [G loss: 0.269073]\n",
      "[Epoch 59/100] [Batch 260/347] [D loss: 0.499085] [G loss: 0.269695]\n",
      "[Epoch 59/100] [Batch 261/347] [D loss: 0.499206] [G loss: 0.266786]\n",
      "[Epoch 59/100] [Batch 262/347] [D loss: 0.499163] [G loss: 0.266359]\n",
      "[Epoch 59/100] [Batch 263/347] [D loss: 0.499042] [G loss: 0.268641]\n",
      "[Epoch 59/100] [Batch 264/347] [D loss: 0.498934] [G loss: 0.270918]\n",
      "[Epoch 59/100] [Batch 265/347] [D loss: 0.498889] [G loss: 0.271340]\n",
      "[Epoch 59/100] [Batch 266/347] [D loss: 0.498914] [G loss: 0.271664]\n",
      "[Epoch 59/100] [Batch 267/347] [D loss: 0.498855] [G loss: 0.274388]\n",
      "[Epoch 59/100] [Batch 268/347] [D loss: 0.498854] [G loss: 0.274722]\n",
      "[Epoch 59/100] [Batch 269/347] [D loss: 0.498843] [G loss: 0.274777]\n",
      "[Epoch 59/100] [Batch 270/347] [D loss: 0.499015] [G loss: 0.269607]\n",
      "[Epoch 59/100] [Batch 271/347] [D loss: 0.498905] [G loss: 0.272409]\n",
      "[Epoch 59/100] [Batch 272/347] [D loss: 0.498002] [G loss: 0.285470]\n",
      "[Epoch 59/100] [Batch 273/347] [D loss: 0.498016] [G loss: 0.286736]\n",
      "[Epoch 59/100] [Batch 274/347] [D loss: 0.497901] [G loss: 0.288299]\n",
      "[Epoch 59/100] [Batch 275/347] [D loss: 0.498133] [G loss: 0.281146]\n",
      "[Epoch 59/100] [Batch 276/347] [D loss: 0.499328] [G loss: 0.257908]\n",
      "[Epoch 59/100] [Batch 277/347] [D loss: 0.499513] [G loss: 0.254747]\n",
      "[Epoch 59/100] [Batch 278/347] [D loss: 0.499662] [G loss: 0.255117]\n",
      "[Epoch 59/100] [Batch 279/347] [D loss: 0.499629] [G loss: 0.256915]\n",
      "[Epoch 59/100] [Batch 280/347] [D loss: 0.499539] [G loss: 0.257558]\n",
      "[Epoch 59/100] [Batch 281/347] [D loss: 0.499449] [G loss: 0.257049]\n",
      "[Epoch 59/100] [Batch 282/347] [D loss: 0.499490] [G loss: 0.256893]\n",
      "[Epoch 59/100] [Batch 283/347] [D loss: 0.499440] [G loss: 0.254694]\n",
      "[Epoch 59/100] [Batch 284/347] [D loss: 0.499449] [G loss: 0.253099]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 59/100] [Batch 285/347] [D loss: 0.499412] [G loss: 0.252312]\n",
      "[Epoch 59/100] [Batch 286/347] [D loss: 0.498783] [G loss: 0.265866]\n",
      "[Epoch 59/100] [Batch 287/347] [D loss: 0.498668] [G loss: 0.267800]\n",
      "[Epoch 59/100] [Batch 288/347] [D loss: 0.498570] [G loss: 0.269343]\n",
      "[Epoch 59/100] [Batch 289/347] [D loss: 0.498381] [G loss: 0.272772]\n",
      "[Epoch 59/100] [Batch 290/347] [D loss: 0.499104] [G loss: 0.255618]\n",
      "[Epoch 59/100] [Batch 291/347] [D loss: 0.499578] [G loss: 0.256234]\n",
      "[Epoch 59/100] [Batch 292/347] [D loss: 0.499888] [G loss: 0.263038]\n",
      "[Epoch 59/100] [Batch 293/347] [D loss: 0.500267] [G loss: 0.270020]\n",
      "[Epoch 59/100] [Batch 294/347] [D loss: 0.500565] [G loss: 0.273610]\n",
      "[Epoch 59/100] [Batch 295/347] [D loss: 0.500569] [G loss: 0.274720]\n",
      "[Epoch 59/100] [Batch 296/347] [D loss: 0.500539] [G loss: 0.276076]\n",
      "[Epoch 59/100] [Batch 297/347] [D loss: 0.500745] [G loss: 0.283372]\n",
      "[Epoch 59/100] [Batch 298/347] [D loss: 0.500606] [G loss: 0.279549]\n",
      "[Epoch 59/100] [Batch 299/347] [D loss: 0.500591] [G loss: 0.277289]\n",
      "[Epoch 59/100] [Batch 300/347] [D loss: 0.500641] [G loss: 0.277177]\n",
      "[Epoch 59/100] [Batch 301/347] [D loss: 0.500052] [G loss: 0.268169]\n",
      "[Epoch 59/100] [Batch 302/347] [D loss: 0.499742] [G loss: 0.260447]\n",
      "[Epoch 59/100] [Batch 303/347] [D loss: 0.499181] [G loss: 0.255480]\n",
      "[Epoch 59/100] [Batch 304/347] [D loss: 0.498687] [G loss: 0.265925]\n",
      "[Epoch 59/100] [Batch 305/347] [D loss: 0.498498] [G loss: 0.267907]\n",
      "[Epoch 59/100] [Batch 306/347] [D loss: 0.498540] [G loss: 0.267623]\n",
      "[Epoch 59/100] [Batch 307/347] [D loss: 0.498899] [G loss: 0.260605]\n",
      "[Epoch 59/100] [Batch 308/347] [D loss: 0.499330] [G loss: 0.252671]\n",
      "[Epoch 59/100] [Batch 309/347] [D loss: 0.499850] [G loss: 0.268101]\n",
      "[Epoch 59/100] [Batch 310/347] [D loss: 0.500335] [G loss: 0.282942]\n",
      "[Epoch 59/100] [Batch 311/347] [D loss: 0.500355] [G loss: 0.283133]\n",
      "[Epoch 59/100] [Batch 312/347] [D loss: 0.500373] [G loss: 0.280703]\n",
      "[Epoch 59/100] [Batch 313/347] [D loss: 0.500225] [G loss: 0.274094]\n",
      "[Epoch 59/100] [Batch 314/347] [D loss: 0.499744] [G loss: 0.261957]\n",
      "[Epoch 59/100] [Batch 315/347] [D loss: 0.499380] [G loss: 0.253042]\n",
      "[Epoch 59/100] [Batch 316/347] [D loss: 0.499497] [G loss: 0.256236]\n",
      "[Epoch 59/100] [Batch 317/347] [D loss: 0.499713] [G loss: 0.262083]\n",
      "[Epoch 59/100] [Batch 318/347] [D loss: 0.500349] [G loss: 0.277191]\n",
      "[Epoch 59/100] [Batch 319/347] [D loss: 0.500887] [G loss: 0.291072]\n",
      "[Epoch 59/100] [Batch 320/347] [D loss: 0.500888] [G loss: 0.291482]\n",
      "[Epoch 59/100] [Batch 321/347] [D loss: 0.500747] [G loss: 0.286719]\n",
      "[Epoch 59/100] [Batch 322/347] [D loss: 0.500566] [G loss: 0.281403]\n",
      "[Epoch 59/100] [Batch 323/347] [D loss: 0.500363] [G loss: 0.274800]\n",
      "[Epoch 59/100] [Batch 324/347] [D loss: 0.500214] [G loss: 0.270572]\n",
      "[Epoch 59/100] [Batch 325/347] [D loss: 0.500002] [G loss: 0.265037]\n",
      "[Epoch 59/100] [Batch 326/347] [D loss: 0.499724] [G loss: 0.258496]\n",
      "[Epoch 59/100] [Batch 327/347] [D loss: 0.499195] [G loss: 0.257589]\n",
      "[Epoch 59/100] [Batch 328/347] [D loss: 0.498879] [G loss: 0.265170]\n",
      "[Epoch 59/100] [Batch 329/347] [D loss: 0.498908] [G loss: 0.263486]\n",
      "[Epoch 59/100] [Batch 330/347] [D loss: 0.499098] [G loss: 0.258175]\n",
      "[Epoch 59/100] [Batch 331/347] [D loss: 0.499653] [G loss: 0.257617]\n",
      "[Epoch 59/100] [Batch 332/347] [D loss: 0.500373] [G loss: 0.278233]\n",
      "[Epoch 59/100] [Batch 333/347] [D loss: 0.500393] [G loss: 0.277409]\n",
      "[Epoch 59/100] [Batch 334/347] [D loss: 0.500242] [G loss: 0.271634]\n",
      "[Epoch 59/100] [Batch 335/347] [D loss: 0.500220] [G loss: 0.270620]\n",
      "[Epoch 59/100] [Batch 336/347] [D loss: 0.500181] [G loss: 0.270470]\n",
      "[Epoch 59/100] [Batch 337/347] [D loss: 0.500309] [G loss: 0.275346]\n",
      "[Epoch 59/100] [Batch 338/347] [D loss: 0.500571] [G loss: 0.283884]\n",
      "[Epoch 59/100] [Batch 339/347] [D loss: 0.500641] [G loss: 0.284787]\n",
      "[Epoch 59/100] [Batch 340/347] [D loss: 0.500513] [G loss: 0.281734]\n",
      "[Epoch 59/100] [Batch 341/347] [D loss: 0.500494] [G loss: 0.282369]\n",
      "[Epoch 59/100] [Batch 342/347] [D loss: 0.500067] [G loss: 0.270586]\n",
      "[Epoch 59/100] [Batch 343/347] [D loss: 0.499495] [G loss: 0.255616]\n",
      "[Epoch 59/100] [Batch 344/347] [D loss: 0.498935] [G loss: 0.261463]\n",
      "[Epoch 59/100] [Batch 345/347] [D loss: 0.498392] [G loss: 0.276283]\n",
      "[Epoch 59/100] [Batch 346/347] [D loss: 0.498405] [G loss: 0.276262]\n",
      "[Epoch 59/100] [Batch 347/347] [D loss: 0.498615] [G loss: 0.270567]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 60/100] [Batch 1/347] [D loss: 0.499719] [G loss: 0.265991]\n",
      "[Epoch 60/100] [Batch 2/347] [D loss: 0.499675] [G loss: 0.266574]\n",
      "[Epoch 60/100] [Batch 3/347] [D loss: 0.499803] [G loss: 0.270765]\n",
      "[Epoch 60/100] [Batch 4/347] [D loss: 0.499782] [G loss: 0.271038]\n",
      "[Epoch 60/100] [Batch 5/347] [D loss: 0.499660] [G loss: 0.267593]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 60/100] [Batch 6/347] [D loss: 0.499588] [G loss: 0.264531]\n",
      "[Epoch 60/100] [Batch 7/347] [D loss: 0.499289] [G loss: 0.265473]\n",
      "[Epoch 60/100] [Batch 8/347] [D loss: 0.499232] [G loss: 0.265699]\n",
      "[Epoch 60/100] [Batch 9/347] [D loss: 0.499252] [G loss: 0.266344]\n",
      "[Epoch 60/100] [Batch 10/347] [D loss: 0.499235] [G loss: 0.268523]\n",
      "[Epoch 60/100] [Batch 11/347] [D loss: 0.499555] [G loss: 0.267428]\n",
      "[Epoch 60/100] [Batch 12/347] [D loss: 0.499650] [G loss: 0.267821]\n",
      "[Epoch 60/100] [Batch 13/347] [D loss: 0.499643] [G loss: 0.266719]\n",
      "[Epoch 60/100] [Batch 14/347] [D loss: 0.499693] [G loss: 0.265924]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 60/100] [Batch 15/347] [D loss: 0.499388] [G loss: 0.261127]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 60/100] [Batch 16/347] [D loss: 0.499236] [G loss: 0.259477]\n",
      "[Epoch 60/100] [Batch 17/347] [D loss: 0.499345] [G loss: 0.257274]\n",
      "[Epoch 60/100] [Batch 18/347] [D loss: 0.499366] [G loss: 0.258319]\n",
      "[Epoch 60/100] [Batch 19/347] [D loss: 0.499531] [G loss: 0.258802]\n",
      "[Epoch 60/100] [Batch 20/347] [D loss: 0.499661] [G loss: 0.263032]\n",
      "[Epoch 60/100] [Batch 21/347] [D loss: 0.499512] [G loss: 0.260529]\n",
      "[Epoch 60/100] [Batch 22/347] [D loss: 0.499489] [G loss: 0.258753]\n",
      "[Epoch 60/100] [Batch 23/347] [D loss: 0.499391] [G loss: 0.258405]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 60/100] [Batch 24/347] [D loss: 0.499156] [G loss: 0.257384]\n",
      "[Epoch 60/100] [Batch 25/347] [D loss: 0.499279] [G loss: 0.255578]\n",
      "[Epoch 60/100] [Batch 26/347] [D loss: 0.499309] [G loss: 0.256025]\n",
      "[Epoch 60/100] [Batch 27/347] [D loss: 0.499639] [G loss: 0.258850]\n",
      "[Epoch 60/100] [Batch 28/347] [D loss: 0.500119] [G loss: 0.266343]\n",
      "[Epoch 60/100] [Batch 29/347] [D loss: 0.500448] [G loss: 0.272587]\n",
      "[Epoch 60/100] [Batch 30/347] [D loss: 0.500542] [G loss: 0.274524]\n",
      "[Epoch 60/100] [Batch 31/347] [D loss: 0.500533] [G loss: 0.274839]\n",
      "[Epoch 60/100] [Batch 32/347] [D loss: 0.500444] [G loss: 0.272046]\n",
      "[Epoch 60/100] [Batch 33/347] [D loss: 0.500323] [G loss: 0.270309]\n",
      "[Epoch 60/100] [Batch 34/347] [D loss: 0.500118] [G loss: 0.265788]\n",
      "[Epoch 60/100] [Batch 35/347] [D loss: 0.499611] [G loss: 0.258252]\n",
      "[Epoch 60/100] [Batch 36/347] [D loss: 0.499131] [G loss: 0.261260]\n",
      "[Epoch 60/100] [Batch 37/347] [D loss: 0.498840] [G loss: 0.265988]\n",
      "[Epoch 60/100] [Batch 38/347] [D loss: 0.498547] [G loss: 0.270263]\n",
      "[Epoch 60/100] [Batch 39/347] [D loss: 0.498637] [G loss: 0.268296]\n",
      "[Epoch 60/100] [Batch 40/347] [D loss: 0.498884] [G loss: 0.266746]\n",
      "[Epoch 60/100] [Batch 41/347] [D loss: 0.499203] [G loss: 0.257196]\n",
      "[Epoch 60/100] [Batch 42/347] [D loss: 0.499745] [G loss: 0.255262]\n",
      "[Epoch 60/100] [Batch 43/347] [D loss: 0.500449] [G loss: 0.270769]\n",
      "[Epoch 60/100] [Batch 44/347] [D loss: 0.500701] [G loss: 0.276788]\n",
      "[Epoch 60/100] [Batch 45/347] [D loss: 0.500426] [G loss: 0.268915]\n",
      "[Epoch 60/100] [Batch 46/347] [D loss: 0.499625] [G loss: 0.262672]\n",
      "[Epoch 60/100] [Batch 47/347] [D loss: 0.498956] [G loss: 0.268084]\n",
      "[Epoch 60/100] [Batch 48/347] [D loss: 0.498104] [G loss: 0.290293]\n",
      "[Epoch 60/100] [Batch 49/347] [D loss: 0.498302] [G loss: 0.286376]\n",
      "[Epoch 60/100] [Batch 50/347] [D loss: 0.498853] [G loss: 0.273022]\n",
      "[Epoch 60/100] [Batch 51/347] [D loss: 0.498955] [G loss: 0.271533]\n",
      "[Epoch 60/100] [Batch 52/347] [D loss: 0.498654] [G loss: 0.278430]\n",
      "[Epoch 60/100] [Batch 53/347] [D loss: 0.497860] [G loss: 0.294633]\n",
      "[Epoch 60/100] [Batch 54/347] [D loss: 0.497303] [G loss: 0.305275]\n",
      "[Epoch 60/100] [Batch 55/347] [D loss: 0.497456] [G loss: 0.302119]\n",
      "[Epoch 60/100] [Batch 56/347] [D loss: 0.498214] [G loss: 0.284552]\n",
      "[Epoch 60/100] [Batch 57/347] [D loss: 0.498941] [G loss: 0.269638]\n",
      "[Epoch 60/100] [Batch 58/347] [D loss: 0.499345] [G loss: 0.265453]\n",
      "[Epoch 60/100] [Batch 59/347] [D loss: 0.498849] [G loss: 0.277498]\n",
      "[Epoch 60/100] [Batch 60/347] [D loss: 0.497818] [G loss: 0.300141]\n",
      "[Epoch 60/100] [Batch 61/347] [D loss: 0.497408] [G loss: 0.305642]\n",
      "[Epoch 60/100] [Batch 62/347] [D loss: 0.497713] [G loss: 0.297370]\n",
      "[Epoch 60/100] [Batch 63/347] [D loss: 0.498287] [G loss: 0.283051]\n",
      "[Epoch 60/100] [Batch 64/347] [D loss: 0.499005] [G loss: 0.265847]\n",
      "[Epoch 60/100] [Batch 65/347] [D loss: 0.499716] [G loss: 0.266840]\n",
      "[Epoch 60/100] [Batch 66/347] [D loss: 0.499121] [G loss: 0.266155]\n",
      "[Epoch 60/100] [Batch 67/347] [D loss: 0.498096] [G loss: 0.287453]\n",
      "[Epoch 60/100] [Batch 68/347] [D loss: 0.497700] [G loss: 0.293991]\n",
      "[Epoch 60/100] [Batch 69/347] [D loss: 0.497182] [G loss: 0.305583]\n",
      "[Epoch 60/100] [Batch 70/347] [D loss: 0.497091] [G loss: 0.304740]\n",
      "[Epoch 60/100] [Batch 71/347] [D loss: 0.497728] [G loss: 0.292469]\n",
      "[Epoch 60/100] [Batch 72/347] [D loss: 0.497978] [G loss: 0.290796]\n",
      "[Epoch 60/100] [Batch 73/347] [D loss: 0.497892] [G loss: 0.291997]\n",
      "[Epoch 60/100] [Batch 74/347] [D loss: 0.498201] [G loss: 0.284560]\n",
      "[Epoch 60/100] [Batch 75/347] [D loss: 0.498388] [G loss: 0.281231]\n",
      "[Epoch 60/100] [Batch 76/347] [D loss: 0.498767] [G loss: 0.272098]\n",
      "[Epoch 60/100] [Batch 77/347] [D loss: 0.499790] [G loss: 0.264084]\n",
      "[Epoch 60/100] [Batch 78/347] [D loss: 0.500556] [G loss: 0.269238]\n",
      "[Epoch 60/100] [Batch 79/347] [D loss: 0.500936] [G loss: 0.278195]\n",
      "[Epoch 60/100] [Batch 80/347] [D loss: 0.500703] [G loss: 0.273406]\n",
      "[Epoch 60/100] [Batch 81/347] [D loss: 0.500741] [G loss: 0.275543]\n",
      "[Epoch 60/100] [Batch 82/347] [D loss: 0.500797] [G loss: 0.278125]\n",
      "[Epoch 60/100] [Batch 83/347] [D loss: 0.500667] [G loss: 0.277225]\n",
      "[Epoch 60/100] [Batch 84/347] [D loss: 0.500692] [G loss: 0.280885]\n",
      "[Epoch 60/100] [Batch 85/347] [D loss: 0.500633] [G loss: 0.280839]\n",
      "[Epoch 60/100] [Batch 86/347] [D loss: 0.500584] [G loss: 0.280133]\n",
      "[Epoch 60/100] [Batch 87/347] [D loss: 0.500578] [G loss: 0.280676]\n",
      "[Epoch 60/100] [Batch 88/347] [D loss: 0.500562] [G loss: 0.280902]\n",
      "[Epoch 60/100] [Batch 89/347] [D loss: 0.500600] [G loss: 0.282427]\n",
      "[Epoch 60/100] [Batch 90/347] [D loss: 0.500550] [G loss: 0.281475]\n",
      "[Epoch 60/100] [Batch 91/347] [D loss: 0.500467] [G loss: 0.279716]\n",
      "[Epoch 60/100] [Batch 92/347] [D loss: 0.500454] [G loss: 0.279447]\n",
      "[Epoch 60/100] [Batch 93/347] [D loss: 0.500429] [G loss: 0.279029]\n",
      "[Epoch 60/100] [Batch 94/347] [D loss: 0.500286] [G loss: 0.274742]\n",
      "[Epoch 60/100] [Batch 95/347] [D loss: 0.500236] [G loss: 0.273286]\n",
      "[Epoch 60/100] [Batch 96/347] [D loss: 0.500255] [G loss: 0.274239]\n",
      "[Epoch 60/100] [Batch 97/347] [D loss: 0.500222] [G loss: 0.273358]\n",
      "[Epoch 60/100] [Batch 98/347] [D loss: 0.500250] [G loss: 0.274494]\n",
      "[Epoch 60/100] [Batch 99/347] [D loss: 0.500257] [G loss: 0.274570]\n",
      "[Epoch 60/100] [Batch 100/347] [D loss: 0.500243] [G loss: 0.274082]\n",
      "[Epoch 60/100] [Batch 101/347] [D loss: 0.500167] [G loss: 0.271829]\n",
      "[Epoch 60/100] [Batch 102/347] [D loss: 0.500046] [G loss: 0.268767]\n",
      "[Epoch 60/100] [Batch 103/347] [D loss: 0.500062] [G loss: 0.269521]\n",
      "[Epoch 60/100] [Batch 104/347] [D loss: 0.499878] [G loss: 0.264239]\n",
      "[Epoch 60/100] [Batch 105/347] [D loss: 0.499717] [G loss: 0.257487]\n",
      "[Epoch 60/100] [Batch 106/347] [D loss: 0.499424] [G loss: 0.259725]\n",
      "[Epoch 60/100] [Batch 107/347] [D loss: 0.499479] [G loss: 0.263640]\n",
      "[Epoch 60/100] [Batch 108/347] [D loss: 0.499523] [G loss: 0.265611]\n",
      "[Epoch 60/100] [Batch 109/347] [D loss: 0.499315] [G loss: 0.269661]\n",
      "[Epoch 60/100] [Batch 110/347] [D loss: 0.499844] [G loss: 0.266008]\n",
      "[Epoch 60/100] [Batch 111/347] [D loss: 0.500060] [G loss: 0.266208]\n",
      "[Epoch 60/100] [Batch 112/347] [D loss: 0.500279] [G loss: 0.269000]\n",
      "[Epoch 60/100] [Batch 113/347] [D loss: 0.500864] [G loss: 0.285897]\n",
      "[Epoch 60/100] [Batch 114/347] [D loss: 0.501059] [G loss: 0.292975]\n",
      "[Epoch 60/100] [Batch 115/347] [D loss: 0.500535] [G loss: 0.276445]\n",
      "[Epoch 60/100] [Batch 116/347] [D loss: 0.499875] [G loss: 0.259761]\n",
      "[Epoch 60/100] [Batch 117/347] [D loss: 0.499379] [G loss: 0.253144]\n",
      "[Epoch 60/100] [Batch 118/347] [D loss: 0.498860] [G loss: 0.265576]\n",
      "[Epoch 60/100] [Batch 119/347] [D loss: 0.498778] [G loss: 0.265435]\n",
      "[Epoch 60/100] [Batch 120/347] [D loss: 0.499059] [G loss: 0.258164]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 60/100] [Batch 121/347] [D loss: 0.499093] [G loss: 0.256841]\n",
      "[Epoch 60/100] [Batch 122/347] [D loss: 0.499253] [G loss: 0.255822]\n",
      "[Epoch 60/100] [Batch 123/347] [D loss: 0.499541] [G loss: 0.256401]\n",
      "[Epoch 60/100] [Batch 124/347] [D loss: 0.499664] [G loss: 0.258893]\n",
      "[Epoch 60/100] [Batch 125/347] [D loss: 0.499885] [G loss: 0.264934]\n",
      "[Epoch 60/100] [Batch 126/347] [D loss: 0.500044] [G loss: 0.268789]\n",
      "[Epoch 60/100] [Batch 127/347] [D loss: 0.500069] [G loss: 0.267251]\n",
      "[Epoch 60/100] [Batch 128/347] [D loss: 0.499772] [G loss: 0.258928]\n",
      "[Epoch 60/100] [Batch 129/347] [D loss: 0.499312] [G loss: 0.258301]\n",
      "[Epoch 60/100] [Batch 130/347] [D loss: 0.498590] [G loss: 0.270141]\n",
      "[Epoch 60/100] [Batch 131/347] [D loss: 0.498032] [G loss: 0.281537]\n",
      "[Epoch 60/100] [Batch 132/347] [D loss: 0.497183] [G loss: 0.301092]\n",
      "[Epoch 60/100] [Batch 133/347] [D loss: 0.496750] [G loss: 0.306686]\n",
      "[Epoch 60/100] [Batch 134/347] [D loss: 0.497383] [G loss: 0.292209]\n",
      "[Epoch 60/100] [Batch 135/347] [D loss: 0.497602] [G loss: 0.289130]\n",
      "[Epoch 60/100] [Batch 136/347] [D loss: 0.497896] [G loss: 0.281229]\n",
      "[Epoch 60/100] [Batch 137/347] [D loss: 0.498040] [G loss: 0.282716]\n",
      "[Epoch 60/100] [Batch 138/347] [D loss: 0.497231] [G loss: 0.301089]\n",
      "[Epoch 60/100] [Batch 139/347] [D loss: 0.496542] [G loss: 0.314620]\n",
      "[Epoch 60/100] [Batch 140/347] [D loss: 0.496115] [G loss: 0.325574]\n",
      "[Epoch 60/100] [Batch 141/347] [D loss: 0.495338] [G loss: 0.340254]\n",
      "[Epoch 60/100] [Batch 142/347] [D loss: 0.495126] [G loss: 0.343143]\n",
      "[Epoch 60/100] [Batch 143/347] [D loss: 0.494816] [G loss: 0.346015]\n",
      "[Epoch 60/100] [Batch 144/347] [D loss: 0.494932] [G loss: 0.338535]\n",
      "[Epoch 60/100] [Batch 145/347] [D loss: 0.495792] [G loss: 0.317884]\n",
      "[Epoch 60/100] [Batch 146/347] [D loss: 0.496240] [G loss: 0.305407]\n",
      "[Epoch 60/100] [Batch 147/347] [D loss: 0.496670] [G loss: 0.296419]\n",
      "[Epoch 60/100] [Batch 148/347] [D loss: 0.497132] [G loss: 0.289325]\n",
      "[Epoch 60/100] [Batch 149/347] [D loss: 0.497126] [G loss: 0.291947]\n",
      "[Epoch 60/100] [Batch 150/347] [D loss: 0.496902] [G loss: 0.299983]\n",
      "[Epoch 60/100] [Batch 151/347] [D loss: 0.496651] [G loss: 0.305764]\n",
      "[Epoch 60/100] [Batch 152/347] [D loss: 0.496195] [G loss: 0.313207]\n",
      "[Epoch 60/100] [Batch 153/347] [D loss: 0.495933] [G loss: 0.316192]\n",
      "[Epoch 60/100] [Batch 154/347] [D loss: 0.496109] [G loss: 0.311129]\n",
      "[Epoch 60/100] [Batch 155/347] [D loss: 0.496202] [G loss: 0.310248]\n",
      "[Epoch 60/100] [Batch 156/347] [D loss: 0.495988] [G loss: 0.314414]\n",
      "[Epoch 60/100] [Batch 157/347] [D loss: 0.495996] [G loss: 0.314104]\n",
      "[Epoch 60/100] [Batch 158/347] [D loss: 0.495888] [G loss: 0.316215]\n",
      "[Epoch 60/100] [Batch 159/347] [D loss: 0.495953] [G loss: 0.314562]\n",
      "[Epoch 60/100] [Batch 160/347] [D loss: 0.496516] [G loss: 0.306278]\n",
      "[Epoch 60/100] [Batch 161/347] [D loss: 0.496194] [G loss: 0.313420]\n",
      "[Epoch 60/100] [Batch 162/347] [D loss: 0.495585] [G loss: 0.324281]\n",
      "[Epoch 60/100] [Batch 163/347] [D loss: 0.495261] [G loss: 0.326794]\n",
      "[Epoch 60/100] [Batch 164/347] [D loss: 0.495657] [G loss: 0.316508]\n",
      "[Epoch 60/100] [Batch 165/347] [D loss: 0.496471] [G loss: 0.300863]\n",
      "[Epoch 60/100] [Batch 166/347] [D loss: 0.497884] [G loss: 0.275052]\n",
      "[Epoch 60/100] [Batch 167/347] [D loss: 0.499140] [G loss: 0.251969]\n",
      "[Epoch 60/100] [Batch 168/347] [D loss: 0.499654] [G loss: 0.255385]\n",
      "[Epoch 60/100] [Batch 169/347] [D loss: 0.500130] [G loss: 0.257644]\n",
      "[Epoch 60/100] [Batch 170/347] [D loss: 0.500407] [G loss: 0.265092]\n",
      "[Epoch 60/100] [Batch 171/347] [D loss: 0.500370] [G loss: 0.265987]\n",
      "[Epoch 60/100] [Batch 172/347] [D loss: 0.500452] [G loss: 0.268291]\n",
      "[Epoch 60/100] [Batch 173/347] [D loss: 0.500379] [G loss: 0.268536]\n",
      "[Epoch 60/100] [Batch 174/347] [D loss: 0.500592] [G loss: 0.273687]\n",
      "[Epoch 60/100] [Batch 175/347] [D loss: 0.500793] [G loss: 0.279951]\n",
      "[Epoch 60/100] [Batch 176/347] [D loss: 0.500967] [G loss: 0.284286]\n",
      "[Epoch 60/100] [Batch 177/347] [D loss: 0.500850] [G loss: 0.282556]\n",
      "[Epoch 60/100] [Batch 178/347] [D loss: 0.500592] [G loss: 0.277735]\n",
      "[Epoch 60/100] [Batch 179/347] [D loss: 0.500431] [G loss: 0.275200]\n",
      "[Epoch 60/100] [Batch 180/347] [D loss: 0.500220] [G loss: 0.272157]\n",
      "[Epoch 60/100] [Batch 181/347] [D loss: 0.500352] [G loss: 0.275522]\n",
      "[Epoch 60/100] [Batch 182/347] [D loss: 0.500345] [G loss: 0.276876]\n",
      "[Epoch 60/100] [Batch 183/347] [D loss: 0.500438] [G loss: 0.278903]\n",
      "[Epoch 60/100] [Batch 184/347] [D loss: 0.500607] [G loss: 0.281634]\n",
      "[Epoch 60/100] [Batch 185/347] [D loss: 0.500502] [G loss: 0.278918]\n",
      "[Epoch 60/100] [Batch 186/347] [D loss: 0.500447] [G loss: 0.277981]\n",
      "[Epoch 60/100] [Batch 187/347] [D loss: 0.500320] [G loss: 0.275294]\n",
      "[Epoch 60/100] [Batch 188/347] [D loss: 0.499823] [G loss: 0.267486]\n",
      "[Epoch 60/100] [Batch 189/347] [D loss: 0.499473] [G loss: 0.261319]\n",
      "[Epoch 60/100] [Batch 190/347] [D loss: 0.499367] [G loss: 0.259365]\n",
      "[Epoch 60/100] [Batch 191/347] [D loss: 0.499210] [G loss: 0.261468]\n",
      "[Epoch 60/100] [Batch 192/347] [D loss: 0.499229] [G loss: 0.260749]\n",
      "[Epoch 60/100] [Batch 193/347] [D loss: 0.499266] [G loss: 0.260902]\n",
      "[Epoch 60/100] [Batch 194/347] [D loss: 0.499036] [G loss: 0.263793]\n",
      "[Epoch 60/100] [Batch 195/347] [D loss: 0.498882] [G loss: 0.264174]\n",
      "[Epoch 60/100] [Batch 196/347] [D loss: 0.498874] [G loss: 0.259969]\n",
      "[Epoch 60/100] [Batch 197/347] [D loss: 0.498910] [G loss: 0.257082]\n",
      "[Epoch 60/100] [Batch 198/347] [D loss: 0.499129] [G loss: 0.252932]\n",
      "[Epoch 60/100] [Batch 199/347] [D loss: 0.499129] [G loss: 0.253918]\n",
      "[Epoch 60/100] [Batch 200/347] [D loss: 0.499029] [G loss: 0.259269]\n",
      "[Epoch 60/100] [Batch 201/347] [D loss: 0.498910] [G loss: 0.263123]\n",
      "[Epoch 60/100] [Batch 202/347] [D loss: 0.498776] [G loss: 0.267914]\n",
      "[Epoch 60/100] [Batch 203/347] [D loss: 0.498737] [G loss: 0.267931]\n",
      "[Epoch 60/100] [Batch 204/347] [D loss: 0.499104] [G loss: 0.258727]\n",
      "[Epoch 60/100] [Batch 205/347] [D loss: 0.499565] [G loss: 0.254858]\n",
      "[Epoch 60/100] [Batch 206/347] [D loss: 0.499769] [G loss: 0.258260]\n",
      "[Epoch 60/100] [Batch 207/347] [D loss: 0.499982] [G loss: 0.260759]\n",
      "[Epoch 60/100] [Batch 208/347] [D loss: 0.500258] [G loss: 0.264722]\n",
      "[Epoch 60/100] [Batch 209/347] [D loss: 0.499977] [G loss: 0.260742]\n",
      "[Epoch 60/100] [Batch 210/347] [D loss: 0.500099] [G loss: 0.262234]\n",
      "[Epoch 60/100] [Batch 211/347] [D loss: 0.499829] [G loss: 0.265702]\n",
      "[Epoch 60/100] [Batch 212/347] [D loss: 0.498951] [G loss: 0.267976]\n",
      "[Epoch 60/100] [Batch 213/347] [D loss: 0.498732] [G loss: 0.270604]\n",
      "[Epoch 60/100] [Batch 214/347] [D loss: 0.498751] [G loss: 0.270508]\n",
      "[Epoch 60/100] [Batch 215/347] [D loss: 0.498912] [G loss: 0.271895]\n",
      "[Epoch 60/100] [Batch 216/347] [D loss: 0.500054] [G loss: 0.267930]\n",
      "[Epoch 60/100] [Batch 217/347] [D loss: 0.500830] [G loss: 0.273465]\n",
      "[Epoch 60/100] [Batch 218/347] [D loss: 0.501522] [G loss: 0.288393]\n",
      "[Epoch 60/100] [Batch 219/347] [D loss: 0.501906] [G loss: 0.295383]\n",
      "[Epoch 60/100] [Batch 220/347] [D loss: 0.502193] [G loss: 0.300177]\n",
      "[Epoch 60/100] [Batch 221/347] [D loss: 0.502243] [G loss: 0.301213]\n",
      "[Epoch 60/100] [Batch 222/347] [D loss: 0.501934] [G loss: 0.293872]\n",
      "[Epoch 60/100] [Batch 223/347] [D loss: 0.501084] [G loss: 0.284636]\n",
      "[Epoch 60/100] [Batch 224/347] [D loss: 0.499910] [G loss: 0.275007]\n",
      "[Epoch 60/100] [Batch 225/347] [D loss: 0.498791] [G loss: 0.266283]\n",
      "[Epoch 60/100] [Batch 226/347] [D loss: 0.497956] [G loss: 0.275528]\n",
      "[Epoch 60/100] [Batch 227/347] [D loss: 0.497744] [G loss: 0.276274]\n",
      "[Epoch 60/100] [Batch 228/347] [D loss: 0.497818] [G loss: 0.279222]\n",
      "[Epoch 60/100] [Batch 229/347] [D loss: 0.498044] [G loss: 0.275902]\n",
      "[Epoch 60/100] [Batch 230/347] [D loss: 0.498271] [G loss: 0.271182]\n",
      "[Epoch 60/100] [Batch 231/347] [D loss: 0.498162] [G loss: 0.266775]\n",
      "[Epoch 60/100] [Batch 232/347] [D loss: 0.498269] [G loss: 0.266870]\n",
      "[Epoch 60/100] [Batch 233/347] [D loss: 0.498682] [G loss: 0.261895]\n",
      "[Epoch 60/100] [Batch 234/347] [D loss: 0.499013] [G loss: 0.257287]\n",
      "[Epoch 60/100] [Batch 235/347] [D loss: 0.499651] [G loss: 0.259786]\n",
      "[Epoch 60/100] [Batch 236/347] [D loss: 0.500140] [G loss: 0.262159]\n",
      "[Epoch 60/100] [Batch 237/347] [D loss: 0.500376] [G loss: 0.268151]\n",
      "[Epoch 60/100] [Batch 238/347] [D loss: 0.500325] [G loss: 0.267479]\n",
      "[Epoch 60/100] [Batch 239/347] [D loss: 0.500107] [G loss: 0.263528]\n",
      "[Epoch 60/100] [Batch 240/347] [D loss: 0.499995] [G loss: 0.261777]\n",
      "[Epoch 60/100] [Batch 241/347] [D loss: 0.500021] [G loss: 0.262846]\n",
      "[Epoch 60/100] [Batch 242/347] [D loss: 0.500203] [G loss: 0.265898]\n",
      "[Epoch 60/100] [Batch 243/347] [D loss: 0.500441] [G loss: 0.268302]\n",
      "[Epoch 60/100] [Batch 244/347] [D loss: 0.499994] [G loss: 0.262619]\n",
      "[Epoch 60/100] [Batch 245/347] [D loss: 0.499375] [G loss: 0.257603]\n",
      "[Epoch 60/100] [Batch 246/347] [D loss: 0.498592] [G loss: 0.264021]\n",
      "[Epoch 60/100] [Batch 247/347] [D loss: 0.497844] [G loss: 0.273167]\n",
      "[Epoch 60/100] [Batch 248/347] [D loss: 0.498123] [G loss: 0.270557]\n",
      "[Epoch 60/100] [Batch 249/347] [D loss: 0.498607] [G loss: 0.264592]\n",
      "[Epoch 60/100] [Batch 250/347] [D loss: 0.499289] [G loss: 0.261879]\n",
      "[Epoch 60/100] [Batch 251/347] [D loss: 0.500081] [G loss: 0.269254]\n",
      "[Epoch 60/100] [Batch 252/347] [D loss: 0.500408] [G loss: 0.270215]\n",
      "[Epoch 60/100] [Batch 253/347] [D loss: 0.500124] [G loss: 0.270230]\n",
      "[Epoch 60/100] [Batch 254/347] [D loss: 0.500359] [G loss: 0.272306]\n",
      "[Epoch 60/100] [Batch 255/347] [D loss: 0.500416] [G loss: 0.273227]\n",
      "[Epoch 60/100] [Batch 256/347] [D loss: 0.500063] [G loss: 0.271831]\n",
      "[Epoch 60/100] [Batch 257/347] [D loss: 0.499709] [G loss: 0.269480]\n",
      "[Epoch 60/100] [Batch 258/347] [D loss: 0.499041] [G loss: 0.265898]\n",
      "[Epoch 60/100] [Batch 259/347] [D loss: 0.498658] [G loss: 0.268164]\n",
      "[Epoch 60/100] [Batch 260/347] [D loss: 0.498550] [G loss: 0.268692]\n",
      "[Epoch 60/100] [Batch 261/347] [D loss: 0.498715] [G loss: 0.265704]\n",
      "[Epoch 60/100] [Batch 262/347] [D loss: 0.498630] [G loss: 0.265237]\n",
      "[Epoch 60/100] [Batch 263/347] [D loss: 0.498452] [G loss: 0.267456]\n",
      "[Epoch 60/100] [Batch 264/347] [D loss: 0.498296] [G loss: 0.269665]\n",
      "[Epoch 60/100] [Batch 265/347] [D loss: 0.498231] [G loss: 0.270071]\n",
      "[Epoch 60/100] [Batch 266/347] [D loss: 0.498299] [G loss: 0.270346]\n",
      "[Epoch 60/100] [Batch 267/347] [D loss: 0.498214] [G loss: 0.273069]\n",
      "[Epoch 60/100] [Batch 268/347] [D loss: 0.498231] [G loss: 0.273375]\n",
      "[Epoch 60/100] [Batch 269/347] [D loss: 0.498213] [G loss: 0.273469]\n",
      "[Epoch 60/100] [Batch 270/347] [D loss: 0.498467] [G loss: 0.268278]\n",
      "[Epoch 60/100] [Batch 271/347] [D loss: 0.498111] [G loss: 0.271088]\n",
      "[Epoch 60/100] [Batch 272/347] [D loss: 0.495238] [G loss: 0.283984]\n",
      "[Epoch 60/100] [Batch 273/347] [D loss: 0.495426] [G loss: 0.285007]\n",
      "[Epoch 60/100] [Batch 274/347] [D loss: 0.495031] [G loss: 0.286220]\n",
      "[Epoch 60/100] [Batch 275/347] [D loss: 0.495492] [G loss: 0.278591]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 60/100] [Batch 276/347] [D loss: 0.498916] [G loss: 0.254999]\n",
      "[Epoch 60/100] [Batch 277/347] [D loss: 0.499237] [G loss: 0.254259]\n",
      "[Epoch 60/100] [Batch 278/347] [D loss: 0.499477] [G loss: 0.254501]\n",
      "[Epoch 60/100] [Batch 279/347] [D loss: 0.499419] [G loss: 0.256242]\n",
      "[Epoch 60/100] [Batch 280/347] [D loss: 0.499284] [G loss: 0.256909]\n",
      "[Epoch 60/100] [Batch 281/347] [D loss: 0.499142] [G loss: 0.256500]\n",
      "[Epoch 60/100] [Batch 282/347] [D loss: 0.499208] [G loss: 0.256532]\n",
      "[Epoch 60/100] [Batch 283/347] [D loss: 0.499131] [G loss: 0.254343]\n",
      "[Epoch 60/100] [Batch 284/347] [D loss: 0.499134] [G loss: 0.252707]\n",
      "[Epoch 60/100] [Batch 285/347] [D loss: 0.499046] [G loss: 0.250369]\n",
      "[Epoch 60/100] [Batch 286/347] [D loss: 0.498041] [G loss: 0.264506]\n",
      "[Epoch 60/100] [Batch 287/347] [D loss: 0.497831] [G loss: 0.267116]\n",
      "[Epoch 60/100] [Batch 288/347] [D loss: 0.497666] [G loss: 0.269216]\n",
      "[Epoch 60/100] [Batch 289/347] [D loss: 0.497344] [G loss: 0.273147]\n",
      "[Epoch 60/100] [Batch 290/347] [D loss: 0.498397] [G loss: 0.256400]\n",
      "[Epoch 60/100] [Batch 291/347] [D loss: 0.499011] [G loss: 0.254507]\n",
      "[Epoch 60/100] [Batch 292/347] [D loss: 0.499426] [G loss: 0.261152]\n",
      "[Epoch 60/100] [Batch 293/347] [D loss: 0.499880] [G loss: 0.267974]\n",
      "[Epoch 60/100] [Batch 294/347] [D loss: 0.500300] [G loss: 0.271401]\n",
      "[Epoch 60/100] [Batch 295/347] [D loss: 0.500341] [G loss: 0.272593]\n",
      "[Epoch 60/100] [Batch 296/347] [D loss: 0.500329] [G loss: 0.273913]\n",
      "[Epoch 60/100] [Batch 297/347] [D loss: 0.500702] [G loss: 0.281152]\n",
      "[Epoch 60/100] [Batch 298/347] [D loss: 0.500470] [G loss: 0.277283]\n",
      "[Epoch 60/100] [Batch 299/347] [D loss: 0.500424] [G loss: 0.274997]\n",
      "[Epoch 60/100] [Batch 300/347] [D loss: 0.500434] [G loss: 0.274865]\n",
      "[Epoch 60/100] [Batch 301/347] [D loss: 0.499539] [G loss: 0.265559]\n",
      "[Epoch 60/100] [Batch 302/347] [D loss: 0.499108] [G loss: 0.257804]\n",
      "[Epoch 60/100] [Batch 303/347] [D loss: 0.498320] [G loss: 0.259540]\n",
      "[Epoch 60/100] [Batch 304/347] [D loss: 0.497613] [G loss: 0.269983]\n",
      "[Epoch 60/100] [Batch 305/347] [D loss: 0.497299] [G loss: 0.271592]\n",
      "[Epoch 60/100] [Batch 306/347] [D loss: 0.497334] [G loss: 0.271247]\n",
      "[Epoch 60/100] [Batch 307/347] [D loss: 0.497839] [G loss: 0.264119]\n",
      "[Epoch 60/100] [Batch 308/347] [D loss: 0.498517] [G loss: 0.256432]\n",
      "[Epoch 60/100] [Batch 309/347] [D loss: 0.499355] [G loss: 0.264981]\n",
      "[Epoch 60/100] [Batch 310/347] [D loss: 0.500125] [G loss: 0.279751]\n",
      "[Epoch 60/100] [Batch 311/347] [D loss: 0.500139] [G loss: 0.279957]\n",
      "[Epoch 60/100] [Batch 312/347] [D loss: 0.500132] [G loss: 0.277509]\n",
      "[Epoch 60/100] [Batch 313/347] [D loss: 0.499873] [G loss: 0.270951]\n",
      "[Epoch 60/100] [Batch 314/347] [D loss: 0.499150] [G loss: 0.258883]\n",
      "[Epoch 60/100] [Batch 315/347] [D loss: 0.498614] [G loss: 0.257048]\n",
      "[Epoch 60/100] [Batch 316/347] [D loss: 0.498788] [G loss: 0.256286]\n",
      "[Epoch 60/100] [Batch 317/347] [D loss: 0.499124] [G loss: 0.259314]\n",
      "[Epoch 60/100] [Batch 318/347] [D loss: 0.500065] [G loss: 0.274604]\n",
      "[Epoch 60/100] [Batch 319/347] [D loss: 0.500886] [G loss: 0.288657]\n",
      "[Epoch 60/100] [Batch 320/347] [D loss: 0.500893] [G loss: 0.289231]\n",
      "[Epoch 60/100] [Batch 321/347] [D loss: 0.500684] [G loss: 0.284619]\n",
      "[Epoch 60/100] [Batch 322/347] [D loss: 0.500428] [G loss: 0.279470]\n",
      "[Epoch 60/100] [Batch 323/347] [D loss: 0.500127] [G loss: 0.272968]\n",
      "[Epoch 60/100] [Batch 324/347] [D loss: 0.499900] [G loss: 0.268848]\n",
      "[Epoch 60/100] [Batch 325/347] [D loss: 0.499584] [G loss: 0.263387]\n",
      "[Epoch 60/100] [Batch 326/347] [D loss: 0.499205] [G loss: 0.256876]\n",
      "[Epoch 60/100] [Batch 327/347] [D loss: 0.498397] [G loss: 0.259801]\n",
      "[Epoch 60/100] [Batch 328/347] [D loss: 0.497949] [G loss: 0.267236]\n",
      "[Epoch 60/100] [Batch 329/347] [D loss: 0.498002] [G loss: 0.265422]\n",
      "[Epoch 60/100] [Batch 330/347] [D loss: 0.498288] [G loss: 0.259921]\n",
      "[Epoch 60/100] [Batch 331/347] [D loss: 0.499131] [G loss: 0.255961]\n",
      "[Epoch 60/100] [Batch 332/347] [D loss: 0.500234] [G loss: 0.276599]\n",
      "[Epoch 60/100] [Batch 333/347] [D loss: 0.500256] [G loss: 0.275786]\n",
      "[Epoch 60/100] [Batch 334/347] [D loss: 0.500023] [G loss: 0.270054]\n",
      "[Epoch 60/100] [Batch 335/347] [D loss: 0.499988] [G loss: 0.269084]\n",
      "[Epoch 60/100] [Batch 336/347] [D loss: 0.499945] [G loss: 0.268981]\n",
      "[Epoch 60/100] [Batch 337/347] [D loss: 0.500160] [G loss: 0.273926]\n",
      "[Epoch 60/100] [Batch 338/347] [D loss: 0.500572] [G loss: 0.282523]\n",
      "[Epoch 60/100] [Batch 339/347] [D loss: 0.500671] [G loss: 0.283487]\n",
      "[Epoch 60/100] [Batch 340/347] [D loss: 0.500483] [G loss: 0.280534]\n",
      "[Epoch 60/100] [Batch 341/347] [D loss: 0.500461] [G loss: 0.281241]\n",
      "[Epoch 60/100] [Batch 342/347] [D loss: 0.499794] [G loss: 0.269479]\n",
      "[Epoch 60/100] [Batch 343/347] [D loss: 0.498929] [G loss: 0.254541]\n",
      "[Epoch 60/100] [Batch 344/347] [D loss: 0.498002] [G loss: 0.262472]\n",
      "[Epoch 60/100] [Batch 345/347] [D loss: 0.497092] [G loss: 0.277198]\n",
      "[Epoch 60/100] [Batch 346/347] [D loss: 0.497114] [G loss: 0.277053]\n",
      "[Epoch 60/100] [Batch 347/347] [D loss: 0.497435] [G loss: 0.271188]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 1/347] [D loss: 0.499355] [G loss: 0.264687]\n",
      "[Epoch 61/100] [Batch 2/347] [D loss: 0.499314] [G loss: 0.265246]\n",
      "[Epoch 61/100] [Batch 3/347] [D loss: 0.499525] [G loss: 0.269433]\n",
      "[Epoch 61/100] [Batch 4/347] [D loss: 0.499498] [G loss: 0.269781]\n",
      "[Epoch 61/100] [Batch 5/347] [D loss: 0.499320] [G loss: 0.266393]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 6/347] [D loss: 0.499203] [G loss: 0.264583]\n",
      "[Epoch 61/100] [Batch 7/347] [D loss: 0.498757] [G loss: 0.265478]\n",
      "[Epoch 61/100] [Batch 8/347] [D loss: 0.498686] [G loss: 0.265535]\n",
      "[Epoch 61/100] [Batch 9/347] [D loss: 0.498725] [G loss: 0.266036]\n",
      "[Epoch 61/100] [Batch 10/347] [D loss: 0.498733] [G loss: 0.268059]\n",
      "[Epoch 61/100] [Batch 11/347] [D loss: 0.499232] [G loss: 0.266838]\n",
      "[Epoch 61/100] [Batch 12/347] [D loss: 0.499382] [G loss: 0.268044]\n",
      "[Epoch 61/100] [Batch 13/347] [D loss: 0.499379] [G loss: 0.267107]\n",
      "[Epoch 61/100] [Batch 14/347] [D loss: 0.499440] [G loss: 0.266404]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 15/347] [D loss: 0.498970] [G loss: 0.260131]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 16/347] [D loss: 0.498743] [G loss: 0.258361]\n",
      "[Epoch 61/100] [Batch 17/347] [D loss: 0.498900] [G loss: 0.256022]\n",
      "[Epoch 61/100] [Batch 18/347] [D loss: 0.498944] [G loss: 0.256880]\n",
      "[Epoch 61/100] [Batch 19/347] [D loss: 0.499221] [G loss: 0.259194]\n",
      "[Epoch 61/100] [Batch 20/347] [D loss: 0.499424] [G loss: 0.263584]\n",
      "[Epoch 61/100] [Batch 21/347] [D loss: 0.499183] [G loss: 0.259149]\n",
      "[Epoch 61/100] [Batch 22/347] [D loss: 0.499133] [G loss: 0.257482]\n",
      "[Epoch 61/100] [Batch 23/347] [D loss: 0.498961] [G loss: 0.257202]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 24/347] [D loss: 0.498586] [G loss: 0.256279]\n",
      "[Epoch 61/100] [Batch 25/347] [D loss: 0.498698] [G loss: 0.254959]\n",
      "[Epoch 61/100] [Batch 26/347] [D loss: 0.498726] [G loss: 0.255458]\n",
      "[Epoch 61/100] [Batch 27/347] [D loss: 0.499199] [G loss: 0.259052]\n",
      "[Epoch 61/100] [Batch 28/347] [D loss: 0.499875] [G loss: 0.266571]\n",
      "[Epoch 61/100] [Batch 29/347] [D loss: 0.500420] [G loss: 0.272483]\n",
      "[Epoch 61/100] [Batch 30/347] [D loss: 0.500525] [G loss: 0.274407]\n",
      "[Epoch 61/100] [Batch 31/347] [D loss: 0.500524] [G loss: 0.274751]\n",
      "[Epoch 61/100] [Batch 32/347] [D loss: 0.500390] [G loss: 0.271946]\n",
      "[Epoch 61/100] [Batch 33/347] [D loss: 0.500233] [G loss: 0.270198]\n",
      "[Epoch 61/100] [Batch 34/347] [D loss: 0.499934] [G loss: 0.265696]\n",
      "[Epoch 61/100] [Batch 35/347] [D loss: 0.499139] [G loss: 0.258492]\n",
      "[Epoch 61/100] [Batch 36/347] [D loss: 0.498443] [G loss: 0.261162]\n",
      "[Epoch 61/100] [Batch 37/347] [D loss: 0.498044] [G loss: 0.265865]\n",
      "[Epoch 61/100] [Batch 38/347] [D loss: 0.497662] [G loss: 0.270059]\n",
      "[Epoch 61/100] [Batch 39/347] [D loss: 0.497814] [G loss: 0.267725]\n",
      "[Epoch 61/100] [Batch 40/347] [D loss: 0.498202] [G loss: 0.266097]\n",
      "[Epoch 61/100] [Batch 41/347] [D loss: 0.498649] [G loss: 0.256483]\n",
      "[Epoch 61/100] [Batch 42/347] [D loss: 0.499420] [G loss: 0.254925]\n",
      "[Epoch 61/100] [Batch 43/347] [D loss: 0.500472] [G loss: 0.270429]\n",
      "[Epoch 61/100] [Batch 44/347] [D loss: 0.500842] [G loss: 0.276477]\n",
      "[Epoch 61/100] [Batch 45/347] [D loss: 0.500415] [G loss: 0.268652]\n",
      "[Epoch 61/100] [Batch 46/347] [D loss: 0.499145] [G loss: 0.262716]\n",
      "[Epoch 61/100] [Batch 47/347] [D loss: 0.498145] [G loss: 0.267687]\n",
      "[Epoch 61/100] [Batch 48/347] [D loss: 0.496680] [G loss: 0.289917]\n",
      "[Epoch 61/100] [Batch 49/347] [D loss: 0.496944] [G loss: 0.285921]\n",
      "[Epoch 61/100] [Batch 50/347] [D loss: 0.497721] [G loss: 0.272512]\n",
      "[Epoch 61/100] [Batch 51/347] [D loss: 0.497873] [G loss: 0.270946]\n",
      "[Epoch 61/100] [Batch 52/347] [D loss: 0.497556] [G loss: 0.277694]\n",
      "[Epoch 61/100] [Batch 53/347] [D loss: 0.496428] [G loss: 0.293781]\n",
      "[Epoch 61/100] [Batch 54/347] [D loss: 0.495620] [G loss: 0.304317]\n",
      "[Epoch 61/100] [Batch 55/347] [D loss: 0.495816] [G loss: 0.301002]\n",
      "[Epoch 61/100] [Batch 56/347] [D loss: 0.496924] [G loss: 0.283312]\n",
      "[Epoch 61/100] [Batch 57/347] [D loss: 0.498041] [G loss: 0.268255]\n",
      "[Epoch 61/100] [Batch 58/347] [D loss: 0.498680] [G loss: 0.264933]\n",
      "[Epoch 61/100] [Batch 59/347] [D loss: 0.497892] [G loss: 0.275995]\n",
      "[Epoch 61/100] [Batch 60/347] [D loss: 0.496234] [G loss: 0.298652]\n",
      "[Epoch 61/100] [Batch 61/347] [D loss: 0.495659] [G loss: 0.304215]\n",
      "[Epoch 61/100] [Batch 62/347] [D loss: 0.496107] [G loss: 0.296016]\n",
      "[Epoch 61/100] [Batch 63/347] [D loss: 0.496928] [G loss: 0.281750]\n",
      "[Epoch 61/100] [Batch 64/347] [D loss: 0.498075] [G loss: 0.264601]\n",
      "[Epoch 61/100] [Batch 65/347] [D loss: 0.499143] [G loss: 0.266966]\n",
      "[Epoch 61/100] [Batch 66/347] [D loss: 0.498186] [G loss: 0.265410]\n",
      "[Epoch 61/100] [Batch 67/347] [D loss: 0.496636] [G loss: 0.286681]\n",
      "[Epoch 61/100] [Batch 68/347] [D loss: 0.496048] [G loss: 0.293353]\n",
      "[Epoch 61/100] [Batch 69/347] [D loss: 0.495283] [G loss: 0.304977]\n",
      "[Epoch 61/100] [Batch 70/347] [D loss: 0.495187] [G loss: 0.304110]\n",
      "[Epoch 61/100] [Batch 71/347] [D loss: 0.496132] [G loss: 0.291842]\n",
      "[Epoch 61/100] [Batch 72/347] [D loss: 0.496450] [G loss: 0.290095]\n",
      "[Epoch 61/100] [Batch 73/347] [D loss: 0.496365] [G loss: 0.291144]\n",
      "[Epoch 61/100] [Batch 74/347] [D loss: 0.496823] [G loss: 0.283558]\n",
      "[Epoch 61/100] [Batch 75/347] [D loss: 0.497096] [G loss: 0.280160]\n",
      "[Epoch 61/100] [Batch 76/347] [D loss: 0.497674] [G loss: 0.270904]\n",
      "[Epoch 61/100] [Batch 77/347] [D loss: 0.499339] [G loss: 0.261667]\n",
      "[Epoch 61/100] [Batch 78/347] [D loss: 0.500620] [G loss: 0.266553]\n",
      "[Epoch 61/100] [Batch 79/347] [D loss: 0.501218] [G loss: 0.275511]\n",
      "[Epoch 61/100] [Batch 80/347] [D loss: 0.500792] [G loss: 0.271012]\n",
      "[Epoch 61/100] [Batch 81/347] [D loss: 0.500839] [G loss: 0.273095]\n",
      "[Epoch 61/100] [Batch 82/347] [D loss: 0.500949] [G loss: 0.275915]\n",
      "[Epoch 61/100] [Batch 83/347] [D loss: 0.500751] [G loss: 0.275276]\n",
      "[Epoch 61/100] [Batch 84/347] [D loss: 0.500846] [G loss: 0.279294]\n",
      "[Epoch 61/100] [Batch 85/347] [D loss: 0.500774] [G loss: 0.279561]\n",
      "[Epoch 61/100] [Batch 86/347] [D loss: 0.500699] [G loss: 0.279253]\n",
      "[Epoch 61/100] [Batch 87/347] [D loss: 0.500680] [G loss: 0.280152]\n",
      "[Epoch 61/100] [Batch 88/347] [D loss: 0.500670] [G loss: 0.280699]\n",
      "[Epoch 61/100] [Batch 89/347] [D loss: 0.500739] [G loss: 0.282540]\n",
      "[Epoch 61/100] [Batch 90/347] [D loss: 0.500661] [G loss: 0.281895]\n",
      "[Epoch 61/100] [Batch 91/347] [D loss: 0.500536] [G loss: 0.280385]\n",
      "[Epoch 61/100] [Batch 92/347] [D loss: 0.500518] [G loss: 0.280345]\n",
      "[Epoch 61/100] [Batch 93/347] [D loss: 0.500470] [G loss: 0.280090]\n",
      "[Epoch 61/100] [Batch 94/347] [D loss: 0.500254] [G loss: 0.275853]\n",
      "[Epoch 61/100] [Batch 95/347] [D loss: 0.500168] [G loss: 0.274424]\n",
      "[Epoch 61/100] [Batch 96/347] [D loss: 0.500202] [G loss: 0.275370]\n",
      "[Epoch 61/100] [Batch 97/347] [D loss: 0.500147] [G loss: 0.274425]\n",
      "[Epoch 61/100] [Batch 98/347] [D loss: 0.500205] [G loss: 0.275504]\n",
      "[Epoch 61/100] [Batch 99/347] [D loss: 0.500221] [G loss: 0.275438]\n",
      "[Epoch 61/100] [Batch 100/347] [D loss: 0.500200] [G loss: 0.274812]\n",
      "[Epoch 61/100] [Batch 101/347] [D loss: 0.500089] [G loss: 0.272340]\n",
      "[Epoch 61/100] [Batch 102/347] [D loss: 0.499911] [G loss: 0.269084]\n",
      "[Epoch 61/100] [Batch 103/347] [D loss: 0.499932] [G loss: 0.269631]\n",
      "[Epoch 61/100] [Batch 104/347] [D loss: 0.499649] [G loss: 0.264158]\n",
      "[Epoch 61/100] [Batch 105/347] [D loss: 0.499331] [G loss: 0.257264]\n",
      "[Epoch 61/100] [Batch 106/347] [D loss: 0.498472] [G loss: 0.259629]\n",
      "[Epoch 61/100] [Batch 107/347] [D loss: 0.498556] [G loss: 0.263324]\n",
      "[Epoch 61/100] [Batch 108/347] [D loss: 0.498562] [G loss: 0.265151]\n",
      "[Epoch 61/100] [Batch 109/347] [D loss: 0.498094] [G loss: 0.269029]\n",
      "[Epoch 61/100] [Batch 110/347] [D loss: 0.499295] [G loss: 0.265210]\n",
      "[Epoch 61/100] [Batch 111/347] [D loss: 0.499637] [G loss: 0.265332]\n",
      "[Epoch 61/100] [Batch 112/347] [D loss: 0.499953] [G loss: 0.268085]\n",
      "[Epoch 61/100] [Batch 113/347] [D loss: 0.501078] [G loss: 0.284622]\n",
      "[Epoch 61/100] [Batch 114/347] [D loss: 0.501472] [G loss: 0.291837]\n",
      "[Epoch 61/100] [Batch 115/347] [D loss: 0.500590] [G loss: 0.275477]\n",
      "[Epoch 61/100] [Batch 116/347] [D loss: 0.499519] [G loss: 0.259427]\n",
      "[Epoch 61/100] [Batch 117/347] [D loss: 0.498771] [G loss: 0.252935]\n",
      "[Epoch 61/100] [Batch 118/347] [D loss: 0.497935] [G loss: 0.265446]\n",
      "[Epoch 61/100] [Batch 119/347] [D loss: 0.497820] [G loss: 0.265559]\n",
      "[Epoch 61/100] [Batch 120/347] [D loss: 0.498260] [G loss: 0.258455]\n",
      "[Epoch 61/100] [Batch 121/347] [D loss: 0.498302] [G loss: 0.257223]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 122/347] [D loss: 0.498584] [G loss: 0.255952]\n",
      "[Epoch 61/100] [Batch 123/347] [D loss: 0.499024] [G loss: 0.255487]\n",
      "[Epoch 61/100] [Batch 124/347] [D loss: 0.499181] [G loss: 0.257839]\n",
      "[Epoch 61/100] [Batch 125/347] [D loss: 0.499521] [G loss: 0.263734]\n",
      "[Epoch 61/100] [Batch 126/347] [D loss: 0.499754] [G loss: 0.267454]\n",
      "[Epoch 61/100] [Batch 127/347] [D loss: 0.499765] [G loss: 0.265801]\n",
      "[Epoch 61/100] [Batch 128/347] [D loss: 0.499245] [G loss: 0.257386]\n",
      "[Epoch 61/100] [Batch 129/347] [D loss: 0.498289] [G loss: 0.256908]\n",
      "[Epoch 61/100] [Batch 130/347] [D loss: 0.496641] [G loss: 0.270394]\n",
      "[Epoch 61/100] [Batch 131/347] [D loss: 0.495586] [G loss: 0.281658]\n",
      "[Epoch 61/100] [Batch 132/347] [D loss: 0.493895] [G loss: 0.300906]\n",
      "[Epoch 61/100] [Batch 133/347] [D loss: 0.492589] [G loss: 0.306128]\n",
      "[Epoch 61/100] [Batch 134/347] [D loss: 0.493625] [G loss: 0.291133]\n",
      "[Epoch 61/100] [Batch 135/347] [D loss: 0.494153] [G loss: 0.287506]\n",
      "[Epoch 61/100] [Batch 136/347] [D loss: 0.494819] [G loss: 0.279041]\n",
      "[Epoch 61/100] [Batch 137/347] [D loss: 0.496112] [G loss: 0.280025]\n",
      "[Epoch 61/100] [Batch 138/347] [D loss: 0.494798] [G loss: 0.297897]\n",
      "[Epoch 61/100] [Batch 139/347] [D loss: 0.493698] [G loss: 0.310959]\n",
      "[Epoch 61/100] [Batch 140/347] [D loss: 0.492960] [G loss: 0.321449]\n",
      "[Epoch 61/100] [Batch 141/347] [D loss: 0.491500] [G loss: 0.335666]\n",
      "[Epoch 61/100] [Batch 142/347] [D loss: 0.491163] [G loss: 0.338105]\n",
      "[Epoch 61/100] [Batch 143/347] [D loss: 0.490607] [G loss: 0.340501]\n",
      "[Epoch 61/100] [Batch 144/347] [D loss: 0.490818] [G loss: 0.332660]\n",
      "[Epoch 61/100] [Batch 145/347] [D loss: 0.492357] [G loss: 0.311666]\n",
      "[Epoch 61/100] [Batch 146/347] [D loss: 0.493166] [G loss: 0.298967]\n",
      "[Epoch 61/100] [Batch 147/347] [D loss: 0.493995] [G loss: 0.289841]\n",
      "[Epoch 61/100] [Batch 148/347] [D loss: 0.494789] [G loss: 0.282830]\n",
      "[Epoch 61/100] [Batch 149/347] [D loss: 0.494698] [G loss: 0.285633]\n",
      "[Epoch 61/100] [Batch 150/347] [D loss: 0.494200] [G loss: 0.293950]\n",
      "[Epoch 61/100] [Batch 151/347] [D loss: 0.493598] [G loss: 0.300049]\n",
      "[Epoch 61/100] [Batch 152/347] [D loss: 0.492694] [G loss: 0.307912]\n",
      "[Epoch 61/100] [Batch 153/347] [D loss: 0.492241] [G loss: 0.311232]\n",
      "[Epoch 61/100] [Batch 154/347] [D loss: 0.492503] [G loss: 0.306503]\n",
      "[Epoch 61/100] [Batch 155/347] [D loss: 0.492549] [G loss: 0.305955]\n",
      "[Epoch 61/100] [Batch 156/347] [D loss: 0.492055] [G loss: 0.310516]\n",
      "[Epoch 61/100] [Batch 157/347] [D loss: 0.491968] [G loss: 0.310534]\n",
      "[Epoch 61/100] [Batch 158/347] [D loss: 0.491455] [G loss: 0.313027]\n",
      "[Epoch 61/100] [Batch 159/347] [D loss: 0.491546] [G loss: 0.311736]\n",
      "[Epoch 61/100] [Batch 160/347] [D loss: 0.492515] [G loss: 0.303868]\n",
      "[Epoch 61/100] [Batch 161/347] [D loss: 0.491712] [G loss: 0.311307]\n",
      "[Epoch 61/100] [Batch 162/347] [D loss: 0.490657] [G loss: 0.322521]\n",
      "[Epoch 61/100] [Batch 163/347] [D loss: 0.490203] [G loss: 0.325359]\n",
      "[Epoch 61/100] [Batch 164/347] [D loss: 0.490918] [G loss: 0.315423]\n",
      "[Epoch 61/100] [Batch 165/347] [D loss: 0.492245] [G loss: 0.299987]\n",
      "[Epoch 61/100] [Batch 166/347] [D loss: 0.495125] [G loss: 0.274297]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 167/347] [D loss: 0.497631] [G loss: 0.251392]\n",
      "[Epoch 61/100] [Batch 168/347] [D loss: 0.498569] [G loss: 0.254791]\n",
      "[Epoch 61/100] [Batch 169/347] [D loss: 0.499705] [G loss: 0.257013]\n",
      "[Epoch 61/100] [Batch 170/347] [D loss: 0.500409] [G loss: 0.264956]\n",
      "[Epoch 61/100] [Batch 171/347] [D loss: 0.500347] [G loss: 0.266385]\n",
      "[Epoch 61/100] [Batch 172/347] [D loss: 0.500502] [G loss: 0.269276]\n",
      "[Epoch 61/100] [Batch 173/347] [D loss: 0.500445] [G loss: 0.270012]\n",
      "[Epoch 61/100] [Batch 174/347] [D loss: 0.500857] [G loss: 0.275812]\n",
      "[Epoch 61/100] [Batch 175/347] [D loss: 0.501292] [G loss: 0.282528]\n",
      "[Epoch 61/100] [Batch 176/347] [D loss: 0.501656] [G loss: 0.287293]\n",
      "[Epoch 61/100] [Batch 177/347] [D loss: 0.501447] [G loss: 0.286002]\n",
      "[Epoch 61/100] [Batch 178/347] [D loss: 0.500952] [G loss: 0.281507]\n",
      "[Epoch 61/100] [Batch 179/347] [D loss: 0.500649] [G loss: 0.279238]\n",
      "[Epoch 61/100] [Batch 180/347] [D loss: 0.500282] [G loss: 0.276291]\n",
      "[Epoch 61/100] [Batch 181/347] [D loss: 0.500549] [G loss: 0.279707]\n",
      "[Epoch 61/100] [Batch 182/347] [D loss: 0.500545] [G loss: 0.281022]\n",
      "[Epoch 61/100] [Batch 183/347] [D loss: 0.500729] [G loss: 0.282853]\n",
      "[Epoch 61/100] [Batch 184/347] [D loss: 0.501065] [G loss: 0.285375]\n",
      "[Epoch 61/100] [Batch 185/347] [D loss: 0.500855] [G loss: 0.282345]\n",
      "[Epoch 61/100] [Batch 186/347] [D loss: 0.500730] [G loss: 0.281089]\n",
      "[Epoch 61/100] [Batch 187/347] [D loss: 0.500469] [G loss: 0.278042]\n",
      "[Epoch 61/100] [Batch 188/347] [D loss: 0.499523] [G loss: 0.269812]\n",
      "[Epoch 61/100] [Batch 189/347] [D loss: 0.498836] [G loss: 0.263240]\n",
      "[Epoch 61/100] [Batch 190/347] [D loss: 0.498627] [G loss: 0.260007]\n",
      "[Epoch 61/100] [Batch 191/347] [D loss: 0.498364] [G loss: 0.260658]\n",
      "[Epoch 61/100] [Batch 192/347] [D loss: 0.498378] [G loss: 0.259617]\n",
      "[Epoch 61/100] [Batch 193/347] [D loss: 0.498449] [G loss: 0.259449]\n",
      "[Epoch 61/100] [Batch 194/347] [D loss: 0.497982] [G loss: 0.262039]\n",
      "[Epoch 61/100] [Batch 195/347] [D loss: 0.497687] [G loss: 0.262092]\n",
      "[Epoch 61/100] [Batch 196/347] [D loss: 0.497576] [G loss: 0.257619]\n",
      "[Epoch 61/100] [Batch 197/347] [D loss: 0.497622] [G loss: 0.254407]\n",
      "[Epoch 61/100] [Batch 198/347] [D loss: 0.498041] [G loss: 0.250380]\n",
      "[Epoch 61/100] [Batch 199/347] [D loss: 0.498070] [G loss: 0.250888]\n",
      "[Epoch 61/100] [Batch 200/347] [D loss: 0.497952] [G loss: 0.256238]\n",
      "[Epoch 61/100] [Batch 201/347] [D loss: 0.497760] [G loss: 0.260154]\n",
      "[Epoch 61/100] [Batch 202/347] [D loss: 0.497518] [G loss: 0.264979]\n",
      "[Epoch 61/100] [Batch 203/347] [D loss: 0.497454] [G loss: 0.265123]\n",
      "[Epoch 61/100] [Batch 204/347] [D loss: 0.498097] [G loss: 0.256140]\n",
      "[Epoch 61/100] [Batch 205/347] [D loss: 0.498928] [G loss: 0.252640]\n",
      "[Epoch 61/100] [Batch 206/347] [D loss: 0.499303] [G loss: 0.256375]\n",
      "[Epoch 61/100] [Batch 207/347] [D loss: 0.499677] [G loss: 0.259285]\n",
      "[Epoch 61/100] [Batch 208/347] [D loss: 0.500175] [G loss: 0.263754]\n",
      "[Epoch 61/100] [Batch 209/347] [D loss: 0.499621] [G loss: 0.260218]\n",
      "[Epoch 61/100] [Batch 210/347] [D loss: 0.499707] [G loss: 0.262112]\n",
      "[Epoch 61/100] [Batch 211/347] [D loss: 0.498878] [G loss: 0.265884]\n",
      "[Epoch 61/100] [Batch 212/347] [D loss: 0.496306] [G loss: 0.268396]\n",
      "[Epoch 61/100] [Batch 213/347] [D loss: 0.495853] [G loss: 0.271005]\n",
      "[Epoch 61/100] [Batch 214/347] [D loss: 0.495868] [G loss: 0.270806]\n",
      "[Epoch 61/100] [Batch 215/347] [D loss: 0.496179] [G loss: 0.271961]\n",
      "[Epoch 61/100] [Batch 216/347] [D loss: 0.499525] [G loss: 0.267738]\n",
      "[Epoch 61/100] [Batch 217/347] [D loss: 0.501107] [G loss: 0.273425]\n",
      "[Epoch 61/100] [Batch 218/347] [D loss: 0.502491] [G loss: 0.288323]\n",
      "[Epoch 61/100] [Batch 219/347] [D loss: 0.503261] [G loss: 0.295488]\n",
      "[Epoch 61/100] [Batch 220/347] [D loss: 0.503730] [G loss: 0.300563]\n",
      "[Epoch 61/100] [Batch 221/347] [D loss: 0.503799] [G loss: 0.301948]\n",
      "[Epoch 61/100] [Batch 222/347] [D loss: 0.503156] [G loss: 0.294992]\n",
      "[Epoch 61/100] [Batch 223/347] [D loss: 0.501425] [G loss: 0.285989]\n",
      "[Epoch 61/100] [Batch 224/347] [D loss: 0.499142] [G loss: 0.276605]\n",
      "[Epoch 61/100] [Batch 225/347] [D loss: 0.497184] [G loss: 0.266582]\n",
      "[Epoch 61/100] [Batch 226/347] [D loss: 0.495789] [G loss: 0.275690]\n",
      "[Epoch 61/100] [Batch 227/347] [D loss: 0.495509] [G loss: 0.276293]\n",
      "[Epoch 61/100] [Batch 228/347] [D loss: 0.495714] [G loss: 0.278856]\n",
      "[Epoch 61/100] [Batch 229/347] [D loss: 0.496112] [G loss: 0.275059]\n",
      "[Epoch 61/100] [Batch 230/347] [D loss: 0.496561] [G loss: 0.269878]\n",
      "[Epoch 61/100] [Batch 231/347] [D loss: 0.496272] [G loss: 0.264863]\n",
      "[Epoch 61/100] [Batch 232/347] [D loss: 0.496411] [G loss: 0.264512]\n",
      "[Epoch 61/100] [Batch 233/347] [D loss: 0.497060] [G loss: 0.259221]\n",
      "[Epoch 61/100] [Batch 234/347] [D loss: 0.497632] [G loss: 0.255549]\n",
      "[Epoch 61/100] [Batch 235/347] [D loss: 0.498844] [G loss: 0.259125]\n",
      "[Epoch 61/100] [Batch 236/347] [D loss: 0.499863] [G loss: 0.261598]\n",
      "[Epoch 61/100] [Batch 237/347] [D loss: 0.500419] [G loss: 0.267676]\n",
      "[Epoch 61/100] [Batch 238/347] [D loss: 0.500400] [G loss: 0.267284]\n",
      "[Epoch 61/100] [Batch 239/347] [D loss: 0.499945] [G loss: 0.263595]\n",
      "[Epoch 61/100] [Batch 240/347] [D loss: 0.499695] [G loss: 0.262293]\n",
      "[Epoch 61/100] [Batch 241/347] [D loss: 0.499728] [G loss: 0.263798]\n",
      "[Epoch 61/100] [Batch 242/347] [D loss: 0.500089] [G loss: 0.267251]\n",
      "[Epoch 61/100] [Batch 243/347] [D loss: 0.500443] [G loss: 0.270040]\n",
      "[Epoch 61/100] [Batch 244/347] [D loss: 0.499523] [G loss: 0.264490]\n",
      "[Epoch 61/100] [Batch 245/347] [D loss: 0.498351] [G loss: 0.259688]\n",
      "[Epoch 61/100] [Batch 246/347] [D loss: 0.496873] [G loss: 0.265126]\n",
      "[Epoch 61/100] [Batch 247/347] [D loss: 0.495594] [G loss: 0.274163]\n",
      "[Epoch 61/100] [Batch 248/347] [D loss: 0.496074] [G loss: 0.271394]\n",
      "[Epoch 61/100] [Batch 249/347] [D loss: 0.496857] [G loss: 0.265090]\n",
      "[Epoch 61/100] [Batch 250/347] [D loss: 0.498073] [G loss: 0.263282]\n",
      "[Epoch 61/100] [Batch 251/347] [D loss: 0.499568] [G loss: 0.270388]\n",
      "[Epoch 61/100] [Batch 252/347] [D loss: 0.500216] [G loss: 0.271151]\n",
      "[Epoch 61/100] [Batch 253/347] [D loss: 0.499505] [G loss: 0.271010]\n",
      "[Epoch 61/100] [Batch 254/347] [D loss: 0.499937] [G loss: 0.273009]\n",
      "[Epoch 61/100] [Batch 255/347] [D loss: 0.499986] [G loss: 0.273861]\n",
      "[Epoch 61/100] [Batch 256/347] [D loss: 0.499302] [G loss: 0.272508]\n",
      "[Epoch 61/100] [Batch 257/347] [D loss: 0.498662] [G loss: 0.270193]\n",
      "[Epoch 61/100] [Batch 258/347] [D loss: 0.497332] [G loss: 0.266664]\n",
      "[Epoch 61/100] [Batch 259/347] [D loss: 0.496685] [G loss: 0.267064]\n",
      "[Epoch 61/100] [Batch 260/347] [D loss: 0.496541] [G loss: 0.267519]\n",
      "[Epoch 61/100] [Batch 261/347] [D loss: 0.496762] [G loss: 0.264367]\n",
      "[Epoch 61/100] [Batch 262/347] [D loss: 0.496447] [G loss: 0.263725]\n",
      "[Epoch 61/100] [Batch 263/347] [D loss: 0.496071] [G loss: 0.265763]\n",
      "[Epoch 61/100] [Batch 264/347] [D loss: 0.495747] [G loss: 0.267763]\n",
      "[Epoch 61/100] [Batch 265/347] [D loss: 0.495629] [G loss: 0.267924]\n",
      "[Epoch 61/100] [Batch 266/347] [D loss: 0.495937] [G loss: 0.267987]\n",
      "[Epoch 61/100] [Batch 267/347] [D loss: 0.495813] [G loss: 0.270425]\n",
      "[Epoch 61/100] [Batch 268/347] [D loss: 0.495907] [G loss: 0.270482]\n",
      "[Epoch 61/100] [Batch 269/347] [D loss: 0.495832] [G loss: 0.270390]\n",
      "[Epoch 61/100] [Batch 270/347] [D loss: 0.496413] [G loss: 0.265086]\n",
      "[Epoch 61/100] [Batch 271/347] [D loss: 0.493047] [G loss: 0.267620]\n",
      "[Epoch 61/100] [Batch 272/347] [D loss: 0.475410] [G loss: 0.279652]\n",
      "[Epoch 61/100] [Batch 273/347] [D loss: 0.474832] [G loss: 0.279422]\n",
      "[Epoch 61/100] [Batch 274/347] [D loss: 0.474027] [G loss: 0.279117]\n",
      "[Epoch 61/100] [Batch 275/347] [D loss: 0.472914] [G loss: 0.269674]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 61/100] [Batch 276/347] [D loss: 0.497101] [G loss: 0.247004]\n",
      "[Epoch 61/100] [Batch 277/347] [D loss: 0.498251] [G loss: 0.246674]\n",
      "[Epoch 61/100] [Batch 278/347] [D loss: 0.498878] [G loss: 0.246662]\n",
      "[Epoch 61/100] [Batch 279/347] [D loss: 0.498677] [G loss: 0.248584]\n",
      "[Epoch 61/100] [Batch 280/347] [D loss: 0.498289] [G loss: 0.249815]\n",
      "[Epoch 61/100] [Batch 281/347] [D loss: 0.497930] [G loss: 0.250263]\n",
      "[Epoch 61/100] [Batch 282/347] [D loss: 0.498094] [G loss: 0.251337]\n",
      "[Epoch 61/100] [Batch 283/347] [D loss: 0.497883] [G loss: 0.250398]\n",
      "[Epoch 61/100] [Batch 284/347] [D loss: 0.497862] [G loss: 0.250058]\n",
      "[Epoch 61/100] [Batch 285/347] [D loss: 0.497654] [G loss: 0.249151]\n",
      "[Epoch 61/100] [Batch 286/347] [D loss: 0.495297] [G loss: 0.262027]\n",
      "[Epoch 61/100] [Batch 287/347] [D loss: 0.494855] [G loss: 0.265800]\n",
      "[Epoch 61/100] [Batch 288/347] [D loss: 0.494511] [G loss: 0.268980]\n",
      "[Epoch 61/100] [Batch 289/347] [D loss: 0.493864] [G loss: 0.273684]\n",
      "[Epoch 61/100] [Batch 290/347] [D loss: 0.496115] [G loss: 0.257436]\n",
      "[Epoch 61/100] [Batch 291/347] [D loss: 0.497197] [G loss: 0.258638]\n",
      "[Epoch 61/100] [Batch 292/347] [D loss: 0.497862] [G loss: 0.265509]\n",
      "[Epoch 61/100] [Batch 293/347] [D loss: 0.498202] [G loss: 0.272435]\n",
      "[Epoch 61/100] [Batch 294/347] [D loss: 0.499031] [G loss: 0.275788]\n",
      "[Epoch 61/100] [Batch 295/347] [D loss: 0.499282] [G loss: 0.276455]\n",
      "[Epoch 61/100] [Batch 296/347] [D loss: 0.499526] [G loss: 0.277324]\n",
      "[Epoch 61/100] [Batch 297/347] [D loss: 0.501097] [G loss: 0.284215]\n",
      "[Epoch 61/100] [Batch 298/347] [D loss: 0.500644] [G loss: 0.280053]\n",
      "[Epoch 61/100] [Batch 299/347] [D loss: 0.500292] [G loss: 0.277448]\n",
      "[Epoch 61/100] [Batch 300/347] [D loss: 0.500153] [G loss: 0.277077]\n",
      "[Epoch 61/100] [Batch 301/347] [D loss: 0.498162] [G loss: 0.267915]\n",
      "[Epoch 61/100] [Batch 302/347] [D loss: 0.497385] [G loss: 0.259906]\n",
      "[Epoch 61/100] [Batch 303/347] [D loss: 0.495880] [G loss: 0.256993]\n",
      "[Epoch 61/100] [Batch 304/347] [D loss: 0.494096] [G loss: 0.267067]\n",
      "[Epoch 61/100] [Batch 305/347] [D loss: 0.493200] [G loss: 0.268712]\n",
      "[Epoch 61/100] [Batch 306/347] [D loss: 0.493198] [G loss: 0.267928]\n",
      "[Epoch 61/100] [Batch 307/347] [D loss: 0.494081] [G loss: 0.260304]\n",
      "[Epoch 61/100] [Batch 308/347] [D loss: 0.495768] [G loss: 0.251733]\n",
      "[Epoch 61/100] [Batch 309/347] [D loss: 0.498420] [G loss: 0.264946]\n",
      "[Epoch 61/100] [Batch 310/347] [D loss: 0.500427] [G loss: 0.279771]\n",
      "[Epoch 61/100] [Batch 311/347] [D loss: 0.500438] [G loss: 0.280248]\n",
      "[Epoch 61/100] [Batch 312/347] [D loss: 0.500262] [G loss: 0.278144]\n",
      "[Epoch 61/100] [Batch 313/347] [D loss: 0.499420] [G loss: 0.272095]\n",
      "[Epoch 61/100] [Batch 314/347] [D loss: 0.497775] [G loss: 0.260599]\n",
      "[Epoch 61/100] [Batch 315/347] [D loss: 0.496613] [G loss: 0.253607]\n",
      "[Epoch 61/100] [Batch 316/347] [D loss: 0.497009] [G loss: 0.256030]\n",
      "[Epoch 61/100] [Batch 317/347] [D loss: 0.497764] [G loss: 0.262312]\n",
      "[Epoch 61/100] [Batch 318/347] [D loss: 0.499728] [G loss: 0.277904]\n",
      "[Epoch 61/100] [Batch 319/347] [D loss: 0.501613] [G loss: 0.292292]\n",
      "[Epoch 61/100] [Batch 320/347] [D loss: 0.501640] [G loss: 0.293159]\n",
      "[Epoch 61/100] [Batch 321/347] [D loss: 0.501073] [G loss: 0.288815]\n",
      "[Epoch 61/100] [Batch 322/347] [D loss: 0.500429] [G loss: 0.283879]\n",
      "[Epoch 61/100] [Batch 323/347] [D loss: 0.499665] [G loss: 0.277481]\n",
      "[Epoch 61/100] [Batch 324/347] [D loss: 0.498997] [G loss: 0.273474]\n",
      "[Epoch 61/100] [Batch 325/347] [D loss: 0.498339] [G loss: 0.267947]\n",
      "[Epoch 61/100] [Batch 326/347] [D loss: 0.497514] [G loss: 0.261353]\n",
      "[Epoch 61/100] [Batch 327/347] [D loss: 0.495572] [G loss: 0.259740]\n",
      "[Epoch 61/100] [Batch 328/347] [D loss: 0.494703] [G loss: 0.266805]\n",
      "[Epoch 61/100] [Batch 329/347] [D loss: 0.494811] [G loss: 0.264435]\n",
      "[Epoch 61/100] [Batch 330/347] [D loss: 0.495410] [G loss: 0.258460]\n",
      "[Epoch 61/100] [Batch 331/347] [D loss: 0.497413] [G loss: 0.258637]\n",
      "[Epoch 61/100] [Batch 332/347] [D loss: 0.500120] [G loss: 0.278998]\n",
      "[Epoch 61/100] [Batch 333/347] [D loss: 0.500083] [G loss: 0.278045]\n",
      "[Epoch 61/100] [Batch 334/347] [D loss: 0.499491] [G loss: 0.272251]\n",
      "[Epoch 61/100] [Batch 335/347] [D loss: 0.499391] [G loss: 0.271348]\n",
      "[Epoch 61/100] [Batch 336/347] [D loss: 0.499381] [G loss: 0.271436]\n",
      "[Epoch 61/100] [Batch 337/347] [D loss: 0.499997] [G loss: 0.276628]\n",
      "[Epoch 61/100] [Batch 338/347] [D loss: 0.501054] [G loss: 0.285537]\n",
      "[Epoch 61/100] [Batch 339/347] [D loss: 0.501199] [G loss: 0.286950]\n",
      "[Epoch 61/100] [Batch 340/347] [D loss: 0.500772] [G loss: 0.284412]\n",
      "[Epoch 61/100] [Batch 341/347] [D loss: 0.500814] [G loss: 0.285579]\n",
      "[Epoch 61/100] [Batch 342/347] [D loss: 0.498888] [G loss: 0.274152]\n",
      "[Epoch 61/100] [Batch 343/347] [D loss: 0.496860] [G loss: 0.259354]\n",
      "[Epoch 61/100] [Batch 344/347] [D loss: 0.493868] [G loss: 0.261436]\n",
      "[Epoch 61/100] [Batch 345/347] [D loss: 0.490523] [G loss: 0.275659]\n",
      "[Epoch 61/100] [Batch 346/347] [D loss: 0.490543] [G loss: 0.274782]\n",
      "[Epoch 61/100] [Batch 347/347] [D loss: 0.491158] [G loss: 0.267945]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 62/100] [Batch 1/347] [D loss: 0.498485] [G loss: 0.266990]\n",
      "[Epoch 62/100] [Batch 2/347] [D loss: 0.498518] [G loss: 0.266965]\n",
      "[Epoch 62/100] [Batch 3/347] [D loss: 0.499111] [G loss: 0.270822]\n",
      "[Epoch 62/100] [Batch 4/347] [D loss: 0.499117] [G loss: 0.271058]\n",
      "[Epoch 62/100] [Batch 5/347] [D loss: 0.498725] [G loss: 0.267780]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 62/100] [Batch 6/347] [D loss: 0.498366] [G loss: 0.265074]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 62/100] [Batch 7/347] [D loss: 0.497243] [G loss: 0.259611]\n",
      "[Epoch 62/100] [Batch 8/347] [D loss: 0.497067] [G loss: 0.260092]\n",
      "[Epoch 62/100] [Batch 9/347] [D loss: 0.497153] [G loss: 0.261090]\n",
      "[Epoch 62/100] [Batch 10/347] [D loss: 0.497184] [G loss: 0.263553]\n",
      "[Epoch 62/100] [Batch 11/347] [D loss: 0.498444] [G loss: 0.268550]\n",
      "[Epoch 62/100] [Batch 12/347] [D loss: 0.498737] [G loss: 0.271300]\n",
      "[Epoch 62/100] [Batch 13/347] [D loss: 0.498664] [G loss: 0.270440]\n",
      "[Epoch 62/100] [Batch 14/347] [D loss: 0.498674] [G loss: 0.269829]\n",
      "[Epoch 62/100] [Batch 15/347] [D loss: 0.497387] [G loss: 0.260330]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 62/100] [Batch 16/347] [D loss: 0.496768] [G loss: 0.256719]\n",
      "[Epoch 62/100] [Batch 17/347] [D loss: 0.497031] [G loss: 0.256448]\n",
      "[Epoch 62/100] [Batch 18/347] [D loss: 0.497108] [G loss: 0.256517]\n",
      "[Epoch 62/100] [Batch 19/347] [D loss: 0.497763] [G loss: 0.260855]\n",
      "[Epoch 62/100] [Batch 20/347] [D loss: 0.498228] [G loss: 0.264614]\n",
      "[Epoch 62/100] [Batch 21/347] [D loss: 0.497549] [G loss: 0.259523]\n",
      "[Epoch 62/100] [Batch 22/347] [D loss: 0.497326] [G loss: 0.258089]\n",
      "[Epoch 62/100] [Batch 23/347] [D loss: 0.496821] [G loss: 0.258094]\n",
      "[Epoch 62/100] [Batch 24/347] [D loss: 0.495681] [G loss: 0.257481]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 62/100] [Batch 25/347] [D loss: 0.495315] [G loss: 0.256030]\n",
      "[Epoch 62/100] [Batch 26/347] [D loss: 0.495295] [G loss: 0.256598]\n",
      "[Epoch 62/100] [Batch 27/347] [D loss: 0.496166] [G loss: 0.256680]\n",
      "[Epoch 62/100] [Batch 28/347] [D loss: 0.497234] [G loss: 0.263897]\n",
      "[Epoch 62/100] [Batch 29/347] [D loss: 0.499014] [G loss: 0.269928]\n",
      "[Epoch 62/100] [Batch 30/347] [D loss: 0.498972] [G loss: 0.271847]\n",
      "[Epoch 62/100] [Batch 31/347] [D loss: 0.498983] [G loss: 0.272242]\n",
      "[Epoch 62/100] [Batch 32/347] [D loss: 0.498771] [G loss: 0.269529]\n",
      "[Epoch 62/100] [Batch 33/347] [D loss: 0.498645] [G loss: 0.267921]\n",
      "[Epoch 62/100] [Batch 34/347] [D loss: 0.498094] [G loss: 0.263454]\n",
      "[Epoch 62/100] [Batch 35/347] [D loss: 0.496076] [G loss: 0.255855]\n",
      "[Epoch 62/100] [Batch 36/347] [D loss: 0.494682] [G loss: 0.263869]\n",
      "[Epoch 62/100] [Batch 37/347] [D loss: 0.493994] [G loss: 0.268516]\n",
      "[Epoch 62/100] [Batch 38/347] [D loss: 0.493432] [G loss: 0.272552]\n",
      "[Epoch 62/100] [Batch 39/347] [D loss: 0.493893] [G loss: 0.270252]\n",
      "[Epoch 62/100] [Batch 40/347] [D loss: 0.494922] [G loss: 0.268385]\n",
      "[Epoch 62/100] [Batch 41/347] [D loss: 0.495804] [G loss: 0.258566]\n",
      "[Epoch 62/100] [Batch 42/347] [D loss: 0.497318] [G loss: 0.251591]\n",
      "[Epoch 62/100] [Batch 43/347] [D loss: 0.499665] [G loss: 0.267160]\n",
      "[Epoch 62/100] [Batch 44/347] [D loss: 0.500434] [G loss: 0.273363]\n",
      "[Epoch 62/100] [Batch 45/347] [D loss: 0.499385] [G loss: 0.265844]\n",
      "[Epoch 62/100] [Batch 46/347] [D loss: 0.495950] [G loss: 0.259865]\n",
      "[Epoch 62/100] [Batch 47/347] [D loss: 0.493686] [G loss: 0.270009]\n",
      "[Epoch 62/100] [Batch 48/347] [D loss: 0.488307] [G loss: 0.292052]\n",
      "[Epoch 62/100] [Batch 49/347] [D loss: 0.488499] [G loss: 0.287690]\n",
      "[Epoch 62/100] [Batch 50/347] [D loss: 0.489752] [G loss: 0.273629]\n",
      "[Epoch 62/100] [Batch 51/347] [D loss: 0.489964] [G loss: 0.271369]\n",
      "[Epoch 62/100] [Batch 52/347] [D loss: 0.491123] [G loss: 0.277414]\n",
      "[Epoch 62/100] [Batch 53/347] [D loss: 0.489136] [G loss: 0.292789]\n",
      "[Epoch 62/100] [Batch 54/347] [D loss: 0.487442] [G loss: 0.302748]\n",
      "[Epoch 62/100] [Batch 55/347] [D loss: 0.487691] [G loss: 0.298765]\n",
      "[Epoch 62/100] [Batch 56/347] [D loss: 0.490144] [G loss: 0.280458]\n",
      "[Epoch 62/100] [Batch 57/347] [D loss: 0.492583] [G loss: 0.264765]\n",
      "[Epoch 62/100] [Batch 58/347] [D loss: 0.494253] [G loss: 0.257908]\n",
      "[Epoch 62/100] [Batch 59/347] [D loss: 0.492178] [G loss: 0.271434]\n",
      "[Epoch 62/100] [Batch 60/347] [D loss: 0.487990] [G loss: 0.293681]\n",
      "[Epoch 62/100] [Batch 61/347] [D loss: 0.487024] [G loss: 0.298786]\n",
      "[Epoch 62/100] [Batch 62/347] [D loss: 0.487808] [G loss: 0.289975]\n",
      "[Epoch 62/100] [Batch 63/347] [D loss: 0.489598] [G loss: 0.275194]\n",
      "[Epoch 62/100] [Batch 64/347] [D loss: 0.492350] [G loss: 0.257610]\n",
      "[Epoch 62/100] [Batch 65/347] [D loss: 0.493739] [G loss: 0.259343]\n",
      "[Epoch 62/100] [Batch 66/347] [D loss: 0.491027] [G loss: 0.258040]\n",
      "[Epoch 62/100] [Batch 67/347] [D loss: 0.487525] [G loss: 0.279163]\n",
      "[Epoch 62/100] [Batch 68/347] [D loss: 0.486233] [G loss: 0.285828]\n",
      "[Epoch 62/100] [Batch 69/347] [D loss: 0.484988] [G loss: 0.297388]\n",
      "[Epoch 62/100] [Batch 70/347] [D loss: 0.484957] [G loss: 0.296303]\n",
      "[Epoch 62/100] [Batch 71/347] [D loss: 0.486948] [G loss: 0.283568]\n",
      "[Epoch 62/100] [Batch 72/347] [D loss: 0.487458] [G loss: 0.281481]\n",
      "[Epoch 62/100] [Batch 73/347] [D loss: 0.488086] [G loss: 0.282385]\n",
      "[Epoch 62/100] [Batch 74/347] [D loss: 0.489320] [G loss: 0.274737]\n",
      "[Epoch 62/100] [Batch 75/347] [D loss: 0.489874] [G loss: 0.271504]\n",
      "[Epoch 62/100] [Batch 76/347] [D loss: 0.491445] [G loss: 0.262666]\n",
      "[Epoch 62/100] [Batch 77/347] [D loss: 0.496732] [G loss: 0.257562]\n",
      "[Epoch 62/100] [Batch 78/347] [D loss: 0.500914] [G loss: 0.263271]\n",
      "[Epoch 62/100] [Batch 79/347] [D loss: 0.502492] [G loss: 0.273691]\n",
      "[Epoch 62/100] [Batch 80/347] [D loss: 0.500650] [G loss: 0.271530]\n",
      "[Epoch 62/100] [Batch 81/347] [D loss: 0.500713] [G loss: 0.274921]\n",
      "[Epoch 62/100] [Batch 82/347] [D loss: 0.501092] [G loss: 0.279399]\n",
      "[Epoch 62/100] [Batch 83/347] [D loss: 0.500837] [G loss: 0.280520]\n",
      "[Epoch 62/100] [Batch 84/347] [D loss: 0.501876] [G loss: 0.286097]\n",
      "[Epoch 62/100] [Batch 85/347] [D loss: 0.501963] [G loss: 0.287849]\n",
      "[Epoch 62/100] [Batch 86/347] [D loss: 0.501810] [G loss: 0.288829]\n",
      "[Epoch 62/100] [Batch 87/347] [D loss: 0.501801] [G loss: 0.290821]\n",
      "[Epoch 62/100] [Batch 88/347] [D loss: 0.501892] [G loss: 0.292188]\n",
      "[Epoch 62/100] [Batch 89/347] [D loss: 0.502127] [G loss: 0.294656]\n",
      "[Epoch 62/100] [Batch 90/347] [D loss: 0.501947] [G loss: 0.294370]\n",
      "[Epoch 62/100] [Batch 91/347] [D loss: 0.501657] [G loss: 0.292920]\n",
      "[Epoch 62/100] [Batch 92/347] [D loss: 0.501574] [G loss: 0.292804]\n",
      "[Epoch 62/100] [Batch 93/347] [D loss: 0.501408] [G loss: 0.292240]\n",
      "[Epoch 62/100] [Batch 94/347] [D loss: 0.500755] [G loss: 0.287510]\n",
      "[Epoch 62/100] [Batch 95/347] [D loss: 0.500477] [G loss: 0.285597]\n",
      "[Epoch 62/100] [Batch 96/347] [D loss: 0.500549] [G loss: 0.285775]\n",
      "[Epoch 62/100] [Batch 97/347] [D loss: 0.500381] [G loss: 0.284047]\n",
      "[Epoch 62/100] [Batch 98/347] [D loss: 0.500575] [G loss: 0.284336]\n",
      "[Epoch 62/100] [Batch 99/347] [D loss: 0.500697] [G loss: 0.283596]\n",
      "[Epoch 62/100] [Batch 100/347] [D loss: 0.500648] [G loss: 0.282274]\n",
      "[Epoch 62/100] [Batch 101/347] [D loss: 0.500387] [G loss: 0.279197]\n",
      "[Epoch 62/100] [Batch 102/347] [D loss: 0.500039] [G loss: 0.275639]\n",
      "[Epoch 62/100] [Batch 103/347] [D loss: 0.500119] [G loss: 0.275938]\n",
      "[Epoch 62/100] [Batch 104/347] [D loss: 0.499380] [G loss: 0.270246]\n",
      "[Epoch 62/100] [Batch 105/347] [D loss: 0.496820] [G loss: 0.262955]\n",
      "[Epoch 62/100] [Batch 106/347] [D loss: 0.487006] [G loss: 0.264909]\n",
      "[Epoch 62/100] [Batch 107/347] [D loss: 0.486829] [G loss: 0.267113]\n",
      "[Epoch 62/100] [Batch 108/347] [D loss: 0.486054] [G loss: 0.266903]\n",
      "[Epoch 62/100] [Batch 109/347] [D loss: 0.481974] [G loss: 0.268182]\n",
      "[Epoch 62/100] [Batch 110/347] [D loss: 0.492860] [G loss: 0.262014]\n",
      "[Epoch 62/100] [Batch 111/347] [D loss: 0.493245] [G loss: 0.260193]\n",
      "[Epoch 62/100] [Batch 112/347] [D loss: 0.493541] [G loss: 0.261394]\n",
      "[Epoch 62/100] [Batch 113/347] [D loss: 0.501827] [G loss: 0.276836]\n",
      "[Epoch 62/100] [Batch 114/347] [D loss: 0.505202] [G loss: 0.285158]\n",
      "[Epoch 62/100] [Batch 115/347] [D loss: 0.501738] [G loss: 0.270868]\n",
      "[Epoch 62/100] [Batch 116/347] [D loss: 0.497693] [G loss: 0.258789]\n",
      "[Epoch 62/100] [Batch 117/347] [D loss: 0.495561] [G loss: 0.255656]\n",
      "[Epoch 62/100] [Batch 118/347] [D loss: 0.492677] [G loss: 0.257774]\n",
      "[Epoch 62/100] [Batch 119/347] [D loss: 0.492683] [G loss: 0.259851]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 62/100] [Batch 120/347] [D loss: 0.494310] [G loss: 0.255174]\n",
      "[Epoch 62/100] [Batch 121/347] [D loss: 0.494606] [G loss: 0.255809]\n",
      "[Epoch 62/100] [Batch 122/347] [D loss: 0.496135] [G loss: 0.258062]\n",
      "[Epoch 62/100] [Batch 123/347] [D loss: 0.497380] [G loss: 0.265265]\n",
      "[Epoch 62/100] [Batch 124/347] [D loss: 0.497239] [G loss: 0.267259]\n",
      "[Epoch 62/100] [Batch 125/347] [D loss: 0.497861] [G loss: 0.272578]\n",
      "[Epoch 62/100] [Batch 126/347] [D loss: 0.498209] [G loss: 0.275512]\n",
      "[Epoch 62/100] [Batch 127/347] [D loss: 0.497795] [G loss: 0.272990]\n",
      "[Epoch 62/100] [Batch 128/347] [D loss: 0.495486] [G loss: 0.263586]\n",
      "[Epoch 62/100] [Batch 129/347] [D loss: 0.486818] [G loss: 0.262176]\n",
      "[Epoch 62/100] [Batch 130/347] [D loss: 0.470370] [G loss: 0.263041]\n",
      "[Epoch 62/100] [Batch 131/347] [D loss: 0.463115] [G loss: 0.270213]\n",
      "[Epoch 62/100] [Batch 132/347] [D loss: 0.453629] [G loss: 0.284371]\n",
      "[Epoch 62/100] [Batch 133/347] [D loss: 0.437782] [G loss: 0.283791]\n",
      "[Epoch 62/100] [Batch 134/347] [D loss: 0.438628] [G loss: 0.263149]\n",
      "[Epoch 62/100] [Batch 135/347] [D loss: 0.439935] [G loss: 0.255585]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 62/100] [Batch 136/347] [D loss: 0.442184] [G loss: 0.245631]\n",
      "[Epoch 62/100] [Batch 137/347] [D loss: 0.478953] [G loss: 0.247514]\n",
      "[Epoch 62/100] [Batch 138/347] [D loss: 0.475933] [G loss: 0.268059]\n",
      "[Epoch 62/100] [Batch 139/347] [D loss: 0.472407] [G loss: 0.284701]\n",
      "[Epoch 62/100] [Batch 140/347] [D loss: 0.469375] [G loss: 0.299455]\n",
      "[Epoch 62/100] [Batch 141/347] [D loss: 0.462052] [G loss: 0.317826]\n",
      "[Epoch 62/100] [Batch 142/347] [D loss: 0.461226] [G loss: 0.323944]\n",
      "[Epoch 62/100] [Batch 143/347] [D loss: 0.458803] [G loss: 0.329778]\n",
      "[Epoch 62/100] [Batch 144/347] [D loss: 0.459482] [G loss: 0.324658]\n",
      "[Epoch 62/100] [Batch 145/347] [D loss: 0.466570] [G loss: 0.305761]\n",
      "[Epoch 62/100] [Batch 146/347] [D loss: 0.470003] [G loss: 0.294393]\n",
      "[Epoch 62/100] [Batch 147/347] [D loss: 0.474404] [G loss: 0.286259]\n",
      "[Epoch 62/100] [Batch 148/347] [D loss: 0.477709] [G loss: 0.279642]\n",
      "[Epoch 62/100] [Batch 149/347] [D loss: 0.475916] [G loss: 0.282871]\n",
      "[Epoch 62/100] [Batch 150/347] [D loss: 0.472670] [G loss: 0.291130]\n",
      "[Epoch 62/100] [Batch 151/347] [D loss: 0.468814] [G loss: 0.296781]\n",
      "[Epoch 62/100] [Batch 152/347] [D loss: 0.463689] [G loss: 0.303793]\n",
      "[Epoch 62/100] [Batch 153/347] [D loss: 0.462482] [G loss: 0.306041]\n",
      "[Epoch 62/100] [Batch 154/347] [D loss: 0.463041] [G loss: 0.300209]\n",
      "[Epoch 62/100] [Batch 155/347] [D loss: 0.461585] [G loss: 0.298904]\n",
      "[Epoch 62/100] [Batch 156/347] [D loss: 0.458898] [G loss: 0.302935]\n",
      "[Epoch 62/100] [Batch 157/347] [D loss: 0.457183] [G loss: 0.303431]\n",
      "[Epoch 62/100] [Batch 158/347] [D loss: 0.448117] [G loss: 0.306682]\n",
      "[Epoch 62/100] [Batch 159/347] [D loss: 0.448011] [G loss: 0.307429]\n",
      "[Epoch 62/100] [Batch 160/347] [D loss: 0.450298] [G loss: 0.301433]\n",
      "[Epoch 62/100] [Batch 161/347] [D loss: 0.445185] [G loss: 0.310988]\n",
      "[Epoch 62/100] [Batch 162/347] [D loss: 0.444367] [G loss: 0.323770]\n",
      "[Epoch 62/100] [Batch 163/347] [D loss: 0.444151] [G loss: 0.327370]\n",
      "[Epoch 62/100] [Batch 164/347] [D loss: 0.445788] [G loss: 0.317455]\n",
      "[Epoch 62/100] [Batch 165/347] [D loss: 0.447935] [G loss: 0.301447]\n",
      "[Epoch 62/100] [Batch 166/347] [D loss: 0.463549] [G loss: 0.274296]\n",
      "[Epoch 62/100] [Batch 167/347] [D loss: 0.477227] [G loss: 0.271175]\n",
      "[Epoch 62/100] [Batch 168/347] [D loss: 0.480234] [G loss: 0.274823]\n",
      "[Epoch 62/100] [Batch 169/347] [D loss: 0.494973] [G loss: 0.276122]\n",
      "[Epoch 62/100] [Batch 170/347] [D loss: 0.503648] [G loss: 0.284951]\n",
      "[Epoch 62/100] [Batch 171/347] [D loss: 0.504464] [G loss: 0.289341]\n",
      "[Epoch 62/100] [Batch 172/347] [D loss: 0.505718] [G loss: 0.295889]\n",
      "[Epoch 62/100] [Batch 173/347] [D loss: 0.505741] [G loss: 0.300845]\n",
      "[Epoch 62/100] [Batch 174/347] [D loss: 0.507412] [G loss: 0.311077]\n",
      "[Epoch 62/100] [Batch 175/347] [D loss: 0.510544] [G loss: 0.322366]\n",
      "[Epoch 62/100] [Batch 176/347] [D loss: 0.512584] [G loss: 0.331984]\n",
      "[Epoch 62/100] [Batch 177/347] [D loss: 0.511509] [G loss: 0.334972]\n",
      "[Epoch 62/100] [Batch 178/347] [D loss: 0.509533] [G loss: 0.334050]\n",
      "[Epoch 62/100] [Batch 179/347] [D loss: 0.508517] [G loss: 0.334281]\n",
      "[Epoch 62/100] [Batch 180/347] [D loss: 0.507370] [G loss: 0.332080]\n",
      "[Epoch 62/100] [Batch 181/347] [D loss: 0.508194] [G loss: 0.335329]\n",
      "[Epoch 62/100] [Batch 182/347] [D loss: 0.508409] [G loss: 0.335501]\n",
      "[Epoch 62/100] [Batch 183/347] [D loss: 0.508734] [G loss: 0.335921]\n",
      "[Epoch 62/100] [Batch 184/347] [D loss: 0.509949] [G loss: 0.336458]\n",
      "[Epoch 62/100] [Batch 185/347] [D loss: 0.509041] [G loss: 0.331541]\n",
      "[Epoch 62/100] [Batch 186/347] [D loss: 0.508304] [G loss: 0.328174]\n",
      "[Epoch 62/100] [Batch 187/347] [D loss: 0.506989] [G loss: 0.322844]\n",
      "[Epoch 62/100] [Batch 188/347] [D loss: 0.503230] [G loss: 0.311689]\n",
      "[Epoch 62/100] [Batch 189/347] [D loss: 0.499716] [G loss: 0.300799]\n",
      "[Epoch 62/100] [Batch 190/347] [D loss: 0.498415] [G loss: 0.292563]\n",
      "[Epoch 62/100] [Batch 191/347] [D loss: 0.497428] [G loss: 0.283761]\n",
      "[Epoch 62/100] [Batch 192/347] [D loss: 0.497679] [G loss: 0.278512]\n",
      "[Epoch 62/100] [Batch 193/347] [D loss: 0.498980] [G loss: 0.275501]\n",
      "[Epoch 62/100] [Batch 194/347] [D loss: 0.496813] [G loss: 0.270540]\n",
      "[Epoch 62/100] [Batch 195/347] [D loss: 0.494788] [G loss: 0.267900]\n",
      "[Epoch 62/100] [Batch 196/347] [D loss: 0.492231] [G loss: 0.266446]\n",
      "[Epoch 62/100] [Batch 197/347] [D loss: 0.491545] [G loss: 0.268155]\n",
      "[Epoch 62/100] [Batch 198/347] [D loss: 0.492532] [G loss: 0.273238]\n",
      "[Epoch 62/100] [Batch 199/347] [D loss: 0.492472] [G loss: 0.273421]\n",
      "[Epoch 62/100] [Batch 200/347] [D loss: 0.493459] [G loss: 0.274584]\n",
      "[Epoch 62/100] [Batch 201/347] [D loss: 0.492912] [G loss: 0.274092]\n",
      "[Epoch 62/100] [Batch 202/347] [D loss: 0.492128] [G loss: 0.272222]\n",
      "[Epoch 62/100] [Batch 203/347] [D loss: 0.491582] [G loss: 0.269478]\n",
      "[Epoch 62/100] [Batch 204/347] [D loss: 0.492680] [G loss: 0.270235]\n",
      "[Epoch 62/100] [Batch 205/347] [D loss: 0.494645] [G loss: 0.272862]\n",
      "[Epoch 62/100] [Batch 206/347] [D loss: 0.495696] [G loss: 0.274226]\n",
      "[Epoch 62/100] [Batch 207/347] [D loss: 0.495851] [G loss: 0.275296]\n",
      "[Epoch 62/100] [Batch 208/347] [D loss: 0.496830] [G loss: 0.278868]\n",
      "[Epoch 62/100] [Batch 209/347] [D loss: 0.494354] [G loss: 0.274743]\n",
      "[Epoch 62/100] [Batch 210/347] [D loss: 0.490993] [G loss: 0.274580]\n",
      "[Epoch 62/100] [Batch 211/347] [D loss: 0.474642] [G loss: 0.276284]\n",
      "[Epoch 62/100] [Batch 212/347] [D loss: 0.429795] [G loss: 0.275348]\n",
      "[Epoch 62/100] [Batch 213/347] [D loss: 0.427793] [G loss: 0.274687]\n",
      "[Epoch 62/100] [Batch 214/347] [D loss: 0.426829] [G loss: 0.272160]\n",
      "[Epoch 62/100] [Batch 215/347] [D loss: 0.426564] [G loss: 0.272614]\n",
      "[Epoch 62/100] [Batch 216/347] [D loss: 0.484192] [G loss: 0.269258]\n",
      "[Epoch 62/100] [Batch 217/347] [D loss: 0.494606] [G loss: 0.279090]\n",
      "[Epoch 62/100] [Batch 218/347] [D loss: 0.503193] [G loss: 0.298379]\n",
      "[Epoch 62/100] [Batch 219/347] [D loss: 0.505476] [G loss: 0.310838]\n",
      "[Epoch 62/100] [Batch 220/347] [D loss: 0.505612] [G loss: 0.320806]\n",
      "[Epoch 62/100] [Batch 221/347] [D loss: 0.505956] [G loss: 0.326391]\n",
      "[Epoch 62/100] [Batch 222/347] [D loss: 0.503796] [G loss: 0.321869]\n",
      "[Epoch 62/100] [Batch 223/347] [D loss: 0.496409] [G loss: 0.311490]\n",
      "[Epoch 62/100] [Batch 224/347] [D loss: 0.489223] [G loss: 0.299619]\n",
      "[Epoch 62/100] [Batch 225/347] [D loss: 0.483495] [G loss: 0.277215]\n",
      "[Epoch 62/100] [Batch 226/347] [D loss: 0.477722] [G loss: 0.276113]\n",
      "[Epoch 62/100] [Batch 227/347] [D loss: 0.475845] [G loss: 0.266260]\n",
      "[Epoch 62/100] [Batch 228/347] [D loss: 0.477517] [G loss: 0.257687]\n",
      "[Epoch 62/100] [Batch 229/347] [D loss: 0.480835] [G loss: 0.247049]\n",
      "[Epoch 62/100] [Batch 230/347] [D loss: 0.484667] [G loss: 0.240200]\n",
      "[Epoch 62/100] [Batch 231/347] [D loss: 0.482605] [G loss: 0.238148]\n",
      "[Epoch 62/100] [Batch 232/347] [D loss: 0.481195] [G loss: 0.244705]\n",
      "[Epoch 62/100] [Batch 233/347] [D loss: 0.479210] [G loss: 0.249030]\n",
      "[Epoch 62/100] [Batch 234/347] [D loss: 0.478469] [G loss: 0.265928]\n",
      "[Epoch 62/100] [Batch 235/347] [D loss: 0.482722] [G loss: 0.278877]\n",
      "[Epoch 62/100] [Batch 236/347] [D loss: 0.488538] [G loss: 0.288846]\n",
      "[Epoch 62/100] [Batch 237/347] [D loss: 0.494233] [G loss: 0.299041]\n",
      "[Epoch 62/100] [Batch 238/347] [D loss: 0.498367] [G loss: 0.300950]\n",
      "[Epoch 62/100] [Batch 239/347] [D loss: 0.497117] [G loss: 0.297712]\n",
      "[Epoch 62/100] [Batch 240/347] [D loss: 0.496624] [G loss: 0.295042]\n",
      "[Epoch 62/100] [Batch 241/347] [D loss: 0.496908] [G loss: 0.293435]\n",
      "[Epoch 62/100] [Batch 242/347] [D loss: 0.498330] [G loss: 0.292859]\n",
      "[Epoch 62/100] [Batch 243/347] [D loss: 0.497550] [G loss: 0.290962]\n",
      "[Epoch 62/100] [Batch 244/347] [D loss: 0.492199] [G loss: 0.280384]\n",
      "[Epoch 62/100] [Batch 245/347] [D loss: 0.487277] [G loss: 0.270840]\n",
      "[Epoch 62/100] [Batch 246/347] [D loss: 0.481328] [G loss: 0.258075]\n",
      "[Epoch 62/100] [Batch 247/347] [D loss: 0.477506] [G loss: 0.260674]\n",
      "[Epoch 62/100] [Batch 248/347] [D loss: 0.479310] [G loss: 0.256119]\n",
      "[Epoch 62/100] [Batch 249/347] [D loss: 0.480749] [G loss: 0.256212]\n",
      "[Epoch 62/100] [Batch 250/347] [D loss: 0.485189] [G loss: 0.268675]\n",
      "[Epoch 62/100] [Batch 251/347] [D loss: 0.491496] [G loss: 0.280112]\n",
      "[Epoch 62/100] [Batch 252/347] [D loss: 0.493909] [G loss: 0.286445]\n",
      "[Epoch 62/100] [Batch 253/347] [D loss: 0.485017] [G loss: 0.291089]\n",
      "[Epoch 62/100] [Batch 254/347] [D loss: 0.484095] [G loss: 0.296425]\n",
      "[Epoch 62/100] [Batch 255/347] [D loss: 0.483707] [G loss: 0.298634]\n",
      "[Epoch 62/100] [Batch 256/347] [D loss: 0.481508] [G loss: 0.296474]\n",
      "[Epoch 62/100] [Batch 257/347] [D loss: 0.480726] [G loss: 0.291621]\n",
      "[Epoch 62/100] [Batch 258/347] [D loss: 0.472800] [G loss: 0.283867]\n",
      "[Epoch 62/100] [Batch 259/347] [D loss: 0.470854] [G loss: 0.273757]\n",
      "[Epoch 62/100] [Batch 260/347] [D loss: 0.471093] [G loss: 0.266416]\n",
      "[Epoch 62/100] [Batch 261/347] [D loss: 0.468288] [G loss: 0.266634]\n",
      "[Epoch 62/100] [Batch 262/347] [D loss: 0.458087] [G loss: 0.265865]\n",
      "[Epoch 62/100] [Batch 263/347] [D loss: 0.455382] [G loss: 0.266271]\n",
      "[Epoch 62/100] [Batch 264/347] [D loss: 0.452835] [G loss: 0.269390]\n",
      "[Epoch 62/100] [Batch 265/347] [D loss: 0.453205] [G loss: 0.271707]\n",
      "[Epoch 62/100] [Batch 266/347] [D loss: 0.461663] [G loss: 0.274846]\n",
      "[Epoch 62/100] [Batch 267/347] [D loss: 0.463525] [G loss: 0.276020]\n",
      "[Epoch 62/100] [Batch 268/347] [D loss: 0.466019] [G loss: 0.274895]\n",
      "[Epoch 62/100] [Batch 269/347] [D loss: 0.463930] [G loss: 0.272699]\n",
      "[Epoch 62/100] [Batch 270/347] [D loss: 0.469488] [G loss: 0.267919]\n",
      "[Epoch 62/100] [Batch 271/347] [D loss: 0.431480] [G loss: 0.270522]\n",
      "[Epoch 62/100] [Batch 272/347] [D loss: 0.295390] [G loss: 0.294675]\n",
      "[Epoch 62/100] [Batch 273/347] [D loss: 0.287244] [G loss: 0.312674]\n",
      "[Epoch 62/100] [Batch 274/347] [D loss: 0.277672] [G loss: 0.327549]\n",
      "[Epoch 62/100] [Batch 275/347] [D loss: 0.276913] [G loss: 0.330380]\n",
      "[Epoch 62/100] [Batch 276/347] [D loss: 0.483866] [G loss: 0.322383]\n",
      "[Epoch 62/100] [Batch 277/347] [D loss: 0.495847] [G loss: 0.325980]\n",
      "[Epoch 62/100] [Batch 278/347] [D loss: 0.498354] [G loss: 0.327051]\n",
      "[Epoch 62/100] [Batch 279/347] [D loss: 0.497977] [G loss: 0.327727]\n",
      "[Epoch 62/100] [Batch 280/347] [D loss: 0.495912] [G loss: 0.325179]\n",
      "[Epoch 62/100] [Batch 281/347] [D loss: 0.492886] [G loss: 0.318998]\n",
      "[Epoch 62/100] [Batch 282/347] [D loss: 0.490284] [G loss: 0.310010]\n",
      "[Epoch 62/100] [Batch 283/347] [D loss: 0.485286] [G loss: 0.293950]\n",
      "[Epoch 62/100] [Batch 284/347] [D loss: 0.480203] [G loss: 0.271906]\n",
      "[Epoch 62/100] [Batch 285/347] [D loss: 0.477535] [G loss: 0.246477]\n",
      "[Epoch 62/100] [Batch 286/347] [D loss: 0.462673] [G loss: 0.234775]\n",
      "[Epoch 62/100] [Batch 287/347] [D loss: 0.464225] [G loss: 0.224794]\n",
      "[Epoch 62/100] [Batch 288/347] [D loss: 0.466259] [G loss: 0.223721]\n",
      "[Epoch 62/100] [Batch 289/347] [D loss: 0.463444] [G loss: 0.232790]\n",
      "[Epoch 62/100] [Batch 290/347] [D loss: 0.473572] [G loss: 0.227511]\n",
      "[Epoch 62/100] [Batch 291/347] [D loss: 0.471996] [G loss: 0.248668]\n",
      "[Epoch 62/100] [Batch 292/347] [D loss: 0.469184] [G loss: 0.271552]\n",
      "[Epoch 62/100] [Batch 293/347] [D loss: 0.437890] [G loss: 0.293437]\n",
      "[Epoch 62/100] [Batch 294/347] [D loss: 0.438513] [G loss: 0.308522]\n",
      "[Epoch 62/100] [Batch 295/347] [D loss: 0.442142] [G loss: 0.316674]\n",
      "[Epoch 62/100] [Batch 296/347] [D loss: 0.445058] [G loss: 0.319869]\n",
      "[Epoch 62/100] [Batch 297/347] [D loss: 0.491618] [G loss: 0.326810]\n",
      "[Epoch 62/100] [Batch 298/347] [D loss: 0.496242] [G loss: 0.320745]\n",
      "[Epoch 62/100] [Batch 299/347] [D loss: 0.491256] [G loss: 0.314139]\n",
      "[Epoch 62/100] [Batch 300/347] [D loss: 0.485524] [G loss: 0.307754]\n",
      "[Epoch 62/100] [Batch 301/347] [D loss: 0.476912] [G loss: 0.291372]\n",
      "[Epoch 62/100] [Batch 302/347] [D loss: 0.475960] [G loss: 0.275985]\n",
      "[Epoch 62/100] [Batch 303/347] [D loss: 0.471724] [G loss: 0.257201]\n",
      "[Epoch 62/100] [Batch 304/347] [D loss: 0.447987] [G loss: 0.256557]\n",
      "[Epoch 62/100] [Batch 305/347] [D loss: 0.431711] [G loss: 0.258597]\n",
      "[Epoch 62/100] [Batch 306/347] [D loss: 0.431364] [G loss: 0.261599]\n",
      "[Epoch 62/100] [Batch 307/347] [D loss: 0.429883] [G loss: 0.262492]\n",
      "[Epoch 62/100] [Batch 308/347] [D loss: 0.445686] [G loss: 0.276614]\n",
      "[Epoch 62/100] [Batch 309/347] [D loss: 0.487150] [G loss: 0.301027]\n",
      "[Epoch 62/100] [Batch 310/347] [D loss: 0.505861] [G loss: 0.323169]\n",
      "[Epoch 62/100] [Batch 311/347] [D loss: 0.504283] [G loss: 0.329947]\n",
      "[Epoch 62/100] [Batch 312/347] [D loss: 0.499200] [G loss: 0.331984]\n",
      "[Epoch 62/100] [Batch 313/347] [D loss: 0.491463] [G loss: 0.326626]\n",
      "[Epoch 62/100] [Batch 314/347] [D loss: 0.485080] [G loss: 0.312038]\n",
      "[Epoch 62/100] [Batch 315/347] [D loss: 0.480138] [G loss: 0.297307]\n",
      "[Epoch 62/100] [Batch 316/347] [D loss: 0.481249] [G loss: 0.292302]\n",
      "[Epoch 62/100] [Batch 317/347] [D loss: 0.485228] [G loss: 0.289089]\n",
      "[Epoch 62/100] [Batch 318/347] [D loss: 0.493248] [G loss: 0.296711]\n",
      "[Epoch 62/100] [Batch 319/347] [D loss: 0.503433] [G loss: 0.306024]\n",
      "[Epoch 62/100] [Batch 320/347] [D loss: 0.504795] [G loss: 0.305874]\n",
      "[Epoch 62/100] [Batch 321/347] [D loss: 0.498549] [G loss: 0.303657]\n",
      "[Epoch 62/100] [Batch 322/347] [D loss: 0.495563] [G loss: 0.303588]\n",
      "[Epoch 62/100] [Batch 323/347] [D loss: 0.484588] [G loss: 0.302778]\n",
      "[Epoch 62/100] [Batch 324/347] [D loss: 0.477432] [G loss: 0.303697]\n",
      "[Epoch 62/100] [Batch 325/347] [D loss: 0.475939] [G loss: 0.301781]\n",
      "[Epoch 62/100] [Batch 326/347] [D loss: 0.473487] [G loss: 0.297098]\n",
      "[Epoch 62/100] [Batch 327/347] [D loss: 0.461370] [G loss: 0.292854]\n",
      "[Epoch 62/100] [Batch 328/347] [D loss: 0.458867] [G loss: 0.286559]\n",
      "[Epoch 62/100] [Batch 329/347] [D loss: 0.459188] [G loss: 0.282522]\n",
      "[Epoch 62/100] [Batch 330/347] [D loss: 0.460513] [G loss: 0.279234]\n",
      "[Epoch 62/100] [Batch 331/347] [D loss: 0.473635] [G loss: 0.282142]\n",
      "[Epoch 62/100] [Batch 332/347] [D loss: 0.498172] [G loss: 0.301757]\n",
      "[Epoch 62/100] [Batch 333/347] [D loss: 0.494472] [G loss: 0.302733]\n",
      "[Epoch 62/100] [Batch 334/347] [D loss: 0.488482] [G loss: 0.300022]\n",
      "[Epoch 62/100] [Batch 335/347] [D loss: 0.487707] [G loss: 0.302786]\n",
      "[Epoch 62/100] [Batch 336/347] [D loss: 0.488540] [G loss: 0.305872]\n",
      "[Epoch 62/100] [Batch 337/347] [D loss: 0.495746] [G loss: 0.313937]\n",
      "[Epoch 62/100] [Batch 338/347] [D loss: 0.505481] [G loss: 0.325525]\n",
      "[Epoch 62/100] [Batch 339/347] [D loss: 0.503150] [G loss: 0.328966]\n",
      "[Epoch 62/100] [Batch 340/347] [D loss: 0.500308] [G loss: 0.327275]\n",
      "[Epoch 62/100] [Batch 341/347] [D loss: 0.501240] [G loss: 0.328017]\n",
      "[Epoch 62/100] [Batch 342/347] [D loss: 0.470357] [G loss: 0.313663]\n",
      "[Epoch 62/100] [Batch 343/347] [D loss: 0.457760] [G loss: 0.293326]\n",
      "[Epoch 62/100] [Batch 344/347] [D loss: 0.419537] [G loss: 0.281860]\n",
      "[Epoch 62/100] [Batch 345/347] [D loss: 0.368323] [G loss: 0.277076]\n",
      "[Epoch 62/100] [Batch 346/347] [D loss: 0.369147] [G loss: 0.278894]\n",
      "[Epoch 62/100] [Batch 347/347] [D loss: 0.366564] [G loss: 0.285366]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 63/100] [Batch 1/347] [D loss: 0.491140] [G loss: 0.305228]\n",
      "[Epoch 63/100] [Batch 2/347] [D loss: 0.493930] [G loss: 0.309270]\n",
      "[Epoch 63/100] [Batch 3/347] [D loss: 0.500153] [G loss: 0.316066]\n",
      "[Epoch 63/100] [Batch 4/347] [D loss: 0.501136] [G loss: 0.318034]\n",
      "[Epoch 63/100] [Batch 5/347] [D loss: 0.499250] [G loss: 0.315029]\n",
      "[Epoch 63/100] [Batch 6/347] [D loss: 0.495922] [G loss: 0.310716]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 63/100] [Batch 7/347] [D loss: 0.487160] [G loss: 0.298654]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 63/100] [Batch 8/347] [D loss: 0.485524] [G loss: 0.291792]\n",
      "[Epoch 63/100] [Batch 9/347] [D loss: 0.485589] [G loss: 0.287299]\n",
      "[Epoch 63/100] [Batch 10/347] [D loss: 0.487207] [G loss: 0.283663]\n",
      "[Epoch 63/100] [Batch 11/347] [D loss: 0.497777] [G loss: 0.290935]\n",
      "[Epoch 63/100] [Batch 12/347] [D loss: 0.500100] [G loss: 0.294382]\n",
      "[Epoch 63/100] [Batch 13/347] [D loss: 0.497427] [G loss: 0.296288]\n",
      "[Epoch 63/100] [Batch 14/347] [D loss: 0.494393] [G loss: 0.299946]\n",
      "[Epoch 63/100] [Batch 15/347] [D loss: 0.485306] [G loss: 0.294124]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 63/100] [Batch 16/347] [D loss: 0.481015] [G loss: 0.289907]\n",
      "[Epoch 63/100] [Batch 17/347] [D loss: 0.481896] [G loss: 0.291737]\n",
      "[Epoch 63/100] [Batch 18/347] [D loss: 0.483446] [G loss: 0.289837]\n",
      "[Epoch 63/100] [Batch 19/347] [D loss: 0.488482] [G loss: 0.291645]\n",
      "[Epoch 63/100] [Batch 20/347] [D loss: 0.493735] [G loss: 0.293021]\n",
      "[Epoch 63/100] [Batch 21/347] [D loss: 0.487102] [G loss: 0.285493]\n",
      "[Epoch 63/100] [Batch 22/347] [D loss: 0.485357] [G loss: 0.281795]\n",
      "[Epoch 63/100] [Batch 23/347] [D loss: 0.482143] [G loss: 0.277285]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 63/100] [Batch 24/347] [D loss: 0.467310] [G loss: 0.268119]\n",
      "[Epoch 63/100] [Batch 25/347] [D loss: 0.440328] [G loss: 0.275259]\n",
      "[Epoch 63/100] [Batch 26/347] [D loss: 0.439836] [G loss: 0.276383]\n",
      "[Epoch 63/100] [Batch 27/347] [D loss: 0.438627] [G loss: 0.281811]\n",
      "[Epoch 63/100] [Batch 28/347] [D loss: 0.434313] [G loss: 0.289508]\n",
      "[Epoch 63/100] [Batch 29/347] [D loss: 0.455184] [G loss: 0.294292]\n",
      "[Epoch 63/100] [Batch 30/347] [D loss: 0.444802] [G loss: 0.296737]\n",
      "[Epoch 63/100] [Batch 31/347] [D loss: 0.443889] [G loss: 0.297258]\n",
      "[Epoch 63/100] [Batch 32/347] [D loss: 0.447754] [G loss: 0.295064]\n",
      "[Epoch 63/100] [Batch 33/347] [D loss: 0.455945] [G loss: 0.293816]\n",
      "[Epoch 63/100] [Batch 34/347] [D loss: 0.466998] [G loss: 0.289647]\n",
      "[Epoch 63/100] [Batch 35/347] [D loss: 0.456162] [G loss: 0.282900]\n",
      "[Epoch 63/100] [Batch 36/347] [D loss: 0.455051] [G loss: 0.273759]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 63/100] [Batch 37/347] [D loss: 0.455709] [G loss: 0.262210]\n",
      "[Epoch 63/100] [Batch 38/347] [D loss: 0.457032] [G loss: 0.263157]\n",
      "[Epoch 63/100] [Batch 39/347] [D loss: 0.462931] [G loss: 0.257340]\n",
      "[Epoch 63/100] [Batch 40/347] [D loss: 0.473428] [G loss: 0.256324]\n",
      "[Epoch 63/100] [Batch 41/347] [D loss: 0.477233] [G loss: 0.259698]\n",
      "[Epoch 63/100] [Batch 42/347] [D loss: 0.481314] [G loss: 0.274412]\n",
      "[Epoch 63/100] [Batch 43/347] [D loss: 0.493363] [G loss: 0.295385]\n",
      "[Epoch 63/100] [Batch 44/347] [D loss: 0.494618] [G loss: 0.307505]\n",
      "[Epoch 63/100] [Batch 45/347] [D loss: 0.487011] [G loss: 0.303919]\n",
      "[Epoch 63/100] [Batch 46/347] [D loss: 0.457515] [G loss: 0.299859]\n",
      "[Epoch 63/100] [Batch 47/347] [D loss: 0.445314] [G loss: 0.289034]\n",
      "[Epoch 63/100] [Batch 48/347] [D loss: 0.369180] [G loss: 0.297728]\n",
      "[Epoch 63/100] [Batch 49/347] [D loss: 0.365749] [G loss: 0.293766]\n",
      "[Epoch 63/100] [Batch 50/347] [D loss: 0.364669] [G loss: 0.301632]\n",
      "[Epoch 63/100] [Batch 51/347] [D loss: 0.362367] [G loss: 0.307291]\n",
      "[Epoch 63/100] [Batch 52/347] [D loss: 0.414525] [G loss: 0.302376]\n",
      "[Epoch 63/100] [Batch 53/347] [D loss: 0.421925] [G loss: 0.306355]\n",
      "[Epoch 63/100] [Batch 54/347] [D loss: 0.414110] [G loss: 0.311540]\n",
      "[Epoch 63/100] [Batch 55/347] [D loss: 0.412870] [G loss: 0.301849]\n",
      "[Epoch 63/100] [Batch 56/347] [D loss: 0.418074] [G loss: 0.279455]\n",
      "[Epoch 63/100] [Batch 57/347] [D loss: 0.418600] [G loss: 0.280608]\n",
      "[Epoch 63/100] [Batch 58/347] [D loss: 0.425795] [G loss: 0.289537]\n",
      "[Epoch 63/100] [Batch 59/347] [D loss: 0.418348] [G loss: 0.294587]\n",
      "[Epoch 63/100] [Batch 60/347] [D loss: 0.401762] [G loss: 0.309280]\n",
      "[Epoch 63/100] [Batch 61/347] [D loss: 0.404871] [G loss: 0.320072]\n",
      "[Epoch 63/100] [Batch 62/347] [D loss: 0.406332] [G loss: 0.314013]\n",
      "[Epoch 63/100] [Batch 63/347] [D loss: 0.408978] [G loss: 0.300757]\n",
      "[Epoch 63/100] [Batch 64/347] [D loss: 0.400190] [G loss: 0.301096]\n",
      "[Epoch 63/100] [Batch 65/347] [D loss: 0.363077] [G loss: 0.308817]\n",
      "[Epoch 63/100] [Batch 66/347] [D loss: 0.362615] [G loss: 0.309886]\n",
      "[Epoch 63/100] [Batch 67/347] [D loss: 0.362476] [G loss: 0.306060]\n",
      "[Epoch 63/100] [Batch 68/347] [D loss: 0.363867] [G loss: 0.315514]\n",
      "[Epoch 63/100] [Batch 69/347] [D loss: 0.376971] [G loss: 0.327290]\n",
      "[Epoch 63/100] [Batch 70/347] [D loss: 0.378700] [G loss: 0.324497]\n",
      "[Epoch 63/100] [Batch 71/347] [D loss: 0.380373] [G loss: 0.307858]\n",
      "[Epoch 63/100] [Batch 72/347] [D loss: 0.383519] [G loss: 0.303012]\n",
      "[Epoch 63/100] [Batch 73/347] [D loss: 0.416648] [G loss: 0.299152]\n",
      "[Epoch 63/100] [Batch 74/347] [D loss: 0.420035] [G loss: 0.290012]\n",
      "[Epoch 63/100] [Batch 75/347] [D loss: 0.422716] [G loss: 0.292616]\n",
      "[Epoch 63/100] [Batch 76/347] [D loss: 0.428271] [G loss: 0.296860]\n",
      "[Epoch 63/100] [Batch 77/347] [D loss: 0.460576] [G loss: 0.302573]\n",
      "[Epoch 63/100] [Batch 78/347] [D loss: 0.494946] [G loss: 0.311008]\n",
      "[Epoch 63/100] [Batch 79/347] [D loss: 0.503278] [G loss: 0.325189]\n",
      "[Epoch 63/100] [Batch 80/347] [D loss: 0.468466] [G loss: 0.325403]\n",
      "[Epoch 63/100] [Batch 81/347] [D loss: 0.461255] [G loss: 0.330220]\n",
      "[Epoch 63/100] [Batch 82/347] [D loss: 0.462568] [G loss: 0.333224]\n",
      "[Epoch 63/100] [Batch 83/347] [D loss: 0.464550] [G loss: 0.330165]\n",
      "[Epoch 63/100] [Batch 84/347] [D loss: 0.502900] [G loss: 0.334344]\n",
      "[Epoch 63/100] [Batch 85/347] [D loss: 0.521490] [G loss: 0.338774]\n",
      "[Epoch 63/100] [Batch 86/347] [D loss: 0.520630] [G loss: 0.345843]\n",
      "[Epoch 63/100] [Batch 87/347] [D loss: 0.520492] [G loss: 0.354645]\n",
      "[Epoch 63/100] [Batch 88/347] [D loss: 0.522052] [G loss: 0.363143]\n",
      "[Epoch 63/100] [Batch 89/347] [D loss: 0.523438] [G loss: 0.372383]\n",
      "[Epoch 63/100] [Batch 90/347] [D loss: 0.522149] [G loss: 0.377655]\n",
      "[Epoch 63/100] [Batch 91/347] [D loss: 0.521172] [G loss: 0.379748]\n",
      "[Epoch 63/100] [Batch 92/347] [D loss: 0.521033] [G loss: 0.382047]\n",
      "[Epoch 63/100] [Batch 93/347] [D loss: 0.520648] [G loss: 0.382899]\n",
      "[Epoch 63/100] [Batch 94/347] [D loss: 0.518256] [G loss: 0.378235]\n",
      "[Epoch 63/100] [Batch 95/347] [D loss: 0.517056] [G loss: 0.375325]\n",
      "[Epoch 63/100] [Batch 96/347] [D loss: 0.517096] [G loss: 0.373447]\n",
      "[Epoch 63/100] [Batch 97/347] [D loss: 0.515697] [G loss: 0.368692]\n",
      "[Epoch 63/100] [Batch 98/347] [D loss: 0.515522] [G loss: 0.365163]\n",
      "[Epoch 63/100] [Batch 99/347] [D loss: 0.516225] [G loss: 0.359762]\n",
      "[Epoch 63/100] [Batch 100/347] [D loss: 0.515361] [G loss: 0.353309]\n",
      "[Epoch 63/100] [Batch 101/347] [D loss: 0.514230] [G loss: 0.344956]\n",
      "[Epoch 63/100] [Batch 102/347] [D loss: 0.514268] [G loss: 0.335580]\n",
      "[Epoch 63/100] [Batch 103/347] [D loss: 0.514559] [G loss: 0.331147]\n",
      "[Epoch 63/100] [Batch 104/347] [D loss: 0.511178] [G loss: 0.322049]\n",
      "[Epoch 63/100] [Batch 105/347] [D loss: 0.461831] [G loss: 0.312455]\n",
      "[Epoch 63/100] [Batch 106/347] [D loss: 0.318815] [G loss: 0.315311]\n",
      "[Epoch 63/100] [Batch 107/347] [D loss: 0.319515] [G loss: 0.320566]\n",
      "[Epoch 63/100] [Batch 108/347] [D loss: 0.317154] [G loss: 0.324674]\n",
      "[Epoch 63/100] [Batch 109/347] [D loss: 0.305162] [G loss: 0.332544]\n",
      "[Epoch 63/100] [Batch 110/347] [D loss: 0.354669] [G loss: 0.328160]\n",
      "[Epoch 63/100] [Batch 111/347] [D loss: 0.349981] [G loss: 0.323709]\n",
      "[Epoch 63/100] [Batch 112/347] [D loss: 0.345443] [G loss: 0.320984]\n",
      "[Epoch 63/100] [Batch 113/347] [D loss: 0.463960] [G loss: 0.334609]\n",
      "[Epoch 63/100] [Batch 114/347] [D loss: 0.516041] [G loss: 0.346699]\n",
      "[Epoch 63/100] [Batch 115/347] [D loss: 0.500645] [G loss: 0.335048]\n",
      "[Epoch 63/100] [Batch 116/347] [D loss: 0.471174] [G loss: 0.321572]\n",
      "[Epoch 63/100] [Batch 117/347] [D loss: 0.468040] [G loss: 0.311417]\n",
      "[Epoch 63/100] [Batch 118/347] [D loss: 0.435617] [G loss: 0.299481]\n",
      "[Epoch 63/100] [Batch 119/347] [D loss: 0.433771] [G loss: 0.289404]\n",
      "[Epoch 63/100] [Batch 120/347] [D loss: 0.438252] [G loss: 0.288590]\n",
      "[Epoch 63/100] [Batch 121/347] [D loss: 0.441195] [G loss: 0.291664]\n",
      "[Epoch 63/100] [Batch 122/347] [D loss: 0.485864] [G loss: 0.301498]\n",
      "[Epoch 63/100] [Batch 123/347] [D loss: 0.502956] [G loss: 0.320863]\n",
      "[Epoch 63/100] [Batch 124/347] [D loss: 0.477708] [G loss: 0.332774]\n",
      "[Epoch 63/100] [Batch 125/347] [D loss: 0.468327] [G loss: 0.343270]\n",
      "[Epoch 63/100] [Batch 126/347] [D loss: 0.456796] [G loss: 0.344021]\n",
      "[Epoch 63/100] [Batch 127/347] [D loss: 0.451825] [G loss: 0.333517]\n",
      "[Epoch 63/100] [Batch 128/347] [D loss: 0.430224] [G loss: 0.315027]\n",
      "[Epoch 63/100] [Batch 129/347] [D loss: 0.363821] [G loss: 0.320171]\n",
      "[Epoch 63/100] [Batch 130/347] [D loss: 0.286774] [G loss: 0.345443]\n",
      "[Epoch 63/100] [Batch 131/347] [D loss: 0.264705] [G loss: 0.363736]\n",
      "[Epoch 63/100] [Batch 132/347] [D loss: 0.256149] [G loss: 0.378581]\n",
      "[Epoch 63/100] [Batch 133/347] [D loss: 0.234057] [G loss: 0.391208]\n",
      "[Epoch 63/100] [Batch 134/347] [D loss: 0.234102] [G loss: 0.401469]\n",
      "[Epoch 63/100] [Batch 135/347] [D loss: 0.235932] [G loss: 0.406285]\n",
      "[Epoch 63/100] [Batch 136/347] [D loss: 0.231496] [G loss: 0.401486]\n",
      "[Epoch 63/100] [Batch 137/347] [D loss: 0.424154] [G loss: 0.387678]\n",
      "[Epoch 63/100] [Batch 138/347] [D loss: 0.414955] [G loss: 0.360693]\n",
      "[Epoch 63/100] [Batch 139/347] [D loss: 0.389551] [G loss: 0.307831]\n",
      "[Epoch 63/100] [Batch 140/347] [D loss: 0.376069] [G loss: 0.264003]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 63/100] [Batch 141/347] [D loss: 0.367176] [G loss: 0.256857]\n",
      "[Epoch 63/100] [Batch 142/347] [D loss: 0.381570] [G loss: 0.261897]\n",
      "[Epoch 63/100] [Batch 143/347] [D loss: 0.379517] [G loss: 0.286750]\n",
      "[Epoch 63/100] [Batch 144/347] [D loss: 0.369270] [G loss: 0.313952]\n",
      "[Epoch 63/100] [Batch 145/347] [D loss: 0.383483] [G loss: 0.327023]\n",
      "[Epoch 63/100] [Batch 146/347] [D loss: 0.399765] [G loss: 0.336286]\n",
      "[Epoch 63/100] [Batch 147/347] [D loss: 0.434939] [G loss: 0.339630]\n",
      "[Epoch 63/100] [Batch 148/347] [D loss: 0.454652] [G loss: 0.346244]\n",
      "[Epoch 63/100] [Batch 149/347] [D loss: 0.438820] [G loss: 0.340674]\n",
      "[Epoch 63/100] [Batch 150/347] [D loss: 0.420998] [G loss: 0.325194]\n",
      "[Epoch 63/100] [Batch 151/347] [D loss: 0.400848] [G loss: 0.302467]\n",
      "[Epoch 63/100] [Batch 152/347] [D loss: 0.386261] [G loss: 0.279209]\n",
      "[Epoch 63/100] [Batch 153/347] [D loss: 0.390469] [G loss: 0.270711]\n",
      "[Epoch 63/100] [Batch 154/347] [D loss: 0.390341] [G loss: 0.264766]\n",
      "[Epoch 63/100] [Batch 155/347] [D loss: 0.384579] [G loss: 0.277711]\n",
      "[Epoch 63/100] [Batch 156/347] [D loss: 0.378310] [G loss: 0.294977]\n",
      "[Epoch 63/100] [Batch 157/347] [D loss: 0.365916] [G loss: 0.318876]\n",
      "[Epoch 63/100] [Batch 158/347] [D loss: 0.318869] [G loss: 0.348297]\n",
      "[Epoch 63/100] [Batch 159/347] [D loss: 0.323247] [G loss: 0.368228]\n",
      "[Epoch 63/100] [Batch 160/347] [D loss: 0.323986] [G loss: 0.385457]\n",
      "[Epoch 63/100] [Batch 161/347] [D loss: 0.318590] [G loss: 0.391443]\n",
      "[Epoch 63/100] [Batch 162/347] [D loss: 0.335452] [G loss: 0.380296]\n",
      "[Epoch 63/100] [Batch 163/347] [D loss: 0.337245] [G loss: 0.365746]\n",
      "[Epoch 63/100] [Batch 164/347] [D loss: 0.331212] [G loss: 0.339762]\n",
      "[Epoch 63/100] [Batch 165/347] [D loss: 0.323677] [G loss: 0.328849]\n",
      "[Epoch 63/100] [Batch 166/347] [D loss: 0.341669] [G loss: 0.320892]\n",
      "[Epoch 63/100] [Batch 167/347] [D loss: 0.367665] [G loss: 0.319183]\n",
      "[Epoch 63/100] [Batch 168/347] [D loss: 0.367658] [G loss: 0.328885]\n",
      "[Epoch 63/100] [Batch 169/347] [D loss: 0.464061] [G loss: 0.340359]\n",
      "[Epoch 63/100] [Batch 170/347] [D loss: 0.516864] [G loss: 0.348854]\n",
      "[Epoch 63/100] [Batch 171/347] [D loss: 0.525639] [G loss: 0.351753]\n",
      "[Epoch 63/100] [Batch 172/347] [D loss: 0.529440] [G loss: 0.356066]\n",
      "[Epoch 63/100] [Batch 173/347] [D loss: 0.532268] [G loss: 0.358041]\n",
      "[Epoch 63/100] [Batch 174/347] [D loss: 0.534506] [G loss: 0.366579]\n",
      "[Epoch 63/100] [Batch 175/347] [D loss: 0.553007] [G loss: 0.379464]\n",
      "[Epoch 63/100] [Batch 176/347] [D loss: 0.564256] [G loss: 0.396372]\n",
      "[Epoch 63/100] [Batch 177/347] [D loss: 0.559786] [G loss: 0.409850]\n",
      "[Epoch 63/100] [Batch 178/347] [D loss: 0.552964] [G loss: 0.421170]\n",
      "[Epoch 63/100] [Batch 179/347] [D loss: 0.548050] [G loss: 0.433198]\n",
      "[Epoch 63/100] [Batch 180/347] [D loss: 0.544141] [G loss: 0.440988]\n",
      "[Epoch 63/100] [Batch 181/347] [D loss: 0.544511] [G loss: 0.452381]\n",
      "[Epoch 63/100] [Batch 182/347] [D loss: 0.545379] [G loss: 0.459480]\n",
      "[Epoch 63/100] [Batch 183/347] [D loss: 0.546062] [G loss: 0.465417]\n",
      "[Epoch 63/100] [Batch 184/347] [D loss: 0.549067] [G loss: 0.471136]\n",
      "[Epoch 63/100] [Batch 185/347] [D loss: 0.548248] [G loss: 0.469706]\n",
      "[Epoch 63/100] [Batch 186/347] [D loss: 0.546737] [G loss: 0.469329]\n",
      "[Epoch 63/100] [Batch 187/347] [D loss: 0.544584] [G loss: 0.465884]\n",
      "[Epoch 63/100] [Batch 188/347] [D loss: 0.539191] [G loss: 0.456223]\n",
      "[Epoch 63/100] [Batch 189/347] [D loss: 0.533289] [G loss: 0.447236]\n",
      "[Epoch 63/100] [Batch 190/347] [D loss: 0.530898] [G loss: 0.440417]\n",
      "[Epoch 63/100] [Batch 191/347] [D loss: 0.529542] [G loss: 0.432405]\n",
      "[Epoch 63/100] [Batch 192/347] [D loss: 0.528642] [G loss: 0.425888]\n",
      "[Epoch 63/100] [Batch 193/347] [D loss: 0.531054] [G loss: 0.418959]\n",
      "[Epoch 63/100] [Batch 194/347] [D loss: 0.527028] [G loss: 0.407191]\n",
      "[Epoch 63/100] [Batch 195/347] [D loss: 0.521364] [G loss: 0.394969]\n",
      "[Epoch 63/100] [Batch 196/347] [D loss: 0.511467] [G loss: 0.381013]\n",
      "[Epoch 63/100] [Batch 197/347] [D loss: 0.506404] [G loss: 0.365933]\n",
      "[Epoch 63/100] [Batch 198/347] [D loss: 0.503441] [G loss: 0.350749]\n",
      "[Epoch 63/100] [Batch 199/347] [D loss: 0.500966] [G loss: 0.330872]\n",
      "[Epoch 63/100] [Batch 200/347] [D loss: 0.514708] [G loss: 0.315405]\n",
      "[Epoch 63/100] [Batch 201/347] [D loss: 0.521523] [G loss: 0.305925]\n",
      "[Epoch 63/100] [Batch 202/347] [D loss: 0.523758] [G loss: 0.304436]\n",
      "[Epoch 63/100] [Batch 203/347] [D loss: 0.525343] [G loss: 0.309758]\n",
      "[Epoch 63/100] [Batch 204/347] [D loss: 0.523112] [G loss: 0.323870]\n",
      "[Epoch 63/100] [Batch 205/347] [D loss: 0.521371] [G loss: 0.341554]\n",
      "[Epoch 63/100] [Batch 206/347] [D loss: 0.519337] [G loss: 0.355127]\n",
      "[Epoch 63/100] [Batch 207/347] [D loss: 0.512796] [G loss: 0.364410]\n",
      "[Epoch 63/100] [Batch 208/347] [D loss: 0.512547] [G loss: 0.372687]\n",
      "[Epoch 63/100] [Batch 209/347] [D loss: 0.509728] [G loss: 0.370880]\n",
      "[Epoch 63/100] [Batch 210/347] [D loss: 0.489788] [G loss: 0.370379]\n",
      "[Epoch 63/100] [Batch 211/347] [D loss: 0.437204] [G loss: 0.361849]\n",
      "[Epoch 63/100] [Batch 212/347] [D loss: 0.301815] [G loss: 0.357541]\n",
      "[Epoch 63/100] [Batch 213/347] [D loss: 0.298334] [G loss: 0.350706]\n",
      "[Epoch 63/100] [Batch 214/347] [D loss: 0.291435] [G loss: 0.338099]\n",
      "[Epoch 63/100] [Batch 215/347] [D loss: 0.289811] [G loss: 0.325630]\n",
      "[Epoch 63/100] [Batch 216/347] [D loss: 0.446118] [G loss: 0.303996]\n",
      "[Epoch 63/100] [Batch 217/347] [D loss: 0.485202] [G loss: 0.304694]\n",
      "[Epoch 63/100] [Batch 218/347] [D loss: 0.519315] [G loss: 0.315374]\n",
      "[Epoch 63/100] [Batch 219/347] [D loss: 0.518114] [G loss: 0.328165]\n",
      "[Epoch 63/100] [Batch 220/347] [D loss: 0.509749] [G loss: 0.345538]\n",
      "[Epoch 63/100] [Batch 221/347] [D loss: 0.516504] [G loss: 0.362864]\n",
      "[Epoch 63/100] [Batch 222/347] [D loss: 0.511436] [G loss: 0.371149]\n",
      "[Epoch 63/100] [Batch 223/347] [D loss: 0.493248] [G loss: 0.363299]\n",
      "[Epoch 63/100] [Batch 224/347] [D loss: 0.491207] [G loss: 0.359705]\n",
      "[Epoch 63/100] [Batch 225/347] [D loss: 0.493220] [G loss: 0.345860]\n",
      "[Epoch 63/100] [Batch 226/347] [D loss: 0.493008] [G loss: 0.326997]\n",
      "[Epoch 63/100] [Batch 227/347] [D loss: 0.497086] [G loss: 0.324961]\n",
      "[Epoch 63/100] [Batch 228/347] [D loss: 0.499912] [G loss: 0.325324]\n",
      "[Epoch 63/100] [Batch 229/347] [D loss: 0.500928] [G loss: 0.325068]\n",
      "[Epoch 63/100] [Batch 230/347] [D loss: 0.503501] [G loss: 0.322634]\n",
      "[Epoch 63/100] [Batch 231/347] [D loss: 0.496904] [G loss: 0.311494]\n",
      "[Epoch 63/100] [Batch 232/347] [D loss: 0.491320] [G loss: 0.304049]\n",
      "[Epoch 63/100] [Batch 233/347] [D loss: 0.467285] [G loss: 0.303695]\n",
      "[Epoch 63/100] [Batch 234/347] [D loss: 0.454338] [G loss: 0.301075]\n",
      "[Epoch 63/100] [Batch 235/347] [D loss: 0.453595] [G loss: 0.298090]\n",
      "[Epoch 63/100] [Batch 236/347] [D loss: 0.456429] [G loss: 0.305842]\n",
      "[Epoch 63/100] [Batch 237/347] [D loss: 0.487223] [G loss: 0.317818]\n",
      "[Epoch 63/100] [Batch 238/347] [D loss: 0.520936] [G loss: 0.329462]\n",
      "[Epoch 63/100] [Batch 239/347] [D loss: 0.514446] [G loss: 0.339721]\n",
      "[Epoch 63/100] [Batch 240/347] [D loss: 0.511169] [G loss: 0.348568]\n",
      "[Epoch 63/100] [Batch 241/347] [D loss: 0.511806] [G loss: 0.357364]\n",
      "[Epoch 63/100] [Batch 242/347] [D loss: 0.515935] [G loss: 0.366060]\n",
      "[Epoch 63/100] [Batch 243/347] [D loss: 0.508553] [G loss: 0.372136]\n",
      "[Epoch 63/100] [Batch 244/347] [D loss: 0.499933] [G loss: 0.366041]\n",
      "[Epoch 63/100] [Batch 245/347] [D loss: 0.499796] [G loss: 0.357167]\n",
      "[Epoch 63/100] [Batch 246/347] [D loss: 0.496768] [G loss: 0.347191]\n",
      "[Epoch 63/100] [Batch 247/347] [D loss: 0.497724] [G loss: 0.329486]\n",
      "[Epoch 63/100] [Batch 248/347] [D loss: 0.498627] [G loss: 0.332300]\n",
      "[Epoch 63/100] [Batch 249/347] [D loss: 0.494337] [G loss: 0.337092]\n",
      "[Epoch 63/100] [Batch 250/347] [D loss: 0.493206] [G loss: 0.340070]\n",
      "[Epoch 63/100] [Batch 251/347] [D loss: 0.492213] [G loss: 0.337927]\n",
      "[Epoch 63/100] [Batch 252/347] [D loss: 0.489694] [G loss: 0.327272]\n",
      "[Epoch 63/100] [Batch 253/347] [D loss: 0.455729] [G loss: 0.311463]\n",
      "[Epoch 63/100] [Batch 254/347] [D loss: 0.448790] [G loss: 0.300316]\n",
      "[Epoch 63/100] [Batch 255/347] [D loss: 0.448323] [G loss: 0.293800]\n",
      "[Epoch 63/100] [Batch 256/347] [D loss: 0.449886] [G loss: 0.293891]\n",
      "[Epoch 63/100] [Batch 257/347] [D loss: 0.452001] [G loss: 0.299840]\n",
      "[Epoch 63/100] [Batch 258/347] [D loss: 0.428384] [G loss: 0.308425]\n",
      "[Epoch 63/100] [Batch 259/347] [D loss: 0.427572] [G loss: 0.314561]\n",
      "[Epoch 63/100] [Batch 260/347] [D loss: 0.427987] [G loss: 0.319002]\n",
      "[Epoch 63/100] [Batch 261/347] [D loss: 0.416207] [G loss: 0.324980]\n",
      "[Epoch 63/100] [Batch 262/347] [D loss: 0.378312] [G loss: 0.325221]\n",
      "[Epoch 63/100] [Batch 263/347] [D loss: 0.375408] [G loss: 0.321684]\n",
      "[Epoch 63/100] [Batch 264/347] [D loss: 0.373102] [G loss: 0.317430]\n",
      "[Epoch 63/100] [Batch 265/347] [D loss: 0.377966] [G loss: 0.312399]\n",
      "[Epoch 63/100] [Batch 266/347] [D loss: 0.415852] [G loss: 0.309334]\n",
      "[Epoch 63/100] [Batch 267/347] [D loss: 0.426578] [G loss: 0.306672]\n",
      "[Epoch 63/100] [Batch 268/347] [D loss: 0.436118] [G loss: 0.304418]\n",
      "[Epoch 63/100] [Batch 269/347] [D loss: 0.433135] [G loss: 0.304672]\n",
      "[Epoch 63/100] [Batch 270/347] [D loss: 0.453027] [G loss: 0.306958]\n",
      "[Epoch 63/100] [Batch 271/347] [D loss: 0.424197] [G loss: 0.322140]\n",
      "[Epoch 63/100] [Batch 272/347] [D loss: 0.358887] [G loss: 0.364683]\n",
      "[Epoch 63/100] [Batch 273/347] [D loss: 0.287938] [G loss: 0.394620]\n",
      "[Epoch 63/100] [Batch 274/347] [D loss: 0.230456] [G loss: 0.418373]\n",
      "[Epoch 63/100] [Batch 275/347] [D loss: 0.196719] [G loss: 0.439809]\n",
      "[Epoch 63/100] [Batch 276/347] [D loss: 0.497978] [G loss: 0.446223]\n",
      "[Epoch 63/100] [Batch 277/347] [D loss: 0.522650] [G loss: 0.459093]\n",
      "[Epoch 63/100] [Batch 278/347] [D loss: 0.531166] [G loss: 0.470289]\n",
      "[Epoch 63/100] [Batch 279/347] [D loss: 0.536180] [G loss: 0.475010]\n",
      "[Epoch 63/100] [Batch 280/347] [D loss: 0.539922] [G loss: 0.479185]\n",
      "[Epoch 63/100] [Batch 281/347] [D loss: 0.543247] [G loss: 0.480952]\n",
      "[Epoch 63/100] [Batch 282/347] [D loss: 0.545609] [G loss: 0.482231]\n",
      "[Epoch 63/100] [Batch 283/347] [D loss: 0.547106] [G loss: 0.480656]\n",
      "[Epoch 63/100] [Batch 284/347] [D loss: 0.548328] [G loss: 0.482327]\n",
      "[Epoch 63/100] [Batch 285/347] [D loss: 0.549659] [G loss: 0.483156]\n",
      "[Epoch 63/100] [Batch 286/347] [D loss: 0.548230] [G loss: 0.469843]\n",
      "[Epoch 63/100] [Batch 287/347] [D loss: 0.548471] [G loss: 0.467710]\n",
      "[Epoch 63/100] [Batch 288/347] [D loss: 0.548555] [G loss: 0.464337]\n",
      "[Epoch 63/100] [Batch 289/347] [D loss: 0.547851] [G loss: 0.460225]\n",
      "[Epoch 63/100] [Batch 290/347] [D loss: 0.548781] [G loss: 0.474569]\n",
      "[Epoch 63/100] [Batch 291/347] [D loss: 0.548003] [G loss: 0.481609]\n",
      "[Epoch 63/100] [Batch 292/347] [D loss: 0.546505] [G loss: 0.485552]\n",
      "[Epoch 63/100] [Batch 293/347] [D loss: 0.530611] [G loss: 0.490879]\n",
      "[Epoch 63/100] [Batch 294/347] [D loss: 0.528741] [G loss: 0.495376]\n",
      "[Epoch 63/100] [Batch 295/347] [D loss: 0.526838] [G loss: 0.493991]\n",
      "[Epoch 63/100] [Batch 296/347] [D loss: 0.524015] [G loss: 0.491894]\n",
      "[Epoch 63/100] [Batch 297/347] [D loss: 0.542742] [G loss: 0.495600]\n",
      "[Epoch 63/100] [Batch 298/347] [D loss: 0.545310] [G loss: 0.488071]\n",
      "[Epoch 63/100] [Batch 299/347] [D loss: 0.542557] [G loss: 0.482154]\n",
      "[Epoch 63/100] [Batch 300/347] [D loss: 0.539348] [G loss: 0.478325]\n",
      "[Epoch 63/100] [Batch 301/347] [D loss: 0.537011] [G loss: 0.460026]\n",
      "[Epoch 63/100] [Batch 302/347] [D loss: 0.535660] [G loss: 0.450078]\n",
      "[Epoch 63/100] [Batch 303/347] [D loss: 0.532978] [G loss: 0.436589]\n",
      "[Epoch 63/100] [Batch 304/347] [D loss: 0.513170] [G loss: 0.421721]\n",
      "[Epoch 63/100] [Batch 305/347] [D loss: 0.495259] [G loss: 0.410819]\n",
      "[Epoch 63/100] [Batch 306/347] [D loss: 0.491126] [G loss: 0.405801]\n",
      "[Epoch 63/100] [Batch 307/347] [D loss: 0.485464] [G loss: 0.406580]\n",
      "[Epoch 63/100] [Batch 308/347] [D loss: 0.493196] [G loss: 0.408472]\n",
      "[Epoch 63/100] [Batch 309/347] [D loss: 0.519344] [G loss: 0.417568]\n",
      "[Epoch 63/100] [Batch 310/347] [D loss: 0.528082] [G loss: 0.424485]\n",
      "[Epoch 63/100] [Batch 311/347] [D loss: 0.523488] [G loss: 0.416610]\n",
      "[Epoch 63/100] [Batch 312/347] [D loss: 0.514784] [G loss: 0.406130]\n",
      "[Epoch 63/100] [Batch 313/347] [D loss: 0.505838] [G loss: 0.391648]\n",
      "[Epoch 63/100] [Batch 314/347] [D loss: 0.502104] [G loss: 0.371527]\n",
      "[Epoch 63/100] [Batch 315/347] [D loss: 0.499209] [G loss: 0.354833]\n",
      "[Epoch 63/100] [Batch 316/347] [D loss: 0.498883] [G loss: 0.350581]\n",
      "[Epoch 63/100] [Batch 317/347] [D loss: 0.499886] [G loss: 0.349002]\n",
      "[Epoch 63/100] [Batch 318/347] [D loss: 0.500481] [G loss: 0.357145]\n",
      "[Epoch 63/100] [Batch 319/347] [D loss: 0.500198] [G loss: 0.364232]\n",
      "[Epoch 63/100] [Batch 320/347] [D loss: 0.498368] [G loss: 0.357815]\n",
      "[Epoch 63/100] [Batch 321/347] [D loss: 0.492810] [G loss: 0.346693]\n",
      "[Epoch 63/100] [Batch 322/347] [D loss: 0.491388] [G loss: 0.334837]\n",
      "[Epoch 63/100] [Batch 323/347] [D loss: 0.479715] [G loss: 0.322052]\n",
      "[Epoch 63/100] [Batch 324/347] [D loss: 0.474017] [G loss: 0.311678]\n",
      "[Epoch 63/100] [Batch 325/347] [D loss: 0.472264] [G loss: 0.299672]\n",
      "[Epoch 63/100] [Batch 326/347] [D loss: 0.469187] [G loss: 0.286466]\n",
      "[Epoch 63/100] [Batch 327/347] [D loss: 0.456993] [G loss: 0.274560]\n",
      "[Epoch 63/100] [Batch 328/347] [D loss: 0.452055] [G loss: 0.262077]\n",
      "[Epoch 63/100] [Batch 329/347] [D loss: 0.444719] [G loss: 0.251025]\n",
      "[Epoch 63/100] [Batch 330/347] [D loss: 0.434922] [G loss: 0.239236]\n",
      "[Epoch 63/100] [Batch 331/347] [D loss: 0.444071] [G loss: 0.230103]\n",
      "[Epoch 63/100] [Batch 332/347] [D loss: 0.480037] [G loss: 0.233151]\n",
      "[Epoch 63/100] [Batch 333/347] [D loss: 0.472433] [G loss: 0.217308]\n",
      "[Epoch 63/100] [Batch 334/347] [D loss: 0.470310] [G loss: 0.202781]\n",
      "[Epoch 63/100] [Batch 335/347] [D loss: 0.473453] [G loss: 0.201517]\n",
      "[Epoch 63/100] [Batch 336/347] [D loss: 0.474940] [G loss: 0.209093]\n",
      "[Epoch 63/100] [Batch 337/347] [D loss: 0.486922] [G loss: 0.227651]\n",
      "[Epoch 63/100] [Batch 338/347] [D loss: 0.501024] [G loss: 0.252247]\n",
      "[Epoch 63/100] [Batch 339/347] [D loss: 0.485854] [G loss: 0.268293]\n",
      "[Epoch 63/100] [Batch 340/347] [D loss: 0.472084] [G loss: 0.277859]\n",
      "[Epoch 63/100] [Batch 341/347] [D loss: 0.474179] [G loss: 0.287511]\n",
      "[Epoch 63/100] [Batch 342/347] [D loss: 0.407395] [G loss: 0.281845]\n",
      "[Epoch 63/100] [Batch 343/347] [D loss: 0.391048] [G loss: 0.270298]\n",
      "[Epoch 63/100] [Batch 344/347] [D loss: 0.351006] [G loss: 0.268086]\n",
      "[Epoch 63/100] [Batch 345/347] [D loss: 0.280475] [G loss: 0.270199]\n",
      "[Epoch 63/100] [Batch 346/347] [D loss: 0.277413] [G loss: 0.275243]\n",
      "[Epoch 63/100] [Batch 347/347] [D loss: 0.273649] [G loss: 0.281173]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 64/100] [Batch 1/347] [D loss: 0.467936] [G loss: 0.299012]\n",
      "[Epoch 64/100] [Batch 2/347] [D loss: 0.474896] [G loss: 0.300072]\n",
      "[Epoch 64/100] [Batch 3/347] [D loss: 0.488245] [G loss: 0.303524]\n",
      "[Epoch 64/100] [Batch 4/347] [D loss: 0.488795] [G loss: 0.301311]\n",
      "[Epoch 64/100] [Batch 5/347] [D loss: 0.485120] [G loss: 0.293762]\n",
      "[Epoch 64/100] [Batch 6/347] [D loss: 0.472566] [G loss: 0.283723]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 64/100] [Batch 7/347] [D loss: 0.449660] [G loss: 0.265580]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 64/100] [Batch 8/347] [D loss: 0.447491] [G loss: 0.254299]\n",
      "[Epoch 64/100] [Batch 9/347] [D loss: 0.447650] [G loss: 0.247965]\n",
      "[Epoch 64/100] [Batch 10/347] [D loss: 0.454577] [G loss: 0.245481]\n",
      "[Epoch 64/100] [Batch 11/347] [D loss: 0.483041] [G loss: 0.256046]\n",
      "[Epoch 64/100] [Batch 12/347] [D loss: 0.488573] [G loss: 0.264531]\n",
      "[Epoch 64/100] [Batch 13/347] [D loss: 0.475931] [G loss: 0.273025]\n",
      "[Epoch 64/100] [Batch 14/347] [D loss: 0.464037] [G loss: 0.283033]\n",
      "[Epoch 64/100] [Batch 15/347] [D loss: 0.450022] [G loss: 0.282201]\n",
      "[Epoch 64/100] [Batch 16/347] [D loss: 0.442451] [G loss: 0.283586]\n",
      "[Epoch 64/100] [Batch 17/347] [D loss: 0.445031] [G loss: 0.289589]\n",
      "[Epoch 64/100] [Batch 18/347] [D loss: 0.449932] [G loss: 0.291076]\n",
      "[Epoch 64/100] [Batch 19/347] [D loss: 0.458915] [G loss: 0.294958]\n",
      "[Epoch 64/100] [Batch 20/347] [D loss: 0.471814] [G loss: 0.296807]\n",
      "[Epoch 64/100] [Batch 21/347] [D loss: 0.447598] [G loss: 0.287583]\n",
      "[Epoch 64/100] [Batch 22/347] [D loss: 0.445632] [G loss: 0.280123]\n",
      "[Epoch 64/100] [Batch 23/347] [D loss: 0.442224] [G loss: 0.272339]\n",
      "[Epoch 64/100] [Batch 24/347] [D loss: 0.406284] [G loss: 0.261922]\n",
      "[Epoch 64/100] [Batch 25/347] [D loss: 0.341196] [G loss: 0.274557]\n",
      "[Epoch 64/100] [Batch 26/347] [D loss: 0.339449] [G loss: 0.284889]\n",
      "[Epoch 64/100] [Batch 27/347] [D loss: 0.334926] [G loss: 0.300650]\n",
      "[Epoch 64/100] [Batch 28/347] [D loss: 0.330771] [G loss: 0.316281]\n",
      "[Epoch 64/100] [Batch 29/347] [D loss: 0.360958] [G loss: 0.325135]\n",
      "[Epoch 64/100] [Batch 30/347] [D loss: 0.348979] [G loss: 0.328176]\n",
      "[Epoch 64/100] [Batch 31/347] [D loss: 0.347896] [G loss: 0.326109]\n",
      "[Epoch 64/100] [Batch 32/347] [D loss: 0.357284] [G loss: 0.317697]\n",
      "[Epoch 64/100] [Batch 33/347] [D loss: 0.372336] [G loss: 0.308339]\n",
      "[Epoch 64/100] [Batch 34/347] [D loss: 0.399435] [G loss: 0.294648]\n",
      "[Epoch 64/100] [Batch 35/347] [D loss: 0.390630] [G loss: 0.279267]\n",
      "[Epoch 64/100] [Batch 36/347] [D loss: 0.397534] [G loss: 0.266635]\n",
      "[Epoch 64/100] [Batch 37/347] [D loss: 0.403040] [G loss: 0.257785]\n",
      "[Epoch 64/100] [Batch 38/347] [D loss: 0.407984] [G loss: 0.262538]\n",
      "[Epoch 64/100] [Batch 39/347] [D loss: 0.419947] [G loss: 0.263538]\n",
      "[Epoch 64/100] [Batch 40/347] [D loss: 0.443029] [G loss: 0.268605]\n",
      "[Epoch 64/100] [Batch 41/347] [D loss: 0.450987] [G loss: 0.278742]\n",
      "[Epoch 64/100] [Batch 42/347] [D loss: 0.453519] [G loss: 0.294470]\n",
      "[Epoch 64/100] [Batch 43/347] [D loss: 0.473744] [G loss: 0.314806]\n",
      "[Epoch 64/100] [Batch 44/347] [D loss: 0.471940] [G loss: 0.324348]\n",
      "[Epoch 64/100] [Batch 45/347] [D loss: 0.454762] [G loss: 0.318403]\n",
      "[Epoch 64/100] [Batch 46/347] [D loss: 0.394187] [G loss: 0.313030]\n",
      "[Epoch 64/100] [Batch 47/347] [D loss: 0.378052] [G loss: 0.304932]\n",
      "[Epoch 64/100] [Batch 48/347] [D loss: 0.272006] [G loss: 0.315241]\n",
      "[Epoch 64/100] [Batch 49/347] [D loss: 0.265309] [G loss: 0.331712]\n",
      "[Epoch 64/100] [Batch 50/347] [D loss: 0.256322] [G loss: 0.351234]\n",
      "[Epoch 64/100] [Batch 51/347] [D loss: 0.255939] [G loss: 0.362042]\n",
      "[Epoch 64/100] [Batch 52/347] [D loss: 0.352737] [G loss: 0.359477]\n",
      "[Epoch 64/100] [Batch 53/347] [D loss: 0.379632] [G loss: 0.351680]\n",
      "[Epoch 64/100] [Batch 54/347] [D loss: 0.360922] [G loss: 0.351773]\n",
      "[Epoch 64/100] [Batch 55/347] [D loss: 0.348674] [G loss: 0.329235]\n",
      "[Epoch 64/100] [Batch 56/347] [D loss: 0.342571] [G loss: 0.292959]\n",
      "[Epoch 64/100] [Batch 57/347] [D loss: 0.330757] [G loss: 0.285331]\n",
      "[Epoch 64/100] [Batch 58/347] [D loss: 0.345756] [G loss: 0.287058]\n",
      "[Epoch 64/100] [Batch 59/347] [D loss: 0.344977] [G loss: 0.292408]\n",
      "[Epoch 64/100] [Batch 60/347] [D loss: 0.330258] [G loss: 0.304034]\n",
      "[Epoch 64/100] [Batch 61/347] [D loss: 0.333991] [G loss: 0.329570]\n",
      "[Epoch 64/100] [Batch 62/347] [D loss: 0.332022] [G loss: 0.337961]\n",
      "[Epoch 64/100] [Batch 63/347] [D loss: 0.332715] [G loss: 0.350495]\n",
      "[Epoch 64/100] [Batch 64/347] [D loss: 0.314954] [G loss: 0.360241]\n",
      "[Epoch 64/100] [Batch 65/347] [D loss: 0.250974] [G loss: 0.372341]\n",
      "[Epoch 64/100] [Batch 66/347] [D loss: 0.254696] [G loss: 0.374097]\n",
      "[Epoch 64/100] [Batch 67/347] [D loss: 0.259268] [G loss: 0.361638]\n",
      "[Epoch 64/100] [Batch 68/347] [D loss: 0.266232] [G loss: 0.355369]\n",
      "[Epoch 64/100] [Batch 69/347] [D loss: 0.291086] [G loss: 0.360700]\n",
      "[Epoch 64/100] [Batch 70/347] [D loss: 0.290828] [G loss: 0.350632]\n",
      "[Epoch 64/100] [Batch 71/347] [D loss: 0.289833] [G loss: 0.326964]\n",
      "[Epoch 64/100] [Batch 72/347] [D loss: 0.298808] [G loss: 0.328394]\n",
      "[Epoch 64/100] [Batch 73/347] [D loss: 0.364744] [G loss: 0.315989]\n",
      "[Epoch 64/100] [Batch 74/347] [D loss: 0.367298] [G loss: 0.309113]\n",
      "[Epoch 64/100] [Batch 75/347] [D loss: 0.370398] [G loss: 0.306456]\n",
      "[Epoch 64/100] [Batch 76/347] [D loss: 0.376028] [G loss: 0.306695]\n",
      "[Epoch 64/100] [Batch 77/347] [D loss: 0.420299] [G loss: 0.308427]\n",
      "[Epoch 64/100] [Batch 78/347] [D loss: 0.476779] [G loss: 0.318912]\n",
      "[Epoch 64/100] [Batch 79/347] [D loss: 0.486951] [G loss: 0.326433]\n",
      "[Epoch 64/100] [Batch 80/347] [D loss: 0.414253] [G loss: 0.323423]\n",
      "[Epoch 64/100] [Batch 81/347] [D loss: 0.398026] [G loss: 0.331486]\n",
      "[Epoch 64/100] [Batch 82/347] [D loss: 0.397340] [G loss: 0.342668]\n",
      "[Epoch 64/100] [Batch 83/347] [D loss: 0.400970] [G loss: 0.350542]\n",
      "[Epoch 64/100] [Batch 84/347] [D loss: 0.490619] [G loss: 0.364322]\n",
      "[Epoch 64/100] [Batch 85/347] [D loss: 0.540170] [G loss: 0.376059]\n",
      "[Epoch 64/100] [Batch 86/347] [D loss: 0.539576] [G loss: 0.388165]\n",
      "[Epoch 64/100] [Batch 87/347] [D loss: 0.539241] [G loss: 0.401834]\n",
      "[Epoch 64/100] [Batch 88/347] [D loss: 0.542477] [G loss: 0.414917]\n",
      "[Epoch 64/100] [Batch 89/347] [D loss: 0.543805] [G loss: 0.427845]\n",
      "[Epoch 64/100] [Batch 90/347] [D loss: 0.541642] [G loss: 0.436258]\n",
      "[Epoch 64/100] [Batch 91/347] [D loss: 0.540242] [G loss: 0.442152]\n",
      "[Epoch 64/100] [Batch 92/347] [D loss: 0.540123] [G loss: 0.447131]\n",
      "[Epoch 64/100] [Batch 93/347] [D loss: 0.539662] [G loss: 0.451072]\n",
      "[Epoch 64/100] [Batch 94/347] [D loss: 0.537310] [G loss: 0.449405]\n",
      "[Epoch 64/100] [Batch 95/347] [D loss: 0.535925] [G loss: 0.449981]\n",
      "[Epoch 64/100] [Batch 96/347] [D loss: 0.536731] [G loss: 0.451725]\n",
      "[Epoch 64/100] [Batch 97/347] [D loss: 0.535671] [G loss: 0.451149]\n",
      "[Epoch 64/100] [Batch 98/347] [D loss: 0.535676] [G loss: 0.451932]\n",
      "[Epoch 64/100] [Batch 99/347] [D loss: 0.537244] [G loss: 0.451013]\n",
      "[Epoch 64/100] [Batch 100/347] [D loss: 0.536794] [G loss: 0.448835]\n",
      "[Epoch 64/100] [Batch 101/347] [D loss: 0.536162] [G loss: 0.444658]\n",
      "[Epoch 64/100] [Batch 102/347] [D loss: 0.537893] [G loss: 0.439050]\n",
      "[Epoch 64/100] [Batch 103/347] [D loss: 0.537273] [G loss: 0.436946]\n",
      "[Epoch 64/100] [Batch 104/347] [D loss: 0.533347] [G loss: 0.428505]\n",
      "[Epoch 64/100] [Batch 105/347] [D loss: 0.461102] [G loss: 0.417297]\n",
      "[Epoch 64/100] [Batch 106/347] [D loss: 0.239030] [G loss: 0.404344]\n",
      "[Epoch 64/100] [Batch 107/347] [D loss: 0.236126] [G loss: 0.398113]\n",
      "[Epoch 64/100] [Batch 108/347] [D loss: 0.229149] [G loss: 0.388052]\n",
      "[Epoch 64/100] [Batch 109/347] [D loss: 0.223720] [G loss: 0.381378]\n",
      "[Epoch 64/100] [Batch 110/347] [D loss: 0.262580] [G loss: 0.367128]\n",
      "[Epoch 64/100] [Batch 111/347] [D loss: 0.260290] [G loss: 0.365032]\n",
      "[Epoch 64/100] [Batch 112/347] [D loss: 0.263116] [G loss: 0.373467]\n",
      "[Epoch 64/100] [Batch 113/347] [D loss: 0.434970] [G loss: 0.397604]\n",
      "[Epoch 64/100] [Batch 114/347] [D loss: 0.510051] [G loss: 0.408958]\n",
      "[Epoch 64/100] [Batch 115/347] [D loss: 0.493229] [G loss: 0.394099]\n",
      "[Epoch 64/100] [Batch 116/347] [D loss: 0.442718] [G loss: 0.372285]\n",
      "[Epoch 64/100] [Batch 117/347] [D loss: 0.438298] [G loss: 0.350265]\n",
      "[Epoch 64/100] [Batch 118/347] [D loss: 0.383227] [G loss: 0.330729]\n",
      "[Epoch 64/100] [Batch 119/347] [D loss: 0.382950] [G loss: 0.315475]\n",
      "[Epoch 64/100] [Batch 120/347] [D loss: 0.384596] [G loss: 0.313960]\n",
      "[Epoch 64/100] [Batch 121/347] [D loss: 0.388618] [G loss: 0.315445]\n",
      "[Epoch 64/100] [Batch 122/347] [D loss: 0.479334] [G loss: 0.325359]\n",
      "[Epoch 64/100] [Batch 123/347] [D loss: 0.515242] [G loss: 0.339444]\n",
      "[Epoch 64/100] [Batch 124/347] [D loss: 0.460308] [G loss: 0.351417]\n",
      "[Epoch 64/100] [Batch 125/347] [D loss: 0.438304] [G loss: 0.367535]\n",
      "[Epoch 64/100] [Batch 126/347] [D loss: 0.408055] [G loss: 0.379579]\n",
      "[Epoch 64/100] [Batch 127/347] [D loss: 0.407347] [G loss: 0.381866]\n",
      "[Epoch 64/100] [Batch 128/347] [D loss: 0.385214] [G loss: 0.375358]\n",
      "[Epoch 64/100] [Batch 129/347] [D loss: 0.311360] [G loss: 0.377407]\n",
      "[Epoch 64/100] [Batch 130/347] [D loss: 0.230740] [G loss: 0.399044]\n",
      "[Epoch 64/100] [Batch 131/347] [D loss: 0.212400] [G loss: 0.416022]\n",
      "[Epoch 64/100] [Batch 132/347] [D loss: 0.201302] [G loss: 0.432403]\n",
      "[Epoch 64/100] [Batch 133/347] [D loss: 0.186087] [G loss: 0.447798]\n",
      "[Epoch 64/100] [Batch 134/347] [D loss: 0.179738] [G loss: 0.461724]\n",
      "[Epoch 64/100] [Batch 135/347] [D loss: 0.181509] [G loss: 0.471144]\n",
      "[Epoch 64/100] [Batch 136/347] [D loss: 0.182134] [G loss: 0.471945]\n",
      "[Epoch 64/100] [Batch 137/347] [D loss: 0.444311] [G loss: 0.467980]\n",
      "[Epoch 64/100] [Batch 138/347] [D loss: 0.464789] [G loss: 0.459686]\n",
      "[Epoch 64/100] [Batch 139/347] [D loss: 0.463786] [G loss: 0.445547]\n",
      "[Epoch 64/100] [Batch 140/347] [D loss: 0.452681] [G loss: 0.437018]\n",
      "[Epoch 64/100] [Batch 141/347] [D loss: 0.396523] [G loss: 0.417623]\n",
      "[Epoch 64/100] [Batch 142/347] [D loss: 0.365061] [G loss: 0.385830]\n",
      "[Epoch 64/100] [Batch 143/347] [D loss: 0.326172] [G loss: 0.328031]\n",
      "[Epoch 64/100] [Batch 144/347] [D loss: 0.316079] [G loss: 0.266504]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 64/100] [Batch 145/347] [D loss: 0.365332] [G loss: 0.230238]\n",
      "[Epoch 64/100] [Batch 146/347] [D loss: 0.401234] [G loss: 0.211056]\n",
      "[Epoch 64/100] [Batch 147/347] [D loss: 0.440912] [G loss: 0.211581]\n",
      "[Epoch 64/100] [Batch 148/347] [D loss: 0.457700] [G loss: 0.230833]\n",
      "[Epoch 64/100] [Batch 149/347] [D loss: 0.429004] [G loss: 0.261962]\n",
      "[Epoch 64/100] [Batch 150/347] [D loss: 0.403057] [G loss: 0.300139]\n",
      "[Epoch 64/100] [Batch 151/347] [D loss: 0.375466] [G loss: 0.336585]\n",
      "[Epoch 64/100] [Batch 152/347] [D loss: 0.353586] [G loss: 0.361010]\n",
      "[Epoch 64/100] [Batch 153/347] [D loss: 0.360511] [G loss: 0.372752]\n",
      "[Epoch 64/100] [Batch 154/347] [D loss: 0.360999] [G loss: 0.379808]\n",
      "[Epoch 64/100] [Batch 155/347] [D loss: 0.355660] [G loss: 0.384498]\n",
      "[Epoch 64/100] [Batch 156/347] [D loss: 0.346957] [G loss: 0.376894]\n",
      "[Epoch 64/100] [Batch 157/347] [D loss: 0.328916] [G loss: 0.366476]\n",
      "[Epoch 64/100] [Batch 158/347] [D loss: 0.271765] [G loss: 0.359401]\n",
      "[Epoch 64/100] [Batch 159/347] [D loss: 0.281165] [G loss: 0.353013]\n",
      "[Epoch 64/100] [Batch 160/347] [D loss: 0.286220] [G loss: 0.357914]\n",
      "[Epoch 64/100] [Batch 161/347] [D loss: 0.272556] [G loss: 0.365291]\n",
      "[Epoch 64/100] [Batch 162/347] [D loss: 0.282453] [G loss: 0.366560]\n",
      "[Epoch 64/100] [Batch 163/347] [D loss: 0.287750] [G loss: 0.363748]\n",
      "[Epoch 64/100] [Batch 164/347] [D loss: 0.284265] [G loss: 0.371341]\n",
      "[Epoch 64/100] [Batch 165/347] [D loss: 0.281785] [G loss: 0.383024]\n",
      "[Epoch 64/100] [Batch 166/347] [D loss: 0.291992] [G loss: 0.390142]\n",
      "[Epoch 64/100] [Batch 167/347] [D loss: 0.324643] [G loss: 0.402840]\n",
      "[Epoch 64/100] [Batch 168/347] [D loss: 0.316120] [G loss: 0.406813]\n",
      "[Epoch 64/100] [Batch 169/347] [D loss: 0.457366] [G loss: 0.408696]\n",
      "[Epoch 64/100] [Batch 170/347] [D loss: 0.525951] [G loss: 0.407497]\n",
      "[Epoch 64/100] [Batch 171/347] [D loss: 0.536505] [G loss: 0.398932]\n",
      "[Epoch 64/100] [Batch 172/347] [D loss: 0.539407] [G loss: 0.392405]\n",
      "[Epoch 64/100] [Batch 173/347] [D loss: 0.543045] [G loss: 0.384857]\n",
      "[Epoch 64/100] [Batch 174/347] [D loss: 0.543012] [G loss: 0.383578]\n",
      "[Epoch 64/100] [Batch 175/347] [D loss: 0.573112] [G loss: 0.388245]\n",
      "[Epoch 64/100] [Batch 176/347] [D loss: 0.592887] [G loss: 0.398942]\n",
      "[Epoch 64/100] [Batch 177/347] [D loss: 0.590094] [G loss: 0.409423]\n",
      "[Epoch 64/100] [Batch 178/347] [D loss: 0.581072] [G loss: 0.422068]\n",
      "[Epoch 64/100] [Batch 179/347] [D loss: 0.572814] [G loss: 0.439010]\n",
      "[Epoch 64/100] [Batch 180/347] [D loss: 0.564614] [G loss: 0.453692]\n",
      "[Epoch 64/100] [Batch 181/347] [D loss: 0.560880] [G loss: 0.472666]\n",
      "[Epoch 64/100] [Batch 182/347] [D loss: 0.558524] [G loss: 0.486769]\n",
      "[Epoch 64/100] [Batch 183/347] [D loss: 0.556722] [G loss: 0.498387]\n",
      "[Epoch 64/100] [Batch 184/347] [D loss: 0.558499] [G loss: 0.508684]\n",
      "[Epoch 64/100] [Batch 185/347] [D loss: 0.557427] [G loss: 0.511772]\n",
      "[Epoch 64/100] [Batch 186/347] [D loss: 0.555650] [G loss: 0.515285]\n",
      "[Epoch 64/100] [Batch 187/347] [D loss: 0.553990] [G loss: 0.516275]\n",
      "[Epoch 64/100] [Batch 188/347] [D loss: 0.549886] [G loss: 0.511104]\n",
      "[Epoch 64/100] [Batch 189/347] [D loss: 0.545755] [G loss: 0.506891]\n",
      "[Epoch 64/100] [Batch 190/347] [D loss: 0.545050] [G loss: 0.505321]\n",
      "[Epoch 64/100] [Batch 191/347] [D loss: 0.545461] [G loss: 0.503097]\n",
      "[Epoch 64/100] [Batch 192/347] [D loss: 0.546162] [G loss: 0.503174]\n",
      "[Epoch 64/100] [Batch 193/347] [D loss: 0.549828] [G loss: 0.503145]\n",
      "[Epoch 64/100] [Batch 194/347] [D loss: 0.548675] [G loss: 0.498863]\n",
      "[Epoch 64/100] [Batch 195/347] [D loss: 0.546073] [G loss: 0.494660]\n",
      "[Epoch 64/100] [Batch 196/347] [D loss: 0.540452] [G loss: 0.490201]\n",
      "[Epoch 64/100] [Batch 197/347] [D loss: 0.539397] [G loss: 0.486689]\n",
      "[Epoch 64/100] [Batch 198/347] [D loss: 0.537739] [G loss: 0.486205]\n",
      "[Epoch 64/100] [Batch 199/347] [D loss: 0.536898] [G loss: 0.482692]\n",
      "[Epoch 64/100] [Batch 200/347] [D loss: 0.541433] [G loss: 0.479000]\n",
      "[Epoch 64/100] [Batch 201/347] [D loss: 0.542555] [G loss: 0.474188]\n",
      "[Epoch 64/100] [Batch 202/347] [D loss: 0.542134] [G loss: 0.468920]\n",
      "[Epoch 64/100] [Batch 203/347] [D loss: 0.542329] [G loss: 0.463259]\n",
      "[Epoch 64/100] [Batch 204/347] [D loss: 0.540716] [G loss: 0.461639]\n",
      "[Epoch 64/100] [Batch 205/347] [D loss: 0.539770] [G loss: 0.461459]\n",
      "[Epoch 64/100] [Batch 206/347] [D loss: 0.538828] [G loss: 0.459377]\n",
      "[Epoch 64/100] [Batch 207/347] [D loss: 0.531838] [G loss: 0.456208]\n",
      "[Epoch 64/100] [Batch 208/347] [D loss: 0.529210] [G loss: 0.454207]\n",
      "[Epoch 64/100] [Batch 209/347] [D loss: 0.524064] [G loss: 0.443715]\n",
      "[Epoch 64/100] [Batch 210/347] [D loss: 0.495204] [G loss: 0.435970]\n",
      "[Epoch 64/100] [Batch 211/347] [D loss: 0.426147] [G loss: 0.420246]\n",
      "[Epoch 64/100] [Batch 212/347] [D loss: 0.247892] [G loss: 0.396709]\n",
      "[Epoch 64/100] [Batch 213/347] [D loss: 0.239471] [G loss: 0.384621]\n",
      "[Epoch 64/100] [Batch 214/347] [D loss: 0.234612] [G loss: 0.368754]\n",
      "[Epoch 64/100] [Batch 215/347] [D loss: 0.237979] [G loss: 0.357294]\n",
      "[Epoch 64/100] [Batch 216/347] [D loss: 0.410215] [G loss: 0.350106]\n",
      "[Epoch 64/100] [Batch 217/347] [D loss: 0.465223] [G loss: 0.349497]\n",
      "[Epoch 64/100] [Batch 218/347] [D loss: 0.506205] [G loss: 0.354423]\n",
      "[Epoch 64/100] [Batch 219/347] [D loss: 0.503605] [G loss: 0.356489]\n",
      "[Epoch 64/100] [Batch 220/347] [D loss: 0.491000] [G loss: 0.361716]\n",
      "[Epoch 64/100] [Batch 221/347] [D loss: 0.510612] [G loss: 0.367749]\n",
      "[Epoch 64/100] [Batch 222/347] [D loss: 0.509139] [G loss: 0.368421]\n",
      "[Epoch 64/100] [Batch 223/347] [D loss: 0.482367] [G loss: 0.359572]\n",
      "[Epoch 64/100] [Batch 224/347] [D loss: 0.483196] [G loss: 0.346823]\n",
      "[Epoch 64/100] [Batch 225/347] [D loss: 0.488986] [G loss: 0.336891]\n",
      "[Epoch 64/100] [Batch 226/347] [D loss: 0.489687] [G loss: 0.333340]\n",
      "[Epoch 64/100] [Batch 227/347] [D loss: 0.502511] [G loss: 0.339890]\n",
      "[Epoch 64/100] [Batch 228/347] [D loss: 0.508974] [G loss: 0.347937]\n",
      "[Epoch 64/100] [Batch 229/347] [D loss: 0.511745] [G loss: 0.356183]\n",
      "[Epoch 64/100] [Batch 230/347] [D loss: 0.516359] [G loss: 0.363431]\n",
      "[Epoch 64/100] [Batch 231/347] [D loss: 0.507324] [G loss: 0.360823]\n",
      "[Epoch 64/100] [Batch 232/347] [D loss: 0.500456] [G loss: 0.361498]\n",
      "[Epoch 64/100] [Batch 233/347] [D loss: 0.462021] [G loss: 0.363831]\n",
      "[Epoch 64/100] [Batch 234/347] [D loss: 0.441951] [G loss: 0.361818]\n",
      "[Epoch 64/100] [Batch 235/347] [D loss: 0.438232] [G loss: 0.363235]\n",
      "[Epoch 64/100] [Batch 236/347] [D loss: 0.432170] [G loss: 0.360235]\n",
      "[Epoch 64/100] [Batch 237/347] [D loss: 0.477053] [G loss: 0.356050]\n",
      "[Epoch 64/100] [Batch 238/347] [D loss: 0.532429] [G loss: 0.351299]\n",
      "[Epoch 64/100] [Batch 239/347] [D loss: 0.530916] [G loss: 0.349552]\n",
      "[Epoch 64/100] [Batch 240/347] [D loss: 0.530777] [G loss: 0.354012]\n",
      "[Epoch 64/100] [Batch 241/347] [D loss: 0.530674] [G loss: 0.365360]\n",
      "[Epoch 64/100] [Batch 242/347] [D loss: 0.534573] [G loss: 0.379728]\n",
      "[Epoch 64/100] [Batch 243/347] [D loss: 0.507696] [G loss: 0.391903]\n",
      "[Epoch 64/100] [Batch 244/347] [D loss: 0.492193] [G loss: 0.390229]\n",
      "[Epoch 64/100] [Batch 245/347] [D loss: 0.493651] [G loss: 0.383093]\n",
      "[Epoch 64/100] [Batch 246/347] [D loss: 0.493230] [G loss: 0.371689]\n",
      "[Epoch 64/100] [Batch 247/347] [D loss: 0.500152] [G loss: 0.362527]\n",
      "[Epoch 64/100] [Batch 248/347] [D loss: 0.505158] [G loss: 0.363680]\n",
      "[Epoch 64/100] [Batch 249/347] [D loss: 0.499114] [G loss: 0.366845]\n",
      "[Epoch 64/100] [Batch 250/347] [D loss: 0.498258] [G loss: 0.373554]\n",
      "[Epoch 64/100] [Batch 251/347] [D loss: 0.496658] [G loss: 0.380890]\n",
      "[Epoch 64/100] [Batch 252/347] [D loss: 0.492868] [G loss: 0.381971]\n",
      "[Epoch 64/100] [Batch 253/347] [D loss: 0.452704] [G loss: 0.368077]\n",
      "[Epoch 64/100] [Batch 254/347] [D loss: 0.441424] [G loss: 0.361956]\n",
      "[Epoch 64/100] [Batch 255/347] [D loss: 0.436593] [G loss: 0.350497]\n",
      "[Epoch 64/100] [Batch 256/347] [D loss: 0.436346] [G loss: 0.330519]\n",
      "[Epoch 64/100] [Batch 257/347] [D loss: 0.438395] [G loss: 0.320003]\n",
      "[Epoch 64/100] [Batch 258/347] [D loss: 0.412134] [G loss: 0.313658]\n",
      "[Epoch 64/100] [Batch 259/347] [D loss: 0.414527] [G loss: 0.310790]\n",
      "[Epoch 64/100] [Batch 260/347] [D loss: 0.414652] [G loss: 0.314948]\n",
      "[Epoch 64/100] [Batch 261/347] [D loss: 0.398554] [G loss: 0.327688]\n",
      "[Epoch 64/100] [Batch 262/347] [D loss: 0.355306] [G loss: 0.340359]\n",
      "[Epoch 64/100] [Batch 263/347] [D loss: 0.346698] [G loss: 0.350558]\n",
      "[Epoch 64/100] [Batch 264/347] [D loss: 0.348604] [G loss: 0.359388]\n",
      "[Epoch 64/100] [Batch 265/347] [D loss: 0.356108] [G loss: 0.362405]\n",
      "[Epoch 64/100] [Batch 266/347] [D loss: 0.413511] [G loss: 0.364289]\n",
      "[Epoch 64/100] [Batch 267/347] [D loss: 0.429448] [G loss: 0.361446]\n",
      "[Epoch 64/100] [Batch 268/347] [D loss: 0.437293] [G loss: 0.354090]\n",
      "[Epoch 64/100] [Batch 269/347] [D loss: 0.433493] [G loss: 0.342884]\n",
      "[Epoch 64/100] [Batch 270/347] [D loss: 0.456500] [G loss: 0.331181]\n",
      "[Epoch 64/100] [Batch 271/347] [D loss: 0.449266] [G loss: 0.332370]\n",
      "[Epoch 64/100] [Batch 272/347] [D loss: 0.505399] [G loss: 0.376266]\n",
      "[Epoch 64/100] [Batch 273/347] [D loss: 0.415059] [G loss: 0.413457]\n",
      "[Epoch 64/100] [Batch 274/347] [D loss: 0.308041] [G loss: 0.438919]\n",
      "[Epoch 64/100] [Batch 275/347] [D loss: 0.235928] [G loss: 0.460159]\n",
      "[Epoch 64/100] [Batch 276/347] [D loss: 0.497121] [G loss: 0.465824]\n",
      "[Epoch 64/100] [Batch 277/347] [D loss: 0.522865] [G loss: 0.481499]\n",
      "[Epoch 64/100] [Batch 278/347] [D loss: 0.531007] [G loss: 0.494684]\n",
      "[Epoch 64/100] [Batch 279/347] [D loss: 0.535923] [G loss: 0.498672]\n",
      "[Epoch 64/100] [Batch 280/347] [D loss: 0.540471] [G loss: 0.500079]\n",
      "[Epoch 64/100] [Batch 281/347] [D loss: 0.544272] [G loss: 0.501975]\n",
      "[Epoch 64/100] [Batch 282/347] [D loss: 0.546455] [G loss: 0.504407]\n",
      "[Epoch 64/100] [Batch 283/347] [D loss: 0.548058] [G loss: 0.505810]\n",
      "[Epoch 64/100] [Batch 284/347] [D loss: 0.549213] [G loss: 0.508102]\n",
      "[Epoch 64/100] [Batch 285/347] [D loss: 0.550798] [G loss: 0.509022]\n",
      "[Epoch 64/100] [Batch 286/347] [D loss: 0.550152] [G loss: 0.495135]\n",
      "[Epoch 64/100] [Batch 287/347] [D loss: 0.550587] [G loss: 0.492548]\n",
      "[Epoch 64/100] [Batch 288/347] [D loss: 0.550987] [G loss: 0.490050]\n",
      "[Epoch 64/100] [Batch 289/347] [D loss: 0.550763] [G loss: 0.486598]\n",
      "[Epoch 64/100] [Batch 290/347] [D loss: 0.551482] [G loss: 0.501254]\n",
      "[Epoch 64/100] [Batch 291/347] [D loss: 0.551184] [G loss: 0.508556]\n",
      "[Epoch 64/100] [Batch 292/347] [D loss: 0.550556] [G loss: 0.512876]\n",
      "[Epoch 64/100] [Batch 293/347] [D loss: 0.542162] [G loss: 0.518795]\n",
      "[Epoch 64/100] [Batch 294/347] [D loss: 0.542004] [G loss: 0.524157]\n",
      "[Epoch 64/100] [Batch 295/347] [D loss: 0.541960] [G loss: 0.523925]\n",
      "[Epoch 64/100] [Batch 296/347] [D loss: 0.541590] [G loss: 0.523323]\n",
      "[Epoch 64/100] [Batch 297/347] [D loss: 0.550485] [G loss: 0.528723]\n",
      "[Epoch 64/100] [Batch 298/347] [D loss: 0.551918] [G loss: 0.523067]\n",
      "[Epoch 64/100] [Batch 299/347] [D loss: 0.551247] [G loss: 0.519184]\n",
      "[Epoch 64/100] [Batch 300/347] [D loss: 0.550546] [G loss: 0.517679]\n",
      "[Epoch 64/100] [Batch 301/347] [D loss: 0.550299] [G loss: 0.506149]\n",
      "[Epoch 64/100] [Batch 302/347] [D loss: 0.550257] [G loss: 0.497748]\n",
      "[Epoch 64/100] [Batch 303/347] [D loss: 0.549875] [G loss: 0.484668]\n",
      "[Epoch 64/100] [Batch 304/347] [D loss: 0.543289] [G loss: 0.473485]\n",
      "[Epoch 64/100] [Batch 305/347] [D loss: 0.537126] [G loss: 0.469531]\n",
      "[Epoch 64/100] [Batch 306/347] [D loss: 0.536300] [G loss: 0.471378]\n",
      "[Epoch 64/100] [Batch 307/347] [D loss: 0.534611] [G loss: 0.477501]\n",
      "[Epoch 64/100] [Batch 308/347] [D loss: 0.537746] [G loss: 0.480242]\n",
      "[Epoch 64/100] [Batch 309/347] [D loss: 0.547860] [G loss: 0.495088]\n",
      "[Epoch 64/100] [Batch 310/347] [D loss: 0.550437] [G loss: 0.507808]\n",
      "[Epoch 64/100] [Batch 311/347] [D loss: 0.549317] [G loss: 0.505769]\n",
      "[Epoch 64/100] [Batch 312/347] [D loss: 0.547153] [G loss: 0.501019]\n",
      "[Epoch 64/100] [Batch 313/347] [D loss: 0.544698] [G loss: 0.492188]\n",
      "[Epoch 64/100] [Batch 314/347] [D loss: 0.543793] [G loss: 0.477770]\n",
      "[Epoch 64/100] [Batch 315/347] [D loss: 0.543216] [G loss: 0.466730]\n",
      "[Epoch 64/100] [Batch 316/347] [D loss: 0.543054] [G loss: 0.467838]\n",
      "[Epoch 64/100] [Batch 317/347] [D loss: 0.543397] [G loss: 0.471538]\n",
      "[Epoch 64/100] [Batch 318/347] [D loss: 0.543421] [G loss: 0.484747]\n",
      "[Epoch 64/100] [Batch 319/347] [D loss: 0.542725] [G loss: 0.496700]\n",
      "[Epoch 64/100] [Batch 320/347] [D loss: 0.541850] [G loss: 0.494940]\n",
      "[Epoch 64/100] [Batch 321/347] [D loss: 0.539649] [G loss: 0.487981]\n",
      "[Epoch 64/100] [Batch 322/347] [D loss: 0.538816] [G loss: 0.480275]\n",
      "[Epoch 64/100] [Batch 323/347] [D loss: 0.533839] [G loss: 0.471183]\n",
      "[Epoch 64/100] [Batch 324/347] [D loss: 0.531487] [G loss: 0.464722]\n",
      "[Epoch 64/100] [Batch 325/347] [D loss: 0.530479] [G loss: 0.457083]\n",
      "[Epoch 64/100] [Batch 326/347] [D loss: 0.529396] [G loss: 0.451069]\n",
      "[Epoch 64/100] [Batch 327/347] [D loss: 0.525897] [G loss: 0.445589]\n",
      "[Epoch 64/100] [Batch 328/347] [D loss: 0.524874] [G loss: 0.439215]\n",
      "[Epoch 64/100] [Batch 329/347] [D loss: 0.523314] [G loss: 0.435807]\n",
      "[Epoch 64/100] [Batch 330/347] [D loss: 0.521370] [G loss: 0.433825]\n",
      "[Epoch 64/100] [Batch 331/347] [D loss: 0.523155] [G loss: 0.433978]\n",
      "[Epoch 64/100] [Batch 332/347] [D loss: 0.529610] [G loss: 0.451140]\n",
      "[Epoch 64/100] [Batch 333/347] [D loss: 0.525916] [G loss: 0.447028]\n",
      "[Epoch 64/100] [Batch 334/347] [D loss: 0.523220] [G loss: 0.437726]\n",
      "[Epoch 64/100] [Batch 335/347] [D loss: 0.521562] [G loss: 0.433105]\n",
      "[Epoch 64/100] [Batch 336/347] [D loss: 0.520510] [G loss: 0.429136]\n",
      "[Epoch 64/100] [Batch 337/347] [D loss: 0.522649] [G loss: 0.430481]\n",
      "[Epoch 64/100] [Batch 338/347] [D loss: 0.525866] [G loss: 0.435540]\n",
      "[Epoch 64/100] [Batch 339/347] [D loss: 0.522025] [G loss: 0.432877]\n",
      "[Epoch 64/100] [Batch 340/347] [D loss: 0.517976] [G loss: 0.426339]\n",
      "[Epoch 64/100] [Batch 341/347] [D loss: 0.516888] [G loss: 0.423428]\n",
      "[Epoch 64/100] [Batch 342/347] [D loss: 0.497156] [G loss: 0.407972]\n",
      "[Epoch 64/100] [Batch 343/347] [D loss: 0.490502] [G loss: 0.389235]\n",
      "[Epoch 64/100] [Batch 344/347] [D loss: 0.472749] [G loss: 0.382521]\n",
      "[Epoch 64/100] [Batch 345/347] [D loss: 0.438279] [G loss: 0.376879]\n",
      "[Epoch 64/100] [Batch 346/347] [D loss: 0.434956] [G loss: 0.372578]\n",
      "[Epoch 64/100] [Batch 347/347] [D loss: 0.428466] [G loss: 0.368299]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 1/347] [D loss: 0.503721] [G loss: 0.375927]\n",
      "[Epoch 65/100] [Batch 2/347] [D loss: 0.504664] [G loss: 0.371284]\n",
      "[Epoch 65/100] [Batch 3/347] [D loss: 0.508918] [G loss: 0.370267]\n",
      "[Epoch 65/100] [Batch 4/347] [D loss: 0.508247] [G loss: 0.365519]\n",
      "[Epoch 65/100] [Batch 5/347] [D loss: 0.506440] [G loss: 0.357156]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 6/347] [D loss: 0.501048] [G loss: 0.349287]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 7/347] [D loss: 0.493659] [G loss: 0.335899]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 8/347] [D loss: 0.492040] [G loss: 0.329619]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 9/347] [D loss: 0.490578] [G loss: 0.325738]\n",
      "[Epoch 65/100] [Batch 10/347] [D loss: 0.490857] [G loss: 0.321885]\n",
      "[Epoch 65/100] [Batch 11/347] [D loss: 0.498027] [G loss: 0.326252]\n",
      "[Epoch 65/100] [Batch 12/347] [D loss: 0.498933] [G loss: 0.323956]\n",
      "[Epoch 65/100] [Batch 13/347] [D loss: 0.494069] [G loss: 0.318258]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 14/347] [D loss: 0.489645] [G loss: 0.313213]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 15/347] [D loss: 0.485724] [G loss: 0.299622]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 16/347] [D loss: 0.482940] [G loss: 0.289676]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 17/347] [D loss: 0.482618] [G loss: 0.287995]\n",
      "[Epoch 65/100] [Batch 18/347] [D loss: 0.483414] [G loss: 0.284751]\n",
      "[Epoch 65/100] [Batch 19/347] [D loss: 0.484917] [G loss: 0.285879]\n",
      "[Epoch 65/100] [Batch 20/347] [D loss: 0.488810] [G loss: 0.286600]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 21/347] [D loss: 0.478476] [G loss: 0.278164]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 22/347] [D loss: 0.477714] [G loss: 0.272770]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 23/347] [D loss: 0.476776] [G loss: 0.266026]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 24/347] [D loss: 0.457921] [G loss: 0.260042]\n",
      "[Epoch 65/100] [Batch 25/347] [D loss: 0.419464] [G loss: 0.260104]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 26/347] [D loss: 0.415830] [G loss: 0.256898]\n",
      "[Epoch 65/100] [Batch 27/347] [D loss: 0.411472] [G loss: 0.257034]\n",
      "[Epoch 65/100] [Batch 28/347] [D loss: 0.405414] [G loss: 0.258216]\n",
      "[Epoch 65/100] [Batch 29/347] [D loss: 0.421049] [G loss: 0.254834]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 30/347] [D loss: 0.406217] [G loss: 0.250104]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 31/347] [D loss: 0.397465] [G loss: 0.242996]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 65/100] [Batch 32/347] [D loss: 0.396766] [G loss: 0.232513]\n",
      "[Epoch 65/100] [Batch 33/347] [D loss: 0.401584] [G loss: 0.222836]\n",
      "[Epoch 65/100] [Batch 34/347] [D loss: 0.418172] [G loss: 0.209039]\n",
      "[Epoch 65/100] [Batch 35/347] [D loss: 0.407698] [G loss: 0.196215]\n",
      "[Epoch 65/100] [Batch 36/347] [D loss: 0.411778] [G loss: 0.196962]\n",
      "[Epoch 65/100] [Batch 37/347] [D loss: 0.416122] [G loss: 0.192632]\n",
      "[Epoch 65/100] [Batch 38/347] [D loss: 0.422256] [G loss: 0.191904]\n",
      "[Epoch 65/100] [Batch 39/347] [D loss: 0.433672] [G loss: 0.187765]\n",
      "[Epoch 65/100] [Batch 40/347] [D loss: 0.450377] [G loss: 0.190945]\n",
      "[Epoch 65/100] [Batch 41/347] [D loss: 0.453882] [G loss: 0.190462]\n",
      "[Epoch 65/100] [Batch 42/347] [D loss: 0.449239] [G loss: 0.195605]\n",
      "[Epoch 65/100] [Batch 43/347] [D loss: 0.460477] [G loss: 0.223026]\n",
      "[Epoch 65/100] [Batch 44/347] [D loss: 0.453349] [G loss: 0.241815]\n",
      "[Epoch 65/100] [Batch 45/347] [D loss: 0.434318] [G loss: 0.245352]\n",
      "[Epoch 65/100] [Batch 46/347] [D loss: 0.379382] [G loss: 0.251243]\n",
      "[Epoch 65/100] [Batch 47/347] [D loss: 0.367082] [G loss: 0.265416]\n",
      "[Epoch 65/100] [Batch 48/347] [D loss: 0.286619] [G loss: 0.296988]\n",
      "[Epoch 65/100] [Batch 49/347] [D loss: 0.276425] [G loss: 0.303411]\n",
      "[Epoch 65/100] [Batch 50/347] [D loss: 0.264787] [G loss: 0.299230]\n",
      "[Epoch 65/100] [Batch 51/347] [D loss: 0.262055] [G loss: 0.306282]\n",
      "[Epoch 65/100] [Batch 52/347] [D loss: 0.343357] [G loss: 0.318556]\n",
      "[Epoch 65/100] [Batch 53/347] [D loss: 0.372797] [G loss: 0.337250]\n",
      "[Epoch 65/100] [Batch 54/347] [D loss: 0.355544] [G loss: 0.347605]\n",
      "[Epoch 65/100] [Batch 55/347] [D loss: 0.343773] [G loss: 0.341074]\n",
      "[Epoch 65/100] [Batch 56/347] [D loss: 0.328915] [G loss: 0.315219]\n",
      "[Epoch 65/100] [Batch 57/347] [D loss: 0.298582] [G loss: 0.287137]\n",
      "[Epoch 65/100] [Batch 58/347] [D loss: 0.306037] [G loss: 0.279403]\n",
      "[Epoch 65/100] [Batch 59/347] [D loss: 0.308205] [G loss: 0.269555]\n",
      "[Epoch 65/100] [Batch 60/347] [D loss: 0.306036] [G loss: 0.290282]\n",
      "[Epoch 65/100] [Batch 61/347] [D loss: 0.315167] [G loss: 0.301777]\n",
      "[Epoch 65/100] [Batch 62/347] [D loss: 0.312179] [G loss: 0.305387]\n",
      "[Epoch 65/100] [Batch 63/347] [D loss: 0.306698] [G loss: 0.305016]\n",
      "[Epoch 65/100] [Batch 64/347] [D loss: 0.290688] [G loss: 0.316637]\n",
      "[Epoch 65/100] [Batch 65/347] [D loss: 0.237306] [G loss: 0.339650]\n",
      "[Epoch 65/100] [Batch 66/347] [D loss: 0.232506] [G loss: 0.350646]\n",
      "[Epoch 65/100] [Batch 67/347] [D loss: 0.234876] [G loss: 0.357668]\n",
      "[Epoch 65/100] [Batch 68/347] [D loss: 0.245390] [G loss: 0.369589]\n",
      "[Epoch 65/100] [Batch 69/347] [D loss: 0.276150] [G loss: 0.383481]\n",
      "[Epoch 65/100] [Batch 70/347] [D loss: 0.280222] [G loss: 0.382334]\n",
      "[Epoch 65/100] [Batch 71/347] [D loss: 0.274580] [G loss: 0.366953]\n",
      "[Epoch 65/100] [Batch 72/347] [D loss: 0.280081] [G loss: 0.358731]\n",
      "[Epoch 65/100] [Batch 73/347] [D loss: 0.351457] [G loss: 0.346197]\n",
      "[Epoch 65/100] [Batch 74/347] [D loss: 0.340877] [G loss: 0.315982]\n",
      "[Epoch 65/100] [Batch 75/347] [D loss: 0.337082] [G loss: 0.295481]\n",
      "[Epoch 65/100] [Batch 76/347] [D loss: 0.343742] [G loss: 0.277866]\n",
      "[Epoch 65/100] [Batch 77/347] [D loss: 0.389674] [G loss: 0.265867]\n",
      "[Epoch 65/100] [Batch 78/347] [D loss: 0.446495] [G loss: 0.262832]\n",
      "[Epoch 65/100] [Batch 79/347] [D loss: 0.458716] [G loss: 0.267630]\n",
      "[Epoch 65/100] [Batch 80/347] [D loss: 0.394481] [G loss: 0.268286]\n",
      "[Epoch 65/100] [Batch 81/347] [D loss: 0.376777] [G loss: 0.286483]\n",
      "[Epoch 65/100] [Batch 82/347] [D loss: 0.370281] [G loss: 0.311032]\n",
      "[Epoch 65/100] [Batch 83/347] [D loss: 0.364698] [G loss: 0.333993]\n",
      "[Epoch 65/100] [Batch 84/347] [D loss: 0.463053] [G loss: 0.359243]\n",
      "[Epoch 65/100] [Batch 85/347] [D loss: 0.518986] [G loss: 0.376541]\n",
      "[Epoch 65/100] [Batch 86/347] [D loss: 0.519445] [G loss: 0.390863]\n",
      "[Epoch 65/100] [Batch 87/347] [D loss: 0.520567] [G loss: 0.402436]\n",
      "[Epoch 65/100] [Batch 88/347] [D loss: 0.525559] [G loss: 0.411561]\n",
      "[Epoch 65/100] [Batch 89/347] [D loss: 0.528778] [G loss: 0.419808]\n",
      "[Epoch 65/100] [Batch 90/347] [D loss: 0.528394] [G loss: 0.424150]\n",
      "[Epoch 65/100] [Batch 91/347] [D loss: 0.528385] [G loss: 0.426557]\n",
      "[Epoch 65/100] [Batch 92/347] [D loss: 0.528947] [G loss: 0.429278]\n",
      "[Epoch 65/100] [Batch 93/347] [D loss: 0.528678] [G loss: 0.431283]\n",
      "[Epoch 65/100] [Batch 94/347] [D loss: 0.525962] [G loss: 0.428742]\n",
      "[Epoch 65/100] [Batch 95/347] [D loss: 0.524494] [G loss: 0.428347]\n",
      "[Epoch 65/100] [Batch 96/347] [D loss: 0.525294] [G loss: 0.429795]\n",
      "[Epoch 65/100] [Batch 97/347] [D loss: 0.523940] [G loss: 0.428863]\n",
      "[Epoch 65/100] [Batch 98/347] [D loss: 0.523804] [G loss: 0.429471]\n",
      "[Epoch 65/100] [Batch 99/347] [D loss: 0.525391] [G loss: 0.428680]\n",
      "[Epoch 65/100] [Batch 100/347] [D loss: 0.525408] [G loss: 0.426973]\n",
      "[Epoch 65/100] [Batch 101/347] [D loss: 0.524580] [G loss: 0.423150]\n",
      "[Epoch 65/100] [Batch 102/347] [D loss: 0.527841] [G loss: 0.418300]\n",
      "[Epoch 65/100] [Batch 103/347] [D loss: 0.527197] [G loss: 0.417007]\n",
      "[Epoch 65/100] [Batch 104/347] [D loss: 0.523197] [G loss: 0.409402]\n",
      "[Epoch 65/100] [Batch 105/347] [D loss: 0.443137] [G loss: 0.399814]\n",
      "[Epoch 65/100] [Batch 106/347] [D loss: 0.206142] [G loss: 0.397792]\n",
      "[Epoch 65/100] [Batch 107/347] [D loss: 0.209089] [G loss: 0.399473]\n",
      "[Epoch 65/100] [Batch 108/347] [D loss: 0.205766] [G loss: 0.399122]\n",
      "[Epoch 65/100] [Batch 109/347] [D loss: 0.203314] [G loss: 0.402199]\n",
      "[Epoch 65/100] [Batch 110/347] [D loss: 0.233495] [G loss: 0.396422]\n",
      "[Epoch 65/100] [Batch 111/347] [D loss: 0.228519] [G loss: 0.393469]\n",
      "[Epoch 65/100] [Batch 112/347] [D loss: 0.228805] [G loss: 0.392783]\n",
      "[Epoch 65/100] [Batch 113/347] [D loss: 0.408588] [G loss: 0.406044]\n",
      "[Epoch 65/100] [Batch 114/347] [D loss: 0.484492] [G loss: 0.405652]\n",
      "[Epoch 65/100] [Batch 115/347] [D loss: 0.464297] [G loss: 0.377376]\n",
      "[Epoch 65/100] [Batch 116/347] [D loss: 0.400293] [G loss: 0.345926]\n",
      "[Epoch 65/100] [Batch 117/347] [D loss: 0.392646] [G loss: 0.321539]\n",
      "[Epoch 65/100] [Batch 118/347] [D loss: 0.344880] [G loss: 0.305717]\n",
      "[Epoch 65/100] [Batch 119/347] [D loss: 0.348603] [G loss: 0.297363]\n",
      "[Epoch 65/100] [Batch 120/347] [D loss: 0.350211] [G loss: 0.300940]\n",
      "[Epoch 65/100] [Batch 121/347] [D loss: 0.352305] [G loss: 0.309263]\n",
      "[Epoch 65/100] [Batch 122/347] [D loss: 0.444878] [G loss: 0.323164]\n",
      "[Epoch 65/100] [Batch 123/347] [D loss: 0.485863] [G loss: 0.338502]\n",
      "[Epoch 65/100] [Batch 124/347] [D loss: 0.425343] [G loss: 0.348718]\n",
      "[Epoch 65/100] [Batch 125/347] [D loss: 0.399558] [G loss: 0.362300]\n",
      "[Epoch 65/100] [Batch 126/347] [D loss: 0.364756] [G loss: 0.372801]\n",
      "[Epoch 65/100] [Batch 127/347] [D loss: 0.363648] [G loss: 0.375546]\n",
      "[Epoch 65/100] [Batch 128/347] [D loss: 0.345286] [G loss: 0.370674]\n",
      "[Epoch 65/100] [Batch 129/347] [D loss: 0.281998] [G loss: 0.376315]\n",
      "[Epoch 65/100] [Batch 130/347] [D loss: 0.221142] [G loss: 0.395120]\n",
      "[Epoch 65/100] [Batch 131/347] [D loss: 0.206566] [G loss: 0.409316]\n",
      "[Epoch 65/100] [Batch 132/347] [D loss: 0.192082] [G loss: 0.424089]\n",
      "[Epoch 65/100] [Batch 133/347] [D loss: 0.186735] [G loss: 0.437821]\n",
      "[Epoch 65/100] [Batch 134/347] [D loss: 0.173505] [G loss: 0.450175]\n",
      "[Epoch 65/100] [Batch 135/347] [D loss: 0.170222] [G loss: 0.458824]\n",
      "[Epoch 65/100] [Batch 136/347] [D loss: 0.167455] [G loss: 0.459831]\n",
      "[Epoch 65/100] [Batch 137/347] [D loss: 0.429380] [G loss: 0.456860]\n",
      "[Epoch 65/100] [Batch 138/347] [D loss: 0.454813] [G loss: 0.450646]\n",
      "[Epoch 65/100] [Batch 139/347] [D loss: 0.462128] [G loss: 0.440006]\n",
      "[Epoch 65/100] [Batch 140/347] [D loss: 0.457971] [G loss: 0.436717]\n",
      "[Epoch 65/100] [Batch 141/347] [D loss: 0.417563] [G loss: 0.426739]\n",
      "[Epoch 65/100] [Batch 142/347] [D loss: 0.403451] [G loss: 0.423753]\n",
      "[Epoch 65/100] [Batch 143/347] [D loss: 0.372228] [G loss: 0.417097]\n",
      "[Epoch 65/100] [Batch 144/347] [D loss: 0.333080] [G loss: 0.391443]\n",
      "[Epoch 65/100] [Batch 145/347] [D loss: 0.340444] [G loss: 0.335496]\n",
      "[Epoch 65/100] [Batch 146/347] [D loss: 0.336863] [G loss: 0.281013]\n",
      "[Epoch 65/100] [Batch 147/347] [D loss: 0.375795] [G loss: 0.233732]\n",
      "[Epoch 65/100] [Batch 148/347] [D loss: 0.410887] [G loss: 0.205539]\n",
      "[Epoch 65/100] [Batch 149/347] [D loss: 0.413913] [G loss: 0.193234]\n",
      "[Epoch 65/100] [Batch 150/347] [D loss: 0.421530] [G loss: 0.198383]\n",
      "[Epoch 65/100] [Batch 151/347] [D loss: 0.411461] [G loss: 0.216314]\n",
      "[Epoch 65/100] [Batch 152/347] [D loss: 0.384330] [G loss: 0.243062]\n",
      "[Epoch 65/100] [Batch 153/347] [D loss: 0.358106] [G loss: 0.276730]\n",
      "[Epoch 65/100] [Batch 154/347] [D loss: 0.330853] [G loss: 0.318075]\n",
      "[Epoch 65/100] [Batch 155/347] [D loss: 0.311794] [G loss: 0.357708]\n",
      "[Epoch 65/100] [Batch 156/347] [D loss: 0.303427] [G loss: 0.380036]\n",
      "[Epoch 65/100] [Batch 157/347] [D loss: 0.302434] [G loss: 0.394042]\n",
      "[Epoch 65/100] [Batch 158/347] [D loss: 0.253136] [G loss: 0.405110]\n",
      "[Epoch 65/100] [Batch 159/347] [D loss: 0.269566] [G loss: 0.408925]\n",
      "[Epoch 65/100] [Batch 160/347] [D loss: 0.278331] [G loss: 0.415514]\n",
      "[Epoch 65/100] [Batch 161/347] [D loss: 0.257509] [G loss: 0.414875]\n",
      "[Epoch 65/100] [Batch 162/347] [D loss: 0.269354] [G loss: 0.402918]\n",
      "[Epoch 65/100] [Batch 163/347] [D loss: 0.270210] [G loss: 0.384646]\n",
      "[Epoch 65/100] [Batch 164/347] [D loss: 0.258057] [G loss: 0.368901]\n",
      "[Epoch 65/100] [Batch 165/347] [D loss: 0.252709] [G loss: 0.359589]\n",
      "[Epoch 65/100] [Batch 166/347] [D loss: 0.258450] [G loss: 0.350030]\n",
      "[Epoch 65/100] [Batch 167/347] [D loss: 0.287477] [G loss: 0.349594]\n",
      "[Epoch 65/100] [Batch 168/347] [D loss: 0.283862] [G loss: 0.352391]\n",
      "[Epoch 65/100] [Batch 169/347] [D loss: 0.415887] [G loss: 0.355252]\n",
      "[Epoch 65/100] [Batch 170/347] [D loss: 0.483646] [G loss: 0.353761]\n",
      "[Epoch 65/100] [Batch 171/347] [D loss: 0.497533] [G loss: 0.346470]\n",
      "[Epoch 65/100] [Batch 172/347] [D loss: 0.500033] [G loss: 0.340096]\n",
      "[Epoch 65/100] [Batch 173/347] [D loss: 0.503468] [G loss: 0.331068]\n",
      "[Epoch 65/100] [Batch 174/347] [D loss: 0.502565] [G loss: 0.329041]\n",
      "[Epoch 65/100] [Batch 175/347] [D loss: 0.545287] [G loss: 0.329718]\n",
      "[Epoch 65/100] [Batch 176/347] [D loss: 0.576573] [G loss: 0.332075]\n",
      "[Epoch 65/100] [Batch 177/347] [D loss: 0.576747] [G loss: 0.331250]\n",
      "[Epoch 65/100] [Batch 178/347] [D loss: 0.567886] [G loss: 0.329465]\n",
      "[Epoch 65/100] [Batch 179/347] [D loss: 0.562770] [G loss: 0.331363]\n",
      "[Epoch 65/100] [Batch 180/347] [D loss: 0.556643] [G loss: 0.334903]\n",
      "[Epoch 65/100] [Batch 181/347] [D loss: 0.558579] [G loss: 0.345512]\n",
      "[Epoch 65/100] [Batch 182/347] [D loss: 0.564170] [G loss: 0.355308]\n",
      "[Epoch 65/100] [Batch 183/347] [D loss: 0.567848] [G loss: 0.367157]\n",
      "[Epoch 65/100] [Batch 184/347] [D loss: 0.584630] [G loss: 0.382443]\n",
      "[Epoch 65/100] [Batch 185/347] [D loss: 0.581155] [G loss: 0.394987]\n",
      "[Epoch 65/100] [Batch 186/347] [D loss: 0.572020] [G loss: 0.410122]\n",
      "[Epoch 65/100] [Batch 187/347] [D loss: 0.562351] [G loss: 0.423395]\n",
      "[Epoch 65/100] [Batch 188/347] [D loss: 0.541106] [G loss: 0.429862]\n",
      "[Epoch 65/100] [Batch 189/347] [D loss: 0.519587] [G loss: 0.433660]\n",
      "[Epoch 65/100] [Batch 190/347] [D loss: 0.518171] [G loss: 0.437617]\n",
      "[Epoch 65/100] [Batch 191/347] [D loss: 0.521061] [G loss: 0.438767]\n",
      "[Epoch 65/100] [Batch 192/347] [D loss: 0.525044] [G loss: 0.440866]\n",
      "[Epoch 65/100] [Batch 193/347] [D loss: 0.543635] [G loss: 0.443552]\n",
      "[Epoch 65/100] [Batch 194/347] [D loss: 0.541804] [G loss: 0.442550]\n",
      "[Epoch 65/100] [Batch 195/347] [D loss: 0.533895] [G loss: 0.441175]\n",
      "[Epoch 65/100] [Batch 196/347] [D loss: 0.515713] [G loss: 0.438216]\n",
      "[Epoch 65/100] [Batch 197/347] [D loss: 0.513224] [G loss: 0.434906]\n",
      "[Epoch 65/100] [Batch 198/347] [D loss: 0.511273] [G loss: 0.433212]\n",
      "[Epoch 65/100] [Batch 199/347] [D loss: 0.509479] [G loss: 0.427246]\n",
      "[Epoch 65/100] [Batch 200/347] [D loss: 0.531520] [G loss: 0.421349]\n",
      "[Epoch 65/100] [Batch 201/347] [D loss: 0.542665] [G loss: 0.415661]\n",
      "[Epoch 65/100] [Batch 202/347] [D loss: 0.545503] [G loss: 0.411097]\n",
      "[Epoch 65/100] [Batch 203/347] [D loss: 0.553335] [G loss: 0.409206]\n",
      "[Epoch 65/100] [Batch 204/347] [D loss: 0.552226] [G loss: 0.413144]\n",
      "[Epoch 65/100] [Batch 205/347] [D loss: 0.552759] [G loss: 0.420597]\n",
      "[Epoch 65/100] [Batch 206/347] [D loss: 0.552632] [G loss: 0.428103]\n",
      "[Epoch 65/100] [Batch 207/347] [D loss: 0.534230] [G loss: 0.434655]\n",
      "[Epoch 65/100] [Batch 208/347] [D loss: 0.529839] [G loss: 0.441360]\n",
      "[Epoch 65/100] [Batch 209/347] [D loss: 0.519435] [G loss: 0.439071]\n",
      "[Epoch 65/100] [Batch 210/347] [D loss: 0.459747] [G loss: 0.437605]\n",
      "[Epoch 65/100] [Batch 211/347] [D loss: 0.396953] [G loss: 0.429086]\n",
      "[Epoch 65/100] [Batch 212/347] [D loss: 0.228107] [G loss: 0.412845]\n",
      "[Epoch 65/100] [Batch 213/347] [D loss: 0.229140] [G loss: 0.415566]\n",
      "[Epoch 65/100] [Batch 214/347] [D loss: 0.228931] [G loss: 0.417436]\n",
      "[Epoch 65/100] [Batch 215/347] [D loss: 0.229590] [G loss: 0.421684]\n",
      "[Epoch 65/100] [Batch 216/347] [D loss: 0.428916] [G loss: 0.436041]\n",
      "[Epoch 65/100] [Batch 217/347] [D loss: 0.485672] [G loss: 0.449129]\n",
      "[Epoch 65/100] [Batch 218/347] [D loss: 0.517906] [G loss: 0.462100]\n",
      "[Epoch 65/100] [Batch 219/347] [D loss: 0.513874] [G loss: 0.467300]\n",
      "[Epoch 65/100] [Batch 220/347] [D loss: 0.503680] [G loss: 0.469335]\n",
      "[Epoch 65/100] [Batch 221/347] [D loss: 0.521225] [G loss: 0.467204]\n",
      "[Epoch 65/100] [Batch 222/347] [D loss: 0.522547] [G loss: 0.456964]\n",
      "[Epoch 65/100] [Batch 223/347] [D loss: 0.504121] [G loss: 0.436148]\n",
      "[Epoch 65/100] [Batch 224/347] [D loss: 0.507890] [G loss: 0.411550]\n",
      "[Epoch 65/100] [Batch 225/347] [D loss: 0.514439] [G loss: 0.390992]\n",
      "[Epoch 65/100] [Batch 226/347] [D loss: 0.516316] [G loss: 0.377548]\n",
      "[Epoch 65/100] [Batch 227/347] [D loss: 0.531960] [G loss: 0.376848]\n",
      "[Epoch 65/100] [Batch 228/347] [D loss: 0.539123] [G loss: 0.380404]\n",
      "[Epoch 65/100] [Batch 229/347] [D loss: 0.542046] [G loss: 0.386520]\n",
      "[Epoch 65/100] [Batch 230/347] [D loss: 0.546868] [G loss: 0.394362]\n",
      "[Epoch 65/100] [Batch 231/347] [D loss: 0.535334] [G loss: 0.394900]\n",
      "[Epoch 65/100] [Batch 232/347] [D loss: 0.525973] [G loss: 0.400269]\n",
      "[Epoch 65/100] [Batch 233/347] [D loss: 0.480349] [G loss: 0.408112]\n",
      "[Epoch 65/100] [Batch 234/347] [D loss: 0.456870] [G loss: 0.412980]\n",
      "[Epoch 65/100] [Batch 235/347] [D loss: 0.458617] [G loss: 0.422476]\n",
      "[Epoch 65/100] [Batch 236/347] [D loss: 0.450080] [G loss: 0.428506]\n",
      "[Epoch 65/100] [Batch 237/347] [D loss: 0.495747] [G loss: 0.431491]\n",
      "[Epoch 65/100] [Batch 238/347] [D loss: 0.546933] [G loss: 0.430055]\n",
      "[Epoch 65/100] [Batch 239/347] [D loss: 0.545834] [G loss: 0.428223]\n",
      "[Epoch 65/100] [Batch 240/347] [D loss: 0.545096] [G loss: 0.430903]\n",
      "[Epoch 65/100] [Batch 241/347] [D loss: 0.544675] [G loss: 0.436516]\n",
      "[Epoch 65/100] [Batch 242/347] [D loss: 0.548523] [G loss: 0.445922]\n",
      "[Epoch 65/100] [Batch 243/347] [D loss: 0.524608] [G loss: 0.453829]\n",
      "[Epoch 65/100] [Batch 244/347] [D loss: 0.510750] [G loss: 0.449924]\n",
      "[Epoch 65/100] [Batch 245/347] [D loss: 0.512358] [G loss: 0.441846]\n",
      "[Epoch 65/100] [Batch 246/347] [D loss: 0.512353] [G loss: 0.430457]\n",
      "[Epoch 65/100] [Batch 247/347] [D loss: 0.519981] [G loss: 0.422091]\n",
      "[Epoch 65/100] [Batch 248/347] [D loss: 0.525225] [G loss: 0.424979]\n",
      "[Epoch 65/100] [Batch 249/347] [D loss: 0.519931] [G loss: 0.430428]\n",
      "[Epoch 65/100] [Batch 250/347] [D loss: 0.519078] [G loss: 0.438810]\n",
      "[Epoch 65/100] [Batch 251/347] [D loss: 0.516854] [G loss: 0.450748]\n",
      "[Epoch 65/100] [Batch 252/347] [D loss: 0.514505] [G loss: 0.456023]\n",
      "[Epoch 65/100] [Batch 253/347] [D loss: 0.482270] [G loss: 0.447145]\n",
      "[Epoch 65/100] [Batch 254/347] [D loss: 0.473689] [G loss: 0.446853]\n",
      "[Epoch 65/100] [Batch 255/347] [D loss: 0.469700] [G loss: 0.440520]\n",
      "[Epoch 65/100] [Batch 256/347] [D loss: 0.464883] [G loss: 0.423205]\n",
      "[Epoch 65/100] [Batch 257/347] [D loss: 0.460992] [G loss: 0.402878]\n",
      "[Epoch 65/100] [Batch 258/347] [D loss: 0.427428] [G loss: 0.383068]\n",
      "[Epoch 65/100] [Batch 259/347] [D loss: 0.426195] [G loss: 0.361017]\n",
      "[Epoch 65/100] [Batch 260/347] [D loss: 0.425659] [G loss: 0.341862]\n",
      "[Epoch 65/100] [Batch 261/347] [D loss: 0.412960] [G loss: 0.332661]\n",
      "[Epoch 65/100] [Batch 262/347] [D loss: 0.374530] [G loss: 0.328403]\n",
      "[Epoch 65/100] [Batch 263/347] [D loss: 0.370714] [G loss: 0.331085]\n",
      "[Epoch 65/100] [Batch 264/347] [D loss: 0.372161] [G loss: 0.342402]\n",
      "[Epoch 65/100] [Batch 265/347] [D loss: 0.372256] [G loss: 0.355663]\n",
      "[Epoch 65/100] [Batch 266/347] [D loss: 0.427071] [G loss: 0.371064]\n",
      "[Epoch 65/100] [Batch 267/347] [D loss: 0.443959] [G loss: 0.382725]\n",
      "[Epoch 65/100] [Batch 268/347] [D loss: 0.453375] [G loss: 0.390546]\n",
      "[Epoch 65/100] [Batch 269/347] [D loss: 0.456989] [G loss: 0.395020]\n",
      "[Epoch 65/100] [Batch 270/347] [D loss: 0.479203] [G loss: 0.398013]\n",
      "[Epoch 65/100] [Batch 271/347] [D loss: 0.445866] [G loss: 0.404828]\n",
      "[Epoch 65/100] [Batch 272/347] [D loss: 0.353743] [G loss: 0.427852]\n",
      "[Epoch 65/100] [Batch 273/347] [D loss: 0.317952] [G loss: 0.446120]\n",
      "[Epoch 65/100] [Batch 274/347] [D loss: 0.265331] [G loss: 0.459263]\n",
      "[Epoch 65/100] [Batch 275/347] [D loss: 0.230632] [G loss: 0.469974]\n",
      "[Epoch 65/100] [Batch 276/347] [D loss: 0.498739] [G loss: 0.473658]\n",
      "[Epoch 65/100] [Batch 277/347] [D loss: 0.519859] [G loss: 0.484923]\n",
      "[Epoch 65/100] [Batch 278/347] [D loss: 0.524885] [G loss: 0.495122]\n",
      "[Epoch 65/100] [Batch 279/347] [D loss: 0.527172] [G loss: 0.497293]\n",
      "[Epoch 65/100] [Batch 280/347] [D loss: 0.530167] [G loss: 0.497914]\n",
      "[Epoch 65/100] [Batch 281/347] [D loss: 0.533408] [G loss: 0.498375]\n",
      "[Epoch 65/100] [Batch 282/347] [D loss: 0.535039] [G loss: 0.501685]\n",
      "[Epoch 65/100] [Batch 283/347] [D loss: 0.536287] [G loss: 0.503131]\n",
      "[Epoch 65/100] [Batch 284/347] [D loss: 0.537464] [G loss: 0.505378]\n",
      "[Epoch 65/100] [Batch 285/347] [D loss: 0.540330] [G loss: 0.506311]\n",
      "[Epoch 65/100] [Batch 286/347] [D loss: 0.537973] [G loss: 0.492308]\n",
      "[Epoch 65/100] [Batch 287/347] [D loss: 0.538426] [G loss: 0.489645]\n",
      "[Epoch 65/100] [Batch 288/347] [D loss: 0.538670] [G loss: 0.486959]\n",
      "[Epoch 65/100] [Batch 289/347] [D loss: 0.537390] [G loss: 0.481945]\n",
      "[Epoch 65/100] [Batch 290/347] [D loss: 0.538459] [G loss: 0.497365]\n",
      "[Epoch 65/100] [Batch 291/347] [D loss: 0.537156] [G loss: 0.504162]\n",
      "[Epoch 65/100] [Batch 292/347] [D loss: 0.534849] [G loss: 0.507943]\n",
      "[Epoch 65/100] [Batch 293/347] [D loss: 0.512066] [G loss: 0.513266]\n",
      "[Epoch 65/100] [Batch 294/347] [D loss: 0.511305] [G loss: 0.517774]\n",
      "[Epoch 65/100] [Batch 295/347] [D loss: 0.510508] [G loss: 0.516656]\n",
      "[Epoch 65/100] [Batch 296/347] [D loss: 0.509266] [G loss: 0.515081]\n",
      "[Epoch 65/100] [Batch 297/347] [D loss: 0.534243] [G loss: 0.519481]\n",
      "[Epoch 65/100] [Batch 298/347] [D loss: 0.537871] [G loss: 0.512757]\n",
      "[Epoch 65/100] [Batch 299/347] [D loss: 0.535874] [G loss: 0.507841]\n",
      "[Epoch 65/100] [Batch 300/347] [D loss: 0.533887] [G loss: 0.505232]\n",
      "[Epoch 65/100] [Batch 301/347] [D loss: 0.533383] [G loss: 0.492585]\n",
      "[Epoch 65/100] [Batch 302/347] [D loss: 0.533441] [G loss: 0.483132]\n",
      "[Epoch 65/100] [Batch 303/347] [D loss: 0.532282] [G loss: 0.468659]\n",
      "[Epoch 65/100] [Batch 304/347] [D loss: 0.512822] [G loss: 0.456187]\n",
      "[Epoch 65/100] [Batch 305/347] [D loss: 0.496819] [G loss: 0.451308]\n",
      "[Epoch 65/100] [Batch 306/347] [D loss: 0.495160] [G loss: 0.451756]\n",
      "[Epoch 65/100] [Batch 307/347] [D loss: 0.492305] [G loss: 0.456434]\n",
      "[Epoch 65/100] [Batch 308/347] [D loss: 0.501619] [G loss: 0.456738]\n",
      "[Epoch 65/100] [Batch 309/347] [D loss: 0.526816] [G loss: 0.470042]\n",
      "[Epoch 65/100] [Batch 310/347] [D loss: 0.537472] [G loss: 0.481204]\n",
      "[Epoch 65/100] [Batch 311/347] [D loss: 0.533451] [G loss: 0.477681]\n",
      "[Epoch 65/100] [Batch 312/347] [D loss: 0.525851] [G loss: 0.471496]\n",
      "[Epoch 65/100] [Batch 313/347] [D loss: 0.519395] [G loss: 0.461156]\n",
      "[Epoch 65/100] [Batch 314/347] [D loss: 0.517570] [G loss: 0.445349]\n",
      "[Epoch 65/100] [Batch 315/347] [D loss: 0.516931] [G loss: 0.432878]\n",
      "[Epoch 65/100] [Batch 316/347] [D loss: 0.517647] [G loss: 0.432584]\n",
      "[Epoch 65/100] [Batch 317/347] [D loss: 0.519626] [G loss: 0.434810]\n",
      "[Epoch 65/100] [Batch 318/347] [D loss: 0.519881] [G loss: 0.446707]\n",
      "[Epoch 65/100] [Batch 319/347] [D loss: 0.518028] [G loss: 0.457268]\n",
      "[Epoch 65/100] [Batch 320/347] [D loss: 0.516334] [G loss: 0.454337]\n",
      "[Epoch 65/100] [Batch 321/347] [D loss: 0.512226] [G loss: 0.446088]\n",
      "[Epoch 65/100] [Batch 322/347] [D loss: 0.511793] [G loss: 0.437382]\n",
      "[Epoch 65/100] [Batch 323/347] [D loss: 0.501303] [G loss: 0.427198]\n",
      "[Epoch 65/100] [Batch 324/347] [D loss: 0.497999] [G loss: 0.419460]\n",
      "[Epoch 65/100] [Batch 325/347] [D loss: 0.496906] [G loss: 0.412418]\n",
      "[Epoch 65/100] [Batch 326/347] [D loss: 0.496033] [G loss: 0.405472]\n",
      "[Epoch 65/100] [Batch 327/347] [D loss: 0.490377] [G loss: 0.399127]\n",
      "[Epoch 65/100] [Batch 328/347] [D loss: 0.489823] [G loss: 0.391756]\n",
      "[Epoch 65/100] [Batch 329/347] [D loss: 0.487970] [G loss: 0.387524]\n",
      "[Epoch 65/100] [Batch 330/347] [D loss: 0.485549] [G loss: 0.384686]\n",
      "[Epoch 65/100] [Batch 331/347] [D loss: 0.490326] [G loss: 0.384118]\n",
      "[Epoch 65/100] [Batch 332/347] [D loss: 0.504533] [G loss: 0.398470]\n",
      "[Epoch 65/100] [Batch 333/347] [D loss: 0.498501] [G loss: 0.393759]\n",
      "[Epoch 65/100] [Batch 334/347] [D loss: 0.495227] [G loss: 0.383938]\n",
      "[Epoch 65/100] [Batch 335/347] [D loss: 0.493575] [G loss: 0.379016]\n",
      "[Epoch 65/100] [Batch 336/347] [D loss: 0.492935] [G loss: 0.374733]\n",
      "[Epoch 65/100] [Batch 337/347] [D loss: 0.499182] [G loss: 0.375696]\n",
      "[Epoch 65/100] [Batch 338/347] [D loss: 0.507379] [G loss: 0.380565]\n",
      "[Epoch 65/100] [Batch 339/347] [D loss: 0.500580] [G loss: 0.377747]\n",
      "[Epoch 65/100] [Batch 340/347] [D loss: 0.494470] [G loss: 0.371031]\n",
      "[Epoch 65/100] [Batch 341/347] [D loss: 0.493261] [G loss: 0.368284]\n",
      "[Epoch 65/100] [Batch 342/347] [D loss: 0.440575] [G loss: 0.352235]\n",
      "[Epoch 65/100] [Batch 343/347] [D loss: 0.422777] [G loss: 0.332614]\n",
      "[Epoch 65/100] [Batch 344/347] [D loss: 0.367420] [G loss: 0.325466]\n",
      "[Epoch 65/100] [Batch 345/347] [D loss: 0.265924] [G loss: 0.318383]\n",
      "[Epoch 65/100] [Batch 346/347] [D loss: 0.262694] [G loss: 0.313880]\n",
      "[Epoch 65/100] [Batch 347/347] [D loss: 0.262269] [G loss: 0.311013]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 66/100] [Batch 1/347] [D loss: 0.473689] [G loss: 0.317365]\n",
      "[Epoch 66/100] [Batch 2/347] [D loss: 0.480316] [G loss: 0.313075]\n",
      "[Epoch 66/100] [Batch 3/347] [D loss: 0.500187] [G loss: 0.312723]\n",
      "[Epoch 66/100] [Batch 4/347] [D loss: 0.503054] [G loss: 0.308313]\n",
      "[Epoch 66/100] [Batch 5/347] [D loss: 0.502880] [G loss: 0.301032]\n",
      "[Epoch 66/100] [Batch 6/347] [D loss: 0.488677] [G loss: 0.294581]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 66/100] [Batch 7/347] [D loss: 0.465963] [G loss: 0.282549]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 66/100] [Batch 8/347] [D loss: 0.465007] [G loss: 0.277819]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 66/100] [Batch 9/347] [D loss: 0.464291] [G loss: 0.275587]\n",
      "[Epoch 66/100] [Batch 10/347] [D loss: 0.470066] [G loss: 0.274515]\n",
      "[Epoch 66/100] [Batch 11/347] [D loss: 0.502261] [G loss: 0.284501]\n",
      "[Epoch 66/100] [Batch 12/347] [D loss: 0.509215] [G loss: 0.289544]\n",
      "[Epoch 66/100] [Batch 13/347] [D loss: 0.492885] [G loss: 0.292590]\n",
      "[Epoch 66/100] [Batch 14/347] [D loss: 0.479129] [G loss: 0.296748]\n",
      "[Epoch 66/100] [Batch 15/347] [D loss: 0.469400] [G loss: 0.291717]\n",
      "[Epoch 66/100] [Batch 16/347] [D loss: 0.462852] [G loss: 0.289368]\n",
      "[Epoch 66/100] [Batch 17/347] [D loss: 0.464731] [G loss: 0.294027]\n",
      "[Epoch 66/100] [Batch 18/347] [D loss: 0.470150] [G loss: 0.296663]\n",
      "[Epoch 66/100] [Batch 19/347] [D loss: 0.476003] [G loss: 0.302921]\n",
      "[Epoch 66/100] [Batch 20/347] [D loss: 0.489427] [G loss: 0.308803]\n",
      "[Epoch 66/100] [Batch 21/347] [D loss: 0.457657] [G loss: 0.304153]\n",
      "[Epoch 66/100] [Batch 22/347] [D loss: 0.456861] [G loss: 0.301628]\n",
      "[Epoch 66/100] [Batch 23/347] [D loss: 0.456409] [G loss: 0.296713]\n",
      "[Epoch 66/100] [Batch 24/347] [D loss: 0.413953] [G loss: 0.290341]\n",
      "[Epoch 66/100] [Batch 25/347] [D loss: 0.326256] [G loss: 0.297270]\n",
      "[Epoch 66/100] [Batch 26/347] [D loss: 0.327330] [G loss: 0.298773]\n",
      "[Epoch 66/100] [Batch 27/347] [D loss: 0.323593] [G loss: 0.305681]\n",
      "[Epoch 66/100] [Batch 28/347] [D loss: 0.324455] [G loss: 0.315829]\n",
      "[Epoch 66/100] [Batch 29/347] [D loss: 0.350920] [G loss: 0.319543]\n",
      "[Epoch 66/100] [Batch 30/347] [D loss: 0.337866] [G loss: 0.324254]\n",
      "[Epoch 66/100] [Batch 31/347] [D loss: 0.335054] [G loss: 0.326518]\n",
      "[Epoch 66/100] [Batch 32/347] [D loss: 0.345730] [G loss: 0.324782]\n",
      "[Epoch 66/100] [Batch 33/347] [D loss: 0.360515] [G loss: 0.323724]\n",
      "[Epoch 66/100] [Batch 34/347] [D loss: 0.396203] [G loss: 0.318022]\n",
      "[Epoch 66/100] [Batch 35/347] [D loss: 0.391620] [G loss: 0.311976]\n",
      "[Epoch 66/100] [Batch 36/347] [D loss: 0.404493] [G loss: 0.301571]\n",
      "[Epoch 66/100] [Batch 37/347] [D loss: 0.410785] [G loss: 0.289766]\n",
      "[Epoch 66/100] [Batch 38/347] [D loss: 0.415480] [G loss: 0.276705]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 66/100] [Batch 39/347] [D loss: 0.429432] [G loss: 0.270436]\n",
      "[Epoch 66/100] [Batch 40/347] [D loss: 0.458432] [G loss: 0.274541]\n",
      "[Epoch 66/100] [Batch 41/347] [D loss: 0.470685] [G loss: 0.279214]\n",
      "[Epoch 66/100] [Batch 42/347] [D loss: 0.470114] [G loss: 0.292769]\n",
      "[Epoch 66/100] [Batch 43/347] [D loss: 0.491027] [G loss: 0.311005]\n",
      "[Epoch 66/100] [Batch 44/347] [D loss: 0.483729] [G loss: 0.323741]\n",
      "[Epoch 66/100] [Batch 45/347] [D loss: 0.460218] [G loss: 0.322487]\n",
      "[Epoch 66/100] [Batch 46/347] [D loss: 0.389078] [G loss: 0.323936]\n",
      "[Epoch 66/100] [Batch 47/347] [D loss: 0.375947] [G loss: 0.321890]\n",
      "[Epoch 66/100] [Batch 48/347] [D loss: 0.263836] [G loss: 0.332172]\n",
      "[Epoch 66/100] [Batch 49/347] [D loss: 0.254154] [G loss: 0.350028]\n",
      "[Epoch 66/100] [Batch 50/347] [D loss: 0.243026] [G loss: 0.367783]\n",
      "[Epoch 66/100] [Batch 51/347] [D loss: 0.243140] [G loss: 0.377678]\n",
      "[Epoch 66/100] [Batch 52/347] [D loss: 0.353051] [G loss: 0.376032]\n",
      "[Epoch 66/100] [Batch 53/347] [D loss: 0.393262] [G loss: 0.364034]\n",
      "[Epoch 66/100] [Batch 54/347] [D loss: 0.374365] [G loss: 0.350084]\n",
      "[Epoch 66/100] [Batch 55/347] [D loss: 0.361973] [G loss: 0.345895]\n",
      "[Epoch 66/100] [Batch 56/347] [D loss: 0.344296] [G loss: 0.341000]\n",
      "[Epoch 66/100] [Batch 57/347] [D loss: 0.306064] [G loss: 0.331978]\n",
      "[Epoch 66/100] [Batch 58/347] [D loss: 0.316564] [G loss: 0.319860]\n",
      "[Epoch 66/100] [Batch 59/347] [D loss: 0.318683] [G loss: 0.306902]\n",
      "[Epoch 66/100] [Batch 60/347] [D loss: 0.314097] [G loss: 0.294830]\n",
      "[Epoch 66/100] [Batch 61/347] [D loss: 0.326580] [G loss: 0.288013]\n",
      "[Epoch 66/100] [Batch 62/347] [D loss: 0.324949] [G loss: 0.300859]\n",
      "[Epoch 66/100] [Batch 63/347] [D loss: 0.320690] [G loss: 0.320492]\n",
      "[Epoch 66/100] [Batch 64/347] [D loss: 0.300990] [G loss: 0.339435]\n",
      "[Epoch 66/100] [Batch 65/347] [D loss: 0.239566] [G loss: 0.363020]\n",
      "[Epoch 66/100] [Batch 66/347] [D loss: 0.232501] [G loss: 0.375626]\n",
      "[Epoch 66/100] [Batch 67/347] [D loss: 0.232439] [G loss: 0.371910]\n",
      "[Epoch 66/100] [Batch 68/347] [D loss: 0.242757] [G loss: 0.370243]\n",
      "[Epoch 66/100] [Batch 69/347] [D loss: 0.277165] [G loss: 0.366485]\n",
      "[Epoch 66/100] [Batch 70/347] [D loss: 0.283441] [G loss: 0.363973]\n",
      "[Epoch 66/100] [Batch 71/347] [D loss: 0.277410] [G loss: 0.367932]\n",
      "[Epoch 66/100] [Batch 72/347] [D loss: 0.285079] [G loss: 0.371700]\n",
      "[Epoch 66/100] [Batch 73/347] [D loss: 0.374340] [G loss: 0.355766]\n",
      "[Epoch 66/100] [Batch 74/347] [D loss: 0.360838] [G loss: 0.338535]\n",
      "[Epoch 66/100] [Batch 75/347] [D loss: 0.351067] [G loss: 0.317155]\n",
      "[Epoch 66/100] [Batch 76/347] [D loss: 0.350853] [G loss: 0.295155]\n",
      "[Epoch 66/100] [Batch 77/347] [D loss: 0.395822] [G loss: 0.278446]\n",
      "[Epoch 66/100] [Batch 78/347] [D loss: 0.456605] [G loss: 0.280334]\n",
      "[Epoch 66/100] [Batch 79/347] [D loss: 0.468013] [G loss: 0.278543]\n",
      "[Epoch 66/100] [Batch 80/347] [D loss: 0.398800] [G loss: 0.271982]\n",
      "[Epoch 66/100] [Batch 81/347] [D loss: 0.383081] [G loss: 0.284885]\n",
      "[Epoch 66/100] [Batch 82/347] [D loss: 0.377094] [G loss: 0.304775]\n",
      "[Epoch 66/100] [Batch 83/347] [D loss: 0.368231] [G loss: 0.326244]\n",
      "[Epoch 66/100] [Batch 84/347] [D loss: 0.472492] [G loss: 0.352976]\n",
      "[Epoch 66/100] [Batch 85/347] [D loss: 0.531144] [G loss: 0.373185]\n",
      "[Epoch 66/100] [Batch 86/347] [D loss: 0.529887] [G loss: 0.391108]\n",
      "[Epoch 66/100] [Batch 87/347] [D loss: 0.528597] [G loss: 0.406785]\n",
      "[Epoch 66/100] [Batch 88/347] [D loss: 0.533373] [G loss: 0.419819]\n",
      "[Epoch 66/100] [Batch 89/347] [D loss: 0.535042] [G loss: 0.431373]\n",
      "[Epoch 66/100] [Batch 90/347] [D loss: 0.533155] [G loss: 0.438192]\n",
      "[Epoch 66/100] [Batch 91/347] [D loss: 0.532349] [G loss: 0.442393]\n",
      "[Epoch 66/100] [Batch 92/347] [D loss: 0.532430] [G loss: 0.447088]\n",
      "[Epoch 66/100] [Batch 93/347] [D loss: 0.532006] [G loss: 0.450311]\n",
      "[Epoch 66/100] [Batch 94/347] [D loss: 0.529506] [G loss: 0.448777]\n",
      "[Epoch 66/100] [Batch 95/347] [D loss: 0.528248] [G loss: 0.449536]\n",
      "[Epoch 66/100] [Batch 96/347] [D loss: 0.529129] [G loss: 0.452095]\n",
      "[Epoch 66/100] [Batch 97/347] [D loss: 0.528102] [G loss: 0.452339]\n",
      "[Epoch 66/100] [Batch 98/347] [D loss: 0.527966] [G loss: 0.454133]\n",
      "[Epoch 66/100] [Batch 99/347] [D loss: 0.529465] [G loss: 0.454574]\n",
      "[Epoch 66/100] [Batch 100/347] [D loss: 0.529774] [G loss: 0.453867]\n",
      "[Epoch 66/100] [Batch 101/347] [D loss: 0.529520] [G loss: 0.451260]\n",
      "[Epoch 66/100] [Batch 102/347] [D loss: 0.532908] [G loss: 0.447666]\n",
      "[Epoch 66/100] [Batch 103/347] [D loss: 0.532699] [G loss: 0.447759]\n",
      "[Epoch 66/100] [Batch 104/347] [D loss: 0.529491] [G loss: 0.441536]\n",
      "[Epoch 66/100] [Batch 105/347] [D loss: 0.453665] [G loss: 0.433438]\n",
      "[Epoch 66/100] [Batch 106/347] [D loss: 0.219019] [G loss: 0.422189]\n",
      "[Epoch 66/100] [Batch 107/347] [D loss: 0.220159] [G loss: 0.419975]\n",
      "[Epoch 66/100] [Batch 108/347] [D loss: 0.209764] [G loss: 0.418135]\n",
      "[Epoch 66/100] [Batch 109/347] [D loss: 0.201398] [G loss: 0.417987]\n",
      "[Epoch 66/100] [Batch 110/347] [D loss: 0.239367] [G loss: 0.410568]\n",
      "[Epoch 66/100] [Batch 111/347] [D loss: 0.225386] [G loss: 0.407852]\n",
      "[Epoch 66/100] [Batch 112/347] [D loss: 0.221673] [G loss: 0.400923]\n",
      "[Epoch 66/100] [Batch 113/347] [D loss: 0.400111] [G loss: 0.404422]\n",
      "[Epoch 66/100] [Batch 114/347] [D loss: 0.473573] [G loss: 0.391939]\n",
      "[Epoch 66/100] [Batch 115/347] [D loss: 0.450682] [G loss: 0.352148]\n",
      "[Epoch 66/100] [Batch 116/347] [D loss: 0.385843] [G loss: 0.314665]\n",
      "[Epoch 66/100] [Batch 117/347] [D loss: 0.383518] [G loss: 0.289640]\n",
      "[Epoch 66/100] [Batch 118/347] [D loss: 0.347145] [G loss: 0.273813]\n",
      "[Epoch 66/100] [Batch 119/347] [D loss: 0.350954] [G loss: 0.276726]\n",
      "[Epoch 66/100] [Batch 120/347] [D loss: 0.347390] [G loss: 0.296513]\n",
      "[Epoch 66/100] [Batch 121/347] [D loss: 0.342398] [G loss: 0.316038]\n",
      "[Epoch 66/100] [Batch 122/347] [D loss: 0.435866] [G loss: 0.339610]\n",
      "[Epoch 66/100] [Batch 123/347] [D loss: 0.481391] [G loss: 0.361007]\n",
      "[Epoch 66/100] [Batch 124/347] [D loss: 0.416394] [G loss: 0.375276]\n",
      "[Epoch 66/100] [Batch 125/347] [D loss: 0.388434] [G loss: 0.389466]\n",
      "[Epoch 66/100] [Batch 126/347] [D loss: 0.352974] [G loss: 0.397707]\n",
      "[Epoch 66/100] [Batch 127/347] [D loss: 0.353082] [G loss: 0.396382]\n",
      "[Epoch 66/100] [Batch 128/347] [D loss: 0.334165] [G loss: 0.385481]\n",
      "[Epoch 66/100] [Batch 129/347] [D loss: 0.269861] [G loss: 0.379062]\n",
      "[Epoch 66/100] [Batch 130/347] [D loss: 0.221972] [G loss: 0.392153]\n",
      "[Epoch 66/100] [Batch 131/347] [D loss: 0.214500] [G loss: 0.404332]\n",
      "[Epoch 66/100] [Batch 132/347] [D loss: 0.198803] [G loss: 0.420342]\n",
      "[Epoch 66/100] [Batch 133/347] [D loss: 0.200583] [G loss: 0.435983]\n",
      "[Epoch 66/100] [Batch 134/347] [D loss: 0.179456] [G loss: 0.449569]\n",
      "[Epoch 66/100] [Batch 135/347] [D loss: 0.169672] [G loss: 0.458967]\n",
      "[Epoch 66/100] [Batch 136/347] [D loss: 0.161938] [G loss: 0.460880]\n",
      "[Epoch 66/100] [Batch 137/347] [D loss: 0.419759] [G loss: 0.458812]\n",
      "[Epoch 66/100] [Batch 138/347] [D loss: 0.447604] [G loss: 0.453299]\n",
      "[Epoch 66/100] [Batch 139/347] [D loss: 0.460330] [G loss: 0.443494]\n",
      "[Epoch 66/100] [Batch 140/347] [D loss: 0.457266] [G loss: 0.441276]\n",
      "[Epoch 66/100] [Batch 141/347] [D loss: 0.421099] [G loss: 0.432867]\n",
      "[Epoch 66/100] [Batch 142/347] [D loss: 0.415443] [G loss: 0.428966]\n",
      "[Epoch 66/100] [Batch 143/347] [D loss: 0.390742] [G loss: 0.426582]\n",
      "[Epoch 66/100] [Batch 144/347] [D loss: 0.360180] [G loss: 0.409851]\n",
      "[Epoch 66/100] [Batch 145/347] [D loss: 0.369043] [G loss: 0.377179]\n",
      "[Epoch 66/100] [Batch 146/347] [D loss: 0.355119] [G loss: 0.341318]\n",
      "[Epoch 66/100] [Batch 147/347] [D loss: 0.371389] [G loss: 0.291993]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 66/100] [Batch 148/347] [D loss: 0.386939] [G loss: 0.248190]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 66/100] [Batch 149/347] [D loss: 0.373944] [G loss: 0.216421]\n",
      "[Epoch 66/100] [Batch 150/347] [D loss: 0.391614] [G loss: 0.200751]\n",
      "[Epoch 66/100] [Batch 151/347] [D loss: 0.403828] [G loss: 0.199983]\n",
      "[Epoch 66/100] [Batch 152/347] [D loss: 0.399197] [G loss: 0.209403]\n",
      "[Epoch 66/100] [Batch 153/347] [D loss: 0.383050] [G loss: 0.231307]\n",
      "[Epoch 66/100] [Batch 154/347] [D loss: 0.353166] [G loss: 0.267672]\n",
      "[Epoch 66/100] [Batch 155/347] [D loss: 0.321821] [G loss: 0.312902]\n",
      "[Epoch 66/100] [Batch 156/347] [D loss: 0.293307] [G loss: 0.349017]\n",
      "[Epoch 66/100] [Batch 157/347] [D loss: 0.279264] [G loss: 0.377156]\n",
      "[Epoch 66/100] [Batch 158/347] [D loss: 0.236901] [G loss: 0.398693]\n",
      "[Epoch 66/100] [Batch 159/347] [D loss: 0.252441] [G loss: 0.409119]\n",
      "[Epoch 66/100] [Batch 160/347] [D loss: 0.270497] [G loss: 0.421071]\n",
      "[Epoch 66/100] [Batch 161/347] [D loss: 0.255334] [G loss: 0.425852]\n",
      "[Epoch 66/100] [Batch 162/347] [D loss: 0.276775] [G loss: 0.419403]\n",
      "[Epoch 66/100] [Batch 163/347] [D loss: 0.285191] [G loss: 0.406545]\n",
      "[Epoch 66/100] [Batch 164/347] [D loss: 0.271311] [G loss: 0.399737]\n",
      "[Epoch 66/100] [Batch 165/347] [D loss: 0.260084] [G loss: 0.395962]\n",
      "[Epoch 66/100] [Batch 166/347] [D loss: 0.253736] [G loss: 0.386417]\n",
      "[Epoch 66/100] [Batch 167/347] [D loss: 0.276537] [G loss: 0.387514]\n",
      "[Epoch 66/100] [Batch 168/347] [D loss: 0.264920] [G loss: 0.377831]\n",
      "[Epoch 66/100] [Batch 169/347] [D loss: 0.406933] [G loss: 0.366760]\n",
      "[Epoch 66/100] [Batch 170/347] [D loss: 0.475207] [G loss: 0.352652]\n",
      "[Epoch 66/100] [Batch 171/347] [D loss: 0.486235] [G loss: 0.332570]\n",
      "[Epoch 66/100] [Batch 172/347] [D loss: 0.487903] [G loss: 0.316365]\n",
      "[Epoch 66/100] [Batch 173/347] [D loss: 0.492677] [G loss: 0.301018]\n",
      "[Epoch 66/100] [Batch 174/347] [D loss: 0.493980] [G loss: 0.295381]\n",
      "[Epoch 66/100] [Batch 175/347] [D loss: 0.543765] [G loss: 0.294564]\n",
      "[Epoch 66/100] [Batch 176/347] [D loss: 0.581761] [G loss: 0.296922]\n",
      "[Epoch 66/100] [Batch 177/347] [D loss: 0.582536] [G loss: 0.296804]\n",
      "[Epoch 66/100] [Batch 178/347] [D loss: 0.572135] [G loss: 0.297142]\n",
      "[Epoch 66/100] [Batch 179/347] [D loss: 0.565840] [G loss: 0.303298]\n",
      "[Epoch 66/100] [Batch 180/347] [D loss: 0.557301] [G loss: 0.311122]\n",
      "[Epoch 66/100] [Batch 181/347] [D loss: 0.557278] [G loss: 0.326423]\n",
      "[Epoch 66/100] [Batch 182/347] [D loss: 0.562449] [G loss: 0.339671]\n",
      "[Epoch 66/100] [Batch 183/347] [D loss: 0.565911] [G loss: 0.354712]\n",
      "[Epoch 66/100] [Batch 184/347] [D loss: 0.586647] [G loss: 0.371984]\n",
      "[Epoch 66/100] [Batch 185/347] [D loss: 0.583792] [G loss: 0.385451]\n",
      "[Epoch 66/100] [Batch 186/347] [D loss: 0.573184] [G loss: 0.400396]\n",
      "[Epoch 66/100] [Batch 187/347] [D loss: 0.563296] [G loss: 0.413294]\n",
      "[Epoch 66/100] [Batch 188/347] [D loss: 0.536954] [G loss: 0.418817]\n",
      "[Epoch 66/100] [Batch 189/347] [D loss: 0.509606] [G loss: 0.421890]\n",
      "[Epoch 66/100] [Batch 190/347] [D loss: 0.507580] [G loss: 0.425624]\n",
      "[Epoch 66/100] [Batch 191/347] [D loss: 0.511088] [G loss: 0.425880]\n",
      "[Epoch 66/100] [Batch 192/347] [D loss: 0.516827] [G loss: 0.426297]\n",
      "[Epoch 66/100] [Batch 193/347] [D loss: 0.545115] [G loss: 0.428207]\n",
      "[Epoch 66/100] [Batch 194/347] [D loss: 0.543531] [G loss: 0.426240]\n",
      "[Epoch 66/100] [Batch 195/347] [D loss: 0.533474] [G loss: 0.424948]\n",
      "[Epoch 66/100] [Batch 196/347] [D loss: 0.505841] [G loss: 0.420870]\n",
      "[Epoch 66/100] [Batch 197/347] [D loss: 0.504401] [G loss: 0.415905]\n",
      "[Epoch 66/100] [Batch 198/347] [D loss: 0.501042] [G loss: 0.412180]\n",
      "[Epoch 66/100] [Batch 199/347] [D loss: 0.499047] [G loss: 0.403895]\n",
      "[Epoch 66/100] [Batch 200/347] [D loss: 0.533753] [G loss: 0.395831]\n",
      "[Epoch 66/100] [Batch 201/347] [D loss: 0.549867] [G loss: 0.389016]\n",
      "[Epoch 66/100] [Batch 202/347] [D loss: 0.556380] [G loss: 0.384257]\n",
      "[Epoch 66/100] [Batch 203/347] [D loss: 0.569948] [G loss: 0.381865]\n",
      "[Epoch 66/100] [Batch 204/347] [D loss: 0.569026] [G loss: 0.386603]\n",
      "[Epoch 66/100] [Batch 205/347] [D loss: 0.570146] [G loss: 0.395657]\n",
      "[Epoch 66/100] [Batch 206/347] [D loss: 0.570626] [G loss: 0.404562]\n",
      "[Epoch 66/100] [Batch 207/347] [D loss: 0.540422] [G loss: 0.413676]\n",
      "[Epoch 66/100] [Batch 208/347] [D loss: 0.535336] [G loss: 0.422284]\n",
      "[Epoch 66/100] [Batch 209/347] [D loss: 0.521372] [G loss: 0.423291]\n",
      "[Epoch 66/100] [Batch 210/347] [D loss: 0.441309] [G loss: 0.424668]\n",
      "[Epoch 66/100] [Batch 211/347] [D loss: 0.383102] [G loss: 0.419181]\n",
      "[Epoch 66/100] [Batch 212/347] [D loss: 0.226393] [G loss: 0.409742]\n",
      "[Epoch 66/100] [Batch 213/347] [D loss: 0.225019] [G loss: 0.416408]\n",
      "[Epoch 66/100] [Batch 214/347] [D loss: 0.221096] [G loss: 0.426315]\n",
      "[Epoch 66/100] [Batch 215/347] [D loss: 0.220349] [G loss: 0.437340]\n",
      "[Epoch 66/100] [Batch 216/347] [D loss: 0.430695] [G loss: 0.462774]\n",
      "[Epoch 66/100] [Batch 217/347] [D loss: 0.491810] [G loss: 0.480580]\n",
      "[Epoch 66/100] [Batch 218/347] [D loss: 0.523700] [G loss: 0.498049]\n",
      "[Epoch 66/100] [Batch 219/347] [D loss: 0.524149] [G loss: 0.506550]\n",
      "[Epoch 66/100] [Batch 220/347] [D loss: 0.513820] [G loss: 0.511341]\n",
      "[Epoch 66/100] [Batch 221/347] [D loss: 0.530536] [G loss: 0.512189]\n",
      "[Epoch 66/100] [Batch 222/347] [D loss: 0.531996] [G loss: 0.504425]\n",
      "[Epoch 66/100] [Batch 223/347] [D loss: 0.519725] [G loss: 0.485582]\n",
      "[Epoch 66/100] [Batch 224/347] [D loss: 0.523514] [G loss: 0.463020]\n",
      "[Epoch 66/100] [Batch 225/347] [D loss: 0.528654] [G loss: 0.443666]\n",
      "[Epoch 66/100] [Batch 226/347] [D loss: 0.530232] [G loss: 0.431554]\n",
      "[Epoch 66/100] [Batch 227/347] [D loss: 0.541678] [G loss: 0.431298]\n",
      "[Epoch 66/100] [Batch 228/347] [D loss: 0.546110] [G loss: 0.434022]\n",
      "[Epoch 66/100] [Batch 229/347] [D loss: 0.547468] [G loss: 0.438243]\n",
      "[Epoch 66/100] [Batch 230/347] [D loss: 0.551001] [G loss: 0.442796]\n",
      "[Epoch 66/100] [Batch 231/347] [D loss: 0.542629] [G loss: 0.440353]\n",
      "[Epoch 66/100] [Batch 232/347] [D loss: 0.535943] [G loss: 0.441679]\n",
      "[Epoch 66/100] [Batch 233/347] [D loss: 0.491906] [G loss: 0.446517]\n",
      "[Epoch 66/100] [Batch 234/347] [D loss: 0.466950] [G loss: 0.447874]\n",
      "[Epoch 66/100] [Batch 235/347] [D loss: 0.466241] [G loss: 0.453755]\n",
      "[Epoch 66/100] [Batch 236/347] [D loss: 0.455148] [G loss: 0.455979]\n",
      "[Epoch 66/100] [Batch 237/347] [D loss: 0.498047] [G loss: 0.452860]\n",
      "[Epoch 66/100] [Batch 238/347] [D loss: 0.554013] [G loss: 0.446547]\n",
      "[Epoch 66/100] [Batch 239/347] [D loss: 0.554040] [G loss: 0.439848]\n",
      "[Epoch 66/100] [Batch 240/347] [D loss: 0.555850] [G loss: 0.438383]\n",
      "[Epoch 66/100] [Batch 241/347] [D loss: 0.555779] [G loss: 0.442898]\n",
      "[Epoch 66/100] [Batch 242/347] [D loss: 0.562147] [G loss: 0.452160]\n",
      "[Epoch 66/100] [Batch 243/347] [D loss: 0.530259] [G loss: 0.460510]\n",
      "[Epoch 66/100] [Batch 244/347] [D loss: 0.516343] [G loss: 0.457646]\n",
      "[Epoch 66/100] [Batch 245/347] [D loss: 0.513851] [G loss: 0.450947]\n",
      "[Epoch 66/100] [Batch 246/347] [D loss: 0.517151] [G loss: 0.441326]\n",
      "[Epoch 66/100] [Batch 247/347] [D loss: 0.525545] [G loss: 0.434578]\n",
      "[Epoch 66/100] [Batch 248/347] [D loss: 0.533721] [G loss: 0.439268]\n",
      "[Epoch 66/100] [Batch 249/347] [D loss: 0.526756] [G loss: 0.446818]\n",
      "[Epoch 66/100] [Batch 250/347] [D loss: 0.525687] [G loss: 0.457124]\n",
      "[Epoch 66/100] [Batch 251/347] [D loss: 0.522575] [G loss: 0.471363]\n",
      "[Epoch 66/100] [Batch 252/347] [D loss: 0.520121] [G loss: 0.478167]\n",
      "[Epoch 66/100] [Batch 253/347] [D loss: 0.488357] [G loss: 0.471124]\n",
      "[Epoch 66/100] [Batch 254/347] [D loss: 0.478196] [G loss: 0.473150]\n",
      "[Epoch 66/100] [Batch 255/347] [D loss: 0.478524] [G loss: 0.469046]\n",
      "[Epoch 66/100] [Batch 256/347] [D loss: 0.472481] [G loss: 0.454613]\n",
      "[Epoch 66/100] [Batch 257/347] [D loss: 0.469445] [G loss: 0.436639]\n",
      "[Epoch 66/100] [Batch 258/347] [D loss: 0.431111] [G loss: 0.413868]\n",
      "[Epoch 66/100] [Batch 259/347] [D loss: 0.425762] [G loss: 0.391077]\n",
      "[Epoch 66/100] [Batch 260/347] [D loss: 0.420664] [G loss: 0.368238]\n",
      "[Epoch 66/100] [Batch 261/347] [D loss: 0.405226] [G loss: 0.353045]\n",
      "[Epoch 66/100] [Batch 262/347] [D loss: 0.363575] [G loss: 0.341252]\n",
      "[Epoch 66/100] [Batch 263/347] [D loss: 0.362014] [G loss: 0.337519]\n",
      "[Epoch 66/100] [Batch 264/347] [D loss: 0.367706] [G loss: 0.343214]\n",
      "[Epoch 66/100] [Batch 265/347] [D loss: 0.370550] [G loss: 0.352333]\n",
      "[Epoch 66/100] [Batch 266/347] [D loss: 0.431050] [G loss: 0.364956]\n",
      "[Epoch 66/100] [Batch 267/347] [D loss: 0.445242] [G loss: 0.376045]\n",
      "[Epoch 66/100] [Batch 268/347] [D loss: 0.455897] [G loss: 0.383789]\n",
      "[Epoch 66/100] [Batch 269/347] [D loss: 0.457768] [G loss: 0.388747]\n",
      "[Epoch 66/100] [Batch 270/347] [D loss: 0.485312] [G loss: 0.393952]\n",
      "[Epoch 66/100] [Batch 271/347] [D loss: 0.454575] [G loss: 0.403180]\n",
      "[Epoch 66/100] [Batch 272/347] [D loss: 0.388875] [G loss: 0.431477]\n",
      "[Epoch 66/100] [Batch 273/347] [D loss: 0.343181] [G loss: 0.456298]\n",
      "[Epoch 66/100] [Batch 274/347] [D loss: 0.276717] [G loss: 0.473445]\n",
      "[Epoch 66/100] [Batch 275/347] [D loss: 0.232831] [G loss: 0.485384]\n",
      "[Epoch 66/100] [Batch 276/347] [D loss: 0.502410] [G loss: 0.496423]\n",
      "[Epoch 66/100] [Batch 277/347] [D loss: 0.524079] [G loss: 0.507606]\n",
      "[Epoch 66/100] [Batch 278/347] [D loss: 0.529130] [G loss: 0.517684]\n",
      "[Epoch 66/100] [Batch 279/347] [D loss: 0.531430] [G loss: 0.519744]\n",
      "[Epoch 66/100] [Batch 280/347] [D loss: 0.534500] [G loss: 0.520087]\n",
      "[Epoch 66/100] [Batch 281/347] [D loss: 0.537645] [G loss: 0.520416]\n",
      "[Epoch 66/100] [Batch 282/347] [D loss: 0.539138] [G loss: 0.523587]\n",
      "[Epoch 66/100] [Batch 283/347] [D loss: 0.540236] [G loss: 0.524876]\n",
      "[Epoch 66/100] [Batch 284/347] [D loss: 0.541207] [G loss: 0.527064]\n",
      "[Epoch 66/100] [Batch 285/347] [D loss: 0.543826] [G loss: 0.527865]\n",
      "[Epoch 66/100] [Batch 286/347] [D loss: 0.542267] [G loss: 0.513813]\n",
      "[Epoch 66/100] [Batch 287/347] [D loss: 0.542736] [G loss: 0.511000]\n",
      "[Epoch 66/100] [Batch 288/347] [D loss: 0.543063] [G loss: 0.508205]\n",
      "[Epoch 66/100] [Batch 289/347] [D loss: 0.542167] [G loss: 0.503193]\n",
      "[Epoch 66/100] [Batch 290/347] [D loss: 0.542871] [G loss: 0.518767]\n",
      "[Epoch 66/100] [Batch 291/347] [D loss: 0.542024] [G loss: 0.525676]\n",
      "[Epoch 66/100] [Batch 292/347] [D loss: 0.540425] [G loss: 0.529514]\n",
      "[Epoch 66/100] [Batch 293/347] [D loss: 0.522667] [G loss: 0.534967]\n",
      "[Epoch 66/100] [Batch 294/347] [D loss: 0.522234] [G loss: 0.539698]\n",
      "[Epoch 66/100] [Batch 295/347] [D loss: 0.521937] [G loss: 0.538892]\n",
      "[Epoch 66/100] [Batch 296/347] [D loss: 0.521359] [G loss: 0.537598]\n",
      "[Epoch 66/100] [Batch 297/347] [D loss: 0.539897] [G loss: 0.542390]\n",
      "[Epoch 66/100] [Batch 298/347] [D loss: 0.542860] [G loss: 0.536080]\n",
      "[Epoch 66/100] [Batch 299/347] [D loss: 0.541720] [G loss: 0.531629]\n",
      "[Epoch 66/100] [Batch 300/347] [D loss: 0.540567] [G loss: 0.529517]\n",
      "[Epoch 66/100] [Batch 301/347] [D loss: 0.540451] [G loss: 0.512669]\n",
      "[Epoch 66/100] [Batch 302/347] [D loss: 0.540562] [G loss: 0.505537]\n",
      "[Epoch 66/100] [Batch 303/347] [D loss: 0.539928] [G loss: 0.494458]\n",
      "[Epoch 66/100] [Batch 304/347] [D loss: 0.525361] [G loss: 0.482480]\n",
      "[Epoch 66/100] [Batch 305/347] [D loss: 0.513193] [G loss: 0.475188]\n",
      "[Epoch 66/100] [Batch 306/347] [D loss: 0.511965] [G loss: 0.474749]\n",
      "[Epoch 66/100] [Batch 307/347] [D loss: 0.509947] [G loss: 0.480698]\n",
      "[Epoch 66/100] [Batch 308/347] [D loss: 0.517168] [G loss: 0.486185]\n",
      "[Epoch 66/100] [Batch 309/347] [D loss: 0.536178] [G loss: 0.500290]\n",
      "[Epoch 66/100] [Batch 310/347] [D loss: 0.543591] [G loss: 0.512311]\n",
      "[Epoch 66/100] [Batch 311/347] [D loss: 0.540854] [G loss: 0.509519]\n",
      "[Epoch 66/100] [Batch 312/347] [D loss: 0.535412] [G loss: 0.503995]\n",
      "[Epoch 66/100] [Batch 313/347] [D loss: 0.530778] [G loss: 0.494460]\n",
      "[Epoch 66/100] [Batch 314/347] [D loss: 0.529597] [G loss: 0.479410]\n",
      "[Epoch 66/100] [Batch 315/347] [D loss: 0.529248] [G loss: 0.467697]\n",
      "[Epoch 66/100] [Batch 316/347] [D loss: 0.529763] [G loss: 0.468232]\n",
      "[Epoch 66/100] [Batch 317/347] [D loss: 0.531250] [G loss: 0.471332]\n",
      "[Epoch 66/100] [Batch 318/347] [D loss: 0.531408] [G loss: 0.484061]\n",
      "[Epoch 66/100] [Batch 319/347] [D loss: 0.529684] [G loss: 0.495466]\n",
      "[Epoch 66/100] [Batch 320/347] [D loss: 0.528317] [G loss: 0.493260]\n",
      "[Epoch 66/100] [Batch 321/347] [D loss: 0.525378] [G loss: 0.485867]\n",
      "[Epoch 66/100] [Batch 322/347] [D loss: 0.525163] [G loss: 0.477727]\n",
      "[Epoch 66/100] [Batch 323/347] [D loss: 0.517269] [G loss: 0.468346]\n",
      "[Epoch 66/100] [Batch 324/347] [D loss: 0.514982] [G loss: 0.461678]\n",
      "[Epoch 66/100] [Batch 325/347] [D loss: 0.514351] [G loss: 0.453948]\n",
      "[Epoch 66/100] [Batch 326/347] [D loss: 0.513630] [G loss: 0.448055]\n",
      "[Epoch 66/100] [Batch 327/347] [D loss: 0.509894] [G loss: 0.442748]\n",
      "[Epoch 66/100] [Batch 328/347] [D loss: 0.509592] [G loss: 0.436512]\n",
      "[Epoch 66/100] [Batch 329/347] [D loss: 0.508209] [G loss: 0.433396]\n",
      "[Epoch 66/100] [Batch 330/347] [D loss: 0.506509] [G loss: 0.431904]\n",
      "[Epoch 66/100] [Batch 331/347] [D loss: 0.509417] [G loss: 0.432579]\n",
      "[Epoch 66/100] [Batch 332/347] [D loss: 0.519135] [G loss: 0.449743]\n",
      "[Epoch 66/100] [Batch 333/347] [D loss: 0.514634] [G loss: 0.446196]\n",
      "[Epoch 66/100] [Batch 334/347] [D loss: 0.512310] [G loss: 0.437507]\n",
      "[Epoch 66/100] [Batch 335/347] [D loss: 0.511111] [G loss: 0.433659]\n",
      "[Epoch 66/100] [Batch 336/347] [D loss: 0.510431] [G loss: 0.430405]\n",
      "[Epoch 66/100] [Batch 337/347] [D loss: 0.514531] [G loss: 0.432462]\n",
      "[Epoch 66/100] [Batch 338/347] [D loss: 0.519428] [G loss: 0.438431]\n",
      "[Epoch 66/100] [Batch 339/347] [D loss: 0.514934] [G loss: 0.436764]\n",
      "[Epoch 66/100] [Batch 340/347] [D loss: 0.510540] [G loss: 0.431059]\n",
      "[Epoch 66/100] [Batch 341/347] [D loss: 0.510000] [G loss: 0.429001]\n",
      "[Epoch 66/100] [Batch 342/347] [D loss: 0.484856] [G loss: 0.414584]\n",
      "[Epoch 66/100] [Batch 343/347] [D loss: 0.477867] [G loss: 0.396868]\n",
      "[Epoch 66/100] [Batch 344/347] [D loss: 0.443132] [G loss: 0.391432]\n",
      "[Epoch 66/100] [Batch 345/347] [D loss: 0.364962] [G loss: 0.385898]\n",
      "[Epoch 66/100] [Batch 346/347] [D loss: 0.352103] [G loss: 0.381006]\n",
      "[Epoch 66/100] [Batch 347/347] [D loss: 0.330956] [G loss: 0.375627]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 1/347] [D loss: 0.497905] [G loss: 0.380971]\n",
      "[Epoch 67/100] [Batch 2/347] [D loss: 0.499172] [G loss: 0.375430]\n",
      "[Epoch 67/100] [Batch 3/347] [D loss: 0.506650] [G loss: 0.373669]\n",
      "[Epoch 67/100] [Batch 4/347] [D loss: 0.506686] [G loss: 0.368269]\n",
      "[Epoch 67/100] [Batch 5/347] [D loss: 0.505188] [G loss: 0.359256]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 6/347] [D loss: 0.495845] [G loss: 0.350682]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 7/347] [D loss: 0.482070] [G loss: 0.336472]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 8/347] [D loss: 0.477798] [G loss: 0.329099]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 9/347] [D loss: 0.473517] [G loss: 0.323218]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 10/347] [D loss: 0.472264] [G loss: 0.316581]\n",
      "[Epoch 67/100] [Batch 11/347] [D loss: 0.492838] [G loss: 0.317874]\n",
      "[Epoch 67/100] [Batch 12/347] [D loss: 0.497726] [G loss: 0.312093]\n",
      "[Epoch 67/100] [Batch 13/347] [D loss: 0.483186] [G loss: 0.302654]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 14/347] [D loss: 0.469572] [G loss: 0.293130]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 15/347] [D loss: 0.460852] [G loss: 0.274179]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 16/347] [D loss: 0.454224] [G loss: 0.259352]\n",
      "[Epoch 67/100] [Batch 17/347] [D loss: 0.456401] [G loss: 0.254232]\n",
      "[Epoch 67/100] [Batch 18/347] [D loss: 0.464121] [G loss: 0.248867]\n",
      "[Epoch 67/100] [Batch 19/347] [D loss: 0.471227] [G loss: 0.250607]\n",
      "[Epoch 67/100] [Batch 20/347] [D loss: 0.489933] [G loss: 0.255255]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 21/347] [D loss: 0.448818] [G loss: 0.252618]\n",
      "[Epoch 67/100] [Batch 22/347] [D loss: 0.447906] [G loss: 0.254755]\n",
      "[Epoch 67/100] [Batch 23/347] [D loss: 0.446150] [G loss: 0.257844]\n",
      "[Epoch 67/100] [Batch 24/347] [D loss: 0.408124] [G loss: 0.261284]\n",
      "[Epoch 67/100] [Batch 25/347] [D loss: 0.322772] [G loss: 0.279510]\n",
      "[Epoch 67/100] [Batch 26/347] [D loss: 0.318301] [G loss: 0.291684]\n",
      "[Epoch 67/100] [Batch 27/347] [D loss: 0.311843] [G loss: 0.306238]\n",
      "[Epoch 67/100] [Batch 28/347] [D loss: 0.313489] [G loss: 0.320988]\n",
      "[Epoch 67/100] [Batch 29/347] [D loss: 0.341985] [G loss: 0.327639]\n",
      "[Epoch 67/100] [Batch 30/347] [D loss: 0.331622] [G loss: 0.333036]\n",
      "[Epoch 67/100] [Batch 31/347] [D loss: 0.330333] [G loss: 0.334419]\n",
      "[Epoch 67/100] [Batch 32/347] [D loss: 0.339801] [G loss: 0.331421]\n",
      "[Epoch 67/100] [Batch 33/347] [D loss: 0.352637] [G loss: 0.327081]\n",
      "[Epoch 67/100] [Batch 34/347] [D loss: 0.387570] [G loss: 0.317771]\n",
      "[Epoch 67/100] [Batch 35/347] [D loss: 0.379046] [G loss: 0.306779]\n",
      "[Epoch 67/100] [Batch 36/347] [D loss: 0.390823] [G loss: 0.290845]\n",
      "[Epoch 67/100] [Batch 37/347] [D loss: 0.394796] [G loss: 0.272897]\n",
      "[Epoch 67/100] [Batch 38/347] [D loss: 0.398017] [G loss: 0.253874]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 39/347] [D loss: 0.412582] [G loss: 0.243639]\n",
      "[Epoch 67/100] [Batch 40/347] [D loss: 0.443243] [G loss: 0.244525]\n",
      "[Epoch 67/100] [Batch 41/347] [D loss: 0.457667] [G loss: 0.246338]\n",
      "[Epoch 67/100] [Batch 42/347] [D loss: 0.457026] [G loss: 0.258389]\n",
      "[Epoch 67/100] [Batch 43/347] [D loss: 0.478446] [G loss: 0.276885]\n",
      "[Epoch 67/100] [Batch 44/347] [D loss: 0.469736] [G loss: 0.289295]\n",
      "[Epoch 67/100] [Batch 45/347] [D loss: 0.444058] [G loss: 0.290461]\n",
      "[Epoch 67/100] [Batch 46/347] [D loss: 0.371978] [G loss: 0.295911]\n",
      "[Epoch 67/100] [Batch 47/347] [D loss: 0.358509] [G loss: 0.300269]\n",
      "[Epoch 67/100] [Batch 48/347] [D loss: 0.269845] [G loss: 0.316840]\n",
      "[Epoch 67/100] [Batch 49/347] [D loss: 0.251769] [G loss: 0.340338]\n",
      "[Epoch 67/100] [Batch 50/347] [D loss: 0.234859] [G loss: 0.361404]\n",
      "[Epoch 67/100] [Batch 51/347] [D loss: 0.231956] [G loss: 0.372801]\n",
      "[Epoch 67/100] [Batch 52/347] [D loss: 0.342652] [G loss: 0.372903]\n",
      "[Epoch 67/100] [Batch 53/347] [D loss: 0.390914] [G loss: 0.362821]\n",
      "[Epoch 67/100] [Batch 54/347] [D loss: 0.375021] [G loss: 0.355030]\n",
      "[Epoch 67/100] [Batch 55/347] [D loss: 0.366221] [G loss: 0.352909]\n",
      "[Epoch 67/100] [Batch 56/347] [D loss: 0.348292] [G loss: 0.355281]\n",
      "[Epoch 67/100] [Batch 57/347] [D loss: 0.300079] [G loss: 0.354247]\n",
      "[Epoch 67/100] [Batch 58/347] [D loss: 0.300645] [G loss: 0.345418]\n",
      "[Epoch 67/100] [Batch 59/347] [D loss: 0.292603] [G loss: 0.326791]\n",
      "[Epoch 67/100] [Batch 60/347] [D loss: 0.284312] [G loss: 0.301345]\n",
      "[Epoch 67/100] [Batch 61/347] [D loss: 0.301372] [G loss: 0.283817]\n",
      "[Epoch 67/100] [Batch 62/347] [D loss: 0.306647] [G loss: 0.278205]\n",
      "[Epoch 67/100] [Batch 63/347] [D loss: 0.309255] [G loss: 0.285826]\n",
      "[Epoch 67/100] [Batch 64/347] [D loss: 0.300324] [G loss: 0.297439]\n",
      "[Epoch 67/100] [Batch 65/347] [D loss: 0.260843] [G loss: 0.322534]\n",
      "[Epoch 67/100] [Batch 66/347] [D loss: 0.243428] [G loss: 0.341963]\n",
      "[Epoch 67/100] [Batch 67/347] [D loss: 0.228201] [G loss: 0.347575]\n",
      "[Epoch 67/100] [Batch 68/347] [D loss: 0.225199] [G loss: 0.353296]\n",
      "[Epoch 67/100] [Batch 69/347] [D loss: 0.249334] [G loss: 0.372061]\n",
      "[Epoch 67/100] [Batch 70/347] [D loss: 0.260627] [G loss: 0.376443]\n",
      "[Epoch 67/100] [Batch 71/347] [D loss: 0.262022] [G loss: 0.367060]\n",
      "[Epoch 67/100] [Batch 72/347] [D loss: 0.278864] [G loss: 0.377081]\n",
      "[Epoch 67/100] [Batch 73/347] [D loss: 0.385808] [G loss: 0.370613]\n",
      "[Epoch 67/100] [Batch 74/347] [D loss: 0.377714] [G loss: 0.366348]\n",
      "[Epoch 67/100] [Batch 75/347] [D loss: 0.363039] [G loss: 0.357500]\n",
      "[Epoch 67/100] [Batch 76/347] [D loss: 0.348891] [G loss: 0.341334]\n",
      "[Epoch 67/100] [Batch 77/347] [D loss: 0.378921] [G loss: 0.323361]\n",
      "[Epoch 67/100] [Batch 78/347] [D loss: 0.432188] [G loss: 0.313421]\n",
      "[Epoch 67/100] [Batch 79/347] [D loss: 0.435792] [G loss: 0.296568]\n",
      "[Epoch 67/100] [Batch 80/347] [D loss: 0.361549] [G loss: 0.272555]\n",
      "[Epoch 67/100] [Batch 81/347] [D loss: 0.356736] [G loss: 0.267875]\n",
      "[Epoch 67/100] [Batch 82/347] [D loss: 0.363568] [G loss: 0.272051]\n",
      "[Epoch 67/100] [Batch 83/347] [D loss: 0.362874] [G loss: 0.280946]\n",
      "[Epoch 67/100] [Batch 84/347] [D loss: 0.459702] [G loss: 0.297388]\n",
      "[Epoch 67/100] [Batch 85/347] [D loss: 0.514609] [G loss: 0.311133]\n",
      "[Epoch 67/100] [Batch 86/347] [D loss: 0.514312] [G loss: 0.323104]\n",
      "[Epoch 67/100] [Batch 87/347] [D loss: 0.514347] [G loss: 0.335740]\n",
      "[Epoch 67/100] [Batch 88/347] [D loss: 0.528208] [G loss: 0.346740]\n",
      "[Epoch 67/100] [Batch 89/347] [D loss: 0.535675] [G loss: 0.359509]\n",
      "[Epoch 67/100] [Batch 90/347] [D loss: 0.533238] [G loss: 0.369352]\n",
      "[Epoch 67/100] [Batch 91/347] [D loss: 0.531558] [G loss: 0.376774]\n",
      "[Epoch 67/100] [Batch 92/347] [D loss: 0.531251] [G loss: 0.386103]\n",
      "[Epoch 67/100] [Batch 93/347] [D loss: 0.529368] [G loss: 0.393753]\n",
      "[Epoch 67/100] [Batch 94/347] [D loss: 0.521150] [G loss: 0.396227]\n",
      "[Epoch 67/100] [Batch 95/347] [D loss: 0.517200] [G loss: 0.400002]\n",
      "[Epoch 67/100] [Batch 96/347] [D loss: 0.518937] [G loss: 0.405395]\n",
      "[Epoch 67/100] [Batch 97/347] [D loss: 0.516209] [G loss: 0.408025]\n",
      "[Epoch 67/100] [Batch 98/347] [D loss: 0.514705] [G loss: 0.411069]\n",
      "[Epoch 67/100] [Batch 99/347] [D loss: 0.519693] [G loss: 0.412741]\n",
      "[Epoch 67/100] [Batch 100/347] [D loss: 0.520420] [G loss: 0.413439]\n",
      "[Epoch 67/100] [Batch 101/347] [D loss: 0.521372] [G loss: 0.411850]\n",
      "[Epoch 67/100] [Batch 102/347] [D loss: 0.530994] [G loss: 0.409851]\n",
      "[Epoch 67/100] [Batch 103/347] [D loss: 0.530988] [G loss: 0.411929]\n",
      "[Epoch 67/100] [Batch 104/347] [D loss: 0.524535] [G loss: 0.407886]\n",
      "[Epoch 67/100] [Batch 105/347] [D loss: 0.440440] [G loss: 0.402440]\n",
      "[Epoch 67/100] [Batch 106/347] [D loss: 0.197933] [G loss: 0.396608]\n",
      "[Epoch 67/100] [Batch 107/347] [D loss: 0.201684] [G loss: 0.400180]\n",
      "[Epoch 67/100] [Batch 108/347] [D loss: 0.195287] [G loss: 0.405813]\n",
      "[Epoch 67/100] [Batch 109/347] [D loss: 0.193824] [G loss: 0.414987]\n",
      "[Epoch 67/100] [Batch 110/347] [D loss: 0.222713] [G loss: 0.419877]\n",
      "[Epoch 67/100] [Batch 111/347] [D loss: 0.219920] [G loss: 0.427845]\n",
      "[Epoch 67/100] [Batch 112/347] [D loss: 0.222826] [G loss: 0.433362]\n",
      "[Epoch 67/100] [Batch 113/347] [D loss: 0.409051] [G loss: 0.451276]\n",
      "[Epoch 67/100] [Batch 114/347] [D loss: 0.491348] [G loss: 0.455781]\n",
      "[Epoch 67/100] [Batch 115/347] [D loss: 0.477717] [G loss: 0.434413]\n",
      "[Epoch 67/100] [Batch 116/347] [D loss: 0.413073] [G loss: 0.408560]\n",
      "[Epoch 67/100] [Batch 117/347] [D loss: 0.395488] [G loss: 0.382788]\n",
      "[Epoch 67/100] [Batch 118/347] [D loss: 0.326928] [G loss: 0.352405]\n",
      "[Epoch 67/100] [Batch 119/347] [D loss: 0.322017] [G loss: 0.331643]\n",
      "[Epoch 67/100] [Batch 120/347] [D loss: 0.320574] [G loss: 0.320622]\n",
      "[Epoch 67/100] [Batch 121/347] [D loss: 0.326884] [G loss: 0.309339]\n",
      "[Epoch 67/100] [Batch 122/347] [D loss: 0.432255] [G loss: 0.305229]\n",
      "[Epoch 67/100] [Batch 123/347] [D loss: 0.479792] [G loss: 0.305999]\n",
      "[Epoch 67/100] [Batch 124/347] [D loss: 0.421652] [G loss: 0.306892]\n",
      "[Epoch 67/100] [Batch 125/347] [D loss: 0.390481] [G loss: 0.316579]\n",
      "[Epoch 67/100] [Batch 126/347] [D loss: 0.358372] [G loss: 0.330294]\n",
      "[Epoch 67/100] [Batch 127/347] [D loss: 0.352499] [G loss: 0.343039]\n",
      "[Epoch 67/100] [Batch 128/347] [D loss: 0.335192] [G loss: 0.353070]\n",
      "[Epoch 67/100] [Batch 129/347] [D loss: 0.284868] [G loss: 0.366787]\n",
      "[Epoch 67/100] [Batch 130/347] [D loss: 0.237011] [G loss: 0.398002]\n",
      "[Epoch 67/100] [Batch 131/347] [D loss: 0.209056] [G loss: 0.418715]\n",
      "[Epoch 67/100] [Batch 132/347] [D loss: 0.185233] [G loss: 0.436591]\n",
      "[Epoch 67/100] [Batch 133/347] [D loss: 0.179624] [G loss: 0.451472]\n",
      "[Epoch 67/100] [Batch 134/347] [D loss: 0.163598] [G loss: 0.463569]\n",
      "[Epoch 67/100] [Batch 135/347] [D loss: 0.161022] [G loss: 0.471318]\n",
      "[Epoch 67/100] [Batch 136/347] [D loss: 0.160046] [G loss: 0.471602]\n",
      "[Epoch 67/100] [Batch 137/347] [D loss: 0.437486] [G loss: 0.468623]\n",
      "[Epoch 67/100] [Batch 138/347] [D loss: 0.467209] [G loss: 0.462804]\n",
      "[Epoch 67/100] [Batch 139/347] [D loss: 0.480274] [G loss: 0.453303]\n",
      "[Epoch 67/100] [Batch 140/347] [D loss: 0.479039] [G loss: 0.451916]\n",
      "[Epoch 67/100] [Batch 141/347] [D loss: 0.455446] [G loss: 0.445037]\n",
      "[Epoch 67/100] [Batch 142/347] [D loss: 0.460099] [G loss: 0.437566]\n",
      "[Epoch 67/100] [Batch 143/347] [D loss: 0.450078] [G loss: 0.438903]\n",
      "[Epoch 67/100] [Batch 144/347] [D loss: 0.439540] [G loss: 0.428693]\n",
      "[Epoch 67/100] [Batch 145/347] [D loss: 0.452792] [G loss: 0.414826]\n",
      "[Epoch 67/100] [Batch 146/347] [D loss: 0.460687] [G loss: 0.407221]\n",
      "[Epoch 67/100] [Batch 147/347] [D loss: 0.473198] [G loss: 0.399701]\n",
      "[Epoch 67/100] [Batch 148/347] [D loss: 0.469679] [G loss: 0.392662]\n",
      "[Epoch 67/100] [Batch 149/347] [D loss: 0.402565] [G loss: 0.374224]\n",
      "[Epoch 67/100] [Batch 150/347] [D loss: 0.352338] [G loss: 0.343575]\n",
      "[Epoch 67/100] [Batch 151/347] [D loss: 0.316277] [G loss: 0.303365]\n",
      "[Epoch 67/100] [Batch 152/347] [D loss: 0.307171] [G loss: 0.263300]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 67/100] [Batch 153/347] [D loss: 0.327663] [G loss: 0.232573]\n",
      "[Epoch 67/100] [Batch 154/347] [D loss: 0.344760] [G loss: 0.219959]\n",
      "[Epoch 67/100] [Batch 155/347] [D loss: 0.355578] [G loss: 0.226232]\n",
      "[Epoch 67/100] [Batch 156/347] [D loss: 0.348144] [G loss: 0.238927]\n",
      "[Epoch 67/100] [Batch 157/347] [D loss: 0.333177] [G loss: 0.264008]\n",
      "[Epoch 67/100] [Batch 158/347] [D loss: 0.305856] [G loss: 0.301277]\n",
      "[Epoch 67/100] [Batch 159/347] [D loss: 0.274296] [G loss: 0.336853]\n",
      "[Epoch 67/100] [Batch 160/347] [D loss: 0.256184] [G loss: 0.373052]\n",
      "[Epoch 67/100] [Batch 161/347] [D loss: 0.229204] [G loss: 0.396328]\n",
      "[Epoch 67/100] [Batch 162/347] [D loss: 0.239610] [G loss: 0.403716]\n",
      "[Epoch 67/100] [Batch 163/347] [D loss: 0.261366] [G loss: 0.406066]\n",
      "[Epoch 67/100] [Batch 164/347] [D loss: 0.267534] [G loss: 0.405151]\n",
      "[Epoch 67/100] [Batch 165/347] [D loss: 0.276278] [G loss: 0.412743]\n",
      "[Epoch 67/100] [Batch 166/347] [D loss: 0.282267] [G loss: 0.416922]\n",
      "[Epoch 67/100] [Batch 167/347] [D loss: 0.310980] [G loss: 0.434810]\n",
      "[Epoch 67/100] [Batch 168/347] [D loss: 0.294280] [G loss: 0.437517]\n",
      "[Epoch 67/100] [Batch 169/347] [D loss: 0.430892] [G loss: 0.437379]\n",
      "[Epoch 67/100] [Batch 170/347] [D loss: 0.496471] [G loss: 0.432251]\n",
      "[Epoch 67/100] [Batch 171/347] [D loss: 0.498263] [G loss: 0.418000]\n",
      "[Epoch 67/100] [Batch 172/347] [D loss: 0.492607] [G loss: 0.400979]\n",
      "[Epoch 67/100] [Batch 173/347] [D loss: 0.486342] [G loss: 0.380169]\n",
      "[Epoch 67/100] [Batch 174/347] [D loss: 0.476073] [G loss: 0.361264]\n",
      "[Epoch 67/100] [Batch 175/347] [D loss: 0.517883] [G loss: 0.344710]\n",
      "[Epoch 67/100] [Batch 176/347] [D loss: 0.553435] [G loss: 0.329201]\n",
      "[Epoch 67/100] [Batch 177/347] [D loss: 0.555701] [G loss: 0.310988]\n",
      "[Epoch 67/100] [Batch 178/347] [D loss: 0.548517] [G loss: 0.293442]\n",
      "[Epoch 67/100] [Batch 179/347] [D loss: 0.546851] [G loss: 0.281988]\n",
      "[Epoch 67/100] [Batch 180/347] [D loss: 0.543441] [G loss: 0.274427]\n",
      "[Epoch 67/100] [Batch 181/347] [D loss: 0.546494] [G loss: 0.277630]\n",
      "[Epoch 67/100] [Batch 182/347] [D loss: 0.553774] [G loss: 0.282352]\n",
      "[Epoch 67/100] [Batch 183/347] [D loss: 0.556982] [G loss: 0.290317]\n",
      "[Epoch 67/100] [Batch 184/347] [D loss: 0.581568] [G loss: 0.302349]\n",
      "[Epoch 67/100] [Batch 185/347] [D loss: 0.579272] [G loss: 0.310810]\n",
      "[Epoch 67/100] [Batch 186/347] [D loss: 0.565977] [G loss: 0.322481]\n",
      "[Epoch 67/100] [Batch 187/347] [D loss: 0.553120] [G loss: 0.333312]\n",
      "[Epoch 67/100] [Batch 188/347] [D loss: 0.519574] [G loss: 0.338614]\n",
      "[Epoch 67/100] [Batch 189/347] [D loss: 0.477759] [G loss: 0.344653]\n",
      "[Epoch 67/100] [Batch 190/347] [D loss: 0.471776] [G loss: 0.353070]\n",
      "[Epoch 67/100] [Batch 191/347] [D loss: 0.474926] [G loss: 0.359907]\n",
      "[Epoch 67/100] [Batch 192/347] [D loss: 0.484479] [G loss: 0.366840]\n",
      "[Epoch 67/100] [Batch 193/347] [D loss: 0.532950] [G loss: 0.373648]\n",
      "[Epoch 67/100] [Batch 194/347] [D loss: 0.528717] [G loss: 0.375929]\n",
      "[Epoch 67/100] [Batch 195/347] [D loss: 0.512433] [G loss: 0.377161]\n",
      "[Epoch 67/100] [Batch 196/347] [D loss: 0.477353] [G loss: 0.376290]\n",
      "[Epoch 67/100] [Batch 197/347] [D loss: 0.474429] [G loss: 0.374605]\n",
      "[Epoch 67/100] [Batch 198/347] [D loss: 0.474488] [G loss: 0.374997]\n",
      "[Epoch 67/100] [Batch 199/347] [D loss: 0.471637] [G loss: 0.370839]\n",
      "[Epoch 67/100] [Batch 200/347] [D loss: 0.517756] [G loss: 0.366315]\n",
      "[Epoch 67/100] [Batch 201/347] [D loss: 0.538938] [G loss: 0.362265]\n",
      "[Epoch 67/100] [Batch 202/347] [D loss: 0.545539] [G loss: 0.358864]\n",
      "[Epoch 67/100] [Batch 203/347] [D loss: 0.564435] [G loss: 0.357580]\n",
      "[Epoch 67/100] [Batch 204/347] [D loss: 0.562835] [G loss: 0.361169]\n",
      "[Epoch 67/100] [Batch 205/347] [D loss: 0.564716] [G loss: 0.369128]\n",
      "[Epoch 67/100] [Batch 206/347] [D loss: 0.566075] [G loss: 0.376625]\n",
      "[Epoch 67/100] [Batch 207/347] [D loss: 0.527827] [G loss: 0.382798]\n",
      "[Epoch 67/100] [Batch 208/347] [D loss: 0.520574] [G loss: 0.390193]\n",
      "[Epoch 67/100] [Batch 209/347] [D loss: 0.507363] [G loss: 0.388654]\n",
      "[Epoch 67/100] [Batch 210/347] [D loss: 0.412594] [G loss: 0.390305]\n",
      "[Epoch 67/100] [Batch 211/347] [D loss: 0.362506] [G loss: 0.387350]\n",
      "[Epoch 67/100] [Batch 212/347] [D loss: 0.234575] [G loss: 0.382406]\n",
      "[Epoch 67/100] [Batch 213/347] [D loss: 0.228459] [G loss: 0.400539]\n",
      "[Epoch 67/100] [Batch 214/347] [D loss: 0.217735] [G loss: 0.417644]\n",
      "[Epoch 67/100] [Batch 215/347] [D loss: 0.211740] [G loss: 0.435008]\n",
      "[Epoch 67/100] [Batch 216/347] [D loss: 0.415389] [G loss: 0.460130]\n",
      "[Epoch 67/100] [Batch 217/347] [D loss: 0.481522] [G loss: 0.481898]\n",
      "[Epoch 67/100] [Batch 218/347] [D loss: 0.518049] [G loss: 0.501836]\n",
      "[Epoch 67/100] [Batch 219/347] [D loss: 0.519539] [G loss: 0.512306]\n",
      "[Epoch 67/100] [Batch 220/347] [D loss: 0.510756] [G loss: 0.518946]\n",
      "[Epoch 67/100] [Batch 221/347] [D loss: 0.527491] [G loss: 0.521193]\n",
      "[Epoch 67/100] [Batch 222/347] [D loss: 0.529169] [G loss: 0.514423]\n",
      "[Epoch 67/100] [Batch 223/347] [D loss: 0.519224] [G loss: 0.496689]\n",
      "[Epoch 67/100] [Batch 224/347] [D loss: 0.522979] [G loss: 0.475218]\n",
      "[Epoch 67/100] [Batch 225/347] [D loss: 0.527587] [G loss: 0.456793]\n",
      "[Epoch 67/100] [Batch 226/347] [D loss: 0.528988] [G loss: 0.445962]\n",
      "[Epoch 67/100] [Batch 227/347] [D loss: 0.538279] [G loss: 0.445680]\n",
      "[Epoch 67/100] [Batch 228/347] [D loss: 0.542016] [G loss: 0.447951]\n",
      "[Epoch 67/100] [Batch 229/347] [D loss: 0.542646] [G loss: 0.451029]\n",
      "[Epoch 67/100] [Batch 230/347] [D loss: 0.545909] [G loss: 0.453616]\n",
      "[Epoch 67/100] [Batch 231/347] [D loss: 0.538750] [G loss: 0.448174]\n",
      "[Epoch 67/100] [Batch 232/347] [D loss: 0.533012] [G loss: 0.447286]\n",
      "[Epoch 67/100] [Batch 233/347] [D loss: 0.487047] [G loss: 0.449332]\n",
      "[Epoch 67/100] [Batch 234/347] [D loss: 0.459924] [G loss: 0.448328]\n",
      "[Epoch 67/100] [Batch 235/347] [D loss: 0.452426] [G loss: 0.452241]\n",
      "[Epoch 67/100] [Batch 236/347] [D loss: 0.442838] [G loss: 0.451642]\n",
      "[Epoch 67/100] [Batch 237/347] [D loss: 0.483660] [G loss: 0.445867]\n",
      "[Epoch 67/100] [Batch 238/347] [D loss: 0.550827] [G loss: 0.435438]\n",
      "[Epoch 67/100] [Batch 239/347] [D loss: 0.550915] [G loss: 0.424671]\n",
      "[Epoch 67/100] [Batch 240/347] [D loss: 0.554792] [G loss: 0.417978]\n",
      "[Epoch 67/100] [Batch 241/347] [D loss: 0.556035] [G loss: 0.417237]\n",
      "[Epoch 67/100] [Batch 242/347] [D loss: 0.567884] [G loss: 0.422163]\n",
      "[Epoch 67/100] [Batch 243/347] [D loss: 0.527540] [G loss: 0.427783]\n",
      "[Epoch 67/100] [Batch 244/347] [D loss: 0.504673] [G loss: 0.423157]\n",
      "[Epoch 67/100] [Batch 245/347] [D loss: 0.504211] [G loss: 0.415676]\n",
      "[Epoch 67/100] [Batch 246/347] [D loss: 0.505948] [G loss: 0.404885]\n",
      "[Epoch 67/100] [Batch 247/347] [D loss: 0.522392] [G loss: 0.398132]\n",
      "[Epoch 67/100] [Batch 248/347] [D loss: 0.536711] [G loss: 0.403172]\n",
      "[Epoch 67/100] [Batch 249/347] [D loss: 0.524830] [G loss: 0.411540]\n",
      "[Epoch 67/100] [Batch 250/347] [D loss: 0.523444] [G loss: 0.423166]\n",
      "[Epoch 67/100] [Batch 251/347] [D loss: 0.518444] [G loss: 0.438234]\n",
      "[Epoch 67/100] [Batch 252/347] [D loss: 0.514932] [G loss: 0.446234]\n",
      "[Epoch 67/100] [Batch 253/347] [D loss: 0.462545] [G loss: 0.439876]\n",
      "[Epoch 67/100] [Batch 254/347] [D loss: 0.456429] [G loss: 0.442800]\n",
      "[Epoch 67/100] [Batch 255/347] [D loss: 0.452277] [G loss: 0.439774]\n",
      "[Epoch 67/100] [Batch 256/347] [D loss: 0.454538] [G loss: 0.426355]\n",
      "[Epoch 67/100] [Batch 257/347] [D loss: 0.446092] [G loss: 0.411542]\n",
      "[Epoch 67/100] [Batch 258/347] [D loss: 0.408187] [G loss: 0.399751]\n",
      "[Epoch 67/100] [Batch 259/347] [D loss: 0.408635] [G loss: 0.386023]\n",
      "[Epoch 67/100] [Batch 260/347] [D loss: 0.410109] [G loss: 0.374143]\n",
      "[Epoch 67/100] [Batch 261/347] [D loss: 0.395991] [G loss: 0.369177]\n",
      "[Epoch 67/100] [Batch 262/347] [D loss: 0.351540] [G loss: 0.365099]\n",
      "[Epoch 67/100] [Batch 263/347] [D loss: 0.347259] [G loss: 0.364681]\n",
      "[Epoch 67/100] [Batch 264/347] [D loss: 0.352494] [G loss: 0.369309]\n",
      "[Epoch 67/100] [Batch 265/347] [D loss: 0.358118] [G loss: 0.376610]\n",
      "[Epoch 67/100] [Batch 266/347] [D loss: 0.426809] [G loss: 0.385568]\n",
      "[Epoch 67/100] [Batch 267/347] [D loss: 0.443121] [G loss: 0.392512]\n",
      "[Epoch 67/100] [Batch 268/347] [D loss: 0.456465] [G loss: 0.397171]\n",
      "[Epoch 67/100] [Batch 269/347] [D loss: 0.457308] [G loss: 0.400167]\n",
      "[Epoch 67/100] [Batch 270/347] [D loss: 0.488989] [G loss: 0.401827]\n",
      "[Epoch 67/100] [Batch 271/347] [D loss: 0.449747] [G loss: 0.409312]\n",
      "[Epoch 67/100] [Batch 272/347] [D loss: 0.384173] [G loss: 0.437464]\n",
      "[Epoch 67/100] [Batch 273/347] [D loss: 0.342700] [G loss: 0.465301]\n",
      "[Epoch 67/100] [Batch 274/347] [D loss: 0.276881] [G loss: 0.485713]\n",
      "[Epoch 67/100] [Batch 275/347] [D loss: 0.230764] [G loss: 0.499900]\n",
      "[Epoch 67/100] [Batch 276/347] [D loss: 0.504433] [G loss: 0.506688]\n",
      "[Epoch 67/100] [Batch 277/347] [D loss: 0.526263] [G loss: 0.517662]\n",
      "[Epoch 67/100] [Batch 278/347] [D loss: 0.531388] [G loss: 0.527393]\n",
      "[Epoch 67/100] [Batch 279/347] [D loss: 0.533515] [G loss: 0.528985]\n",
      "[Epoch 67/100] [Batch 280/347] [D loss: 0.536279] [G loss: 0.529073]\n",
      "[Epoch 67/100] [Batch 281/347] [D loss: 0.539198] [G loss: 0.529160]\n",
      "[Epoch 67/100] [Batch 282/347] [D loss: 0.540405] [G loss: 0.532218]\n",
      "[Epoch 67/100] [Batch 283/347] [D loss: 0.541316] [G loss: 0.533434]\n",
      "[Epoch 67/100] [Batch 284/347] [D loss: 0.542183] [G loss: 0.535521]\n",
      "[Epoch 67/100] [Batch 285/347] [D loss: 0.544558] [G loss: 0.536333]\n",
      "[Epoch 67/100] [Batch 286/347] [D loss: 0.543154] [G loss: 0.522249]\n",
      "[Epoch 67/100] [Batch 287/347] [D loss: 0.543528] [G loss: 0.519486]\n",
      "[Epoch 67/100] [Batch 288/347] [D loss: 0.543821] [G loss: 0.516789]\n",
      "[Epoch 67/100] [Batch 289/347] [D loss: 0.543036] [G loss: 0.511832]\n",
      "[Epoch 67/100] [Batch 290/347] [D loss: 0.543588] [G loss: 0.527493]\n",
      "[Epoch 67/100] [Batch 291/347] [D loss: 0.542735] [G loss: 0.534551]\n",
      "[Epoch 67/100] [Batch 292/347] [D loss: 0.541294] [G loss: 0.538515]\n",
      "[Epoch 67/100] [Batch 293/347] [D loss: 0.525138] [G loss: 0.544104]\n",
      "[Epoch 67/100] [Batch 294/347] [D loss: 0.524761] [G loss: 0.548869]\n",
      "[Epoch 67/100] [Batch 295/347] [D loss: 0.524611] [G loss: 0.548048]\n",
      "[Epoch 67/100] [Batch 296/347] [D loss: 0.524091] [G loss: 0.546943]\n",
      "[Epoch 67/100] [Batch 297/347] [D loss: 0.540925] [G loss: 0.551808]\n",
      "[Epoch 67/100] [Batch 298/347] [D loss: 0.543558] [G loss: 0.545630]\n",
      "[Epoch 67/100] [Batch 299/347] [D loss: 0.542693] [G loss: 0.541304]\n",
      "[Epoch 67/100] [Batch 300/347] [D loss: 0.541727] [G loss: 0.539404]\n",
      "[Epoch 67/100] [Batch 301/347] [D loss: 0.541698] [G loss: 0.524251]\n",
      "[Epoch 67/100] [Batch 302/347] [D loss: 0.541965] [G loss: 0.515952]\n",
      "[Epoch 67/100] [Batch 303/347] [D loss: 0.541470] [G loss: 0.505151]\n",
      "[Epoch 67/100] [Batch 304/347] [D loss: 0.528431] [G loss: 0.493485]\n",
      "[Epoch 67/100] [Batch 305/347] [D loss: 0.517672] [G loss: 0.487029]\n",
      "[Epoch 67/100] [Batch 306/347] [D loss: 0.516736] [G loss: 0.488750]\n",
      "[Epoch 67/100] [Batch 307/347] [D loss: 0.514994] [G loss: 0.494825]\n",
      "[Epoch 67/100] [Batch 308/347] [D loss: 0.521368] [G loss: 0.499018]\n",
      "[Epoch 67/100] [Batch 309/347] [D loss: 0.538444] [G loss: 0.513556]\n",
      "[Epoch 67/100] [Batch 310/347] [D loss: 0.545028] [G loss: 0.525992]\n",
      "[Epoch 67/100] [Batch 311/347] [D loss: 0.542726] [G loss: 0.523515]\n",
      "[Epoch 67/100] [Batch 312/347] [D loss: 0.537904] [G loss: 0.518362]\n",
      "[Epoch 67/100] [Batch 313/347] [D loss: 0.533997] [G loss: 0.509203]\n",
      "[Epoch 67/100] [Batch 314/347] [D loss: 0.533091] [G loss: 0.494464]\n",
      "[Epoch 67/100] [Batch 315/347] [D loss: 0.532927] [G loss: 0.483155]\n",
      "[Epoch 67/100] [Batch 316/347] [D loss: 0.533482] [G loss: 0.484077]\n",
      "[Epoch 67/100] [Batch 317/347] [D loss: 0.534850] [G loss: 0.487609]\n",
      "[Epoch 67/100] [Batch 318/347] [D loss: 0.535049] [G loss: 0.500778]\n",
      "[Epoch 67/100] [Batch 319/347] [D loss: 0.533440] [G loss: 0.512696]\n",
      "[Epoch 67/100] [Batch 320/347] [D loss: 0.532275] [G loss: 0.510824]\n",
      "[Epoch 67/100] [Batch 321/347] [D loss: 0.529741] [G loss: 0.503812]\n",
      "[Epoch 67/100] [Batch 322/347] [D loss: 0.529672] [G loss: 0.496029]\n",
      "[Epoch 67/100] [Batch 323/347] [D loss: 0.522678] [G loss: 0.487041]\n",
      "[Epoch 67/100] [Batch 324/347] [D loss: 0.520767] [G loss: 0.480662]\n",
      "[Epoch 67/100] [Batch 325/347] [D loss: 0.520261] [G loss: 0.473118]\n",
      "[Epoch 67/100] [Batch 326/347] [D loss: 0.519680] [G loss: 0.467427]\n",
      "[Epoch 67/100] [Batch 327/347] [D loss: 0.516503] [G loss: 0.462432]\n",
      "[Epoch 67/100] [Batch 328/347] [D loss: 0.516245] [G loss: 0.456679]\n",
      "[Epoch 67/100] [Batch 329/347] [D loss: 0.515086] [G loss: 0.453980]\n",
      "[Epoch 67/100] [Batch 330/347] [D loss: 0.513612] [G loss: 0.452801]\n",
      "[Epoch 67/100] [Batch 331/347] [D loss: 0.516141] [G loss: 0.453981]\n",
      "[Epoch 67/100] [Batch 332/347] [D loss: 0.524753] [G loss: 0.471907]\n",
      "[Epoch 67/100] [Batch 333/347] [D loss: 0.520796] [G loss: 0.468714]\n",
      "[Epoch 67/100] [Batch 334/347] [D loss: 0.518803] [G loss: 0.460473]\n",
      "[Epoch 67/100] [Batch 335/347] [D loss: 0.517882] [G loss: 0.456800]\n",
      "[Epoch 67/100] [Batch 336/347] [D loss: 0.517186] [G loss: 0.453868]\n",
      "[Epoch 67/100] [Batch 337/347] [D loss: 0.520895] [G loss: 0.456451]\n",
      "[Epoch 67/100] [Batch 338/347] [D loss: 0.525166] [G loss: 0.462654]\n",
      "[Epoch 67/100] [Batch 339/347] [D loss: 0.521171] [G loss: 0.461350]\n",
      "[Epoch 67/100] [Batch 340/347] [D loss: 0.517300] [G loss: 0.456088]\n",
      "[Epoch 67/100] [Batch 341/347] [D loss: 0.516936] [G loss: 0.454464]\n",
      "[Epoch 67/100] [Batch 342/347] [D loss: 0.495006] [G loss: 0.440384]\n",
      "[Epoch 67/100] [Batch 343/347] [D loss: 0.489085] [G loss: 0.423154]\n",
      "[Epoch 67/100] [Batch 344/347] [D loss: 0.458241] [G loss: 0.418251]\n",
      "[Epoch 67/100] [Batch 345/347] [D loss: 0.384745] [G loss: 0.413367]\n",
      "[Epoch 67/100] [Batch 346/347] [D loss: 0.372107] [G loss: 0.409267]\n",
      "[Epoch 67/100] [Batch 347/347] [D loss: 0.349605] [G loss: 0.404759]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 1/347] [D loss: 0.506264] [G loss: 0.411402]\n",
      "[Epoch 68/100] [Batch 2/347] [D loss: 0.507138] [G loss: 0.406761]\n",
      "[Epoch 68/100] [Batch 3/347] [D loss: 0.513526] [G loss: 0.405977]\n",
      "[Epoch 68/100] [Batch 4/347] [D loss: 0.513324] [G loss: 0.401490]\n",
      "[Epoch 68/100] [Batch 5/347] [D loss: 0.512038] [G loss: 0.393399]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 6/347] [D loss: 0.504242] [G loss: 0.385927]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 7/347] [D loss: 0.493273] [G loss: 0.372952]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 8/347] [D loss: 0.489403] [G loss: 0.366623]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 9/347] [D loss: 0.486188] [G loss: 0.362271]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 10/347] [D loss: 0.484257] [G loss: 0.357277]\n",
      "[Epoch 68/100] [Batch 11/347] [D loss: 0.500809] [G loss: 0.360378]\n",
      "[Epoch 68/100] [Batch 12/347] [D loss: 0.503580] [G loss: 0.356067]\n",
      "[Epoch 68/100] [Batch 13/347] [D loss: 0.489363] [G loss: 0.347538]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 14/347] [D loss: 0.476357] [G loss: 0.338591]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 15/347] [D loss: 0.466318] [G loss: 0.319124]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 16/347] [D loss: 0.456646] [G loss: 0.302631]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 17/347] [D loss: 0.456550] [G loss: 0.292731]\n",
      "[Epoch 68/100] [Batch 18/347] [D loss: 0.461558] [G loss: 0.281345]\n",
      "[Epoch 68/100] [Batch 19/347] [D loss: 0.466624] [G loss: 0.275330]\n",
      "[Epoch 68/100] [Batch 20/347] [D loss: 0.487890] [G loss: 0.270813]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 21/347] [D loss: 0.441905] [G loss: 0.259630]\n",
      "[Epoch 68/100] [Batch 22/347] [D loss: 0.445842] [G loss: 0.255235]\n",
      "[Epoch 68/100] [Batch 23/347] [D loss: 0.445225] [G loss: 0.252240]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 68/100] [Batch 24/347] [D loss: 0.411176] [G loss: 0.251502]\n",
      "[Epoch 68/100] [Batch 25/347] [D loss: 0.330030] [G loss: 0.270005]\n",
      "[Epoch 68/100] [Batch 26/347] [D loss: 0.322299] [G loss: 0.286166]\n",
      "[Epoch 68/100] [Batch 27/347] [D loss: 0.310691] [G loss: 0.306840]\n",
      "[Epoch 68/100] [Batch 28/347] [D loss: 0.307355] [G loss: 0.327482]\n",
      "[Epoch 68/100] [Batch 29/347] [D loss: 0.330868] [G loss: 0.339573]\n",
      "[Epoch 68/100] [Batch 30/347] [D loss: 0.322119] [G loss: 0.348703]\n",
      "[Epoch 68/100] [Batch 31/347] [D loss: 0.324248] [G loss: 0.353170]\n",
      "[Epoch 68/100] [Batch 32/347] [D loss: 0.337392] [G loss: 0.352168]\n",
      "[Epoch 68/100] [Batch 33/347] [D loss: 0.354018] [G loss: 0.350107]\n",
      "[Epoch 68/100] [Batch 34/347] [D loss: 0.394845] [G loss: 0.343595]\n",
      "[Epoch 68/100] [Batch 35/347] [D loss: 0.387055] [G loss: 0.334130]\n",
      "[Epoch 68/100] [Batch 36/347] [D loss: 0.401012] [G loss: 0.320313]\n",
      "[Epoch 68/100] [Batch 37/347] [D loss: 0.402625] [G loss: 0.301889]\n",
      "[Epoch 68/100] [Batch 38/347] [D loss: 0.401166] [G loss: 0.280296]\n",
      "[Epoch 68/100] [Batch 39/347] [D loss: 0.412294] [G loss: 0.265083]\n",
      "[Epoch 68/100] [Batch 40/347] [D loss: 0.443141] [G loss: 0.259327]\n",
      "[Epoch 68/100] [Batch 41/347] [D loss: 0.460015] [G loss: 0.253001]\n",
      "[Epoch 68/100] [Batch 42/347] [D loss: 0.461329] [G loss: 0.256632]\n",
      "[Epoch 68/100] [Batch 43/347] [D loss: 0.484776] [G loss: 0.269642]\n",
      "[Epoch 68/100] [Batch 44/347] [D loss: 0.477588] [G loss: 0.276802]\n",
      "[Epoch 68/100] [Batch 45/347] [D loss: 0.452231] [G loss: 0.273497]\n",
      "[Epoch 68/100] [Batch 46/347] [D loss: 0.381700] [G loss: 0.278552]\n",
      "[Epoch 68/100] [Batch 47/347] [D loss: 0.367924] [G loss: 0.284642]\n",
      "[Epoch 68/100] [Batch 48/347] [D loss: 0.290437] [G loss: 0.306073]\n",
      "[Epoch 68/100] [Batch 49/347] [D loss: 0.264868] [G loss: 0.335264]\n",
      "[Epoch 68/100] [Batch 50/347] [D loss: 0.241261] [G loss: 0.362612]\n",
      "[Epoch 68/100] [Batch 51/347] [D loss: 0.231560] [G loss: 0.377613]\n",
      "[Epoch 68/100] [Batch 52/347] [D loss: 0.340234] [G loss: 0.380271]\n",
      "[Epoch 68/100] [Batch 53/347] [D loss: 0.393294] [G loss: 0.372071]\n",
      "[Epoch 68/100] [Batch 54/347] [D loss: 0.381763] [G loss: 0.362568]\n",
      "[Epoch 68/100] [Batch 55/347] [D loss: 0.377839] [G loss: 0.365525]\n",
      "[Epoch 68/100] [Batch 56/347] [D loss: 0.364033] [G loss: 0.370575]\n",
      "[Epoch 68/100] [Batch 57/347] [D loss: 0.313695] [G loss: 0.373416]\n",
      "[Epoch 68/100] [Batch 58/347] [D loss: 0.313507] [G loss: 0.370523]\n",
      "[Epoch 68/100] [Batch 59/347] [D loss: 0.301384] [G loss: 0.356166]\n",
      "[Epoch 68/100] [Batch 60/347] [D loss: 0.283166] [G loss: 0.331337]\n",
      "[Epoch 68/100] [Batch 61/347] [D loss: 0.296177] [G loss: 0.304419]\n",
      "[Epoch 68/100] [Batch 62/347] [D loss: 0.298756] [G loss: 0.295202]\n",
      "[Epoch 68/100] [Batch 63/347] [D loss: 0.302130] [G loss: 0.291368]\n",
      "[Epoch 68/100] [Batch 64/347] [D loss: 0.297090] [G loss: 0.292579]\n",
      "[Epoch 68/100] [Batch 65/347] [D loss: 0.268865] [G loss: 0.307274]\n",
      "[Epoch 68/100] [Batch 66/347] [D loss: 0.260269] [G loss: 0.320995]\n",
      "[Epoch 68/100] [Batch 67/347] [D loss: 0.245588] [G loss: 0.326568]\n",
      "[Epoch 68/100] [Batch 68/347] [D loss: 0.234556] [G loss: 0.336171]\n",
      "[Epoch 68/100] [Batch 69/347] [D loss: 0.243718] [G loss: 0.351972]\n",
      "[Epoch 68/100] [Batch 70/347] [D loss: 0.247841] [G loss: 0.360585]\n",
      "[Epoch 68/100] [Batch 71/347] [D loss: 0.248484] [G loss: 0.362046]\n",
      "[Epoch 68/100] [Batch 72/347] [D loss: 0.266032] [G loss: 0.375171]\n",
      "[Epoch 68/100] [Batch 73/347] [D loss: 0.376448] [G loss: 0.371675]\n",
      "[Epoch 68/100] [Batch 74/347] [D loss: 0.376265] [G loss: 0.371663]\n",
      "[Epoch 68/100] [Batch 75/347] [D loss: 0.369623] [G loss: 0.368791]\n",
      "[Epoch 68/100] [Batch 76/347] [D loss: 0.360503] [G loss: 0.361302]\n",
      "[Epoch 68/100] [Batch 77/347] [D loss: 0.389148] [G loss: 0.350827]\n",
      "[Epoch 68/100] [Batch 78/347] [D loss: 0.439101] [G loss: 0.349162]\n",
      "[Epoch 68/100] [Batch 79/347] [D loss: 0.434291] [G loss: 0.334523]\n",
      "[Epoch 68/100] [Batch 80/347] [D loss: 0.342415] [G loss: 0.308162]\n",
      "[Epoch 68/100] [Batch 81/347] [D loss: 0.330636] [G loss: 0.295240]\n",
      "[Epoch 68/100] [Batch 82/347] [D loss: 0.339197] [G loss: 0.289918]\n",
      "[Epoch 68/100] [Batch 83/347] [D loss: 0.345153] [G loss: 0.288853]\n",
      "[Epoch 68/100] [Batch 84/347] [D loss: 0.452930] [G loss: 0.295574]\n",
      "[Epoch 68/100] [Batch 85/347] [D loss: 0.511697] [G loss: 0.299709]\n",
      "[Epoch 68/100] [Batch 86/347] [D loss: 0.512375] [G loss: 0.304523]\n",
      "[Epoch 68/100] [Batch 87/347] [D loss: 0.512272] [G loss: 0.311212]\n",
      "[Epoch 68/100] [Batch 88/347] [D loss: 0.527855] [G loss: 0.318534]\n",
      "[Epoch 68/100] [Batch 89/347] [D loss: 0.536509] [G loss: 0.327990]\n",
      "[Epoch 68/100] [Batch 90/347] [D loss: 0.534111] [G loss: 0.335287]\n",
      "[Epoch 68/100] [Batch 91/347] [D loss: 0.532614] [G loss: 0.342192]\n",
      "[Epoch 68/100] [Batch 92/347] [D loss: 0.532490] [G loss: 0.350341]\n",
      "[Epoch 68/100] [Batch 93/347] [D loss: 0.530828] [G loss: 0.358390]\n",
      "[Epoch 68/100] [Batch 94/347] [D loss: 0.518735] [G loss: 0.361934]\n",
      "[Epoch 68/100] [Batch 95/347] [D loss: 0.512740] [G loss: 0.366470]\n",
      "[Epoch 68/100] [Batch 96/347] [D loss: 0.514638] [G loss: 0.373019]\n",
      "[Epoch 68/100] [Batch 97/347] [D loss: 0.510885] [G loss: 0.376307]\n",
      "[Epoch 68/100] [Batch 98/347] [D loss: 0.506486] [G loss: 0.380471]\n",
      "[Epoch 68/100] [Batch 99/347] [D loss: 0.514603] [G loss: 0.382554]\n",
      "[Epoch 68/100] [Batch 100/347] [D loss: 0.515783] [G loss: 0.384209]\n",
      "[Epoch 68/100] [Batch 101/347] [D loss: 0.518830] [G loss: 0.383741]\n",
      "[Epoch 68/100] [Batch 102/347] [D loss: 0.536522] [G loss: 0.383374]\n",
      "[Epoch 68/100] [Batch 103/347] [D loss: 0.537485] [G loss: 0.387600]\n",
      "[Epoch 68/100] [Batch 104/347] [D loss: 0.527132] [G loss: 0.386631]\n",
      "[Epoch 68/100] [Batch 105/347] [D loss: 0.443815] [G loss: 0.384084]\n",
      "[Epoch 68/100] [Batch 106/347] [D loss: 0.213706] [G loss: 0.383477]\n",
      "[Epoch 68/100] [Batch 107/347] [D loss: 0.212364] [G loss: 0.395037]\n",
      "[Epoch 68/100] [Batch 108/347] [D loss: 0.201691] [G loss: 0.407448]\n",
      "[Epoch 68/100] [Batch 109/347] [D loss: 0.196730] [G loss: 0.420952]\n",
      "[Epoch 68/100] [Batch 110/347] [D loss: 0.224548] [G loss: 0.426657]\n",
      "[Epoch 68/100] [Batch 111/347] [D loss: 0.224303] [G loss: 0.437572]\n",
      "[Epoch 68/100] [Batch 112/347] [D loss: 0.230617] [G loss: 0.445433]\n",
      "[Epoch 68/100] [Batch 113/347] [D loss: 0.415910] [G loss: 0.465735]\n",
      "[Epoch 68/100] [Batch 114/347] [D loss: 0.497825] [G loss: 0.472933]\n",
      "[Epoch 68/100] [Batch 115/347] [D loss: 0.490220] [G loss: 0.455281]\n",
      "[Epoch 68/100] [Batch 116/347] [D loss: 0.437242] [G loss: 0.434535]\n",
      "[Epoch 68/100] [Batch 117/347] [D loss: 0.425189] [G loss: 0.416209]\n",
      "[Epoch 68/100] [Batch 118/347] [D loss: 0.354492] [G loss: 0.393678]\n",
      "[Epoch 68/100] [Batch 119/347] [D loss: 0.340072] [G loss: 0.375719]\n",
      "[Epoch 68/100] [Batch 120/347] [D loss: 0.326097] [G loss: 0.361913]\n",
      "[Epoch 68/100] [Batch 121/347] [D loss: 0.322837] [G loss: 0.341114]\n",
      "[Epoch 68/100] [Batch 122/347] [D loss: 0.435956] [G loss: 0.325074]\n",
      "[Epoch 68/100] [Batch 123/347] [D loss: 0.486138] [G loss: 0.314425]\n",
      "[Epoch 68/100] [Batch 124/347] [D loss: 0.426544] [G loss: 0.303712]\n",
      "[Epoch 68/100] [Batch 125/347] [D loss: 0.399733] [G loss: 0.304561]\n",
      "[Epoch 68/100] [Batch 126/347] [D loss: 0.373218] [G loss: 0.310297]\n",
      "[Epoch 68/100] [Batch 127/347] [D loss: 0.372085] [G loss: 0.317508]\n",
      "[Epoch 68/100] [Batch 128/347] [D loss: 0.357307] [G loss: 0.324492]\n",
      "[Epoch 68/100] [Batch 129/347] [D loss: 0.314321] [G loss: 0.341498]\n",
      "[Epoch 68/100] [Batch 130/347] [D loss: 0.273642] [G loss: 0.380162]\n",
      "[Epoch 68/100] [Batch 131/347] [D loss: 0.235336] [G loss: 0.409561]\n",
      "[Epoch 68/100] [Batch 132/347] [D loss: 0.200017] [G loss: 0.435652]\n",
      "[Epoch 68/100] [Batch 133/347] [D loss: 0.188039] [G loss: 0.454757]\n",
      "[Epoch 68/100] [Batch 134/347] [D loss: 0.167217] [G loss: 0.468747]\n",
      "[Epoch 68/100] [Batch 135/347] [D loss: 0.162394] [G loss: 0.477438]\n",
      "[Epoch 68/100] [Batch 136/347] [D loss: 0.161498] [G loss: 0.478292]\n",
      "[Epoch 68/100] [Batch 137/347] [D loss: 0.436329] [G loss: 0.475746]\n",
      "[Epoch 68/100] [Batch 138/347] [D loss: 0.466962] [G loss: 0.470561]\n",
      "[Epoch 68/100] [Batch 139/347] [D loss: 0.482500] [G loss: 0.461539]\n",
      "[Epoch 68/100] [Batch 140/347] [D loss: 0.482432] [G loss: 0.460828]\n",
      "[Epoch 68/100] [Batch 141/347] [D loss: 0.463205] [G loss: 0.454649]\n",
      "[Epoch 68/100] [Batch 142/347] [D loss: 0.471413] [G loss: 0.447985]\n",
      "[Epoch 68/100] [Batch 143/347] [D loss: 0.466735] [G loss: 0.438670]\n",
      "[Epoch 68/100] [Batch 144/347] [D loss: 0.464466] [G loss: 0.429668]\n",
      "[Epoch 68/100] [Batch 145/347] [D loss: 0.477951] [G loss: 0.429527]\n",
      "[Epoch 68/100] [Batch 146/347] [D loss: 0.491445] [G loss: 0.424926]\n",
      "[Epoch 68/100] [Batch 147/347] [D loss: 0.504020] [G loss: 0.422734]\n",
      "[Epoch 68/100] [Batch 148/347] [D loss: 0.507537] [G loss: 0.425302]\n",
      "[Epoch 68/100] [Batch 149/347] [D loss: 0.479960] [G loss: 0.424158]\n",
      "[Epoch 68/100] [Batch 150/347] [D loss: 0.453052] [G loss: 0.421013]\n",
      "[Epoch 68/100] [Batch 151/347] [D loss: 0.416227] [G loss: 0.411308]\n",
      "[Epoch 68/100] [Batch 152/347] [D loss: 0.366924] [G loss: 0.390863]\n",
      "[Epoch 68/100] [Batch 153/347] [D loss: 0.339189] [G loss: 0.360976]\n",
      "[Epoch 68/100] [Batch 154/347] [D loss: 0.305520] [G loss: 0.329351]\n",
      "[Epoch 68/100] [Batch 155/347] [D loss: 0.290757] [G loss: 0.299954]\n",
      "[Epoch 68/100] [Batch 156/347] [D loss: 0.287820] [G loss: 0.270767]\n",
      "[Epoch 68/100] [Batch 157/347] [D loss: 0.300119] [G loss: 0.254191]\n",
      "[Epoch 68/100] [Batch 158/347] [D loss: 0.313973] [G loss: 0.253882]\n",
      "[Epoch 68/100] [Batch 159/347] [D loss: 0.320471] [G loss: 0.263310]\n",
      "[Epoch 68/100] [Batch 160/347] [D loss: 0.314182] [G loss: 0.287056]\n",
      "[Epoch 68/100] [Batch 161/347] [D loss: 0.285359] [G loss: 0.314608]\n",
      "[Epoch 68/100] [Batch 162/347] [D loss: 0.257744] [G loss: 0.335351]\n",
      "[Epoch 68/100] [Batch 163/347] [D loss: 0.245630] [G loss: 0.356275]\n",
      "[Epoch 68/100] [Batch 164/347] [D loss: 0.233880] [G loss: 0.368347]\n",
      "[Epoch 68/100] [Batch 165/347] [D loss: 0.236432] [G loss: 0.386938]\n",
      "[Epoch 68/100] [Batch 166/347] [D loss: 0.244901] [G loss: 0.400957]\n",
      "[Epoch 68/100] [Batch 167/347] [D loss: 0.282566] [G loss: 0.425563]\n",
      "[Epoch 68/100] [Batch 168/347] [D loss: 0.281523] [G loss: 0.436786]\n",
      "[Epoch 68/100] [Batch 169/347] [D loss: 0.428201] [G loss: 0.445778]\n",
      "[Epoch 68/100] [Batch 170/347] [D loss: 0.498304] [G loss: 0.451458]\n",
      "[Epoch 68/100] [Batch 171/347] [D loss: 0.504540] [G loss: 0.449644]\n",
      "[Epoch 68/100] [Batch 172/347] [D loss: 0.504954] [G loss: 0.448125]\n",
      "[Epoch 68/100] [Batch 173/347] [D loss: 0.503685] [G loss: 0.443594]\n",
      "[Epoch 68/100] [Batch 174/347] [D loss: 0.498735] [G loss: 0.443154]\n",
      "[Epoch 68/100] [Batch 175/347] [D loss: 0.520722] [G loss: 0.443187]\n",
      "[Epoch 68/100] [Batch 176/347] [D loss: 0.534276] [G loss: 0.441586]\n",
      "[Epoch 68/100] [Batch 177/347] [D loss: 0.535444] [G loss: 0.433856]\n",
      "[Epoch 68/100] [Batch 178/347] [D loss: 0.530197] [G loss: 0.423295]\n",
      "[Epoch 68/100] [Batch 179/347] [D loss: 0.527280] [G loss: 0.414711]\n",
      "[Epoch 68/100] [Batch 180/347] [D loss: 0.522934] [G loss: 0.406294]\n",
      "[Epoch 68/100] [Batch 181/347] [D loss: 0.522075] [G loss: 0.404128]\n",
      "[Epoch 68/100] [Batch 182/347] [D loss: 0.525092] [G loss: 0.399566]\n",
      "[Epoch 68/100] [Batch 183/347] [D loss: 0.526714] [G loss: 0.395336]\n",
      "[Epoch 68/100] [Batch 184/347] [D loss: 0.543557] [G loss: 0.393928]\n",
      "[Epoch 68/100] [Batch 185/347] [D loss: 0.544306] [G loss: 0.387822]\n",
      "[Epoch 68/100] [Batch 186/347] [D loss: 0.536748] [G loss: 0.383878]\n",
      "[Epoch 68/100] [Batch 187/347] [D loss: 0.528121] [G loss: 0.379338]\n",
      "[Epoch 68/100] [Batch 188/347] [D loss: 0.497461] [G loss: 0.368858]\n",
      "[Epoch 68/100] [Batch 189/347] [D loss: 0.456408] [G loss: 0.359145]\n",
      "[Epoch 68/100] [Batch 190/347] [D loss: 0.449432] [G loss: 0.351640]\n",
      "[Epoch 68/100] [Batch 191/347] [D loss: 0.451042] [G loss: 0.343377]\n",
      "[Epoch 68/100] [Batch 192/347] [D loss: 0.459592] [G loss: 0.338076]\n",
      "[Epoch 68/100] [Batch 193/347] [D loss: 0.511565] [G loss: 0.334157]\n",
      "[Epoch 68/100] [Batch 194/347] [D loss: 0.506519] [G loss: 0.327529]\n",
      "[Epoch 68/100] [Batch 195/347] [D loss: 0.487435] [G loss: 0.321954]\n",
      "[Epoch 68/100] [Batch 196/347] [D loss: 0.450549] [G loss: 0.317372]\n",
      "[Epoch 68/100] [Batch 197/347] [D loss: 0.447671] [G loss: 0.315801]\n",
      "[Epoch 68/100] [Batch 198/347] [D loss: 0.448642] [G loss: 0.318458]\n",
      "[Epoch 68/100] [Batch 199/347] [D loss: 0.446009] [G loss: 0.319587]\n",
      "[Epoch 68/100] [Batch 200/347] [D loss: 0.494929] [G loss: 0.321450]\n",
      "[Epoch 68/100] [Batch 201/347] [D loss: 0.519367] [G loss: 0.323285]\n",
      "[Epoch 68/100] [Batch 202/347] [D loss: 0.525532] [G loss: 0.326153]\n",
      "[Epoch 68/100] [Batch 203/347] [D loss: 0.548928] [G loss: 0.330658]\n",
      "[Epoch 68/100] [Batch 204/347] [D loss: 0.545115] [G loss: 0.339464]\n",
      "[Epoch 68/100] [Batch 205/347] [D loss: 0.546288] [G loss: 0.350719]\n",
      "[Epoch 68/100] [Batch 206/347] [D loss: 0.546655] [G loss: 0.361198]\n",
      "[Epoch 68/100] [Batch 207/347] [D loss: 0.503328] [G loss: 0.370652]\n",
      "[Epoch 68/100] [Batch 208/347] [D loss: 0.495171] [G loss: 0.379075]\n",
      "[Epoch 68/100] [Batch 209/347] [D loss: 0.482148] [G loss: 0.379198]\n",
      "[Epoch 68/100] [Batch 210/347] [D loss: 0.388619] [G loss: 0.381472]\n",
      "[Epoch 68/100] [Batch 211/347] [D loss: 0.343963] [G loss: 0.379300]\n",
      "[Epoch 68/100] [Batch 212/347] [D loss: 0.229089] [G loss: 0.374015]\n",
      "[Epoch 68/100] [Batch 213/347] [D loss: 0.222590] [G loss: 0.386679]\n",
      "[Epoch 68/100] [Batch 214/347] [D loss: 0.212267] [G loss: 0.401425]\n",
      "[Epoch 68/100] [Batch 215/347] [D loss: 0.206652] [G loss: 0.416420]\n",
      "[Epoch 68/100] [Batch 216/347] [D loss: 0.393995] [G loss: 0.443870]\n",
      "[Epoch 68/100] [Batch 217/347] [D loss: 0.461067] [G loss: 0.463935]\n",
      "[Epoch 68/100] [Batch 218/347] [D loss: 0.501450] [G loss: 0.482952]\n",
      "[Epoch 68/100] [Batch 219/347] [D loss: 0.500199] [G loss: 0.492093]\n",
      "[Epoch 68/100] [Batch 220/347] [D loss: 0.492154] [G loss: 0.497567]\n",
      "[Epoch 68/100] [Batch 221/347] [D loss: 0.510018] [G loss: 0.498317]\n",
      "[Epoch 68/100] [Batch 222/347] [D loss: 0.512312] [G loss: 0.490008]\n",
      "[Epoch 68/100] [Batch 223/347] [D loss: 0.499155] [G loss: 0.470312]\n",
      "[Epoch 68/100] [Batch 224/347] [D loss: 0.503081] [G loss: 0.446760]\n",
      "[Epoch 68/100] [Batch 225/347] [D loss: 0.508456] [G loss: 0.425869]\n",
      "[Epoch 68/100] [Batch 226/347] [D loss: 0.509705] [G loss: 0.411592]\n",
      "[Epoch 68/100] [Batch 227/347] [D loss: 0.523220] [G loss: 0.408054]\n",
      "[Epoch 68/100] [Batch 228/347] [D loss: 0.529804] [G loss: 0.406492]\n",
      "[Epoch 68/100] [Batch 229/347] [D loss: 0.531296] [G loss: 0.405811]\n",
      "[Epoch 68/100] [Batch 230/347] [D loss: 0.537401] [G loss: 0.405207]\n",
      "[Epoch 68/100] [Batch 231/347] [D loss: 0.525692] [G loss: 0.396450]\n",
      "[Epoch 68/100] [Batch 232/347] [D loss: 0.514853] [G loss: 0.391947]\n",
      "[Epoch 68/100] [Batch 233/347] [D loss: 0.450476] [G loss: 0.390965]\n",
      "[Epoch 68/100] [Batch 234/347] [D loss: 0.415297] [G loss: 0.388572]\n",
      "[Epoch 68/100] [Batch 235/347] [D loss: 0.408327] [G loss: 0.391226]\n",
      "[Epoch 68/100] [Batch 236/347] [D loss: 0.402969] [G loss: 0.392688]\n",
      "[Epoch 68/100] [Batch 237/347] [D loss: 0.461612] [G loss: 0.391105]\n",
      "[Epoch 68/100] [Batch 238/347] [D loss: 0.544609] [G loss: 0.385153]\n",
      "[Epoch 68/100] [Batch 239/347] [D loss: 0.545471] [G loss: 0.378481]\n",
      "[Epoch 68/100] [Batch 240/347] [D loss: 0.548416] [G loss: 0.376469]\n",
      "[Epoch 68/100] [Batch 241/347] [D loss: 0.551381] [G loss: 0.379449]\n",
      "[Epoch 68/100] [Batch 242/347] [D loss: 0.565654] [G loss: 0.386519]\n",
      "[Epoch 68/100] [Batch 243/347] [D loss: 0.521020] [G loss: 0.396086]\n",
      "[Epoch 68/100] [Batch 244/347] [D loss: 0.490003] [G loss: 0.394958]\n",
      "[Epoch 68/100] [Batch 245/347] [D loss: 0.491975] [G loss: 0.391096]\n",
      "[Epoch 68/100] [Batch 246/347] [D loss: 0.490709] [G loss: 0.384004]\n",
      "[Epoch 68/100] [Batch 247/347] [D loss: 0.511774] [G loss: 0.380642]\n",
      "[Epoch 68/100] [Batch 248/347] [D loss: 0.528831] [G loss: 0.387962]\n",
      "[Epoch 68/100] [Batch 249/347] [D loss: 0.515345] [G loss: 0.398225]\n",
      "[Epoch 68/100] [Batch 250/347] [D loss: 0.513603] [G loss: 0.411185]\n",
      "[Epoch 68/100] [Batch 251/347] [D loss: 0.508161] [G loss: 0.426901]\n",
      "[Epoch 68/100] [Batch 252/347] [D loss: 0.504526] [G loss: 0.436175]\n",
      "[Epoch 68/100] [Batch 253/347] [D loss: 0.450964] [G loss: 0.430932]\n",
      "[Epoch 68/100] [Batch 254/347] [D loss: 0.445719] [G loss: 0.434484]\n",
      "[Epoch 68/100] [Batch 255/347] [D loss: 0.442614] [G loss: 0.432043]\n",
      "[Epoch 68/100] [Batch 256/347] [D loss: 0.444277] [G loss: 0.419714]\n",
      "[Epoch 68/100] [Batch 257/347] [D loss: 0.434848] [G loss: 0.406329]\n",
      "[Epoch 68/100] [Batch 258/347] [D loss: 0.396378] [G loss: 0.393172]\n",
      "[Epoch 68/100] [Batch 259/347] [D loss: 0.397302] [G loss: 0.379885]\n",
      "[Epoch 68/100] [Batch 260/347] [D loss: 0.398025] [G loss: 0.369165]\n",
      "[Epoch 68/100] [Batch 261/347] [D loss: 0.384878] [G loss: 0.364927]\n",
      "[Epoch 68/100] [Batch 262/347] [D loss: 0.341641] [G loss: 0.360338]\n",
      "[Epoch 68/100] [Batch 263/347] [D loss: 0.338179] [G loss: 0.358900]\n",
      "[Epoch 68/100] [Batch 264/347] [D loss: 0.343136] [G loss: 0.362945]\n",
      "[Epoch 68/100] [Batch 265/347] [D loss: 0.349914] [G loss: 0.368066]\n",
      "[Epoch 68/100] [Batch 266/347] [D loss: 0.415447] [G loss: 0.375759]\n",
      "[Epoch 68/100] [Batch 267/347] [D loss: 0.433001] [G loss: 0.381824]\n",
      "[Epoch 68/100] [Batch 268/347] [D loss: 0.443367] [G loss: 0.385848]\n",
      "[Epoch 68/100] [Batch 269/347] [D loss: 0.445694] [G loss: 0.388506]\n",
      "[Epoch 68/100] [Batch 270/347] [D loss: 0.476946] [G loss: 0.390284]\n",
      "[Epoch 68/100] [Batch 271/347] [D loss: 0.443760] [G loss: 0.397687]\n",
      "[Epoch 68/100] [Batch 272/347] [D loss: 0.414088] [G loss: 0.426997]\n",
      "[Epoch 68/100] [Batch 273/347] [D loss: 0.367132] [G loss: 0.455141]\n",
      "[Epoch 68/100] [Batch 274/347] [D loss: 0.298234] [G loss: 0.476665]\n",
      "[Epoch 68/100] [Batch 275/347] [D loss: 0.245905] [G loss: 0.490908]\n",
      "[Epoch 68/100] [Batch 276/347] [D loss: 0.499295] [G loss: 0.498304]\n",
      "[Epoch 68/100] [Batch 277/347] [D loss: 0.522117] [G loss: 0.509457]\n",
      "[Epoch 68/100] [Batch 278/347] [D loss: 0.527594] [G loss: 0.519403]\n",
      "[Epoch 68/100] [Batch 279/347] [D loss: 0.530068] [G loss: 0.521066]\n",
      "[Epoch 68/100] [Batch 280/347] [D loss: 0.532905] [G loss: 0.521163]\n",
      "[Epoch 68/100] [Batch 281/347] [D loss: 0.536135] [G loss: 0.521478]\n",
      "[Epoch 68/100] [Batch 282/347] [D loss: 0.537528] [G loss: 0.524586]\n",
      "[Epoch 68/100] [Batch 283/347] [D loss: 0.538531] [G loss: 0.525948]\n",
      "[Epoch 68/100] [Batch 284/347] [D loss: 0.539515] [G loss: 0.528229]\n",
      "[Epoch 68/100] [Batch 285/347] [D loss: 0.542239] [G loss: 0.529221]\n",
      "[Epoch 68/100] [Batch 286/347] [D loss: 0.540883] [G loss: 0.515325]\n",
      "[Epoch 68/100] [Batch 287/347] [D loss: 0.541397] [G loss: 0.512737]\n",
      "[Epoch 68/100] [Batch 288/347] [D loss: 0.541695] [G loss: 0.510203]\n",
      "[Epoch 68/100] [Batch 289/347] [D loss: 0.540926] [G loss: 0.505371]\n",
      "[Epoch 68/100] [Batch 290/347] [D loss: 0.541398] [G loss: 0.521314]\n",
      "[Epoch 68/100] [Batch 291/347] [D loss: 0.540597] [G loss: 0.528501]\n",
      "[Epoch 68/100] [Batch 292/347] [D loss: 0.539037] [G loss: 0.532661]\n",
      "[Epoch 68/100] [Batch 293/347] [D loss: 0.522282] [G loss: 0.538480]\n",
      "[Epoch 68/100] [Batch 294/347] [D loss: 0.522019] [G loss: 0.543316]\n",
      "[Epoch 68/100] [Batch 295/347] [D loss: 0.521930] [G loss: 0.542655]\n",
      "[Epoch 68/100] [Batch 296/347] [D loss: 0.521501] [G loss: 0.541585]\n",
      "[Epoch 68/100] [Batch 297/347] [D loss: 0.538992] [G loss: 0.546600]\n",
      "[Epoch 68/100] [Batch 298/347] [D loss: 0.541607] [G loss: 0.540488]\n",
      "[Epoch 68/100] [Batch 299/347] [D loss: 0.540827] [G loss: 0.536355]\n",
      "[Epoch 68/100] [Batch 300/347] [D loss: 0.539922] [G loss: 0.534602]\n",
      "[Epoch 68/100] [Batch 301/347] [D loss: 0.540016] [G loss: 0.518071]\n",
      "[Epoch 68/100] [Batch 302/347] [D loss: 0.540350] [G loss: 0.511314]\n",
      "[Epoch 68/100] [Batch 303/347] [D loss: 0.539831] [G loss: 0.500568]\n",
      "[Epoch 68/100] [Batch 304/347] [D loss: 0.526501] [G loss: 0.488910]\n",
      "[Epoch 68/100] [Batch 305/347] [D loss: 0.515627] [G loss: 0.482128]\n",
      "[Epoch 68/100] [Batch 306/347] [D loss: 0.514730] [G loss: 0.482324]\n",
      "[Epoch 68/100] [Batch 307/347] [D loss: 0.513049] [G loss: 0.488557]\n",
      "[Epoch 68/100] [Batch 308/347] [D loss: 0.519612] [G loss: 0.494757]\n",
      "[Epoch 68/100] [Batch 309/347] [D loss: 0.536750] [G loss: 0.509364]\n",
      "[Epoch 68/100] [Batch 310/347] [D loss: 0.543781] [G loss: 0.521788]\n",
      "[Epoch 68/100] [Batch 311/347] [D loss: 0.541332] [G loss: 0.519387]\n",
      "[Epoch 68/100] [Batch 312/347] [D loss: 0.536155] [G loss: 0.514258]\n",
      "[Epoch 68/100] [Batch 313/347] [D loss: 0.532305] [G loss: 0.505090]\n",
      "[Epoch 68/100] [Batch 314/347] [D loss: 0.531423] [G loss: 0.490384]\n",
      "[Epoch 68/100] [Batch 315/347] [D loss: 0.531305] [G loss: 0.479096]\n",
      "[Epoch 68/100] [Batch 316/347] [D loss: 0.532000] [G loss: 0.480196]\n",
      "[Epoch 68/100] [Batch 317/347] [D loss: 0.533396] [G loss: 0.483741]\n",
      "[Epoch 68/100] [Batch 318/347] [D loss: 0.533662] [G loss: 0.496971]\n",
      "[Epoch 68/100] [Batch 319/347] [D loss: 0.531812] [G loss: 0.509086]\n",
      "[Epoch 68/100] [Batch 320/347] [D loss: 0.530720] [G loss: 0.507354]\n",
      "[Epoch 68/100] [Batch 321/347] [D loss: 0.528226] [G loss: 0.500502]\n",
      "[Epoch 68/100] [Batch 322/347] [D loss: 0.528328] [G loss: 0.492731]\n",
      "[Epoch 68/100] [Batch 323/347] [D loss: 0.521201] [G loss: 0.483738]\n",
      "[Epoch 68/100] [Batch 324/347] [D loss: 0.519386] [G loss: 0.477519]\n",
      "[Epoch 68/100] [Batch 325/347] [D loss: 0.518964] [G loss: 0.470238]\n",
      "[Epoch 68/100] [Batch 326/347] [D loss: 0.518450] [G loss: 0.463616]\n",
      "[Epoch 68/100] [Batch 327/347] [D loss: 0.515405] [G loss: 0.458804]\n",
      "[Epoch 68/100] [Batch 328/347] [D loss: 0.515203] [G loss: 0.453121]\n",
      "[Epoch 68/100] [Batch 329/347] [D loss: 0.514029] [G loss: 0.450571]\n",
      "[Epoch 68/100] [Batch 330/347] [D loss: 0.512601] [G loss: 0.449568]\n",
      "[Epoch 68/100] [Batch 331/347] [D loss: 0.515064] [G loss: 0.451443]\n",
      "[Epoch 68/100] [Batch 332/347] [D loss: 0.523688] [G loss: 0.470075]\n",
      "[Epoch 68/100] [Batch 333/347] [D loss: 0.519575] [G loss: 0.466957]\n",
      "[Epoch 68/100] [Batch 334/347] [D loss: 0.517666] [G loss: 0.458759]\n",
      "[Epoch 68/100] [Batch 335/347] [D loss: 0.516799] [G loss: 0.455219]\n",
      "[Epoch 68/100] [Batch 336/347] [D loss: 0.516171] [G loss: 0.452338]\n",
      "[Epoch 68/100] [Batch 337/347] [D loss: 0.520087] [G loss: 0.454996]\n",
      "[Epoch 68/100] [Batch 338/347] [D loss: 0.524272] [G loss: 0.461337]\n",
      "[Epoch 68/100] [Batch 339/347] [D loss: 0.520371] [G loss: 0.460181]\n",
      "[Epoch 68/100] [Batch 340/347] [D loss: 0.516371] [G loss: 0.455032]\n",
      "[Epoch 68/100] [Batch 341/347] [D loss: 0.516279] [G loss: 0.453646]\n",
      "[Epoch 68/100] [Batch 342/347] [D loss: 0.495339] [G loss: 0.439666]\n",
      "[Epoch 68/100] [Batch 343/347] [D loss: 0.489510] [G loss: 0.422570]\n",
      "[Epoch 68/100] [Batch 344/347] [D loss: 0.460179] [G loss: 0.417061]\n",
      "[Epoch 68/100] [Batch 345/347] [D loss: 0.387067] [G loss: 0.412406]\n",
      "[Epoch 68/100] [Batch 346/347] [D loss: 0.374905] [G loss: 0.408789]\n",
      "[Epoch 68/100] [Batch 347/347] [D loss: 0.353118] [G loss: 0.404661]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 1/347] [D loss: 0.505951] [G loss: 0.412538]\n",
      "[Epoch 69/100] [Batch 2/347] [D loss: 0.507310] [G loss: 0.408241]\n",
      "[Epoch 69/100] [Batch 3/347] [D loss: 0.513112] [G loss: 0.407941]\n",
      "[Epoch 69/100] [Batch 4/347] [D loss: 0.512914] [G loss: 0.403853]\n",
      "[Epoch 69/100] [Batch 5/347] [D loss: 0.511735] [G loss: 0.396104]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 6/347] [D loss: 0.504178] [G loss: 0.389043]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 7/347] [D loss: 0.493915] [G loss: 0.376347]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 8/347] [D loss: 0.490048] [G loss: 0.370593]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 9/347] [D loss: 0.487293] [G loss: 0.366970]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 10/347] [D loss: 0.484489] [G loss: 0.363138]\n",
      "[Epoch 69/100] [Batch 11/347] [D loss: 0.500463] [G loss: 0.367248]\n",
      "[Epoch 69/100] [Batch 12/347] [D loss: 0.502637] [G loss: 0.364049]\n",
      "[Epoch 69/100] [Batch 13/347] [D loss: 0.487865] [G loss: 0.357350]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 14/347] [D loss: 0.474487] [G loss: 0.349886]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 15/347] [D loss: 0.465402] [G loss: 0.332355]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 16/347] [D loss: 0.454837] [G loss: 0.316930]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 17/347] [D loss: 0.452389] [G loss: 0.308240]\n",
      "[Epoch 69/100] [Batch 18/347] [D loss: 0.455047] [G loss: 0.296110]\n",
      "[Epoch 69/100] [Batch 19/347] [D loss: 0.457244] [G loss: 0.288766]\n",
      "[Epoch 69/100] [Batch 20/347] [D loss: 0.477075] [G loss: 0.280605]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 21/347] [D loss: 0.426178] [G loss: 0.265050]\n",
      "[Epoch 69/100] [Batch 22/347] [D loss: 0.430137] [G loss: 0.254844]\n",
      "[Epoch 69/100] [Batch 23/347] [D loss: 0.431952] [G loss: 0.247036]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 69/100] [Batch 24/347] [D loss: 0.401867] [G loss: 0.239567]\n",
      "[Epoch 69/100] [Batch 25/347] [D loss: 0.330768] [G loss: 0.252715]\n",
      "[Epoch 69/100] [Batch 26/347] [D loss: 0.326141] [G loss: 0.265475]\n",
      "[Epoch 69/100] [Batch 27/347] [D loss: 0.314840] [G loss: 0.286176]\n",
      "[Epoch 69/100] [Batch 28/347] [D loss: 0.306705] [G loss: 0.308515]\n",
      "[Epoch 69/100] [Batch 29/347] [D loss: 0.319883] [G loss: 0.326694]\n",
      "[Epoch 69/100] [Batch 30/347] [D loss: 0.308308] [G loss: 0.339392]\n",
      "[Epoch 69/100] [Batch 31/347] [D loss: 0.308424] [G loss: 0.347906]\n",
      "[Epoch 69/100] [Batch 32/347] [D loss: 0.321546] [G loss: 0.350165]\n",
      "[Epoch 69/100] [Batch 33/347] [D loss: 0.341819] [G loss: 0.351451]\n",
      "[Epoch 69/100] [Batch 34/347] [D loss: 0.386228] [G loss: 0.347796]\n",
      "[Epoch 69/100] [Batch 35/347] [D loss: 0.383026] [G loss: 0.340488]\n",
      "[Epoch 69/100] [Batch 36/347] [D loss: 0.400726] [G loss: 0.330098]\n",
      "[Epoch 69/100] [Batch 37/347] [D loss: 0.402707] [G loss: 0.315679]\n",
      "[Epoch 69/100] [Batch 38/347] [D loss: 0.399613] [G loss: 0.297442]\n",
      "[Epoch 69/100] [Batch 39/347] [D loss: 0.407429] [G loss: 0.285090]\n",
      "[Epoch 69/100] [Batch 40/347] [D loss: 0.434550] [G loss: 0.278996]\n",
      "[Epoch 69/100] [Batch 41/347] [D loss: 0.448333] [G loss: 0.269462]\n",
      "[Epoch 69/100] [Batch 42/347] [D loss: 0.446564] [G loss: 0.266613]\n",
      "[Epoch 69/100] [Batch 43/347] [D loss: 0.470273] [G loss: 0.272145]\n",
      "[Epoch 69/100] [Batch 44/347] [D loss: 0.463452] [G loss: 0.271093]\n",
      "[Epoch 69/100] [Batch 45/347] [D loss: 0.440536] [G loss: 0.260391]\n",
      "[Epoch 69/100] [Batch 46/347] [D loss: 0.376704] [G loss: 0.257277]\n",
      "[Epoch 69/100] [Batch 47/347] [D loss: 0.367632] [G loss: 0.259402]\n",
      "[Epoch 69/100] [Batch 48/347] [D loss: 0.314819] [G loss: 0.278631]\n",
      "[Epoch 69/100] [Batch 49/347] [D loss: 0.287339] [G loss: 0.309269]\n",
      "[Epoch 69/100] [Batch 50/347] [D loss: 0.256894] [G loss: 0.341481]\n",
      "[Epoch 69/100] [Batch 51/347] [D loss: 0.235966] [G loss: 0.363048]\n",
      "[Epoch 69/100] [Batch 52/347] [D loss: 0.319590] [G loss: 0.369652]\n",
      "[Epoch 69/100] [Batch 53/347] [D loss: 0.370216] [G loss: 0.363797]\n",
      "[Epoch 69/100] [Batch 54/347] [D loss: 0.362281] [G loss: 0.355941]\n",
      "[Epoch 69/100] [Batch 55/347] [D loss: 0.362957] [G loss: 0.360416]\n",
      "[Epoch 69/100] [Batch 56/347] [D loss: 0.353594] [G loss: 0.367883]\n",
      "[Epoch 69/100] [Batch 57/347] [D loss: 0.308678] [G loss: 0.373387]\n",
      "[Epoch 69/100] [Batch 58/347] [D loss: 0.311311] [G loss: 0.374019]\n",
      "[Epoch 69/100] [Batch 59/347] [D loss: 0.300587] [G loss: 0.364214]\n",
      "[Epoch 69/100] [Batch 60/347] [D loss: 0.279934] [G loss: 0.343840]\n",
      "[Epoch 69/100] [Batch 61/347] [D loss: 0.289471] [G loss: 0.322872]\n",
      "[Epoch 69/100] [Batch 62/347] [D loss: 0.287437] [G loss: 0.310462]\n",
      "[Epoch 69/100] [Batch 63/347] [D loss: 0.286605] [G loss: 0.303935]\n",
      "[Epoch 69/100] [Batch 64/347] [D loss: 0.279079] [G loss: 0.298896]\n",
      "[Epoch 69/100] [Batch 65/347] [D loss: 0.254714] [G loss: 0.305508]\n",
      "[Epoch 69/100] [Batch 66/347] [D loss: 0.254438] [G loss: 0.310640]\n",
      "[Epoch 69/100] [Batch 67/347] [D loss: 0.247219] [G loss: 0.308968]\n",
      "[Epoch 69/100] [Batch 68/347] [D loss: 0.238886] [G loss: 0.316221]\n",
      "[Epoch 69/100] [Batch 69/347] [D loss: 0.241697] [G loss: 0.342532]\n",
      "[Epoch 69/100] [Batch 70/347] [D loss: 0.239747] [G loss: 0.352266]\n",
      "[Epoch 69/100] [Batch 71/347] [D loss: 0.236323] [G loss: 0.347540]\n",
      "[Epoch 69/100] [Batch 72/347] [D loss: 0.249365] [G loss: 0.362541]\n",
      "[Epoch 69/100] [Batch 73/347] [D loss: 0.352075] [G loss: 0.361429]\n",
      "[Epoch 69/100] [Batch 74/347] [D loss: 0.356045] [G loss: 0.363633]\n",
      "[Epoch 69/100] [Batch 75/347] [D loss: 0.354552] [G loss: 0.363420]\n",
      "[Epoch 69/100] [Batch 76/347] [D loss: 0.350839] [G loss: 0.359648]\n",
      "[Epoch 69/100] [Batch 77/347] [D loss: 0.384836] [G loss: 0.355340]\n",
      "[Epoch 69/100] [Batch 78/347] [D loss: 0.438758] [G loss: 0.359562]\n",
      "[Epoch 69/100] [Batch 79/347] [D loss: 0.434267] [G loss: 0.351217]\n",
      "[Epoch 69/100] [Batch 80/347] [D loss: 0.335691] [G loss: 0.329243]\n",
      "[Epoch 69/100] [Batch 81/347] [D loss: 0.317926] [G loss: 0.318351]\n",
      "[Epoch 69/100] [Batch 82/347] [D loss: 0.322377] [G loss: 0.311204]\n",
      "[Epoch 69/100] [Batch 83/347] [D loss: 0.328067] [G loss: 0.304937]\n",
      "[Epoch 69/100] [Batch 84/347] [D loss: 0.443473] [G loss: 0.305951]\n",
      "[Epoch 69/100] [Batch 85/347] [D loss: 0.507799] [G loss: 0.304386]\n",
      "[Epoch 69/100] [Batch 86/347] [D loss: 0.509473] [G loss: 0.303270]\n",
      "[Epoch 69/100] [Batch 87/347] [D loss: 0.510313] [G loss: 0.304237]\n",
      "[Epoch 69/100] [Batch 88/347] [D loss: 0.527485] [G loss: 0.306153]\n",
      "[Epoch 69/100] [Batch 89/347] [D loss: 0.537485] [G loss: 0.311245]\n",
      "[Epoch 69/100] [Batch 90/347] [D loss: 0.535436] [G loss: 0.313537]\n",
      "[Epoch 69/100] [Batch 91/347] [D loss: 0.534577] [G loss: 0.316278]\n",
      "[Epoch 69/100] [Batch 92/347] [D loss: 0.535076] [G loss: 0.320659]\n",
      "[Epoch 69/100] [Batch 93/347] [D loss: 0.534130] [G loss: 0.326192]\n",
      "[Epoch 69/100] [Batch 94/347] [D loss: 0.519452] [G loss: 0.327514]\n",
      "[Epoch 69/100] [Batch 95/347] [D loss: 0.512109] [G loss: 0.331582]\n",
      "[Epoch 69/100] [Batch 96/347] [D loss: 0.513913] [G loss: 0.337602]\n",
      "[Epoch 69/100] [Batch 97/347] [D loss: 0.509563] [G loss: 0.341863]\n",
      "[Epoch 69/100] [Batch 98/347] [D loss: 0.502713] [G loss: 0.347020]\n",
      "[Epoch 69/100] [Batch 99/347] [D loss: 0.512673] [G loss: 0.350638]\n",
      "[Epoch 69/100] [Batch 100/347] [D loss: 0.514059] [G loss: 0.353838]\n",
      "[Epoch 69/100] [Batch 101/347] [D loss: 0.519164] [G loss: 0.354721]\n",
      "[Epoch 69/100] [Batch 102/347] [D loss: 0.543698] [G loss: 0.355802]\n",
      "[Epoch 69/100] [Batch 103/347] [D loss: 0.546350] [G loss: 0.361793]\n",
      "[Epoch 69/100] [Batch 104/347] [D loss: 0.531636] [G loss: 0.362833]\n",
      "[Epoch 69/100] [Batch 105/347] [D loss: 0.450153] [G loss: 0.363459]\n",
      "[Epoch 69/100] [Batch 106/347] [D loss: 0.233903] [G loss: 0.367753]\n",
      "[Epoch 69/100] [Batch 107/347] [D loss: 0.225632] [G loss: 0.384405]\n",
      "[Epoch 69/100] [Batch 108/347] [D loss: 0.208908] [G loss: 0.402235]\n",
      "[Epoch 69/100] [Batch 109/347] [D loss: 0.198933] [G loss: 0.420415]\n",
      "[Epoch 69/100] [Batch 110/347] [D loss: 0.223365] [G loss: 0.429838]\n",
      "[Epoch 69/100] [Batch 111/347] [D loss: 0.224680] [G loss: 0.442972]\n",
      "[Epoch 69/100] [Batch 112/347] [D loss: 0.233792] [G loss: 0.452346]\n",
      "[Epoch 69/100] [Batch 113/347] [D loss: 0.421026] [G loss: 0.474152]\n",
      "[Epoch 69/100] [Batch 114/347] [D loss: 0.503037] [G loss: 0.482842]\n",
      "[Epoch 69/100] [Batch 115/347] [D loss: 0.497456] [G loss: 0.466935]\n",
      "[Epoch 69/100] [Batch 116/347] [D loss: 0.455111] [G loss: 0.449031]\n",
      "[Epoch 69/100] [Batch 117/347] [D loss: 0.449249] [G loss: 0.434817]\n",
      "[Epoch 69/100] [Batch 118/347] [D loss: 0.385576] [G loss: 0.417133]\n",
      "[Epoch 69/100] [Batch 119/347] [D loss: 0.369816] [G loss: 0.406678]\n",
      "[Epoch 69/100] [Batch 120/347] [D loss: 0.349062] [G loss: 0.398438]\n",
      "[Epoch 69/100] [Batch 121/347] [D loss: 0.333352] [G loss: 0.379026]\n",
      "[Epoch 69/100] [Batch 122/347] [D loss: 0.443130] [G loss: 0.361699]\n",
      "[Epoch 69/100] [Batch 123/347] [D loss: 0.488556] [G loss: 0.344087]\n",
      "[Epoch 69/100] [Batch 124/347] [D loss: 0.420441] [G loss: 0.324820]\n",
      "[Epoch 69/100] [Batch 125/347] [D loss: 0.392177] [G loss: 0.314591]\n",
      "[Epoch 69/100] [Batch 126/347] [D loss: 0.367842] [G loss: 0.309536]\n",
      "[Epoch 69/100] [Batch 127/347] [D loss: 0.373834] [G loss: 0.305657]\n",
      "[Epoch 69/100] [Batch 128/347] [D loss: 0.367148] [G loss: 0.303294]\n",
      "[Epoch 69/100] [Batch 129/347] [D loss: 0.337755] [G loss: 0.310136]\n",
      "[Epoch 69/100] [Batch 130/347] [D loss: 0.318024] [G loss: 0.342650]\n",
      "[Epoch 69/100] [Batch 131/347] [D loss: 0.283519] [G loss: 0.375888]\n",
      "[Epoch 69/100] [Batch 132/347] [D loss: 0.236266] [G loss: 0.412464]\n",
      "[Epoch 69/100] [Batch 133/347] [D loss: 0.216543] [G loss: 0.441738]\n",
      "[Epoch 69/100] [Batch 134/347] [D loss: 0.180229] [G loss: 0.461620]\n",
      "[Epoch 69/100] [Batch 135/347] [D loss: 0.164514] [G loss: 0.473257]\n",
      "[Epoch 69/100] [Batch 136/347] [D loss: 0.158489] [G loss: 0.475648]\n",
      "[Epoch 69/100] [Batch 137/347] [D loss: 0.423728] [G loss: 0.474081]\n",
      "[Epoch 69/100] [Batch 138/347] [D loss: 0.457759] [G loss: 0.469615]\n",
      "[Epoch 69/100] [Batch 139/347] [D loss: 0.476552] [G loss: 0.461201]\n",
      "[Epoch 69/100] [Batch 140/347] [D loss: 0.479048] [G loss: 0.460849]\n",
      "[Epoch 69/100] [Batch 141/347] [D loss: 0.459874] [G loss: 0.455218]\n",
      "[Epoch 69/100] [Batch 142/347] [D loss: 0.471055] [G loss: 0.449051]\n",
      "[Epoch 69/100] [Batch 143/347] [D loss: 0.468855] [G loss: 0.440314]\n",
      "[Epoch 69/100] [Batch 144/347] [D loss: 0.469131] [G loss: 0.432002]\n",
      "[Epoch 69/100] [Batch 145/347] [D loss: 0.483942] [G loss: 0.432466]\n",
      "[Epoch 69/100] [Batch 146/347] [D loss: 0.498364] [G loss: 0.428767]\n",
      "[Epoch 69/100] [Batch 147/347] [D loss: 0.511158] [G loss: 0.427500]\n",
      "[Epoch 69/100] [Batch 148/347] [D loss: 0.515196] [G loss: 0.431064]\n",
      "[Epoch 69/100] [Batch 149/347] [D loss: 0.494908] [G loss: 0.431759]\n",
      "[Epoch 69/100] [Batch 150/347] [D loss: 0.477755] [G loss: 0.431017]\n",
      "[Epoch 69/100] [Batch 151/347] [D loss: 0.454491] [G loss: 0.425943]\n",
      "[Epoch 69/100] [Batch 152/347] [D loss: 0.420427] [G loss: 0.413394]\n",
      "[Epoch 69/100] [Batch 153/347] [D loss: 0.397659] [G loss: 0.396461]\n",
      "[Epoch 69/100] [Batch 154/347] [D loss: 0.357293] [G loss: 0.379499]\n",
      "[Epoch 69/100] [Batch 155/347] [D loss: 0.317011] [G loss: 0.361363]\n",
      "[Epoch 69/100] [Batch 156/347] [D loss: 0.284191] [G loss: 0.332911]\n",
      "[Epoch 69/100] [Batch 157/347] [D loss: 0.269662] [G loss: 0.305694]\n",
      "[Epoch 69/100] [Batch 158/347] [D loss: 0.258947] [G loss: 0.289039]\n",
      "[Epoch 69/100] [Batch 159/347] [D loss: 0.281475] [G loss: 0.275791]\n",
      "[Epoch 69/100] [Batch 160/347] [D loss: 0.298578] [G loss: 0.279045]\n",
      "[Epoch 69/100] [Batch 161/347] [D loss: 0.292320] [G loss: 0.286032]\n",
      "[Epoch 69/100] [Batch 162/347] [D loss: 0.280932] [G loss: 0.292458]\n",
      "[Epoch 69/100] [Batch 163/347] [D loss: 0.272394] [G loss: 0.306363]\n",
      "[Epoch 69/100] [Batch 164/347] [D loss: 0.256907] [G loss: 0.317729]\n",
      "[Epoch 69/100] [Batch 165/347] [D loss: 0.246472] [G loss: 0.343207]\n",
      "[Epoch 69/100] [Batch 166/347] [D loss: 0.240227] [G loss: 0.364747]\n",
      "[Epoch 69/100] [Batch 167/347] [D loss: 0.261471] [G loss: 0.399119]\n",
      "[Epoch 69/100] [Batch 168/347] [D loss: 0.257594] [G loss: 0.417960]\n",
      "[Epoch 69/100] [Batch 169/347] [D loss: 0.407764] [G loss: 0.432331]\n",
      "[Epoch 69/100] [Batch 170/347] [D loss: 0.485830] [G loss: 0.442301]\n",
      "[Epoch 69/100] [Batch 171/347] [D loss: 0.495747] [G loss: 0.443762]\n",
      "[Epoch 69/100] [Batch 172/347] [D loss: 0.498838] [G loss: 0.445414]\n",
      "[Epoch 69/100] [Batch 173/347] [D loss: 0.499933] [G loss: 0.443511]\n",
      "[Epoch 69/100] [Batch 174/347] [D loss: 0.496493] [G loss: 0.445713]\n",
      "[Epoch 69/100] [Batch 175/347] [D loss: 0.521050] [G loss: 0.448255]\n",
      "[Epoch 69/100] [Batch 176/347] [D loss: 0.534730] [G loss: 0.449706]\n",
      "[Epoch 69/100] [Batch 177/347] [D loss: 0.535937] [G loss: 0.445284]\n",
      "[Epoch 69/100] [Batch 178/347] [D loss: 0.531322] [G loss: 0.437527]\n",
      "[Epoch 69/100] [Batch 179/347] [D loss: 0.529418] [G loss: 0.432654]\n",
      "[Epoch 69/100] [Batch 180/347] [D loss: 0.525949] [G loss: 0.426955]\n",
      "[Epoch 69/100] [Batch 181/347] [D loss: 0.525601] [G loss: 0.427422]\n",
      "[Epoch 69/100] [Batch 182/347] [D loss: 0.527752] [G loss: 0.426576]\n",
      "[Epoch 69/100] [Batch 183/347] [D loss: 0.529060] [G loss: 0.426164]\n",
      "[Epoch 69/100] [Batch 184/347] [D loss: 0.540614] [G loss: 0.427519]\n",
      "[Epoch 69/100] [Batch 185/347] [D loss: 0.541488] [G loss: 0.424215]\n",
      "[Epoch 69/100] [Batch 186/347] [D loss: 0.535581] [G loss: 0.422606]\n",
      "[Epoch 69/100] [Batch 187/347] [D loss: 0.529882] [G loss: 0.419696]\n",
      "[Epoch 69/100] [Batch 188/347] [D loss: 0.506209] [G loss: 0.410889]\n",
      "[Epoch 69/100] [Batch 189/347] [D loss: 0.470854] [G loss: 0.401477]\n",
      "[Epoch 69/100] [Batch 190/347] [D loss: 0.463745] [G loss: 0.394027]\n",
      "[Epoch 69/100] [Batch 191/347] [D loss: 0.462434] [G loss: 0.384028]\n",
      "[Epoch 69/100] [Batch 192/347] [D loss: 0.465387] [G loss: 0.374674]\n",
      "[Epoch 69/100] [Batch 193/347] [D loss: 0.509835] [G loss: 0.365764]\n",
      "[Epoch 69/100] [Batch 194/347] [D loss: 0.505125] [G loss: 0.354038]\n",
      "[Epoch 69/100] [Batch 195/347] [D loss: 0.485768] [G loss: 0.341415]\n",
      "[Epoch 69/100] [Batch 196/347] [D loss: 0.446194] [G loss: 0.329619]\n",
      "[Epoch 69/100] [Batch 197/347] [D loss: 0.442993] [G loss: 0.320357]\n",
      "[Epoch 69/100] [Batch 198/347] [D loss: 0.442606] [G loss: 0.314828]\n",
      "[Epoch 69/100] [Batch 199/347] [D loss: 0.440560] [G loss: 0.307804]\n",
      "[Epoch 69/100] [Batch 200/347] [D loss: 0.489495] [G loss: 0.303142]\n",
      "[Epoch 69/100] [Batch 201/347] [D loss: 0.515425] [G loss: 0.299993]\n",
      "[Epoch 69/100] [Batch 202/347] [D loss: 0.522323] [G loss: 0.297878]\n",
      "[Epoch 69/100] [Batch 203/347] [D loss: 0.548136] [G loss: 0.297685]\n",
      "[Epoch 69/100] [Batch 204/347] [D loss: 0.543951] [G loss: 0.303883]\n",
      "[Epoch 69/100] [Batch 205/347] [D loss: 0.544906] [G loss: 0.311488]\n",
      "[Epoch 69/100] [Batch 206/347] [D loss: 0.545380] [G loss: 0.319283]\n",
      "[Epoch 69/100] [Batch 207/347] [D loss: 0.496136] [G loss: 0.326556]\n",
      "[Epoch 69/100] [Batch 208/347] [D loss: 0.485870] [G loss: 0.335819]\n",
      "[Epoch 69/100] [Batch 209/347] [D loss: 0.472784] [G loss: 0.337647]\n",
      "[Epoch 69/100] [Batch 210/347] [D loss: 0.382650] [G loss: 0.343733]\n",
      "[Epoch 69/100] [Batch 211/347] [D loss: 0.347888] [G loss: 0.347929]\n",
      "[Epoch 69/100] [Batch 212/347] [D loss: 0.255807] [G loss: 0.349242]\n",
      "[Epoch 69/100] [Batch 213/347] [D loss: 0.239583] [G loss: 0.364183]\n",
      "[Epoch 69/100] [Batch 214/347] [D loss: 0.221240] [G loss: 0.385312]\n",
      "[Epoch 69/100] [Batch 215/347] [D loss: 0.208752] [G loss: 0.407568]\n",
      "[Epoch 69/100] [Batch 216/347] [D loss: 0.385163] [G loss: 0.440624]\n",
      "[Epoch 69/100] [Batch 217/347] [D loss: 0.455901] [G loss: 0.463570]\n",
      "[Epoch 69/100] [Batch 218/347] [D loss: 0.498463] [G loss: 0.484272]\n",
      "[Epoch 69/100] [Batch 219/347] [D loss: 0.498537] [G loss: 0.495004]\n",
      "[Epoch 69/100] [Batch 220/347] [D loss: 0.492790] [G loss: 0.501634]\n",
      "[Epoch 69/100] [Batch 221/347] [D loss: 0.510526] [G loss: 0.503610]\n",
      "[Epoch 69/100] [Batch 222/347] [D loss: 0.513276] [G loss: 0.496516]\n",
      "[Epoch 69/100] [Batch 223/347] [D loss: 0.503348] [G loss: 0.478509]\n",
      "[Epoch 69/100] [Batch 224/347] [D loss: 0.507475] [G loss: 0.456827]\n",
      "[Epoch 69/100] [Batch 225/347] [D loss: 0.512045] [G loss: 0.438139]\n",
      "[Epoch 69/100] [Batch 226/347] [D loss: 0.513195] [G loss: 0.426955]\n",
      "[Epoch 69/100] [Batch 227/347] [D loss: 0.523192] [G loss: 0.425799]\n",
      "[Epoch 69/100] [Batch 228/347] [D loss: 0.527125] [G loss: 0.426997]\n",
      "[Epoch 69/100] [Batch 229/347] [D loss: 0.526959] [G loss: 0.427971]\n",
      "[Epoch 69/100] [Batch 230/347] [D loss: 0.530349] [G loss: 0.427952]\n",
      "[Epoch 69/100] [Batch 231/347] [D loss: 0.520833] [G loss: 0.419650]\n",
      "[Epoch 69/100] [Batch 232/347] [D loss: 0.512354] [G loss: 0.415045]\n",
      "[Epoch 69/100] [Batch 233/347] [D loss: 0.454137] [G loss: 0.413597]\n",
      "[Epoch 69/100] [Batch 234/347] [D loss: 0.416636] [G loss: 0.409125]\n",
      "[Epoch 69/100] [Batch 235/347] [D loss: 0.405559] [G loss: 0.409208]\n",
      "[Epoch 69/100] [Batch 236/347] [D loss: 0.392874] [G loss: 0.406431]\n",
      "[Epoch 69/100] [Batch 237/347] [D loss: 0.444286] [G loss: 0.398154]\n",
      "[Epoch 69/100] [Batch 238/347] [D loss: 0.525518] [G loss: 0.384164]\n",
      "[Epoch 69/100] [Batch 239/347] [D loss: 0.525115] [G loss: 0.368534]\n",
      "[Epoch 69/100] [Batch 240/347] [D loss: 0.527817] [G loss: 0.356810]\n",
      "[Epoch 69/100] [Batch 241/347] [D loss: 0.531593] [G loss: 0.348858]\n",
      "[Epoch 69/100] [Batch 242/347] [D loss: 0.550860] [G loss: 0.345533]\n",
      "[Epoch 69/100] [Batch 243/347] [D loss: 0.506497] [G loss: 0.343937]\n",
      "[Epoch 69/100] [Batch 244/347] [D loss: 0.470480] [G loss: 0.334428]\n",
      "[Epoch 69/100] [Batch 245/347] [D loss: 0.472677] [G loss: 0.324140]\n",
      "[Epoch 69/100] [Batch 246/347] [D loss: 0.469071] [G loss: 0.312959]\n",
      "[Epoch 69/100] [Batch 247/347] [D loss: 0.492075] [G loss: 0.307467]\n",
      "[Epoch 69/100] [Batch 248/347] [D loss: 0.510838] [G loss: 0.313130]\n",
      "[Epoch 69/100] [Batch 249/347] [D loss: 0.491958] [G loss: 0.322599]\n",
      "[Epoch 69/100] [Batch 250/347] [D loss: 0.488920] [G loss: 0.335614]\n",
      "[Epoch 69/100] [Batch 251/347] [D loss: 0.480805] [G loss: 0.353216]\n",
      "[Epoch 69/100] [Batch 252/347] [D loss: 0.475707] [G loss: 0.364248]\n",
      "[Epoch 69/100] [Batch 253/347] [D loss: 0.418679] [G loss: 0.362891]\n",
      "[Epoch 69/100] [Batch 254/347] [D loss: 0.415361] [G loss: 0.372583]\n",
      "[Epoch 69/100] [Batch 255/347] [D loss: 0.411318] [G loss: 0.378506]\n",
      "[Epoch 69/100] [Batch 256/347] [D loss: 0.414660] [G loss: 0.375519]\n",
      "[Epoch 69/100] [Batch 257/347] [D loss: 0.404006] [G loss: 0.373683]\n",
      "[Epoch 69/100] [Batch 258/347] [D loss: 0.367175] [G loss: 0.374215]\n",
      "[Epoch 69/100] [Batch 259/347] [D loss: 0.368998] [G loss: 0.372189]\n",
      "[Epoch 69/100] [Batch 260/347] [D loss: 0.370690] [G loss: 0.371804]\n",
      "[Epoch 69/100] [Batch 261/347] [D loss: 0.358240] [G loss: 0.376615]\n",
      "[Epoch 69/100] [Batch 262/347] [D loss: 0.314514] [G loss: 0.378680]\n",
      "[Epoch 69/100] [Batch 263/347] [D loss: 0.309067] [G loss: 0.380605]\n",
      "[Epoch 69/100] [Batch 264/347] [D loss: 0.313069] [G loss: 0.384043]\n",
      "[Epoch 69/100] [Batch 265/347] [D loss: 0.321276] [G loss: 0.386681]\n",
      "[Epoch 69/100] [Batch 266/347] [D loss: 0.388890] [G loss: 0.389536]\n",
      "[Epoch 69/100] [Batch 267/347] [D loss: 0.408243] [G loss: 0.389915]\n",
      "[Epoch 69/100] [Batch 268/347] [D loss: 0.417741] [G loss: 0.387773]\n",
      "[Epoch 69/100] [Batch 269/347] [D loss: 0.418851] [G loss: 0.383662]\n",
      "[Epoch 69/100] [Batch 270/347] [D loss: 0.450144] [G loss: 0.378730]\n",
      "[Epoch 69/100] [Batch 271/347] [D loss: 0.423813] [G loss: 0.379660]\n",
      "[Epoch 69/100] [Batch 272/347] [D loss: 0.450820] [G loss: 0.402406]\n",
      "[Epoch 69/100] [Batch 273/347] [D loss: 0.415631] [G loss: 0.427478]\n",
      "[Epoch 69/100] [Batch 274/347] [D loss: 0.354163] [G loss: 0.451362]\n",
      "[Epoch 69/100] [Batch 275/347] [D loss: 0.294131] [G loss: 0.469790]\n",
      "[Epoch 69/100] [Batch 276/347] [D loss: 0.481487] [G loss: 0.475936]\n",
      "[Epoch 69/100] [Batch 277/347] [D loss: 0.509511] [G loss: 0.487641]\n",
      "[Epoch 69/100] [Batch 278/347] [D loss: 0.519351] [G loss: 0.497634]\n",
      "[Epoch 69/100] [Batch 279/347] [D loss: 0.521950] [G loss: 0.499451]\n",
      "[Epoch 69/100] [Batch 280/347] [D loss: 0.526869] [G loss: 0.499588]\n",
      "[Epoch 69/100] [Batch 281/347] [D loss: 0.531064] [G loss: 0.500022]\n",
      "[Epoch 69/100] [Batch 282/347] [D loss: 0.532355] [G loss: 0.503404]\n",
      "[Epoch 69/100] [Batch 283/347] [D loss: 0.533320] [G loss: 0.504890]\n",
      "[Epoch 69/100] [Batch 284/347] [D loss: 0.534235] [G loss: 0.507317]\n",
      "[Epoch 69/100] [Batch 285/347] [D loss: 0.537691] [G loss: 0.508500]\n",
      "[Epoch 69/100] [Batch 286/347] [D loss: 0.535721] [G loss: 0.494765]\n",
      "[Epoch 69/100] [Batch 287/347] [D loss: 0.536275] [G loss: 0.492334]\n",
      "[Epoch 69/100] [Batch 288/347] [D loss: 0.536581] [G loss: 0.489895]\n",
      "[Epoch 69/100] [Batch 289/347] [D loss: 0.535225] [G loss: 0.485146]\n",
      "[Epoch 69/100] [Batch 290/347] [D loss: 0.535693] [G loss: 0.501175]\n",
      "[Epoch 69/100] [Batch 291/347] [D loss: 0.534472] [G loss: 0.508415]\n",
      "[Epoch 69/100] [Batch 292/347] [D loss: 0.532292] [G loss: 0.512535]\n",
      "[Epoch 69/100] [Batch 293/347] [D loss: 0.506485] [G loss: 0.518305]\n",
      "[Epoch 69/100] [Batch 294/347] [D loss: 0.505748] [G loss: 0.523017]\n",
      "[Epoch 69/100] [Batch 295/347] [D loss: 0.505453] [G loss: 0.522202]\n",
      "[Epoch 69/100] [Batch 296/347] [D loss: 0.504428] [G loss: 0.520930]\n",
      "[Epoch 69/100] [Batch 297/347] [D loss: 0.531919] [G loss: 0.525685]\n",
      "[Epoch 69/100] [Batch 298/347] [D loss: 0.535090] [G loss: 0.519435]\n",
      "[Epoch 69/100] [Batch 299/347] [D loss: 0.533975] [G loss: 0.515020]\n",
      "[Epoch 69/100] [Batch 300/347] [D loss: 0.532622] [G loss: 0.513003]\n",
      "[Epoch 69/100] [Batch 301/347] [D loss: 0.532731] [G loss: 0.496940]\n",
      "[Epoch 69/100] [Batch 302/347] [D loss: 0.533162] [G loss: 0.489371]\n",
      "[Epoch 69/100] [Batch 303/347] [D loss: 0.532292] [G loss: 0.478394]\n",
      "[Epoch 69/100] [Batch 304/347] [D loss: 0.508112] [G loss: 0.466402]\n",
      "[Epoch 69/100] [Batch 305/347] [D loss: 0.486795] [G loss: 0.459182]\n",
      "[Epoch 69/100] [Batch 306/347] [D loss: 0.484298] [G loss: 0.459540]\n",
      "[Epoch 69/100] [Batch 307/347] [D loss: 0.478825] [G loss: 0.464817]\n",
      "[Epoch 69/100] [Batch 308/347] [D loss: 0.488810] [G loss: 0.469394]\n",
      "[Epoch 69/100] [Batch 309/347] [D loss: 0.526568] [G loss: 0.483083]\n",
      "[Epoch 69/100] [Batch 310/347] [D loss: 0.538738] [G loss: 0.494616]\n",
      "[Epoch 69/100] [Batch 311/347] [D loss: 0.533933] [G loss: 0.491325]\n",
      "[Epoch 69/100] [Batch 312/347] [D loss: 0.524672] [G loss: 0.485565]\n",
      "[Epoch 69/100] [Batch 313/347] [D loss: 0.518595] [G loss: 0.475703]\n",
      "[Epoch 69/100] [Batch 314/347] [D loss: 0.516798] [G loss: 0.460329]\n",
      "[Epoch 69/100] [Batch 315/347] [D loss: 0.516655] [G loss: 0.448403]\n",
      "[Epoch 69/100] [Batch 316/347] [D loss: 0.517823] [G loss: 0.448957]\n",
      "[Epoch 69/100] [Batch 317/347] [D loss: 0.520517] [G loss: 0.451949]\n",
      "[Epoch 69/100] [Batch 318/347] [D loss: 0.521090] [G loss: 0.464721]\n",
      "[Epoch 69/100] [Batch 319/347] [D loss: 0.518268] [G loss: 0.476317]\n",
      "[Epoch 69/100] [Batch 320/347] [D loss: 0.516384] [G loss: 0.474196]\n",
      "[Epoch 69/100] [Batch 321/347] [D loss: 0.512744] [G loss: 0.466851]\n",
      "[Epoch 69/100] [Batch 322/347] [D loss: 0.512697] [G loss: 0.458719]\n",
      "[Epoch 69/100] [Batch 323/347] [D loss: 0.498208] [G loss: 0.449161]\n",
      "[Epoch 69/100] [Batch 324/347] [D loss: 0.494695] [G loss: 0.442350]\n",
      "[Epoch 69/100] [Batch 325/347] [D loss: 0.491819] [G loss: 0.434068]\n",
      "[Epoch 69/100] [Batch 326/347] [D loss: 0.490587] [G loss: 0.426011]\n",
      "[Epoch 69/100] [Batch 327/347] [D loss: 0.476876] [G loss: 0.419980]\n",
      "[Epoch 69/100] [Batch 328/347] [D loss: 0.473384] [G loss: 0.412551]\n",
      "[Epoch 69/100] [Batch 329/347] [D loss: 0.465092] [G loss: 0.407494]\n",
      "[Epoch 69/100] [Batch 330/347] [D loss: 0.452504] [G loss: 0.403236]\n",
      "[Epoch 69/100] [Batch 331/347] [D loss: 0.456960] [G loss: 0.401109]\n",
      "[Epoch 69/100] [Batch 332/347] [D loss: 0.497487] [G loss: 0.414360]\n",
      "[Epoch 69/100] [Batch 333/347] [D loss: 0.474520] [G loss: 0.403737]\n",
      "[Epoch 69/100] [Batch 334/347] [D loss: 0.457942] [G loss: 0.385025]\n",
      "[Epoch 69/100] [Batch 335/347] [D loss: 0.446036] [G loss: 0.367645]\n",
      "[Epoch 69/100] [Batch 336/347] [D loss: 0.436112] [G loss: 0.348420]\n",
      "[Epoch 69/100] [Batch 337/347] [D loss: 0.466773] [G loss: 0.333778]\n",
      "[Epoch 69/100] [Batch 338/347] [D loss: 0.501237] [G loss: 0.323807]\n",
      "[Epoch 69/100] [Batch 339/347] [D loss: 0.484104] [G loss: 0.309308]\n",
      "[Epoch 69/100] [Batch 340/347] [D loss: 0.460416] [G loss: 0.294098]\n",
      "[Epoch 69/100] [Batch 341/347] [D loss: 0.473767] [G loss: 0.286963]\n",
      "[Epoch 69/100] [Batch 342/347] [D loss: 0.380272] [G loss: 0.274357]\n",
      "[Epoch 69/100] [Batch 343/347] [D loss: 0.349277] [G loss: 0.264799]\n",
      "[Epoch 69/100] [Batch 344/347] [D loss: 0.340019] [G loss: 0.275385]\n",
      "[Epoch 69/100] [Batch 345/347] [D loss: 0.308452] [G loss: 0.296646]\n",
      "[Epoch 69/100] [Batch 346/347] [D loss: 0.277198] [G loss: 0.324309]\n",
      "[Epoch 69/100] [Batch 347/347] [D loss: 0.246680] [G loss: 0.352426]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 70/100] [Batch 1/347] [D loss: 0.451355] [G loss: 0.384901]\n",
      "[Epoch 70/100] [Batch 2/347] [D loss: 0.475145] [G loss: 0.397819]\n",
      "[Epoch 70/100] [Batch 3/347] [D loss: 0.511685] [G loss: 0.410814]\n",
      "[Epoch 70/100] [Batch 4/347] [D loss: 0.515799] [G loss: 0.417311]\n",
      "[Epoch 70/100] [Batch 5/347] [D loss: 0.516731] [G loss: 0.418524]\n",
      "[Epoch 70/100] [Batch 6/347] [D loss: 0.507950] [G loss: 0.419056]\n",
      "[Epoch 70/100] [Batch 7/347] [D loss: 0.498242] [G loss: 0.412880]\n",
      "[Epoch 70/100] [Batch 8/347] [D loss: 0.499376] [G loss: 0.413156]\n",
      "[Epoch 70/100] [Batch 9/347] [D loss: 0.501655] [G loss: 0.415067]\n",
      "[Epoch 70/100] [Batch 10/347] [D loss: 0.503370] [G loss: 0.416529]\n",
      "[Epoch 70/100] [Batch 11/347] [D loss: 0.516315] [G loss: 0.425859]\n",
      "[Epoch 70/100] [Batch 12/347] [D loss: 0.519139] [G loss: 0.427932]\n",
      "[Epoch 70/100] [Batch 13/347] [D loss: 0.512591] [G loss: 0.426265]\n",
      "[Epoch 70/100] [Batch 14/347] [D loss: 0.508795] [G loss: 0.424802]\n",
      "[Epoch 70/100] [Batch 15/347] [D loss: 0.507087] [G loss: 0.414316]\n",
      "[Epoch 70/100] [Batch 16/347] [D loss: 0.505712] [G loss: 0.407270]\n",
      "[Epoch 70/100] [Batch 17/347] [D loss: 0.506050] [G loss: 0.408199]\n",
      "[Epoch 70/100] [Batch 18/347] [D loss: 0.507909] [G loss: 0.407234]\n",
      "[Epoch 70/100] [Batch 19/347] [D loss: 0.508469] [G loss: 0.410504]\n",
      "[Epoch 70/100] [Batch 20/347] [D loss: 0.512760] [G loss: 0.413226]\n",
      "[Epoch 70/100] [Batch 21/347] [D loss: 0.497544] [G loss: 0.406248]\n",
      "[Epoch 70/100] [Batch 22/347] [D loss: 0.495095] [G loss: 0.401931]\n",
      "[Epoch 70/100] [Batch 23/347] [D loss: 0.496333] [G loss: 0.396326]\n",
      "[Epoch 70/100] [Batch 24/347] [D loss: 0.458167] [G loss: 0.386504]\n",
      "[Epoch 70/100] [Batch 25/347] [D loss: 0.369595] [G loss: 0.390137]\n",
      "[Epoch 70/100] [Batch 26/347] [D loss: 0.356810] [G loss: 0.386021]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 70/100] [Batch 27/347] [D loss: 0.340005] [G loss: 0.384145]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 70/100] [Batch 28/347] [D loss: 0.327245] [G loss: 0.381812]\n",
      "[Epoch 70/100] [Batch 29/347] [D loss: 0.341311] [G loss: 0.372515]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 70/100] [Batch 30/347] [D loss: 0.314486] [G loss: 0.357412]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 70/100] [Batch 31/347] [D loss: 0.304296] [G loss: 0.337904]\n",
      "[Epoch 70/100] [Batch 32/347] [D loss: 0.312182] [G loss: 0.315571]\n",
      "[Epoch 70/100] [Batch 33/347] [D loss: 0.328325] [G loss: 0.296793]\n",
      "[Epoch 70/100] [Batch 34/347] [D loss: 0.367455] [G loss: 0.278040]\n",
      "[Epoch 70/100] [Batch 35/347] [D loss: 0.369245] [G loss: 0.262292]\n",
      "[Epoch 70/100] [Batch 36/347] [D loss: 0.389385] [G loss: 0.250444]\n",
      "[Epoch 70/100] [Batch 37/347] [D loss: 0.398481] [G loss: 0.241813]\n",
      "[Epoch 70/100] [Batch 38/347] [D loss: 0.401836] [G loss: 0.235037]\n",
      "[Epoch 70/100] [Batch 39/347] [D loss: 0.413273] [G loss: 0.239789]\n",
      "[Epoch 70/100] [Batch 40/347] [D loss: 0.439963] [G loss: 0.253304]\n",
      "[Epoch 70/100] [Batch 41/347] [D loss: 0.454942] [G loss: 0.264810]\n",
      "[Epoch 70/100] [Batch 42/347] [D loss: 0.451699] [G loss: 0.283810]\n",
      "[Epoch 70/100] [Batch 43/347] [D loss: 0.473575] [G loss: 0.306893]\n",
      "[Epoch 70/100] [Batch 44/347] [D loss: 0.462069] [G loss: 0.320782]\n",
      "[Epoch 70/100] [Batch 45/347] [D loss: 0.434166] [G loss: 0.319182]\n",
      "[Epoch 70/100] [Batch 46/347] [D loss: 0.356077] [G loss: 0.320234]\n",
      "[Epoch 70/100] [Batch 47/347] [D loss: 0.345216] [G loss: 0.319348]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 70/100] [Batch 48/347] [D loss: 0.249404] [G loss: 0.328949]\n",
      "[Epoch 70/100] [Batch 49/347] [D loss: 0.239789] [G loss: 0.346183]\n",
      "[Epoch 70/100] [Batch 50/347] [D loss: 0.229182] [G loss: 0.365281]\n",
      "[Epoch 70/100] [Batch 51/347] [D loss: 0.224303] [G loss: 0.377812]\n",
      "[Epoch 70/100] [Batch 52/347] [D loss: 0.323398] [G loss: 0.378923]\n",
      "[Epoch 70/100] [Batch 53/347] [D loss: 0.366081] [G loss: 0.369771]\n",
      "[Epoch 70/100] [Batch 54/347] [D loss: 0.347805] [G loss: 0.359623]\n",
      "[Epoch 70/100] [Batch 55/347] [D loss: 0.342113] [G loss: 0.361666]\n",
      "[Epoch 70/100] [Batch 56/347] [D loss: 0.329260] [G loss: 0.366066]\n",
      "[Epoch 70/100] [Batch 57/347] [D loss: 0.286357] [G loss: 0.369207]\n",
      "[Epoch 70/100] [Batch 58/347] [D loss: 0.293470] [G loss: 0.367299]\n",
      "[Epoch 70/100] [Batch 59/347] [D loss: 0.288403] [G loss: 0.357108]\n",
      "[Epoch 70/100] [Batch 60/347] [D loss: 0.276020] [G loss: 0.338960]\n",
      "[Epoch 70/100] [Batch 61/347] [D loss: 0.290068] [G loss: 0.319731]\n",
      "[Epoch 70/100] [Batch 62/347] [D loss: 0.291212] [G loss: 0.316674]\n",
      "[Epoch 70/100] [Batch 63/347] [D loss: 0.290213] [G loss: 0.316994]\n",
      "[Epoch 70/100] [Batch 64/347] [D loss: 0.278250] [G loss: 0.317401]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 70/100] [Batch 65/347] [D loss: 0.243913] [G loss: 0.327583]\n",
      "[Epoch 70/100] [Batch 66/347] [D loss: 0.240658] [G loss: 0.333470]\n",
      "[Epoch 70/100] [Batch 67/347] [D loss: 0.234420] [G loss: 0.330644]\n",
      "[Epoch 70/100] [Batch 68/347] [D loss: 0.230493] [G loss: 0.333916]\n",
      "[Epoch 70/100] [Batch 69/347] [D loss: 0.240940] [G loss: 0.344238]\n",
      "[Epoch 70/100] [Batch 70/347] [D loss: 0.241355] [G loss: 0.351102]\n",
      "[Epoch 70/100] [Batch 71/347] [D loss: 0.239137] [G loss: 0.356240]\n",
      "[Epoch 70/100] [Batch 72/347] [D loss: 0.251720] [G loss: 0.369914]\n",
      "[Epoch 70/100] [Batch 73/347] [D loss: 0.357051] [G loss: 0.367179]\n",
      "[Epoch 70/100] [Batch 74/347] [D loss: 0.358905] [G loss: 0.367945]\n",
      "[Epoch 70/100] [Batch 75/347] [D loss: 0.355758] [G loss: 0.366673]\n",
      "[Epoch 70/100] [Batch 76/347] [D loss: 0.351808] [G loss: 0.362061]\n",
      "[Epoch 70/100] [Batch 77/347] [D loss: 0.386336] [G loss: 0.358677]\n",
      "[Epoch 70/100] [Batch 78/347] [D loss: 0.440251] [G loss: 0.362951]\n",
      "[Epoch 70/100] [Batch 79/347] [D loss: 0.436834] [G loss: 0.355707]\n",
      "[Epoch 70/100] [Batch 80/347] [D loss: 0.338504] [G loss: 0.335405]\n",
      "[Epoch 70/100] [Batch 81/347] [D loss: 0.319986] [G loss: 0.325361]\n",
      "[Epoch 70/100] [Batch 82/347] [D loss: 0.323478] [G loss: 0.318728]\n",
      "[Epoch 70/100] [Batch 83/347] [D loss: 0.328864] [G loss: 0.312719]\n",
      "[Epoch 70/100] [Batch 84/347] [D loss: 0.445998] [G loss: 0.314012]\n",
      "[Epoch 70/100] [Batch 85/347] [D loss: 0.512919] [G loss: 0.311710]\n",
      "[Epoch 70/100] [Batch 86/347] [D loss: 0.514693] [G loss: 0.309896]\n",
      "[Epoch 70/100] [Batch 87/347] [D loss: 0.515256] [G loss: 0.309740]\n",
      "[Epoch 70/100] [Batch 88/347] [D loss: 0.533312] [G loss: 0.310996]\n",
      "[Epoch 70/100] [Batch 89/347] [D loss: 0.543237] [G loss: 0.314801]\n",
      "[Epoch 70/100] [Batch 90/347] [D loss: 0.541352] [G loss: 0.316628]\n",
      "[Epoch 70/100] [Batch 91/347] [D loss: 0.540717] [G loss: 0.318561]\n",
      "[Epoch 70/100] [Batch 92/347] [D loss: 0.541230] [G loss: 0.322762]\n",
      "[Epoch 70/100] [Batch 93/347] [D loss: 0.540396] [G loss: 0.327067]\n",
      "[Epoch 70/100] [Batch 94/347] [D loss: 0.525208] [G loss: 0.328071]\n",
      "[Epoch 70/100] [Batch 95/347] [D loss: 0.517495] [G loss: 0.331805]\n",
      "[Epoch 70/100] [Batch 96/347] [D loss: 0.518800] [G loss: 0.337383]\n",
      "[Epoch 70/100] [Batch 97/347] [D loss: 0.514248] [G loss: 0.340921]\n",
      "[Epoch 70/100] [Batch 98/347] [D loss: 0.505415] [G loss: 0.346168]\n",
      "[Epoch 70/100] [Batch 99/347] [D loss: 0.515324] [G loss: 0.349412]\n",
      "[Epoch 70/100] [Batch 100/347] [D loss: 0.516334] [G loss: 0.351922]\n",
      "[Epoch 70/100] [Batch 101/347] [D loss: 0.522575] [G loss: 0.352289]\n",
      "[Epoch 70/100] [Batch 102/347] [D loss: 0.550994] [G loss: 0.352934]\n",
      "[Epoch 70/100] [Batch 103/347] [D loss: 0.553753] [G loss: 0.358709]\n",
      "[Epoch 70/100] [Batch 104/347] [D loss: 0.537482] [G loss: 0.359043]\n",
      "[Epoch 70/100] [Batch 105/347] [D loss: 0.454993] [G loss: 0.358958]\n",
      "[Epoch 70/100] [Batch 106/347] [D loss: 0.243106] [G loss: 0.363240]\n",
      "[Epoch 70/100] [Batch 107/347] [D loss: 0.232914] [G loss: 0.379548]\n",
      "[Epoch 70/100] [Batch 108/347] [D loss: 0.216315] [G loss: 0.398680]\n",
      "[Epoch 70/100] [Batch 109/347] [D loss: 0.202342] [G loss: 0.419062]\n",
      "[Epoch 70/100] [Batch 110/347] [D loss: 0.223338] [G loss: 0.432183]\n",
      "[Epoch 70/100] [Batch 111/347] [D loss: 0.224365] [G loss: 0.446552]\n",
      "[Epoch 70/100] [Batch 112/347] [D loss: 0.233109] [G loss: 0.457044]\n",
      "[Epoch 70/100] [Batch 113/347] [D loss: 0.422669] [G loss: 0.479880]\n",
      "[Epoch 70/100] [Batch 114/347] [D loss: 0.504519] [G loss: 0.489323]\n",
      "[Epoch 70/100] [Batch 115/347] [D loss: 0.500132] [G loss: 0.474004]\n",
      "[Epoch 70/100] [Batch 116/347] [D loss: 0.458241] [G loss: 0.456835]\n",
      "[Epoch 70/100] [Batch 117/347] [D loss: 0.454264] [G loss: 0.443557]\n",
      "[Epoch 70/100] [Batch 118/347] [D loss: 0.394145] [G loss: 0.426786]\n",
      "[Epoch 70/100] [Batch 119/347] [D loss: 0.381080] [G loss: 0.419381]\n",
      "[Epoch 70/100] [Batch 120/347] [D loss: 0.361164] [G loss: 0.414333]\n",
      "[Epoch 70/100] [Batch 121/347] [D loss: 0.343114] [G loss: 0.398149]\n",
      "[Epoch 70/100] [Batch 122/347] [D loss: 0.451313] [G loss: 0.382782]\n",
      "[Epoch 70/100] [Batch 123/347] [D loss: 0.494198] [G loss: 0.366681]\n",
      "[Epoch 70/100] [Batch 124/347] [D loss: 0.421652] [G loss: 0.348284]\n",
      "[Epoch 70/100] [Batch 125/347] [D loss: 0.388693] [G loss: 0.335312]\n",
      "[Epoch 70/100] [Batch 126/347] [D loss: 0.360462] [G loss: 0.325625]\n",
      "[Epoch 70/100] [Batch 127/347] [D loss: 0.367034] [G loss: 0.316987]\n",
      "[Epoch 70/100] [Batch 128/347] [D loss: 0.362346] [G loss: 0.307649]\n",
      "[Epoch 70/100] [Batch 129/347] [D loss: 0.335638] [G loss: 0.307357]\n",
      "[Epoch 70/100] [Batch 130/347] [D loss: 0.323911] [G loss: 0.331467]\n",
      "[Epoch 70/100] [Batch 131/347] [D loss: 0.300978] [G loss: 0.359623]\n",
      "[Epoch 70/100] [Batch 132/347] [D loss: 0.258255] [G loss: 0.395739]\n",
      "[Epoch 70/100] [Batch 133/347] [D loss: 0.240350] [G loss: 0.430389]\n",
      "[Epoch 70/100] [Batch 134/347] [D loss: 0.196390] [G loss: 0.456245]\n",
      "[Epoch 70/100] [Batch 135/347] [D loss: 0.171077] [G loss: 0.471694]\n",
      "[Epoch 70/100] [Batch 136/347] [D loss: 0.158854] [G loss: 0.476543]\n",
      "[Epoch 70/100] [Batch 137/347] [D loss: 0.405069] [G loss: 0.476201]\n",
      "[Epoch 70/100] [Batch 138/347] [D loss: 0.440491] [G loss: 0.472451]\n",
      "[Epoch 70/100] [Batch 139/347] [D loss: 0.459430] [G loss: 0.464416]\n",
      "[Epoch 70/100] [Batch 140/347] [D loss: 0.465360] [G loss: 0.464247]\n",
      "[Epoch 70/100] [Batch 141/347] [D loss: 0.439095] [G loss: 0.458589]\n",
      "[Epoch 70/100] [Batch 142/347] [D loss: 0.450293] [G loss: 0.452172]\n",
      "[Epoch 70/100] [Batch 143/347] [D loss: 0.448153] [G loss: 0.443067]\n",
      "[Epoch 70/100] [Batch 144/347] [D loss: 0.443663] [G loss: 0.434020]\n",
      "[Epoch 70/100] [Batch 145/347] [D loss: 0.463436] [G loss: 0.433662]\n",
      "[Epoch 70/100] [Batch 146/347] [D loss: 0.478710] [G loss: 0.428640]\n",
      "[Epoch 70/100] [Batch 147/347] [D loss: 0.496739] [G loss: 0.425671]\n",
      "[Epoch 70/100] [Batch 148/347] [D loss: 0.501925] [G loss: 0.427034]\n",
      "[Epoch 70/100] [Batch 149/347] [D loss: 0.461942] [G loss: 0.424133]\n",
      "[Epoch 70/100] [Batch 150/347] [D loss: 0.428573] [G loss: 0.418118]\n",
      "[Epoch 70/100] [Batch 151/347] [D loss: 0.389138] [G loss: 0.404515]\n",
      "[Epoch 70/100] [Batch 152/347] [D loss: 0.344956] [G loss: 0.378989]\n",
      "[Epoch 70/100] [Batch 153/347] [D loss: 0.327765] [G loss: 0.346095]\n",
      "[Epoch 70/100] [Batch 154/347] [D loss: 0.308534] [G loss: 0.316905]\n",
      "[Epoch 70/100] [Batch 155/347] [D loss: 0.303405] [G loss: 0.295940]\n",
      "[Epoch 70/100] [Batch 156/347] [D loss: 0.302136] [G loss: 0.274221]\n",
      "[Epoch 70/100] [Batch 157/347] [D loss: 0.308058] [G loss: 0.263213]\n",
      "[Epoch 70/100] [Batch 158/347] [D loss: 0.310688] [G loss: 0.265339]\n",
      "[Epoch 70/100] [Batch 159/347] [D loss: 0.318075] [G loss: 0.271111]\n",
      "[Epoch 70/100] [Batch 160/347] [D loss: 0.314528] [G loss: 0.290800]\n",
      "[Epoch 70/100] [Batch 161/347] [D loss: 0.292758] [G loss: 0.311433]\n",
      "[Epoch 70/100] [Batch 162/347] [D loss: 0.271494] [G loss: 0.326994]\n",
      "[Epoch 70/100] [Batch 163/347] [D loss: 0.261440] [G loss: 0.337494]\n",
      "[Epoch 70/100] [Batch 164/347] [D loss: 0.248599] [G loss: 0.357876]\n",
      "[Epoch 70/100] [Batch 165/347] [D loss: 0.245790] [G loss: 0.380162]\n",
      "[Epoch 70/100] [Batch 166/347] [D loss: 0.249217] [G loss: 0.397116]\n",
      "[Epoch 70/100] [Batch 167/347] [D loss: 0.279725] [G loss: 0.427717]\n",
      "[Epoch 70/100] [Batch 168/347] [D loss: 0.279997] [G loss: 0.441151]\n",
      "[Epoch 70/100] [Batch 169/347] [D loss: 0.429407] [G loss: 0.452297]\n",
      "[Epoch 70/100] [Batch 170/347] [D loss: 0.502472] [G loss: 0.459632]\n",
      "[Epoch 70/100] [Batch 171/347] [D loss: 0.509252] [G loss: 0.459378]\n",
      "[Epoch 70/100] [Batch 172/347] [D loss: 0.511050] [G loss: 0.459849]\n",
      "[Epoch 70/100] [Batch 173/347] [D loss: 0.511096] [G loss: 0.457363]\n",
      "[Epoch 70/100] [Batch 174/347] [D loss: 0.507527] [G loss: 0.458779]\n",
      "[Epoch 70/100] [Batch 175/347] [D loss: 0.530370] [G loss: 0.461394]\n",
      "[Epoch 70/100] [Batch 176/347] [D loss: 0.544002] [G loss: 0.462343]\n",
      "[Epoch 70/100] [Batch 177/347] [D loss: 0.544998] [G loss: 0.457632]\n",
      "[Epoch 70/100] [Batch 178/347] [D loss: 0.540889] [G loss: 0.450049]\n",
      "[Epoch 70/100] [Batch 179/347] [D loss: 0.539136] [G loss: 0.444744]\n",
      "[Epoch 70/100] [Batch 180/347] [D loss: 0.535862] [G loss: 0.439303]\n",
      "[Epoch 70/100] [Batch 181/347] [D loss: 0.535427] [G loss: 0.440039]\n",
      "[Epoch 70/100] [Batch 182/347] [D loss: 0.537285] [G loss: 0.439435]\n",
      "[Epoch 70/100] [Batch 183/347] [D loss: 0.538569] [G loss: 0.439505]\n",
      "[Epoch 70/100] [Batch 184/347] [D loss: 0.549483] [G loss: 0.440922]\n",
      "[Epoch 70/100] [Batch 185/347] [D loss: 0.550461] [G loss: 0.437727]\n",
      "[Epoch 70/100] [Batch 186/347] [D loss: 0.544618] [G loss: 0.437094]\n",
      "[Epoch 70/100] [Batch 187/347] [D loss: 0.539163] [G loss: 0.434470]\n",
      "[Epoch 70/100] [Batch 188/347] [D loss: 0.516225] [G loss: 0.426245]\n",
      "[Epoch 70/100] [Batch 189/347] [D loss: 0.481458] [G loss: 0.418263]\n",
      "[Epoch 70/100] [Batch 190/347] [D loss: 0.475250] [G loss: 0.411499]\n",
      "[Epoch 70/100] [Batch 191/347] [D loss: 0.473814] [G loss: 0.402548]\n",
      "[Epoch 70/100] [Batch 192/347] [D loss: 0.476717] [G loss: 0.395144]\n",
      "[Epoch 70/100] [Batch 193/347] [D loss: 0.519918] [G loss: 0.387666]\n",
      "[Epoch 70/100] [Batch 194/347] [D loss: 0.515543] [G loss: 0.376386]\n",
      "[Epoch 70/100] [Batch 195/347] [D loss: 0.497539] [G loss: 0.365610]\n",
      "[Epoch 70/100] [Batch 196/347] [D loss: 0.457763] [G loss: 0.353870]\n",
      "[Epoch 70/100] [Batch 197/347] [D loss: 0.453456] [G loss: 0.344231]\n",
      "[Epoch 70/100] [Batch 198/347] [D loss: 0.451962] [G loss: 0.337926]\n",
      "[Epoch 70/100] [Batch 199/347] [D loss: 0.448336] [G loss: 0.329812]\n",
      "[Epoch 70/100] [Batch 200/347] [D loss: 0.496842] [G loss: 0.323017]\n",
      "[Epoch 70/100] [Batch 201/347] [D loss: 0.523914] [G loss: 0.316974]\n",
      "[Epoch 70/100] [Batch 202/347] [D loss: 0.530509] [G loss: 0.311783]\n",
      "[Epoch 70/100] [Batch 203/347] [D loss: 0.558561] [G loss: 0.308386]\n",
      "[Epoch 70/100] [Batch 204/347] [D loss: 0.554557] [G loss: 0.311269]\n",
      "[Epoch 70/100] [Batch 205/347] [D loss: 0.555698] [G loss: 0.316942]\n",
      "[Epoch 70/100] [Batch 206/347] [D loss: 0.555929] [G loss: 0.322421]\n",
      "[Epoch 70/100] [Batch 207/347] [D loss: 0.504026] [G loss: 0.327838]\n",
      "[Epoch 70/100] [Batch 208/347] [D loss: 0.493203] [G loss: 0.335352]\n",
      "[Epoch 70/100] [Batch 209/347] [D loss: 0.480236] [G loss: 0.335711]\n",
      "[Epoch 70/100] [Batch 210/347] [D loss: 0.391007] [G loss: 0.341828]\n",
      "[Epoch 70/100] [Batch 211/347] [D loss: 0.354552] [G loss: 0.345027]\n",
      "[Epoch 70/100] [Batch 212/347] [D loss: 0.265040] [G loss: 0.345113]\n",
      "[Epoch 70/100] [Batch 213/347] [D loss: 0.249959] [G loss: 0.361577]\n",
      "[Epoch 70/100] [Batch 214/347] [D loss: 0.231038] [G loss: 0.383358]\n",
      "[Epoch 70/100] [Batch 215/347] [D loss: 0.217338] [G loss: 0.404953]\n",
      "[Epoch 70/100] [Batch 216/347] [D loss: 0.385716] [G loss: 0.439914]\n",
      "[Epoch 70/100] [Batch 217/347] [D loss: 0.457193] [G loss: 0.464334]\n",
      "[Epoch 70/100] [Batch 218/347] [D loss: 0.500766] [G loss: 0.486782]\n",
      "[Epoch 70/100] [Batch 219/347] [D loss: 0.498952] [G loss: 0.498245]\n",
      "[Epoch 70/100] [Batch 220/347] [D loss: 0.493933] [G loss: 0.505973]\n",
      "[Epoch 70/100] [Batch 221/347] [D loss: 0.513528] [G loss: 0.508618]\n",
      "[Epoch 70/100] [Batch 222/347] [D loss: 0.516778] [G loss: 0.502109]\n",
      "[Epoch 70/100] [Batch 223/347] [D loss: 0.506539] [G loss: 0.484803]\n",
      "[Epoch 70/100] [Batch 224/347] [D loss: 0.511450] [G loss: 0.463500]\n",
      "[Epoch 70/100] [Batch 225/347] [D loss: 0.516462] [G loss: 0.445101]\n",
      "[Epoch 70/100] [Batch 226/347] [D loss: 0.518280] [G loss: 0.434340]\n",
      "[Epoch 70/100] [Batch 227/347] [D loss: 0.528646] [G loss: 0.433951]\n",
      "[Epoch 70/100] [Batch 228/347] [D loss: 0.533702] [G loss: 0.435758]\n",
      "[Epoch 70/100] [Batch 229/347] [D loss: 0.533758] [G loss: 0.437695]\n",
      "[Epoch 70/100] [Batch 230/347] [D loss: 0.537018] [G loss: 0.438815]\n",
      "[Epoch 70/100] [Batch 231/347] [D loss: 0.528432] [G loss: 0.431351]\n",
      "[Epoch 70/100] [Batch 232/347] [D loss: 0.520416] [G loss: 0.427901]\n",
      "[Epoch 70/100] [Batch 233/347] [D loss: 0.465510] [G loss: 0.428086]\n",
      "[Epoch 70/100] [Batch 234/347] [D loss: 0.430105] [G loss: 0.425710]\n",
      "[Epoch 70/100] [Batch 235/347] [D loss: 0.419581] [G loss: 0.428159]\n",
      "[Epoch 70/100] [Batch 236/347] [D loss: 0.408437] [G loss: 0.427297]\n",
      "[Epoch 70/100] [Batch 237/347] [D loss: 0.454168] [G loss: 0.421785]\n",
      "[Epoch 70/100] [Batch 238/347] [D loss: 0.532110] [G loss: 0.409162]\n",
      "[Epoch 70/100] [Batch 239/347] [D loss: 0.530962] [G loss: 0.394876]\n",
      "[Epoch 70/100] [Batch 240/347] [D loss: 0.534107] [G loss: 0.383871]\n",
      "[Epoch 70/100] [Batch 241/347] [D loss: 0.536186] [G loss: 0.376811]\n",
      "[Epoch 70/100] [Batch 242/347] [D loss: 0.553258] [G loss: 0.373483]\n",
      "[Epoch 70/100] [Batch 243/347] [D loss: 0.508153] [G loss: 0.371667]\n",
      "[Epoch 70/100] [Batch 244/347] [D loss: 0.474327] [G loss: 0.361040]\n",
      "[Epoch 70/100] [Batch 245/347] [D loss: 0.476791] [G loss: 0.347646]\n",
      "[Epoch 70/100] [Batch 246/347] [D loss: 0.473818] [G loss: 0.333967]\n",
      "[Epoch 70/100] [Batch 247/347] [D loss: 0.497371] [G loss: 0.324338]\n",
      "[Epoch 70/100] [Batch 248/347] [D loss: 0.518755] [G loss: 0.327049]\n",
      "[Epoch 70/100] [Batch 249/347] [D loss: 0.500114] [G loss: 0.333603]\n",
      "[Epoch 70/100] [Batch 250/347] [D loss: 0.496580] [G loss: 0.343688]\n",
      "[Epoch 70/100] [Batch 251/347] [D loss: 0.488083] [G loss: 0.357522]\n",
      "[Epoch 70/100] [Batch 252/347] [D loss: 0.482825] [G loss: 0.366077]\n",
      "[Epoch 70/100] [Batch 253/347] [D loss: 0.426916] [G loss: 0.362573]\n",
      "[Epoch 70/100] [Batch 254/347] [D loss: 0.423409] [G loss: 0.370449]\n",
      "[Epoch 70/100] [Batch 255/347] [D loss: 0.420068] [G loss: 0.375276]\n",
      "[Epoch 70/100] [Batch 256/347] [D loss: 0.422266] [G loss: 0.370789]\n",
      "[Epoch 70/100] [Batch 257/347] [D loss: 0.410947] [G loss: 0.367853]\n",
      "[Epoch 70/100] [Batch 258/347] [D loss: 0.373275] [G loss: 0.368723]\n",
      "[Epoch 70/100] [Batch 259/347] [D loss: 0.374843] [G loss: 0.367713]\n",
      "[Epoch 70/100] [Batch 260/347] [D loss: 0.375869] [G loss: 0.368028]\n",
      "[Epoch 70/100] [Batch 261/347] [D loss: 0.364263] [G loss: 0.374159]\n",
      "[Epoch 70/100] [Batch 262/347] [D loss: 0.321375] [G loss: 0.377324]\n",
      "[Epoch 70/100] [Batch 263/347] [D loss: 0.315958] [G loss: 0.380257]\n",
      "[Epoch 70/100] [Batch 264/347] [D loss: 0.319149] [G loss: 0.385243]\n",
      "[Epoch 70/100] [Batch 265/347] [D loss: 0.327688] [G loss: 0.388296]\n",
      "[Epoch 70/100] [Batch 266/347] [D loss: 0.393851] [G loss: 0.392130]\n",
      "[Epoch 70/100] [Batch 267/347] [D loss: 0.414911] [G loss: 0.394200]\n",
      "[Epoch 70/100] [Batch 268/347] [D loss: 0.423619] [G loss: 0.393411]\n",
      "[Epoch 70/100] [Batch 269/347] [D loss: 0.425685] [G loss: 0.390889]\n",
      "[Epoch 70/100] [Batch 270/347] [D loss: 0.456531] [G loss: 0.387413]\n",
      "[Epoch 70/100] [Batch 271/347] [D loss: 0.420542] [G loss: 0.389077]\n",
      "[Epoch 70/100] [Batch 272/347] [D loss: 0.414346] [G loss: 0.408692]\n",
      "[Epoch 70/100] [Batch 273/347] [D loss: 0.387098] [G loss: 0.430360]\n",
      "[Epoch 70/100] [Batch 274/347] [D loss: 0.336358] [G loss: 0.451841]\n",
      "[Epoch 70/100] [Batch 275/347] [D loss: 0.283721] [G loss: 0.470162]\n",
      "[Epoch 70/100] [Batch 276/347] [D loss: 0.482854] [G loss: 0.479522]\n",
      "[Epoch 70/100] [Batch 277/347] [D loss: 0.510151] [G loss: 0.492164]\n",
      "[Epoch 70/100] [Batch 278/347] [D loss: 0.518821] [G loss: 0.502973]\n",
      "[Epoch 70/100] [Batch 279/347] [D loss: 0.521722] [G loss: 0.505235]\n",
      "[Epoch 70/100] [Batch 280/347] [D loss: 0.526376] [G loss: 0.505676]\n",
      "[Epoch 70/100] [Batch 281/347] [D loss: 0.531300] [G loss: 0.506345]\n",
      "[Epoch 70/100] [Batch 282/347] [D loss: 0.532536] [G loss: 0.509734]\n",
      "[Epoch 70/100] [Batch 283/347] [D loss: 0.533374] [G loss: 0.511301]\n",
      "[Epoch 70/100] [Batch 284/347] [D loss: 0.534236] [G loss: 0.513864]\n",
      "[Epoch 70/100] [Batch 285/347] [D loss: 0.538014] [G loss: 0.515010]\n",
      "[Epoch 70/100] [Batch 286/347] [D loss: 0.535776] [G loss: 0.501226]\n",
      "[Epoch 70/100] [Batch 287/347] [D loss: 0.536333] [G loss: 0.498682]\n",
      "[Epoch 70/100] [Batch 288/347] [D loss: 0.536599] [G loss: 0.496214]\n",
      "[Epoch 70/100] [Batch 289/347] [D loss: 0.534946] [G loss: 0.491470]\n",
      "[Epoch 70/100] [Batch 290/347] [D loss: 0.535389] [G loss: 0.507556]\n",
      "[Epoch 70/100] [Batch 291/347] [D loss: 0.534045] [G loss: 0.514718]\n",
      "[Epoch 70/100] [Batch 292/347] [D loss: 0.531535] [G loss: 0.518796]\n",
      "[Epoch 70/100] [Batch 293/347] [D loss: 0.500322] [G loss: 0.524446]\n",
      "[Epoch 70/100] [Batch 294/347] [D loss: 0.499429] [G loss: 0.528958]\n",
      "[Epoch 70/100] [Batch 295/347] [D loss: 0.498915] [G loss: 0.527675]\n",
      "[Epoch 70/100] [Batch 296/347] [D loss: 0.496904] [G loss: 0.526092]\n",
      "[Epoch 70/100] [Batch 297/347] [D loss: 0.530451] [G loss: 0.530448]\n",
      "[Epoch 70/100] [Batch 298/347] [D loss: 0.534252] [G loss: 0.523779]\n",
      "[Epoch 70/100] [Batch 299/347] [D loss: 0.532977] [G loss: 0.519006]\n",
      "[Epoch 70/100] [Batch 300/347] [D loss: 0.531385] [G loss: 0.516767]\n",
      "[Epoch 70/100] [Batch 301/347] [D loss: 0.531554] [G loss: 0.499635]\n",
      "[Epoch 70/100] [Batch 302/347] [D loss: 0.531969] [G loss: 0.492256]\n",
      "[Epoch 70/100] [Batch 303/347] [D loss: 0.530784] [G loss: 0.480976]\n",
      "[Epoch 70/100] [Batch 304/347] [D loss: 0.497907] [G loss: 0.468543]\n",
      "[Epoch 70/100] [Batch 305/347] [D loss: 0.466064] [G loss: 0.460789]\n",
      "[Epoch 70/100] [Batch 306/347] [D loss: 0.459939] [G loss: 0.460412]\n",
      "[Epoch 70/100] [Batch 307/347] [D loss: 0.447669] [G loss: 0.464691]\n",
      "[Epoch 70/100] [Batch 308/347] [D loss: 0.458179] [G loss: 0.467584]\n",
      "[Epoch 70/100] [Batch 309/347] [D loss: 0.522261] [G loss: 0.479812]\n",
      "[Epoch 70/100] [Batch 310/347] [D loss: 0.537862] [G loss: 0.490032]\n",
      "[Epoch 70/100] [Batch 311/347] [D loss: 0.531733] [G loss: 0.485334]\n",
      "[Epoch 70/100] [Batch 312/347] [D loss: 0.518954] [G loss: 0.478183]\n",
      "[Epoch 70/100] [Batch 313/347] [D loss: 0.508604] [G loss: 0.466800]\n",
      "[Epoch 70/100] [Batch 314/347] [D loss: 0.502498] [G loss: 0.449769]\n",
      "[Epoch 70/100] [Batch 315/347] [D loss: 0.501733] [G loss: 0.435963]\n",
      "[Epoch 70/100] [Batch 316/347] [D loss: 0.500745] [G loss: 0.434051]\n",
      "[Epoch 70/100] [Batch 317/347] [D loss: 0.507424] [G loss: 0.434637]\n",
      "[Epoch 70/100] [Batch 318/347] [D loss: 0.511278] [G loss: 0.444218]\n",
      "[Epoch 70/100] [Batch 319/347] [D loss: 0.503210] [G loss: 0.451880]\n",
      "[Epoch 70/100] [Batch 320/347] [D loss: 0.494685] [G loss: 0.445201]\n",
      "[Epoch 70/100] [Batch 321/347] [D loss: 0.479820] [G loss: 0.431782]\n",
      "[Epoch 70/100] [Batch 322/347] [D loss: 0.477060] [G loss: 0.415815]\n",
      "[Epoch 70/100] [Batch 323/347] [D loss: 0.418012] [G loss: 0.396215]\n",
      "[Epoch 70/100] [Batch 324/347] [D loss: 0.399729] [G loss: 0.376722]\n",
      "[Epoch 70/100] [Batch 325/347] [D loss: 0.395207] [G loss: 0.354569]\n",
      "[Epoch 70/100] [Batch 326/347] [D loss: 0.391424] [G loss: 0.333330]\n",
      "[Epoch 70/100] [Batch 327/347] [D loss: 0.373704] [G loss: 0.315065]\n",
      "[Epoch 70/100] [Batch 328/347] [D loss: 0.379683] [G loss: 0.298820]\n",
      "[Epoch 70/100] [Batch 329/347] [D loss: 0.382068] [G loss: 0.290511]\n",
      "[Epoch 70/100] [Batch 330/347] [D loss: 0.383881] [G loss: 0.287817]\n",
      "[Epoch 70/100] [Batch 331/347] [D loss: 0.410470] [G loss: 0.290730]\n",
      "[Epoch 70/100] [Batch 332/347] [D loss: 0.486846] [G loss: 0.313166]\n",
      "[Epoch 70/100] [Batch 333/347] [D loss: 0.458752] [G loss: 0.315827]\n",
      "[Epoch 70/100] [Batch 334/347] [D loss: 0.450348] [G loss: 0.315421]\n",
      "[Epoch 70/100] [Batch 335/347] [D loss: 0.450104] [G loss: 0.320250]\n",
      "[Epoch 70/100] [Batch 336/347] [D loss: 0.448999] [G loss: 0.327725]\n",
      "[Epoch 70/100] [Batch 337/347] [D loss: 0.492326] [G loss: 0.339624]\n",
      "[Epoch 70/100] [Batch 338/347] [D loss: 0.528595] [G loss: 0.355641]\n",
      "[Epoch 70/100] [Batch 339/347] [D loss: 0.507043] [G loss: 0.365341]\n",
      "[Epoch 70/100] [Batch 340/347] [D loss: 0.480355] [G loss: 0.370486]\n",
      "[Epoch 70/100] [Batch 341/347] [D loss: 0.484968] [G loss: 0.378991]\n",
      "[Epoch 70/100] [Batch 342/347] [D loss: 0.361902] [G loss: 0.375948]\n",
      "[Epoch 70/100] [Batch 343/347] [D loss: 0.326310] [G loss: 0.369116]\n",
      "[Epoch 70/100] [Batch 344/347] [D loss: 0.291507] [G loss: 0.374029]\n",
      "[Epoch 70/100] [Batch 345/347] [D loss: 0.223572] [G loss: 0.382525]\n",
      "[Epoch 70/100] [Batch 346/347] [D loss: 0.217474] [G loss: 0.393722]\n",
      "[Epoch 70/100] [Batch 347/347] [D loss: 0.213050] [G loss: 0.404870]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 71/100] [Batch 1/347] [D loss: 0.488229] [G loss: 0.425906]\n",
      "[Epoch 71/100] [Batch 2/347] [D loss: 0.502436] [G loss: 0.432131]\n",
      "[Epoch 71/100] [Batch 3/347] [D loss: 0.530165] [G loss: 0.441165]\n",
      "[Epoch 71/100] [Batch 4/347] [D loss: 0.532186] [G loss: 0.446038]\n",
      "[Epoch 71/100] [Batch 5/347] [D loss: 0.531653] [G loss: 0.445856]\n",
      "[Epoch 71/100] [Batch 6/347] [D loss: 0.521198] [G loss: 0.446065]\n",
      "[Epoch 71/100] [Batch 7/347] [D loss: 0.508264] [G loss: 0.439723]\n",
      "[Epoch 71/100] [Batch 8/347] [D loss: 0.508582] [G loss: 0.439540]\n",
      "[Epoch 71/100] [Batch 9/347] [D loss: 0.509384] [G loss: 0.440960]\n",
      "[Epoch 71/100] [Batch 10/347] [D loss: 0.510771] [G loss: 0.441916]\n",
      "[Epoch 71/100] [Batch 11/347] [D loss: 0.525760] [G loss: 0.451007]\n",
      "[Epoch 71/100] [Batch 12/347] [D loss: 0.529700] [G loss: 0.453017]\n",
      "[Epoch 71/100] [Batch 13/347] [D loss: 0.520931] [G loss: 0.451491]\n",
      "[Epoch 71/100] [Batch 14/347] [D loss: 0.515636] [G loss: 0.449924]\n",
      "[Epoch 71/100] [Batch 15/347] [D loss: 0.514053] [G loss: 0.439226]\n",
      "[Epoch 71/100] [Batch 16/347] [D loss: 0.511795] [G loss: 0.432112]\n",
      "[Epoch 71/100] [Batch 17/347] [D loss: 0.512549] [G loss: 0.432861]\n",
      "[Epoch 71/100] [Batch 18/347] [D loss: 0.515256] [G loss: 0.431627]\n",
      "[Epoch 71/100] [Batch 19/347] [D loss: 0.515937] [G loss: 0.434891]\n",
      "[Epoch 71/100] [Batch 20/347] [D loss: 0.521878] [G loss: 0.437530]\n",
      "[Epoch 71/100] [Batch 21/347] [D loss: 0.499873] [G loss: 0.430162]\n",
      "[Epoch 71/100] [Batch 22/347] [D loss: 0.497547] [G loss: 0.425285]\n",
      "[Epoch 71/100] [Batch 23/347] [D loss: 0.498646] [G loss: 0.418739]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 71/100] [Batch 24/347] [D loss: 0.451483] [G loss: 0.406802]\n",
      "[Epoch 71/100] [Batch 25/347] [D loss: 0.343830] [G loss: 0.408460]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 71/100] [Batch 26/347] [D loss: 0.335253] [G loss: 0.400877]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 71/100] [Batch 27/347] [D loss: 0.324535] [G loss: 0.394674]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 71/100] [Batch 28/347] [D loss: 0.321153] [G loss: 0.388397]\n",
      "[Epoch 71/100] [Batch 29/347] [D loss: 0.346450] [G loss: 0.377296]\n",
      "[Epoch 71/100] [Batch 30/347] [D loss: 0.332474] [G loss: 0.363233]\n",
      "[Epoch 71/100] [Batch 31/347] [D loss: 0.331637] [G loss: 0.349647]\n",
      "[Epoch 71/100] [Batch 32/347] [D loss: 0.344307] [G loss: 0.335214]\n",
      "[Epoch 71/100] [Batch 33/347] [D loss: 0.361827] [G loss: 0.326075]\n",
      "[Epoch 71/100] [Batch 34/347] [D loss: 0.403043] [G loss: 0.316086]\n",
      "[Epoch 71/100] [Batch 35/347] [D loss: 0.402529] [G loss: 0.306777]\n",
      "[Epoch 71/100] [Batch 36/347] [D loss: 0.424165] [G loss: 0.299157]\n",
      "[Epoch 71/100] [Batch 37/347] [D loss: 0.433494] [G loss: 0.292650]\n",
      "[Epoch 71/100] [Batch 38/347] [D loss: 0.437363] [G loss: 0.286517]\n",
      "[Epoch 71/100] [Batch 39/347] [D loss: 0.452417] [G loss: 0.291144]\n",
      "[Epoch 71/100] [Batch 40/347] [D loss: 0.485640] [G loss: 0.302340]\n",
      "[Epoch 71/100] [Batch 41/347] [D loss: 0.505001] [G loss: 0.311460]\n",
      "[Epoch 71/100] [Batch 42/347] [D loss: 0.503093] [G loss: 0.326699]\n",
      "[Epoch 71/100] [Batch 43/347] [D loss: 0.526005] [G loss: 0.348486]\n",
      "[Epoch 71/100] [Batch 44/347] [D loss: 0.513581] [G loss: 0.361541]\n",
      "[Epoch 71/100] [Batch 45/347] [D loss: 0.485642] [G loss: 0.359567]\n",
      "[Epoch 71/100] [Batch 46/347] [D loss: 0.400269] [G loss: 0.356930]\n",
      "[Epoch 71/100] [Batch 47/347] [D loss: 0.389406] [G loss: 0.354113]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 71/100] [Batch 48/347] [D loss: 0.259199] [G loss: 0.360502]\n",
      "[Epoch 71/100] [Batch 49/347] [D loss: 0.252438] [G loss: 0.375960]\n",
      "[Epoch 71/100] [Batch 50/347] [D loss: 0.245843] [G loss: 0.393125]\n",
      "[Epoch 71/100] [Batch 51/347] [D loss: 0.242954] [G loss: 0.404704]\n",
      "[Epoch 71/100] [Batch 52/347] [D loss: 0.364312] [G loss: 0.405767]\n",
      "[Epoch 71/100] [Batch 53/347] [D loss: 0.409533] [G loss: 0.396706]\n",
      "[Epoch 71/100] [Batch 54/347] [D loss: 0.388743] [G loss: 0.386712]\n",
      "[Epoch 71/100] [Batch 55/347] [D loss: 0.382561] [G loss: 0.387883]\n",
      "[Epoch 71/100] [Batch 56/347] [D loss: 0.371545] [G loss: 0.391556]\n",
      "[Epoch 71/100] [Batch 57/347] [D loss: 0.325963] [G loss: 0.393437]\n",
      "[Epoch 71/100] [Batch 58/347] [D loss: 0.335994] [G loss: 0.391904]\n",
      "[Epoch 71/100] [Batch 59/347] [D loss: 0.334006] [G loss: 0.381375]\n",
      "[Epoch 71/100] [Batch 60/347] [D loss: 0.320496] [G loss: 0.363501]\n",
      "[Epoch 71/100] [Batch 61/347] [D loss: 0.338540] [G loss: 0.345057]\n",
      "[Epoch 71/100] [Batch 62/347] [D loss: 0.340829] [G loss: 0.341930]\n",
      "[Epoch 71/100] [Batch 63/347] [D loss: 0.339361] [G loss: 0.342034]\n",
      "[Epoch 71/100] [Batch 64/347] [D loss: 0.320343] [G loss: 0.341857]\n",
      "[Epoch 71/100] [Batch 65/347] [D loss: 0.272350] [G loss: 0.351067]\n",
      "[Epoch 71/100] [Batch 66/347] [D loss: 0.271070] [G loss: 0.356313]\n",
      "[Epoch 71/100] [Batch 67/347] [D loss: 0.267026] [G loss: 0.353351]\n",
      "[Epoch 71/100] [Batch 68/347] [D loss: 0.266918] [G loss: 0.357001]\n",
      "[Epoch 71/100] [Batch 69/347] [D loss: 0.285121] [G loss: 0.361137]\n",
      "[Epoch 71/100] [Batch 70/347] [D loss: 0.285990] [G loss: 0.363055]\n",
      "[Epoch 71/100] [Batch 71/347] [D loss: 0.284470] [G loss: 0.379395]\n",
      "[Epoch 71/100] [Batch 72/347] [D loss: 0.298006] [G loss: 0.393353]\n",
      "[Epoch 71/100] [Batch 73/347] [D loss: 0.419247] [G loss: 0.390970]\n",
      "[Epoch 71/100] [Batch 74/347] [D loss: 0.422456] [G loss: 0.391599]\n",
      "[Epoch 71/100] [Batch 75/347] [D loss: 0.421332] [G loss: 0.390587]\n",
      "[Epoch 71/100] [Batch 76/347] [D loss: 0.420633] [G loss: 0.387301]\n",
      "[Epoch 71/100] [Batch 77/347] [D loss: 0.456559] [G loss: 0.392879]\n",
      "[Epoch 71/100] [Batch 78/347] [D loss: 0.511260] [G loss: 0.402674]\n",
      "[Epoch 71/100] [Batch 79/347] [D loss: 0.512220] [G loss: 0.401751]\n",
      "[Epoch 71/100] [Batch 80/347] [D loss: 0.409864] [G loss: 0.387086]\n",
      "[Epoch 71/100] [Batch 81/347] [D loss: 0.387304] [G loss: 0.380678]\n",
      "[Epoch 71/100] [Batch 82/347] [D loss: 0.386256] [G loss: 0.374357]\n",
      "[Epoch 71/100] [Batch 83/347] [D loss: 0.389907] [G loss: 0.366539]\n",
      "[Epoch 71/100] [Batch 84/347] [D loss: 0.515295] [G loss: 0.366531]\n",
      "[Epoch 71/100] [Batch 85/347] [D loss: 0.588681] [G loss: 0.365146]\n",
      "[Epoch 71/100] [Batch 86/347] [D loss: 0.590524] [G loss: 0.366110]\n",
      "[Epoch 71/100] [Batch 87/347] [D loss: 0.590723] [G loss: 0.370913]\n",
      "[Epoch 71/100] [Batch 88/347] [D loss: 0.601461] [G loss: 0.378224]\n",
      "[Epoch 71/100] [Batch 89/347] [D loss: 0.603572] [G loss: 0.390135]\n",
      "[Epoch 71/100] [Batch 90/347] [D loss: 0.597230] [G loss: 0.402517]\n",
      "[Epoch 71/100] [Batch 91/347] [D loss: 0.589671] [G loss: 0.414360]\n",
      "[Epoch 71/100] [Batch 92/347] [D loss: 0.582744] [G loss: 0.429085]\n",
      "[Epoch 71/100] [Batch 93/347] [D loss: 0.574073] [G loss: 0.442843]\n",
      "[Epoch 71/100] [Batch 94/347] [D loss: 0.562598] [G loss: 0.452096]\n",
      "[Epoch 71/100] [Batch 95/347] [D loss: 0.554110] [G loss: 0.462214]\n",
      "[Epoch 71/100] [Batch 96/347] [D loss: 0.549195] [G loss: 0.473461]\n",
      "[Epoch 71/100] [Batch 97/347] [D loss: 0.544016] [G loss: 0.480895]\n",
      "[Epoch 71/100] [Batch 98/347] [D loss: 0.539295] [G loss: 0.489003]\n",
      "[Epoch 71/100] [Batch 99/347] [D loss: 0.538732] [G loss: 0.494852]\n",
      "[Epoch 71/100] [Batch 100/347] [D loss: 0.537455] [G loss: 0.498566]\n",
      "[Epoch 71/100] [Batch 101/347] [D loss: 0.537468] [G loss: 0.500076]\n",
      "[Epoch 71/100] [Batch 102/347] [D loss: 0.541858] [G loss: 0.499754]\n",
      "[Epoch 71/100] [Batch 103/347] [D loss: 0.541885] [G loss: 0.502845]\n",
      "[Epoch 71/100] [Batch 104/347] [D loss: 0.538776] [G loss: 0.499388]\n",
      "[Epoch 71/100] [Batch 105/347] [D loss: 0.481593] [G loss: 0.494013]\n",
      "[Epoch 71/100] [Batch 106/347] [D loss: 0.299935] [G loss: 0.485019]\n",
      "[Epoch 71/100] [Batch 107/347] [D loss: 0.301178] [G loss: 0.483228]\n",
      "[Epoch 71/100] [Batch 108/347] [D loss: 0.295342] [G loss: 0.481856]\n",
      "[Epoch 71/100] [Batch 109/347] [D loss: 0.276714] [G loss: 0.474352]\n",
      "[Epoch 71/100] [Batch 110/347] [D loss: 0.347464] [G loss: 0.480632]\n",
      "[Epoch 71/100] [Batch 111/347] [D loss: 0.327269] [G loss: 0.480819]\n",
      "[Epoch 71/100] [Batch 112/347] [D loss: 0.306457] [G loss: 0.477449]\n",
      "[Epoch 71/100] [Batch 113/347] [D loss: 0.448321] [G loss: 0.486282]\n",
      "[Epoch 71/100] [Batch 114/347] [D loss: 0.514326] [G loss: 0.481560]\n",
      "[Epoch 71/100] [Batch 115/347] [D loss: 0.506442] [G loss: 0.451718]\n",
      "[Epoch 71/100] [Batch 116/347] [D loss: 0.449480] [G loss: 0.419165]\n",
      "[Epoch 71/100] [Batch 117/347] [D loss: 0.435423] [G loss: 0.388547]\n",
      "[Epoch 71/100] [Batch 118/347] [D loss: 0.371843] [G loss: 0.356090]\n",
      "[Epoch 71/100] [Batch 119/347] [D loss: 0.369962] [G loss: 0.336932]\n",
      "[Epoch 71/100] [Batch 120/347] [D loss: 0.370425] [G loss: 0.326977]\n",
      "[Epoch 71/100] [Batch 121/347] [D loss: 0.376248] [G loss: 0.317063]\n",
      "[Epoch 71/100] [Batch 122/347] [D loss: 0.489991] [G loss: 0.314145]\n",
      "[Epoch 71/100] [Batch 123/347] [D loss: 0.541195] [G loss: 0.317444]\n",
      "[Epoch 71/100] [Batch 124/347] [D loss: 0.477139] [G loss: 0.319309]\n",
      "[Epoch 71/100] [Batch 125/347] [D loss: 0.445573] [G loss: 0.328316]\n",
      "[Epoch 71/100] [Batch 126/347] [D loss: 0.409476] [G loss: 0.339301]\n",
      "[Epoch 71/100] [Batch 127/347] [D loss: 0.406144] [G loss: 0.347897]\n",
      "[Epoch 71/100] [Batch 128/347] [D loss: 0.388316] [G loss: 0.352201]\n",
      "[Epoch 71/100] [Batch 129/347] [D loss: 0.327549] [G loss: 0.358033]\n",
      "[Epoch 71/100] [Batch 130/347] [D loss: 0.269983] [G loss: 0.385052]\n",
      "[Epoch 71/100] [Batch 131/347] [D loss: 0.243946] [G loss: 0.406719]\n",
      "[Epoch 71/100] [Batch 132/347] [D loss: 0.218906] [G loss: 0.430397]\n",
      "[Epoch 71/100] [Batch 133/347] [D loss: 0.203349] [G loss: 0.452054]\n",
      "[Epoch 71/100] [Batch 134/347] [D loss: 0.183577] [G loss: 0.469865]\n",
      "[Epoch 71/100] [Batch 135/347] [D loss: 0.174865] [G loss: 0.481398]\n",
      "[Epoch 71/100] [Batch 136/347] [D loss: 0.171590] [G loss: 0.484001]\n",
      "[Epoch 71/100] [Batch 137/347] [D loss: 0.429213] [G loss: 0.482668]\n",
      "[Epoch 71/100] [Batch 138/347] [D loss: 0.457290] [G loss: 0.478366]\n",
      "[Epoch 71/100] [Batch 139/347] [D loss: 0.469135] [G loss: 0.469956]\n",
      "[Epoch 71/100] [Batch 140/347] [D loss: 0.471882] [G loss: 0.469501]\n",
      "[Epoch 71/100] [Batch 141/347] [D loss: 0.446308] [G loss: 0.463462]\n",
      "[Epoch 71/100] [Batch 142/347] [D loss: 0.455015] [G loss: 0.456621]\n",
      "[Epoch 71/100] [Batch 143/347] [D loss: 0.452302] [G loss: 0.446924]\n",
      "[Epoch 71/100] [Batch 144/347] [D loss: 0.446601] [G loss: 0.437205]\n",
      "[Epoch 71/100] [Batch 145/347] [D loss: 0.465733] [G loss: 0.436057]\n",
      "[Epoch 71/100] [Batch 146/347] [D loss: 0.481142] [G loss: 0.430011]\n",
      "[Epoch 71/100] [Batch 147/347] [D loss: 0.498170] [G loss: 0.429534]\n",
      "[Epoch 71/100] [Batch 148/347] [D loss: 0.504754] [G loss: 0.430060]\n",
      "[Epoch 71/100] [Batch 149/347] [D loss: 0.471016] [G loss: 0.422993]\n",
      "[Epoch 71/100] [Batch 150/347] [D loss: 0.445595] [G loss: 0.415846]\n",
      "[Epoch 71/100] [Batch 151/347] [D loss: 0.414184] [G loss: 0.401936]\n",
      "[Epoch 71/100] [Batch 152/347] [D loss: 0.378786] [G loss: 0.378616]\n",
      "[Epoch 71/100] [Batch 153/347] [D loss: 0.367381] [G loss: 0.349994]\n",
      "[Epoch 71/100] [Batch 154/347] [D loss: 0.348468] [G loss: 0.325090]\n",
      "[Epoch 71/100] [Batch 155/347] [D loss: 0.340767] [G loss: 0.307747]\n",
      "[Epoch 71/100] [Batch 156/347] [D loss: 0.335740] [G loss: 0.288063]\n",
      "[Epoch 71/100] [Batch 157/347] [D loss: 0.336537] [G loss: 0.279951]\n",
      "[Epoch 71/100] [Batch 158/347] [D loss: 0.325150] [G loss: 0.281726]\n",
      "[Epoch 71/100] [Batch 159/347] [D loss: 0.337463] [G loss: 0.288388]\n",
      "[Epoch 71/100] [Batch 160/347] [D loss: 0.333067] [G loss: 0.307210]\n",
      "[Epoch 71/100] [Batch 161/347] [D loss: 0.312586] [G loss: 0.326593]\n",
      "[Epoch 71/100] [Batch 162/347] [D loss: 0.296205] [G loss: 0.339871]\n",
      "[Epoch 71/100] [Batch 163/347] [D loss: 0.290803] [G loss: 0.347666]\n",
      "[Epoch 71/100] [Batch 164/347] [D loss: 0.281698] [G loss: 0.364411]\n",
      "[Epoch 71/100] [Batch 165/347] [D loss: 0.281554] [G loss: 0.383780]\n",
      "[Epoch 71/100] [Batch 166/347] [D loss: 0.286773] [G loss: 0.402417]\n",
      "[Epoch 71/100] [Batch 167/347] [D loss: 0.317971] [G loss: 0.431423]\n",
      "[Epoch 71/100] [Batch 168/347] [D loss: 0.317624] [G loss: 0.444807]\n",
      "[Epoch 71/100] [Batch 169/347] [D loss: 0.457643] [G loss: 0.456157]\n",
      "[Epoch 71/100] [Batch 170/347] [D loss: 0.524356] [G loss: 0.464727]\n",
      "[Epoch 71/100] [Batch 171/347] [D loss: 0.528658] [G loss: 0.466231]\n",
      "[Epoch 71/100] [Batch 172/347] [D loss: 0.530570] [G loss: 0.469427]\n",
      "[Epoch 71/100] [Batch 173/347] [D loss: 0.531217] [G loss: 0.470179]\n",
      "[Epoch 71/100] [Batch 174/347] [D loss: 0.529901] [G loss: 0.475629]\n",
      "[Epoch 71/100] [Batch 175/347] [D loss: 0.543045] [G loss: 0.482717]\n",
      "[Epoch 71/100] [Batch 176/347] [D loss: 0.550950] [G loss: 0.488297]\n",
      "[Epoch 71/100] [Batch 177/347] [D loss: 0.550000] [G loss: 0.488485]\n",
      "[Epoch 71/100] [Batch 178/347] [D loss: 0.547241] [G loss: 0.485025]\n",
      "[Epoch 71/100] [Batch 179/347] [D loss: 0.545586] [G loss: 0.484569]\n",
      "[Epoch 71/100] [Batch 180/347] [D loss: 0.543428] [G loss: 0.483287]\n",
      "[Epoch 71/100] [Batch 181/347] [D loss: 0.542134] [G loss: 0.488638]\n",
      "[Epoch 71/100] [Batch 182/347] [D loss: 0.542045] [G loss: 0.491854]\n",
      "[Epoch 71/100] [Batch 183/347] [D loss: 0.541469] [G loss: 0.495378]\n",
      "[Epoch 71/100] [Batch 184/347] [D loss: 0.544451] [G loss: 0.499993]\n",
      "[Epoch 71/100] [Batch 185/347] [D loss: 0.543813] [G loss: 0.498770]\n",
      "[Epoch 71/100] [Batch 186/347] [D loss: 0.540961] [G loss: 0.499181]\n",
      "[Epoch 71/100] [Batch 187/347] [D loss: 0.538581] [G loss: 0.497476]\n",
      "[Epoch 71/100] [Batch 188/347] [D loss: 0.532486] [G loss: 0.490475]\n",
      "[Epoch 71/100] [Batch 189/347] [D loss: 0.524041] [G loss: 0.485081]\n",
      "[Epoch 71/100] [Batch 190/347] [D loss: 0.522614] [G loss: 0.482627]\n",
      "[Epoch 71/100] [Batch 191/347] [D loss: 0.522473] [G loss: 0.479973]\n",
      "[Epoch 71/100] [Batch 192/347] [D loss: 0.523235] [G loss: 0.479948]\n",
      "[Epoch 71/100] [Batch 193/347] [D loss: 0.532013] [G loss: 0.480094]\n",
      "[Epoch 71/100] [Batch 194/347] [D loss: 0.530839] [G loss: 0.476020]\n",
      "[Epoch 71/100] [Batch 195/347] [D loss: 0.527041] [G loss: 0.472316]\n",
      "[Epoch 71/100] [Batch 196/347] [D loss: 0.519245] [G loss: 0.468403]\n",
      "[Epoch 71/100] [Batch 197/347] [D loss: 0.517934] [G loss: 0.465996]\n",
      "[Epoch 71/100] [Batch 198/347] [D loss: 0.517151] [G loss: 0.466871]\n",
      "[Epoch 71/100] [Batch 199/347] [D loss: 0.515444] [G loss: 0.464980]\n",
      "[Epoch 71/100] [Batch 200/347] [D loss: 0.523865] [G loss: 0.462976]\n",
      "[Epoch 71/100] [Batch 201/347] [D loss: 0.527521] [G loss: 0.460074]\n",
      "[Epoch 71/100] [Batch 202/347] [D loss: 0.527852] [G loss: 0.456805]\n",
      "[Epoch 71/100] [Batch 203/347] [D loss: 0.531663] [G loss: 0.453635]\n",
      "[Epoch 71/100] [Batch 204/347] [D loss: 0.529902] [G loss: 0.454579]\n",
      "[Epoch 71/100] [Batch 205/347] [D loss: 0.528938] [G loss: 0.457330]\n",
      "[Epoch 71/100] [Batch 206/347] [D loss: 0.528068] [G loss: 0.458189]\n",
      "[Epoch 71/100] [Batch 207/347] [D loss: 0.518044] [G loss: 0.458178]\n",
      "[Epoch 71/100] [Batch 208/347] [D loss: 0.515047] [G loss: 0.459295]\n",
      "[Epoch 71/100] [Batch 209/347] [D loss: 0.511140] [G loss: 0.452147]\n",
      "[Epoch 71/100] [Batch 210/347] [D loss: 0.482342] [G loss: 0.448964]\n",
      "[Epoch 71/100] [Batch 211/347] [D loss: 0.420139] [G loss: 0.439417]\n",
      "[Epoch 71/100] [Batch 212/347] [D loss: 0.240557] [G loss: 0.419854]\n",
      "[Epoch 71/100] [Batch 213/347] [D loss: 0.234910] [G loss: 0.417465]\n",
      "[Epoch 71/100] [Batch 214/347] [D loss: 0.224766] [G loss: 0.412680]\n",
      "[Epoch 71/100] [Batch 215/347] [D loss: 0.220380] [G loss: 0.408457]\n",
      "[Epoch 71/100] [Batch 216/347] [D loss: 0.410840] [G loss: 0.415296]\n",
      "[Epoch 71/100] [Batch 217/347] [D loss: 0.448770] [G loss: 0.420195]\n",
      "[Epoch 71/100] [Batch 218/347] [D loss: 0.476202] [G loss: 0.424694]\n",
      "[Epoch 71/100] [Batch 219/347] [D loss: 0.459973] [G loss: 0.418191]\n",
      "[Epoch 71/100] [Batch 220/347] [D loss: 0.442335] [G loss: 0.408232]\n",
      "[Epoch 71/100] [Batch 221/347] [D loss: 0.457017] [G loss: 0.391957]\n",
      "[Epoch 71/100] [Batch 222/347] [D loss: 0.455795] [G loss: 0.367708]\n",
      "[Epoch 71/100] [Batch 223/347] [D loss: 0.430421] [G loss: 0.333034]\n",
      "[Epoch 71/100] [Batch 224/347] [D loss: 0.437115] [G loss: 0.296375]\n",
      "[Epoch 71/100] [Batch 225/347] [D loss: 0.449077] [G loss: 0.266264]\n",
      "[Epoch 71/100] [Batch 226/347] [D loss: 0.457708] [G loss: 0.246484]\n",
      "[Epoch 71/100] [Batch 227/347] [D loss: 0.493361] [G loss: 0.241452]\n",
      "[Epoch 71/100] [Batch 228/347] [D loss: 0.510770] [G loss: 0.240709]\n",
      "[Epoch 71/100] [Batch 229/347] [D loss: 0.515953] [G loss: 0.243462]\n",
      "[Epoch 71/100] [Batch 230/347] [D loss: 0.527349] [G loss: 0.247999]\n",
      "[Epoch 71/100] [Batch 231/347] [D loss: 0.503686] [G loss: 0.247911]\n",
      "[Epoch 71/100] [Batch 232/347] [D loss: 0.485220] [G loss: 0.254079]\n",
      "[Epoch 71/100] [Batch 233/347] [D loss: 0.423437] [G loss: 0.268613]\n",
      "[Epoch 71/100] [Batch 234/347] [D loss: 0.389373] [G loss: 0.286437]\n",
      "[Epoch 71/100] [Batch 235/347] [D loss: 0.377766] [G loss: 0.312467]\n",
      "[Epoch 71/100] [Batch 236/347] [D loss: 0.367593] [G loss: 0.338774]\n",
      "[Epoch 71/100] [Batch 237/347] [D loss: 0.424888] [G loss: 0.358794]\n",
      "[Epoch 71/100] [Batch 238/347] [D loss: 0.505082] [G loss: 0.370786]\n",
      "[Epoch 71/100] [Batch 239/347] [D loss: 0.505683] [G loss: 0.376697]\n",
      "[Epoch 71/100] [Batch 240/347] [D loss: 0.509467] [G loss: 0.383130]\n",
      "[Epoch 71/100] [Batch 241/347] [D loss: 0.511310] [G loss: 0.391058]\n",
      "[Epoch 71/100] [Batch 242/347] [D loss: 0.523165] [G loss: 0.400235]\n",
      "[Epoch 71/100] [Batch 243/347] [D loss: 0.480021] [G loss: 0.407186]\n",
      "[Epoch 71/100] [Batch 244/347] [D loss: 0.458479] [G loss: 0.402656]\n",
      "[Epoch 71/100] [Batch 245/347] [D loss: 0.461976] [G loss: 0.393242]\n",
      "[Epoch 71/100] [Batch 246/347] [D loss: 0.463093] [G loss: 0.380543]\n",
      "[Epoch 71/100] [Batch 247/347] [D loss: 0.484398] [G loss: 0.370122]\n",
      "[Epoch 71/100] [Batch 248/347] [D loss: 0.502032] [G loss: 0.370812]\n",
      "[Epoch 71/100] [Batch 249/347] [D loss: 0.486265] [G loss: 0.375355]\n",
      "[Epoch 71/100] [Batch 250/347] [D loss: 0.480890] [G loss: 0.381455]\n",
      "[Epoch 71/100] [Batch 251/347] [D loss: 0.469535] [G loss: 0.384712]\n",
      "[Epoch 71/100] [Batch 252/347] [D loss: 0.459952] [G loss: 0.384325]\n",
      "[Epoch 71/100] [Batch 253/347] [D loss: 0.398695] [G loss: 0.369893]\n",
      "[Epoch 71/100] [Batch 254/347] [D loss: 0.392228] [G loss: 0.364965]\n",
      "[Epoch 71/100] [Batch 255/347] [D loss: 0.387208] [G loss: 0.356726]\n",
      "[Epoch 71/100] [Batch 256/347] [D loss: 0.388487] [G loss: 0.341446]\n",
      "[Epoch 71/100] [Batch 257/347] [D loss: 0.377030] [G loss: 0.331944]\n",
      "[Epoch 71/100] [Batch 258/347] [D loss: 0.343113] [G loss: 0.324198]\n",
      "[Epoch 71/100] [Batch 259/347] [D loss: 0.346160] [G loss: 0.317679]\n",
      "[Epoch 71/100] [Batch 260/347] [D loss: 0.347860] [G loss: 0.315772]\n",
      "[Epoch 71/100] [Batch 261/347] [D loss: 0.339086] [G loss: 0.322435]\n",
      "[Epoch 71/100] [Batch 262/347] [D loss: 0.308346] [G loss: 0.329503]\n",
      "[Epoch 71/100] [Batch 263/347] [D loss: 0.300738] [G loss: 0.338817]\n",
      "[Epoch 71/100] [Batch 264/347] [D loss: 0.296957] [G loss: 0.350029]\n",
      "[Epoch 71/100] [Batch 265/347] [D loss: 0.300681] [G loss: 0.361023]\n",
      "[Epoch 71/100] [Batch 266/347] [D loss: 0.357014] [G loss: 0.371203]\n",
      "[Epoch 71/100] [Batch 267/347] [D loss: 0.377714] [G loss: 0.377758]\n",
      "[Epoch 71/100] [Batch 268/347] [D loss: 0.387861] [G loss: 0.381057]\n",
      "[Epoch 71/100] [Batch 269/347] [D loss: 0.391941] [G loss: 0.381668]\n",
      "[Epoch 71/100] [Batch 270/347] [D loss: 0.423433] [G loss: 0.379820]\n",
      "[Epoch 71/100] [Batch 271/347] [D loss: 0.397516] [G loss: 0.381899]\n",
      "[Epoch 71/100] [Batch 272/347] [D loss: 0.453070] [G loss: 0.399261]\n",
      "[Epoch 71/100] [Batch 273/347] [D loss: 0.419324] [G loss: 0.416365]\n",
      "[Epoch 71/100] [Batch 274/347] [D loss: 0.371478] [G loss: 0.431598]\n",
      "[Epoch 71/100] [Batch 275/347] [D loss: 0.312912] [G loss: 0.444382]\n",
      "[Epoch 71/100] [Batch 276/347] [D loss: 0.468678] [G loss: 0.446392]\n",
      "[Epoch 71/100] [Batch 277/347] [D loss: 0.495639] [G loss: 0.457288]\n",
      "[Epoch 71/100] [Batch 278/347] [D loss: 0.503727] [G loss: 0.466864]\n",
      "[Epoch 71/100] [Batch 279/347] [D loss: 0.507756] [G loss: 0.468369]\n",
      "[Epoch 71/100] [Batch 280/347] [D loss: 0.511682] [G loss: 0.468351]\n",
      "[Epoch 71/100] [Batch 281/347] [D loss: 0.517449] [G loss: 0.468565]\n",
      "[Epoch 71/100] [Batch 282/347] [D loss: 0.519059] [G loss: 0.471810]\n",
      "[Epoch 71/100] [Batch 283/347] [D loss: 0.520162] [G loss: 0.473132]\n",
      "[Epoch 71/100] [Batch 284/347] [D loss: 0.521212] [G loss: 0.475380]\n",
      "[Epoch 71/100] [Batch 285/347] [D loss: 0.526124] [G loss: 0.476533]\n",
      "[Epoch 71/100] [Batch 286/347] [D loss: 0.523402] [G loss: 0.462517]\n",
      "[Epoch 71/100] [Batch 287/347] [D loss: 0.524053] [G loss: 0.459900]\n",
      "[Epoch 71/100] [Batch 288/347] [D loss: 0.524310] [G loss: 0.457221]\n",
      "[Epoch 71/100] [Batch 289/347] [D loss: 0.522084] [G loss: 0.452258]\n",
      "[Epoch 71/100] [Batch 290/347] [D loss: 0.522442] [G loss: 0.468114]\n",
      "[Epoch 71/100] [Batch 291/347] [D loss: 0.520617] [G loss: 0.475064]\n",
      "[Epoch 71/100] [Batch 292/347] [D loss: 0.517416] [G loss: 0.478867]\n",
      "[Epoch 71/100] [Batch 293/347] [D loss: 0.479748] [G loss: 0.484214]\n",
      "[Epoch 71/100] [Batch 294/347] [D loss: 0.478230] [G loss: 0.488367]\n",
      "[Epoch 71/100] [Batch 295/347] [D loss: 0.476989] [G loss: 0.486769]\n",
      "[Epoch 71/100] [Batch 296/347] [D loss: 0.474099] [G loss: 0.484721]\n",
      "[Epoch 71/100] [Batch 297/347] [D loss: 0.515799] [G loss: 0.488618]\n",
      "[Epoch 71/100] [Batch 298/347] [D loss: 0.520098] [G loss: 0.481558]\n",
      "[Epoch 71/100] [Batch 299/347] [D loss: 0.518648] [G loss: 0.476420]\n",
      "[Epoch 71/100] [Batch 300/347] [D loss: 0.516615] [G loss: 0.473557]\n",
      "[Epoch 71/100] [Batch 301/347] [D loss: 0.516721] [G loss: 0.459389]\n",
      "[Epoch 71/100] [Batch 302/347] [D loss: 0.517227] [G loss: 0.449869]\n",
      "[Epoch 71/100] [Batch 303/347] [D loss: 0.515736] [G loss: 0.436851]\n",
      "[Epoch 71/100] [Batch 304/347] [D loss: 0.471614] [G loss: 0.424025]\n",
      "[Epoch 71/100] [Batch 305/347] [D loss: 0.425136] [G loss: 0.417154]\n",
      "[Epoch 71/100] [Batch 306/347] [D loss: 0.414435] [G loss: 0.416319]\n",
      "[Epoch 71/100] [Batch 307/347] [D loss: 0.395582] [G loss: 0.419206]\n",
      "[Epoch 71/100] [Batch 308/347] [D loss: 0.409737] [G loss: 0.419871]\n",
      "[Epoch 71/100] [Batch 309/347] [D loss: 0.503286] [G loss: 0.430967]\n",
      "[Epoch 71/100] [Batch 310/347] [D loss: 0.524144] [G loss: 0.440134]\n",
      "[Epoch 71/100] [Batch 311/347] [D loss: 0.516186] [G loss: 0.434478]\n",
      "[Epoch 71/100] [Batch 312/347] [D loss: 0.495996] [G loss: 0.425961]\n",
      "[Epoch 71/100] [Batch 313/347] [D loss: 0.473665] [G loss: 0.412576]\n",
      "[Epoch 71/100] [Batch 314/347] [D loss: 0.458693] [G loss: 0.392444]\n",
      "[Epoch 71/100] [Batch 315/347] [D loss: 0.448450] [G loss: 0.373471]\n",
      "[Epoch 71/100] [Batch 316/347] [D loss: 0.447546] [G loss: 0.363922]\n",
      "[Epoch 71/100] [Batch 317/347] [D loss: 0.453852] [G loss: 0.353877]\n",
      "[Epoch 71/100] [Batch 318/347] [D loss: 0.456972] [G loss: 0.350938]\n",
      "[Epoch 71/100] [Batch 319/347] [D loss: 0.435886] [G loss: 0.344283]\n",
      "[Epoch 71/100] [Batch 320/347] [D loss: 0.427261] [G loss: 0.323655]\n",
      "[Epoch 71/100] [Batch 321/347] [D loss: 0.410022] [G loss: 0.300323]\n",
      "[Epoch 71/100] [Batch 322/347] [D loss: 0.421650] [G loss: 0.279620]\n",
      "[Epoch 71/100] [Batch 323/347] [D loss: 0.379515] [G loss: 0.263226]\n",
      "[Epoch 71/100] [Batch 324/347] [D loss: 0.379129] [G loss: 0.254831]\n",
      "[Epoch 71/100] [Batch 325/347] [D loss: 0.385165] [G loss: 0.250970]\n",
      "[Epoch 71/100] [Batch 326/347] [D loss: 0.384338] [G loss: 0.252548]\n",
      "[Epoch 71/100] [Batch 327/347] [D loss: 0.369050] [G loss: 0.260824]\n",
      "[Epoch 71/100] [Batch 328/347] [D loss: 0.364376] [G loss: 0.271860]\n",
      "[Epoch 71/100] [Batch 329/347] [D loss: 0.354805] [G loss: 0.286968]\n",
      "[Epoch 71/100] [Batch 330/347] [D loss: 0.346986] [G loss: 0.303775]\n",
      "[Epoch 71/100] [Batch 331/347] [D loss: 0.368012] [G loss: 0.322758]\n",
      "[Epoch 71/100] [Batch 332/347] [D loss: 0.449017] [G loss: 0.355136]\n",
      "[Epoch 71/100] [Batch 333/347] [D loss: 0.421219] [G loss: 0.363067]\n",
      "[Epoch 71/100] [Batch 334/347] [D loss: 0.416641] [G loss: 0.362746]\n",
      "[Epoch 71/100] [Batch 335/347] [D loss: 0.419008] [G loss: 0.364980]\n",
      "[Epoch 71/100] [Batch 336/347] [D loss: 0.420983] [G loss: 0.365851]\n",
      "[Epoch 71/100] [Batch 337/347] [D loss: 0.462104] [G loss: 0.370267]\n",
      "[Epoch 71/100] [Batch 338/347] [D loss: 0.495830] [G loss: 0.377889]\n",
      "[Epoch 71/100] [Batch 339/347] [D loss: 0.472666] [G loss: 0.377648]\n",
      "[Epoch 71/100] [Batch 340/347] [D loss: 0.448144] [G loss: 0.372552]\n",
      "[Epoch 71/100] [Batch 341/347] [D loss: 0.452129] [G loss: 0.371138]\n",
      "[Epoch 71/100] [Batch 342/347] [D loss: 0.329121] [G loss: 0.357289]\n",
      "[Epoch 71/100] [Batch 343/347] [D loss: 0.293932] [G loss: 0.341335]\n",
      "[Epoch 71/100] [Batch 344/347] [D loss: 0.270012] [G loss: 0.338659]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 71/100] [Batch 345/347] [D loss: 0.229346] [G loss: 0.343721]\n",
      "[Epoch 71/100] [Batch 346/347] [D loss: 0.223922] [G loss: 0.353791]\n",
      "[Epoch 71/100] [Batch 347/347] [D loss: 0.216144] [G loss: 0.365715]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 72/100] [Batch 1/347] [D loss: 0.449687] [G loss: 0.388744]\n",
      "[Epoch 72/100] [Batch 2/347] [D loss: 0.474264] [G loss: 0.395033]\n",
      "[Epoch 72/100] [Batch 3/347] [D loss: 0.514418] [G loss: 0.403918]\n",
      "[Epoch 72/100] [Batch 4/347] [D loss: 0.518976] [G loss: 0.408511]\n",
      "[Epoch 72/100] [Batch 5/347] [D loss: 0.519409] [G loss: 0.408464]\n",
      "[Epoch 72/100] [Batch 6/347] [D loss: 0.500997] [G loss: 0.407998]\n",
      "[Epoch 72/100] [Batch 7/347] [D loss: 0.477459] [G loss: 0.400226]\n",
      "[Epoch 72/100] [Batch 8/347] [D loss: 0.477818] [G loss: 0.398028]\n",
      "[Epoch 72/100] [Batch 9/347] [D loss: 0.476091] [G loss: 0.396946]\n",
      "[Epoch 72/100] [Batch 10/347] [D loss: 0.477892] [G loss: 0.394611]\n",
      "[Epoch 72/100] [Batch 11/347] [D loss: 0.509082] [G loss: 0.400360]\n",
      "[Epoch 72/100] [Batch 12/347] [D loss: 0.519695] [G loss: 0.399215]\n",
      "[Epoch 72/100] [Batch 13/347] [D loss: 0.497191] [G loss: 0.394192]\n",
      "[Epoch 72/100] [Batch 14/347] [D loss: 0.480887] [G loss: 0.388200]\n",
      "[Epoch 72/100] [Batch 15/347] [D loss: 0.475243] [G loss: 0.372611]\n",
      "[Epoch 72/100] [Batch 16/347] [D loss: 0.465442] [G loss: 0.358655]\n",
      "[Epoch 72/100] [Batch 17/347] [D loss: 0.467240] [G loss: 0.351195]\n",
      "[Epoch 72/100] [Batch 18/347] [D loss: 0.474744] [G loss: 0.341516]\n",
      "[Epoch 72/100] [Batch 19/347] [D loss: 0.475708] [G loss: 0.335238]\n",
      "[Epoch 72/100] [Batch 20/347] [D loss: 0.500397] [G loss: 0.329420]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 72/100] [Batch 21/347] [D loss: 0.433260] [G loss: 0.314472]\n",
      "[Epoch 72/100] [Batch 22/347] [D loss: 0.435313] [G loss: 0.304217]\n",
      "[Epoch 72/100] [Batch 23/347] [D loss: 0.438787] [G loss: 0.293979]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 72/100] [Batch 24/347] [D loss: 0.398421] [G loss: 0.282319]\n",
      "[Epoch 72/100] [Batch 25/347] [D loss: 0.317993] [G loss: 0.289218]\n",
      "[Epoch 72/100] [Batch 26/347] [D loss: 0.317118] [G loss: 0.298141]\n",
      "[Epoch 72/100] [Batch 27/347] [D loss: 0.311653] [G loss: 0.315069]\n",
      "[Epoch 72/100] [Batch 28/347] [D loss: 0.307310] [G loss: 0.336172]\n",
      "[Epoch 72/100] [Batch 29/347] [D loss: 0.322522] [G loss: 0.357532]\n",
      "[Epoch 72/100] [Batch 30/347] [D loss: 0.311409] [G loss: 0.372630]\n",
      "[Epoch 72/100] [Batch 31/347] [D loss: 0.309537] [G loss: 0.383905]\n",
      "[Epoch 72/100] [Batch 32/347] [D loss: 0.322186] [G loss: 0.389482]\n",
      "[Epoch 72/100] [Batch 33/347] [D loss: 0.341742] [G loss: 0.393255]\n",
      "[Epoch 72/100] [Batch 34/347] [D loss: 0.391240] [G loss: 0.391668]\n",
      "[Epoch 72/100] [Batch 35/347] [D loss: 0.392066] [G loss: 0.382489]\n",
      "[Epoch 72/100] [Batch 36/347] [D loss: 0.419152] [G loss: 0.373706]\n",
      "[Epoch 72/100] [Batch 37/347] [D loss: 0.427504] [G loss: 0.361697]\n",
      "[Epoch 72/100] [Batch 38/347] [D loss: 0.428270] [G loss: 0.345607]\n",
      "[Epoch 72/100] [Batch 39/347] [D loss: 0.439877] [G loss: 0.339269]\n",
      "[Epoch 72/100] [Batch 40/347] [D loss: 0.469609] [G loss: 0.335864]\n",
      "[Epoch 72/100] [Batch 41/347] [D loss: 0.489004] [G loss: 0.329504]\n",
      "[Epoch 72/100] [Batch 42/347] [D loss: 0.486701] [G loss: 0.329643]\n",
      "[Epoch 72/100] [Batch 43/347] [D loss: 0.511705] [G loss: 0.335801]\n",
      "[Epoch 72/100] [Batch 44/347] [D loss: 0.498879] [G loss: 0.333785]\n",
      "[Epoch 72/100] [Batch 45/347] [D loss: 0.469400] [G loss: 0.319216]\n",
      "[Epoch 72/100] [Batch 46/347] [D loss: 0.386955] [G loss: 0.304188]\n",
      "[Epoch 72/100] [Batch 47/347] [D loss: 0.380128] [G loss: 0.297557]\n",
      "[Epoch 72/100] [Batch 48/347] [D loss: 0.299549] [G loss: 0.307082]\n",
      "[Epoch 72/100] [Batch 49/347] [D loss: 0.285478] [G loss: 0.328885]\n",
      "[Epoch 72/100] [Batch 50/347] [D loss: 0.269795] [G loss: 0.356754]\n",
      "[Epoch 72/100] [Batch 51/347] [D loss: 0.251011] [G loss: 0.379696]\n",
      "[Epoch 72/100] [Batch 52/347] [D loss: 0.342722] [G loss: 0.391231]\n",
      "[Epoch 72/100] [Batch 53/347] [D loss: 0.384507] [G loss: 0.390200]\n",
      "[Epoch 72/100] [Batch 54/347] [D loss: 0.369175] [G loss: 0.385542]\n",
      "[Epoch 72/100] [Batch 55/347] [D loss: 0.367708] [G loss: 0.391968]\n",
      "[Epoch 72/100] [Batch 56/347] [D loss: 0.362094] [G loss: 0.400284]\n",
      "[Epoch 72/100] [Batch 57/347] [D loss: 0.316922] [G loss: 0.406660]\n",
      "[Epoch 72/100] [Batch 58/347] [D loss: 0.328943] [G loss: 0.407937]\n",
      "[Epoch 72/100] [Batch 59/347] [D loss: 0.325890] [G loss: 0.399784]\n",
      "[Epoch 72/100] [Batch 60/347] [D loss: 0.308803] [G loss: 0.381899]\n",
      "[Epoch 72/100] [Batch 61/347] [D loss: 0.325317] [G loss: 0.362225]\n",
      "[Epoch 72/100] [Batch 62/347] [D loss: 0.325056] [G loss: 0.356328]\n",
      "[Epoch 72/100] [Batch 63/347] [D loss: 0.320695] [G loss: 0.351443]\n",
      "[Epoch 72/100] [Batch 64/347] [D loss: 0.300986] [G loss: 0.346147]\n",
      "[Epoch 72/100] [Batch 65/347] [D loss: 0.256473] [G loss: 0.350036]\n",
      "[Epoch 72/100] [Batch 66/347] [D loss: 0.258773] [G loss: 0.350081]\n",
      "[Epoch 72/100] [Batch 67/347] [D loss: 0.257929] [G loss: 0.342233]\n",
      "[Epoch 72/100] [Batch 68/347] [D loss: 0.258957] [G loss: 0.343771]\n",
      "[Epoch 72/100] [Batch 69/347] [D loss: 0.273271] [G loss: 0.346978]\n",
      "[Epoch 72/100] [Batch 70/347] [D loss: 0.271703] [G loss: 0.348808]\n",
      "[Epoch 72/100] [Batch 71/347] [D loss: 0.269760] [G loss: 0.366571]\n",
      "[Epoch 72/100] [Batch 72/347] [D loss: 0.280395] [G loss: 0.381338]\n",
      "[Epoch 72/100] [Batch 73/347] [D loss: 0.398097] [G loss: 0.380139]\n",
      "[Epoch 72/100] [Batch 74/347] [D loss: 0.402583] [G loss: 0.381958]\n",
      "[Epoch 72/100] [Batch 75/347] [D loss: 0.402382] [G loss: 0.381811]\n",
      "[Epoch 72/100] [Batch 76/347] [D loss: 0.402624] [G loss: 0.378251]\n",
      "[Epoch 72/100] [Batch 77/347] [D loss: 0.442293] [G loss: 0.391947]\n",
      "[Epoch 72/100] [Batch 78/347] [D loss: 0.500855] [G loss: 0.401188]\n",
      "[Epoch 72/100] [Batch 79/347] [D loss: 0.500456] [G loss: 0.399581]\n",
      "[Epoch 72/100] [Batch 80/347] [D loss: 0.392621] [G loss: 0.383736]\n",
      "[Epoch 72/100] [Batch 81/347] [D loss: 0.369995] [G loss: 0.376892]\n",
      "[Epoch 72/100] [Batch 82/347] [D loss: 0.369750] [G loss: 0.371888]\n",
      "[Epoch 72/100] [Batch 83/347] [D loss: 0.374015] [G loss: 0.365033]\n",
      "[Epoch 72/100] [Batch 84/347] [D loss: 0.506224] [G loss: 0.365188]\n",
      "[Epoch 72/100] [Batch 85/347] [D loss: 0.583379] [G loss: 0.363812]\n",
      "[Epoch 72/100] [Batch 86/347] [D loss: 0.585349] [G loss: 0.363393]\n",
      "[Epoch 72/100] [Batch 87/347] [D loss: 0.586020] [G loss: 0.366082]\n",
      "[Epoch 72/100] [Batch 88/347] [D loss: 0.600814] [G loss: 0.371057]\n",
      "[Epoch 72/100] [Batch 89/347] [D loss: 0.606307] [G loss: 0.379527]\n",
      "[Epoch 72/100] [Batch 90/347] [D loss: 0.602312] [G loss: 0.387232]\n",
      "[Epoch 72/100] [Batch 91/347] [D loss: 0.598405] [G loss: 0.396564]\n",
      "[Epoch 72/100] [Batch 92/347] [D loss: 0.594159] [G loss: 0.408834]\n",
      "[Epoch 72/100] [Batch 93/347] [D loss: 0.588175] [G loss: 0.421041]\n",
      "[Epoch 72/100] [Batch 94/347] [D loss: 0.575573] [G loss: 0.430555]\n",
      "[Epoch 72/100] [Batch 95/347] [D loss: 0.566513] [G loss: 0.441624]\n",
      "[Epoch 72/100] [Batch 96/347] [D loss: 0.561508] [G loss: 0.454295]\n",
      "[Epoch 72/100] [Batch 97/347] [D loss: 0.555359] [G loss: 0.464288]\n",
      "[Epoch 72/100] [Batch 98/347] [D loss: 0.548071] [G loss: 0.474833]\n",
      "[Epoch 72/100] [Batch 99/347] [D loss: 0.546605] [G loss: 0.483222]\n",
      "[Epoch 72/100] [Batch 100/347] [D loss: 0.543489] [G loss: 0.490138]\n",
      "[Epoch 72/100] [Batch 101/347] [D loss: 0.542005] [G loss: 0.494113]\n",
      "[Epoch 72/100] [Batch 102/347] [D loss: 0.545897] [G loss: 0.496379]\n",
      "[Epoch 72/100] [Batch 103/347] [D loss: 0.544930] [G loss: 0.501482]\n",
      "[Epoch 72/100] [Batch 104/347] [D loss: 0.540679] [G loss: 0.499935]\n",
      "[Epoch 72/100] [Batch 105/347] [D loss: 0.473732] [G loss: 0.495693]\n",
      "[Epoch 72/100] [Batch 106/347] [D loss: 0.258591] [G loss: 0.487844]\n",
      "[Epoch 72/100] [Batch 107/347] [D loss: 0.263499] [G loss: 0.486941]\n",
      "[Epoch 72/100] [Batch 108/347] [D loss: 0.260008] [G loss: 0.485971]\n",
      "[Epoch 72/100] [Batch 109/347] [D loss: 0.244397] [G loss: 0.476727]\n",
      "[Epoch 72/100] [Batch 110/347] [D loss: 0.316066] [G loss: 0.485469]\n",
      "[Epoch 72/100] [Batch 111/347] [D loss: 0.299058] [G loss: 0.485084]\n",
      "[Epoch 72/100] [Batch 112/347] [D loss: 0.282888] [G loss: 0.481365]\n",
      "[Epoch 72/100] [Batch 113/347] [D loss: 0.442750] [G loss: 0.489761]\n",
      "[Epoch 72/100] [Batch 114/347] [D loss: 0.513171] [G loss: 0.485138]\n",
      "[Epoch 72/100] [Batch 115/347] [D loss: 0.505806] [G loss: 0.456247]\n",
      "[Epoch 72/100] [Batch 116/347] [D loss: 0.440536] [G loss: 0.423546]\n",
      "[Epoch 72/100] [Batch 117/347] [D loss: 0.425407] [G loss: 0.393431]\n",
      "[Epoch 72/100] [Batch 118/347] [D loss: 0.360717] [G loss: 0.362947]\n",
      "[Epoch 72/100] [Batch 119/347] [D loss: 0.359143] [G loss: 0.344220]\n",
      "[Epoch 72/100] [Batch 120/347] [D loss: 0.359706] [G loss: 0.336522]\n",
      "[Epoch 72/100] [Batch 121/347] [D loss: 0.364379] [G loss: 0.327290]\n",
      "[Epoch 72/100] [Batch 122/347] [D loss: 0.481646] [G loss: 0.326252]\n",
      "[Epoch 72/100] [Batch 123/347] [D loss: 0.533847] [G loss: 0.328311]\n",
      "[Epoch 72/100] [Batch 124/347] [D loss: 0.466826] [G loss: 0.329145]\n",
      "[Epoch 72/100] [Batch 125/347] [D loss: 0.434755] [G loss: 0.337302]\n",
      "[Epoch 72/100] [Batch 126/347] [D loss: 0.398050] [G loss: 0.347483]\n",
      "[Epoch 72/100] [Batch 127/347] [D loss: 0.395264] [G loss: 0.354762]\n",
      "[Epoch 72/100] [Batch 128/347] [D loss: 0.378155] [G loss: 0.358443]\n",
      "[Epoch 72/100] [Batch 129/347] [D loss: 0.320961] [G loss: 0.362651]\n",
      "[Epoch 72/100] [Batch 130/347] [D loss: 0.268859] [G loss: 0.384519]\n",
      "[Epoch 72/100] [Batch 131/347] [D loss: 0.242296] [G loss: 0.407103]\n",
      "[Epoch 72/100] [Batch 132/347] [D loss: 0.215594] [G loss: 0.432410]\n",
      "[Epoch 72/100] [Batch 133/347] [D loss: 0.200389] [G loss: 0.455411]\n",
      "[Epoch 72/100] [Batch 134/347] [D loss: 0.178828] [G loss: 0.474736]\n",
      "[Epoch 72/100] [Batch 135/347] [D loss: 0.167397] [G loss: 0.487279]\n",
      "[Epoch 72/100] [Batch 136/347] [D loss: 0.163432] [G loss: 0.490637]\n",
      "[Epoch 72/100] [Batch 137/347] [D loss: 0.427003] [G loss: 0.489615]\n",
      "[Epoch 72/100] [Batch 138/347] [D loss: 0.458789] [G loss: 0.485313]\n",
      "[Epoch 72/100] [Batch 139/347] [D loss: 0.469367] [G loss: 0.476956]\n",
      "[Epoch 72/100] [Batch 140/347] [D loss: 0.475405] [G loss: 0.476551]\n",
      "[Epoch 72/100] [Batch 141/347] [D loss: 0.449307] [G loss: 0.470371]\n",
      "[Epoch 72/100] [Batch 142/347] [D loss: 0.456544] [G loss: 0.463477]\n",
      "[Epoch 72/100] [Batch 143/347] [D loss: 0.454672] [G loss: 0.453662]\n",
      "[Epoch 72/100] [Batch 144/347] [D loss: 0.446699] [G loss: 0.443779]\n",
      "[Epoch 72/100] [Batch 145/347] [D loss: 0.466769] [G loss: 0.442038]\n",
      "[Epoch 72/100] [Batch 146/347] [D loss: 0.481260] [G loss: 0.438158]\n",
      "[Epoch 72/100] [Batch 147/347] [D loss: 0.498975] [G loss: 0.440615]\n",
      "[Epoch 72/100] [Batch 148/347] [D loss: 0.506046] [G loss: 0.439745]\n",
      "[Epoch 72/100] [Batch 149/347] [D loss: 0.468038] [G loss: 0.426830]\n",
      "[Epoch 72/100] [Batch 150/347] [D loss: 0.439312] [G loss: 0.415873]\n",
      "[Epoch 72/100] [Batch 151/347] [D loss: 0.403811] [G loss: 0.400636]\n",
      "[Epoch 72/100] [Batch 152/347] [D loss: 0.367372] [G loss: 0.375184]\n",
      "[Epoch 72/100] [Batch 153/347] [D loss: 0.355730] [G loss: 0.344924]\n",
      "[Epoch 72/100] [Batch 154/347] [D loss: 0.339333] [G loss: 0.318506]\n",
      "[Epoch 72/100] [Batch 155/347] [D loss: 0.334242] [G loss: 0.301805]\n",
      "[Epoch 72/100] [Batch 156/347] [D loss: 0.333031] [G loss: 0.284810]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 72/100] [Batch 157/347] [D loss: 0.333097] [G loss: 0.277299]\n",
      "[Epoch 72/100] [Batch 158/347] [D loss: 0.324375] [G loss: 0.281897]\n",
      "[Epoch 72/100] [Batch 159/347] [D loss: 0.336634] [G loss: 0.289963]\n",
      "[Epoch 72/100] [Batch 160/347] [D loss: 0.327453] [G loss: 0.310617]\n",
      "[Epoch 72/100] [Batch 161/347] [D loss: 0.308232] [G loss: 0.330982]\n",
      "[Epoch 72/100] [Batch 162/347] [D loss: 0.289381] [G loss: 0.345132]\n",
      "[Epoch 72/100] [Batch 163/347] [D loss: 0.283058] [G loss: 0.352711]\n",
      "[Epoch 72/100] [Batch 164/347] [D loss: 0.275337] [G loss: 0.370887]\n",
      "[Epoch 72/100] [Batch 165/347] [D loss: 0.274595] [G loss: 0.390168]\n",
      "[Epoch 72/100] [Batch 166/347] [D loss: 0.281058] [G loss: 0.413537]\n",
      "[Epoch 72/100] [Batch 167/347] [D loss: 0.312564] [G loss: 0.443176]\n",
      "[Epoch 72/100] [Batch 168/347] [D loss: 0.313933] [G loss: 0.456396]\n",
      "[Epoch 72/100] [Batch 169/347] [D loss: 0.458061] [G loss: 0.467639]\n",
      "[Epoch 72/100] [Batch 170/347] [D loss: 0.528559] [G loss: 0.476138]\n",
      "[Epoch 72/100] [Batch 171/347] [D loss: 0.532169] [G loss: 0.477722]\n",
      "[Epoch 72/100] [Batch 172/347] [D loss: 0.533732] [G loss: 0.480437]\n",
      "[Epoch 72/100] [Batch 173/347] [D loss: 0.534799] [G loss: 0.481006]\n",
      "[Epoch 72/100] [Batch 174/347] [D loss: 0.533101] [G loss: 0.486388]\n",
      "[Epoch 72/100] [Batch 175/347] [D loss: 0.546468] [G loss: 0.493221]\n",
      "[Epoch 72/100] [Batch 176/347] [D loss: 0.555022] [G loss: 0.498495]\n",
      "[Epoch 72/100] [Batch 177/347] [D loss: 0.554100] [G loss: 0.498529]\n",
      "[Epoch 72/100] [Batch 178/347] [D loss: 0.551444] [G loss: 0.495253]\n",
      "[Epoch 72/100] [Batch 179/347] [D loss: 0.549623] [G loss: 0.494603]\n",
      "[Epoch 72/100] [Batch 180/347] [D loss: 0.547562] [G loss: 0.493569]\n",
      "[Epoch 72/100] [Batch 181/347] [D loss: 0.546089] [G loss: 0.499083]\n",
      "[Epoch 72/100] [Batch 182/347] [D loss: 0.545896] [G loss: 0.502702]\n",
      "[Epoch 72/100] [Batch 183/347] [D loss: 0.545093] [G loss: 0.506528]\n",
      "[Epoch 72/100] [Batch 184/347] [D loss: 0.547967] [G loss: 0.511406]\n",
      "[Epoch 72/100] [Batch 185/347] [D loss: 0.547221] [G loss: 0.510077]\n",
      "[Epoch 72/100] [Batch 186/347] [D loss: 0.544331] [G loss: 0.511004]\n",
      "[Epoch 72/100] [Batch 187/347] [D loss: 0.541910] [G loss: 0.509542]\n",
      "[Epoch 72/100] [Batch 188/347] [D loss: 0.535632] [G loss: 0.502882]\n",
      "[Epoch 72/100] [Batch 189/347] [D loss: 0.526679] [G loss: 0.497661]\n",
      "[Epoch 72/100] [Batch 190/347] [D loss: 0.525192] [G loss: 0.495337]\n",
      "[Epoch 72/100] [Batch 191/347] [D loss: 0.525024] [G loss: 0.492984]\n",
      "[Epoch 72/100] [Batch 192/347] [D loss: 0.525895] [G loss: 0.492967]\n",
      "[Epoch 72/100] [Batch 193/347] [D loss: 0.534893] [G loss: 0.493030]\n",
      "[Epoch 72/100] [Batch 194/347] [D loss: 0.533751] [G loss: 0.489181]\n",
      "[Epoch 72/100] [Batch 195/347] [D loss: 0.529861] [G loss: 0.485545]\n",
      "[Epoch 72/100] [Batch 196/347] [D loss: 0.521916] [G loss: 0.481805]\n",
      "[Epoch 72/100] [Batch 197/347] [D loss: 0.520686] [G loss: 0.479244]\n",
      "[Epoch 72/100] [Batch 198/347] [D loss: 0.519815] [G loss: 0.480239]\n",
      "[Epoch 72/100] [Batch 199/347] [D loss: 0.518045] [G loss: 0.478445]\n",
      "[Epoch 72/100] [Batch 200/347] [D loss: 0.526598] [G loss: 0.476440]\n",
      "[Epoch 72/100] [Batch 201/347] [D loss: 0.530364] [G loss: 0.473811]\n",
      "[Epoch 72/100] [Batch 202/347] [D loss: 0.530766] [G loss: 0.470461]\n",
      "[Epoch 72/100] [Batch 203/347] [D loss: 0.534885] [G loss: 0.467189]\n",
      "[Epoch 72/100] [Batch 204/347] [D loss: 0.533009] [G loss: 0.468093]\n",
      "[Epoch 72/100] [Batch 205/347] [D loss: 0.532022] [G loss: 0.470576]\n",
      "[Epoch 72/100] [Batch 206/347] [D loss: 0.531013] [G loss: 0.471406]\n",
      "[Epoch 72/100] [Batch 207/347] [D loss: 0.520599] [G loss: 0.471361]\n",
      "[Epoch 72/100] [Batch 208/347] [D loss: 0.517442] [G loss: 0.472334]\n",
      "[Epoch 72/100] [Batch 209/347] [D loss: 0.513693] [G loss: 0.465186]\n",
      "[Epoch 72/100] [Batch 210/347] [D loss: 0.485099] [G loss: 0.461829]\n",
      "[Epoch 72/100] [Batch 211/347] [D loss: 0.419848] [G loss: 0.452021]\n",
      "[Epoch 72/100] [Batch 212/347] [D loss: 0.234269] [G loss: 0.432238]\n",
      "[Epoch 72/100] [Batch 213/347] [D loss: 0.228092] [G loss: 0.425261]\n",
      "[Epoch 72/100] [Batch 214/347] [D loss: 0.217857] [G loss: 0.420028]\n",
      "[Epoch 72/100] [Batch 215/347] [D loss: 0.213206] [G loss: 0.415449]\n",
      "[Epoch 72/100] [Batch 216/347] [D loss: 0.409289] [G loss: 0.425880]\n",
      "[Epoch 72/100] [Batch 217/347] [D loss: 0.446108] [G loss: 0.430860]\n",
      "[Epoch 72/100] [Batch 218/347] [D loss: 0.477792] [G loss: 0.434257]\n",
      "[Epoch 72/100] [Batch 219/347] [D loss: 0.457183] [G loss: 0.427681]\n",
      "[Epoch 72/100] [Batch 220/347] [D loss: 0.439085] [G loss: 0.416858]\n",
      "[Epoch 72/100] [Batch 221/347] [D loss: 0.453375] [G loss: 0.400069]\n",
      "[Epoch 72/100] [Batch 222/347] [D loss: 0.450693] [G loss: 0.373713]\n",
      "[Epoch 72/100] [Batch 223/347] [D loss: 0.423413] [G loss: 0.337724]\n",
      "[Epoch 72/100] [Batch 224/347] [D loss: 0.429923] [G loss: 0.299832]\n",
      "[Epoch 72/100] [Batch 225/347] [D loss: 0.441988] [G loss: 0.267621]\n",
      "[Epoch 72/100] [Batch 226/347] [D loss: 0.451655] [G loss: 0.247356]\n",
      "[Epoch 72/100] [Batch 227/347] [D loss: 0.491066] [G loss: 0.240248]\n",
      "[Epoch 72/100] [Batch 228/347] [D loss: 0.509760] [G loss: 0.238845]\n",
      "[Epoch 72/100] [Batch 229/347] [D loss: 0.514765] [G loss: 0.241522]\n",
      "[Epoch 72/100] [Batch 230/347] [D loss: 0.527085] [G loss: 0.245636]\n",
      "[Epoch 72/100] [Batch 231/347] [D loss: 0.501924] [G loss: 0.244835]\n",
      "[Epoch 72/100] [Batch 232/347] [D loss: 0.483325] [G loss: 0.251733]\n",
      "[Epoch 72/100] [Batch 233/347] [D loss: 0.421329] [G loss: 0.267203]\n",
      "[Epoch 72/100] [Batch 234/347] [D loss: 0.385490] [G loss: 0.286800]\n",
      "[Epoch 72/100] [Batch 235/347] [D loss: 0.373477] [G loss: 0.314839]\n",
      "[Epoch 72/100] [Batch 236/347] [D loss: 0.360601] [G loss: 0.342092]\n",
      "[Epoch 72/100] [Batch 237/347] [D loss: 0.421467] [G loss: 0.364620]\n",
      "[Epoch 72/100] [Batch 238/347] [D loss: 0.502609] [G loss: 0.377493]\n",
      "[Epoch 72/100] [Batch 239/347] [D loss: 0.504375] [G loss: 0.384952]\n",
      "[Epoch 72/100] [Batch 240/347] [D loss: 0.508866] [G loss: 0.392035]\n",
      "[Epoch 72/100] [Batch 241/347] [D loss: 0.511691] [G loss: 0.399686]\n",
      "[Epoch 72/100] [Batch 242/347] [D loss: 0.523679] [G loss: 0.408848]\n",
      "[Epoch 72/100] [Batch 243/347] [D loss: 0.480031] [G loss: 0.415878]\n",
      "[Epoch 72/100] [Batch 244/347] [D loss: 0.455649] [G loss: 0.411187]\n",
      "[Epoch 72/100] [Batch 245/347] [D loss: 0.460366] [G loss: 0.401416]\n",
      "[Epoch 72/100] [Batch 246/347] [D loss: 0.460064] [G loss: 0.388504]\n",
      "[Epoch 72/100] [Batch 247/347] [D loss: 0.483991] [G loss: 0.377776]\n",
      "[Epoch 72/100] [Batch 248/347] [D loss: 0.503192] [G loss: 0.377738]\n",
      "[Epoch 72/100] [Batch 249/347] [D loss: 0.485346] [G loss: 0.379647]\n",
      "[Epoch 72/100] [Batch 250/347] [D loss: 0.478849] [G loss: 0.383528]\n",
      "[Epoch 72/100] [Batch 251/347] [D loss: 0.465728] [G loss: 0.389475]\n",
      "[Epoch 72/100] [Batch 252/347] [D loss: 0.455154] [G loss: 0.387481]\n",
      "[Epoch 72/100] [Batch 253/347] [D loss: 0.392034] [G loss: 0.371985]\n",
      "[Epoch 72/100] [Batch 254/347] [D loss: 0.385864] [G loss: 0.366530]\n",
      "[Epoch 72/100] [Batch 255/347] [D loss: 0.381846] [G loss: 0.357597]\n",
      "[Epoch 72/100] [Batch 256/347] [D loss: 0.383369] [G loss: 0.341330]\n",
      "[Epoch 72/100] [Batch 257/347] [D loss: 0.371368] [G loss: 0.331435]\n",
      "[Epoch 72/100] [Batch 258/347] [D loss: 0.337550] [G loss: 0.324675]\n",
      "[Epoch 72/100] [Batch 259/347] [D loss: 0.340720] [G loss: 0.319635]\n",
      "[Epoch 72/100] [Batch 260/347] [D loss: 0.341847] [G loss: 0.319220]\n",
      "[Epoch 72/100] [Batch 261/347] [D loss: 0.332973] [G loss: 0.327954]\n",
      "[Epoch 72/100] [Batch 262/347] [D loss: 0.301638] [G loss: 0.336614]\n",
      "[Epoch 72/100] [Batch 263/347] [D loss: 0.294187] [G loss: 0.347088]\n",
      "[Epoch 72/100] [Batch 264/347] [D loss: 0.289052] [G loss: 0.359834]\n",
      "[Epoch 72/100] [Batch 265/347] [D loss: 0.294209] [G loss: 0.371772]\n",
      "[Epoch 72/100] [Batch 266/347] [D loss: 0.352080] [G loss: 0.381762]\n",
      "[Epoch 72/100] [Batch 267/347] [D loss: 0.374456] [G loss: 0.388194]\n",
      "[Epoch 72/100] [Batch 268/347] [D loss: 0.384554] [G loss: 0.391154]\n",
      "[Epoch 72/100] [Batch 269/347] [D loss: 0.389064] [G loss: 0.391084]\n",
      "[Epoch 72/100] [Batch 270/347] [D loss: 0.421299] [G loss: 0.388491]\n",
      "[Epoch 72/100] [Batch 271/347] [D loss: 0.392799] [G loss: 0.389348]\n",
      "[Epoch 72/100] [Batch 272/347] [D loss: 0.461047] [G loss: 0.406886]\n",
      "[Epoch 72/100] [Batch 273/347] [D loss: 0.424580] [G loss: 0.423636]\n",
      "[Epoch 72/100] [Batch 274/347] [D loss: 0.379823] [G loss: 0.439772]\n",
      "[Epoch 72/100] [Batch 275/347] [D loss: 0.316355] [G loss: 0.453284]\n",
      "[Epoch 72/100] [Batch 276/347] [D loss: 0.467971] [G loss: 0.457053]\n",
      "[Epoch 72/100] [Batch 277/347] [D loss: 0.496591] [G loss: 0.467813]\n",
      "[Epoch 72/100] [Batch 278/347] [D loss: 0.504034] [G loss: 0.477381]\n",
      "[Epoch 72/100] [Batch 279/347] [D loss: 0.509355] [G loss: 0.478834]\n",
      "[Epoch 72/100] [Batch 280/347] [D loss: 0.513369] [G loss: 0.478521]\n",
      "[Epoch 72/100] [Batch 281/347] [D loss: 0.519586] [G loss: 0.478710]\n",
      "[Epoch 72/100] [Batch 282/347] [D loss: 0.521183] [G loss: 0.481756]\n",
      "[Epoch 72/100] [Batch 283/347] [D loss: 0.522252] [G loss: 0.483016]\n",
      "[Epoch 72/100] [Batch 284/347] [D loss: 0.523270] [G loss: 0.485115]\n",
      "[Epoch 72/100] [Batch 285/347] [D loss: 0.528340] [G loss: 0.486122]\n",
      "[Epoch 72/100] [Batch 286/347] [D loss: 0.525544] [G loss: 0.472018]\n",
      "[Epoch 72/100] [Batch 287/347] [D loss: 0.526242] [G loss: 0.469318]\n",
      "[Epoch 72/100] [Batch 288/347] [D loss: 0.526414] [G loss: 0.466607]\n",
      "[Epoch 72/100] [Batch 289/347] [D loss: 0.524203] [G loss: 0.461522]\n",
      "[Epoch 72/100] [Batch 290/347] [D loss: 0.524369] [G loss: 0.477311]\n",
      "[Epoch 72/100] [Batch 291/347] [D loss: 0.522511] [G loss: 0.484179]\n",
      "[Epoch 72/100] [Batch 292/347] [D loss: 0.519081] [G loss: 0.487950]\n",
      "[Epoch 72/100] [Batch 293/347] [D loss: 0.477365] [G loss: 0.493185]\n",
      "[Epoch 72/100] [Batch 294/347] [D loss: 0.475509] [G loss: 0.497102]\n",
      "[Epoch 72/100] [Batch 295/347] [D loss: 0.473329] [G loss: 0.495094]\n",
      "[Epoch 72/100] [Batch 296/347] [D loss: 0.469091] [G loss: 0.492700]\n",
      "[Epoch 72/100] [Batch 297/347] [D loss: 0.515379] [G loss: 0.496312]\n",
      "[Epoch 72/100] [Batch 298/347] [D loss: 0.521058] [G loss: 0.488739]\n",
      "[Epoch 72/100] [Batch 299/347] [D loss: 0.519439] [G loss: 0.483212]\n",
      "[Epoch 72/100] [Batch 300/347] [D loss: 0.517198] [G loss: 0.480062]\n",
      "[Epoch 72/100] [Batch 301/347] [D loss: 0.517212] [G loss: 0.464638]\n",
      "[Epoch 72/100] [Batch 302/347] [D loss: 0.517597] [G loss: 0.454887]\n",
      "[Epoch 72/100] [Batch 303/347] [D loss: 0.515943] [G loss: 0.442316]\n",
      "[Epoch 72/100] [Batch 304/347] [D loss: 0.459550] [G loss: 0.429077]\n",
      "[Epoch 72/100] [Batch 305/347] [D loss: 0.395452] [G loss: 0.420658]\n",
      "[Epoch 72/100] [Batch 306/347] [D loss: 0.379093] [G loss: 0.419034]\n",
      "[Epoch 72/100] [Batch 307/347] [D loss: 0.353643] [G loss: 0.420845]\n",
      "[Epoch 72/100] [Batch 308/347] [D loss: 0.374455] [G loss: 0.421095]\n",
      "[Epoch 72/100] [Batch 309/347] [D loss: 0.494937] [G loss: 0.430541]\n",
      "[Epoch 72/100] [Batch 310/347] [D loss: 0.524211] [G loss: 0.437244]\n",
      "[Epoch 72/100] [Batch 311/347] [D loss: 0.513726] [G loss: 0.428227]\n",
      "[Epoch 72/100] [Batch 312/347] [D loss: 0.475807] [G loss: 0.415062]\n",
      "[Epoch 72/100] [Batch 313/347] [D loss: 0.433983] [G loss: 0.394222]\n",
      "[Epoch 72/100] [Batch 314/347] [D loss: 0.410515] [G loss: 0.364131]\n",
      "[Epoch 72/100] [Batch 315/347] [D loss: 0.399289] [G loss: 0.334257]\n",
      "[Epoch 72/100] [Batch 316/347] [D loss: 0.411476] [G loss: 0.314620]\n",
      "[Epoch 72/100] [Batch 317/347] [D loss: 0.430684] [G loss: 0.298462]\n",
      "[Epoch 72/100] [Batch 318/347] [D loss: 0.439096] [G loss: 0.292952]\n",
      "[Epoch 72/100] [Batch 319/347] [D loss: 0.429899] [G loss: 0.290106]\n",
      "[Epoch 72/100] [Batch 320/347] [D loss: 0.433557] [G loss: 0.278361]\n",
      "[Epoch 72/100] [Batch 321/347] [D loss: 0.425454] [G loss: 0.266998]\n",
      "[Epoch 72/100] [Batch 322/347] [D loss: 0.437663] [G loss: 0.260056]\n",
      "[Epoch 72/100] [Batch 323/347] [D loss: 0.396174] [G loss: 0.258347]\n",
      "[Epoch 72/100] [Batch 324/347] [D loss: 0.386016] [G loss: 0.264800]\n",
      "[Epoch 72/100] [Batch 325/347] [D loss: 0.381394] [G loss: 0.273353]\n",
      "[Epoch 72/100] [Batch 326/347] [D loss: 0.372644] [G loss: 0.285678]\n",
      "[Epoch 72/100] [Batch 327/347] [D loss: 0.350780] [G loss: 0.301401]\n",
      "[Epoch 72/100] [Batch 328/347] [D loss: 0.346118] [G loss: 0.315953]\n",
      "[Epoch 72/100] [Batch 329/347] [D loss: 0.340962] [G loss: 0.333039]\n",
      "[Epoch 72/100] [Batch 330/347] [D loss: 0.338775] [G loss: 0.347561]\n",
      "[Epoch 72/100] [Batch 331/347] [D loss: 0.369680] [G loss: 0.363380]\n",
      "[Epoch 72/100] [Batch 332/347] [D loss: 0.460764] [G loss: 0.391692]\n",
      "[Epoch 72/100] [Batch 333/347] [D loss: 0.434362] [G loss: 0.394984]\n",
      "[Epoch 72/100] [Batch 334/347] [D loss: 0.429256] [G loss: 0.390718]\n",
      "[Epoch 72/100] [Batch 335/347] [D loss: 0.429939] [G loss: 0.388273]\n",
      "[Epoch 72/100] [Batch 336/347] [D loss: 0.428950] [G loss: 0.384483]\n",
      "[Epoch 72/100] [Batch 337/347] [D loss: 0.468650] [G loss: 0.384679]\n",
      "[Epoch 72/100] [Batch 338/347] [D loss: 0.501025] [G loss: 0.388197]\n",
      "[Epoch 72/100] [Batch 339/347] [D loss: 0.477183] [G loss: 0.384045]\n",
      "[Epoch 72/100] [Batch 340/347] [D loss: 0.450022] [G loss: 0.375442]\n",
      "[Epoch 72/100] [Batch 341/347] [D loss: 0.455613] [G loss: 0.370798]\n",
      "[Epoch 72/100] [Batch 342/347] [D loss: 0.329505] [G loss: 0.355291]\n",
      "[Epoch 72/100] [Batch 343/347] [D loss: 0.295144] [G loss: 0.339405]\n",
      "[Epoch 72/100] [Batch 344/347] [D loss: 0.274959] [G loss: 0.337032]\n",
      "[Epoch 72/100] [Batch 345/347] [D loss: 0.239778] [G loss: 0.344957]\n",
      "[Epoch 72/100] [Batch 346/347] [D loss: 0.231540] [G loss: 0.358858]\n",
      "[Epoch 72/100] [Batch 347/347] [D loss: 0.219270] [G loss: 0.375514]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 73/100] [Batch 1/347] [D loss: 0.452900] [G loss: 0.402813]\n",
      "[Epoch 73/100] [Batch 2/347] [D loss: 0.480565] [G loss: 0.411594]\n",
      "[Epoch 73/100] [Batch 3/347] [D loss: 0.521491] [G loss: 0.422936]\n",
      "[Epoch 73/100] [Batch 4/347] [D loss: 0.525959] [G loss: 0.429194]\n",
      "[Epoch 73/100] [Batch 5/347] [D loss: 0.525980] [G loss: 0.430854]\n",
      "[Epoch 73/100] [Batch 6/347] [D loss: 0.509947] [G loss: 0.431481]\n",
      "[Epoch 73/100] [Batch 7/347] [D loss: 0.489195] [G loss: 0.425385]\n",
      "[Epoch 73/100] [Batch 8/347] [D loss: 0.491973] [G loss: 0.424872]\n",
      "[Epoch 73/100] [Batch 9/347] [D loss: 0.490858] [G loss: 0.425584]\n",
      "[Epoch 73/100] [Batch 10/347] [D loss: 0.494003] [G loss: 0.425310]\n",
      "[Epoch 73/100] [Batch 11/347] [D loss: 0.516128] [G loss: 0.433039]\n",
      "[Epoch 73/100] [Batch 12/347] [D loss: 0.524893] [G loss: 0.433879]\n",
      "[Epoch 73/100] [Batch 13/347] [D loss: 0.510253] [G loss: 0.430640]\n",
      "[Epoch 73/100] [Batch 14/347] [D loss: 0.496594] [G loss: 0.427394]\n",
      "[Epoch 73/100] [Batch 15/347] [D loss: 0.495851] [G loss: 0.414483]\n",
      "[Epoch 73/100] [Batch 16/347] [D loss: 0.488724] [G loss: 0.404199]\n",
      "[Epoch 73/100] [Batch 17/347] [D loss: 0.490125] [G loss: 0.400735]\n",
      "[Epoch 73/100] [Batch 18/347] [D loss: 0.494962] [G loss: 0.394378]\n",
      "[Epoch 73/100] [Batch 19/347] [D loss: 0.493978] [G loss: 0.391852]\n",
      "[Epoch 73/100] [Batch 20/347] [D loss: 0.509358] [G loss: 0.387746]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 73/100] [Batch 21/347] [D loss: 0.448000] [G loss: 0.373405]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 73/100] [Batch 22/347] [D loss: 0.446344] [G loss: 0.360265]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 73/100] [Batch 23/347] [D loss: 0.445117] [G loss: 0.344420]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 73/100] [Batch 24/347] [D loss: 0.392904] [G loss: 0.325329]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 73/100] [Batch 25/347] [D loss: 0.295970] [G loss: 0.320426]\n",
      "[Epoch 73/100] [Batch 26/347] [D loss: 0.300443] [G loss: 0.317894]\n",
      "[Epoch 73/100] [Batch 27/347] [D loss: 0.302927] [G loss: 0.324160]\n",
      "[Epoch 73/100] [Batch 28/347] [D loss: 0.305422] [G loss: 0.336364]\n",
      "[Epoch 73/100] [Batch 29/347] [D loss: 0.324136] [G loss: 0.351341]\n",
      "[Epoch 73/100] [Batch 30/347] [D loss: 0.314504] [G loss: 0.361456]\n",
      "[Epoch 73/100] [Batch 31/347] [D loss: 0.311881] [G loss: 0.370977]\n",
      "[Epoch 73/100] [Batch 32/347] [D loss: 0.320679] [G loss: 0.376729]\n",
      "[Epoch 73/100] [Batch 33/347] [D loss: 0.336179] [G loss: 0.382130]\n",
      "[Epoch 73/100] [Batch 34/347] [D loss: 0.381810] [G loss: 0.382474]\n",
      "[Epoch 73/100] [Batch 35/347] [D loss: 0.383374] [G loss: 0.374917]\n",
      "[Epoch 73/100] [Batch 36/347] [D loss: 0.412196] [G loss: 0.368597]\n",
      "[Epoch 73/100] [Batch 37/347] [D loss: 0.422662] [G loss: 0.359083]\n",
      "[Epoch 73/100] [Batch 38/347] [D loss: 0.425928] [G loss: 0.346158]\n",
      "[Epoch 73/100] [Batch 39/347] [D loss: 0.440109] [G loss: 0.345141]\n",
      "[Epoch 73/100] [Batch 40/347] [D loss: 0.472228] [G loss: 0.344948]\n",
      "[Epoch 73/100] [Batch 41/347] [D loss: 0.493625] [G loss: 0.342459]\n",
      "[Epoch 73/100] [Batch 42/347] [D loss: 0.491492] [G loss: 0.346035]\n",
      "[Epoch 73/100] [Batch 43/347] [D loss: 0.516266] [G loss: 0.355726]\n",
      "[Epoch 73/100] [Batch 44/347] [D loss: 0.502690] [G loss: 0.356221]\n",
      "[Epoch 73/100] [Batch 45/347] [D loss: 0.473208] [G loss: 0.344336]\n",
      "[Epoch 73/100] [Batch 46/347] [D loss: 0.383824] [G loss: 0.329943]\n",
      "[Epoch 73/100] [Batch 47/347] [D loss: 0.375920] [G loss: 0.322745]\n",
      "[Epoch 73/100] [Batch 48/347] [D loss: 0.279083] [G loss: 0.330878]\n",
      "[Epoch 73/100] [Batch 49/347] [D loss: 0.266809] [G loss: 0.349510]\n",
      "[Epoch 73/100] [Batch 50/347] [D loss: 0.257271] [G loss: 0.374442]\n",
      "[Epoch 73/100] [Batch 51/347] [D loss: 0.242486] [G loss: 0.394406]\n",
      "[Epoch 73/100] [Batch 52/347] [D loss: 0.347783] [G loss: 0.402642]\n",
      "[Epoch 73/100] [Batch 53/347] [D loss: 0.390843] [G loss: 0.399438]\n",
      "[Epoch 73/100] [Batch 54/347] [D loss: 0.372826] [G loss: 0.393236]\n",
      "[Epoch 73/100] [Batch 55/347] [D loss: 0.368666] [G loss: 0.398432]\n",
      "[Epoch 73/100] [Batch 56/347] [D loss: 0.361294] [G loss: 0.405079]\n",
      "[Epoch 73/100] [Batch 57/347] [D loss: 0.313663] [G loss: 0.410194]\n",
      "[Epoch 73/100] [Batch 58/347] [D loss: 0.326102] [G loss: 0.409912]\n",
      "[Epoch 73/100] [Batch 59/347] [D loss: 0.323384] [G loss: 0.401379]\n",
      "[Epoch 73/100] [Batch 60/347] [D loss: 0.307482] [G loss: 0.383509]\n",
      "[Epoch 73/100] [Batch 61/347] [D loss: 0.325277] [G loss: 0.364525]\n",
      "[Epoch 73/100] [Batch 62/347] [D loss: 0.327230] [G loss: 0.359626]\n",
      "[Epoch 73/100] [Batch 63/347] [D loss: 0.323603] [G loss: 0.356053]\n",
      "[Epoch 73/100] [Batch 64/347] [D loss: 0.305038] [G loss: 0.352592]\n",
      "[Epoch 73/100] [Batch 65/347] [D loss: 0.259427] [G loss: 0.358625]\n",
      "[Epoch 73/100] [Batch 66/347] [D loss: 0.260369] [G loss: 0.362142]\n",
      "[Epoch 73/100] [Batch 67/347] [D loss: 0.257416] [G loss: 0.357760]\n",
      "[Epoch 73/100] [Batch 68/347] [D loss: 0.256989] [G loss: 0.359851]\n",
      "[Epoch 73/100] [Batch 69/347] [D loss: 0.274601] [G loss: 0.364175]\n",
      "[Epoch 73/100] [Batch 70/347] [D loss: 0.273402] [G loss: 0.366143]\n",
      "[Epoch 73/100] [Batch 71/347] [D loss: 0.273119] [G loss: 0.382404]\n",
      "[Epoch 73/100] [Batch 72/347] [D loss: 0.284999] [G loss: 0.397081]\n",
      "[Epoch 73/100] [Batch 73/347] [D loss: 0.412894] [G loss: 0.394644]\n",
      "[Epoch 73/100] [Batch 74/347] [D loss: 0.416502] [G loss: 0.394954]\n",
      "[Epoch 73/100] [Batch 75/347] [D loss: 0.415204] [G loss: 0.394071]\n",
      "[Epoch 73/100] [Batch 76/347] [D loss: 0.414868] [G loss: 0.389579]\n",
      "[Epoch 73/100] [Batch 77/347] [D loss: 0.453842] [G loss: 0.402280]\n",
      "[Epoch 73/100] [Batch 78/347] [D loss: 0.511504] [G loss: 0.410484]\n",
      "[Epoch 73/100] [Batch 79/347] [D loss: 0.509616] [G loss: 0.408460]\n",
      "[Epoch 73/100] [Batch 80/347] [D loss: 0.400744] [G loss: 0.392649]\n",
      "[Epoch 73/100] [Batch 81/347] [D loss: 0.378592] [G loss: 0.385457]\n",
      "[Epoch 73/100] [Batch 82/347] [D loss: 0.377988] [G loss: 0.380446]\n",
      "[Epoch 73/100] [Batch 83/347] [D loss: 0.383255] [G loss: 0.373643]\n",
      "[Epoch 73/100] [Batch 84/347] [D loss: 0.517494] [G loss: 0.374765]\n",
      "[Epoch 73/100] [Batch 85/347] [D loss: 0.596412] [G loss: 0.374550]\n",
      "[Epoch 73/100] [Batch 86/347] [D loss: 0.598397] [G loss: 0.375661]\n",
      "[Epoch 73/100] [Batch 87/347] [D loss: 0.598306] [G loss: 0.381488]\n",
      "[Epoch 73/100] [Batch 88/347] [D loss: 0.610588] [G loss: 0.388511]\n",
      "[Epoch 73/100] [Batch 89/347] [D loss: 0.613321] [G loss: 0.400544]\n",
      "[Epoch 73/100] [Batch 90/347] [D loss: 0.607037] [G loss: 0.412385]\n",
      "[Epoch 73/100] [Batch 91/347] [D loss: 0.600123] [G loss: 0.426006]\n",
      "[Epoch 73/100] [Batch 92/347] [D loss: 0.591795] [G loss: 0.440465]\n",
      "[Epoch 73/100] [Batch 93/347] [D loss: 0.583689] [G loss: 0.455505]\n",
      "[Epoch 73/100] [Batch 94/347] [D loss: 0.570694] [G loss: 0.465561]\n",
      "[Epoch 73/100] [Batch 95/347] [D loss: 0.561516] [G loss: 0.476962]\n",
      "[Epoch 73/100] [Batch 96/347] [D loss: 0.555831] [G loss: 0.489227]\n",
      "[Epoch 73/100] [Batch 97/347] [D loss: 0.549908] [G loss: 0.498019]\n",
      "[Epoch 73/100] [Batch 98/347] [D loss: 0.544051] [G loss: 0.507447]\n",
      "[Epoch 73/100] [Batch 99/347] [D loss: 0.542628] [G loss: 0.514426]\n",
      "[Epoch 73/100] [Batch 100/347] [D loss: 0.540914] [G loss: 0.519219]\n",
      "[Epoch 73/100] [Batch 101/347] [D loss: 0.540809] [G loss: 0.521202]\n",
      "[Epoch 73/100] [Batch 102/347] [D loss: 0.545644] [G loss: 0.521750]\n",
      "[Epoch 73/100] [Batch 103/347] [D loss: 0.545759] [G loss: 0.525280]\n",
      "[Epoch 73/100] [Batch 104/347] [D loss: 0.542359] [G loss: 0.522054]\n",
      "[Epoch 73/100] [Batch 105/347] [D loss: 0.486160] [G loss: 0.516813]\n",
      "[Epoch 73/100] [Batch 106/347] [D loss: 0.299414] [G loss: 0.507913]\n",
      "[Epoch 73/100] [Batch 107/347] [D loss: 0.300063] [G loss: 0.506057]\n",
      "[Epoch 73/100] [Batch 108/347] [D loss: 0.295002] [G loss: 0.504138]\n",
      "[Epoch 73/100] [Batch 109/347] [D loss: 0.270979] [G loss: 0.493812]\n",
      "[Epoch 73/100] [Batch 110/347] [D loss: 0.345951] [G loss: 0.501389]\n",
      "[Epoch 73/100] [Batch 111/347] [D loss: 0.322142] [G loss: 0.500143]\n",
      "[Epoch 73/100] [Batch 112/347] [D loss: 0.298240] [G loss: 0.495031]\n",
      "[Epoch 73/100] [Batch 113/347] [D loss: 0.446839] [G loss: 0.501668]\n",
      "[Epoch 73/100] [Batch 114/347] [D loss: 0.514747] [G loss: 0.495413]\n",
      "[Epoch 73/100] [Batch 115/347] [D loss: 0.510416] [G loss: 0.464166]\n",
      "[Epoch 73/100] [Batch 116/347] [D loss: 0.446075] [G loss: 0.429458]\n",
      "[Epoch 73/100] [Batch 117/347] [D loss: 0.429212] [G loss: 0.397948]\n",
      "[Epoch 73/100] [Batch 118/347] [D loss: 0.364049] [G loss: 0.364080]\n",
      "[Epoch 73/100] [Batch 119/347] [D loss: 0.363413] [G loss: 0.343944]\n",
      "[Epoch 73/100] [Batch 120/347] [D loss: 0.365734] [G loss: 0.335769]\n",
      "[Epoch 73/100] [Batch 121/347] [D loss: 0.371556] [G loss: 0.326246]\n",
      "[Epoch 73/100] [Batch 122/347] [D loss: 0.492910] [G loss: 0.324513]\n",
      "[Epoch 73/100] [Batch 123/347] [D loss: 0.545106] [G loss: 0.327404]\n",
      "[Epoch 73/100] [Batch 124/347] [D loss: 0.475667] [G loss: 0.329817]\n",
      "[Epoch 73/100] [Batch 125/347] [D loss: 0.443975] [G loss: 0.338855]\n",
      "[Epoch 73/100] [Batch 126/347] [D loss: 0.405273] [G loss: 0.350240]\n",
      "[Epoch 73/100] [Batch 127/347] [D loss: 0.402287] [G loss: 0.359681]\n",
      "[Epoch 73/100] [Batch 128/347] [D loss: 0.382658] [G loss: 0.364879]\n",
      "[Epoch 73/100] [Batch 129/347] [D loss: 0.323246] [G loss: 0.370917]\n",
      "[Epoch 73/100] [Batch 130/347] [D loss: 0.266185] [G loss: 0.393826]\n",
      "[Epoch 73/100] [Batch 131/347] [D loss: 0.238836] [G loss: 0.417116]\n",
      "[Epoch 73/100] [Batch 132/347] [D loss: 0.212763] [G loss: 0.442566]\n",
      "[Epoch 73/100] [Batch 133/347] [D loss: 0.196636] [G loss: 0.465198]\n",
      "[Epoch 73/100] [Batch 134/347] [D loss: 0.176911] [G loss: 0.484039]\n",
      "[Epoch 73/100] [Batch 135/347] [D loss: 0.166403] [G loss: 0.496516]\n",
      "[Epoch 73/100] [Batch 136/347] [D loss: 0.163560] [G loss: 0.499453]\n",
      "[Epoch 73/100] [Batch 137/347] [D loss: 0.430599] [G loss: 0.498465]\n",
      "[Epoch 73/100] [Batch 138/347] [D loss: 0.464167] [G loss: 0.494154]\n",
      "[Epoch 73/100] [Batch 139/347] [D loss: 0.472177] [G loss: 0.485889]\n",
      "[Epoch 73/100] [Batch 140/347] [D loss: 0.480037] [G loss: 0.485518]\n",
      "[Epoch 73/100] [Batch 141/347] [D loss: 0.455556] [G loss: 0.479578]\n",
      "[Epoch 73/100] [Batch 142/347] [D loss: 0.462864] [G loss: 0.472857]\n",
      "[Epoch 73/100] [Batch 143/347] [D loss: 0.462082] [G loss: 0.463355]\n",
      "[Epoch 73/100] [Batch 144/347] [D loss: 0.455067] [G loss: 0.454035]\n",
      "[Epoch 73/100] [Batch 145/347] [D loss: 0.475024] [G loss: 0.453256]\n",
      "[Epoch 73/100] [Batch 146/347] [D loss: 0.489082] [G loss: 0.449608]\n",
      "[Epoch 73/100] [Batch 147/347] [D loss: 0.504628] [G loss: 0.453533]\n",
      "[Epoch 73/100] [Batch 148/347] [D loss: 0.511237] [G loss: 0.454504]\n",
      "[Epoch 73/100] [Batch 149/347] [D loss: 0.482202] [G loss: 0.444008]\n",
      "[Epoch 73/100] [Batch 150/347] [D loss: 0.461627] [G loss: 0.438098]\n",
      "[Epoch 73/100] [Batch 151/347] [D loss: 0.431881] [G loss: 0.426457]\n",
      "[Epoch 73/100] [Batch 152/347] [D loss: 0.394826] [G loss: 0.406261]\n",
      "[Epoch 73/100] [Batch 153/347] [D loss: 0.379446] [G loss: 0.379147]\n",
      "[Epoch 73/100] [Batch 154/347] [D loss: 0.351749] [G loss: 0.354991]\n",
      "[Epoch 73/100] [Batch 155/347] [D loss: 0.334192] [G loss: 0.334463]\n",
      "[Epoch 73/100] [Batch 156/347] [D loss: 0.325164] [G loss: 0.310821]\n",
      "[Epoch 73/100] [Batch 157/347] [D loss: 0.321038] [G loss: 0.296683]\n",
      "[Epoch 73/100] [Batch 158/347] [D loss: 0.309578] [G loss: 0.293284]\n",
      "[Epoch 73/100] [Batch 159/347] [D loss: 0.333137] [G loss: 0.295155]\n",
      "[Epoch 73/100] [Batch 160/347] [D loss: 0.328746] [G loss: 0.309689]\n",
      "[Epoch 73/100] [Batch 161/347] [D loss: 0.317199] [G loss: 0.326185]\n",
      "[Epoch 73/100] [Batch 162/347] [D loss: 0.299653] [G loss: 0.337882]\n",
      "[Epoch 73/100] [Batch 163/347] [D loss: 0.290877] [G loss: 0.345248]\n",
      "[Epoch 73/100] [Batch 164/347] [D loss: 0.281664] [G loss: 0.364530]\n",
      "[Epoch 73/100] [Batch 165/347] [D loss: 0.276475] [G loss: 0.385693]\n",
      "[Epoch 73/100] [Batch 166/347] [D loss: 0.280582] [G loss: 0.408916]\n",
      "[Epoch 73/100] [Batch 167/347] [D loss: 0.308383] [G loss: 0.440714]\n",
      "[Epoch 73/100] [Batch 168/347] [D loss: 0.310889] [G loss: 0.455415]\n",
      "[Epoch 73/100] [Batch 169/347] [D loss: 0.455252] [G loss: 0.468290]\n",
      "[Epoch 73/100] [Batch 170/347] [D loss: 0.528534] [G loss: 0.478194]\n",
      "[Epoch 73/100] [Batch 171/347] [D loss: 0.531579] [G loss: 0.481193]\n",
      "[Epoch 73/100] [Batch 172/347] [D loss: 0.532702] [G loss: 0.485056]\n",
      "[Epoch 73/100] [Batch 173/347] [D loss: 0.534144] [G loss: 0.486632]\n",
      "[Epoch 73/100] [Batch 174/347] [D loss: 0.532053] [G loss: 0.493211]\n",
      "[Epoch 73/100] [Batch 175/347] [D loss: 0.544736] [G loss: 0.500800]\n",
      "[Epoch 73/100] [Batch 176/347] [D loss: 0.552634] [G loss: 0.506796]\n",
      "[Epoch 73/100] [Batch 177/347] [D loss: 0.551619] [G loss: 0.507195]\n",
      "[Epoch 73/100] [Batch 178/347] [D loss: 0.548925] [G loss: 0.504502]\n",
      "[Epoch 73/100] [Batch 179/347] [D loss: 0.547102] [G loss: 0.503999]\n",
      "[Epoch 73/100] [Batch 180/347] [D loss: 0.545151] [G loss: 0.502873]\n",
      "[Epoch 73/100] [Batch 181/347] [D loss: 0.543846] [G loss: 0.508447]\n",
      "[Epoch 73/100] [Batch 182/347] [D loss: 0.543656] [G loss: 0.511832]\n",
      "[Epoch 73/100] [Batch 183/347] [D loss: 0.543015] [G loss: 0.515462]\n",
      "[Epoch 73/100] [Batch 184/347] [D loss: 0.546029] [G loss: 0.519985]\n",
      "[Epoch 73/100] [Batch 185/347] [D loss: 0.545632] [G loss: 0.518658]\n",
      "[Epoch 73/100] [Batch 186/347] [D loss: 0.542826] [G loss: 0.518834]\n",
      "[Epoch 73/100] [Batch 187/347] [D loss: 0.540647] [G loss: 0.517128]\n",
      "[Epoch 73/100] [Batch 188/347] [D loss: 0.534634] [G loss: 0.509904]\n",
      "[Epoch 73/100] [Batch 189/347] [D loss: 0.525961] [G loss: 0.504367]\n",
      "[Epoch 73/100] [Batch 190/347] [D loss: 0.524489] [G loss: 0.502018]\n",
      "[Epoch 73/100] [Batch 191/347] [D loss: 0.524378] [G loss: 0.499168]\n",
      "[Epoch 73/100] [Batch 192/347] [D loss: 0.525234] [G loss: 0.499028]\n",
      "[Epoch 73/100] [Batch 193/347] [D loss: 0.534280] [G loss: 0.498998]\n",
      "[Epoch 73/100] [Batch 194/347] [D loss: 0.533137] [G loss: 0.494752]\n",
      "[Epoch 73/100] [Batch 195/347] [D loss: 0.529348] [G loss: 0.490905]\n",
      "[Epoch 73/100] [Batch 196/347] [D loss: 0.521456] [G loss: 0.486840]\n",
      "[Epoch 73/100] [Batch 197/347] [D loss: 0.520354] [G loss: 0.484203]\n",
      "[Epoch 73/100] [Batch 198/347] [D loss: 0.519386] [G loss: 0.484802]\n",
      "[Epoch 73/100] [Batch 199/347] [D loss: 0.517707] [G loss: 0.482857]\n",
      "[Epoch 73/100] [Batch 200/347] [D loss: 0.526105] [G loss: 0.480668]\n",
      "[Epoch 73/100] [Batch 201/347] [D loss: 0.530001] [G loss: 0.477822]\n",
      "[Epoch 73/100] [Batch 202/347] [D loss: 0.530494] [G loss: 0.474160]\n",
      "[Epoch 73/100] [Batch 203/347] [D loss: 0.534900] [G loss: 0.470712]\n",
      "[Epoch 73/100] [Batch 204/347] [D loss: 0.532927] [G loss: 0.471527]\n",
      "[Epoch 73/100] [Batch 205/347] [D loss: 0.531848] [G loss: 0.474011]\n",
      "[Epoch 73/100] [Batch 206/347] [D loss: 0.530814] [G loss: 0.474771]\n",
      "[Epoch 73/100] [Batch 207/347] [D loss: 0.520023] [G loss: 0.474417]\n",
      "[Epoch 73/100] [Batch 208/347] [D loss: 0.516770] [G loss: 0.475223]\n",
      "[Epoch 73/100] [Batch 209/347] [D loss: 0.513137] [G loss: 0.467898]\n",
      "[Epoch 73/100] [Batch 210/347] [D loss: 0.485946] [G loss: 0.464366]\n",
      "[Epoch 73/100] [Batch 211/347] [D loss: 0.420506] [G loss: 0.454566]\n",
      "[Epoch 73/100] [Batch 212/347] [D loss: 0.235896] [G loss: 0.434818]\n",
      "[Epoch 73/100] [Batch 213/347] [D loss: 0.229416] [G loss: 0.430299]\n",
      "[Epoch 73/100] [Batch 214/347] [D loss: 0.219110] [G loss: 0.425153]\n",
      "[Epoch 73/100] [Batch 215/347] [D loss: 0.214147] [G loss: 0.420840]\n",
      "[Epoch 73/100] [Batch 216/347] [D loss: 0.411284] [G loss: 0.429500]\n",
      "[Epoch 73/100] [Batch 217/347] [D loss: 0.444822] [G loss: 0.434622]\n",
      "[Epoch 73/100] [Batch 218/347] [D loss: 0.479526] [G loss: 0.438109]\n",
      "[Epoch 73/100] [Batch 219/347] [D loss: 0.457247] [G loss: 0.431963]\n",
      "[Epoch 73/100] [Batch 220/347] [D loss: 0.440047] [G loss: 0.420654]\n",
      "[Epoch 73/100] [Batch 221/347] [D loss: 0.454761] [G loss: 0.403906]\n",
      "[Epoch 73/100] [Batch 222/347] [D loss: 0.451892] [G loss: 0.378068]\n",
      "[Epoch 73/100] [Batch 223/347] [D loss: 0.425239] [G loss: 0.341610]\n",
      "[Epoch 73/100] [Batch 224/347] [D loss: 0.431872] [G loss: 0.303465]\n",
      "[Epoch 73/100] [Batch 225/347] [D loss: 0.443724] [G loss: 0.271840]\n",
      "[Epoch 73/100] [Batch 226/347] [D loss: 0.453179] [G loss: 0.250513]\n",
      "[Epoch 73/100] [Batch 227/347] [D loss: 0.495584] [G loss: 0.243390]\n",
      "[Epoch 73/100] [Batch 228/347] [D loss: 0.514840] [G loss: 0.241641]\n",
      "[Epoch 73/100] [Batch 229/347] [D loss: 0.520084] [G loss: 0.243600]\n",
      "[Epoch 73/100] [Batch 230/347] [D loss: 0.532984] [G loss: 0.247611]\n",
      "[Epoch 73/100] [Batch 231/347] [D loss: 0.507370] [G loss: 0.247235]\n",
      "[Epoch 73/100] [Batch 232/347] [D loss: 0.487469] [G loss: 0.253755]\n",
      "[Epoch 73/100] [Batch 233/347] [D loss: 0.423434] [G loss: 0.269782]\n",
      "[Epoch 73/100] [Batch 234/347] [D loss: 0.386420] [G loss: 0.288567]\n",
      "[Epoch 73/100] [Batch 235/347] [D loss: 0.375820] [G loss: 0.317816]\n",
      "[Epoch 73/100] [Batch 236/347] [D loss: 0.361353] [G loss: 0.345179]\n",
      "[Epoch 73/100] [Batch 237/347] [D loss: 0.423585] [G loss: 0.368584]\n",
      "[Epoch 73/100] [Batch 238/347] [D loss: 0.504791] [G loss: 0.382610]\n",
      "[Epoch 73/100] [Batch 239/347] [D loss: 0.506512] [G loss: 0.389646]\n",
      "[Epoch 73/100] [Batch 240/347] [D loss: 0.509532] [G loss: 0.397752]\n",
      "[Epoch 73/100] [Batch 241/347] [D loss: 0.512935] [G loss: 0.406470]\n",
      "[Epoch 73/100] [Batch 242/347] [D loss: 0.522852] [G loss: 0.416033]\n",
      "[Epoch 73/100] [Batch 243/347] [D loss: 0.481710] [G loss: 0.423655]\n",
      "[Epoch 73/100] [Batch 244/347] [D loss: 0.457339] [G loss: 0.419040]\n",
      "[Epoch 73/100] [Batch 245/347] [D loss: 0.464114] [G loss: 0.409743]\n",
      "[Epoch 73/100] [Batch 246/347] [D loss: 0.463112] [G loss: 0.397079]\n",
      "[Epoch 73/100] [Batch 247/347] [D loss: 0.487801] [G loss: 0.386977]\n",
      "[Epoch 73/100] [Batch 248/347] [D loss: 0.505548] [G loss: 0.387758]\n",
      "[Epoch 73/100] [Batch 249/347] [D loss: 0.490193] [G loss: 0.390935]\n",
      "[Epoch 73/100] [Batch 250/347] [D loss: 0.483974] [G loss: 0.397697]\n",
      "[Epoch 73/100] [Batch 251/347] [D loss: 0.472293] [G loss: 0.402786]\n",
      "[Epoch 73/100] [Batch 252/347] [D loss: 0.462378] [G loss: 0.402850]\n",
      "[Epoch 73/100] [Batch 253/347] [D loss: 0.399625] [G loss: 0.388464]\n",
      "[Epoch 73/100] [Batch 254/347] [D loss: 0.392018] [G loss: 0.383488]\n",
      "[Epoch 73/100] [Batch 255/347] [D loss: 0.386913] [G loss: 0.373378]\n",
      "[Epoch 73/100] [Batch 256/347] [D loss: 0.386182] [G loss: 0.356147]\n",
      "[Epoch 73/100] [Batch 257/347] [D loss: 0.371813] [G loss: 0.344769]\n",
      "[Epoch 73/100] [Batch 258/347] [D loss: 0.335635] [G loss: 0.335114]\n",
      "[Epoch 73/100] [Batch 259/347] [D loss: 0.339796] [G loss: 0.326882]\n",
      "[Epoch 73/100] [Batch 260/347] [D loss: 0.341751] [G loss: 0.323459]\n",
      "[Epoch 73/100] [Batch 261/347] [D loss: 0.334061] [G loss: 0.329153]\n",
      "[Epoch 73/100] [Batch 262/347] [D loss: 0.303750] [G loss: 0.335503]\n",
      "[Epoch 73/100] [Batch 263/347] [D loss: 0.298509] [G loss: 0.344421]\n",
      "[Epoch 73/100] [Batch 264/347] [D loss: 0.292554] [G loss: 0.356776]\n",
      "[Epoch 73/100] [Batch 265/347] [D loss: 0.298349] [G loss: 0.368501]\n",
      "[Epoch 73/100] [Batch 266/347] [D loss: 0.353467] [G loss: 0.379580]\n",
      "[Epoch 73/100] [Batch 267/347] [D loss: 0.375302] [G loss: 0.386888]\n",
      "[Epoch 73/100] [Batch 268/347] [D loss: 0.384678] [G loss: 0.390538]\n",
      "[Epoch 73/100] [Batch 269/347] [D loss: 0.389592] [G loss: 0.391520]\n",
      "[Epoch 73/100] [Batch 270/347] [D loss: 0.421920] [G loss: 0.390282]\n",
      "[Epoch 73/100] [Batch 271/347] [D loss: 0.394370] [G loss: 0.392497]\n",
      "[Epoch 73/100] [Batch 272/347] [D loss: 0.469172] [G loss: 0.410262]\n",
      "[Epoch 73/100] [Batch 273/347] [D loss: 0.429744] [G loss: 0.428172]\n",
      "[Epoch 73/100] [Batch 274/347] [D loss: 0.383544] [G loss: 0.444096]\n",
      "[Epoch 73/100] [Batch 275/347] [D loss: 0.317415] [G loss: 0.457459]\n",
      "[Epoch 73/100] [Batch 276/347] [D loss: 0.469924] [G loss: 0.460905]\n",
      "[Epoch 73/100] [Batch 277/347] [D loss: 0.497632] [G loss: 0.471616]\n",
      "[Epoch 73/100] [Batch 278/347] [D loss: 0.504048] [G loss: 0.481227]\n",
      "[Epoch 73/100] [Batch 279/347] [D loss: 0.509554] [G loss: 0.482773]\n",
      "[Epoch 73/100] [Batch 280/347] [D loss: 0.513420] [G loss: 0.482779]\n",
      "[Epoch 73/100] [Batch 281/347] [D loss: 0.519469] [G loss: 0.483018]\n",
      "[Epoch 73/100] [Batch 282/347] [D loss: 0.520945] [G loss: 0.486180]\n",
      "[Epoch 73/100] [Batch 283/347] [D loss: 0.522029] [G loss: 0.487701]\n",
      "[Epoch 73/100] [Batch 284/347] [D loss: 0.523086] [G loss: 0.489928]\n",
      "[Epoch 73/100] [Batch 285/347] [D loss: 0.528248] [G loss: 0.490941]\n",
      "[Epoch 73/100] [Batch 286/347] [D loss: 0.525571] [G loss: 0.477055]\n",
      "[Epoch 73/100] [Batch 287/347] [D loss: 0.526457] [G loss: 0.474506]\n",
      "[Epoch 73/100] [Batch 288/347] [D loss: 0.526650] [G loss: 0.471783]\n",
      "[Epoch 73/100] [Batch 289/347] [D loss: 0.524367] [G loss: 0.466776]\n",
      "[Epoch 73/100] [Batch 290/347] [D loss: 0.524450] [G loss: 0.482638]\n",
      "[Epoch 73/100] [Batch 291/347] [D loss: 0.522561] [G loss: 0.489468]\n",
      "[Epoch 73/100] [Batch 292/347] [D loss: 0.519122] [G loss: 0.493280]\n",
      "[Epoch 73/100] [Batch 293/347] [D loss: 0.480911] [G loss: 0.498620]\n",
      "[Epoch 73/100] [Batch 294/347] [D loss: 0.479521] [G loss: 0.502612]\n",
      "[Epoch 73/100] [Batch 295/347] [D loss: 0.478113] [G loss: 0.500833]\n",
      "[Epoch 73/100] [Batch 296/347] [D loss: 0.475578] [G loss: 0.498625]\n",
      "[Epoch 73/100] [Batch 297/347] [D loss: 0.516561] [G loss: 0.502410]\n",
      "[Epoch 73/100] [Batch 298/347] [D loss: 0.521485] [G loss: 0.495147]\n",
      "[Epoch 73/100] [Batch 299/347] [D loss: 0.520208] [G loss: 0.489702]\n",
      "[Epoch 73/100] [Batch 300/347] [D loss: 0.518171] [G loss: 0.486893]\n",
      "[Epoch 73/100] [Batch 301/347] [D loss: 0.518405] [G loss: 0.471493]\n",
      "[Epoch 73/100] [Batch 302/347] [D loss: 0.518950] [G loss: 0.461916]\n",
      "[Epoch 73/100] [Batch 303/347] [D loss: 0.517459] [G loss: 0.449791]\n",
      "[Epoch 73/100] [Batch 304/347] [D loss: 0.474794] [G loss: 0.436867]\n",
      "[Epoch 73/100] [Batch 305/347] [D loss: 0.427691] [G loss: 0.428584]\n",
      "[Epoch 73/100] [Batch 306/347] [D loss: 0.416416] [G loss: 0.427608]\n",
      "[Epoch 73/100] [Batch 307/347] [D loss: 0.397927] [G loss: 0.430348]\n",
      "[Epoch 73/100] [Batch 308/347] [D loss: 0.409626] [G loss: 0.432144]\n",
      "[Epoch 73/100] [Batch 309/347] [D loss: 0.504678] [G loss: 0.443321]\n",
      "[Epoch 73/100] [Batch 310/347] [D loss: 0.526148] [G loss: 0.452323]\n",
      "[Epoch 73/100] [Batch 311/347] [D loss: 0.517669] [G loss: 0.446561]\n",
      "[Epoch 73/100] [Batch 312/347] [D loss: 0.496069] [G loss: 0.437927]\n",
      "[Epoch 73/100] [Batch 313/347] [D loss: 0.475195] [G loss: 0.424713]\n",
      "[Epoch 73/100] [Batch 314/347] [D loss: 0.462744] [G loss: 0.405056]\n",
      "[Epoch 73/100] [Batch 315/347] [D loss: 0.451926] [G loss: 0.387034]\n",
      "[Epoch 73/100] [Batch 316/347] [D loss: 0.452604] [G loss: 0.379067]\n",
      "[Epoch 73/100] [Batch 317/347] [D loss: 0.455909] [G loss: 0.371229]\n",
      "[Epoch 73/100] [Batch 318/347] [D loss: 0.460570] [G loss: 0.370341]\n",
      "[Epoch 73/100] [Batch 319/347] [D loss: 0.437389] [G loss: 0.365034]\n",
      "[Epoch 73/100] [Batch 320/347] [D loss: 0.424842] [G loss: 0.344831]\n",
      "[Epoch 73/100] [Batch 321/347] [D loss: 0.406086] [G loss: 0.320534]\n",
      "[Epoch 73/100] [Batch 322/347] [D loss: 0.414511] [G loss: 0.297778]\n",
      "[Epoch 73/100] [Batch 323/347] [D loss: 0.368641] [G loss: 0.278361]\n",
      "[Epoch 73/100] [Batch 324/347] [D loss: 0.369584] [G loss: 0.267765]\n",
      "[Epoch 73/100] [Batch 325/347] [D loss: 0.375710] [G loss: 0.260427]\n",
      "[Epoch 73/100] [Batch 326/347] [D loss: 0.378705] [G loss: 0.258033]\n",
      "[Epoch 73/100] [Batch 327/347] [D loss: 0.364475] [G loss: 0.264016]\n",
      "[Epoch 73/100] [Batch 328/347] [D loss: 0.361389] [G loss: 0.271918]\n",
      "[Epoch 73/100] [Batch 329/347] [D loss: 0.353623] [G loss: 0.285730]\n",
      "[Epoch 73/100] [Batch 330/347] [D loss: 0.345484] [G loss: 0.301616]\n",
      "[Epoch 73/100] [Batch 331/347] [D loss: 0.365588] [G loss: 0.322104]\n",
      "[Epoch 73/100] [Batch 332/347] [D loss: 0.444333] [G loss: 0.354588]\n",
      "[Epoch 73/100] [Batch 333/347] [D loss: 0.414608] [G loss: 0.363285]\n",
      "[Epoch 73/100] [Batch 334/347] [D loss: 0.409759] [G loss: 0.364417]\n",
      "[Epoch 73/100] [Batch 335/347] [D loss: 0.412269] [G loss: 0.367577]\n",
      "[Epoch 73/100] [Batch 336/347] [D loss: 0.413994] [G loss: 0.369456]\n",
      "[Epoch 73/100] [Batch 337/347] [D loss: 0.457432] [G loss: 0.374801]\n",
      "[Epoch 73/100] [Batch 338/347] [D loss: 0.490333] [G loss: 0.383518]\n",
      "[Epoch 73/100] [Batch 339/347] [D loss: 0.469082] [G loss: 0.384172]\n",
      "[Epoch 73/100] [Batch 340/347] [D loss: 0.442814] [G loss: 0.380295]\n",
      "[Epoch 73/100] [Batch 341/347] [D loss: 0.448922] [G loss: 0.379011]\n",
      "[Epoch 73/100] [Batch 342/347] [D loss: 0.323652] [G loss: 0.366096]\n",
      "[Epoch 73/100] [Batch 343/347] [D loss: 0.288953] [G loss: 0.350712]\n",
      "[Epoch 73/100] [Batch 344/347] [D loss: 0.264309] [G loss: 0.347523]\n",
      "[Epoch 73/100] [Batch 345/347] [D loss: 0.224927] [G loss: 0.353071]\n",
      "[Epoch 73/100] [Batch 346/347] [D loss: 0.219830] [G loss: 0.362954]\n",
      "[Epoch 73/100] [Batch 347/347] [D loss: 0.211613] [G loss: 0.374966]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 74/100] [Batch 1/347] [D loss: 0.446175] [G loss: 0.399349]\n",
      "[Epoch 74/100] [Batch 2/347] [D loss: 0.472968] [G loss: 0.405344]\n",
      "[Epoch 74/100] [Batch 3/347] [D loss: 0.512128] [G loss: 0.413869]\n",
      "[Epoch 74/100] [Batch 4/347] [D loss: 0.517585] [G loss: 0.417936]\n",
      "[Epoch 74/100] [Batch 5/347] [D loss: 0.518417] [G loss: 0.417705]\n",
      "[Epoch 74/100] [Batch 6/347] [D loss: 0.499169] [G loss: 0.416999]\n",
      "[Epoch 74/100] [Batch 7/347] [D loss: 0.474296] [G loss: 0.408952]\n",
      "[Epoch 74/100] [Batch 8/347] [D loss: 0.476178] [G loss: 0.406579]\n",
      "[Epoch 74/100] [Batch 9/347] [D loss: 0.472158] [G loss: 0.405116]\n",
      "[Epoch 74/100] [Batch 10/347] [D loss: 0.475328] [G loss: 0.402203]\n",
      "[Epoch 74/100] [Batch 11/347] [D loss: 0.504555] [G loss: 0.407283]\n",
      "[Epoch 74/100] [Batch 12/347] [D loss: 0.517480] [G loss: 0.404926]\n",
      "[Epoch 74/100] [Batch 13/347] [D loss: 0.494425] [G loss: 0.398872]\n",
      "[Epoch 74/100] [Batch 14/347] [D loss: 0.473196] [G loss: 0.391920]\n",
      "[Epoch 74/100] [Batch 15/347] [D loss: 0.470022] [G loss: 0.374847]\n",
      "[Epoch 74/100] [Batch 16/347] [D loss: 0.459172] [G loss: 0.359734]\n",
      "[Epoch 74/100] [Batch 17/347] [D loss: 0.462073] [G loss: 0.351563]\n",
      "[Epoch 74/100] [Batch 18/347] [D loss: 0.470922] [G loss: 0.341383]\n",
      "[Epoch 74/100] [Batch 19/347] [D loss: 0.471747] [G loss: 0.334678]\n",
      "[Epoch 74/100] [Batch 20/347] [D loss: 0.497390] [G loss: 0.329269]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 74/100] [Batch 21/347] [D loss: 0.428773] [G loss: 0.315661]\n",
      "[Epoch 74/100] [Batch 22/347] [D loss: 0.431113] [G loss: 0.306536]\n",
      "[Epoch 74/100] [Batch 23/347] [D loss: 0.435995] [G loss: 0.297997]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 74/100] [Batch 24/347] [D loss: 0.395222] [G loss: 0.288037]\n",
      "[Epoch 74/100] [Batch 25/347] [D loss: 0.315443] [G loss: 0.297154]\n",
      "[Epoch 74/100] [Batch 26/347] [D loss: 0.312220] [G loss: 0.307915]\n",
      "[Epoch 74/100] [Batch 27/347] [D loss: 0.306290] [G loss: 0.326622]\n",
      "[Epoch 74/100] [Batch 28/347] [D loss: 0.300994] [G loss: 0.349340]\n",
      "[Epoch 74/100] [Batch 29/347] [D loss: 0.316593] [G loss: 0.371389]\n",
      "[Epoch 74/100] [Batch 30/347] [D loss: 0.306373] [G loss: 0.387531]\n",
      "[Epoch 74/100] [Batch 31/347] [D loss: 0.305855] [G loss: 0.398829]\n",
      "[Epoch 74/100] [Batch 32/347] [D loss: 0.319206] [G loss: 0.403900]\n",
      "[Epoch 74/100] [Batch 33/347] [D loss: 0.340146] [G loss: 0.406740]\n",
      "[Epoch 74/100] [Batch 34/347] [D loss: 0.389499] [G loss: 0.404457]\n",
      "[Epoch 74/100] [Batch 35/347] [D loss: 0.391592] [G loss: 0.394817]\n",
      "[Epoch 74/100] [Batch 36/347] [D loss: 0.419745] [G loss: 0.385669]\n",
      "[Epoch 74/100] [Batch 37/347] [D loss: 0.427795] [G loss: 0.372752]\n",
      "[Epoch 74/100] [Batch 38/347] [D loss: 0.427796] [G loss: 0.355595]\n",
      "[Epoch 74/100] [Batch 39/347] [D loss: 0.437941] [G loss: 0.348548]\n",
      "[Epoch 74/100] [Batch 40/347] [D loss: 0.467599] [G loss: 0.344283]\n",
      "[Epoch 74/100] [Batch 41/347] [D loss: 0.489232] [G loss: 0.337369]\n",
      "[Epoch 74/100] [Batch 42/347] [D loss: 0.486476] [G loss: 0.336428]\n",
      "[Epoch 74/100] [Batch 43/347] [D loss: 0.512111] [G loss: 0.342222]\n",
      "[Epoch 74/100] [Batch 44/347] [D loss: 0.498922] [G loss: 0.340903]\n",
      "[Epoch 74/100] [Batch 45/347] [D loss: 0.470259] [G loss: 0.327366]\n",
      "[Epoch 74/100] [Batch 46/347] [D loss: 0.384425] [G loss: 0.314303]\n",
      "[Epoch 74/100] [Batch 47/347] [D loss: 0.378400] [G loss: 0.308367]\n",
      "[Epoch 74/100] [Batch 48/347] [D loss: 0.294116] [G loss: 0.318004]\n",
      "[Epoch 74/100] [Batch 49/347] [D loss: 0.278632] [G loss: 0.341172]\n",
      "[Epoch 74/100] [Batch 50/347] [D loss: 0.264562] [G loss: 0.369896]\n",
      "[Epoch 74/100] [Batch 51/347] [D loss: 0.244014] [G loss: 0.394057]\n",
      "[Epoch 74/100] [Batch 52/347] [D loss: 0.344851] [G loss: 0.405366]\n",
      "[Epoch 74/100] [Batch 53/347] [D loss: 0.387137] [G loss: 0.404368]\n",
      "[Epoch 74/100] [Batch 54/347] [D loss: 0.370785] [G loss: 0.399898]\n",
      "[Epoch 74/100] [Batch 55/347] [D loss: 0.368001] [G loss: 0.406155]\n",
      "[Epoch 74/100] [Batch 56/347] [D loss: 0.362054] [G loss: 0.414003]\n",
      "[Epoch 74/100] [Batch 57/347] [D loss: 0.313112] [G loss: 0.419766]\n",
      "[Epoch 74/100] [Batch 58/347] [D loss: 0.324907] [G loss: 0.420163]\n",
      "[Epoch 74/100] [Batch 59/347] [D loss: 0.321792] [G loss: 0.411326]\n",
      "[Epoch 74/100] [Batch 60/347] [D loss: 0.304246] [G loss: 0.393419]\n",
      "[Epoch 74/100] [Batch 61/347] [D loss: 0.321724] [G loss: 0.373124]\n",
      "[Epoch 74/100] [Batch 62/347] [D loss: 0.322738] [G loss: 0.366417]\n",
      "[Epoch 74/100] [Batch 63/347] [D loss: 0.317967] [G loss: 0.362373]\n",
      "[Epoch 74/100] [Batch 64/347] [D loss: 0.298685] [G loss: 0.357413]\n",
      "[Epoch 74/100] [Batch 65/347] [D loss: 0.253516] [G loss: 0.361513]\n",
      "[Epoch 74/100] [Batch 66/347] [D loss: 0.255559] [G loss: 0.362922]\n",
      "[Epoch 74/100] [Batch 67/347] [D loss: 0.253969] [G loss: 0.356522]\n",
      "[Epoch 74/100] [Batch 68/347] [D loss: 0.254010] [G loss: 0.359024]\n",
      "[Epoch 74/100] [Batch 69/347] [D loss: 0.270420] [G loss: 0.364124]\n",
      "[Epoch 74/100] [Batch 70/347] [D loss: 0.267383] [G loss: 0.366794]\n",
      "[Epoch 74/100] [Batch 71/347] [D loss: 0.266874] [G loss: 0.383966]\n",
      "[Epoch 74/100] [Batch 72/347] [D loss: 0.277577] [G loss: 0.399235]\n",
      "[Epoch 74/100] [Batch 73/347] [D loss: 0.404317] [G loss: 0.397506]\n",
      "[Epoch 74/100] [Batch 74/347] [D loss: 0.408144] [G loss: 0.398773]\n",
      "[Epoch 74/100] [Batch 75/347] [D loss: 0.407437] [G loss: 0.397880]\n",
      "[Epoch 74/100] [Batch 76/347] [D loss: 0.407012] [G loss: 0.393787]\n",
      "[Epoch 74/100] [Batch 77/347] [D loss: 0.445857] [G loss: 0.403855]\n",
      "[Epoch 74/100] [Batch 78/347] [D loss: 0.504226] [G loss: 0.412222]\n",
      "[Epoch 74/100] [Batch 79/347] [D loss: 0.501615] [G loss: 0.410855]\n",
      "[Epoch 74/100] [Batch 80/347] [D loss: 0.392903] [G loss: 0.394937]\n",
      "[Epoch 74/100] [Batch 81/347] [D loss: 0.370739] [G loss: 0.388234]\n",
      "[Epoch 74/100] [Batch 82/347] [D loss: 0.369611] [G loss: 0.383490]\n",
      "[Epoch 74/100] [Batch 83/347] [D loss: 0.375085] [G loss: 0.376837]\n",
      "[Epoch 74/100] [Batch 84/347] [D loss: 0.508955] [G loss: 0.377262]\n",
      "[Epoch 74/100] [Batch 85/347] [D loss: 0.588800] [G loss: 0.376647]\n",
      "[Epoch 74/100] [Batch 86/347] [D loss: 0.591592] [G loss: 0.378053]\n",
      "[Epoch 74/100] [Batch 87/347] [D loss: 0.590914] [G loss: 0.382728]\n",
      "[Epoch 74/100] [Batch 88/347] [D loss: 0.604295] [G loss: 0.390181]\n",
      "[Epoch 74/100] [Batch 89/347] [D loss: 0.606376] [G loss: 0.402779]\n",
      "[Epoch 74/100] [Batch 90/347] [D loss: 0.600181] [G loss: 0.414232]\n",
      "[Epoch 74/100] [Batch 91/347] [D loss: 0.593906] [G loss: 0.427697]\n",
      "[Epoch 74/100] [Batch 92/347] [D loss: 0.586155] [G loss: 0.442825]\n",
      "[Epoch 74/100] [Batch 93/347] [D loss: 0.578107] [G loss: 0.457755]\n",
      "[Epoch 74/100] [Batch 94/347] [D loss: 0.565384] [G loss: 0.467479]\n",
      "[Epoch 74/100] [Batch 95/347] [D loss: 0.556916] [G loss: 0.478634]\n",
      "[Epoch 74/100] [Batch 96/347] [D loss: 0.551586] [G loss: 0.490389]\n",
      "[Epoch 74/100] [Batch 97/347] [D loss: 0.546602] [G loss: 0.498740]\n",
      "[Epoch 74/100] [Batch 98/347] [D loss: 0.540841] [G loss: 0.507134]\n",
      "[Epoch 74/100] [Batch 99/347] [D loss: 0.540181] [G loss: 0.513632]\n",
      "[Epoch 74/100] [Batch 100/347] [D loss: 0.538767] [G loss: 0.518246]\n",
      "[Epoch 74/100] [Batch 101/347] [D loss: 0.538991] [G loss: 0.519887]\n",
      "[Epoch 74/100] [Batch 102/347] [D loss: 0.544472] [G loss: 0.520212]\n",
      "[Epoch 74/100] [Batch 103/347] [D loss: 0.544889] [G loss: 0.523388]\n",
      "[Epoch 74/100] [Batch 104/347] [D loss: 0.541201] [G loss: 0.519989]\n",
      "[Epoch 74/100] [Batch 105/347] [D loss: 0.482857] [G loss: 0.514578]\n",
      "[Epoch 74/100] [Batch 106/347] [D loss: 0.286295] [G loss: 0.505658]\n",
      "[Epoch 74/100] [Batch 107/347] [D loss: 0.285786] [G loss: 0.503866]\n",
      "[Epoch 74/100] [Batch 108/347] [D loss: 0.281792] [G loss: 0.502252]\n",
      "[Epoch 74/100] [Batch 109/347] [D loss: 0.258333] [G loss: 0.492132]\n",
      "[Epoch 74/100] [Batch 110/347] [D loss: 0.333297] [G loss: 0.500100]\n",
      "[Epoch 74/100] [Batch 111/347] [D loss: 0.311670] [G loss: 0.499291]\n",
      "[Epoch 74/100] [Batch 112/347] [D loss: 0.289500] [G loss: 0.494275]\n",
      "[Epoch 74/100] [Batch 113/347] [D loss: 0.441951] [G loss: 0.501909]\n",
      "[Epoch 74/100] [Batch 114/347] [D loss: 0.509683] [G loss: 0.496349]\n",
      "[Epoch 74/100] [Batch 115/347] [D loss: 0.505793] [G loss: 0.464393]\n",
      "[Epoch 74/100] [Batch 116/347] [D loss: 0.439973] [G loss: 0.429183]\n",
      "[Epoch 74/100] [Batch 117/347] [D loss: 0.423490] [G loss: 0.396312]\n",
      "[Epoch 74/100] [Batch 118/347] [D loss: 0.360638] [G loss: 0.363500]\n",
      "[Epoch 74/100] [Batch 119/347] [D loss: 0.361008] [G loss: 0.344878]\n",
      "[Epoch 74/100] [Batch 120/347] [D loss: 0.363638] [G loss: 0.336956]\n",
      "[Epoch 74/100] [Batch 121/347] [D loss: 0.369141] [G loss: 0.328632]\n",
      "[Epoch 74/100] [Batch 122/347] [D loss: 0.490920] [G loss: 0.328266]\n",
      "[Epoch 74/100] [Batch 123/347] [D loss: 0.542493] [G loss: 0.332148]\n",
      "[Epoch 74/100] [Batch 124/347] [D loss: 0.472080] [G loss: 0.335220]\n",
      "[Epoch 74/100] [Batch 125/347] [D loss: 0.440120] [G loss: 0.345027]\n",
      "[Epoch 74/100] [Batch 126/347] [D loss: 0.399880] [G loss: 0.356551]\n",
      "[Epoch 74/100] [Batch 127/347] [D loss: 0.397600] [G loss: 0.365859]\n",
      "[Epoch 74/100] [Batch 128/347] [D loss: 0.377538] [G loss: 0.370083]\n",
      "[Epoch 74/100] [Batch 129/347] [D loss: 0.318321] [G loss: 0.375649]\n",
      "[Epoch 74/100] [Batch 130/347] [D loss: 0.260857] [G loss: 0.399875]\n",
      "[Epoch 74/100] [Batch 131/347] [D loss: 0.233788] [G loss: 0.423681]\n",
      "[Epoch 74/100] [Batch 132/347] [D loss: 0.208305] [G loss: 0.448902]\n",
      "[Epoch 74/100] [Batch 133/347] [D loss: 0.192819] [G loss: 0.470330]\n",
      "[Epoch 74/100] [Batch 134/347] [D loss: 0.174793] [G loss: 0.488240]\n",
      "[Epoch 74/100] [Batch 135/347] [D loss: 0.164216] [G loss: 0.499838]\n",
      "[Epoch 74/100] [Batch 136/347] [D loss: 0.161908] [G loss: 0.502739]\n",
      "[Epoch 74/100] [Batch 137/347] [D loss: 0.428670] [G loss: 0.501313]\n",
      "[Epoch 74/100] [Batch 138/347] [D loss: 0.462926] [G loss: 0.497006]\n",
      "[Epoch 74/100] [Batch 139/347] [D loss: 0.469081] [G loss: 0.488341]\n",
      "[Epoch 74/100] [Batch 140/347] [D loss: 0.478441] [G loss: 0.488000]\n",
      "[Epoch 74/100] [Batch 141/347] [D loss: 0.451912] [G loss: 0.481746]\n",
      "[Epoch 74/100] [Batch 142/347] [D loss: 0.457358] [G loss: 0.474954]\n",
      "[Epoch 74/100] [Batch 143/347] [D loss: 0.458222] [G loss: 0.465125]\n",
      "[Epoch 74/100] [Batch 144/347] [D loss: 0.447394] [G loss: 0.455347]\n",
      "[Epoch 74/100] [Batch 145/347] [D loss: 0.469654] [G loss: 0.453786]\n",
      "[Epoch 74/100] [Batch 146/347] [D loss: 0.481760] [G loss: 0.447926]\n",
      "[Epoch 74/100] [Batch 147/347] [D loss: 0.499522] [G loss: 0.450438]\n",
      "[Epoch 74/100] [Batch 148/347] [D loss: 0.506598] [G loss: 0.450004]\n",
      "[Epoch 74/100] [Batch 149/347] [D loss: 0.469165] [G loss: 0.438265]\n",
      "[Epoch 74/100] [Batch 150/347] [D loss: 0.443322] [G loss: 0.429848]\n",
      "[Epoch 74/100] [Batch 151/347] [D loss: 0.408085] [G loss: 0.414422]\n",
      "[Epoch 74/100] [Batch 152/347] [D loss: 0.370401] [G loss: 0.387963]\n",
      "[Epoch 74/100] [Batch 153/347] [D loss: 0.358506] [G loss: 0.356259]\n",
      "[Epoch 74/100] [Batch 154/347] [D loss: 0.342028] [G loss: 0.329734]\n",
      "[Epoch 74/100] [Batch 155/347] [D loss: 0.335652] [G loss: 0.312017]\n",
      "[Epoch 74/100] [Batch 156/347] [D loss: 0.334839] [G loss: 0.294223]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 74/100] [Batch 157/347] [D loss: 0.332547] [G loss: 0.286125]\n",
      "[Epoch 74/100] [Batch 158/347] [D loss: 0.322572] [G loss: 0.290199]\n",
      "[Epoch 74/100] [Batch 159/347] [D loss: 0.339875] [G loss: 0.298794]\n",
      "[Epoch 74/100] [Batch 160/347] [D loss: 0.326508] [G loss: 0.318850]\n",
      "[Epoch 74/100] [Batch 161/347] [D loss: 0.311508] [G loss: 0.339121]\n",
      "[Epoch 74/100] [Batch 162/347] [D loss: 0.292088] [G loss: 0.353586]\n",
      "[Epoch 74/100] [Batch 163/347] [D loss: 0.282876] [G loss: 0.362976]\n",
      "[Epoch 74/100] [Batch 164/347] [D loss: 0.276402] [G loss: 0.381914]\n",
      "[Epoch 74/100] [Batch 165/347] [D loss: 0.273586] [G loss: 0.401840]\n",
      "[Epoch 74/100] [Batch 166/347] [D loss: 0.280715] [G loss: 0.423843]\n",
      "[Epoch 74/100] [Batch 167/347] [D loss: 0.311286] [G loss: 0.453620]\n",
      "[Epoch 74/100] [Batch 168/347] [D loss: 0.314822] [G loss: 0.466931]\n",
      "[Epoch 74/100] [Batch 169/347] [D loss: 0.455068] [G loss: 0.478375]\n",
      "[Epoch 74/100] [Batch 170/347] [D loss: 0.529096] [G loss: 0.487297]\n",
      "[Epoch 74/100] [Batch 171/347] [D loss: 0.531240] [G loss: 0.488919]\n",
      "[Epoch 74/100] [Batch 172/347] [D loss: 0.532239] [G loss: 0.492126]\n",
      "[Epoch 74/100] [Batch 173/347] [D loss: 0.533330] [G loss: 0.493000]\n",
      "[Epoch 74/100] [Batch 174/347] [D loss: 0.531568] [G loss: 0.498990]\n",
      "[Epoch 74/100] [Batch 175/347] [D loss: 0.543966] [G loss: 0.505876]\n",
      "[Epoch 74/100] [Batch 176/347] [D loss: 0.552065] [G loss: 0.511856]\n",
      "[Epoch 74/100] [Batch 177/347] [D loss: 0.551050] [G loss: 0.511694]\n",
      "[Epoch 74/100] [Batch 178/347] [D loss: 0.548601] [G loss: 0.508220]\n",
      "[Epoch 74/100] [Batch 179/347] [D loss: 0.547050] [G loss: 0.507664]\n",
      "[Epoch 74/100] [Batch 180/347] [D loss: 0.545237] [G loss: 0.506279]\n",
      "[Epoch 74/100] [Batch 181/347] [D loss: 0.543935] [G loss: 0.511354]\n",
      "[Epoch 74/100] [Batch 182/347] [D loss: 0.543853] [G loss: 0.514681]\n",
      "[Epoch 74/100] [Batch 183/347] [D loss: 0.543139] [G loss: 0.518689]\n",
      "[Epoch 74/100] [Batch 184/347] [D loss: 0.546206] [G loss: 0.523188]\n",
      "[Epoch 74/100] [Batch 185/347] [D loss: 0.545886] [G loss: 0.521787]\n",
      "[Epoch 74/100] [Batch 186/347] [D loss: 0.542999] [G loss: 0.521981]\n",
      "[Epoch 74/100] [Batch 187/347] [D loss: 0.540739] [G loss: 0.520419]\n",
      "[Epoch 74/100] [Batch 188/347] [D loss: 0.534557] [G loss: 0.513373]\n",
      "[Epoch 74/100] [Batch 189/347] [D loss: 0.525393] [G loss: 0.507998]\n",
      "[Epoch 74/100] [Batch 190/347] [D loss: 0.523893] [G loss: 0.505470]\n",
      "[Epoch 74/100] [Batch 191/347] [D loss: 0.523694] [G loss: 0.502711]\n",
      "[Epoch 74/100] [Batch 192/347] [D loss: 0.524655] [G loss: 0.502740]\n",
      "[Epoch 74/100] [Batch 193/347] [D loss: 0.534174] [G loss: 0.502713]\n",
      "[Epoch 74/100] [Batch 194/347] [D loss: 0.533063] [G loss: 0.498446]\n",
      "[Epoch 74/100] [Batch 195/347] [D loss: 0.529131] [G loss: 0.494645]\n",
      "[Epoch 74/100] [Batch 196/347] [D loss: 0.520915] [G loss: 0.490758]\n",
      "[Epoch 74/100] [Batch 197/347] [D loss: 0.519880] [G loss: 0.488088]\n",
      "[Epoch 74/100] [Batch 198/347] [D loss: 0.518814] [G loss: 0.488890]\n",
      "[Epoch 74/100] [Batch 199/347] [D loss: 0.517124] [G loss: 0.486781]\n",
      "[Epoch 74/100] [Batch 200/347] [D loss: 0.525713] [G loss: 0.484624]\n",
      "[Epoch 74/100] [Batch 201/347] [D loss: 0.529907] [G loss: 0.481764]\n",
      "[Epoch 74/100] [Batch 202/347] [D loss: 0.530392] [G loss: 0.478024]\n",
      "[Epoch 74/100] [Batch 203/347] [D loss: 0.535264] [G loss: 0.474595]\n",
      "[Epoch 74/100] [Batch 204/347] [D loss: 0.533153] [G loss: 0.475595]\n",
      "[Epoch 74/100] [Batch 205/347] [D loss: 0.532059] [G loss: 0.477971]\n",
      "[Epoch 74/100] [Batch 206/347] [D loss: 0.530888] [G loss: 0.478777]\n",
      "[Epoch 74/100] [Batch 207/347] [D loss: 0.519333] [G loss: 0.478463]\n",
      "[Epoch 74/100] [Batch 208/347] [D loss: 0.515939] [G loss: 0.479306]\n",
      "[Epoch 74/100] [Batch 209/347] [D loss: 0.512070] [G loss: 0.472008]\n",
      "[Epoch 74/100] [Batch 210/347] [D loss: 0.483524] [G loss: 0.468517]\n",
      "[Epoch 74/100] [Batch 211/347] [D loss: 0.414733] [G loss: 0.458320]\n",
      "[Epoch 74/100] [Batch 212/347] [D loss: 0.227528] [G loss: 0.438525]\n",
      "[Epoch 74/100] [Batch 213/347] [D loss: 0.221379] [G loss: 0.431202]\n",
      "[Epoch 74/100] [Batch 214/347] [D loss: 0.212308] [G loss: 0.425883]\n",
      "[Epoch 74/100] [Batch 215/347] [D loss: 0.208570] [G loss: 0.421488]\n",
      "[Epoch 74/100] [Batch 216/347] [D loss: 0.405949] [G loss: 0.432420]\n",
      "[Epoch 74/100] [Batch 217/347] [D loss: 0.440180] [G loss: 0.437345]\n",
      "[Epoch 74/100] [Batch 218/347] [D loss: 0.477848] [G loss: 0.440656]\n",
      "[Epoch 74/100] [Batch 219/347] [D loss: 0.453565] [G loss: 0.433988]\n",
      "[Epoch 74/100] [Batch 220/347] [D loss: 0.438112] [G loss: 0.421944]\n",
      "[Epoch 74/100] [Batch 221/347] [D loss: 0.455167] [G loss: 0.404871]\n",
      "[Epoch 74/100] [Batch 222/347] [D loss: 0.453702] [G loss: 0.379843]\n",
      "[Epoch 74/100] [Batch 223/347] [D loss: 0.428885] [G loss: 0.344638]\n",
      "[Epoch 74/100] [Batch 224/347] [D loss: 0.436474] [G loss: 0.308482]\n",
      "[Epoch 74/100] [Batch 225/347] [D loss: 0.448801] [G loss: 0.277830]\n",
      "[Epoch 74/100] [Batch 226/347] [D loss: 0.458524] [G loss: 0.258139]\n",
      "[Epoch 74/100] [Batch 227/347] [D loss: 0.502828] [G loss: 0.252071]\n",
      "[Epoch 74/100] [Batch 228/347] [D loss: 0.522728] [G loss: 0.251501]\n",
      "[Epoch 74/100] [Batch 229/347] [D loss: 0.526592] [G loss: 0.254542]\n",
      "[Epoch 74/100] [Batch 230/347] [D loss: 0.538948] [G loss: 0.259124]\n",
      "[Epoch 74/100] [Batch 231/347] [D loss: 0.512410] [G loss: 0.258481]\n",
      "[Epoch 74/100] [Batch 232/347] [D loss: 0.492593] [G loss: 0.264874]\n",
      "[Epoch 74/100] [Batch 233/347] [D loss: 0.426078] [G loss: 0.280062]\n",
      "[Epoch 74/100] [Batch 234/347] [D loss: 0.387131] [G loss: 0.297655]\n",
      "[Epoch 74/100] [Batch 235/347] [D loss: 0.378442] [G loss: 0.324174]\n",
      "[Epoch 74/100] [Batch 236/347] [D loss: 0.365113] [G loss: 0.350605]\n",
      "[Epoch 74/100] [Batch 237/347] [D loss: 0.428073] [G loss: 0.372753]\n",
      "[Epoch 74/100] [Batch 238/347] [D loss: 0.509562] [G loss: 0.386400]\n",
      "[Epoch 74/100] [Batch 239/347] [D loss: 0.511154] [G loss: 0.394562]\n",
      "[Epoch 74/100] [Batch 240/347] [D loss: 0.512617] [G loss: 0.403225]\n",
      "[Epoch 74/100] [Batch 241/347] [D loss: 0.516114] [G loss: 0.412654]\n",
      "[Epoch 74/100] [Batch 242/347] [D loss: 0.524653] [G loss: 0.423673]\n",
      "[Epoch 74/100] [Batch 243/347] [D loss: 0.484155] [G loss: 0.431201]\n",
      "[Epoch 74/100] [Batch 244/347] [D loss: 0.457664] [G loss: 0.427442]\n",
      "[Epoch 74/100] [Batch 245/347] [D loss: 0.467879] [G loss: 0.418490]\n",
      "[Epoch 74/100] [Batch 246/347] [D loss: 0.464831] [G loss: 0.406355]\n",
      "[Epoch 74/100] [Batch 247/347] [D loss: 0.492426] [G loss: 0.396797]\n",
      "[Epoch 74/100] [Batch 248/347] [D loss: 0.508916] [G loss: 0.398292]\n",
      "[Epoch 74/100] [Batch 249/347] [D loss: 0.495409] [G loss: 0.402085]\n",
      "[Epoch 74/100] [Batch 250/347] [D loss: 0.489535] [G loss: 0.408257]\n",
      "[Epoch 74/100] [Batch 251/347] [D loss: 0.478746] [G loss: 0.417159]\n",
      "[Epoch 74/100] [Batch 252/347] [D loss: 0.469925] [G loss: 0.418287]\n",
      "[Epoch 74/100] [Batch 253/347] [D loss: 0.408337] [G loss: 0.404977]\n",
      "[Epoch 74/100] [Batch 254/347] [D loss: 0.401980] [G loss: 0.401299]\n",
      "[Epoch 74/100] [Batch 255/347] [D loss: 0.396014] [G loss: 0.391944]\n",
      "[Epoch 74/100] [Batch 256/347] [D loss: 0.394455] [G loss: 0.373537]\n",
      "[Epoch 74/100] [Batch 257/347] [D loss: 0.377036] [G loss: 0.360150]\n",
      "[Epoch 74/100] [Batch 258/347] [D loss: 0.337402] [G loss: 0.347851]\n",
      "[Epoch 74/100] [Batch 259/347] [D loss: 0.341316] [G loss: 0.337419]\n",
      "[Epoch 74/100] [Batch 260/347] [D loss: 0.343583] [G loss: 0.330716]\n",
      "[Epoch 74/100] [Batch 261/347] [D loss: 0.336317] [G loss: 0.333437]\n",
      "[Epoch 74/100] [Batch 262/347] [D loss: 0.305676] [G loss: 0.336444]\n",
      "[Epoch 74/100] [Batch 263/347] [D loss: 0.303309] [G loss: 0.342521]\n",
      "[Epoch 74/100] [Batch 264/347] [D loss: 0.298068] [G loss: 0.353364]\n",
      "[Epoch 74/100] [Batch 265/347] [D loss: 0.304652] [G loss: 0.364390]\n",
      "[Epoch 74/100] [Batch 266/347] [D loss: 0.358240] [G loss: 0.375807]\n",
      "[Epoch 74/100] [Batch 267/347] [D loss: 0.378396] [G loss: 0.384556]\n",
      "[Epoch 74/100] [Batch 268/347] [D loss: 0.386207] [G loss: 0.389072]\n",
      "[Epoch 74/100] [Batch 269/347] [D loss: 0.391298] [G loss: 0.391833]\n",
      "[Epoch 74/100] [Batch 270/347] [D loss: 0.423516] [G loss: 0.392053]\n",
      "[Epoch 74/100] [Batch 271/347] [D loss: 0.398102] [G loss: 0.395857]\n",
      "[Epoch 74/100] [Batch 272/347] [D loss: 0.471555] [G loss: 0.416892]\n",
      "[Epoch 74/100] [Batch 273/347] [D loss: 0.423382] [G loss: 0.437074]\n",
      "[Epoch 74/100] [Batch 274/347] [D loss: 0.373887] [G loss: 0.452940]\n",
      "[Epoch 74/100] [Batch 275/347] [D loss: 0.306577] [G loss: 0.465090]\n",
      "[Epoch 74/100] [Batch 276/347] [D loss: 0.474326] [G loss: 0.467220]\n",
      "[Epoch 74/100] [Batch 277/347] [D loss: 0.500409] [G loss: 0.477836]\n",
      "[Epoch 74/100] [Batch 278/347] [D loss: 0.506331] [G loss: 0.487398]\n",
      "[Epoch 74/100] [Batch 279/347] [D loss: 0.510952] [G loss: 0.489187]\n",
      "[Epoch 74/100] [Batch 280/347] [D loss: 0.514779] [G loss: 0.489286]\n",
      "[Epoch 74/100] [Batch 281/347] [D loss: 0.520338] [G loss: 0.489605]\n",
      "[Epoch 74/100] [Batch 282/347] [D loss: 0.521777] [G loss: 0.493049]\n",
      "[Epoch 74/100] [Batch 283/347] [D loss: 0.522975] [G loss: 0.494566]\n",
      "[Epoch 74/100] [Batch 284/347] [D loss: 0.523989] [G loss: 0.496982]\n",
      "[Epoch 74/100] [Batch 285/347] [D loss: 0.529351] [G loss: 0.498252]\n",
      "[Epoch 74/100] [Batch 286/347] [D loss: 0.526872] [G loss: 0.484398]\n",
      "[Epoch 74/100] [Batch 287/347] [D loss: 0.527799] [G loss: 0.481815]\n",
      "[Epoch 74/100] [Batch 288/347] [D loss: 0.527887] [G loss: 0.479207]\n",
      "[Epoch 74/100] [Batch 289/347] [D loss: 0.525706] [G loss: 0.474345]\n",
      "[Epoch 74/100] [Batch 290/347] [D loss: 0.525686] [G loss: 0.490226]\n",
      "[Epoch 74/100] [Batch 291/347] [D loss: 0.523831] [G loss: 0.497109]\n",
      "[Epoch 74/100] [Batch 292/347] [D loss: 0.520596] [G loss: 0.501036]\n",
      "[Epoch 74/100] [Batch 293/347] [D loss: 0.487366] [G loss: 0.506551]\n",
      "[Epoch 74/100] [Batch 294/347] [D loss: 0.486423] [G loss: 0.510749]\n",
      "[Epoch 74/100] [Batch 295/347] [D loss: 0.485697] [G loss: 0.509381]\n",
      "[Epoch 74/100] [Batch 296/347] [D loss: 0.484434] [G loss: 0.507656]\n",
      "[Epoch 74/100] [Batch 297/347] [D loss: 0.519690] [G loss: 0.511872]\n",
      "[Epoch 74/100] [Batch 298/347] [D loss: 0.523558] [G loss: 0.505018]\n",
      "[Epoch 74/100] [Batch 299/347] [D loss: 0.522678] [G loss: 0.500023]\n",
      "[Epoch 74/100] [Batch 300/347] [D loss: 0.520947] [G loss: 0.497433]\n",
      "[Epoch 74/100] [Batch 301/347] [D loss: 0.521315] [G loss: 0.482895]\n",
      "[Epoch 74/100] [Batch 302/347] [D loss: 0.522038] [G loss: 0.473582]\n",
      "[Epoch 74/100] [Batch 303/347] [D loss: 0.520660] [G loss: 0.461200]\n",
      "[Epoch 74/100] [Batch 304/347] [D loss: 0.489757] [G loss: 0.448687]\n",
      "[Epoch 74/100] [Batch 305/347] [D loss: 0.460534] [G loss: 0.441485]\n",
      "[Epoch 74/100] [Batch 306/347] [D loss: 0.455163] [G loss: 0.441500]\n",
      "[Epoch 74/100] [Batch 307/347] [D loss: 0.446461] [G loss: 0.445321]\n",
      "[Epoch 74/100] [Batch 308/347] [D loss: 0.455212] [G loss: 0.448038]\n",
      "[Epoch 74/100] [Batch 309/347] [D loss: 0.511770] [G loss: 0.460510]\n",
      "[Epoch 74/100] [Batch 310/347] [D loss: 0.530527] [G loss: 0.470963]\n",
      "[Epoch 74/100] [Batch 311/347] [D loss: 0.522931] [G loss: 0.466539]\n",
      "[Epoch 74/100] [Batch 312/347] [D loss: 0.507778] [G loss: 0.459651]\n",
      "[Epoch 74/100] [Batch 313/347] [D loss: 0.499059] [G loss: 0.448568]\n",
      "[Epoch 74/100] [Batch 314/347] [D loss: 0.496326] [G loss: 0.432205]\n",
      "[Epoch 74/100] [Batch 315/347] [D loss: 0.494701] [G loss: 0.419256]\n",
      "[Epoch 74/100] [Batch 316/347] [D loss: 0.497735] [G loss: 0.418519]\n",
      "[Epoch 74/100] [Batch 317/347] [D loss: 0.499281] [G loss: 0.420283]\n",
      "[Epoch 74/100] [Batch 318/347] [D loss: 0.502122] [G loss: 0.431892]\n",
      "[Epoch 74/100] [Batch 319/347] [D loss: 0.495836] [G loss: 0.442275]\n",
      "[Epoch 74/100] [Batch 320/347] [D loss: 0.492408] [G loss: 0.438479]\n",
      "[Epoch 74/100] [Batch 321/347] [D loss: 0.480897] [G loss: 0.429515]\n",
      "[Epoch 74/100] [Batch 322/347] [D loss: 0.482409] [G loss: 0.419362]\n",
      "[Epoch 74/100] [Batch 323/347] [D loss: 0.442258] [G loss: 0.407015]\n",
      "[Epoch 74/100] [Batch 324/347] [D loss: 0.425055] [G loss: 0.396698]\n",
      "[Epoch 74/100] [Batch 325/347] [D loss: 0.414297] [G loss: 0.383316]\n",
      "[Epoch 74/100] [Batch 326/347] [D loss: 0.398076] [G loss: 0.366638]\n",
      "[Epoch 74/100] [Batch 327/347] [D loss: 0.363161] [G loss: 0.350239]\n",
      "[Epoch 74/100] [Batch 328/347] [D loss: 0.351609] [G loss: 0.328902]\n",
      "[Epoch 74/100] [Batch 329/347] [D loss: 0.339994] [G loss: 0.308898]\n",
      "[Epoch 74/100] [Batch 330/347] [D loss: 0.334471] [G loss: 0.289960]\n",
      "[Epoch 74/100] [Batch 331/347] [D loss: 0.359903] [G loss: 0.278589]\n",
      "[Epoch 74/100] [Batch 332/347] [D loss: 0.435028] [G loss: 0.284476]\n",
      "[Epoch 74/100] [Batch 333/347] [D loss: 0.409521] [G loss: 0.272484]\n",
      "[Epoch 74/100] [Batch 334/347] [D loss: 0.407709] [G loss: 0.260487]\n",
      "[Epoch 74/100] [Batch 335/347] [D loss: 0.410854] [G loss: 0.257553]\n",
      "[Epoch 74/100] [Batch 336/347] [D loss: 0.410836] [G loss: 0.258923]\n",
      "[Epoch 74/100] [Batch 337/347] [D loss: 0.449109] [G loss: 0.268782]\n",
      "[Epoch 74/100] [Batch 338/347] [D loss: 0.483841] [G loss: 0.284057]\n",
      "[Epoch 74/100] [Batch 339/347] [D loss: 0.465423] [G loss: 0.293859]\n",
      "[Epoch 74/100] [Batch 340/347] [D loss: 0.438439] [G loss: 0.300966]\n",
      "[Epoch 74/100] [Batch 341/347] [D loss: 0.440396] [G loss: 0.313281]\n",
      "[Epoch 74/100] [Batch 342/347] [D loss: 0.334461] [G loss: 0.315595]\n",
      "[Epoch 74/100] [Batch 343/347] [D loss: 0.295530] [G loss: 0.316905]\n",
      "[Epoch 74/100] [Batch 344/347] [D loss: 0.273640] [G loss: 0.329306]\n",
      "[Epoch 74/100] [Batch 345/347] [D loss: 0.233648] [G loss: 0.346991]\n",
      "[Epoch 74/100] [Batch 346/347] [D loss: 0.215507] [G loss: 0.364928]\n",
      "[Epoch 74/100] [Batch 347/347] [D loss: 0.200495] [G loss: 0.379621]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 75/100] [Batch 1/347] [D loss: 0.446570] [G loss: 0.403157]\n",
      "[Epoch 75/100] [Batch 2/347] [D loss: 0.475429] [G loss: 0.409753]\n",
      "[Epoch 75/100] [Batch 3/347] [D loss: 0.505897] [G loss: 0.418913]\n",
      "[Epoch 75/100] [Batch 4/347] [D loss: 0.510623] [G loss: 0.422923]\n",
      "[Epoch 75/100] [Batch 5/347] [D loss: 0.512452] [G loss: 0.422048]\n",
      "[Epoch 75/100] [Batch 6/347] [D loss: 0.501847] [G loss: 0.421321]\n",
      "[Epoch 75/100] [Batch 7/347] [D loss: 0.489723] [G loss: 0.414020]\n",
      "[Epoch 75/100] [Batch 8/347] [D loss: 0.492456] [G loss: 0.413123]\n",
      "[Epoch 75/100] [Batch 9/347] [D loss: 0.491187] [G loss: 0.414095]\n",
      "[Epoch 75/100] [Batch 10/347] [D loss: 0.494580] [G loss: 0.414532]\n",
      "[Epoch 75/100] [Batch 11/347] [D loss: 0.509206] [G loss: 0.422870]\n",
      "[Epoch 75/100] [Batch 12/347] [D loss: 0.513353] [G loss: 0.423999]\n",
      "[Epoch 75/100] [Batch 13/347] [D loss: 0.504501] [G loss: 0.421444]\n",
      "[Epoch 75/100] [Batch 14/347] [D loss: 0.495129] [G loss: 0.418878]\n",
      "[Epoch 75/100] [Batch 15/347] [D loss: 0.495593] [G loss: 0.406946]\n",
      "[Epoch 75/100] [Batch 16/347] [D loss: 0.490788] [G loss: 0.398568]\n",
      "[Epoch 75/100] [Batch 17/347] [D loss: 0.491673] [G loss: 0.398246]\n",
      "[Epoch 75/100] [Batch 18/347] [D loss: 0.494324] [G loss: 0.395532]\n",
      "[Epoch 75/100] [Batch 19/347] [D loss: 0.491591] [G loss: 0.397110]\n",
      "[Epoch 75/100] [Batch 20/347] [D loss: 0.497824] [G loss: 0.397851]\n",
      "[Epoch 75/100] [Batch 21/347] [D loss: 0.458322] [G loss: 0.388142]\n",
      "[Epoch 75/100] [Batch 22/347] [D loss: 0.455188] [G loss: 0.380155]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 75/100] [Batch 23/347] [D loss: 0.446224] [G loss: 0.369518]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 75/100] [Batch 24/347] [D loss: 0.388570] [G loss: 0.352203]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 75/100] [Batch 25/347] [D loss: 0.268235] [G loss: 0.348313]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 75/100] [Batch 26/347] [D loss: 0.262398] [G loss: 0.336642]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 75/100] [Batch 27/347] [D loss: 0.260983] [G loss: 0.329752]\n",
      "[Epoch 75/100] [Batch 28/347] [D loss: 0.264683] [G loss: 0.325999]\n",
      "[Epoch 75/100] [Batch 29/347] [D loss: 0.285227] [G loss: 0.321902]\n",
      "[Epoch 75/100] [Batch 30/347] [D loss: 0.281775] [G loss: 0.317813]\n",
      "[Epoch 75/100] [Batch 31/347] [D loss: 0.283839] [G loss: 0.315077]\n",
      "[Epoch 75/100] [Batch 32/347] [D loss: 0.291379] [G loss: 0.312661]\n",
      "[Epoch 75/100] [Batch 33/347] [D loss: 0.301969] [G loss: 0.314188]\n",
      "[Epoch 75/100] [Batch 34/347] [D loss: 0.329680] [G loss: 0.312850]\n",
      "[Epoch 75/100] [Batch 35/347] [D loss: 0.329810] [G loss: 0.309277]\n",
      "[Epoch 75/100] [Batch 36/347] [D loss: 0.349485] [G loss: 0.306799]\n",
      "[Epoch 75/100] [Batch 37/347] [D loss: 0.357464] [G loss: 0.302538]\n",
      "[Epoch 75/100] [Batch 38/347] [D loss: 0.360130] [G loss: 0.295556]\n",
      "[Epoch 75/100] [Batch 39/347] [D loss: 0.373516] [G loss: 0.297113]\n",
      "[Epoch 75/100] [Batch 40/347] [D loss: 0.405252] [G loss: 0.303954]\n",
      "[Epoch 75/100] [Batch 41/347] [D loss: 0.427313] [G loss: 0.306827]\n",
      "[Epoch 75/100] [Batch 42/347] [D loss: 0.422958] [G loss: 0.314449]\n",
      "[Epoch 75/100] [Batch 43/347] [D loss: 0.448298] [G loss: 0.326921]\n",
      "[Epoch 75/100] [Batch 44/347] [D loss: 0.431799] [G loss: 0.329351]\n",
      "[Epoch 75/100] [Batch 45/347] [D loss: 0.403123] [G loss: 0.316801]\n",
      "[Epoch 75/100] [Batch 46/347] [D loss: 0.324002] [G loss: 0.307558]\n",
      "[Epoch 75/100] [Batch 47/347] [D loss: 0.319823] [G loss: 0.300965]\n",
      "[Epoch 75/100] [Batch 48/347] [D loss: 0.263080] [G loss: 0.308420]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 75/100] [Batch 49/347] [D loss: 0.249166] [G loss: 0.328581]\n",
      "[Epoch 75/100] [Batch 50/347] [D loss: 0.237747] [G loss: 0.352027]\n",
      "[Epoch 75/100] [Batch 51/347] [D loss: 0.219230] [G loss: 0.370665]\n",
      "[Epoch 75/100] [Batch 52/347] [D loss: 0.294071] [G loss: 0.377403]\n",
      "[Epoch 75/100] [Batch 53/347] [D loss: 0.327627] [G loss: 0.372686]\n",
      "[Epoch 75/100] [Batch 54/347] [D loss: 0.312435] [G loss: 0.366175]\n",
      "[Epoch 75/100] [Batch 55/347] [D loss: 0.308323] [G loss: 0.371217]\n",
      "[Epoch 75/100] [Batch 56/347] [D loss: 0.301247] [G loss: 0.378977]\n",
      "[Epoch 75/100] [Batch 57/347] [D loss: 0.257811] [G loss: 0.385405]\n",
      "[Epoch 75/100] [Batch 58/347] [D loss: 0.266447] [G loss: 0.387675]\n",
      "[Epoch 75/100] [Batch 59/347] [D loss: 0.263344] [G loss: 0.381118]\n",
      "[Epoch 75/100] [Batch 60/347] [D loss: 0.248117] [G loss: 0.366035]\n",
      "[Epoch 75/100] [Batch 61/347] [D loss: 0.261311] [G loss: 0.348698]\n",
      "[Epoch 75/100] [Batch 62/347] [D loss: 0.262211] [G loss: 0.345522]\n",
      "[Epoch 75/100] [Batch 63/347] [D loss: 0.257077] [G loss: 0.344390]\n",
      "[Epoch 75/100] [Batch 64/347] [D loss: 0.245488] [G loss: 0.341800]\n",
      "[Epoch 75/100] [Batch 65/347] [D loss: 0.215183] [G loss: 0.347663]\n",
      "[Epoch 75/100] [Batch 66/347] [D loss: 0.215157] [G loss: 0.350013]\n",
      "[Epoch 75/100] [Batch 67/347] [D loss: 0.211480] [G loss: 0.343420]\n",
      "[Epoch 75/100] [Batch 68/347] [D loss: 0.208212] [G loss: 0.344501]\n",
      "[Epoch 75/100] [Batch 69/347] [D loss: 0.217505] [G loss: 0.356282]\n",
      "[Epoch 75/100] [Batch 70/347] [D loss: 0.213526] [G loss: 0.362916]\n",
      "[Epoch 75/100] [Batch 71/347] [D loss: 0.213289] [G loss: 0.363585]\n",
      "[Epoch 75/100] [Batch 72/347] [D loss: 0.220690] [G loss: 0.377856]\n",
      "[Epoch 75/100] [Batch 73/347] [D loss: 0.323898] [G loss: 0.375679]\n",
      "[Epoch 75/100] [Batch 74/347] [D loss: 0.325911] [G loss: 0.377095]\n",
      "[Epoch 75/100] [Batch 75/347] [D loss: 0.323176] [G loss: 0.376711]\n",
      "[Epoch 75/100] [Batch 76/347] [D loss: 0.320256] [G loss: 0.373165]\n",
      "[Epoch 75/100] [Batch 77/347] [D loss: 0.360236] [G loss: 0.371028]\n",
      "[Epoch 75/100] [Batch 78/347] [D loss: 0.412340] [G loss: 0.375627]\n",
      "[Epoch 75/100] [Batch 79/347] [D loss: 0.406240] [G loss: 0.368439]\n",
      "[Epoch 75/100] [Batch 80/347] [D loss: 0.302951] [G loss: 0.348488]\n",
      "[Epoch 75/100] [Batch 81/347] [D loss: 0.288132] [G loss: 0.338961]\n",
      "[Epoch 75/100] [Batch 82/347] [D loss: 0.289306] [G loss: 0.333389]\n",
      "[Epoch 75/100] [Batch 83/347] [D loss: 0.297234] [G loss: 0.328126]\n",
      "[Epoch 75/100] [Batch 84/347] [D loss: 0.416966] [G loss: 0.328758]\n",
      "[Epoch 75/100] [Batch 85/347] [D loss: 0.489424] [G loss: 0.325372]\n",
      "[Epoch 75/100] [Batch 86/347] [D loss: 0.491099] [G loss: 0.321255]\n",
      "[Epoch 75/100] [Batch 87/347] [D loss: 0.491962] [G loss: 0.318332]\n",
      "[Epoch 75/100] [Batch 88/347] [D loss: 0.515462] [G loss: 0.315534]\n",
      "[Epoch 75/100] [Batch 89/347] [D loss: 0.527339] [G loss: 0.314518]\n",
      "[Epoch 75/100] [Batch 90/347] [D loss: 0.525389] [G loss: 0.311743]\n",
      "[Epoch 75/100] [Batch 91/347] [D loss: 0.526745] [G loss: 0.308692]\n",
      "[Epoch 75/100] [Batch 92/347] [D loss: 0.529952] [G loss: 0.308237]\n",
      "[Epoch 75/100] [Batch 93/347] [D loss: 0.530614] [G loss: 0.308653]\n",
      "[Epoch 75/100] [Batch 94/347] [D loss: 0.512121] [G loss: 0.305577]\n",
      "[Epoch 75/100] [Batch 95/347] [D loss: 0.502355] [G loss: 0.306245]\n",
      "[Epoch 75/100] [Batch 96/347] [D loss: 0.503585] [G loss: 0.309837]\n",
      "[Epoch 75/100] [Batch 97/347] [D loss: 0.497325] [G loss: 0.312588]\n",
      "[Epoch 75/100] [Batch 98/347] [D loss: 0.483196] [G loss: 0.317027]\n",
      "[Epoch 75/100] [Batch 99/347] [D loss: 0.490607] [G loss: 0.321497]\n",
      "[Epoch 75/100] [Batch 100/347] [D loss: 0.492578] [G loss: 0.325721]\n",
      "[Epoch 75/100] [Batch 101/347] [D loss: 0.501063] [G loss: 0.327838]\n",
      "[Epoch 75/100] [Batch 102/347] [D loss: 0.550873] [G loss: 0.330269]\n",
      "[Epoch 75/100] [Batch 103/347] [D loss: 0.557528] [G loss: 0.336897]\n",
      "[Epoch 75/100] [Batch 104/347] [D loss: 0.530310] [G loss: 0.337714]\n",
      "[Epoch 75/100] [Batch 105/347] [D loss: 0.447157] [G loss: 0.338498]\n",
      "[Epoch 75/100] [Batch 106/347] [D loss: 0.283413] [G loss: 0.348715]\n",
      "[Epoch 75/100] [Batch 107/347] [D loss: 0.254230] [G loss: 0.372899]\n",
      "[Epoch 75/100] [Batch 108/347] [D loss: 0.231897] [G loss: 0.403042]\n",
      "[Epoch 75/100] [Batch 109/347] [D loss: 0.198980] [G loss: 0.433176]\n",
      "[Epoch 75/100] [Batch 110/347] [D loss: 0.200316] [G loss: 0.452322]\n",
      "[Epoch 75/100] [Batch 111/347] [D loss: 0.203381] [G loss: 0.471305]\n",
      "[Epoch 75/100] [Batch 112/347] [D loss: 0.210704] [G loss: 0.485147]\n",
      "[Epoch 75/100] [Batch 113/347] [D loss: 0.421153] [G loss: 0.510331]\n",
      "[Epoch 75/100] [Batch 114/347] [D loss: 0.506788] [G loss: 0.521502]\n",
      "[Epoch 75/100] [Batch 115/347] [D loss: 0.510200] [G loss: 0.508004]\n",
      "[Epoch 75/100] [Batch 116/347] [D loss: 0.473593] [G loss: 0.492491]\n",
      "[Epoch 75/100] [Batch 117/347] [D loss: 0.475905] [G loss: 0.481218]\n",
      "[Epoch 75/100] [Batch 118/347] [D loss: 0.421095] [G loss: 0.468063]\n",
      "[Epoch 75/100] [Batch 119/347] [D loss: 0.411078] [G loss: 0.463276]\n",
      "[Epoch 75/100] [Batch 120/347] [D loss: 0.388929] [G loss: 0.463553]\n",
      "[Epoch 75/100] [Batch 121/347] [D loss: 0.362455] [G loss: 0.453945]\n",
      "[Epoch 75/100] [Batch 122/347] [D loss: 0.459940] [G loss: 0.444674]\n",
      "[Epoch 75/100] [Batch 123/347] [D loss: 0.503202] [G loss: 0.431473]\n",
      "[Epoch 75/100] [Batch 124/347] [D loss: 0.413463] [G loss: 0.409776]\n",
      "[Epoch 75/100] [Batch 125/347] [D loss: 0.367714] [G loss: 0.390070]\n",
      "[Epoch 75/100] [Batch 126/347] [D loss: 0.324694] [G loss: 0.371014]\n",
      "[Epoch 75/100] [Batch 127/347] [D loss: 0.331629] [G loss: 0.350866]\n",
      "[Epoch 75/100] [Batch 128/347] [D loss: 0.326599] [G loss: 0.329993]\n",
      "[Epoch 75/100] [Batch 129/347] [D loss: 0.312694] [G loss: 0.319886]\n",
      "[Epoch 75/100] [Batch 130/347] [D loss: 0.317990] [G loss: 0.335867]\n",
      "[Epoch 75/100] [Batch 131/347] [D loss: 0.308515] [G loss: 0.356592]\n",
      "[Epoch 75/100] [Batch 132/347] [D loss: 0.276592] [G loss: 0.390890]\n",
      "[Epoch 75/100] [Batch 133/347] [D loss: 0.267266] [G loss: 0.430134]\n",
      "[Epoch 75/100] [Batch 134/347] [D loss: 0.216534] [G loss: 0.463801]\n",
      "[Epoch 75/100] [Batch 135/347] [D loss: 0.175504] [G loss: 0.486378]\n",
      "[Epoch 75/100] [Batch 136/347] [D loss: 0.153301] [G loss: 0.495067]\n",
      "[Epoch 75/100] [Batch 137/347] [D loss: 0.370688] [G loss: 0.496584]\n",
      "[Epoch 75/100] [Batch 138/347] [D loss: 0.413341] [G loss: 0.493414]\n",
      "[Epoch 75/100] [Batch 139/347] [D loss: 0.428746] [G loss: 0.485534]\n",
      "[Epoch 75/100] [Batch 140/347] [D loss: 0.448156] [G loss: 0.485371]\n",
      "[Epoch 75/100] [Batch 141/347] [D loss: 0.406578] [G loss: 0.479269]\n",
      "[Epoch 75/100] [Batch 142/347] [D loss: 0.415749] [G loss: 0.472444]\n",
      "[Epoch 75/100] [Batch 143/347] [D loss: 0.412261] [G loss: 0.462361]\n",
      "[Epoch 75/100] [Batch 144/347] [D loss: 0.396358] [G loss: 0.451787]\n",
      "[Epoch 75/100] [Batch 145/347] [D loss: 0.424740] [G loss: 0.448891]\n",
      "[Epoch 75/100] [Batch 146/347] [D loss: 0.431762] [G loss: 0.439884]\n",
      "[Epoch 75/100] [Batch 147/347] [D loss: 0.452457] [G loss: 0.429767]\n",
      "[Epoch 75/100] [Batch 148/347] [D loss: 0.456785] [G loss: 0.419736]\n",
      "[Epoch 75/100] [Batch 149/347] [D loss: 0.378198] [G loss: 0.400224]\n",
      "[Epoch 75/100] [Batch 150/347] [D loss: 0.334782] [G loss: 0.373837]\n",
      "[Epoch 75/100] [Batch 151/347] [D loss: 0.311666] [G loss: 0.342589]\n",
      "[Epoch 75/100] [Batch 152/347] [D loss: 0.299845] [G loss: 0.309162]\n",
      "[Epoch 75/100] [Batch 153/347] [D loss: 0.311942] [G loss: 0.280884]\n",
      "[Epoch 75/100] [Batch 154/347] [D loss: 0.320766] [G loss: 0.264302]\n",
      "[Epoch 75/100] [Batch 155/347] [D loss: 0.327685] [G loss: 0.262621]\n",
      "[Epoch 75/100] [Batch 156/347] [D loss: 0.330399] [G loss: 0.263059]\n",
      "[Epoch 75/100] [Batch 157/347] [D loss: 0.321372] [G loss: 0.272466]\n",
      "[Epoch 75/100] [Batch 158/347] [D loss: 0.307656] [G loss: 0.294443]\n",
      "[Epoch 75/100] [Batch 159/347] [D loss: 0.303287] [G loss: 0.317579]\n",
      "[Epoch 75/100] [Batch 160/347] [D loss: 0.275331] [G loss: 0.350442]\n",
      "[Epoch 75/100] [Batch 161/347] [D loss: 0.254697] [G loss: 0.378286]\n",
      "[Epoch 75/100] [Batch 162/347] [D loss: 0.236894] [G loss: 0.396066]\n",
      "[Epoch 75/100] [Batch 163/347] [D loss: 0.233077] [G loss: 0.402862]\n",
      "[Epoch 75/100] [Batch 164/347] [D loss: 0.235081] [G loss: 0.417640]\n",
      "[Epoch 75/100] [Batch 165/347] [D loss: 0.238609] [G loss: 0.433708]\n",
      "[Epoch 75/100] [Batch 166/347] [D loss: 0.250110] [G loss: 0.444438]\n",
      "[Epoch 75/100] [Batch 167/347] [D loss: 0.282712] [G loss: 0.468623]\n",
      "[Epoch 75/100] [Batch 168/347] [D loss: 0.284821] [G loss: 0.478337]\n",
      "[Epoch 75/100] [Batch 169/347] [D loss: 0.434732] [G loss: 0.486147]\n",
      "[Epoch 75/100] [Batch 170/347] [D loss: 0.514133] [G loss: 0.490786]\n",
      "[Epoch 75/100] [Batch 171/347] [D loss: 0.515734] [G loss: 0.487997]\n",
      "[Epoch 75/100] [Batch 172/347] [D loss: 0.514679] [G loss: 0.485809]\n",
      "[Epoch 75/100] [Batch 173/347] [D loss: 0.514051] [G loss: 0.480719]\n",
      "[Epoch 75/100] [Batch 174/347] [D loss: 0.506694] [G loss: 0.478402]\n",
      "[Epoch 75/100] [Batch 175/347] [D loss: 0.530495] [G loss: 0.477128]\n",
      "[Epoch 75/100] [Batch 176/347] [D loss: 0.553238] [G loss: 0.474383]\n",
      "[Epoch 75/100] [Batch 177/347] [D loss: 0.552457] [G loss: 0.466166]\n",
      "[Epoch 75/100] [Batch 178/347] [D loss: 0.550040] [G loss: 0.455417]\n",
      "[Epoch 75/100] [Batch 179/347] [D loss: 0.546618] [G loss: 0.447448]\n",
      "[Epoch 75/100] [Batch 180/347] [D loss: 0.544344] [G loss: 0.439904]\n",
      "[Epoch 75/100] [Batch 181/347] [D loss: 0.542144] [G loss: 0.438489]\n",
      "[Epoch 75/100] [Batch 182/347] [D loss: 0.545709] [G loss: 0.434808]\n",
      "[Epoch 75/100] [Batch 183/347] [D loss: 0.546281] [G loss: 0.431852]\n",
      "[Epoch 75/100] [Batch 184/347] [D loss: 0.565289] [G loss: 0.431198]\n",
      "[Epoch 75/100] [Batch 185/347] [D loss: 0.566776] [G loss: 0.426446]\n",
      "[Epoch 75/100] [Batch 186/347] [D loss: 0.558718] [G loss: 0.424949]\n",
      "[Epoch 75/100] [Batch 187/347] [D loss: 0.550548] [G loss: 0.421868]\n",
      "[Epoch 75/100] [Batch 188/347] [D loss: 0.517140] [G loss: 0.412547]\n",
      "[Epoch 75/100] [Batch 189/347] [D loss: 0.464871] [G loss: 0.403040]\n",
      "[Epoch 75/100] [Batch 190/347] [D loss: 0.456877] [G loss: 0.395674]\n",
      "[Epoch 75/100] [Batch 191/347] [D loss: 0.457549] [G loss: 0.386967]\n",
      "[Epoch 75/100] [Batch 192/347] [D loss: 0.467562] [G loss: 0.380198]\n",
      "[Epoch 75/100] [Batch 193/347] [D loss: 0.534389] [G loss: 0.375212]\n",
      "[Epoch 75/100] [Batch 194/347] [D loss: 0.530460] [G loss: 0.366224]\n",
      "[Epoch 75/100] [Batch 195/347] [D loss: 0.507656] [G loss: 0.359313]\n",
      "[Epoch 75/100] [Batch 196/347] [D loss: 0.463447] [G loss: 0.352640]\n",
      "[Epoch 75/100] [Batch 197/347] [D loss: 0.463099] [G loss: 0.348417]\n",
      "[Epoch 75/100] [Batch 198/347] [D loss: 0.463198] [G loss: 0.348056]\n",
      "[Epoch 75/100] [Batch 199/347] [D loss: 0.460258] [G loss: 0.346346]\n",
      "[Epoch 75/100] [Batch 200/347] [D loss: 0.515942] [G loss: 0.345743]\n",
      "[Epoch 75/100] [Batch 201/347] [D loss: 0.549531] [G loss: 0.345408]\n",
      "[Epoch 75/100] [Batch 202/347] [D loss: 0.553734] [G loss: 0.346469]\n",
      "[Epoch 75/100] [Batch 203/347] [D loss: 0.594194] [G loss: 0.349151]\n",
      "[Epoch 75/100] [Batch 204/347] [D loss: 0.587493] [G loss: 0.357282]\n",
      "[Epoch 75/100] [Batch 205/347] [D loss: 0.586681] [G loss: 0.369217]\n",
      "[Epoch 75/100] [Batch 206/347] [D loss: 0.583665] [G loss: 0.379747]\n",
      "[Epoch 75/100] [Batch 207/347] [D loss: 0.522693] [G loss: 0.388735]\n",
      "[Epoch 75/100] [Batch 208/347] [D loss: 0.509139] [G loss: 0.398013]\n",
      "[Epoch 75/100] [Batch 209/347] [D loss: 0.498680] [G loss: 0.399447]\n",
      "[Epoch 75/100] [Batch 210/347] [D loss: 0.400119] [G loss: 0.403884]\n",
      "[Epoch 75/100] [Batch 211/347] [D loss: 0.352651] [G loss: 0.402896]\n",
      "[Epoch 75/100] [Batch 212/347] [D loss: 0.235287] [G loss: 0.398585]\n",
      "[Epoch 75/100] [Batch 213/347] [D loss: 0.227845] [G loss: 0.409151]\n",
      "[Epoch 75/100] [Batch 214/347] [D loss: 0.218341] [G loss: 0.425333]\n",
      "[Epoch 75/100] [Batch 215/347] [D loss: 0.212415] [G loss: 0.442636]\n",
      "[Epoch 75/100] [Batch 216/347] [D loss: 0.403767] [G loss: 0.473910]\n",
      "[Epoch 75/100] [Batch 217/347] [D loss: 0.467180] [G loss: 0.497235]\n",
      "[Epoch 75/100] [Batch 218/347] [D loss: 0.521053] [G loss: 0.518209]\n",
      "[Epoch 75/100] [Batch 219/347] [D loss: 0.506498] [G loss: 0.530044]\n",
      "[Epoch 75/100] [Batch 220/347] [D loss: 0.508368] [G loss: 0.537834]\n",
      "[Epoch 75/100] [Batch 221/347] [D loss: 0.525599] [G loss: 0.540977]\n",
      "[Epoch 75/100] [Batch 222/347] [D loss: 0.529193] [G loss: 0.534692]\n",
      "[Epoch 75/100] [Batch 223/347] [D loss: 0.519459] [G loss: 0.517554]\n",
      "[Epoch 75/100] [Batch 224/347] [D loss: 0.524646] [G loss: 0.496616]\n",
      "[Epoch 75/100] [Batch 225/347] [D loss: 0.530554] [G loss: 0.478861]\n",
      "[Epoch 75/100] [Batch 226/347] [D loss: 0.534084] [G loss: 0.468519]\n",
      "[Epoch 75/100] [Batch 227/347] [D loss: 0.548018] [G loss: 0.469216]\n",
      "[Epoch 75/100] [Batch 228/347] [D loss: 0.555110] [G loss: 0.472603]\n",
      "[Epoch 75/100] [Batch 229/347] [D loss: 0.555826] [G loss: 0.476651]\n",
      "[Epoch 75/100] [Batch 230/347] [D loss: 0.558595] [G loss: 0.480850]\n",
      "[Epoch 75/100] [Batch 231/347] [D loss: 0.551031] [G loss: 0.476641]\n",
      "[Epoch 75/100] [Batch 232/347] [D loss: 0.544129] [G loss: 0.477121]\n",
      "[Epoch 75/100] [Batch 233/347] [D loss: 0.492646] [G loss: 0.481226]\n",
      "[Epoch 75/100] [Batch 234/347] [D loss: 0.466088] [G loss: 0.483012]\n",
      "[Epoch 75/100] [Batch 235/347] [D loss: 0.455432] [G loss: 0.489941]\n",
      "[Epoch 75/100] [Batch 236/347] [D loss: 0.452678] [G loss: 0.493475]\n",
      "[Epoch 75/100] [Batch 237/347] [D loss: 0.482322] [G loss: 0.492980]\n",
      "[Epoch 75/100] [Batch 238/347] [D loss: 0.551884] [G loss: 0.486816]\n",
      "[Epoch 75/100] [Batch 239/347] [D loss: 0.554135] [G loss: 0.478672]\n",
      "[Epoch 75/100] [Batch 240/347] [D loss: 0.554322] [G loss: 0.473609]\n",
      "[Epoch 75/100] [Batch 241/347] [D loss: 0.557125] [G loss: 0.473333]\n",
      "[Epoch 75/100] [Batch 242/347] [D loss: 0.564111] [G loss: 0.476586]\n",
      "[Epoch 75/100] [Batch 243/347] [D loss: 0.531294] [G loss: 0.478722]\n",
      "[Epoch 75/100] [Batch 244/347] [D loss: 0.503167] [G loss: 0.471088]\n",
      "[Epoch 75/100] [Batch 245/347] [D loss: 0.514001] [G loss: 0.459370]\n",
      "[Epoch 75/100] [Batch 246/347] [D loss: 0.506587] [G loss: 0.445789]\n",
      "[Epoch 75/100] [Batch 247/347] [D loss: 0.534827] [G loss: 0.436119]\n",
      "[Epoch 75/100] [Batch 248/347] [D loss: 0.549527] [G loss: 0.438757]\n",
      "[Epoch 75/100] [Batch 249/347] [D loss: 0.537732] [G loss: 0.444275]\n",
      "[Epoch 75/100] [Batch 250/347] [D loss: 0.532798] [G loss: 0.453751]\n",
      "[Epoch 75/100] [Batch 251/347] [D loss: 0.525922] [G loss: 0.467369]\n",
      "[Epoch 75/100] [Batch 252/347] [D loss: 0.520034] [G loss: 0.474400]\n",
      "[Epoch 75/100] [Batch 253/347] [D loss: 0.467417] [G loss: 0.468056]\n",
      "[Epoch 75/100] [Batch 254/347] [D loss: 0.470856] [G loss: 0.471077]\n",
      "[Epoch 75/100] [Batch 255/347] [D loss: 0.462375] [G loss: 0.469153]\n",
      "[Epoch 75/100] [Batch 256/347] [D loss: 0.468760] [G loss: 0.457797]\n",
      "[Epoch 75/100] [Batch 257/347] [D loss: 0.447347] [G loss: 0.445192]\n",
      "[Epoch 75/100] [Batch 258/347] [D loss: 0.407747] [G loss: 0.431223]\n",
      "[Epoch 75/100] [Batch 259/347] [D loss: 0.407690] [G loss: 0.418511]\n",
      "[Epoch 75/100] [Batch 260/347] [D loss: 0.406824] [G loss: 0.407170]\n",
      "[Epoch 75/100] [Batch 261/347] [D loss: 0.393649] [G loss: 0.400744]\n",
      "[Epoch 75/100] [Batch 262/347] [D loss: 0.343732] [G loss: 0.392803]\n",
      "[Epoch 75/100] [Batch 263/347] [D loss: 0.345123] [G loss: 0.386651]\n",
      "[Epoch 75/100] [Batch 264/347] [D loss: 0.345625] [G loss: 0.384567]\n",
      "[Epoch 75/100] [Batch 265/347] [D loss: 0.360640] [G loss: 0.383515]\n",
      "[Epoch 75/100] [Batch 266/347] [D loss: 0.427620] [G loss: 0.385498]\n",
      "[Epoch 75/100] [Batch 267/347] [D loss: 0.448006] [G loss: 0.387326]\n",
      "[Epoch 75/100] [Batch 268/347] [D loss: 0.455076] [G loss: 0.388606]\n",
      "[Epoch 75/100] [Batch 269/347] [D loss: 0.457570] [G loss: 0.389197]\n",
      "[Epoch 75/100] [Batch 270/347] [D loss: 0.489236] [G loss: 0.389653]\n",
      "[Epoch 75/100] [Batch 271/347] [D loss: 0.452346] [G loss: 0.397502]\n",
      "[Epoch 75/100] [Batch 272/347] [D loss: 0.443703] [G loss: 0.425579]\n",
      "[Epoch 75/100] [Batch 273/347] [D loss: 0.386386] [G loss: 0.458037]\n",
      "[Epoch 75/100] [Batch 274/347] [D loss: 0.327639] [G loss: 0.486702]\n",
      "[Epoch 75/100] [Batch 275/347] [D loss: 0.255353] [G loss: 0.510898]\n",
      "[Epoch 75/100] [Batch 276/347] [D loss: 0.501768] [G loss: 0.527258]\n",
      "[Epoch 75/100] [Batch 277/347] [D loss: 0.524429] [G loss: 0.541410]\n",
      "[Epoch 75/100] [Batch 278/347] [D loss: 0.527556] [G loss: 0.553187]\n",
      "[Epoch 75/100] [Batch 279/347] [D loss: 0.530959] [G loss: 0.555910]\n",
      "[Epoch 75/100] [Batch 280/347] [D loss: 0.533843] [G loss: 0.556630]\n",
      "[Epoch 75/100] [Batch 281/347] [D loss: 0.538447] [G loss: 0.557473]\n",
      "[Epoch 75/100] [Batch 282/347] [D loss: 0.539957] [G loss: 0.561054]\n",
      "[Epoch 75/100] [Batch 283/347] [D loss: 0.540902] [G loss: 0.562769]\n",
      "[Epoch 75/100] [Batch 284/347] [D loss: 0.541959] [G loss: 0.565359]\n",
      "[Epoch 75/100] [Batch 285/347] [D loss: 0.545522] [G loss: 0.566666]\n",
      "[Epoch 75/100] [Batch 286/347] [D loss: 0.544235] [G loss: 0.552942]\n",
      "[Epoch 75/100] [Batch 287/347] [D loss: 0.545105] [G loss: 0.550443]\n",
      "[Epoch 75/100] [Batch 288/347] [D loss: 0.545256] [G loss: 0.547974]\n",
      "[Epoch 75/100] [Batch 289/347] [D loss: 0.544292] [G loss: 0.543142]\n",
      "[Epoch 75/100] [Batch 290/347] [D loss: 0.544327] [G loss: 0.559377]\n",
      "[Epoch 75/100] [Batch 291/347] [D loss: 0.543376] [G loss: 0.566563]\n",
      "[Epoch 75/100] [Batch 292/347] [D loss: 0.541492] [G loss: 0.570683]\n",
      "[Epoch 75/100] [Batch 293/347] [D loss: 0.520526] [G loss: 0.576592]\n",
      "[Epoch 75/100] [Batch 294/347] [D loss: 0.520207] [G loss: 0.581073]\n",
      "[Epoch 75/100] [Batch 295/347] [D loss: 0.520187] [G loss: 0.580080]\n",
      "[Epoch 75/100] [Batch 296/347] [D loss: 0.519793] [G loss: 0.578788]\n",
      "[Epoch 75/100] [Batch 297/347] [D loss: 0.540615] [G loss: 0.583534]\n",
      "[Epoch 75/100] [Batch 298/347] [D loss: 0.543979] [G loss: 0.577129]\n",
      "[Epoch 75/100] [Batch 299/347] [D loss: 0.543622] [G loss: 0.572764]\n",
      "[Epoch 75/100] [Batch 300/347] [D loss: 0.542700] [G loss: 0.570912]\n",
      "[Epoch 75/100] [Batch 301/347] [D loss: 0.543126] [G loss: 0.554137]\n",
      "[Epoch 75/100] [Batch 302/347] [D loss: 0.543671] [G loss: 0.547250]\n",
      "[Epoch 75/100] [Batch 303/347] [D loss: 0.542911] [G loss: 0.536273]\n",
      "[Epoch 75/100] [Batch 304/347] [D loss: 0.526199] [G loss: 0.524425]\n",
      "[Epoch 75/100] [Batch 305/347] [D loss: 0.513124] [G loss: 0.517704]\n",
      "[Epoch 75/100] [Batch 306/347] [D loss: 0.511873] [G loss: 0.515588]\n",
      "[Epoch 75/100] [Batch 307/347] [D loss: 0.509844] [G loss: 0.520894]\n",
      "[Epoch 75/100] [Batch 308/347] [D loss: 0.517888] [G loss: 0.530060]\n",
      "[Epoch 75/100] [Batch 309/347] [D loss: 0.538556] [G loss: 0.544398]\n",
      "[Epoch 75/100] [Batch 310/347] [D loss: 0.548745] [G loss: 0.556498]\n",
      "[Epoch 75/100] [Batch 311/347] [D loss: 0.545020] [G loss: 0.553672]\n",
      "[Epoch 75/100] [Batch 312/347] [D loss: 0.537104] [G loss: 0.548252]\n",
      "[Epoch 75/100] [Batch 313/347] [D loss: 0.532627] [G loss: 0.538742]\n",
      "[Epoch 75/100] [Batch 314/347] [D loss: 0.531722] [G loss: 0.523568]\n",
      "[Epoch 75/100] [Batch 315/347] [D loss: 0.531364] [G loss: 0.512058]\n",
      "[Epoch 75/100] [Batch 316/347] [D loss: 0.533385] [G loss: 0.512789]\n",
      "[Epoch 75/100] [Batch 317/347] [D loss: 0.534915] [G loss: 0.516162]\n",
      "[Epoch 75/100] [Batch 318/347] [D loss: 0.535342] [G loss: 0.529288]\n",
      "[Epoch 75/100] [Batch 319/347] [D loss: 0.532232] [G loss: 0.541233]\n",
      "[Epoch 75/100] [Batch 320/347] [D loss: 0.530953] [G loss: 0.539123]\n",
      "[Epoch 75/100] [Batch 321/347] [D loss: 0.527869] [G loss: 0.531925]\n",
      "[Epoch 75/100] [Batch 322/347] [D loss: 0.528717] [G loss: 0.523670]\n",
      "[Epoch 75/100] [Batch 323/347] [D loss: 0.519459] [G loss: 0.514358]\n",
      "[Epoch 75/100] [Batch 324/347] [D loss: 0.517554] [G loss: 0.507967]\n",
      "[Epoch 75/100] [Batch 325/347] [D loss: 0.517207] [G loss: 0.500298]\n",
      "[Epoch 75/100] [Batch 326/347] [D loss: 0.516525] [G loss: 0.491851]\n",
      "[Epoch 75/100] [Batch 327/347] [D loss: 0.513271] [G loss: 0.486888]\n",
      "[Epoch 75/100] [Batch 328/347] [D loss: 0.513150] [G loss: 0.481010]\n",
      "[Epoch 75/100] [Batch 329/347] [D loss: 0.511741] [G loss: 0.478295]\n",
      "[Epoch 75/100] [Batch 330/347] [D loss: 0.510126] [G loss: 0.477133]\n",
      "[Epoch 75/100] [Batch 331/347] [D loss: 0.512563] [G loss: 0.480660]\n",
      "[Epoch 75/100] [Batch 332/347] [D loss: 0.523582] [G loss: 0.499047]\n",
      "[Epoch 75/100] [Batch 333/347] [D loss: 0.517676] [G loss: 0.495671]\n",
      "[Epoch 75/100] [Batch 334/347] [D loss: 0.515697] [G loss: 0.487208]\n",
      "[Epoch 75/100] [Batch 335/347] [D loss: 0.514801] [G loss: 0.483449]\n",
      "[Epoch 75/100] [Batch 336/347] [D loss: 0.514013] [G loss: 0.480168]\n",
      "[Epoch 75/100] [Batch 337/347] [D loss: 0.519972] [G loss: 0.482516]\n",
      "[Epoch 75/100] [Batch 338/347] [D loss: 0.524875] [G loss: 0.488900]\n",
      "[Epoch 75/100] [Batch 339/347] [D loss: 0.520639] [G loss: 0.487470]\n",
      "[Epoch 75/100] [Batch 340/347] [D loss: 0.514851] [G loss: 0.482145]\n",
      "[Epoch 75/100] [Batch 341/347] [D loss: 0.515701] [G loss: 0.480463]\n",
      "[Epoch 75/100] [Batch 342/347] [D loss: 0.489815] [G loss: 0.466339]\n",
      "[Epoch 75/100] [Batch 343/347] [D loss: 0.482123] [G loss: 0.448845]\n",
      "[Epoch 75/100] [Batch 344/347] [D loss: 0.437772] [G loss: 0.441244]\n",
      "[Epoch 75/100] [Batch 345/347] [D loss: 0.330148] [G loss: 0.436188]\n",
      "[Epoch 75/100] [Batch 346/347] [D loss: 0.315097] [G loss: 0.432172]\n",
      "[Epoch 75/100] [Batch 347/347] [D loss: 0.295132] [G loss: 0.428077]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 1/347] [D loss: 0.502578] [G loss: 0.437564]\n",
      "[Epoch 76/100] [Batch 2/347] [D loss: 0.505414] [G loss: 0.433183]\n",
      "[Epoch 76/100] [Batch 3/347] [D loss: 0.512930] [G loss: 0.432664]\n",
      "[Epoch 76/100] [Batch 4/347] [D loss: 0.513055] [G loss: 0.428370]\n",
      "[Epoch 76/100] [Batch 5/347] [D loss: 0.512329] [G loss: 0.420224]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 6/347] [D loss: 0.500040] [G loss: 0.412493]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 7/347] [D loss: 0.483338] [G loss: 0.398916]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 8/347] [D loss: 0.479637] [G loss: 0.391618]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 9/347] [D loss: 0.470699] [G loss: 0.385699]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 10/347] [D loss: 0.468196] [G loss: 0.378441]\n",
      "[Epoch 76/100] [Batch 11/347] [D loss: 0.490742] [G loss: 0.378012]\n",
      "[Epoch 76/100] [Batch 12/347] [D loss: 0.499201] [G loss: 0.370747]\n",
      "[Epoch 76/100] [Batch 13/347] [D loss: 0.475829] [G loss: 0.359236]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 14/347] [D loss: 0.452493] [G loss: 0.347048]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 15/347] [D loss: 0.448851] [G loss: 0.326139]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 16/347] [D loss: 0.439701] [G loss: 0.308712]\n",
      "[Epoch 76/100] [Batch 17/347] [D loss: 0.443370] [G loss: 0.300465]\n",
      "[Epoch 76/100] [Batch 18/347] [D loss: 0.454710] [G loss: 0.291258]\n",
      "[Epoch 76/100] [Batch 19/347] [D loss: 0.454821] [G loss: 0.287823]\n",
      "[Epoch 76/100] [Batch 20/347] [D loss: 0.479296] [G loss: 0.285821]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 21/347] [D loss: 0.419015] [G loss: 0.277047]\n",
      "[Epoch 76/100] [Batch 22/347] [D loss: 0.421271] [G loss: 0.273253]\n",
      "[Epoch 76/100] [Batch 23/347] [D loss: 0.423974] [G loss: 0.270835]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 76/100] [Batch 24/347] [D loss: 0.391347] [G loss: 0.266713]\n",
      "[Epoch 76/100] [Batch 25/347] [D loss: 0.319969] [G loss: 0.281876]\n",
      "[Epoch 76/100] [Batch 26/347] [D loss: 0.310905] [G loss: 0.295639]\n",
      "[Epoch 76/100] [Batch 27/347] [D loss: 0.302228] [G loss: 0.314570]\n",
      "[Epoch 76/100] [Batch 28/347] [D loss: 0.295744] [G loss: 0.336725]\n",
      "[Epoch 76/100] [Batch 29/347] [D loss: 0.308847] [G loss: 0.356695]\n",
      "[Epoch 76/100] [Batch 30/347] [D loss: 0.299628] [G loss: 0.369935]\n",
      "[Epoch 76/100] [Batch 31/347] [D loss: 0.299870] [G loss: 0.379178]\n",
      "[Epoch 76/100] [Batch 32/347] [D loss: 0.311726] [G loss: 0.382446]\n",
      "[Epoch 76/100] [Batch 33/347] [D loss: 0.330867] [G loss: 0.384349]\n",
      "[Epoch 76/100] [Batch 34/347] [D loss: 0.375543] [G loss: 0.381809]\n",
      "[Epoch 76/100] [Batch 35/347] [D loss: 0.376405] [G loss: 0.373052]\n",
      "[Epoch 76/100] [Batch 36/347] [D loss: 0.401983] [G loss: 0.364013]\n",
      "[Epoch 76/100] [Batch 37/347] [D loss: 0.407877] [G loss: 0.351468]\n",
      "[Epoch 76/100] [Batch 38/347] [D loss: 0.404964] [G loss: 0.335897]\n",
      "[Epoch 76/100] [Batch 39/347] [D loss: 0.411497] [G loss: 0.327560]\n",
      "[Epoch 76/100] [Batch 40/347] [D loss: 0.436483] [G loss: 0.322662]\n",
      "[Epoch 76/100] [Batch 41/347] [D loss: 0.455397] [G loss: 0.315030]\n",
      "[Epoch 76/100] [Batch 42/347] [D loss: 0.449651] [G loss: 0.312643]\n",
      "[Epoch 76/100] [Batch 43/347] [D loss: 0.473439] [G loss: 0.316403]\n",
      "[Epoch 76/100] [Batch 44/347] [D loss: 0.458338] [G loss: 0.312885]\n",
      "[Epoch 76/100] [Batch 45/347] [D loss: 0.432948] [G loss: 0.298065]\n",
      "[Epoch 76/100] [Batch 46/347] [D loss: 0.361985] [G loss: 0.286103]\n",
      "[Epoch 76/100] [Batch 47/347] [D loss: 0.359741] [G loss: 0.279899]\n",
      "[Epoch 76/100] [Batch 48/347] [D loss: 0.305613] [G loss: 0.290291]\n",
      "[Epoch 76/100] [Batch 49/347] [D loss: 0.287166] [G loss: 0.312732]\n",
      "[Epoch 76/100] [Batch 50/347] [D loss: 0.271666] [G loss: 0.341440]\n",
      "[Epoch 76/100] [Batch 51/347] [D loss: 0.246387] [G loss: 0.365805]\n",
      "[Epoch 76/100] [Batch 52/347] [D loss: 0.315974] [G loss: 0.378408]\n",
      "[Epoch 76/100] [Batch 53/347] [D loss: 0.348895] [G loss: 0.377951]\n",
      "[Epoch 76/100] [Batch 54/347] [D loss: 0.335216] [G loss: 0.374511]\n",
      "[Epoch 76/100] [Batch 55/347] [D loss: 0.334083] [G loss: 0.381948]\n",
      "[Epoch 76/100] [Batch 56/347] [D loss: 0.329597] [G loss: 0.391709]\n",
      "[Epoch 76/100] [Batch 57/347] [D loss: 0.286067] [G loss: 0.400197]\n",
      "[Epoch 76/100] [Batch 58/347] [D loss: 0.296539] [G loss: 0.404149]\n",
      "[Epoch 76/100] [Batch 59/347] [D loss: 0.294433] [G loss: 0.398687]\n",
      "[Epoch 76/100] [Batch 60/347] [D loss: 0.278019] [G loss: 0.384259]\n",
      "[Epoch 76/100] [Batch 61/347] [D loss: 0.292509] [G loss: 0.367467]\n",
      "[Epoch 76/100] [Batch 62/347] [D loss: 0.291217] [G loss: 0.363780]\n",
      "[Epoch 76/100] [Batch 63/347] [D loss: 0.283050] [G loss: 0.360958]\n",
      "[Epoch 76/100] [Batch 64/347] [D loss: 0.264696] [G loss: 0.354998]\n",
      "[Epoch 76/100] [Batch 65/347] [D loss: 0.224873] [G loss: 0.356582]\n",
      "[Epoch 76/100] [Batch 66/347] [D loss: 0.228071] [G loss: 0.354536]\n",
      "[Epoch 76/100] [Batch 67/347] [D loss: 0.228048] [G loss: 0.343888]\n",
      "[Epoch 76/100] [Batch 68/347] [D loss: 0.228321] [G loss: 0.342196]\n",
      "[Epoch 76/100] [Batch 69/347] [D loss: 0.240703] [G loss: 0.342575]\n",
      "[Epoch 76/100] [Batch 70/347] [D loss: 0.236424] [G loss: 0.342493]\n",
      "[Epoch 76/100] [Batch 71/347] [D loss: 0.234893] [G loss: 0.359018]\n",
      "[Epoch 76/100] [Batch 72/347] [D loss: 0.240402] [G loss: 0.373989]\n",
      "[Epoch 76/100] [Batch 73/347] [D loss: 0.339253] [G loss: 0.372751]\n",
      "[Epoch 76/100] [Batch 74/347] [D loss: 0.341414] [G loss: 0.375254]\n",
      "[Epoch 76/100] [Batch 75/347] [D loss: 0.340151] [G loss: 0.375765]\n",
      "[Epoch 76/100] [Batch 76/347] [D loss: 0.339170] [G loss: 0.374158]\n",
      "[Epoch 76/100] [Batch 77/347] [D loss: 0.378809] [G loss: 0.374521]\n",
      "[Epoch 76/100] [Batch 78/347] [D loss: 0.432503] [G loss: 0.382405]\n",
      "[Epoch 76/100] [Batch 79/347] [D loss: 0.427595] [G loss: 0.380276]\n",
      "[Epoch 76/100] [Batch 80/347] [D loss: 0.323936] [G loss: 0.363539]\n",
      "[Epoch 76/100] [Batch 81/347] [D loss: 0.306045] [G loss: 0.355961]\n",
      "[Epoch 76/100] [Batch 82/347] [D loss: 0.305223] [G loss: 0.351877]\n",
      "[Epoch 76/100] [Batch 83/347] [D loss: 0.311145] [G loss: 0.346324]\n",
      "[Epoch 76/100] [Batch 84/347] [D loss: 0.434160] [G loss: 0.345728]\n",
      "[Epoch 76/100] [Batch 85/347] [D loss: 0.508410] [G loss: 0.342394]\n",
      "[Epoch 76/100] [Batch 86/347] [D loss: 0.509985] [G loss: 0.338092]\n",
      "[Epoch 76/100] [Batch 87/347] [D loss: 0.510431] [G loss: 0.335717]\n",
      "[Epoch 76/100] [Batch 88/347] [D loss: 0.532113] [G loss: 0.333519]\n",
      "[Epoch 76/100] [Batch 89/347] [D loss: 0.542241] [G loss: 0.333162]\n",
      "[Epoch 76/100] [Batch 90/347] [D loss: 0.540708] [G loss: 0.331335]\n",
      "[Epoch 76/100] [Batch 91/347] [D loss: 0.541828] [G loss: 0.329847]\n",
      "[Epoch 76/100] [Batch 92/347] [D loss: 0.544058] [G loss: 0.330860]\n",
      "[Epoch 76/100] [Batch 93/347] [D loss: 0.544658] [G loss: 0.332223]\n",
      "[Epoch 76/100] [Batch 94/347] [D loss: 0.527146] [G loss: 0.330087]\n",
      "[Epoch 76/100] [Batch 95/347] [D loss: 0.517381] [G loss: 0.331389]\n",
      "[Epoch 76/100] [Batch 96/347] [D loss: 0.518134] [G loss: 0.334914]\n",
      "[Epoch 76/100] [Batch 97/347] [D loss: 0.511908] [G loss: 0.336558]\n",
      "[Epoch 76/100] [Batch 98/347] [D loss: 0.497439] [G loss: 0.340489]\n",
      "[Epoch 76/100] [Batch 99/347] [D loss: 0.503541] [G loss: 0.343595]\n",
      "[Epoch 76/100] [Batch 100/347] [D loss: 0.505445] [G loss: 0.345761]\n",
      "[Epoch 76/100] [Batch 101/347] [D loss: 0.513114] [G loss: 0.346666]\n",
      "[Epoch 76/100] [Batch 102/347] [D loss: 0.556997] [G loss: 0.348335]\n",
      "[Epoch 76/100] [Batch 103/347] [D loss: 0.563409] [G loss: 0.354813]\n",
      "[Epoch 76/100] [Batch 104/347] [D loss: 0.537906] [G loss: 0.355009]\n",
      "[Epoch 76/100] [Batch 105/347] [D loss: 0.453678] [G loss: 0.356399]\n",
      "[Epoch 76/100] [Batch 106/347] [D loss: 0.263722] [G loss: 0.362920]\n",
      "[Epoch 76/100] [Batch 107/347] [D loss: 0.242422] [G loss: 0.384199]\n",
      "[Epoch 76/100] [Batch 108/347] [D loss: 0.226871] [G loss: 0.407357]\n",
      "[Epoch 76/100] [Batch 109/347] [D loss: 0.201506] [G loss: 0.432198]\n",
      "[Epoch 76/100] [Batch 110/347] [D loss: 0.215201] [G loss: 0.448771]\n",
      "[Epoch 76/100] [Batch 111/347] [D loss: 0.218302] [G loss: 0.466248]\n",
      "[Epoch 76/100] [Batch 112/347] [D loss: 0.222917] [G loss: 0.479521]\n",
      "[Epoch 76/100] [Batch 113/347] [D loss: 0.420635] [G loss: 0.504146]\n",
      "[Epoch 76/100] [Batch 114/347] [D loss: 0.499786] [G loss: 0.514959]\n",
      "[Epoch 76/100] [Batch 115/347] [D loss: 0.503348] [G loss: 0.501089]\n",
      "[Epoch 76/100] [Batch 116/347] [D loss: 0.463673] [G loss: 0.485171]\n",
      "[Epoch 76/100] [Batch 117/347] [D loss: 0.463700] [G loss: 0.473295]\n",
      "[Epoch 76/100] [Batch 118/347] [D loss: 0.406024] [G loss: 0.458327]\n",
      "[Epoch 76/100] [Batch 119/347] [D loss: 0.396193] [G loss: 0.453487]\n",
      "[Epoch 76/100] [Batch 120/347] [D loss: 0.375233] [G loss: 0.452319]\n",
      "[Epoch 76/100] [Batch 121/347] [D loss: 0.354954] [G loss: 0.441274]\n",
      "[Epoch 76/100] [Batch 122/347] [D loss: 0.454914] [G loss: 0.431030]\n",
      "[Epoch 76/100] [Batch 123/347] [D loss: 0.499939] [G loss: 0.418933]\n",
      "[Epoch 76/100] [Batch 124/347] [D loss: 0.418900] [G loss: 0.399659]\n",
      "[Epoch 76/100] [Batch 125/347] [D loss: 0.379816] [G loss: 0.384060]\n",
      "[Epoch 76/100] [Batch 126/347] [D loss: 0.342284] [G loss: 0.369047]\n",
      "[Epoch 76/100] [Batch 127/347] [D loss: 0.349127] [G loss: 0.353810]\n",
      "[Epoch 76/100] [Batch 128/347] [D loss: 0.341647] [G loss: 0.336638]\n",
      "[Epoch 76/100] [Batch 129/347] [D loss: 0.318924] [G loss: 0.327887]\n",
      "[Epoch 76/100] [Batch 130/347] [D loss: 0.307187] [G loss: 0.345101]\n",
      "[Epoch 76/100] [Batch 131/347] [D loss: 0.293620] [G loss: 0.363944]\n",
      "[Epoch 76/100] [Batch 132/347] [D loss: 0.266907] [G loss: 0.395650]\n",
      "[Epoch 76/100] [Batch 133/347] [D loss: 0.254849] [G loss: 0.430999]\n",
      "[Epoch 76/100] [Batch 134/347] [D loss: 0.213125] [G loss: 0.461651]\n",
      "[Epoch 76/100] [Batch 135/347] [D loss: 0.178650] [G loss: 0.482709]\n",
      "[Epoch 76/100] [Batch 136/347] [D loss: 0.160599] [G loss: 0.491028]\n",
      "[Epoch 76/100] [Batch 137/347] [D loss: 0.372246] [G loss: 0.492646]\n",
      "[Epoch 76/100] [Batch 138/347] [D loss: 0.411051] [G loss: 0.489725]\n",
      "[Epoch 76/100] [Batch 139/347] [D loss: 0.424894] [G loss: 0.481908]\n",
      "[Epoch 76/100] [Batch 140/347] [D loss: 0.442321] [G loss: 0.481901]\n",
      "[Epoch 76/100] [Batch 141/347] [D loss: 0.401384] [G loss: 0.475913]\n",
      "[Epoch 76/100] [Batch 142/347] [D loss: 0.409723] [G loss: 0.469024]\n",
      "[Epoch 76/100] [Batch 143/347] [D loss: 0.406854] [G loss: 0.458774]\n",
      "[Epoch 76/100] [Batch 144/347] [D loss: 0.390793] [G loss: 0.447966]\n",
      "[Epoch 76/100] [Batch 145/347] [D loss: 0.419672] [G loss: 0.444761]\n",
      "[Epoch 76/100] [Batch 146/347] [D loss: 0.427031] [G loss: 0.435039]\n",
      "[Epoch 76/100] [Batch 147/347] [D loss: 0.447987] [G loss: 0.424238]\n",
      "[Epoch 76/100] [Batch 148/347] [D loss: 0.454976] [G loss: 0.413516]\n",
      "[Epoch 76/100] [Batch 149/347] [D loss: 0.382219] [G loss: 0.395022]\n",
      "[Epoch 76/100] [Batch 150/347] [D loss: 0.345390] [G loss: 0.370730]\n",
      "[Epoch 76/100] [Batch 151/347] [D loss: 0.325916] [G loss: 0.342079]\n",
      "[Epoch 76/100] [Batch 152/347] [D loss: 0.315312] [G loss: 0.312015]\n",
      "[Epoch 76/100] [Batch 153/347] [D loss: 0.326706] [G loss: 0.285518]\n",
      "[Epoch 76/100] [Batch 154/347] [D loss: 0.333794] [G loss: 0.272083]\n",
      "[Epoch 76/100] [Batch 155/347] [D loss: 0.336834] [G loss: 0.271030]\n",
      "[Epoch 76/100] [Batch 156/347] [D loss: 0.337442] [G loss: 0.271446]\n",
      "[Epoch 76/100] [Batch 157/347] [D loss: 0.327048] [G loss: 0.281190]\n",
      "[Epoch 76/100] [Batch 158/347] [D loss: 0.307745] [G loss: 0.301358]\n",
      "[Epoch 76/100] [Batch 159/347] [D loss: 0.307634] [G loss: 0.322056]\n",
      "[Epoch 76/100] [Batch 160/347] [D loss: 0.283295] [G loss: 0.353429]\n",
      "[Epoch 76/100] [Batch 161/347] [D loss: 0.264170] [G loss: 0.380338]\n",
      "[Epoch 76/100] [Batch 162/347] [D loss: 0.248876] [G loss: 0.396167]\n",
      "[Epoch 76/100] [Batch 163/347] [D loss: 0.245430] [G loss: 0.403076]\n",
      "[Epoch 76/100] [Batch 164/347] [D loss: 0.247128] [G loss: 0.416950]\n",
      "[Epoch 76/100] [Batch 165/347] [D loss: 0.249832] [G loss: 0.432221]\n",
      "[Epoch 76/100] [Batch 166/347] [D loss: 0.259213] [G loss: 0.443248]\n",
      "[Epoch 76/100] [Batch 167/347] [D loss: 0.290161] [G loss: 0.464492]\n",
      "[Epoch 76/100] [Batch 168/347] [D loss: 0.292043] [G loss: 0.474577]\n",
      "[Epoch 76/100] [Batch 169/347] [D loss: 0.436353] [G loss: 0.482597]\n",
      "[Epoch 76/100] [Batch 170/347] [D loss: 0.512571] [G loss: 0.487617]\n",
      "[Epoch 76/100] [Batch 171/347] [D loss: 0.514372] [G loss: 0.485374]\n",
      "[Epoch 76/100] [Batch 172/347] [D loss: 0.513579] [G loss: 0.483833]\n",
      "[Epoch 76/100] [Batch 173/347] [D loss: 0.513849] [G loss: 0.479209]\n",
      "[Epoch 76/100] [Batch 174/347] [D loss: 0.506930] [G loss: 0.478905]\n",
      "[Epoch 76/100] [Batch 175/347] [D loss: 0.529599] [G loss: 0.478885]\n",
      "[Epoch 76/100] [Batch 176/347] [D loss: 0.550277] [G loss: 0.477789]\n",
      "[Epoch 76/100] [Batch 177/347] [D loss: 0.549602] [G loss: 0.471277]\n",
      "[Epoch 76/100] [Batch 178/347] [D loss: 0.547822] [G loss: 0.461945]\n",
      "[Epoch 76/100] [Batch 179/347] [D loss: 0.545124] [G loss: 0.455792]\n",
      "[Epoch 76/100] [Batch 180/347] [D loss: 0.543755] [G loss: 0.449118]\n",
      "[Epoch 76/100] [Batch 181/347] [D loss: 0.541847] [G loss: 0.449833]\n",
      "[Epoch 76/100] [Batch 182/347] [D loss: 0.544878] [G loss: 0.448371]\n",
      "[Epoch 76/100] [Batch 183/347] [D loss: 0.545026] [G loss: 0.448062]\n",
      "[Epoch 76/100] [Batch 184/347] [D loss: 0.559945] [G loss: 0.449358]\n",
      "[Epoch 76/100] [Batch 185/347] [D loss: 0.560817] [G loss: 0.447100]\n",
      "[Epoch 76/100] [Batch 186/347] [D loss: 0.554121] [G loss: 0.447104]\n",
      "[Epoch 76/100] [Batch 187/347] [D loss: 0.547709] [G loss: 0.445054]\n",
      "[Epoch 76/100] [Batch 188/347] [D loss: 0.519903] [G loss: 0.437838]\n",
      "[Epoch 76/100] [Batch 189/347] [D loss: 0.475230] [G loss: 0.429224]\n",
      "[Epoch 76/100] [Batch 190/347] [D loss: 0.467149] [G loss: 0.422814]\n",
      "[Epoch 76/100] [Batch 191/347] [D loss: 0.466507] [G loss: 0.414446]\n",
      "[Epoch 76/100] [Batch 192/347] [D loss: 0.473546] [G loss: 0.406748]\n",
      "[Epoch 76/100] [Batch 193/347] [D loss: 0.529854] [G loss: 0.400036]\n",
      "[Epoch 76/100] [Batch 194/347] [D loss: 0.527772] [G loss: 0.389727]\n",
      "[Epoch 76/100] [Batch 195/347] [D loss: 0.505957] [G loss: 0.380502]\n",
      "[Epoch 76/100] [Batch 196/347] [D loss: 0.464421] [G loss: 0.371438]\n",
      "[Epoch 76/100] [Batch 197/347] [D loss: 0.462530] [G loss: 0.363971]\n",
      "[Epoch 76/100] [Batch 198/347] [D loss: 0.462406] [G loss: 0.360224]\n",
      "[Epoch 76/100] [Batch 199/347] [D loss: 0.459172] [G loss: 0.355327]\n",
      "[Epoch 76/100] [Batch 200/347] [D loss: 0.511659] [G loss: 0.351776]\n",
      "[Epoch 76/100] [Batch 201/347] [D loss: 0.544620] [G loss: 0.348787]\n",
      "[Epoch 76/100] [Batch 202/347] [D loss: 0.548708] [G loss: 0.348157]\n",
      "[Epoch 76/100] [Batch 203/347] [D loss: 0.588444] [G loss: 0.348281]\n",
      "[Epoch 76/100] [Batch 204/347] [D loss: 0.581630] [G loss: 0.355201]\n",
      "[Epoch 76/100] [Batch 205/347] [D loss: 0.581213] [G loss: 0.365024]\n",
      "[Epoch 76/100] [Batch 206/347] [D loss: 0.577748] [G loss: 0.374493]\n",
      "[Epoch 76/100] [Batch 207/347] [D loss: 0.517309] [G loss: 0.382378]\n",
      "[Epoch 76/100] [Batch 208/347] [D loss: 0.503915] [G loss: 0.392586]\n",
      "[Epoch 76/100] [Batch 209/347] [D loss: 0.493828] [G loss: 0.394392]\n",
      "[Epoch 76/100] [Batch 210/347] [D loss: 0.401208] [G loss: 0.399206]\n",
      "[Epoch 76/100] [Batch 211/347] [D loss: 0.356666] [G loss: 0.399847]\n",
      "[Epoch 76/100] [Batch 212/347] [D loss: 0.240926] [G loss: 0.396056]\n",
      "[Epoch 76/100] [Batch 213/347] [D loss: 0.233047] [G loss: 0.409538]\n",
      "[Epoch 76/100] [Batch 214/347] [D loss: 0.223647] [G loss: 0.425094]\n",
      "[Epoch 76/100] [Batch 215/347] [D loss: 0.218080] [G loss: 0.441682]\n",
      "[Epoch 76/100] [Batch 216/347] [D loss: 0.403677] [G loss: 0.470215]\n",
      "[Epoch 76/100] [Batch 217/347] [D loss: 0.461830] [G loss: 0.492871]\n",
      "[Epoch 76/100] [Batch 218/347] [D loss: 0.514469] [G loss: 0.514058]\n",
      "[Epoch 76/100] [Batch 219/347] [D loss: 0.499602] [G loss: 0.525200]\n",
      "[Epoch 76/100] [Batch 220/347] [D loss: 0.501374] [G loss: 0.532460]\n",
      "[Epoch 76/100] [Batch 221/347] [D loss: 0.518647] [G loss: 0.535330]\n",
      "[Epoch 76/100] [Batch 222/347] [D loss: 0.521372] [G loss: 0.528809]\n",
      "[Epoch 76/100] [Batch 223/347] [D loss: 0.512377] [G loss: 0.511704]\n",
      "[Epoch 76/100] [Batch 224/347] [D loss: 0.517600] [G loss: 0.490772]\n",
      "[Epoch 76/100] [Batch 225/347] [D loss: 0.522996] [G loss: 0.472807]\n",
      "[Epoch 76/100] [Batch 226/347] [D loss: 0.526671] [G loss: 0.462174]\n",
      "[Epoch 76/100] [Batch 227/347] [D loss: 0.541111] [G loss: 0.462653]\n",
      "[Epoch 76/100] [Batch 228/347] [D loss: 0.548035] [G loss: 0.465555]\n",
      "[Epoch 76/100] [Batch 229/347] [D loss: 0.548413] [G loss: 0.469285]\n",
      "[Epoch 76/100] [Batch 230/347] [D loss: 0.551192] [G loss: 0.472387]\n",
      "[Epoch 76/100] [Batch 231/347] [D loss: 0.543426] [G loss: 0.468073]\n",
      "[Epoch 76/100] [Batch 232/347] [D loss: 0.536124] [G loss: 0.468137]\n",
      "[Epoch 76/100] [Batch 233/347] [D loss: 0.482900] [G loss: 0.471873]\n",
      "[Epoch 76/100] [Batch 234/347] [D loss: 0.457325] [G loss: 0.473114]\n",
      "[Epoch 76/100] [Batch 235/347] [D loss: 0.446466] [G loss: 0.479191]\n",
      "[Epoch 76/100] [Batch 236/347] [D loss: 0.442860] [G loss: 0.482732]\n",
      "[Epoch 76/100] [Batch 237/347] [D loss: 0.476347] [G loss: 0.481603]\n",
      "[Epoch 76/100] [Batch 238/347] [D loss: 0.542991] [G loss: 0.474900]\n",
      "[Epoch 76/100] [Batch 239/347] [D loss: 0.546072] [G loss: 0.466555]\n",
      "[Epoch 76/100] [Batch 240/347] [D loss: 0.545817] [G loss: 0.461814]\n",
      "[Epoch 76/100] [Batch 241/347] [D loss: 0.549057] [G loss: 0.460854]\n",
      "[Epoch 76/100] [Batch 242/347] [D loss: 0.556700] [G loss: 0.463379]\n",
      "[Epoch 76/100] [Batch 243/347] [D loss: 0.522970] [G loss: 0.465995]\n",
      "[Epoch 76/100] [Batch 244/347] [D loss: 0.493224] [G loss: 0.458309]\n",
      "[Epoch 76/100] [Batch 245/347] [D loss: 0.503923] [G loss: 0.447082]\n",
      "[Epoch 76/100] [Batch 246/347] [D loss: 0.496631] [G loss: 0.433731]\n",
      "[Epoch 76/100] [Batch 247/347] [D loss: 0.526104] [G loss: 0.424501]\n",
      "[Epoch 76/100] [Batch 248/347] [D loss: 0.541781] [G loss: 0.427201]\n",
      "[Epoch 76/100] [Batch 249/347] [D loss: 0.529138] [G loss: 0.433290]\n",
      "[Epoch 76/100] [Batch 250/347] [D loss: 0.523808] [G loss: 0.442637]\n",
      "[Epoch 76/100] [Batch 251/347] [D loss: 0.516145] [G loss: 0.455687]\n",
      "[Epoch 76/100] [Batch 252/347] [D loss: 0.510125] [G loss: 0.462816]\n",
      "[Epoch 76/100] [Batch 253/347] [D loss: 0.458108] [G loss: 0.456317]\n",
      "[Epoch 76/100] [Batch 254/347] [D loss: 0.461290] [G loss: 0.459695]\n",
      "[Epoch 76/100] [Batch 255/347] [D loss: 0.453597] [G loss: 0.458250]\n",
      "[Epoch 76/100] [Batch 256/347] [D loss: 0.459843] [G loss: 0.447297]\n",
      "[Epoch 76/100] [Batch 257/347] [D loss: 0.438699] [G loss: 0.435281]\n",
      "[Epoch 76/100] [Batch 258/347] [D loss: 0.399181] [G loss: 0.424678]\n",
      "[Epoch 76/100] [Batch 259/347] [D loss: 0.399999] [G loss: 0.414062]\n",
      "[Epoch 76/100] [Batch 260/347] [D loss: 0.400000] [G loss: 0.404400]\n",
      "[Epoch 76/100] [Batch 261/347] [D loss: 0.388570] [G loss: 0.400697]\n",
      "[Epoch 76/100] [Batch 262/347] [D loss: 0.341627] [G loss: 0.395165]\n",
      "[Epoch 76/100] [Batch 263/347] [D loss: 0.342617] [G loss: 0.390393]\n",
      "[Epoch 76/100] [Batch 264/347] [D loss: 0.342620] [G loss: 0.389615]\n",
      "[Epoch 76/100] [Batch 265/347] [D loss: 0.356154] [G loss: 0.390853]\n",
      "[Epoch 76/100] [Batch 266/347] [D loss: 0.420797] [G loss: 0.393784]\n",
      "[Epoch 76/100] [Batch 267/347] [D loss: 0.439679] [G loss: 0.396339]\n",
      "[Epoch 76/100] [Batch 268/347] [D loss: 0.446528] [G loss: 0.398485]\n",
      "[Epoch 76/100] [Batch 269/347] [D loss: 0.448207] [G loss: 0.400378]\n",
      "[Epoch 76/100] [Batch 270/347] [D loss: 0.478242] [G loss: 0.401089]\n",
      "[Epoch 76/100] [Batch 271/347] [D loss: 0.439895] [G loss: 0.407898]\n",
      "[Epoch 76/100] [Batch 272/347] [D loss: 0.411222] [G loss: 0.432560]\n",
      "[Epoch 76/100] [Batch 273/347] [D loss: 0.364876] [G loss: 0.458587]\n",
      "[Epoch 76/100] [Batch 274/347] [D loss: 0.321696] [G loss: 0.482279]\n",
      "[Epoch 76/100] [Batch 275/347] [D loss: 0.260931] [G loss: 0.501727]\n",
      "[Epoch 76/100] [Batch 276/347] [D loss: 0.490897] [G loss: 0.511736]\n",
      "[Epoch 76/100] [Batch 277/347] [D loss: 0.514727] [G loss: 0.525034]\n",
      "[Epoch 76/100] [Batch 278/347] [D loss: 0.517923] [G loss: 0.536192]\n",
      "[Epoch 76/100] [Batch 279/347] [D loss: 0.521752] [G loss: 0.538860]\n",
      "[Epoch 76/100] [Batch 280/347] [D loss: 0.524688] [G loss: 0.539608]\n",
      "[Epoch 76/100] [Batch 281/347] [D loss: 0.529585] [G loss: 0.540618]\n",
      "[Epoch 76/100] [Batch 282/347] [D loss: 0.530801] [G loss: 0.544231]\n",
      "[Epoch 76/100] [Batch 283/347] [D loss: 0.531680] [G loss: 0.545922]\n",
      "[Epoch 76/100] [Batch 284/347] [D loss: 0.532567] [G loss: 0.548586]\n",
      "[Epoch 76/100] [Batch 285/347] [D loss: 0.537174] [G loss: 0.549853]\n",
      "[Epoch 76/100] [Batch 286/347] [D loss: 0.535220] [G loss: 0.536155]\n",
      "[Epoch 76/100] [Batch 287/347] [D loss: 0.536055] [G loss: 0.533769]\n",
      "[Epoch 76/100] [Batch 288/347] [D loss: 0.536276] [G loss: 0.531219]\n",
      "[Epoch 76/100] [Batch 289/347] [D loss: 0.534420] [G loss: 0.526433]\n",
      "[Epoch 76/100] [Batch 290/347] [D loss: 0.534184] [G loss: 0.542523]\n",
      "[Epoch 76/100] [Batch 291/347] [D loss: 0.532707] [G loss: 0.549584]\n",
      "[Epoch 76/100] [Batch 292/347] [D loss: 0.530059] [G loss: 0.553499]\n",
      "[Epoch 76/100] [Batch 293/347] [D loss: 0.502658] [G loss: 0.559131]\n",
      "[Epoch 76/100] [Batch 294/347] [D loss: 0.502008] [G loss: 0.563561]\n",
      "[Epoch 76/100] [Batch 295/347] [D loss: 0.501807] [G loss: 0.562477]\n",
      "[Epoch 76/100] [Batch 296/347] [D loss: 0.501279] [G loss: 0.560975]\n",
      "[Epoch 76/100] [Batch 297/347] [D loss: 0.529348] [G loss: 0.565525]\n",
      "[Epoch 76/100] [Batch 298/347] [D loss: 0.532972] [G loss: 0.558957]\n",
      "[Epoch 76/100] [Batch 299/347] [D loss: 0.532545] [G loss: 0.554321]\n",
      "[Epoch 76/100] [Batch 300/347] [D loss: 0.531324] [G loss: 0.552034]\n",
      "[Epoch 76/100] [Batch 301/347] [D loss: 0.531884] [G loss: 0.534958]\n",
      "[Epoch 76/100] [Batch 302/347] [D loss: 0.532661] [G loss: 0.527708]\n",
      "[Epoch 76/100] [Batch 303/347] [D loss: 0.531621] [G loss: 0.516416]\n",
      "[Epoch 76/100] [Batch 304/347] [D loss: 0.509506] [G loss: 0.504239]\n",
      "[Epoch 76/100] [Batch 305/347] [D loss: 0.491790] [G loss: 0.497000]\n",
      "[Epoch 76/100] [Batch 306/347] [D loss: 0.489905] [G loss: 0.496226]\n",
      "[Epoch 76/100] [Batch 307/347] [D loss: 0.486896] [G loss: 0.501797]\n",
      "[Epoch 76/100] [Batch 308/347] [D loss: 0.496214] [G loss: 0.507346]\n",
      "[Epoch 76/100] [Batch 309/347] [D loss: 0.525715] [G loss: 0.521143]\n",
      "[Epoch 76/100] [Batch 310/347] [D loss: 0.541273] [G loss: 0.532870]\n",
      "[Epoch 76/100] [Batch 311/347] [D loss: 0.535280] [G loss: 0.529504]\n",
      "[Epoch 76/100] [Batch 312/347] [D loss: 0.523218] [G loss: 0.523676]\n",
      "[Epoch 76/100] [Batch 313/347] [D loss: 0.517661] [G loss: 0.513763]\n",
      "[Epoch 76/100] [Batch 314/347] [D loss: 0.516293] [G loss: 0.498257]\n",
      "[Epoch 76/100] [Batch 315/347] [D loss: 0.516073] [G loss: 0.486407]\n",
      "[Epoch 76/100] [Batch 316/347] [D loss: 0.518885] [G loss: 0.486771]\n",
      "[Epoch 76/100] [Batch 317/347] [D loss: 0.521030] [G loss: 0.489766]\n",
      "[Epoch 76/100] [Batch 318/347] [D loss: 0.521327] [G loss: 0.502576]\n",
      "[Epoch 76/100] [Batch 319/347] [D loss: 0.517638] [G loss: 0.514152]\n",
      "[Epoch 76/100] [Batch 320/347] [D loss: 0.516260] [G loss: 0.511921]\n",
      "[Epoch 76/100] [Batch 321/347] [D loss: 0.512927] [G loss: 0.504584]\n",
      "[Epoch 76/100] [Batch 322/347] [D loss: 0.513977] [G loss: 0.496218]\n",
      "[Epoch 76/100] [Batch 323/347] [D loss: 0.503345] [G loss: 0.486745]\n",
      "[Epoch 76/100] [Batch 324/347] [D loss: 0.501168] [G loss: 0.480161]\n",
      "[Epoch 76/100] [Batch 325/347] [D loss: 0.500743] [G loss: 0.472422]\n",
      "[Epoch 76/100] [Batch 326/347] [D loss: 0.500196] [G loss: 0.464038]\n",
      "[Epoch 76/100] [Batch 327/347] [D loss: 0.495943] [G loss: 0.458897]\n",
      "[Epoch 76/100] [Batch 328/347] [D loss: 0.495869] [G loss: 0.452729]\n",
      "[Epoch 76/100] [Batch 329/347] [D loss: 0.494063] [G loss: 0.449746]\n",
      "[Epoch 76/100] [Batch 330/347] [D loss: 0.491874] [G loss: 0.448368]\n",
      "[Epoch 76/100] [Batch 331/347] [D loss: 0.494932] [G loss: 0.451429]\n",
      "[Epoch 76/100] [Batch 332/347] [D loss: 0.509778] [G loss: 0.469389]\n",
      "[Epoch 76/100] [Batch 333/347] [D loss: 0.502393] [G loss: 0.465865]\n",
      "[Epoch 76/100] [Batch 334/347] [D loss: 0.500090] [G loss: 0.457209]\n",
      "[Epoch 76/100] [Batch 335/347] [D loss: 0.498977] [G loss: 0.453073]\n",
      "[Epoch 76/100] [Batch 336/347] [D loss: 0.497816] [G loss: 0.449578]\n",
      "[Epoch 76/100] [Batch 337/347] [D loss: 0.505455] [G loss: 0.451672]\n",
      "[Epoch 76/100] [Batch 338/347] [D loss: 0.511707] [G loss: 0.457831]\n",
      "[Epoch 76/100] [Batch 339/347] [D loss: 0.505306] [G loss: 0.456108]\n",
      "[Epoch 76/100] [Batch 340/347] [D loss: 0.496475] [G loss: 0.450562]\n",
      "[Epoch 76/100] [Batch 341/347] [D loss: 0.498041] [G loss: 0.448446]\n",
      "[Epoch 76/100] [Batch 342/347] [D loss: 0.438626] [G loss: 0.433369]\n",
      "[Epoch 76/100] [Batch 343/347] [D loss: 0.413680] [G loss: 0.414365]\n",
      "[Epoch 76/100] [Batch 344/347] [D loss: 0.346653] [G loss: 0.404793]\n",
      "[Epoch 76/100] [Batch 345/347] [D loss: 0.229686] [G loss: 0.398306]\n",
      "[Epoch 76/100] [Batch 346/347] [D loss: 0.223774] [G loss: 0.393687]\n",
      "[Epoch 76/100] [Batch 347/347] [D loss: 0.218570] [G loss: 0.389261]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 1/347] [D loss: 0.464904] [G loss: 0.397918]\n",
      "[Epoch 77/100] [Batch 2/347] [D loss: 0.475377] [G loss: 0.390625]\n",
      "[Epoch 77/100] [Batch 3/347] [D loss: 0.498652] [G loss: 0.386653]\n",
      "[Epoch 77/100] [Batch 4/347] [D loss: 0.501983] [G loss: 0.378599]\n",
      "[Epoch 77/100] [Batch 5/347] [D loss: 0.503128] [G loss: 0.366320]\n",
      "[Epoch 77/100] [Batch 6/347] [D loss: 0.474569] [G loss: 0.354792]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 7/347] [D loss: 0.441170] [G loss: 0.337077]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 8/347] [D loss: 0.440198] [G loss: 0.325999]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 9/347] [D loss: 0.436697] [G loss: 0.318053]\n",
      "[Epoch 77/100] [Batch 10/347] [D loss: 0.443635] [G loss: 0.310640]\n",
      "[Epoch 77/100] [Batch 11/347] [D loss: 0.492491] [G loss: 0.313847]\n",
      "[Epoch 77/100] [Batch 12/347] [D loss: 0.507247] [G loss: 0.311940]\n",
      "[Epoch 77/100] [Batch 13/347] [D loss: 0.480901] [G loss: 0.307781]\n",
      "[Epoch 77/100] [Batch 14/347] [D loss: 0.458617] [G loss: 0.306202]\n",
      "[Epoch 77/100] [Batch 15/347] [D loss: 0.456618] [G loss: 0.297260]\n",
      "[Epoch 77/100] [Batch 16/347] [D loss: 0.449343] [G loss: 0.293358]\n",
      "[Epoch 77/100] [Batch 17/347] [D loss: 0.455050] [G loss: 0.298169]\n",
      "[Epoch 77/100] [Batch 18/347] [D loss: 0.465880] [G loss: 0.301839]\n",
      "[Epoch 77/100] [Batch 19/347] [D loss: 0.464910] [G loss: 0.310441]\n",
      "[Epoch 77/100] [Batch 20/347] [D loss: 0.485752] [G loss: 0.319342]\n",
      "[Epoch 77/100] [Batch 21/347] [D loss: 0.425241] [G loss: 0.318963]\n",
      "[Epoch 77/100] [Batch 22/347] [D loss: 0.426839] [G loss: 0.321710]\n",
      "[Epoch 77/100] [Batch 23/347] [D loss: 0.428531] [G loss: 0.322716]\n",
      "[Epoch 77/100] [Batch 24/347] [D loss: 0.390936] [G loss: 0.319571]\n",
      "[Epoch 77/100] [Batch 25/347] [D loss: 0.301605] [G loss: 0.332314]\n",
      "[Epoch 77/100] [Batch 26/347] [D loss: 0.298483] [G loss: 0.341118]\n",
      "[Epoch 77/100] [Batch 27/347] [D loss: 0.296411] [G loss: 0.353835]\n",
      "[Epoch 77/100] [Batch 28/347] [D loss: 0.297497] [G loss: 0.367490]\n",
      "[Epoch 77/100] [Batch 29/347] [D loss: 0.320854] [G loss: 0.378676]\n",
      "[Epoch 77/100] [Batch 30/347] [D loss: 0.312815] [G loss: 0.384915]\n",
      "[Epoch 77/100] [Batch 31/347] [D loss: 0.313067] [G loss: 0.388417]\n",
      "[Epoch 77/100] [Batch 32/347] [D loss: 0.322667] [G loss: 0.387621]\n",
      "[Epoch 77/100] [Batch 33/347] [D loss: 0.337952] [G loss: 0.385632]\n",
      "[Epoch 77/100] [Batch 34/347] [D loss: 0.378299] [G loss: 0.379785]\n",
      "[Epoch 77/100] [Batch 35/347] [D loss: 0.377125] [G loss: 0.368759]\n",
      "[Epoch 77/100] [Batch 36/347] [D loss: 0.400977] [G loss: 0.357185]\n",
      "[Epoch 77/100] [Batch 37/347] [D loss: 0.407706] [G loss: 0.342585]\n",
      "[Epoch 77/100] [Batch 38/347] [D loss: 0.407432] [G loss: 0.325612]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 39/347] [D loss: 0.416899] [G loss: 0.317256]\n",
      "[Epoch 77/100] [Batch 40/347] [D loss: 0.445119] [G loss: 0.314510]\n",
      "[Epoch 77/100] [Batch 41/347] [D loss: 0.466817] [G loss: 0.310590]\n",
      "[Epoch 77/100] [Batch 42/347] [D loss: 0.463865] [G loss: 0.313113]\n",
      "[Epoch 77/100] [Batch 43/347] [D loss: 0.488796] [G loss: 0.322410]\n",
      "[Epoch 77/100] [Batch 44/347] [D loss: 0.474044] [G loss: 0.324865]\n",
      "[Epoch 77/100] [Batch 45/347] [D loss: 0.449039] [G loss: 0.315403]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 46/347] [D loss: 0.374557] [G loss: 0.308821]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 47/347] [D loss: 0.369247] [G loss: 0.307108]\n",
      "[Epoch 77/100] [Batch 48/347] [D loss: 0.289969] [G loss: 0.319499]\n",
      "[Epoch 77/100] [Batch 49/347] [D loss: 0.271438] [G loss: 0.342570]\n",
      "[Epoch 77/100] [Batch 50/347] [D loss: 0.258568] [G loss: 0.370876]\n",
      "[Epoch 77/100] [Batch 51/347] [D loss: 0.238569] [G loss: 0.392993]\n",
      "[Epoch 77/100] [Batch 52/347] [D loss: 0.331706] [G loss: 0.401347]\n",
      "[Epoch 77/100] [Batch 53/347] [D loss: 0.374366] [G loss: 0.397848]\n",
      "[Epoch 77/100] [Batch 54/347] [D loss: 0.359148] [G loss: 0.392199]\n",
      "[Epoch 77/100] [Batch 55/347] [D loss: 0.356330] [G loss: 0.397729]\n",
      "[Epoch 77/100] [Batch 56/347] [D loss: 0.348824] [G loss: 0.405706]\n",
      "[Epoch 77/100] [Batch 57/347] [D loss: 0.301404] [G loss: 0.412156]\n",
      "[Epoch 77/100] [Batch 58/347] [D loss: 0.309061] [G loss: 0.414094]\n",
      "[Epoch 77/100] [Batch 59/347] [D loss: 0.306110] [G loss: 0.406173]\n",
      "[Epoch 77/100] [Batch 60/347] [D loss: 0.289900] [G loss: 0.389552]\n",
      "[Epoch 77/100] [Batch 61/347] [D loss: 0.304556] [G loss: 0.370429]\n",
      "[Epoch 77/100] [Batch 62/347] [D loss: 0.304268] [G loss: 0.364590]\n",
      "[Epoch 77/100] [Batch 63/347] [D loss: 0.298431] [G loss: 0.360510]\n",
      "[Epoch 77/100] [Batch 64/347] [D loss: 0.282425] [G loss: 0.355603]\n",
      "[Epoch 77/100] [Batch 65/347] [D loss: 0.242475] [G loss: 0.359424]\n",
      "[Epoch 77/100] [Batch 66/347] [D loss: 0.244290] [G loss: 0.360296]\n",
      "[Epoch 77/100] [Batch 67/347] [D loss: 0.242379] [G loss: 0.353148]\n",
      "[Epoch 77/100] [Batch 68/347] [D loss: 0.241215] [G loss: 0.355224]\n",
      "[Epoch 77/100] [Batch 69/347] [D loss: 0.254310] [G loss: 0.358652]\n",
      "[Epoch 77/100] [Batch 70/347] [D loss: 0.249713] [G loss: 0.360600]\n",
      "[Epoch 77/100] [Batch 71/347] [D loss: 0.248332] [G loss: 0.377976]\n",
      "[Epoch 77/100] [Batch 72/347] [D loss: 0.255327] [G loss: 0.393284]\n",
      "[Epoch 77/100] [Batch 73/347] [D loss: 0.364383] [G loss: 0.392144]\n",
      "[Epoch 77/100] [Batch 74/347] [D loss: 0.366852] [G loss: 0.394324]\n",
      "[Epoch 77/100] [Batch 75/347] [D loss: 0.365295] [G loss: 0.394631]\n",
      "[Epoch 77/100] [Batch 76/347] [D loss: 0.363928] [G loss: 0.392583]\n",
      "[Epoch 77/100] [Batch 77/347] [D loss: 0.401153] [G loss: 0.389131]\n",
      "[Epoch 77/100] [Batch 78/347] [D loss: 0.453366] [G loss: 0.395990]\n",
      "[Epoch 77/100] [Batch 79/347] [D loss: 0.446993] [G loss: 0.392068]\n",
      "[Epoch 77/100] [Batch 80/347] [D loss: 0.344331] [G loss: 0.373877]\n",
      "[Epoch 77/100] [Batch 81/347] [D loss: 0.325294] [G loss: 0.366899]\n",
      "[Epoch 77/100] [Batch 82/347] [D loss: 0.324574] [G loss: 0.360939]\n",
      "[Epoch 77/100] [Batch 83/347] [D loss: 0.331087] [G loss: 0.354744]\n",
      "[Epoch 77/100] [Batch 84/347] [D loss: 0.455303] [G loss: 0.355103]\n",
      "[Epoch 77/100] [Batch 85/347] [D loss: 0.529076] [G loss: 0.352072]\n",
      "[Epoch 77/100] [Batch 86/347] [D loss: 0.531761] [G loss: 0.348983]\n",
      "[Epoch 77/100] [Batch 87/347] [D loss: 0.531875] [G loss: 0.348361]\n",
      "[Epoch 77/100] [Batch 88/347] [D loss: 0.552891] [G loss: 0.348422]\n",
      "[Epoch 77/100] [Batch 89/347] [D loss: 0.561265] [G loss: 0.351636]\n",
      "[Epoch 77/100] [Batch 90/347] [D loss: 0.559827] [G loss: 0.353951]\n",
      "[Epoch 77/100] [Batch 91/347] [D loss: 0.560466] [G loss: 0.356322]\n",
      "[Epoch 77/100] [Batch 92/347] [D loss: 0.561335] [G loss: 0.361653]\n",
      "[Epoch 77/100] [Batch 93/347] [D loss: 0.561169] [G loss: 0.369408]\n",
      "[Epoch 77/100] [Batch 94/347] [D loss: 0.545022] [G loss: 0.372121]\n",
      "[Epoch 77/100] [Batch 95/347] [D loss: 0.536952] [G loss: 0.378046]\n",
      "[Epoch 77/100] [Batch 96/347] [D loss: 0.535683] [G loss: 0.386875]\n",
      "[Epoch 77/100] [Batch 97/347] [D loss: 0.530147] [G loss: 0.393925]\n",
      "[Epoch 77/100] [Batch 98/347] [D loss: 0.516311] [G loss: 0.401569]\n",
      "[Epoch 77/100] [Batch 99/347] [D loss: 0.521808] [G loss: 0.407420]\n",
      "[Epoch 77/100] [Batch 100/347] [D loss: 0.520233] [G loss: 0.412418]\n",
      "[Epoch 77/100] [Batch 101/347] [D loss: 0.527246] [G loss: 0.414810]\n",
      "[Epoch 77/100] [Batch 102/347] [D loss: 0.551727] [G loss: 0.417828]\n",
      "[Epoch 77/100] [Batch 103/347] [D loss: 0.554047] [G loss: 0.426049]\n",
      "[Epoch 77/100] [Batch 104/347] [D loss: 0.538704] [G loss: 0.428106]\n",
      "[Epoch 77/100] [Batch 105/347] [D loss: 0.449721] [G loss: 0.428458]\n",
      "[Epoch 77/100] [Batch 106/347] [D loss: 0.210843] [G loss: 0.427452]\n",
      "[Epoch 77/100] [Batch 107/347] [D loss: 0.202807] [G loss: 0.435520]\n",
      "[Epoch 77/100] [Batch 108/347] [D loss: 0.204645] [G loss: 0.446020]\n",
      "[Epoch 77/100] [Batch 109/347] [D loss: 0.192356] [G loss: 0.457959]\n",
      "[Epoch 77/100] [Batch 110/347] [D loss: 0.235285] [G loss: 0.463763]\n",
      "[Epoch 77/100] [Batch 111/347] [D loss: 0.239061] [G loss: 0.473603]\n",
      "[Epoch 77/100] [Batch 112/347] [D loss: 0.239441] [G loss: 0.480628]\n",
      "[Epoch 77/100] [Batch 113/347] [D loss: 0.422085] [G loss: 0.500517]\n",
      "[Epoch 77/100] [Batch 114/347] [D loss: 0.492459] [G loss: 0.507159]\n",
      "[Epoch 77/100] [Batch 115/347] [D loss: 0.492730] [G loss: 0.489268]\n",
      "[Epoch 77/100] [Batch 116/347] [D loss: 0.439196] [G loss: 0.468722]\n",
      "[Epoch 77/100] [Batch 117/347] [D loss: 0.430130] [G loss: 0.450568]\n",
      "[Epoch 77/100] [Batch 118/347] [D loss: 0.363934] [G loss: 0.429109]\n",
      "[Epoch 77/100] [Batch 119/347] [D loss: 0.353556] [G loss: 0.415642]\n",
      "[Epoch 77/100] [Batch 120/347] [D loss: 0.340582] [G loss: 0.406536]\n",
      "[Epoch 77/100] [Batch 121/347] [D loss: 0.333497] [G loss: 0.390238]\n",
      "[Epoch 77/100] [Batch 122/347] [D loss: 0.448224] [G loss: 0.377554]\n",
      "[Epoch 77/100] [Batch 123/347] [D loss: 0.500777] [G loss: 0.370138]\n",
      "[Epoch 77/100] [Batch 124/347] [D loss: 0.432843] [G loss: 0.359694]\n",
      "[Epoch 77/100] [Batch 125/347] [D loss: 0.405383] [G loss: 0.356333]\n",
      "[Epoch 77/100] [Batch 126/347] [D loss: 0.372792] [G loss: 0.356159]\n",
      "[Epoch 77/100] [Batch 127/347] [D loss: 0.376531] [G loss: 0.355403]\n",
      "[Epoch 77/100] [Batch 128/347] [D loss: 0.362726] [G loss: 0.352408]\n",
      "[Epoch 77/100] [Batch 129/347] [D loss: 0.322576] [G loss: 0.356511]\n",
      "[Epoch 77/100] [Batch 130/347] [D loss: 0.281330] [G loss: 0.381806]\n",
      "[Epoch 77/100] [Batch 131/347] [D loss: 0.256897] [G loss: 0.407170]\n",
      "[Epoch 77/100] [Batch 132/347] [D loss: 0.227661] [G loss: 0.437935]\n",
      "[Epoch 77/100] [Batch 133/347] [D loss: 0.208767] [G loss: 0.465492]\n",
      "[Epoch 77/100] [Batch 134/347] [D loss: 0.183194] [G loss: 0.487881]\n",
      "[Epoch 77/100] [Batch 135/347] [D loss: 0.164800] [G loss: 0.501863]\n",
      "[Epoch 77/100] [Batch 136/347] [D loss: 0.159307] [G loss: 0.506325]\n",
      "[Epoch 77/100] [Batch 137/347] [D loss: 0.405227] [G loss: 0.505699]\n",
      "[Epoch 77/100] [Batch 138/347] [D loss: 0.442964] [G loss: 0.501589]\n",
      "[Epoch 77/100] [Batch 139/347] [D loss: 0.450006] [G loss: 0.493250]\n",
      "[Epoch 77/100] [Batch 140/347] [D loss: 0.464776] [G loss: 0.492910]\n",
      "[Epoch 77/100] [Batch 141/347] [D loss: 0.433269] [G loss: 0.486730]\n",
      "[Epoch 77/100] [Batch 142/347] [D loss: 0.438664] [G loss: 0.479739]\n",
      "[Epoch 77/100] [Batch 143/347] [D loss: 0.436906] [G loss: 0.469602]\n",
      "[Epoch 77/100] [Batch 144/347] [D loss: 0.421277] [G loss: 0.458992]\n",
      "[Epoch 77/100] [Batch 145/347] [D loss: 0.446024] [G loss: 0.456690]\n",
      "[Epoch 77/100] [Batch 146/347] [D loss: 0.454029] [G loss: 0.448446]\n",
      "[Epoch 77/100] [Batch 147/347] [D loss: 0.472149] [G loss: 0.440115]\n",
      "[Epoch 77/100] [Batch 148/347] [D loss: 0.478178] [G loss: 0.433493]\n",
      "[Epoch 77/100] [Batch 149/347] [D loss: 0.413805] [G loss: 0.419196]\n",
      "[Epoch 77/100] [Batch 150/347] [D loss: 0.374864] [G loss: 0.398319]\n",
      "[Epoch 77/100] [Batch 151/347] [D loss: 0.347549] [G loss: 0.370346]\n",
      "[Epoch 77/100] [Batch 152/347] [D loss: 0.328386] [G loss: 0.338423]\n",
      "[Epoch 77/100] [Batch 153/347] [D loss: 0.335737] [G loss: 0.308996]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 154/347] [D loss: 0.339552] [G loss: 0.289922]\n",
      "[Epoch 77/100] [Batch 155/347] [D loss: 0.342559] [G loss: 0.285150]\n",
      "[Epoch 77/100] [Batch 156/347] [D loss: 0.344846] [G loss: 0.281485]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 77/100] [Batch 157/347] [D loss: 0.336587] [G loss: 0.287677]\n",
      "[Epoch 77/100] [Batch 158/347] [D loss: 0.317617] [G loss: 0.305198]\n",
      "[Epoch 77/100] [Batch 159/347] [D loss: 0.321387] [G loss: 0.324446]\n",
      "[Epoch 77/100] [Batch 160/347] [D loss: 0.298027] [G loss: 0.354018]\n",
      "[Epoch 77/100] [Batch 161/347] [D loss: 0.279665] [G loss: 0.380990]\n",
      "[Epoch 77/100] [Batch 162/347] [D loss: 0.264629] [G loss: 0.397303]\n",
      "[Epoch 77/100] [Batch 163/347] [D loss: 0.259908] [G loss: 0.405197]\n",
      "[Epoch 77/100] [Batch 164/347] [D loss: 0.260902] [G loss: 0.420049]\n",
      "[Epoch 77/100] [Batch 165/347] [D loss: 0.262773] [G loss: 0.436079]\n",
      "[Epoch 77/100] [Batch 166/347] [D loss: 0.271404] [G loss: 0.447366]\n",
      "[Epoch 77/100] [Batch 167/347] [D loss: 0.301824] [G loss: 0.467545]\n",
      "[Epoch 77/100] [Batch 168/347] [D loss: 0.304269] [G loss: 0.477446]\n",
      "[Epoch 77/100] [Batch 169/347] [D loss: 0.442417] [G loss: 0.485811]\n",
      "[Epoch 77/100] [Batch 170/347] [D loss: 0.514429] [G loss: 0.490998]\n",
      "[Epoch 77/100] [Batch 171/347] [D loss: 0.516145] [G loss: 0.489192]\n",
      "[Epoch 77/100] [Batch 172/347] [D loss: 0.515960] [G loss: 0.488377]\n",
      "[Epoch 77/100] [Batch 173/347] [D loss: 0.517067] [G loss: 0.484869]\n",
      "[Epoch 77/100] [Batch 174/347] [D loss: 0.512170] [G loss: 0.485563]\n",
      "[Epoch 77/100] [Batch 175/347] [D loss: 0.532113] [G loss: 0.487455]\n",
      "[Epoch 77/100] [Batch 176/347] [D loss: 0.549379] [G loss: 0.488162]\n",
      "[Epoch 77/100] [Batch 177/347] [D loss: 0.549144] [G loss: 0.483903]\n",
      "[Epoch 77/100] [Batch 178/347] [D loss: 0.547808] [G loss: 0.477130]\n",
      "[Epoch 77/100] [Batch 179/347] [D loss: 0.546147] [G loss: 0.473763]\n",
      "[Epoch 77/100] [Batch 180/347] [D loss: 0.545271] [G loss: 0.470360]\n",
      "[Epoch 77/100] [Batch 181/347] [D loss: 0.543776] [G loss: 0.473732]\n",
      "[Epoch 77/100] [Batch 182/347] [D loss: 0.545484] [G loss: 0.476083]\n",
      "[Epoch 77/100] [Batch 183/347] [D loss: 0.544841] [G loss: 0.479119]\n",
      "[Epoch 77/100] [Batch 184/347] [D loss: 0.553046] [G loss: 0.484107]\n",
      "[Epoch 77/100] [Batch 185/347] [D loss: 0.552694] [G loss: 0.483696]\n",
      "[Epoch 77/100] [Batch 186/347] [D loss: 0.547942] [G loss: 0.485955]\n",
      "[Epoch 77/100] [Batch 187/347] [D loss: 0.543756] [G loss: 0.486578]\n",
      "[Epoch 77/100] [Batch 188/347] [D loss: 0.529543] [G loss: 0.481103]\n",
      "[Epoch 77/100] [Batch 189/347] [D loss: 0.503460] [G loss: 0.476510]\n",
      "[Epoch 77/100] [Batch 190/347] [D loss: 0.500007] [G loss: 0.473679]\n",
      "[Epoch 77/100] [Batch 191/347] [D loss: 0.500050] [G loss: 0.469882]\n",
      "[Epoch 77/100] [Batch 192/347] [D loss: 0.502178] [G loss: 0.467564]\n",
      "[Epoch 77/100] [Batch 193/347] [D loss: 0.530417] [G loss: 0.465860]\n",
      "[Epoch 77/100] [Batch 194/347] [D loss: 0.530329] [G loss: 0.460881]\n",
      "[Epoch 77/100] [Batch 195/347] [D loss: 0.517593] [G loss: 0.455683]\n",
      "[Epoch 77/100] [Batch 196/347] [D loss: 0.494406] [G loss: 0.449366]\n",
      "[Epoch 77/100] [Batch 197/347] [D loss: 0.487832] [G loss: 0.443020]\n",
      "[Epoch 77/100] [Batch 198/347] [D loss: 0.485419] [G loss: 0.438505]\n",
      "[Epoch 77/100] [Batch 199/347] [D loss: 0.476190] [G loss: 0.430252]\n",
      "[Epoch 77/100] [Batch 200/347] [D loss: 0.509739] [G loss: 0.422163]\n",
      "[Epoch 77/100] [Batch 201/347] [D loss: 0.532678] [G loss: 0.413631]\n",
      "[Epoch 77/100] [Batch 202/347] [D loss: 0.531765] [G loss: 0.406542]\n",
      "[Epoch 77/100] [Batch 203/347] [D loss: 0.559497] [G loss: 0.401151]\n",
      "[Epoch 77/100] [Batch 204/347] [D loss: 0.555479] [G loss: 0.401169]\n",
      "[Epoch 77/100] [Batch 205/347] [D loss: 0.555553] [G loss: 0.405025]\n",
      "[Epoch 77/100] [Batch 206/347] [D loss: 0.552992] [G loss: 0.408842]\n",
      "[Epoch 77/100] [Batch 207/347] [D loss: 0.506365] [G loss: 0.411714]\n",
      "[Epoch 77/100] [Batch 208/347] [D loss: 0.493742] [G loss: 0.415106]\n",
      "[Epoch 77/100] [Batch 209/347] [D loss: 0.482988] [G loss: 0.410210]\n",
      "[Epoch 77/100] [Batch 210/347] [D loss: 0.395637] [G loss: 0.408505]\n",
      "[Epoch 77/100] [Batch 211/347] [D loss: 0.349969] [G loss: 0.401417]\n",
      "[Epoch 77/100] [Batch 212/347] [D loss: 0.236620] [G loss: 0.389852]\n",
      "[Epoch 77/100] [Batch 213/347] [D loss: 0.234347] [G loss: 0.393732]\n",
      "[Epoch 77/100] [Batch 214/347] [D loss: 0.228995] [G loss: 0.403182]\n",
      "[Epoch 77/100] [Batch 215/347] [D loss: 0.225049] [G loss: 0.416650]\n",
      "[Epoch 77/100] [Batch 216/347] [D loss: 0.388487] [G loss: 0.445509]\n",
      "[Epoch 77/100] [Batch 217/347] [D loss: 0.444393] [G loss: 0.465785]\n",
      "[Epoch 77/100] [Batch 218/347] [D loss: 0.495547] [G loss: 0.484994]\n",
      "[Epoch 77/100] [Batch 219/347] [D loss: 0.478114] [G loss: 0.494740]\n",
      "[Epoch 77/100] [Batch 220/347] [D loss: 0.476603] [G loss: 0.501092]\n",
      "[Epoch 77/100] [Batch 221/347] [D loss: 0.497026] [G loss: 0.502338]\n",
      "[Epoch 77/100] [Batch 222/347] [D loss: 0.499301] [G loss: 0.494683]\n",
      "[Epoch 77/100] [Batch 223/347] [D loss: 0.487830] [G loss: 0.475794]\n",
      "[Epoch 77/100] [Batch 224/347] [D loss: 0.493471] [G loss: 0.452783]\n",
      "[Epoch 77/100] [Batch 225/347] [D loss: 0.499464] [G loss: 0.432773]\n",
      "[Epoch 77/100] [Batch 226/347] [D loss: 0.504358] [G loss: 0.419998]\n",
      "[Epoch 77/100] [Batch 227/347] [D loss: 0.525995] [G loss: 0.418431]\n",
      "[Epoch 77/100] [Batch 228/347] [D loss: 0.536481] [G loss: 0.419056]\n",
      "[Epoch 77/100] [Batch 229/347] [D loss: 0.537823] [G loss: 0.420969]\n",
      "[Epoch 77/100] [Batch 230/347] [D loss: 0.542406] [G loss: 0.423360]\n",
      "[Epoch 77/100] [Batch 231/347] [D loss: 0.530391] [G loss: 0.418490]\n",
      "[Epoch 77/100] [Batch 232/347] [D loss: 0.519451] [G loss: 0.418243]\n",
      "[Epoch 77/100] [Batch 233/347] [D loss: 0.453609] [G loss: 0.421550]\n",
      "[Epoch 77/100] [Batch 234/347] [D loss: 0.420637] [G loss: 0.423050]\n",
      "[Epoch 77/100] [Batch 235/347] [D loss: 0.413822] [G loss: 0.430029]\n",
      "[Epoch 77/100] [Batch 236/347] [D loss: 0.409222] [G loss: 0.434910]\n",
      "[Epoch 77/100] [Batch 237/347] [D loss: 0.459502] [G loss: 0.435867]\n",
      "[Epoch 77/100] [Batch 238/347] [D loss: 0.531534] [G loss: 0.431954]\n",
      "[Epoch 77/100] [Batch 239/347] [D loss: 0.534198] [G loss: 0.425765]\n",
      "[Epoch 77/100] [Batch 240/347] [D loss: 0.534740] [G loss: 0.423327]\n",
      "[Epoch 77/100] [Batch 241/347] [D loss: 0.537701] [G loss: 0.424697]\n",
      "[Epoch 77/100] [Batch 242/347] [D loss: 0.548319] [G loss: 0.430069]\n",
      "[Epoch 77/100] [Batch 243/347] [D loss: 0.510652] [G loss: 0.435453]\n",
      "[Epoch 77/100] [Batch 244/347] [D loss: 0.478354] [G loss: 0.430331]\n",
      "[Epoch 77/100] [Batch 245/347] [D loss: 0.487085] [G loss: 0.421956]\n",
      "[Epoch 77/100] [Batch 246/347] [D loss: 0.481720] [G loss: 0.410839]\n",
      "[Epoch 77/100] [Batch 247/347] [D loss: 0.511212] [G loss: 0.404151]\n",
      "[Epoch 77/100] [Batch 248/347] [D loss: 0.528800] [G loss: 0.408852]\n",
      "[Epoch 77/100] [Batch 249/347] [D loss: 0.514254] [G loss: 0.416580]\n",
      "[Epoch 77/100] [Batch 250/347] [D loss: 0.508901] [G loss: 0.427086]\n",
      "[Epoch 77/100] [Batch 251/347] [D loss: 0.500223] [G loss: 0.441335]\n",
      "[Epoch 77/100] [Batch 252/347] [D loss: 0.494398] [G loss: 0.449235]\n",
      "[Epoch 77/100] [Batch 253/347] [D loss: 0.446139] [G loss: 0.443986]\n",
      "[Epoch 77/100] [Batch 254/347] [D loss: 0.448973] [G loss: 0.448518]\n",
      "[Epoch 77/100] [Batch 255/347] [D loss: 0.442612] [G loss: 0.447883]\n",
      "[Epoch 77/100] [Batch 256/347] [D loss: 0.447933] [G loss: 0.437761]\n",
      "[Epoch 77/100] [Batch 257/347] [D loss: 0.428014] [G loss: 0.426116]\n",
      "[Epoch 77/100] [Batch 258/347] [D loss: 0.388673] [G loss: 0.413560]\n",
      "[Epoch 77/100] [Batch 259/347] [D loss: 0.389274] [G loss: 0.402665]\n",
      "[Epoch 77/100] [Batch 260/347] [D loss: 0.388542] [G loss: 0.393231]\n",
      "[Epoch 77/100] [Batch 261/347] [D loss: 0.377385] [G loss: 0.389783]\n",
      "[Epoch 77/100] [Batch 262/347] [D loss: 0.333547] [G loss: 0.384108]\n",
      "[Epoch 77/100] [Batch 263/347] [D loss: 0.334397] [G loss: 0.380203]\n",
      "[Epoch 77/100] [Batch 264/347] [D loss: 0.334475] [G loss: 0.380718]\n",
      "[Epoch 77/100] [Batch 265/347] [D loss: 0.346321] [G loss: 0.382280]\n",
      "[Epoch 77/100] [Batch 266/347] [D loss: 0.407679] [G loss: 0.386099]\n",
      "[Epoch 77/100] [Batch 267/347] [D loss: 0.425726] [G loss: 0.388889]\n",
      "[Epoch 77/100] [Batch 268/347] [D loss: 0.430938] [G loss: 0.391425]\n",
      "[Epoch 77/100] [Batch 269/347] [D loss: 0.433114] [G loss: 0.393479]\n",
      "[Epoch 77/100] [Batch 270/347] [D loss: 0.460347] [G loss: 0.394570]\n",
      "[Epoch 77/100] [Batch 271/347] [D loss: 0.429292] [G loss: 0.400805]\n",
      "[Epoch 77/100] [Batch 272/347] [D loss: 0.429556] [G loss: 0.425352]\n",
      "[Epoch 77/100] [Batch 273/347] [D loss: 0.379427] [G loss: 0.449299]\n",
      "[Epoch 77/100] [Batch 274/347] [D loss: 0.334463] [G loss: 0.471220]\n",
      "[Epoch 77/100] [Batch 275/347] [D loss: 0.270920] [G loss: 0.488049]\n",
      "[Epoch 77/100] [Batch 276/347] [D loss: 0.480709] [G loss: 0.498922]\n",
      "[Epoch 77/100] [Batch 277/347] [D loss: 0.505461] [G loss: 0.511398]\n",
      "[Epoch 77/100] [Batch 278/347] [D loss: 0.509771] [G loss: 0.522265]\n",
      "[Epoch 77/100] [Batch 279/347] [D loss: 0.513987] [G loss: 0.524702]\n",
      "[Epoch 77/100] [Batch 280/347] [D loss: 0.517322] [G loss: 0.525568]\n",
      "[Epoch 77/100] [Batch 281/347] [D loss: 0.522826] [G loss: 0.526491]\n",
      "[Epoch 77/100] [Batch 282/347] [D loss: 0.524165] [G loss: 0.530228]\n",
      "[Epoch 77/100] [Batch 283/347] [D loss: 0.525215] [G loss: 0.531980]\n",
      "[Epoch 77/100] [Batch 284/347] [D loss: 0.526079] [G loss: 0.534698]\n",
      "[Epoch 77/100] [Batch 285/347] [D loss: 0.531355] [G loss: 0.536032]\n",
      "[Epoch 77/100] [Batch 286/347] [D loss: 0.529440] [G loss: 0.522237]\n",
      "[Epoch 77/100] [Batch 287/347] [D loss: 0.530331] [G loss: 0.519718]\n",
      "[Epoch 77/100] [Batch 288/347] [D loss: 0.530535] [G loss: 0.517107]\n",
      "[Epoch 77/100] [Batch 289/347] [D loss: 0.528516] [G loss: 0.512232]\n",
      "[Epoch 77/100] [Batch 290/347] [D loss: 0.528158] [G loss: 0.528077]\n",
      "[Epoch 77/100] [Batch 291/347] [D loss: 0.526531] [G loss: 0.534935]\n",
      "[Epoch 77/100] [Batch 292/347] [D loss: 0.523635] [G loss: 0.538665]\n",
      "[Epoch 77/100] [Batch 293/347] [D loss: 0.495002] [G loss: 0.544052]\n",
      "[Epoch 77/100] [Batch 294/347] [D loss: 0.494243] [G loss: 0.548337]\n",
      "[Epoch 77/100] [Batch 295/347] [D loss: 0.493950] [G loss: 0.547110]\n",
      "[Epoch 77/100] [Batch 296/347] [D loss: 0.493323] [G loss: 0.545416]\n",
      "[Epoch 77/100] [Batch 297/347] [D loss: 0.522944] [G loss: 0.549785]\n",
      "[Epoch 77/100] [Batch 298/347] [D loss: 0.526487] [G loss: 0.542928]\n",
      "[Epoch 77/100] [Batch 299/347] [D loss: 0.525944] [G loss: 0.538120]\n",
      "[Epoch 77/100] [Batch 300/347] [D loss: 0.524731] [G loss: 0.535526]\n",
      "[Epoch 77/100] [Batch 301/347] [D loss: 0.525290] [G loss: 0.518186]\n",
      "[Epoch 77/100] [Batch 302/347] [D loss: 0.526082] [G loss: 0.510623]\n",
      "[Epoch 77/100] [Batch 303/347] [D loss: 0.524959] [G loss: 0.499043]\n",
      "[Epoch 77/100] [Batch 304/347] [D loss: 0.501547] [G loss: 0.486571]\n",
      "[Epoch 77/100] [Batch 305/347] [D loss: 0.483028] [G loss: 0.478933]\n",
      "[Epoch 77/100] [Batch 306/347] [D loss: 0.480932] [G loss: 0.475949]\n",
      "[Epoch 77/100] [Batch 307/347] [D loss: 0.477620] [G loss: 0.481094]\n",
      "[Epoch 77/100] [Batch 308/347] [D loss: 0.487222] [G loss: 0.488106]\n",
      "[Epoch 77/100] [Batch 309/347] [D loss: 0.518330] [G loss: 0.501284]\n",
      "[Epoch 77/100] [Batch 310/347] [D loss: 0.535297] [G loss: 0.512581]\n",
      "[Epoch 77/100] [Batch 311/347] [D loss: 0.528519] [G loss: 0.509019]\n",
      "[Epoch 77/100] [Batch 312/347] [D loss: 0.515168] [G loss: 0.502766]\n",
      "[Epoch 77/100] [Batch 313/347] [D loss: 0.509225] [G loss: 0.492592]\n",
      "[Epoch 77/100] [Batch 314/347] [D loss: 0.507734] [G loss: 0.476775]\n",
      "[Epoch 77/100] [Batch 315/347] [D loss: 0.507457] [G loss: 0.464573]\n",
      "[Epoch 77/100] [Batch 316/347] [D loss: 0.510545] [G loss: 0.464678]\n",
      "[Epoch 77/100] [Batch 317/347] [D loss: 0.512718] [G loss: 0.467474]\n",
      "[Epoch 77/100] [Batch 318/347] [D loss: 0.513082] [G loss: 0.479926]\n",
      "[Epoch 77/100] [Batch 319/347] [D loss: 0.509015] [G loss: 0.491329]\n",
      "[Epoch 77/100] [Batch 320/347] [D loss: 0.507580] [G loss: 0.488769]\n",
      "[Epoch 77/100] [Batch 321/347] [D loss: 0.503951] [G loss: 0.481107]\n",
      "[Epoch 77/100] [Batch 322/347] [D loss: 0.505124] [G loss: 0.472627]\n",
      "[Epoch 77/100] [Batch 323/347] [D loss: 0.493355] [G loss: 0.463036]\n",
      "[Epoch 77/100] [Batch 324/347] [D loss: 0.490945] [G loss: 0.456264]\n",
      "[Epoch 77/100] [Batch 325/347] [D loss: 0.490502] [G loss: 0.448182]\n",
      "[Epoch 77/100] [Batch 326/347] [D loss: 0.489674] [G loss: 0.439245]\n",
      "[Epoch 77/100] [Batch 327/347] [D loss: 0.484706] [G loss: 0.433838]\n",
      "[Epoch 77/100] [Batch 328/347] [D loss: 0.484413] [G loss: 0.427179]\n",
      "[Epoch 77/100] [Batch 329/347] [D loss: 0.481854] [G loss: 0.423817]\n",
      "[Epoch 77/100] [Batch 330/347] [D loss: 0.478902] [G loss: 0.421715]\n",
      "[Epoch 77/100] [Batch 331/347] [D loss: 0.481625] [G loss: 0.424143]\n",
      "[Epoch 77/100] [Batch 332/347] [D loss: 0.499517] [G loss: 0.441787]\n",
      "[Epoch 77/100] [Batch 333/347] [D loss: 0.490459] [G loss: 0.437528]\n",
      "[Epoch 77/100] [Batch 334/347] [D loss: 0.487183] [G loss: 0.428005]\n",
      "[Epoch 77/100] [Batch 335/347] [D loss: 0.485063] [G loss: 0.423196]\n",
      "[Epoch 77/100] [Batch 336/347] [D loss: 0.483038] [G loss: 0.418783]\n",
      "[Epoch 77/100] [Batch 337/347] [D loss: 0.492295] [G loss: 0.419970]\n",
      "[Epoch 77/100] [Batch 338/347] [D loss: 0.500375] [G loss: 0.425075]\n",
      "[Epoch 77/100] [Batch 339/347] [D loss: 0.491512] [G loss: 0.422330]\n",
      "[Epoch 77/100] [Batch 340/347] [D loss: 0.477512] [G loss: 0.415381]\n",
      "[Epoch 77/100] [Batch 341/347] [D loss: 0.478992] [G loss: 0.412074]\n",
      "[Epoch 77/100] [Batch 342/347] [D loss: 0.401017] [G loss: 0.395385]\n",
      "[Epoch 77/100] [Batch 343/347] [D loss: 0.367974] [G loss: 0.374577]\n",
      "[Epoch 77/100] [Batch 344/347] [D loss: 0.311992] [G loss: 0.363122]\n",
      "[Epoch 77/100] [Batch 345/347] [D loss: 0.224455] [G loss: 0.355637]\n",
      "[Epoch 77/100] [Batch 346/347] [D loss: 0.225346] [G loss: 0.350295]\n",
      "[Epoch 77/100] [Batch 347/347] [D loss: 0.226491] [G loss: 0.346733]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 78/100] [Batch 1/347] [D loss: 0.438826] [G loss: 0.356680]\n",
      "[Epoch 78/100] [Batch 2/347] [D loss: 0.454253] [G loss: 0.350902]\n",
      "[Epoch 78/100] [Batch 3/347] [D loss: 0.483409] [G loss: 0.349014]\n",
      "[Epoch 78/100] [Batch 4/347] [D loss: 0.487631] [G loss: 0.342918]\n",
      "[Epoch 78/100] [Batch 5/347] [D loss: 0.489849] [G loss: 0.333522]\n",
      "[Epoch 78/100] [Batch 6/347] [D loss: 0.457421] [G loss: 0.324601]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 78/100] [Batch 7/347] [D loss: 0.424642] [G loss: 0.309770]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 78/100] [Batch 8/347] [D loss: 0.424265] [G loss: 0.302883]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 78/100] [Batch 9/347] [D loss: 0.421727] [G loss: 0.298653]\n",
      "[Epoch 78/100] [Batch 10/347] [D loss: 0.428124] [G loss: 0.295048]\n",
      "[Epoch 78/100] [Batch 11/347] [D loss: 0.476303] [G loss: 0.301020]\n",
      "[Epoch 78/100] [Batch 12/347] [D loss: 0.488785] [G loss: 0.301733]\n",
      "[Epoch 78/100] [Batch 13/347] [D loss: 0.462296] [G loss: 0.300063]\n",
      "[Epoch 78/100] [Batch 14/347] [D loss: 0.440787] [G loss: 0.300144]\n",
      "[Epoch 78/100] [Batch 15/347] [D loss: 0.438125] [G loss: 0.292854]\n",
      "[Epoch 78/100] [Batch 16/347] [D loss: 0.430661] [G loss: 0.290427]\n",
      "[Epoch 78/100] [Batch 17/347] [D loss: 0.436018] [G loss: 0.295851]\n",
      "[Epoch 78/100] [Batch 18/347] [D loss: 0.446636] [G loss: 0.299743]\n",
      "[Epoch 78/100] [Batch 19/347] [D loss: 0.445308] [G loss: 0.307833]\n",
      "[Epoch 78/100] [Batch 20/347] [D loss: 0.465484] [G loss: 0.315340]\n",
      "[Epoch 78/100] [Batch 21/347] [D loss: 0.406421] [G loss: 0.314346]\n",
      "[Epoch 78/100] [Batch 22/347] [D loss: 0.407509] [G loss: 0.315604]\n",
      "[Epoch 78/100] [Batch 23/347] [D loss: 0.409756] [G loss: 0.315032]\n",
      "[Epoch 78/100] [Batch 24/347] [D loss: 0.374293] [G loss: 0.310158]\n",
      "[Epoch 78/100] [Batch 25/347] [D loss: 0.289384] [G loss: 0.322225]\n",
      "[Epoch 78/100] [Batch 26/347] [D loss: 0.286264] [G loss: 0.329902]\n",
      "[Epoch 78/100] [Batch 27/347] [D loss: 0.283881] [G loss: 0.342073]\n",
      "[Epoch 78/100] [Batch 28/347] [D loss: 0.284236] [G loss: 0.355616]\n",
      "[Epoch 78/100] [Batch 29/347] [D loss: 0.304666] [G loss: 0.365626]\n",
      "[Epoch 78/100] [Batch 30/347] [D loss: 0.296817] [G loss: 0.371979]\n",
      "[Epoch 78/100] [Batch 31/347] [D loss: 0.296264] [G loss: 0.375566]\n",
      "[Epoch 78/100] [Batch 32/347] [D loss: 0.304397] [G loss: 0.374891]\n",
      "[Epoch 78/100] [Batch 33/347] [D loss: 0.318549] [G loss: 0.373678]\n",
      "[Epoch 78/100] [Batch 34/347] [D loss: 0.356412] [G loss: 0.368037]\n",
      "[Epoch 78/100] [Batch 35/347] [D loss: 0.355662] [G loss: 0.358556]\n",
      "[Epoch 78/100] [Batch 36/347] [D loss: 0.378452] [G loss: 0.347044]\n",
      "[Epoch 78/100] [Batch 37/347] [D loss: 0.384186] [G loss: 0.332749]\n",
      "[Epoch 78/100] [Batch 38/347] [D loss: 0.383449] [G loss: 0.315094]\n",
      "[Epoch 78/100] [Batch 39/347] [D loss: 0.392010] [G loss: 0.306133]\n",
      "[Epoch 78/100] [Batch 40/347] [D loss: 0.419517] [G loss: 0.302765]\n",
      "[Epoch 78/100] [Batch 41/347] [D loss: 0.441602] [G loss: 0.298650]\n",
      "[Epoch 78/100] [Batch 42/347] [D loss: 0.438080] [G loss: 0.301102]\n",
      "[Epoch 78/100] [Batch 43/347] [D loss: 0.462967] [G loss: 0.310855]\n",
      "[Epoch 78/100] [Batch 44/347] [D loss: 0.447617] [G loss: 0.313584]\n",
      "[Epoch 78/100] [Batch 45/347] [D loss: 0.423781] [G loss: 0.304541]\n",
      "[Epoch 78/100] [Batch 46/347] [D loss: 0.353963] [G loss: 0.300696]\n",
      "[Epoch 78/100] [Batch 47/347] [D loss: 0.348727] [G loss: 0.301025]\n",
      "[Epoch 78/100] [Batch 48/347] [D loss: 0.283163] [G loss: 0.315566]\n",
      "[Epoch 78/100] [Batch 49/347] [D loss: 0.262015] [G loss: 0.342316]\n",
      "[Epoch 78/100] [Batch 50/347] [D loss: 0.245090] [G loss: 0.371513]\n",
      "[Epoch 78/100] [Batch 51/347] [D loss: 0.223988] [G loss: 0.393021]\n",
      "[Epoch 78/100] [Batch 52/347] [D loss: 0.311721] [G loss: 0.400635]\n",
      "[Epoch 78/100] [Batch 53/347] [D loss: 0.356974] [G loss: 0.395909]\n",
      "[Epoch 78/100] [Batch 54/347] [D loss: 0.343626] [G loss: 0.389100]\n",
      "[Epoch 78/100] [Batch 55/347] [D loss: 0.340394] [G loss: 0.393879]\n",
      "[Epoch 78/100] [Batch 56/347] [D loss: 0.331884] [G loss: 0.401635]\n",
      "[Epoch 78/100] [Batch 57/347] [D loss: 0.283343] [G loss: 0.407600]\n",
      "[Epoch 78/100] [Batch 58/347] [D loss: 0.287923] [G loss: 0.409181]\n",
      "[Epoch 78/100] [Batch 59/347] [D loss: 0.284210] [G loss: 0.400580]\n",
      "[Epoch 78/100] [Batch 60/347] [D loss: 0.267287] [G loss: 0.382347]\n",
      "[Epoch 78/100] [Batch 61/347] [D loss: 0.280174] [G loss: 0.362448]\n",
      "[Epoch 78/100] [Batch 62/347] [D loss: 0.280077] [G loss: 0.356333]\n",
      "[Epoch 78/100] [Batch 63/347] [D loss: 0.274926] [G loss: 0.351155]\n",
      "[Epoch 78/100] [Batch 64/347] [D loss: 0.264042] [G loss: 0.346334]\n",
      "[Epoch 78/100] [Batch 65/347] [D loss: 0.232050] [G loss: 0.351223]\n",
      "[Epoch 78/100] [Batch 66/347] [D loss: 0.232799] [G loss: 0.353477]\n",
      "[Epoch 78/100] [Batch 67/347] [D loss: 0.229170] [G loss: 0.348750]\n",
      "[Epoch 78/100] [Batch 68/347] [D loss: 0.225121] [G loss: 0.352475]\n",
      "[Epoch 78/100] [Batch 69/347] [D loss: 0.234226] [G loss: 0.356325]\n",
      "[Epoch 78/100] [Batch 70/347] [D loss: 0.229537] [G loss: 0.359511]\n",
      "[Epoch 78/100] [Batch 71/347] [D loss: 0.227879] [G loss: 0.376708]\n",
      "[Epoch 78/100] [Batch 72/347] [D loss: 0.234724] [G loss: 0.392241]\n",
      "[Epoch 78/100] [Batch 73/347] [D loss: 0.340728] [G loss: 0.390858]\n",
      "[Epoch 78/100] [Batch 74/347] [D loss: 0.343207] [G loss: 0.392890]\n",
      "[Epoch 78/100] [Batch 75/347] [D loss: 0.341262] [G loss: 0.392766]\n",
      "[Epoch 78/100] [Batch 76/347] [D loss: 0.338522] [G loss: 0.389133]\n",
      "[Epoch 78/100] [Batch 77/347] [D loss: 0.373078] [G loss: 0.384990]\n",
      "[Epoch 78/100] [Batch 78/347] [D loss: 0.422698] [G loss: 0.390707]\n",
      "[Epoch 78/100] [Batch 79/347] [D loss: 0.414932] [G loss: 0.383898]\n",
      "[Epoch 78/100] [Batch 80/347] [D loss: 0.313747] [G loss: 0.363874]\n",
      "[Epoch 78/100] [Batch 81/347] [D loss: 0.296696] [G loss: 0.354139]\n",
      "[Epoch 78/100] [Batch 82/347] [D loss: 0.297377] [G loss: 0.348821]\n",
      "[Epoch 78/100] [Batch 83/347] [D loss: 0.304265] [G loss: 0.342545]\n",
      "[Epoch 78/100] [Batch 84/347] [D loss: 0.422091] [G loss: 0.341954]\n",
      "[Epoch 78/100] [Batch 85/347] [D loss: 0.493380] [G loss: 0.337978]\n",
      "[Epoch 78/100] [Batch 86/347] [D loss: 0.495299] [G loss: 0.333559]\n",
      "[Epoch 78/100] [Batch 87/347] [D loss: 0.495766] [G loss: 0.330811]\n",
      "[Epoch 78/100] [Batch 88/347] [D loss: 0.518605] [G loss: 0.328590]\n",
      "[Epoch 78/100] [Batch 89/347] [D loss: 0.529367] [G loss: 0.328724]\n",
      "[Epoch 78/100] [Batch 90/347] [D loss: 0.526966] [G loss: 0.326993]\n",
      "[Epoch 78/100] [Batch 91/347] [D loss: 0.529069] [G loss: 0.325672]\n",
      "[Epoch 78/100] [Batch 92/347] [D loss: 0.532092] [G loss: 0.326177]\n",
      "[Epoch 78/100] [Batch 93/347] [D loss: 0.532638] [G loss: 0.327510]\n",
      "[Epoch 78/100] [Batch 94/347] [D loss: 0.514322] [G loss: 0.325725]\n",
      "[Epoch 78/100] [Batch 95/347] [D loss: 0.504058] [G loss: 0.326782]\n",
      "[Epoch 78/100] [Batch 96/347] [D loss: 0.504261] [G loss: 0.330334]\n",
      "[Epoch 78/100] [Batch 97/347] [D loss: 0.497868] [G loss: 0.332732]\n",
      "[Epoch 78/100] [Batch 98/347] [D loss: 0.481431] [G loss: 0.337921]\n",
      "[Epoch 78/100] [Batch 99/347] [D loss: 0.485605] [G loss: 0.342488]\n",
      "[Epoch 78/100] [Batch 100/347] [D loss: 0.487096] [G loss: 0.346034]\n",
      "[Epoch 78/100] [Batch 101/347] [D loss: 0.495371] [G loss: 0.348498]\n",
      "[Epoch 78/100] [Batch 102/347] [D loss: 0.545394] [G loss: 0.350317]\n",
      "[Epoch 78/100] [Batch 103/347] [D loss: 0.551921] [G loss: 0.357647]\n",
      "[Epoch 78/100] [Batch 104/347] [D loss: 0.524728] [G loss: 0.358421]\n",
      "[Epoch 78/100] [Batch 105/347] [D loss: 0.441939] [G loss: 0.359701]\n",
      "[Epoch 78/100] [Batch 106/347] [D loss: 0.260615] [G loss: 0.367480]\n",
      "[Epoch 78/100] [Batch 107/347] [D loss: 0.237768] [G loss: 0.391977]\n",
      "[Epoch 78/100] [Batch 108/347] [D loss: 0.221248] [G loss: 0.417716]\n",
      "[Epoch 78/100] [Batch 109/347] [D loss: 0.195152] [G loss: 0.443986]\n",
      "[Epoch 78/100] [Batch 110/347] [D loss: 0.207459] [G loss: 0.458557]\n",
      "[Epoch 78/100] [Batch 111/347] [D loss: 0.211173] [G loss: 0.475915]\n",
      "[Epoch 78/100] [Batch 112/347] [D loss: 0.216992] [G loss: 0.488853]\n",
      "[Epoch 78/100] [Batch 113/347] [D loss: 0.416676] [G loss: 0.513106]\n",
      "[Epoch 78/100] [Batch 114/347] [D loss: 0.497115] [G loss: 0.523479]\n",
      "[Epoch 78/100] [Batch 115/347] [D loss: 0.500496] [G loss: 0.508998]\n",
      "[Epoch 78/100] [Batch 116/347] [D loss: 0.457431] [G loss: 0.492478]\n",
      "[Epoch 78/100] [Batch 117/347] [D loss: 0.455261] [G loss: 0.479777]\n",
      "[Epoch 78/100] [Batch 118/347] [D loss: 0.391803] [G loss: 0.466305]\n",
      "[Epoch 78/100] [Batch 119/347] [D loss: 0.377803] [G loss: 0.456603]\n",
      "[Epoch 78/100] [Batch 120/347] [D loss: 0.352413] [G loss: 0.452613]\n",
      "[Epoch 78/100] [Batch 121/347] [D loss: 0.329961] [G loss: 0.436503]\n",
      "[Epoch 78/100] [Batch 122/347] [D loss: 0.435975] [G loss: 0.420833]\n",
      "[Epoch 78/100] [Batch 123/347] [D loss: 0.482308] [G loss: 0.403197]\n",
      "[Epoch 78/100] [Batch 124/347] [D loss: 0.400979] [G loss: 0.378911]\n",
      "[Epoch 78/100] [Batch 125/347] [D loss: 0.368790] [G loss: 0.361854]\n",
      "[Epoch 78/100] [Batch 126/347] [D loss: 0.338600] [G loss: 0.347554]\n",
      "[Epoch 78/100] [Batch 127/347] [D loss: 0.349115] [G loss: 0.335977]\n",
      "[Epoch 78/100] [Batch 128/347] [D loss: 0.344665] [G loss: 0.324966]\n",
      "[Epoch 78/100] [Batch 129/347] [D loss: 0.327686] [G loss: 0.325651]\n",
      "[Epoch 78/100] [Batch 130/347] [D loss: 0.317286] [G loss: 0.349171]\n",
      "[Epoch 78/100] [Batch 131/347] [D loss: 0.294001] [G loss: 0.378248]\n",
      "[Epoch 78/100] [Batch 132/347] [D loss: 0.254027] [G loss: 0.415565]\n",
      "[Epoch 78/100] [Batch 133/347] [D loss: 0.235590] [G loss: 0.452944]\n",
      "[Epoch 78/100] [Batch 134/347] [D loss: 0.193647] [G loss: 0.483442]\n",
      "[Epoch 78/100] [Batch 135/347] [D loss: 0.162295] [G loss: 0.502372]\n",
      "[Epoch 78/100] [Batch 136/347] [D loss: 0.149147] [G loss: 0.509169]\n",
      "[Epoch 78/100] [Batch 137/347] [D loss: 0.384543] [G loss: 0.509621]\n",
      "[Epoch 78/100] [Batch 138/347] [D loss: 0.425985] [G loss: 0.505888]\n",
      "[Epoch 78/100] [Batch 139/347] [D loss: 0.440222] [G loss: 0.497766]\n",
      "[Epoch 78/100] [Batch 140/347] [D loss: 0.457832] [G loss: 0.497438]\n",
      "[Epoch 78/100] [Batch 141/347] [D loss: 0.423805] [G loss: 0.491341]\n",
      "[Epoch 78/100] [Batch 142/347] [D loss: 0.431207] [G loss: 0.484499]\n",
      "[Epoch 78/100] [Batch 143/347] [D loss: 0.428438] [G loss: 0.474702]\n",
      "[Epoch 78/100] [Batch 144/347] [D loss: 0.412095] [G loss: 0.464449]\n",
      "[Epoch 78/100] [Batch 145/347] [D loss: 0.437970] [G loss: 0.462224]\n",
      "[Epoch 78/100] [Batch 146/347] [D loss: 0.443528] [G loss: 0.454171]\n",
      "[Epoch 78/100] [Batch 147/347] [D loss: 0.460418] [G loss: 0.445759]\n",
      "[Epoch 78/100] [Batch 148/347] [D loss: 0.464251] [G loss: 0.437846]\n",
      "[Epoch 78/100] [Batch 149/347] [D loss: 0.387646] [G loss: 0.421274]\n",
      "[Epoch 78/100] [Batch 150/347] [D loss: 0.343992] [G loss: 0.396525]\n",
      "[Epoch 78/100] [Batch 151/347] [D loss: 0.316399] [G loss: 0.365249]\n",
      "[Epoch 78/100] [Batch 152/347] [D loss: 0.299905] [G loss: 0.330650]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 78/100] [Batch 153/347] [D loss: 0.309375] [G loss: 0.297998]\n",
      "[Epoch 78/100] [Batch 154/347] [D loss: 0.318046] [G loss: 0.278832]\n",
      "[Epoch 78/100] [Batch 155/347] [D loss: 0.324511] [G loss: 0.274218]\n",
      "[Epoch 78/100] [Batch 156/347] [D loss: 0.328347] [G loss: 0.271455]\n",
      "[Epoch 78/100] [Batch 157/347] [D loss: 0.321858] [G loss: 0.280144]\n",
      "[Epoch 78/100] [Batch 158/347] [D loss: 0.307406] [G loss: 0.299336]\n",
      "[Epoch 78/100] [Batch 159/347] [D loss: 0.306179] [G loss: 0.322237]\n",
      "[Epoch 78/100] [Batch 160/347] [D loss: 0.279264] [G loss: 0.354546]\n",
      "[Epoch 78/100] [Batch 161/347] [D loss: 0.258540] [G loss: 0.382713]\n",
      "[Epoch 78/100] [Batch 162/347] [D loss: 0.241864] [G loss: 0.400637]\n",
      "[Epoch 78/100] [Batch 163/347] [D loss: 0.235901] [G loss: 0.408964]\n",
      "[Epoch 78/100] [Batch 164/347] [D loss: 0.236855] [G loss: 0.425044]\n",
      "[Epoch 78/100] [Batch 165/347] [D loss: 0.239094] [G loss: 0.441468]\n",
      "[Epoch 78/100] [Batch 166/347] [D loss: 0.247612] [G loss: 0.453070]\n",
      "[Epoch 78/100] [Batch 167/347] [D loss: 0.279012] [G loss: 0.472362]\n",
      "[Epoch 78/100] [Batch 168/347] [D loss: 0.281586] [G loss: 0.482803]\n",
      "[Epoch 78/100] [Batch 169/347] [D loss: 0.429412] [G loss: 0.490900]\n",
      "[Epoch 78/100] [Batch 170/347] [D loss: 0.504124] [G loss: 0.495193]\n",
      "[Epoch 78/100] [Batch 171/347] [D loss: 0.506028] [G loss: 0.491946]\n",
      "[Epoch 78/100] [Batch 172/347] [D loss: 0.502757] [G loss: 0.488984]\n",
      "[Epoch 78/100] [Batch 173/347] [D loss: 0.500920] [G loss: 0.481959]\n",
      "[Epoch 78/100] [Batch 174/347] [D loss: 0.490759] [G loss: 0.477632]\n",
      "[Epoch 78/100] [Batch 175/347] [D loss: 0.518344] [G loss: 0.473431]\n",
      "[Epoch 78/100] [Batch 176/347] [D loss: 0.543922] [G loss: 0.467517]\n",
      "[Epoch 78/100] [Batch 177/347] [D loss: 0.542220] [G loss: 0.456248]\n",
      "[Epoch 78/100] [Batch 178/347] [D loss: 0.538074] [G loss: 0.441869]\n",
      "[Epoch 78/100] [Batch 179/347] [D loss: 0.532883] [G loss: 0.429550]\n",
      "[Epoch 78/100] [Batch 180/347] [D loss: 0.529525] [G loss: 0.416372]\n",
      "[Epoch 78/100] [Batch 181/347] [D loss: 0.525677] [G loss: 0.409949]\n",
      "[Epoch 78/100] [Batch 182/347] [D loss: 0.528660] [G loss: 0.400102]\n",
      "[Epoch 78/100] [Batch 183/347] [D loss: 0.528902] [G loss: 0.391524]\n",
      "[Epoch 78/100] [Batch 184/347] [D loss: 0.555839] [G loss: 0.384791]\n",
      "[Epoch 78/100] [Batch 185/347] [D loss: 0.560512] [G loss: 0.374464]\n",
      "[Epoch 78/100] [Batch 186/347] [D loss: 0.546528] [G loss: 0.366376]\n",
      "[Epoch 78/100] [Batch 187/347] [D loss: 0.537137] [G loss: 0.358384]\n",
      "[Epoch 78/100] [Batch 188/347] [D loss: 0.498533] [G loss: 0.346385]\n",
      "[Epoch 78/100] [Batch 189/347] [D loss: 0.445953] [G loss: 0.338127]\n",
      "[Epoch 78/100] [Batch 190/347] [D loss: 0.440029] [G loss: 0.335761]\n",
      "[Epoch 78/100] [Batch 191/347] [D loss: 0.442246] [G loss: 0.334702]\n",
      "[Epoch 78/100] [Batch 192/347] [D loss: 0.454441] [G loss: 0.338369]\n",
      "[Epoch 78/100] [Batch 193/347] [D loss: 0.525577] [G loss: 0.343424]\n",
      "[Epoch 78/100] [Batch 194/347] [D loss: 0.517025] [G loss: 0.345408]\n",
      "[Epoch 78/100] [Batch 195/347] [D loss: 0.496311] [G loss: 0.348074]\n",
      "[Epoch 78/100] [Batch 196/347] [D loss: 0.449830] [G loss: 0.351596]\n",
      "[Epoch 78/100] [Batch 197/347] [D loss: 0.449618] [G loss: 0.357419]\n",
      "[Epoch 78/100] [Batch 198/347] [D loss: 0.448053] [G loss: 0.366774]\n",
      "[Epoch 78/100] [Batch 199/347] [D loss: 0.445427] [G loss: 0.371642]\n",
      "[Epoch 78/100] [Batch 200/347] [D loss: 0.499995] [G loss: 0.377934]\n",
      "[Epoch 78/100] [Batch 201/347] [D loss: 0.534047] [G loss: 0.382906]\n",
      "[Epoch 78/100] [Batch 202/347] [D loss: 0.538171] [G loss: 0.386799]\n",
      "[Epoch 78/100] [Batch 203/347] [D loss: 0.580087] [G loss: 0.392096]\n",
      "[Epoch 78/100] [Batch 204/347] [D loss: 0.571949] [G loss: 0.401255]\n",
      "[Epoch 78/100] [Batch 205/347] [D loss: 0.571207] [G loss: 0.412341]\n",
      "[Epoch 78/100] [Batch 206/347] [D loss: 0.567844] [G loss: 0.422573]\n",
      "[Epoch 78/100] [Batch 207/347] [D loss: 0.508824] [G loss: 0.430095]\n",
      "[Epoch 78/100] [Batch 208/347] [D loss: 0.496893] [G loss: 0.436611]\n",
      "[Epoch 78/100] [Batch 209/347] [D loss: 0.486748] [G loss: 0.433650]\n",
      "[Epoch 78/100] [Batch 210/347] [D loss: 0.391742] [G loss: 0.432781]\n",
      "[Epoch 78/100] [Batch 211/347] [D loss: 0.343282] [G loss: 0.426941]\n",
      "[Epoch 78/100] [Batch 212/347] [D loss: 0.217872] [G loss: 0.419652]\n",
      "[Epoch 78/100] [Batch 213/347] [D loss: 0.216726] [G loss: 0.429714]\n",
      "[Epoch 78/100] [Batch 214/347] [D loss: 0.212856] [G loss: 0.439763]\n",
      "[Epoch 78/100] [Batch 215/347] [D loss: 0.210891] [G loss: 0.452301]\n",
      "[Epoch 78/100] [Batch 216/347] [D loss: 0.389371] [G loss: 0.471087]\n",
      "[Epoch 78/100] [Batch 217/347] [D loss: 0.454113] [G loss: 0.490686]\n",
      "[Epoch 78/100] [Batch 218/347] [D loss: 0.508626] [G loss: 0.509493]\n",
      "[Epoch 78/100] [Batch 219/347] [D loss: 0.490865] [G loss: 0.518629]\n",
      "[Epoch 78/100] [Batch 220/347] [D loss: 0.486442] [G loss: 0.523592]\n",
      "[Epoch 78/100] [Batch 221/347] [D loss: 0.512932] [G loss: 0.523136]\n",
      "[Epoch 78/100] [Batch 222/347] [D loss: 0.515343] [G loss: 0.513524]\n",
      "[Epoch 78/100] [Batch 223/347] [D loss: 0.499232] [G loss: 0.491872]\n",
      "[Epoch 78/100] [Batch 224/347] [D loss: 0.506098] [G loss: 0.465953]\n",
      "[Epoch 78/100] [Batch 225/347] [D loss: 0.513069] [G loss: 0.442866]\n",
      "[Epoch 78/100] [Batch 226/347] [D loss: 0.519697] [G loss: 0.426248]\n",
      "[Epoch 78/100] [Batch 227/347] [D loss: 0.553470] [G loss: 0.420401]\n",
      "[Epoch 78/100] [Batch 228/347] [D loss: 0.568351] [G loss: 0.417881]\n",
      "[Epoch 78/100] [Batch 229/347] [D loss: 0.571244] [G loss: 0.416963]\n",
      "[Epoch 78/100] [Batch 230/347] [D loss: 0.579670] [G loss: 0.417567]\n",
      "[Epoch 78/100] [Batch 231/347] [D loss: 0.561808] [G loss: 0.410999]\n",
      "[Epoch 78/100] [Batch 232/347] [D loss: 0.547655] [G loss: 0.410158]\n",
      "[Epoch 78/100] [Batch 233/347] [D loss: 0.469447] [G loss: 0.414289]\n",
      "[Epoch 78/100] [Batch 234/347] [D loss: 0.427873] [G loss: 0.417638]\n",
      "[Epoch 78/100] [Batch 235/347] [D loss: 0.425208] [G loss: 0.427428]\n",
      "[Epoch 78/100] [Batch 236/347] [D loss: 0.420386] [G loss: 0.435639]\n",
      "[Epoch 78/100] [Batch 237/347] [D loss: 0.484995] [G loss: 0.440956]\n",
      "[Epoch 78/100] [Batch 238/347] [D loss: 0.568989] [G loss: 0.441481]\n",
      "[Epoch 78/100] [Batch 239/347] [D loss: 0.571902] [G loss: 0.441405]\n",
      "[Epoch 78/100] [Batch 240/347] [D loss: 0.572438] [G loss: 0.444524]\n",
      "[Epoch 78/100] [Batch 241/347] [D loss: 0.574864] [G loss: 0.451713]\n",
      "[Epoch 78/100] [Batch 242/347] [D loss: 0.587173] [G loss: 0.462605]\n",
      "[Epoch 78/100] [Batch 243/347] [D loss: 0.542634] [G loss: 0.473745]\n",
      "[Epoch 78/100] [Batch 244/347] [D loss: 0.510752] [G loss: 0.473948]\n",
      "[Epoch 78/100] [Batch 245/347] [D loss: 0.518750] [G loss: 0.469878]\n",
      "[Epoch 78/100] [Batch 246/347] [D loss: 0.516034] [G loss: 0.462991]\n",
      "[Epoch 78/100] [Batch 247/347] [D loss: 0.543990] [G loss: 0.459739]\n",
      "[Epoch 78/100] [Batch 248/347] [D loss: 0.562941] [G loss: 0.468311]\n",
      "[Epoch 78/100] [Batch 249/347] [D loss: 0.549746] [G loss: 0.479052]\n",
      "[Epoch 78/100] [Batch 250/347] [D loss: 0.545592] [G loss: 0.493133]\n",
      "[Epoch 78/100] [Batch 251/347] [D loss: 0.538070] [G loss: 0.510215]\n",
      "[Epoch 78/100] [Batch 252/347] [D loss: 0.533569] [G loss: 0.520827]\n",
      "[Epoch 78/100] [Batch 253/347] [D loss: 0.489821] [G loss: 0.517029]\n",
      "[Epoch 78/100] [Batch 254/347] [D loss: 0.492436] [G loss: 0.522220]\n",
      "[Epoch 78/100] [Batch 255/347] [D loss: 0.487612] [G loss: 0.521977]\n",
      "[Epoch 78/100] [Batch 256/347] [D loss: 0.491863] [G loss: 0.512054]\n",
      "[Epoch 78/100] [Batch 257/347] [D loss: 0.475485] [G loss: 0.504546]\n",
      "[Epoch 78/100] [Batch 258/347] [D loss: 0.433630] [G loss: 0.494511]\n",
      "[Epoch 78/100] [Batch 259/347] [D loss: 0.431564] [G loss: 0.479688]\n",
      "[Epoch 78/100] [Batch 260/347] [D loss: 0.427151] [G loss: 0.463849]\n",
      "[Epoch 78/100] [Batch 261/347] [D loss: 0.410847] [G loss: 0.453191]\n",
      "[Epoch 78/100] [Batch 262/347] [D loss: 0.356296] [G loss: 0.438716]\n",
      "[Epoch 78/100] [Batch 263/347] [D loss: 0.355062] [G loss: 0.424155]\n",
      "[Epoch 78/100] [Batch 264/347] [D loss: 0.359038] [G loss: 0.414810]\n",
      "[Epoch 78/100] [Batch 265/347] [D loss: 0.373886] [G loss: 0.407745]\n",
      "[Epoch 78/100] [Batch 266/347] [D loss: 0.445475] [G loss: 0.404679]\n",
      "[Epoch 78/100] [Batch 267/347] [D loss: 0.466573] [G loss: 0.403060]\n",
      "[Epoch 78/100] [Batch 268/347] [D loss: 0.472698] [G loss: 0.402308]\n",
      "[Epoch 78/100] [Batch 269/347] [D loss: 0.476274] [G loss: 0.402690]\n",
      "[Epoch 78/100] [Batch 270/347] [D loss: 0.505763] [G loss: 0.404296]\n",
      "[Epoch 78/100] [Batch 271/347] [D loss: 0.464401] [G loss: 0.413303]\n",
      "[Epoch 78/100] [Batch 272/347] [D loss: 0.432031] [G loss: 0.444182]\n",
      "[Epoch 78/100] [Batch 273/347] [D loss: 0.376807] [G loss: 0.479545]\n",
      "[Epoch 78/100] [Batch 274/347] [D loss: 0.318849] [G loss: 0.513121]\n",
      "[Epoch 78/100] [Batch 275/347] [D loss: 0.250435] [G loss: 0.540335]\n",
      "[Epoch 78/100] [Batch 276/347] [D loss: 0.508726] [G loss: 0.551063]\n",
      "[Epoch 78/100] [Batch 277/347] [D loss: 0.531089] [G loss: 0.567232]\n",
      "[Epoch 78/100] [Batch 278/347] [D loss: 0.532876] [G loss: 0.580326]\n",
      "[Epoch 78/100] [Batch 279/347] [D loss: 0.535625] [G loss: 0.584420]\n",
      "[Epoch 78/100] [Batch 280/347] [D loss: 0.537608] [G loss: 0.585766]\n",
      "[Epoch 78/100] [Batch 281/347] [D loss: 0.541497] [G loss: 0.586571]\n",
      "[Epoch 78/100] [Batch 282/347] [D loss: 0.542442] [G loss: 0.590217]\n",
      "[Epoch 78/100] [Batch 283/347] [D loss: 0.543248] [G loss: 0.591714]\n",
      "[Epoch 78/100] [Batch 284/347] [D loss: 0.543976] [G loss: 0.594126]\n",
      "[Epoch 78/100] [Batch 285/347] [D loss: 0.546946] [G loss: 0.595144]\n",
      "[Epoch 78/100] [Batch 286/347] [D loss: 0.546072] [G loss: 0.581048]\n",
      "[Epoch 78/100] [Batch 287/347] [D loss: 0.546790] [G loss: 0.578290]\n",
      "[Epoch 78/100] [Batch 288/347] [D loss: 0.546897] [G loss: 0.575457]\n",
      "[Epoch 78/100] [Batch 289/347] [D loss: 0.546131] [G loss: 0.570300]\n",
      "[Epoch 78/100] [Batch 290/347] [D loss: 0.545921] [G loss: 0.586295]\n",
      "[Epoch 78/100] [Batch 291/347] [D loss: 0.545138] [G loss: 0.593165]\n",
      "[Epoch 78/100] [Batch 292/347] [D loss: 0.543559] [G loss: 0.596853]\n",
      "[Epoch 78/100] [Batch 293/347] [D loss: 0.525125] [G loss: 0.602427]\n",
      "[Epoch 78/100] [Batch 294/347] [D loss: 0.524757] [G loss: 0.606568]\n",
      "[Epoch 78/100] [Batch 295/347] [D loss: 0.524824] [G loss: 0.605186]\n",
      "[Epoch 78/100] [Batch 296/347] [D loss: 0.524495] [G loss: 0.603578]\n",
      "[Epoch 78/100] [Batch 297/347] [D loss: 0.542136] [G loss: 0.607969]\n",
      "[Epoch 78/100] [Batch 298/347] [D loss: 0.545173] [G loss: 0.601287]\n",
      "[Epoch 78/100] [Batch 299/347] [D loss: 0.544982] [G loss: 0.596681]\n",
      "[Epoch 78/100] [Batch 300/347] [D loss: 0.544297] [G loss: 0.594598]\n",
      "[Epoch 78/100] [Batch 301/347] [D loss: 0.544692] [G loss: 0.583219]\n",
      "[Epoch 78/100] [Batch 302/347] [D loss: 0.545118] [G loss: 0.574483]\n",
      "[Epoch 78/100] [Batch 303/347] [D loss: 0.544565] [G loss: 0.559533]\n",
      "[Epoch 78/100] [Batch 304/347] [D loss: 0.530235] [G loss: 0.547541]\n",
      "[Epoch 78/100] [Batch 305/347] [D loss: 0.518680] [G loss: 0.544817]\n",
      "[Epoch 78/100] [Batch 306/347] [D loss: 0.517489] [G loss: 0.546398]\n",
      "[Epoch 78/100] [Batch 307/347] [D loss: 0.515157] [G loss: 0.552528]\n",
      "[Epoch 78/100] [Batch 308/347] [D loss: 0.522214] [G loss: 0.553610]\n",
      "[Epoch 78/100] [Batch 309/347] [D loss: 0.540192] [G loss: 0.568121]\n",
      "[Epoch 78/100] [Batch 310/347] [D loss: 0.549024] [G loss: 0.580227]\n",
      "[Epoch 78/100] [Batch 311/347] [D loss: 0.545557] [G loss: 0.577395]\n",
      "[Epoch 78/100] [Batch 312/347] [D loss: 0.538353] [G loss: 0.571851]\n",
      "[Epoch 78/100] [Batch 313/347] [D loss: 0.534424] [G loss: 0.562161]\n",
      "[Epoch 78/100] [Batch 314/347] [D loss: 0.533655] [G loss: 0.546946]\n",
      "[Epoch 78/100] [Batch 315/347] [D loss: 0.533354] [G loss: 0.535378]\n",
      "[Epoch 78/100] [Batch 316/347] [D loss: 0.535189] [G loss: 0.536112]\n",
      "[Epoch 78/100] [Batch 317/347] [D loss: 0.536455] [G loss: 0.539326]\n",
      "[Epoch 78/100] [Batch 318/347] [D loss: 0.536486] [G loss: 0.552510]\n",
      "[Epoch 78/100] [Batch 319/347] [D loss: 0.533391] [G loss: 0.564474]\n",
      "[Epoch 78/100] [Batch 320/347] [D loss: 0.532255] [G loss: 0.562394]\n",
      "[Epoch 78/100] [Batch 321/347] [D loss: 0.529640] [G loss: 0.555179]\n",
      "[Epoch 78/100] [Batch 322/347] [D loss: 0.530402] [G loss: 0.546736]\n",
      "[Epoch 78/100] [Batch 323/347] [D loss: 0.522089] [G loss: 0.537221]\n",
      "[Epoch 78/100] [Batch 324/347] [D loss: 0.520411] [G loss: 0.530721]\n",
      "[Epoch 78/100] [Batch 325/347] [D loss: 0.519954] [G loss: 0.524776]\n",
      "[Epoch 78/100] [Batch 326/347] [D loss: 0.519410] [G loss: 0.518960]\n",
      "[Epoch 78/100] [Batch 327/347] [D loss: 0.516528] [G loss: 0.513695]\n",
      "[Epoch 78/100] [Batch 328/347] [D loss: 0.516381] [G loss: 0.507632]\n",
      "[Epoch 78/100] [Batch 329/347] [D loss: 0.514971] [G loss: 0.504642]\n",
      "[Epoch 78/100] [Batch 330/347] [D loss: 0.513342] [G loss: 0.503369]\n",
      "[Epoch 78/100] [Batch 331/347] [D loss: 0.515131] [G loss: 0.504297]\n",
      "[Epoch 78/100] [Batch 332/347] [D loss: 0.524920] [G loss: 0.521385]\n",
      "[Epoch 78/100] [Batch 333/347] [D loss: 0.519193] [G loss: 0.518100]\n",
      "[Epoch 78/100] [Batch 334/347] [D loss: 0.517376] [G loss: 0.509531]\n",
      "[Epoch 78/100] [Batch 335/347] [D loss: 0.516536] [G loss: 0.505499]\n",
      "[Epoch 78/100] [Batch 336/347] [D loss: 0.515649] [G loss: 0.501985]\n",
      "[Epoch 78/100] [Batch 337/347] [D loss: 0.521276] [G loss: 0.504265]\n",
      "[Epoch 78/100] [Batch 338/347] [D loss: 0.525834] [G loss: 0.510555]\n",
      "[Epoch 78/100] [Batch 339/347] [D loss: 0.521794] [G loss: 0.509112]\n",
      "[Epoch 78/100] [Batch 340/347] [D loss: 0.516419] [G loss: 0.503632]\n",
      "[Epoch 78/100] [Batch 341/347] [D loss: 0.517094] [G loss: 0.501816]\n",
      "[Epoch 78/100] [Batch 342/347] [D loss: 0.494947] [G loss: 0.487461]\n",
      "[Epoch 78/100] [Batch 343/347] [D loss: 0.487720] [G loss: 0.470017]\n",
      "[Epoch 78/100] [Batch 344/347] [D loss: 0.448762] [G loss: 0.464825]\n",
      "[Epoch 78/100] [Batch 345/347] [D loss: 0.358922] [G loss: 0.459777]\n",
      "[Epoch 78/100] [Batch 346/347] [D loss: 0.345360] [G loss: 0.455931]\n",
      "[Epoch 78/100] [Batch 347/347] [D loss: 0.325811] [G loss: 0.451890]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 1/347] [D loss: 0.506122] [G loss: 0.459193]\n",
      "[Epoch 79/100] [Batch 2/347] [D loss: 0.508752] [G loss: 0.455124]\n",
      "[Epoch 79/100] [Batch 3/347] [D loss: 0.514980] [G loss: 0.454902]\n",
      "[Epoch 79/100] [Batch 4/347] [D loss: 0.515067] [G loss: 0.451030]\n",
      "[Epoch 79/100] [Batch 5/347] [D loss: 0.514828] [G loss: 0.443247]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 6/347] [D loss: 0.505078] [G loss: 0.436325]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 7/347] [D loss: 0.494338] [G loss: 0.423476]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 8/347] [D loss: 0.492036] [G loss: 0.417938]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 9/347] [D loss: 0.486760] [G loss: 0.414286]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 10/347] [D loss: 0.485756] [G loss: 0.410378]\n",
      "[Epoch 79/100] [Batch 11/347] [D loss: 0.500326] [G loss: 0.414356]\n",
      "[Epoch 79/100] [Batch 12/347] [D loss: 0.504641] [G loss: 0.411246]\n",
      "[Epoch 79/100] [Batch 13/347] [D loss: 0.489416] [G loss: 0.404225]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 14/347] [D loss: 0.471644] [G loss: 0.396718]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 15/347] [D loss: 0.468005] [G loss: 0.379038]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 16/347] [D loss: 0.458207] [G loss: 0.363522]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 17/347] [D loss: 0.457583] [G loss: 0.355263]\n",
      "[Epoch 79/100] [Batch 18/347] [D loss: 0.463464] [G loss: 0.343625]\n",
      "[Epoch 79/100] [Batch 19/347] [D loss: 0.459136] [G loss: 0.335746]\n",
      "[Epoch 79/100] [Batch 20/347] [D loss: 0.475226] [G loss: 0.328276]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 21/347] [D loss: 0.416878] [G loss: 0.312335]\n",
      "[Epoch 79/100] [Batch 22/347] [D loss: 0.418711] [G loss: 0.301361]\n",
      "[Epoch 79/100] [Batch 23/347] [D loss: 0.422567] [G loss: 0.291024]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 24/347] [D loss: 0.393147] [G loss: 0.280391]\n",
      "[Epoch 79/100] [Batch 25/347] [D loss: 0.322153] [G loss: 0.290081]\n",
      "[Epoch 79/100] [Batch 26/347] [D loss: 0.319544] [G loss: 0.298416]\n",
      "[Epoch 79/100] [Batch 27/347] [D loss: 0.313639] [G loss: 0.314540]\n",
      "[Epoch 79/100] [Batch 28/347] [D loss: 0.308187] [G loss: 0.334374]\n",
      "[Epoch 79/100] [Batch 29/347] [D loss: 0.319175] [G loss: 0.351712]\n",
      "[Epoch 79/100] [Batch 30/347] [D loss: 0.307910] [G loss: 0.365169]\n",
      "[Epoch 79/100] [Batch 31/347] [D loss: 0.305600] [G loss: 0.375476]\n",
      "[Epoch 79/100] [Batch 32/347] [D loss: 0.313947] [G loss: 0.379867]\n",
      "[Epoch 79/100] [Batch 33/347] [D loss: 0.329421] [G loss: 0.383314]\n",
      "[Epoch 79/100] [Batch 34/347] [D loss: 0.372018] [G loss: 0.381414]\n",
      "[Epoch 79/100] [Batch 35/347] [D loss: 0.374790] [G loss: 0.375874]\n",
      "[Epoch 79/100] [Batch 36/347] [D loss: 0.400828] [G loss: 0.367655]\n",
      "[Epoch 79/100] [Batch 37/347] [D loss: 0.407220] [G loss: 0.356702]\n",
      "[Epoch 79/100] [Batch 38/347] [D loss: 0.405438] [G loss: 0.341856]\n",
      "[Epoch 79/100] [Batch 39/347] [D loss: 0.410300] [G loss: 0.333317]\n",
      "[Epoch 79/100] [Batch 40/347] [D loss: 0.432658] [G loss: 0.330062]\n",
      "[Epoch 79/100] [Batch 41/347] [D loss: 0.449728] [G loss: 0.322558]\n",
      "[Epoch 79/100] [Batch 42/347] [D loss: 0.444560] [G loss: 0.321131]\n",
      "[Epoch 79/100] [Batch 43/347] [D loss: 0.466971] [G loss: 0.326945]\n",
      "[Epoch 79/100] [Batch 44/347] [D loss: 0.451242] [G loss: 0.325114]\n",
      "[Epoch 79/100] [Batch 45/347] [D loss: 0.427522] [G loss: 0.311076]\n",
      "[Epoch 79/100] [Batch 46/347] [D loss: 0.359094] [G loss: 0.302576]\n",
      "[Epoch 79/100] [Batch 47/347] [D loss: 0.355708] [G loss: 0.297457]\n",
      "[Epoch 79/100] [Batch 48/347] [D loss: 0.290824] [G loss: 0.308089]\n",
      "[Epoch 79/100] [Batch 49/347] [D loss: 0.274472] [G loss: 0.330235]\n",
      "[Epoch 79/100] [Batch 50/347] [D loss: 0.260699] [G loss: 0.357573]\n",
      "[Epoch 79/100] [Batch 51/347] [D loss: 0.240081] [G loss: 0.379662]\n",
      "[Epoch 79/100] [Batch 52/347] [D loss: 0.315811] [G loss: 0.389115]\n",
      "[Epoch 79/100] [Batch 53/347] [D loss: 0.354263] [G loss: 0.385912]\n",
      "[Epoch 79/100] [Batch 54/347] [D loss: 0.340308] [G loss: 0.380603]\n",
      "[Epoch 79/100] [Batch 55/347] [D loss: 0.337383] [G loss: 0.386835]\n",
      "[Epoch 79/100] [Batch 56/347] [D loss: 0.331379] [G loss: 0.395672]\n",
      "[Epoch 79/100] [Batch 57/347] [D loss: 0.286519] [G loss: 0.403027]\n",
      "[Epoch 79/100] [Batch 58/347] [D loss: 0.293155] [G loss: 0.406189]\n",
      "[Epoch 79/100] [Batch 59/347] [D loss: 0.291059] [G loss: 0.400083]\n",
      "[Epoch 79/100] [Batch 60/347] [D loss: 0.276347] [G loss: 0.384481]\n",
      "[Epoch 79/100] [Batch 61/347] [D loss: 0.289704] [G loss: 0.367162]\n",
      "[Epoch 79/100] [Batch 62/347] [D loss: 0.288400] [G loss: 0.362648]\n",
      "[Epoch 79/100] [Batch 63/347] [D loss: 0.281754] [G loss: 0.359058]\n",
      "[Epoch 79/100] [Batch 64/347] [D loss: 0.266740] [G loss: 0.353992]\n",
      "[Epoch 79/100] [Batch 65/347] [D loss: 0.230166] [G loss: 0.357702]\n",
      "[Epoch 79/100] [Batch 66/347] [D loss: 0.231719] [G loss: 0.358290]\n",
      "[Epoch 79/100] [Batch 67/347] [D loss: 0.229762] [G loss: 0.350560]\n",
      "[Epoch 79/100] [Batch 68/347] [D loss: 0.228777] [G loss: 0.350750]\n",
      "[Epoch 79/100] [Batch 69/347] [D loss: 0.240081] [G loss: 0.353167]\n",
      "[Epoch 79/100] [Batch 70/347] [D loss: 0.236004] [G loss: 0.353934]\n",
      "[Epoch 79/100] [Batch 71/347] [D loss: 0.233911] [G loss: 0.370243]\n",
      "[Epoch 79/100] [Batch 72/347] [D loss: 0.239765] [G loss: 0.385336]\n",
      "[Epoch 79/100] [Batch 73/347] [D loss: 0.340225] [G loss: 0.383893]\n",
      "[Epoch 79/100] [Batch 74/347] [D loss: 0.342019] [G loss: 0.385559]\n",
      "[Epoch 79/100] [Batch 75/347] [D loss: 0.339477] [G loss: 0.385478]\n",
      "[Epoch 79/100] [Batch 76/347] [D loss: 0.336818] [G loss: 0.383079]\n",
      "[Epoch 79/100] [Batch 77/347] [D loss: 0.369945] [G loss: 0.379257]\n",
      "[Epoch 79/100] [Batch 78/347] [D loss: 0.417145] [G loss: 0.385756]\n",
      "[Epoch 79/100] [Batch 79/347] [D loss: 0.410925] [G loss: 0.381508]\n",
      "[Epoch 79/100] [Batch 80/347] [D loss: 0.314715] [G loss: 0.362494]\n",
      "[Epoch 79/100] [Batch 81/347] [D loss: 0.297909] [G loss: 0.355444]\n",
      "[Epoch 79/100] [Batch 82/347] [D loss: 0.298155] [G loss: 0.350978]\n",
      "[Epoch 79/100] [Batch 83/347] [D loss: 0.303702] [G loss: 0.345990]\n",
      "[Epoch 79/100] [Batch 84/347] [D loss: 0.419101] [G loss: 0.346723]\n",
      "[Epoch 79/100] [Batch 85/347] [D loss: 0.488620] [G loss: 0.343750]\n",
      "[Epoch 79/100] [Batch 86/347] [D loss: 0.490287] [G loss: 0.340518]\n",
      "[Epoch 79/100] [Batch 87/347] [D loss: 0.490458] [G loss: 0.338167]\n",
      "[Epoch 79/100] [Batch 88/347] [D loss: 0.512118] [G loss: 0.336407]\n",
      "[Epoch 79/100] [Batch 89/347] [D loss: 0.521916] [G loss: 0.336185]\n",
      "[Epoch 79/100] [Batch 90/347] [D loss: 0.519599] [G loss: 0.333970]\n",
      "[Epoch 79/100] [Batch 91/347] [D loss: 0.521717] [G loss: 0.332008]\n",
      "[Epoch 79/100] [Batch 92/347] [D loss: 0.524855] [G loss: 0.332511]\n",
      "[Epoch 79/100] [Batch 93/347] [D loss: 0.525233] [G loss: 0.333423]\n",
      "[Epoch 79/100] [Batch 94/347] [D loss: 0.507491] [G loss: 0.330912]\n",
      "[Epoch 79/100] [Batch 95/347] [D loss: 0.497363] [G loss: 0.331673]\n",
      "[Epoch 79/100] [Batch 96/347] [D loss: 0.497184] [G loss: 0.335439]\n",
      "[Epoch 79/100] [Batch 97/347] [D loss: 0.490883] [G loss: 0.337346]\n",
      "[Epoch 79/100] [Batch 98/347] [D loss: 0.474107] [G loss: 0.341385]\n",
      "[Epoch 79/100] [Batch 99/347] [D loss: 0.477152] [G loss: 0.344182]\n",
      "[Epoch 79/100] [Batch 100/347] [D loss: 0.478547] [G loss: 0.346901]\n",
      "[Epoch 79/100] [Batch 101/347] [D loss: 0.485944] [G loss: 0.347498]\n",
      "[Epoch 79/100] [Batch 102/347] [D loss: 0.537369] [G loss: 0.348884]\n",
      "[Epoch 79/100] [Batch 103/347] [D loss: 0.542526] [G loss: 0.354852]\n",
      "[Epoch 79/100] [Batch 104/347] [D loss: 0.516809] [G loss: 0.354301]\n",
      "[Epoch 79/100] [Batch 105/347] [D loss: 0.435891] [G loss: 0.354478]\n",
      "[Epoch 79/100] [Batch 106/347] [D loss: 0.260951] [G loss: 0.361898]\n",
      "[Epoch 79/100] [Batch 107/347] [D loss: 0.239099] [G loss: 0.386827]\n",
      "[Epoch 79/100] [Batch 108/347] [D loss: 0.223423] [G loss: 0.412819]\n",
      "[Epoch 79/100] [Batch 109/347] [D loss: 0.197451] [G loss: 0.437697]\n",
      "[Epoch 79/100] [Batch 110/347] [D loss: 0.208318] [G loss: 0.449668]\n",
      "[Epoch 79/100] [Batch 111/347] [D loss: 0.210991] [G loss: 0.466761]\n",
      "[Epoch 79/100] [Batch 112/347] [D loss: 0.216262] [G loss: 0.479113]\n",
      "[Epoch 79/100] [Batch 113/347] [D loss: 0.409782] [G loss: 0.503002]\n",
      "[Epoch 79/100] [Batch 114/347] [D loss: 0.488623] [G loss: 0.513144]\n",
      "[Epoch 79/100] [Batch 115/347] [D loss: 0.492009] [G loss: 0.498425]\n",
      "[Epoch 79/100] [Batch 116/347] [D loss: 0.446211] [G loss: 0.481464]\n",
      "[Epoch 79/100] [Batch 117/347] [D loss: 0.440973] [G loss: 0.468345]\n",
      "[Epoch 79/100] [Batch 118/347] [D loss: 0.375553] [G loss: 0.456357]\n",
      "[Epoch 79/100] [Batch 119/347] [D loss: 0.360232] [G loss: 0.445761]\n",
      "[Epoch 79/100] [Batch 120/347] [D loss: 0.337114] [G loss: 0.440668]\n",
      "[Epoch 79/100] [Batch 121/347] [D loss: 0.316954] [G loss: 0.425175]\n",
      "[Epoch 79/100] [Batch 122/347] [D loss: 0.424167] [G loss: 0.409757]\n",
      "[Epoch 79/100] [Batch 123/347] [D loss: 0.468582] [G loss: 0.392161]\n",
      "[Epoch 79/100] [Batch 124/347] [D loss: 0.392750] [G loss: 0.368919]\n",
      "[Epoch 79/100] [Batch 125/347] [D loss: 0.363575] [G loss: 0.353600]\n",
      "[Epoch 79/100] [Batch 126/347] [D loss: 0.336176] [G loss: 0.342864]\n",
      "[Epoch 79/100] [Batch 127/347] [D loss: 0.344646] [G loss: 0.333090]\n",
      "[Epoch 79/100] [Batch 128/347] [D loss: 0.340274] [G loss: 0.323402]\n",
      "[Epoch 79/100] [Batch 129/347] [D loss: 0.322287] [G loss: 0.327061]\n",
      "[Epoch 79/100] [Batch 130/347] [D loss: 0.308428] [G loss: 0.350926]\n",
      "[Epoch 79/100] [Batch 131/347] [D loss: 0.284737] [G loss: 0.378497]\n",
      "[Epoch 79/100] [Batch 132/347] [D loss: 0.247611] [G loss: 0.414273]\n",
      "[Epoch 79/100] [Batch 133/347] [D loss: 0.230028] [G loss: 0.449284]\n",
      "[Epoch 79/100] [Batch 134/347] [D loss: 0.191851] [G loss: 0.477238]\n",
      "[Epoch 79/100] [Batch 135/347] [D loss: 0.163436] [G loss: 0.494532]\n",
      "[Epoch 79/100] [Batch 136/347] [D loss: 0.151286] [G loss: 0.500128]\n",
      "[Epoch 79/100] [Batch 137/347] [D loss: 0.375796] [G loss: 0.500184]\n",
      "[Epoch 79/100] [Batch 138/347] [D loss: 0.413451] [G loss: 0.496177]\n",
      "[Epoch 79/100] [Batch 139/347] [D loss: 0.429394] [G loss: 0.487972]\n",
      "[Epoch 79/100] [Batch 140/347] [D loss: 0.444615] [G loss: 0.487498]\n",
      "[Epoch 79/100] [Batch 141/347] [D loss: 0.407643] [G loss: 0.481161]\n",
      "[Epoch 79/100] [Batch 142/347] [D loss: 0.414807] [G loss: 0.474221]\n",
      "[Epoch 79/100] [Batch 143/347] [D loss: 0.409964] [G loss: 0.463952]\n",
      "[Epoch 79/100] [Batch 144/347] [D loss: 0.391700] [G loss: 0.453336]\n",
      "[Epoch 79/100] [Batch 145/347] [D loss: 0.417077] [G loss: 0.450464]\n",
      "[Epoch 79/100] [Batch 146/347] [D loss: 0.420433] [G loss: 0.441181]\n",
      "[Epoch 79/100] [Batch 147/347] [D loss: 0.436094] [G loss: 0.429930]\n",
      "[Epoch 79/100] [Batch 148/347] [D loss: 0.437770] [G loss: 0.418158]\n",
      "[Epoch 79/100] [Batch 149/347] [D loss: 0.359780] [G loss: 0.396446]\n",
      "[Epoch 79/100] [Batch 150/347] [D loss: 0.322855] [G loss: 0.368754]\n",
      "[Epoch 79/100] [Batch 151/347] [D loss: 0.305732] [G loss: 0.337894]\n",
      "[Epoch 79/100] [Batch 152/347] [D loss: 0.299986] [G loss: 0.305619]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 79/100] [Batch 153/347] [D loss: 0.313737] [G loss: 0.279139]\n",
      "[Epoch 79/100] [Batch 154/347] [D loss: 0.323436] [G loss: 0.265598]\n",
      "[Epoch 79/100] [Batch 155/347] [D loss: 0.328043] [G loss: 0.266668]\n",
      "[Epoch 79/100] [Batch 156/347] [D loss: 0.327738] [G loss: 0.269612]\n",
      "[Epoch 79/100] [Batch 157/347] [D loss: 0.316505] [G loss: 0.282712]\n",
      "[Epoch 79/100] [Batch 158/347] [D loss: 0.297519] [G loss: 0.306537]\n",
      "[Epoch 79/100] [Batch 159/347] [D loss: 0.291864] [G loss: 0.332365]\n",
      "[Epoch 79/100] [Batch 160/347] [D loss: 0.265087] [G loss: 0.364638]\n",
      "[Epoch 79/100] [Batch 161/347] [D loss: 0.245902] [G loss: 0.392973]\n",
      "[Epoch 79/100] [Batch 162/347] [D loss: 0.232591] [G loss: 0.409016]\n",
      "[Epoch 79/100] [Batch 163/347] [D loss: 0.230607] [G loss: 0.414266]\n",
      "[Epoch 79/100] [Batch 164/347] [D loss: 0.233768] [G loss: 0.427408]\n",
      "[Epoch 79/100] [Batch 165/347] [D loss: 0.237786] [G loss: 0.441782]\n",
      "[Epoch 79/100] [Batch 166/347] [D loss: 0.244991] [G loss: 0.451713]\n",
      "[Epoch 79/100] [Batch 167/347] [D loss: 0.275318] [G loss: 0.468689]\n",
      "[Epoch 79/100] [Batch 168/347] [D loss: 0.275823] [G loss: 0.477956]\n",
      "[Epoch 79/100] [Batch 169/347] [D loss: 0.421401] [G loss: 0.485166]\n",
      "[Epoch 79/100] [Batch 170/347] [D loss: 0.493885] [G loss: 0.488400]\n",
      "[Epoch 79/100] [Batch 171/347] [D loss: 0.494569] [G loss: 0.483628]\n",
      "[Epoch 79/100] [Batch 172/347] [D loss: 0.488254] [G loss: 0.478999]\n",
      "[Epoch 79/100] [Batch 173/347] [D loss: 0.483501] [G loss: 0.468724]\n",
      "[Epoch 79/100] [Batch 174/347] [D loss: 0.468564] [G loss: 0.461457]\n",
      "[Epoch 79/100] [Batch 175/347] [D loss: 0.501292] [G loss: 0.453621]\n",
      "[Epoch 79/100] [Batch 176/347] [D loss: 0.529437] [G loss: 0.442923]\n",
      "[Epoch 79/100] [Batch 177/347] [D loss: 0.526026] [G loss: 0.425459]\n",
      "[Epoch 79/100] [Batch 178/347] [D loss: 0.516047] [G loss: 0.404822]\n",
      "[Epoch 79/100] [Batch 179/347] [D loss: 0.509974] [G loss: 0.386424]\n",
      "[Epoch 79/100] [Batch 180/347] [D loss: 0.504374] [G loss: 0.367559]\n",
      "[Epoch 79/100] [Batch 181/347] [D loss: 0.501271] [G loss: 0.355699]\n",
      "[Epoch 79/100] [Batch 182/347] [D loss: 0.505925] [G loss: 0.342661]\n",
      "[Epoch 79/100] [Batch 183/347] [D loss: 0.509389] [G loss: 0.334276]\n",
      "[Epoch 79/100] [Batch 184/347] [D loss: 0.540973] [G loss: 0.327901]\n",
      "[Epoch 79/100] [Batch 185/347] [D loss: 0.549636] [G loss: 0.319016]\n",
      "[Epoch 79/100] [Batch 186/347] [D loss: 0.534194] [G loss: 0.314189]\n",
      "[Epoch 79/100] [Batch 187/347] [D loss: 0.526155] [G loss: 0.310358]\n",
      "[Epoch 79/100] [Batch 188/347] [D loss: 0.490326] [G loss: 0.304378]\n",
      "[Epoch 79/100] [Batch 189/347] [D loss: 0.441924] [G loss: 0.304221]\n",
      "[Epoch 79/100] [Batch 190/347] [D loss: 0.433786] [G loss: 0.309789]\n",
      "[Epoch 79/100] [Batch 191/347] [D loss: 0.432205] [G loss: 0.317600]\n",
      "[Epoch 79/100] [Batch 192/347] [D loss: 0.440356] [G loss: 0.330351]\n",
      "[Epoch 79/100] [Batch 193/347] [D loss: 0.508902] [G loss: 0.344229]\n",
      "[Epoch 79/100] [Batch 194/347] [D loss: 0.497985] [G loss: 0.352906]\n",
      "[Epoch 79/100] [Batch 195/347] [D loss: 0.477140] [G loss: 0.361858]\n",
      "[Epoch 79/100] [Batch 196/347] [D loss: 0.429943] [G loss: 0.369355]\n",
      "[Epoch 79/100] [Batch 197/347] [D loss: 0.430323] [G loss: 0.377450]\n",
      "[Epoch 79/100] [Batch 198/347] [D loss: 0.429830] [G loss: 0.387625]\n",
      "[Epoch 79/100] [Batch 199/347] [D loss: 0.428119] [G loss: 0.393341]\n",
      "[Epoch 79/100] [Batch 200/347] [D loss: 0.484382] [G loss: 0.397393]\n",
      "[Epoch 79/100] [Batch 201/347] [D loss: 0.518062] [G loss: 0.399642]\n",
      "[Epoch 79/100] [Batch 202/347] [D loss: 0.523834] [G loss: 0.400912]\n",
      "[Epoch 79/100] [Batch 203/347] [D loss: 0.565518] [G loss: 0.402977]\n",
      "[Epoch 79/100] [Batch 204/347] [D loss: 0.558008] [G loss: 0.409186]\n",
      "[Epoch 79/100] [Batch 205/347] [D loss: 0.557486] [G loss: 0.417426]\n",
      "[Epoch 79/100] [Batch 206/347] [D loss: 0.554500] [G loss: 0.424065]\n",
      "[Epoch 79/100] [Batch 207/347] [D loss: 0.491313] [G loss: 0.427207]\n",
      "[Epoch 79/100] [Batch 208/347] [D loss: 0.478419] [G loss: 0.430520]\n",
      "[Epoch 79/100] [Batch 209/347] [D loss: 0.467230] [G loss: 0.424491]\n",
      "[Epoch 79/100] [Batch 210/347] [D loss: 0.371917] [G loss: 0.421287]\n",
      "[Epoch 79/100] [Batch 211/347] [D loss: 0.327890] [G loss: 0.412828]\n",
      "[Epoch 79/100] [Batch 212/347] [D loss: 0.217539] [G loss: 0.408955]\n",
      "[Epoch 79/100] [Batch 213/347] [D loss: 0.216356] [G loss: 0.419861]\n",
      "[Epoch 79/100] [Batch 214/347] [D loss: 0.211244] [G loss: 0.431997]\n",
      "[Epoch 79/100] [Batch 215/347] [D loss: 0.206671] [G loss: 0.446981]\n",
      "[Epoch 79/100] [Batch 216/347] [D loss: 0.368584] [G loss: 0.463117]\n",
      "[Epoch 79/100] [Batch 217/347] [D loss: 0.436821] [G loss: 0.484942]\n",
      "[Epoch 79/100] [Batch 218/347] [D loss: 0.493211] [G loss: 0.504316]\n",
      "[Epoch 79/100] [Batch 219/347] [D loss: 0.475742] [G loss: 0.513521]\n",
      "[Epoch 79/100] [Batch 220/347] [D loss: 0.468276] [G loss: 0.518080]\n",
      "[Epoch 79/100] [Batch 221/347] [D loss: 0.498338] [G loss: 0.516894]\n",
      "[Epoch 79/100] [Batch 222/347] [D loss: 0.500638] [G loss: 0.505308]\n",
      "[Epoch 79/100] [Batch 223/347] [D loss: 0.480658] [G loss: 0.481535]\n",
      "[Epoch 79/100] [Batch 224/347] [D loss: 0.487157] [G loss: 0.452760]\n",
      "[Epoch 79/100] [Batch 225/347] [D loss: 0.493239] [G loss: 0.424858]\n",
      "[Epoch 79/100] [Batch 226/347] [D loss: 0.499552] [G loss: 0.402773]\n",
      "[Epoch 79/100] [Batch 227/347] [D loss: 0.541086] [G loss: 0.392215]\n",
      "[Epoch 79/100] [Batch 228/347] [D loss: 0.559692] [G loss: 0.384357]\n",
      "[Epoch 79/100] [Batch 229/347] [D loss: 0.563055] [G loss: 0.378384]\n",
      "[Epoch 79/100] [Batch 230/347] [D loss: 0.575168] [G loss: 0.373863]\n",
      "[Epoch 79/100] [Batch 231/347] [D loss: 0.551210] [G loss: 0.363335]\n",
      "[Epoch 79/100] [Batch 232/347] [D loss: 0.533530] [G loss: 0.358846]\n",
      "[Epoch 79/100] [Batch 233/347] [D loss: 0.455046] [G loss: 0.361459]\n",
      "[Epoch 79/100] [Batch 234/347] [D loss: 0.412842] [G loss: 0.366532]\n",
      "[Epoch 79/100] [Batch 235/347] [D loss: 0.411320] [G loss: 0.380842]\n",
      "[Epoch 79/100] [Batch 236/347] [D loss: 0.405745] [G loss: 0.394392]\n",
      "[Epoch 79/100] [Batch 237/347] [D loss: 0.474530] [G loss: 0.407073]\n",
      "[Epoch 79/100] [Batch 238/347] [D loss: 0.560797] [G loss: 0.412702]\n",
      "[Epoch 79/100] [Batch 239/347] [D loss: 0.562005] [G loss: 0.416566]\n",
      "[Epoch 79/100] [Batch 240/347] [D loss: 0.564566] [G loss: 0.424501]\n",
      "[Epoch 79/100] [Batch 241/347] [D loss: 0.565891] [G loss: 0.433980]\n",
      "[Epoch 79/100] [Batch 242/347] [D loss: 0.583457] [G loss: 0.447400]\n",
      "[Epoch 79/100] [Batch 243/347] [D loss: 0.531626] [G loss: 0.460344]\n",
      "[Epoch 79/100] [Batch 244/347] [D loss: 0.497848] [G loss: 0.461483]\n",
      "[Epoch 79/100] [Batch 245/347] [D loss: 0.503418] [G loss: 0.458803]\n",
      "[Epoch 79/100] [Batch 246/347] [D loss: 0.503101] [G loss: 0.452961]\n",
      "[Epoch 79/100] [Batch 247/347] [D loss: 0.534445] [G loss: 0.450003]\n",
      "[Epoch 79/100] [Batch 248/347] [D loss: 0.558000] [G loss: 0.458969]\n",
      "[Epoch 79/100] [Batch 249/347] [D loss: 0.542889] [G loss: 0.471711]\n",
      "[Epoch 79/100] [Batch 250/347] [D loss: 0.538304] [G loss: 0.486794]\n",
      "[Epoch 79/100] [Batch 251/347] [D loss: 0.529635] [G loss: 0.498583]\n",
      "[Epoch 79/100] [Batch 252/347] [D loss: 0.524665] [G loss: 0.507801]\n",
      "[Epoch 79/100] [Batch 253/347] [D loss: 0.474797] [G loss: 0.502129]\n",
      "[Epoch 79/100] [Batch 254/347] [D loss: 0.474811] [G loss: 0.506039]\n",
      "[Epoch 79/100] [Batch 255/347] [D loss: 0.471492] [G loss: 0.503265]\n",
      "[Epoch 79/100] [Batch 256/347] [D loss: 0.473299] [G loss: 0.493534]\n",
      "[Epoch 79/100] [Batch 257/347] [D loss: 0.451937] [G loss: 0.484183]\n",
      "[Epoch 79/100] [Batch 258/347] [D loss: 0.403527] [G loss: 0.471820]\n",
      "[Epoch 79/100] [Batch 259/347] [D loss: 0.403459] [G loss: 0.455652]\n",
      "[Epoch 79/100] [Batch 260/347] [D loss: 0.402303] [G loss: 0.440942]\n",
      "[Epoch 79/100] [Batch 261/347] [D loss: 0.390368] [G loss: 0.431521]\n",
      "[Epoch 79/100] [Batch 262/347] [D loss: 0.344189] [G loss: 0.421380]\n",
      "[Epoch 79/100] [Batch 263/347] [D loss: 0.344823] [G loss: 0.414096]\n",
      "[Epoch 79/100] [Batch 264/347] [D loss: 0.348697] [G loss: 0.411560]\n",
      "[Epoch 79/100] [Batch 265/347] [D loss: 0.361301] [G loss: 0.411362]\n",
      "[Epoch 79/100] [Batch 266/347] [D loss: 0.431460] [G loss: 0.413844]\n",
      "[Epoch 79/100] [Batch 267/347] [D loss: 0.451977] [G loss: 0.416926]\n",
      "[Epoch 79/100] [Batch 268/347] [D loss: 0.457519] [G loss: 0.419371]\n",
      "[Epoch 79/100] [Batch 269/347] [D loss: 0.461202] [G loss: 0.421446]\n",
      "[Epoch 79/100] [Batch 270/347] [D loss: 0.491360] [G loss: 0.423591]\n",
      "[Epoch 79/100] [Batch 271/347] [D loss: 0.443847] [G loss: 0.432111]\n",
      "[Epoch 79/100] [Batch 272/347] [D loss: 0.395937] [G loss: 0.461339]\n",
      "[Epoch 79/100] [Batch 273/347] [D loss: 0.348125] [G loss: 0.493217]\n",
      "[Epoch 79/100] [Batch 274/347] [D loss: 0.298680] [G loss: 0.523580]\n",
      "[Epoch 79/100] [Batch 275/347] [D loss: 0.238631] [G loss: 0.548180]\n",
      "[Epoch 79/100] [Batch 276/347] [D loss: 0.506960] [G loss: 0.554474]\n",
      "[Epoch 79/100] [Batch 277/347] [D loss: 0.531065] [G loss: 0.569688]\n",
      "[Epoch 79/100] [Batch 278/347] [D loss: 0.533704] [G loss: 0.581889]\n",
      "[Epoch 79/100] [Batch 279/347] [D loss: 0.536871] [G loss: 0.584939]\n",
      "[Epoch 79/100] [Batch 280/347] [D loss: 0.538489] [G loss: 0.585721]\n",
      "[Epoch 79/100] [Batch 281/347] [D loss: 0.542456] [G loss: 0.586002]\n",
      "[Epoch 79/100] [Batch 282/347] [D loss: 0.543190] [G loss: 0.589149]\n",
      "[Epoch 79/100] [Batch 283/347] [D loss: 0.543738] [G loss: 0.590337]\n",
      "[Epoch 79/100] [Batch 284/347] [D loss: 0.544354] [G loss: 0.592510]\n",
      "[Epoch 79/100] [Batch 285/347] [D loss: 0.546972] [G loss: 0.593342]\n",
      "[Epoch 79/100] [Batch 286/347] [D loss: 0.546156] [G loss: 0.579132]\n",
      "[Epoch 79/100] [Batch 287/347] [D loss: 0.546780] [G loss: 0.576306]\n",
      "[Epoch 79/100] [Batch 288/347] [D loss: 0.546822] [G loss: 0.573441]\n",
      "[Epoch 79/100] [Batch 289/347] [D loss: 0.546059] [G loss: 0.568483]\n",
      "[Epoch 79/100] [Batch 290/347] [D loss: 0.545744] [G loss: 0.584437]\n",
      "[Epoch 79/100] [Batch 291/347] [D loss: 0.544860] [G loss: 0.591513]\n",
      "[Epoch 79/100] [Batch 292/347] [D loss: 0.543353] [G loss: 0.595397]\n",
      "[Epoch 79/100] [Batch 293/347] [D loss: 0.525387] [G loss: 0.601151]\n",
      "[Epoch 79/100] [Batch 294/347] [D loss: 0.524944] [G loss: 0.605287]\n",
      "[Epoch 79/100] [Batch 295/347] [D loss: 0.524980] [G loss: 0.603929]\n",
      "[Epoch 79/100] [Batch 296/347] [D loss: 0.524544] [G loss: 0.602342]\n",
      "[Epoch 79/100] [Batch 297/347] [D loss: 0.541482] [G loss: 0.606780]\n",
      "[Epoch 79/100] [Batch 298/347] [D loss: 0.544586] [G loss: 0.600151]\n",
      "[Epoch 79/100] [Batch 299/347] [D loss: 0.544390] [G loss: 0.595598]\n",
      "[Epoch 79/100] [Batch 300/347] [D loss: 0.543668] [G loss: 0.593682]\n",
      "[Epoch 79/100] [Batch 301/347] [D loss: 0.544092] [G loss: 0.582752]\n",
      "[Epoch 79/100] [Batch 302/347] [D loss: 0.544520] [G loss: 0.573949]\n",
      "[Epoch 79/100] [Batch 303/347] [D loss: 0.543947] [G loss: 0.558800]\n",
      "[Epoch 79/100] [Batch 304/347] [D loss: 0.529930] [G loss: 0.546920]\n",
      "[Epoch 79/100] [Batch 305/347] [D loss: 0.518291] [G loss: 0.544330]\n",
      "[Epoch 79/100] [Batch 306/347] [D loss: 0.517086] [G loss: 0.545890]\n",
      "[Epoch 79/100] [Batch 307/347] [D loss: 0.514504] [G loss: 0.551964]\n",
      "[Epoch 79/100] [Batch 308/347] [D loss: 0.520954] [G loss: 0.553392]\n",
      "[Epoch 79/100] [Batch 309/347] [D loss: 0.539405] [G loss: 0.567962]\n",
      "[Epoch 79/100] [Batch 310/347] [D loss: 0.548102] [G loss: 0.580178]\n",
      "[Epoch 79/100] [Batch 311/347] [D loss: 0.544614] [G loss: 0.577280]\n",
      "[Epoch 79/100] [Batch 312/347] [D loss: 0.537321] [G loss: 0.571651]\n",
      "[Epoch 79/100] [Batch 313/347] [D loss: 0.533464] [G loss: 0.561914]\n",
      "[Epoch 79/100] [Batch 314/347] [D loss: 0.532715] [G loss: 0.546722]\n",
      "[Epoch 79/100] [Batch 315/347] [D loss: 0.532481] [G loss: 0.535107]\n",
      "[Epoch 79/100] [Batch 316/347] [D loss: 0.534237] [G loss: 0.535827]\n",
      "[Epoch 79/100] [Batch 317/347] [D loss: 0.535401] [G loss: 0.539044]\n",
      "[Epoch 79/100] [Batch 318/347] [D loss: 0.535232] [G loss: 0.552300]\n",
      "[Epoch 79/100] [Batch 319/347] [D loss: 0.532097] [G loss: 0.564326]\n",
      "[Epoch 79/100] [Batch 320/347] [D loss: 0.530969] [G loss: 0.562160]\n",
      "[Epoch 79/100] [Batch 321/347] [D loss: 0.528402] [G loss: 0.554885]\n",
      "[Epoch 79/100] [Batch 322/347] [D loss: 0.529125] [G loss: 0.546444]\n",
      "[Epoch 79/100] [Batch 323/347] [D loss: 0.521165] [G loss: 0.536789]\n",
      "[Epoch 79/100] [Batch 324/347] [D loss: 0.519507] [G loss: 0.530203]\n",
      "[Epoch 79/100] [Batch 325/347] [D loss: 0.519008] [G loss: 0.523967]\n",
      "[Epoch 79/100] [Batch 326/347] [D loss: 0.518557] [G loss: 0.518196]\n",
      "[Epoch 79/100] [Batch 327/347] [D loss: 0.515839] [G loss: 0.513006]\n",
      "[Epoch 79/100] [Batch 328/347] [D loss: 0.515775] [G loss: 0.506860]\n",
      "[Epoch 79/100] [Batch 329/347] [D loss: 0.514303] [G loss: 0.504016]\n",
      "[Epoch 79/100] [Batch 330/347] [D loss: 0.512818] [G loss: 0.502688]\n",
      "[Epoch 79/100] [Batch 331/347] [D loss: 0.514328] [G loss: 0.503675]\n",
      "[Epoch 79/100] [Batch 332/347] [D loss: 0.523761] [G loss: 0.521407]\n",
      "[Epoch 79/100] [Batch 333/347] [D loss: 0.518105] [G loss: 0.518093]\n",
      "[Epoch 79/100] [Batch 334/347] [D loss: 0.516357] [G loss: 0.509503]\n",
      "[Epoch 79/100] [Batch 335/347] [D loss: 0.515558] [G loss: 0.505597]\n",
      "[Epoch 79/100] [Batch 336/347] [D loss: 0.514778] [G loss: 0.501900]\n",
      "[Epoch 79/100] [Batch 337/347] [D loss: 0.520171] [G loss: 0.504316]\n",
      "[Epoch 79/100] [Batch 338/347] [D loss: 0.524533] [G loss: 0.510583]\n",
      "[Epoch 79/100] [Batch 339/347] [D loss: 0.520661] [G loss: 0.509109]\n",
      "[Epoch 79/100] [Batch 340/347] [D loss: 0.515230] [G loss: 0.503867]\n",
      "[Epoch 79/100] [Batch 341/347] [D loss: 0.516119] [G loss: 0.502078]\n",
      "[Epoch 79/100] [Batch 342/347] [D loss: 0.492174] [G loss: 0.487792]\n",
      "[Epoch 79/100] [Batch 343/347] [D loss: 0.483337] [G loss: 0.470168]\n",
      "[Epoch 79/100] [Batch 344/347] [D loss: 0.428027] [G loss: 0.464017]\n",
      "[Epoch 79/100] [Batch 345/347] [D loss: 0.311252] [G loss: 0.459003]\n",
      "[Epoch 79/100] [Batch 346/347] [D loss: 0.296573] [G loss: 0.455077]\n",
      "[Epoch 79/100] [Batch 347/347] [D loss: 0.278291] [G loss: 0.451303]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 1/347] [D loss: 0.503669] [G loss: 0.459620]\n",
      "[Epoch 80/100] [Batch 2/347] [D loss: 0.506339] [G loss: 0.455499]\n",
      "[Epoch 80/100] [Batch 3/347] [D loss: 0.513778] [G loss: 0.455429]\n",
      "[Epoch 80/100] [Batch 4/347] [D loss: 0.513973] [G loss: 0.451207]\n",
      "[Epoch 80/100] [Batch 5/347] [D loss: 0.513754] [G loss: 0.443169]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 6/347] [D loss: 0.501757] [G loss: 0.435797]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 7/347] [D loss: 0.484136] [G loss: 0.422075]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 8/347] [D loss: 0.478654] [G loss: 0.414660]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 9/347] [D loss: 0.469777] [G loss: 0.408017]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 10/347] [D loss: 0.464913] [G loss: 0.399633]\n",
      "[Epoch 80/100] [Batch 11/347] [D loss: 0.491726] [G loss: 0.397544]\n",
      "[Epoch 80/100] [Batch 12/347] [D loss: 0.500492] [G loss: 0.387643]\n",
      "[Epoch 80/100] [Batch 13/347] [D loss: 0.474326] [G loss: 0.373222]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 14/347] [D loss: 0.450305] [G loss: 0.359545]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 15/347] [D loss: 0.447722] [G loss: 0.336787]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 16/347] [D loss: 0.439782] [G loss: 0.318527]\n",
      "[Epoch 80/100] [Batch 17/347] [D loss: 0.446466] [G loss: 0.309724]\n",
      "[Epoch 80/100] [Batch 18/347] [D loss: 0.460267] [G loss: 0.300813]\n",
      "[Epoch 80/100] [Batch 19/347] [D loss: 0.460133] [G loss: 0.298725]\n",
      "[Epoch 80/100] [Batch 20/347] [D loss: 0.484286] [G loss: 0.299175]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 21/347] [D loss: 0.423403] [G loss: 0.293243]\n",
      "[Epoch 80/100] [Batch 22/347] [D loss: 0.424445] [G loss: 0.293415]\n",
      "[Epoch 80/100] [Batch 23/347] [D loss: 0.426426] [G loss: 0.294639]\n",
      "[Epoch 80/100] [Batch 24/347] [D loss: 0.393731] [G loss: 0.293794]\n",
      "[Epoch 80/100] [Batch 25/347] [D loss: 0.314429] [G loss: 0.313679]\n",
      "[Epoch 80/100] [Batch 26/347] [D loss: 0.304961] [G loss: 0.330272]\n",
      "[Epoch 80/100] [Batch 27/347] [D loss: 0.295301] [G loss: 0.351479]\n",
      "[Epoch 80/100] [Batch 28/347] [D loss: 0.290849] [G loss: 0.374412]\n",
      "[Epoch 80/100] [Batch 29/347] [D loss: 0.309454] [G loss: 0.391343]\n",
      "[Epoch 80/100] [Batch 30/347] [D loss: 0.302213] [G loss: 0.402439]\n",
      "[Epoch 80/100] [Batch 31/347] [D loss: 0.304415] [G loss: 0.408979]\n",
      "[Epoch 80/100] [Batch 32/347] [D loss: 0.317277] [G loss: 0.409544]\n",
      "[Epoch 80/100] [Batch 33/347] [D loss: 0.334679] [G loss: 0.409304]\n",
      "[Epoch 80/100] [Batch 34/347] [D loss: 0.379635] [G loss: 0.403884]\n",
      "[Epoch 80/100] [Batch 35/347] [D loss: 0.379550] [G loss: 0.394797]\n",
      "[Epoch 80/100] [Batch 36/347] [D loss: 0.403657] [G loss: 0.383243]\n",
      "[Epoch 80/100] [Batch 37/347] [D loss: 0.407970] [G loss: 0.367095]\n",
      "[Epoch 80/100] [Batch 38/347] [D loss: 0.403961] [G loss: 0.346508]\n",
      "[Epoch 80/100] [Batch 39/347] [D loss: 0.409249] [G loss: 0.332626]\n",
      "[Epoch 80/100] [Batch 40/347] [D loss: 0.434227] [G loss: 0.325423]\n",
      "[Epoch 80/100] [Batch 41/347] [D loss: 0.455166] [G loss: 0.314960]\n",
      "[Epoch 80/100] [Batch 42/347] [D loss: 0.452034] [G loss: 0.314036]\n",
      "[Epoch 80/100] [Batch 43/347] [D loss: 0.477271] [G loss: 0.319771]\n",
      "[Epoch 80/100] [Batch 44/347] [D loss: 0.461164] [G loss: 0.318837]\n",
      "[Epoch 80/100] [Batch 45/347] [D loss: 0.437473] [G loss: 0.306609]\n",
      "[Epoch 80/100] [Batch 46/347] [D loss: 0.369899] [G loss: 0.301443]\n",
      "[Epoch 80/100] [Batch 47/347] [D loss: 0.365011] [G loss: 0.300383]\n",
      "[Epoch 80/100] [Batch 48/347] [D loss: 0.298110] [G loss: 0.313885]\n",
      "[Epoch 80/100] [Batch 49/347] [D loss: 0.278718] [G loss: 0.340843]\n",
      "[Epoch 80/100] [Batch 50/347] [D loss: 0.260306] [G loss: 0.372470]\n",
      "[Epoch 80/100] [Batch 51/347] [D loss: 0.236777] [G loss: 0.397994]\n",
      "[Epoch 80/100] [Batch 52/347] [D loss: 0.319504] [G loss: 0.409316]\n",
      "[Epoch 80/100] [Batch 53/347] [D loss: 0.363084] [G loss: 0.407251]\n",
      "[Epoch 80/100] [Batch 54/347] [D loss: 0.350289] [G loss: 0.402024]\n",
      "[Epoch 80/100] [Batch 55/347] [D loss: 0.348210] [G loss: 0.408232]\n",
      "[Epoch 80/100] [Batch 56/347] [D loss: 0.341969] [G loss: 0.416722]\n",
      "[Epoch 80/100] [Batch 57/347] [D loss: 0.293080] [G loss: 0.423716]\n",
      "[Epoch 80/100] [Batch 58/347] [D loss: 0.299990] [G loss: 0.426229]\n",
      "[Epoch 80/100] [Batch 59/347] [D loss: 0.296720] [G loss: 0.419302]\n",
      "[Epoch 80/100] [Batch 60/347] [D loss: 0.281121] [G loss: 0.402710]\n",
      "[Epoch 80/100] [Batch 61/347] [D loss: 0.295168] [G loss: 0.383261]\n",
      "[Epoch 80/100] [Batch 62/347] [D loss: 0.292905] [G loss: 0.376791]\n",
      "[Epoch 80/100] [Batch 63/347] [D loss: 0.286066] [G loss: 0.371294]\n",
      "[Epoch 80/100] [Batch 64/347] [D loss: 0.270337] [G loss: 0.364305]\n",
      "[Epoch 80/100] [Batch 65/347] [D loss: 0.233014] [G loss: 0.366921]\n",
      "[Epoch 80/100] [Batch 66/347] [D loss: 0.235573] [G loss: 0.367058]\n",
      "[Epoch 80/100] [Batch 67/347] [D loss: 0.234124] [G loss: 0.360217]\n",
      "[Epoch 80/100] [Batch 68/347] [D loss: 0.232995] [G loss: 0.361235]\n",
      "[Epoch 80/100] [Batch 69/347] [D loss: 0.244390] [G loss: 0.364795]\n",
      "[Epoch 80/100] [Batch 70/347] [D loss: 0.240245] [G loss: 0.367401]\n",
      "[Epoch 80/100] [Batch 71/347] [D loss: 0.237539] [G loss: 0.384307]\n",
      "[Epoch 80/100] [Batch 72/347] [D loss: 0.243883] [G loss: 0.399571]\n",
      "[Epoch 80/100] [Batch 73/347] [D loss: 0.349742] [G loss: 0.398477]\n",
      "[Epoch 80/100] [Batch 74/347] [D loss: 0.351975] [G loss: 0.400667]\n",
      "[Epoch 80/100] [Batch 75/347] [D loss: 0.350228] [G loss: 0.401127]\n",
      "[Epoch 80/100] [Batch 76/347] [D loss: 0.348543] [G loss: 0.398949]\n",
      "[Epoch 80/100] [Batch 77/347] [D loss: 0.383548] [G loss: 0.393437]\n",
      "[Epoch 80/100] [Batch 78/347] [D loss: 0.431455] [G loss: 0.400078]\n",
      "[Epoch 80/100] [Batch 79/347] [D loss: 0.424885] [G loss: 0.395406]\n",
      "[Epoch 80/100] [Batch 80/347] [D loss: 0.323893] [G loss: 0.376702]\n",
      "[Epoch 80/100] [Batch 81/347] [D loss: 0.305752] [G loss: 0.368857]\n",
      "[Epoch 80/100] [Batch 82/347] [D loss: 0.306056] [G loss: 0.364246]\n",
      "[Epoch 80/100] [Batch 83/347] [D loss: 0.311504] [G loss: 0.359158]\n",
      "[Epoch 80/100] [Batch 84/347] [D loss: 0.433987] [G loss: 0.358670]\n",
      "[Epoch 80/100] [Batch 85/347] [D loss: 0.506955] [G loss: 0.355021]\n",
      "[Epoch 80/100] [Batch 86/347] [D loss: 0.508798] [G loss: 0.351582]\n",
      "[Epoch 80/100] [Batch 87/347] [D loss: 0.509272] [G loss: 0.349544]\n",
      "[Epoch 80/100] [Batch 88/347] [D loss: 0.531338] [G loss: 0.347779]\n",
      "[Epoch 80/100] [Batch 89/347] [D loss: 0.541252] [G loss: 0.348442]\n",
      "[Epoch 80/100] [Batch 90/347] [D loss: 0.538970] [G loss: 0.347565]\n",
      "[Epoch 80/100] [Batch 91/347] [D loss: 0.541307] [G loss: 0.346508]\n",
      "[Epoch 80/100] [Batch 92/347] [D loss: 0.544706] [G loss: 0.347781]\n",
      "[Epoch 80/100] [Batch 93/347] [D loss: 0.545147] [G loss: 0.349165]\n",
      "[Epoch 80/100] [Batch 94/347] [D loss: 0.527259] [G loss: 0.347454]\n",
      "[Epoch 80/100] [Batch 95/347] [D loss: 0.516817] [G loss: 0.349149]\n",
      "[Epoch 80/100] [Batch 96/347] [D loss: 0.516349] [G loss: 0.352794]\n",
      "[Epoch 80/100] [Batch 97/347] [D loss: 0.509778] [G loss: 0.355426]\n",
      "[Epoch 80/100] [Batch 98/347] [D loss: 0.491581] [G loss: 0.359332]\n",
      "[Epoch 80/100] [Batch 99/347] [D loss: 0.494453] [G loss: 0.362708]\n",
      "[Epoch 80/100] [Batch 100/347] [D loss: 0.495371] [G loss: 0.364837]\n",
      "[Epoch 80/100] [Batch 101/347] [D loss: 0.503109] [G loss: 0.365514]\n",
      "[Epoch 80/100] [Batch 102/347] [D loss: 0.554768] [G loss: 0.366215]\n",
      "[Epoch 80/100] [Batch 103/347] [D loss: 0.559144] [G loss: 0.372376]\n",
      "[Epoch 80/100] [Batch 104/347] [D loss: 0.534186] [G loss: 0.372532]\n",
      "[Epoch 80/100] [Batch 105/347] [D loss: 0.447303] [G loss: 0.372665]\n",
      "[Epoch 80/100] [Batch 106/347] [D loss: 0.253124] [G loss: 0.379945]\n",
      "[Epoch 80/100] [Batch 107/347] [D loss: 0.233389] [G loss: 0.404354]\n",
      "[Epoch 80/100] [Batch 108/347] [D loss: 0.219501] [G loss: 0.428925]\n",
      "[Epoch 80/100] [Batch 109/347] [D loss: 0.196121] [G loss: 0.452130]\n",
      "[Epoch 80/100] [Batch 110/347] [D loss: 0.214662] [G loss: 0.463300]\n",
      "[Epoch 80/100] [Batch 111/347] [D loss: 0.217625] [G loss: 0.480056]\n",
      "[Epoch 80/100] [Batch 112/347] [D loss: 0.223011] [G loss: 0.492129]\n",
      "[Epoch 80/100] [Batch 113/347] [D loss: 0.416775] [G loss: 0.515808]\n",
      "[Epoch 80/100] [Batch 114/347] [D loss: 0.494666] [G loss: 0.525889]\n",
      "[Epoch 80/100] [Batch 115/347] [D loss: 0.497761] [G loss: 0.511173]\n",
      "[Epoch 80/100] [Batch 116/347] [D loss: 0.454015] [G loss: 0.494124]\n",
      "[Epoch 80/100] [Batch 117/347] [D loss: 0.449186] [G loss: 0.480826]\n",
      "[Epoch 80/100] [Batch 118/347] [D loss: 0.384056] [G loss: 0.468500]\n",
      "[Epoch 80/100] [Batch 119/347] [D loss: 0.369524] [G loss: 0.457546]\n",
      "[Epoch 80/100] [Batch 120/347] [D loss: 0.346778] [G loss: 0.451981]\n",
      "[Epoch 80/100] [Batch 121/347] [D loss: 0.327377] [G loss: 0.436386]\n",
      "[Epoch 80/100] [Batch 122/347] [D loss: 0.437433] [G loss: 0.420400]\n",
      "[Epoch 80/100] [Batch 123/347] [D loss: 0.484279] [G loss: 0.403548]\n",
      "[Epoch 80/100] [Batch 124/347] [D loss: 0.408978] [G loss: 0.382147]\n",
      "[Epoch 80/100] [Batch 125/347] [D loss: 0.377970] [G loss: 0.368581]\n",
      "[Epoch 80/100] [Batch 126/347] [D loss: 0.347311] [G loss: 0.356957]\n",
      "[Epoch 80/100] [Batch 127/347] [D loss: 0.355418] [G loss: 0.347258]\n",
      "[Epoch 80/100] [Batch 128/347] [D loss: 0.349446] [G loss: 0.336992]\n",
      "[Epoch 80/100] [Batch 129/347] [D loss: 0.324247] [G loss: 0.339096]\n",
      "[Epoch 80/100] [Batch 130/347] [D loss: 0.304440] [G loss: 0.362730]\n",
      "[Epoch 80/100] [Batch 131/347] [D loss: 0.280651] [G loss: 0.388848]\n",
      "[Epoch 80/100] [Batch 132/347] [D loss: 0.246602] [G loss: 0.424660]\n",
      "[Epoch 80/100] [Batch 133/347] [D loss: 0.226738] [G loss: 0.460014]\n",
      "[Epoch 80/100] [Batch 134/347] [D loss: 0.190678] [G loss: 0.488163]\n",
      "[Epoch 80/100] [Batch 135/347] [D loss: 0.163666] [G loss: 0.506005]\n",
      "[Epoch 80/100] [Batch 136/347] [D loss: 0.152461] [G loss: 0.512230]\n",
      "[Epoch 80/100] [Batch 137/347] [D loss: 0.384280] [G loss: 0.512489]\n",
      "[Epoch 80/100] [Batch 138/347] [D loss: 0.420019] [G loss: 0.508811]\n",
      "[Epoch 80/100] [Batch 139/347] [D loss: 0.436700] [G loss: 0.500629]\n",
      "[Epoch 80/100] [Batch 140/347] [D loss: 0.450254] [G loss: 0.500157]\n",
      "[Epoch 80/100] [Batch 141/347] [D loss: 0.416287] [G loss: 0.493960]\n",
      "[Epoch 80/100] [Batch 142/347] [D loss: 0.424808] [G loss: 0.486809]\n",
      "[Epoch 80/100] [Batch 143/347] [D loss: 0.418842] [G loss: 0.476534]\n",
      "[Epoch 80/100] [Batch 144/347] [D loss: 0.402481] [G loss: 0.465688]\n",
      "[Epoch 80/100] [Batch 145/347] [D loss: 0.427370] [G loss: 0.462341]\n",
      "[Epoch 80/100] [Batch 146/347] [D loss: 0.432625] [G loss: 0.452211]\n",
      "[Epoch 80/100] [Batch 147/347] [D loss: 0.448068] [G loss: 0.440312]\n",
      "[Epoch 80/100] [Batch 148/347] [D loss: 0.453464] [G loss: 0.427463]\n",
      "[Epoch 80/100] [Batch 149/347] [D loss: 0.375625] [G loss: 0.406246]\n",
      "[Epoch 80/100] [Batch 150/347] [D loss: 0.339340] [G loss: 0.378330]\n",
      "[Epoch 80/100] [Batch 151/347] [D loss: 0.322394] [G loss: 0.347547]\n",
      "[Epoch 80/100] [Batch 152/347] [D loss: 0.315386] [G loss: 0.316542]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 80/100] [Batch 153/347] [D loss: 0.328491] [G loss: 0.290042]\n",
      "[Epoch 80/100] [Batch 154/347] [D loss: 0.336593] [G loss: 0.276842]\n",
      "[Epoch 80/100] [Batch 155/347] [D loss: 0.340113] [G loss: 0.276881]\n",
      "[Epoch 80/100] [Batch 156/347] [D loss: 0.339547] [G loss: 0.280309]\n",
      "[Epoch 80/100] [Batch 157/347] [D loss: 0.326853] [G loss: 0.292284]\n",
      "[Epoch 80/100] [Batch 158/347] [D loss: 0.305482] [G loss: 0.315531]\n",
      "[Epoch 80/100] [Batch 159/347] [D loss: 0.302003] [G loss: 0.340369]\n",
      "[Epoch 80/100] [Batch 160/347] [D loss: 0.277258] [G loss: 0.372676]\n",
      "[Epoch 80/100] [Batch 161/347] [D loss: 0.257650] [G loss: 0.401379]\n",
      "[Epoch 80/100] [Batch 162/347] [D loss: 0.245226] [G loss: 0.417491]\n",
      "[Epoch 80/100] [Batch 163/347] [D loss: 0.244200] [G loss: 0.423359]\n",
      "[Epoch 80/100] [Batch 164/347] [D loss: 0.247224] [G loss: 0.436679]\n",
      "[Epoch 80/100] [Batch 165/347] [D loss: 0.251483] [G loss: 0.451257]\n",
      "[Epoch 80/100] [Batch 166/347] [D loss: 0.257709] [G loss: 0.461067]\n",
      "[Epoch 80/100] [Batch 167/347] [D loss: 0.288681] [G loss: 0.480088]\n",
      "[Epoch 80/100] [Batch 168/347] [D loss: 0.288532] [G loss: 0.489348]\n",
      "[Epoch 80/100] [Batch 169/347] [D loss: 0.433671] [G loss: 0.496330]\n",
      "[Epoch 80/100] [Batch 170/347] [D loss: 0.506170] [G loss: 0.499936]\n",
      "[Epoch 80/100] [Batch 171/347] [D loss: 0.507143] [G loss: 0.495896]\n",
      "[Epoch 80/100] [Batch 172/347] [D loss: 0.503152] [G loss: 0.492382]\n",
      "[Epoch 80/100] [Batch 173/347] [D loss: 0.501252] [G loss: 0.485075]\n",
      "[Epoch 80/100] [Batch 174/347] [D loss: 0.491393] [G loss: 0.481062]\n",
      "[Epoch 80/100] [Batch 175/347] [D loss: 0.519750] [G loss: 0.477005]\n",
      "[Epoch 80/100] [Batch 176/347] [D loss: 0.544424] [G loss: 0.471298]\n",
      "[Epoch 80/100] [Batch 177/347] [D loss: 0.542950] [G loss: 0.459598]\n",
      "[Epoch 80/100] [Batch 178/347] [D loss: 0.539109] [G loss: 0.444983]\n",
      "[Epoch 80/100] [Batch 179/347] [D loss: 0.535176] [G loss: 0.432885]\n",
      "[Epoch 80/100] [Batch 180/347] [D loss: 0.532743] [G loss: 0.419812]\n",
      "[Epoch 80/100] [Batch 181/347] [D loss: 0.529726] [G loss: 0.413374]\n",
      "[Epoch 80/100] [Batch 182/347] [D loss: 0.532663] [G loss: 0.404538]\n",
      "[Epoch 80/100] [Batch 183/347] [D loss: 0.534089] [G loss: 0.397614]\n",
      "[Epoch 80/100] [Batch 184/347] [D loss: 0.560072] [G loss: 0.392783]\n",
      "[Epoch 80/100] [Batch 185/347] [D loss: 0.567071] [G loss: 0.384200]\n",
      "[Epoch 80/100] [Batch 186/347] [D loss: 0.552237] [G loss: 0.378467]\n",
      "[Epoch 80/100] [Batch 187/347] [D loss: 0.543189] [G loss: 0.371512]\n",
      "[Epoch 80/100] [Batch 188/347] [D loss: 0.502821] [G loss: 0.360993]\n",
      "[Epoch 80/100] [Batch 189/347] [D loss: 0.447430] [G loss: 0.353379]\n",
      "[Epoch 80/100] [Batch 190/347] [D loss: 0.440981] [G loss: 0.350148]\n",
      "[Epoch 80/100] [Batch 191/347] [D loss: 0.443218] [G loss: 0.349041]\n",
      "[Epoch 80/100] [Batch 192/347] [D loss: 0.455820] [G loss: 0.350924]\n",
      "[Epoch 80/100] [Batch 193/347] [D loss: 0.529620] [G loss: 0.355451]\n",
      "[Epoch 80/100] [Batch 194/347] [D loss: 0.520822] [G loss: 0.356213]\n",
      "[Epoch 80/100] [Batch 195/347] [D loss: 0.499512] [G loss: 0.358242]\n",
      "[Epoch 80/100] [Batch 196/347] [D loss: 0.451943] [G loss: 0.360104]\n",
      "[Epoch 80/100] [Batch 197/347] [D loss: 0.452095] [G loss: 0.363773]\n",
      "[Epoch 80/100] [Batch 198/347] [D loss: 0.450384] [G loss: 0.371196]\n",
      "[Epoch 80/100] [Batch 199/347] [D loss: 0.448256] [G loss: 0.375032]\n",
      "[Epoch 80/100] [Batch 200/347] [D loss: 0.504161] [G loss: 0.379264]\n",
      "[Epoch 80/100] [Batch 201/347] [D loss: 0.537426] [G loss: 0.382874]\n",
      "[Epoch 80/100] [Batch 202/347] [D loss: 0.543509] [G loss: 0.387253]\n",
      "[Epoch 80/100] [Batch 203/347] [D loss: 0.585541] [G loss: 0.392669]\n",
      "[Epoch 80/100] [Batch 204/347] [D loss: 0.576477] [G loss: 0.402739]\n",
      "[Epoch 80/100] [Batch 205/347] [D loss: 0.574458] [G loss: 0.415677]\n",
      "[Epoch 80/100] [Batch 206/347] [D loss: 0.570060] [G loss: 0.427609]\n",
      "[Epoch 80/100] [Batch 207/347] [D loss: 0.507832] [G loss: 0.436544]\n",
      "[Epoch 80/100] [Batch 208/347] [D loss: 0.496244] [G loss: 0.444812]\n",
      "[Epoch 80/100] [Batch 209/347] [D loss: 0.485615] [G loss: 0.443301]\n",
      "[Epoch 80/100] [Batch 210/347] [D loss: 0.392055] [G loss: 0.443615]\n",
      "[Epoch 80/100] [Batch 211/347] [D loss: 0.342909] [G loss: 0.438167]\n",
      "[Epoch 80/100] [Batch 212/347] [D loss: 0.214480] [G loss: 0.431000]\n",
      "[Epoch 80/100] [Batch 213/347] [D loss: 0.213569] [G loss: 0.441569]\n",
      "[Epoch 80/100] [Batch 214/347] [D loss: 0.209582] [G loss: 0.451239]\n",
      "[Epoch 80/100] [Batch 215/347] [D loss: 0.208365] [G loss: 0.462935]\n",
      "[Epoch 80/100] [Batch 216/347] [D loss: 0.389511] [G loss: 0.480321]\n",
      "[Epoch 80/100] [Batch 217/347] [D loss: 0.453184] [G loss: 0.499477]\n",
      "[Epoch 80/100] [Batch 218/347] [D loss: 0.503601] [G loss: 0.517171]\n",
      "[Epoch 80/100] [Batch 219/347] [D loss: 0.488737] [G loss: 0.525119]\n",
      "[Epoch 80/100] [Batch 220/347] [D loss: 0.480802] [G loss: 0.529409]\n",
      "[Epoch 80/100] [Batch 221/347] [D loss: 0.509471] [G loss: 0.528325]\n",
      "[Epoch 80/100] [Batch 222/347] [D loss: 0.512178] [G loss: 0.517874]\n",
      "[Epoch 80/100] [Batch 223/347] [D loss: 0.495427] [G loss: 0.495200]\n",
      "[Epoch 80/100] [Batch 224/347] [D loss: 0.502553] [G loss: 0.467623]\n",
      "[Epoch 80/100] [Batch 225/347] [D loss: 0.509105] [G loss: 0.442376]\n",
      "[Epoch 80/100] [Batch 226/347] [D loss: 0.516305] [G loss: 0.423179]\n",
      "[Epoch 80/100] [Batch 227/347] [D loss: 0.551653] [G loss: 0.416307]\n",
      "[Epoch 80/100] [Batch 228/347] [D loss: 0.568546] [G loss: 0.412916]\n",
      "[Epoch 80/100] [Batch 229/347] [D loss: 0.571414] [G loss: 0.411536]\n",
      "[Epoch 80/100] [Batch 230/347] [D loss: 0.580462] [G loss: 0.412694]\n",
      "[Epoch 80/100] [Batch 231/347] [D loss: 0.561342] [G loss: 0.406254]\n",
      "[Epoch 80/100] [Batch 232/347] [D loss: 0.546275] [G loss: 0.406678]\n",
      "[Epoch 80/100] [Batch 233/347] [D loss: 0.464685] [G loss: 0.412095]\n",
      "[Epoch 80/100] [Batch 234/347] [D loss: 0.420833] [G loss: 0.416770]\n",
      "[Epoch 80/100] [Batch 235/347] [D loss: 0.418423] [G loss: 0.427764]\n",
      "[Epoch 80/100] [Batch 236/347] [D loss: 0.413409] [G loss: 0.436637]\n",
      "[Epoch 80/100] [Batch 237/347] [D loss: 0.478399] [G loss: 0.443352]\n",
      "[Epoch 80/100] [Batch 238/347] [D loss: 0.563735] [G loss: 0.444604]\n",
      "[Epoch 80/100] [Batch 239/347] [D loss: 0.565083] [G loss: 0.445133]\n",
      "[Epoch 80/100] [Batch 240/347] [D loss: 0.566511] [G loss: 0.448531]\n",
      "[Epoch 80/100] [Batch 241/347] [D loss: 0.567506] [G loss: 0.456544]\n",
      "[Epoch 80/100] [Batch 242/347] [D loss: 0.579284] [G loss: 0.468117]\n",
      "[Epoch 80/100] [Batch 243/347] [D loss: 0.532548] [G loss: 0.479447]\n",
      "[Epoch 80/100] [Batch 244/347] [D loss: 0.503734] [G loss: 0.478575]\n",
      "[Epoch 80/100] [Batch 245/347] [D loss: 0.508275] [G loss: 0.474748]\n",
      "[Epoch 80/100] [Batch 246/347] [D loss: 0.509313] [G loss: 0.467308]\n",
      "[Epoch 80/100] [Batch 247/347] [D loss: 0.535597] [G loss: 0.463542]\n",
      "[Epoch 80/100] [Batch 248/347] [D loss: 0.556664] [G loss: 0.471149]\n",
      "[Epoch 80/100] [Batch 249/347] [D loss: 0.543567] [G loss: 0.481639]\n",
      "[Epoch 80/100] [Batch 250/347] [D loss: 0.538651] [G loss: 0.495416]\n",
      "[Epoch 80/100] [Batch 251/347] [D loss: 0.530621] [G loss: 0.511876]\n",
      "[Epoch 80/100] [Batch 252/347] [D loss: 0.525334] [G loss: 0.521989]\n",
      "[Epoch 80/100] [Batch 253/347] [D loss: 0.482782] [G loss: 0.517936]\n",
      "[Epoch 80/100] [Batch 254/347] [D loss: 0.482180] [G loss: 0.522409]\n",
      "[Epoch 80/100] [Batch 255/347] [D loss: 0.480138] [G loss: 0.521200]\n",
      "[Epoch 80/100] [Batch 256/347] [D loss: 0.480957] [G loss: 0.509797]\n",
      "[Epoch 80/100] [Batch 257/347] [D loss: 0.462209] [G loss: 0.501764]\n",
      "[Epoch 80/100] [Batch 258/347] [D loss: 0.416335] [G loss: 0.489749]\n",
      "[Epoch 80/100] [Batch 259/347] [D loss: 0.413911] [G loss: 0.473924]\n",
      "[Epoch 80/100] [Batch 260/347] [D loss: 0.409271] [G loss: 0.457411]\n",
      "[Epoch 80/100] [Batch 261/347] [D loss: 0.393974] [G loss: 0.444630]\n",
      "[Epoch 80/100] [Batch 262/347] [D loss: 0.344149] [G loss: 0.430621]\n",
      "[Epoch 80/100] [Batch 263/347] [D loss: 0.343911] [G loss: 0.418424]\n",
      "[Epoch 80/100] [Batch 264/347] [D loss: 0.348692] [G loss: 0.410944]\n",
      "[Epoch 80/100] [Batch 265/347] [D loss: 0.361730] [G loss: 0.406256]\n",
      "[Epoch 80/100] [Batch 266/347] [D loss: 0.431424] [G loss: 0.404892]\n",
      "[Epoch 80/100] [Batch 267/347] [D loss: 0.451233] [G loss: 0.405456]\n",
      "[Epoch 80/100] [Batch 268/347] [D loss: 0.455557] [G loss: 0.405783]\n",
      "[Epoch 80/100] [Batch 269/347] [D loss: 0.459308] [G loss: 0.406531]\n",
      "[Epoch 80/100] [Batch 270/347] [D loss: 0.487909] [G loss: 0.408734]\n",
      "[Epoch 80/100] [Batch 271/347] [D loss: 0.443661] [G loss: 0.417886]\n",
      "[Epoch 80/100] [Batch 272/347] [D loss: 0.418266] [G loss: 0.447363]\n",
      "[Epoch 80/100] [Batch 273/347] [D loss: 0.368279] [G loss: 0.481845]\n",
      "[Epoch 80/100] [Batch 274/347] [D loss: 0.312061] [G loss: 0.514061]\n",
      "[Epoch 80/100] [Batch 275/347] [D loss: 0.247594] [G loss: 0.539735]\n",
      "[Epoch 80/100] [Batch 276/347] [D loss: 0.500092] [G loss: 0.547733]\n",
      "[Epoch 80/100] [Batch 277/347] [D loss: 0.523926] [G loss: 0.562695]\n",
      "[Epoch 80/100] [Batch 278/347] [D loss: 0.526658] [G loss: 0.574971]\n",
      "[Epoch 80/100] [Batch 279/347] [D loss: 0.530208] [G loss: 0.577979]\n",
      "[Epoch 80/100] [Batch 280/347] [D loss: 0.532030] [G loss: 0.578905]\n",
      "[Epoch 80/100] [Batch 281/347] [D loss: 0.536309] [G loss: 0.579413]\n",
      "[Epoch 80/100] [Batch 282/347] [D loss: 0.537248] [G loss: 0.582643]\n",
      "[Epoch 80/100] [Batch 283/347] [D loss: 0.537967] [G loss: 0.583928]\n",
      "[Epoch 80/100] [Batch 284/347] [D loss: 0.538661] [G loss: 0.586248]\n",
      "[Epoch 80/100] [Batch 285/347] [D loss: 0.541886] [G loss: 0.587257]\n",
      "[Epoch 80/100] [Batch 286/347] [D loss: 0.541129] [G loss: 0.573025]\n",
      "[Epoch 80/100] [Batch 287/347] [D loss: 0.541826] [G loss: 0.570235]\n",
      "[Epoch 80/100] [Batch 288/347] [D loss: 0.541942] [G loss: 0.567375]\n",
      "[Epoch 80/100] [Batch 289/347] [D loss: 0.540920] [G loss: 0.562165]\n",
      "[Epoch 80/100] [Batch 290/347] [D loss: 0.540390] [G loss: 0.578330]\n",
      "[Epoch 80/100] [Batch 291/347] [D loss: 0.539268] [G loss: 0.585239]\n",
      "[Epoch 80/100] [Batch 292/347] [D loss: 0.537339] [G loss: 0.588940]\n",
      "[Epoch 80/100] [Batch 293/347] [D loss: 0.517497] [G loss: 0.594575]\n",
      "[Epoch 80/100] [Batch 294/347] [D loss: 0.516934] [G loss: 0.598396]\n",
      "[Epoch 80/100] [Batch 295/347] [D loss: 0.516824] [G loss: 0.596785]\n",
      "[Epoch 80/100] [Batch 296/347] [D loss: 0.516423] [G loss: 0.594968]\n",
      "[Epoch 80/100] [Batch 297/347] [D loss: 0.535579] [G loss: 0.599136]\n",
      "[Epoch 80/100] [Batch 298/347] [D loss: 0.538644] [G loss: 0.592222]\n",
      "[Epoch 80/100] [Batch 299/347] [D loss: 0.538354] [G loss: 0.587446]\n",
      "[Epoch 80/100] [Batch 300/347] [D loss: 0.537539] [G loss: 0.585324]\n",
      "[Epoch 80/100] [Batch 301/347] [D loss: 0.538107] [G loss: 0.574198]\n",
      "[Epoch 80/100] [Batch 302/347] [D loss: 0.538638] [G loss: 0.565217]\n",
      "[Epoch 80/100] [Batch 303/347] [D loss: 0.538025] [G loss: 0.549593]\n",
      "[Epoch 80/100] [Batch 304/347] [D loss: 0.522484] [G loss: 0.537452]\n",
      "[Epoch 80/100] [Batch 305/347] [D loss: 0.510382] [G loss: 0.534889]\n",
      "[Epoch 80/100] [Batch 306/347] [D loss: 0.509134] [G loss: 0.536318]\n",
      "[Epoch 80/100] [Batch 307/347] [D loss: 0.506748] [G loss: 0.542093]\n",
      "[Epoch 80/100] [Batch 308/347] [D loss: 0.513713] [G loss: 0.542984]\n",
      "[Epoch 80/100] [Batch 309/347] [D loss: 0.532660] [G loss: 0.557441]\n",
      "[Epoch 80/100] [Batch 310/347] [D loss: 0.543170] [G loss: 0.569438]\n",
      "[Epoch 80/100] [Batch 311/347] [D loss: 0.538863] [G loss: 0.566191]\n",
      "[Epoch 80/100] [Batch 312/347] [D loss: 0.530048] [G loss: 0.560347]\n",
      "[Epoch 80/100] [Batch 313/347] [D loss: 0.526039] [G loss: 0.550355]\n",
      "[Epoch 80/100] [Batch 314/347] [D loss: 0.525187] [G loss: 0.534717]\n",
      "[Epoch 80/100] [Batch 315/347] [D loss: 0.525024] [G loss: 0.523189]\n",
      "[Epoch 80/100] [Batch 316/347] [D loss: 0.527020] [G loss: 0.523501]\n",
      "[Epoch 80/100] [Batch 317/347] [D loss: 0.528282] [G loss: 0.526635]\n",
      "[Epoch 80/100] [Batch 318/347] [D loss: 0.527971] [G loss: 0.539716]\n",
      "[Epoch 80/100] [Batch 319/347] [D loss: 0.524528] [G loss: 0.551581]\n",
      "[Epoch 80/100] [Batch 320/347] [D loss: 0.523415] [G loss: 0.549369]\n",
      "[Epoch 80/100] [Batch 321/347] [D loss: 0.520878] [G loss: 0.541922]\n",
      "[Epoch 80/100] [Batch 322/347] [D loss: 0.521645] [G loss: 0.533166]\n",
      "[Epoch 80/100] [Batch 323/347] [D loss: 0.513489] [G loss: 0.523360]\n",
      "[Epoch 80/100] [Batch 324/347] [D loss: 0.511991] [G loss: 0.516721]\n",
      "[Epoch 80/100] [Batch 325/347] [D loss: 0.511627] [G loss: 0.510349]\n",
      "[Epoch 80/100] [Batch 326/347] [D loss: 0.511261] [G loss: 0.504409]\n",
      "[Epoch 80/100] [Batch 327/347] [D loss: 0.508756] [G loss: 0.499151]\n",
      "[Epoch 80/100] [Batch 328/347] [D loss: 0.508836] [G loss: 0.492989]\n",
      "[Epoch 80/100] [Batch 329/347] [D loss: 0.507505] [G loss: 0.490091]\n",
      "[Epoch 80/100] [Batch 330/347] [D loss: 0.506091] [G loss: 0.488590]\n",
      "[Epoch 80/100] [Batch 331/347] [D loss: 0.507489] [G loss: 0.489557]\n",
      "[Epoch 80/100] [Batch 332/347] [D loss: 0.516800] [G loss: 0.507805]\n",
      "[Epoch 80/100] [Batch 333/347] [D loss: 0.511144] [G loss: 0.504512]\n",
      "[Epoch 80/100] [Batch 334/347] [D loss: 0.509506] [G loss: 0.495829]\n",
      "[Epoch 80/100] [Batch 335/347] [D loss: 0.508768] [G loss: 0.491897]\n",
      "[Epoch 80/100] [Batch 336/347] [D loss: 0.508081] [G loss: 0.488304]\n",
      "[Epoch 80/100] [Batch 337/347] [D loss: 0.513564] [G loss: 0.490513]\n",
      "[Epoch 80/100] [Batch 338/347] [D loss: 0.517825] [G loss: 0.496848]\n",
      "[Epoch 80/100] [Batch 339/347] [D loss: 0.514065] [G loss: 0.495429]\n",
      "[Epoch 80/100] [Batch 340/347] [D loss: 0.508805] [G loss: 0.490158]\n",
      "[Epoch 80/100] [Batch 341/347] [D loss: 0.509749] [G loss: 0.488358]\n",
      "[Epoch 80/100] [Batch 342/347] [D loss: 0.487049] [G loss: 0.473973]\n",
      "[Epoch 80/100] [Batch 343/347] [D loss: 0.479173] [G loss: 0.456391]\n",
      "[Epoch 80/100] [Batch 344/347] [D loss: 0.430539] [G loss: 0.450163]\n",
      "[Epoch 80/100] [Batch 345/347] [D loss: 0.325317] [G loss: 0.445225]\n",
      "[Epoch 80/100] [Batch 346/347] [D loss: 0.311961] [G loss: 0.441467]\n",
      "[Epoch 80/100] [Batch 347/347] [D loss: 0.293433] [G loss: 0.437828]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 1/347] [D loss: 0.498741] [G loss: 0.446352]\n",
      "[Epoch 81/100] [Batch 2/347] [D loss: 0.501572] [G loss: 0.442302]\n",
      "[Epoch 81/100] [Batch 3/347] [D loss: 0.508222] [G loss: 0.442376]\n",
      "[Epoch 81/100] [Batch 4/347] [D loss: 0.508461] [G loss: 0.438524]\n",
      "[Epoch 81/100] [Batch 5/347] [D loss: 0.508290] [G loss: 0.430742]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 6/347] [D loss: 0.497283] [G loss: 0.423674]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 7/347] [D loss: 0.483010] [G loss: 0.410554]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 8/347] [D loss: 0.479306] [G loss: 0.404068]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 9/347] [D loss: 0.472124] [G loss: 0.399365]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 10/347] [D loss: 0.469122] [G loss: 0.393386]\n",
      "[Epoch 81/100] [Batch 11/347] [D loss: 0.488669] [G loss: 0.394864]\n",
      "[Epoch 81/100] [Batch 12/347] [D loss: 0.495568] [G loss: 0.388859]\n",
      "[Epoch 81/100] [Batch 13/347] [D loss: 0.474373] [G loss: 0.378271]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 14/347] [D loss: 0.451774] [G loss: 0.367352]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 15/347] [D loss: 0.449541] [G loss: 0.346169]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 16/347] [D loss: 0.440546] [G loss: 0.328910]\n",
      "[Epoch 81/100] [Batch 17/347] [D loss: 0.444466] [G loss: 0.319563]\n",
      "[Epoch 81/100] [Batch 18/347] [D loss: 0.455062] [G loss: 0.309505]\n",
      "[Epoch 81/100] [Batch 19/347] [D loss: 0.453071] [G loss: 0.303653]\n",
      "[Epoch 81/100] [Batch 20/347] [D loss: 0.473819] [G loss: 0.300680]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 21/347] [D loss: 0.416110] [G loss: 0.290023]\n",
      "[Epoch 81/100] [Batch 22/347] [D loss: 0.417973] [G loss: 0.285036]\n",
      "[Epoch 81/100] [Batch 23/347] [D loss: 0.421791] [G loss: 0.282295]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 24/347] [D loss: 0.392712] [G loss: 0.277401]\n",
      "[Epoch 81/100] [Batch 25/347] [D loss: 0.321016] [G loss: 0.293527]\n",
      "[Epoch 81/100] [Batch 26/347] [D loss: 0.312601] [G loss: 0.306578]\n",
      "[Epoch 81/100] [Batch 27/347] [D loss: 0.303446] [G loss: 0.325886]\n",
      "[Epoch 81/100] [Batch 28/347] [D loss: 0.296911] [G loss: 0.347305]\n",
      "[Epoch 81/100] [Batch 29/347] [D loss: 0.310057] [G loss: 0.365524]\n",
      "[Epoch 81/100] [Batch 30/347] [D loss: 0.300861] [G loss: 0.378057]\n",
      "[Epoch 81/100] [Batch 31/347] [D loss: 0.300891] [G loss: 0.386341]\n",
      "[Epoch 81/100] [Batch 32/347] [D loss: 0.311038] [G loss: 0.388815]\n",
      "[Epoch 81/100] [Batch 33/347] [D loss: 0.327637] [G loss: 0.390222]\n",
      "[Epoch 81/100] [Batch 34/347] [D loss: 0.371360] [G loss: 0.386824]\n",
      "[Epoch 81/100] [Batch 35/347] [D loss: 0.373704] [G loss: 0.378818]\n",
      "[Epoch 81/100] [Batch 36/347] [D loss: 0.398591] [G loss: 0.369234]\n",
      "[Epoch 81/100] [Batch 37/347] [D loss: 0.403291] [G loss: 0.356707]\n",
      "[Epoch 81/100] [Batch 38/347] [D loss: 0.399583] [G loss: 0.340260]\n",
      "[Epoch 81/100] [Batch 39/347] [D loss: 0.403119] [G loss: 0.329299]\n",
      "[Epoch 81/100] [Batch 40/347] [D loss: 0.424102] [G loss: 0.323929]\n",
      "[Epoch 81/100] [Batch 41/347] [D loss: 0.442043] [G loss: 0.314873]\n",
      "[Epoch 81/100] [Batch 42/347] [D loss: 0.436576] [G loss: 0.312764]\n",
      "[Epoch 81/100] [Batch 43/347] [D loss: 0.460058] [G loss: 0.317343]\n",
      "[Epoch 81/100] [Batch 44/347] [D loss: 0.442795] [G loss: 0.315322]\n",
      "[Epoch 81/100] [Batch 45/347] [D loss: 0.419540] [G loss: 0.302175]\n",
      "[Epoch 81/100] [Batch 46/347] [D loss: 0.355819] [G loss: 0.293132]\n",
      "[Epoch 81/100] [Batch 47/347] [D loss: 0.352863] [G loss: 0.289869]\n",
      "[Epoch 81/100] [Batch 48/347] [D loss: 0.296997] [G loss: 0.301951]\n",
      "[Epoch 81/100] [Batch 49/347] [D loss: 0.278936] [G loss: 0.326534]\n",
      "[Epoch 81/100] [Batch 50/347] [D loss: 0.261475] [G loss: 0.356453]\n",
      "[Epoch 81/100] [Batch 51/347] [D loss: 0.237565] [G loss: 0.380490]\n",
      "[Epoch 81/100] [Batch 52/347] [D loss: 0.308636] [G loss: 0.391170]\n",
      "[Epoch 81/100] [Batch 53/347] [D loss: 0.347356] [G loss: 0.388686]\n",
      "[Epoch 81/100] [Batch 54/347] [D loss: 0.334661] [G loss: 0.383593]\n",
      "[Epoch 81/100] [Batch 55/347] [D loss: 0.332148] [G loss: 0.389781]\n",
      "[Epoch 81/100] [Batch 56/347] [D loss: 0.326048] [G loss: 0.398757]\n",
      "[Epoch 81/100] [Batch 57/347] [D loss: 0.280156] [G loss: 0.406408]\n",
      "[Epoch 81/100] [Batch 58/347] [D loss: 0.286531] [G loss: 0.409474]\n",
      "[Epoch 81/100] [Batch 59/347] [D loss: 0.283551] [G loss: 0.403964]\n",
      "[Epoch 81/100] [Batch 60/347] [D loss: 0.269855] [G loss: 0.388477]\n",
      "[Epoch 81/100] [Batch 61/347] [D loss: 0.283013] [G loss: 0.370969]\n",
      "[Epoch 81/100] [Batch 62/347] [D loss: 0.280623] [G loss: 0.366481]\n",
      "[Epoch 81/100] [Batch 63/347] [D loss: 0.273122] [G loss: 0.362545]\n",
      "[Epoch 81/100] [Batch 64/347] [D loss: 0.258191] [G loss: 0.356243]\n",
      "[Epoch 81/100] [Batch 65/347] [D loss: 0.223739] [G loss: 0.359069]\n",
      "[Epoch 81/100] [Batch 66/347] [D loss: 0.225844] [G loss: 0.358040]\n",
      "[Epoch 81/100] [Batch 67/347] [D loss: 0.224940] [G loss: 0.348764]\n",
      "[Epoch 81/100] [Batch 68/347] [D loss: 0.224528] [G loss: 0.348213]\n",
      "[Epoch 81/100] [Batch 69/347] [D loss: 0.234282] [G loss: 0.350205]\n",
      "[Epoch 81/100] [Batch 70/347] [D loss: 0.230016] [G loss: 0.351204]\n",
      "[Epoch 81/100] [Batch 71/347] [D loss: 0.227266] [G loss: 0.367269]\n",
      "[Epoch 81/100] [Batch 72/347] [D loss: 0.232543] [G loss: 0.381663]\n",
      "[Epoch 81/100] [Batch 73/347] [D loss: 0.329709] [G loss: 0.380162]\n",
      "[Epoch 81/100] [Batch 74/347] [D loss: 0.331345] [G loss: 0.382241]\n",
      "[Epoch 81/100] [Batch 75/347] [D loss: 0.329381] [G loss: 0.382850]\n",
      "[Epoch 81/100] [Batch 76/347] [D loss: 0.327511] [G loss: 0.381012]\n",
      "[Epoch 81/100] [Batch 77/347] [D loss: 0.360786] [G loss: 0.381661]\n",
      "[Epoch 81/100] [Batch 78/347] [D loss: 0.404945] [G loss: 0.389111]\n",
      "[Epoch 81/100] [Batch 79/347] [D loss: 0.398247] [G loss: 0.385257]\n",
      "[Epoch 81/100] [Batch 80/347] [D loss: 0.301548] [G loss: 0.366953]\n",
      "[Epoch 81/100] [Batch 81/347] [D loss: 0.285124] [G loss: 0.360086]\n",
      "[Epoch 81/100] [Batch 82/347] [D loss: 0.285277] [G loss: 0.356143]\n",
      "[Epoch 81/100] [Batch 83/347] [D loss: 0.290432] [G loss: 0.351336]\n",
      "[Epoch 81/100] [Batch 84/347] [D loss: 0.406319] [G loss: 0.351519]\n",
      "[Epoch 81/100] [Batch 85/347] [D loss: 0.475286] [G loss: 0.347526]\n",
      "[Epoch 81/100] [Batch 86/347] [D loss: 0.476359] [G loss: 0.342033]\n",
      "[Epoch 81/100] [Batch 87/347] [D loss: 0.476169] [G loss: 0.338732]\n",
      "[Epoch 81/100] [Batch 88/347] [D loss: 0.497998] [G loss: 0.335639]\n",
      "[Epoch 81/100] [Batch 89/347] [D loss: 0.507547] [G loss: 0.333903]\n",
      "[Epoch 81/100] [Batch 90/347] [D loss: 0.504677] [G loss: 0.328870]\n",
      "[Epoch 81/100] [Batch 91/347] [D loss: 0.507069] [G loss: 0.324251]\n",
      "[Epoch 81/100] [Batch 92/347] [D loss: 0.510866] [G loss: 0.322513]\n",
      "[Epoch 81/100] [Batch 93/347] [D loss: 0.511267] [G loss: 0.321348]\n",
      "[Epoch 81/100] [Batch 94/347] [D loss: 0.492584] [G loss: 0.316580]\n",
      "[Epoch 81/100] [Batch 95/347] [D loss: 0.481457] [G loss: 0.315864]\n",
      "[Epoch 81/100] [Batch 96/347] [D loss: 0.481188] [G loss: 0.318369]\n",
      "[Epoch 81/100] [Batch 97/347] [D loss: 0.473988] [G loss: 0.319907]\n",
      "[Epoch 81/100] [Batch 98/347] [D loss: 0.455877] [G loss: 0.324319]\n",
      "[Epoch 81/100] [Batch 99/347] [D loss: 0.457193] [G loss: 0.328945]\n",
      "[Epoch 81/100] [Batch 100/347] [D loss: 0.458150] [G loss: 0.333462]\n",
      "[Epoch 81/100] [Batch 101/347] [D loss: 0.465067] [G loss: 0.337183]\n",
      "[Epoch 81/100] [Batch 102/347] [D loss: 0.522785] [G loss: 0.339941]\n",
      "[Epoch 81/100] [Batch 103/347] [D loss: 0.527825] [G loss: 0.345825]\n",
      "[Epoch 81/100] [Batch 104/347] [D loss: 0.499978] [G loss: 0.345935]\n",
      "[Epoch 81/100] [Batch 105/347] [D loss: 0.420598] [G loss: 0.346195]\n",
      "[Epoch 81/100] [Batch 106/347] [D loss: 0.270046] [G loss: 0.354462]\n",
      "[Epoch 81/100] [Batch 107/347] [D loss: 0.245245] [G loss: 0.376455]\n",
      "[Epoch 81/100] [Batch 108/347] [D loss: 0.226548] [G loss: 0.404496]\n",
      "[Epoch 81/100] [Batch 109/347] [D loss: 0.197225] [G loss: 0.432356]\n",
      "[Epoch 81/100] [Batch 110/347] [D loss: 0.197553] [G loss: 0.448783]\n",
      "[Epoch 81/100] [Batch 111/347] [D loss: 0.198965] [G loss: 0.466641]\n",
      "[Epoch 81/100] [Batch 112/347] [D loss: 0.203231] [G loss: 0.480088]\n",
      "[Epoch 81/100] [Batch 113/347] [D loss: 0.399624] [G loss: 0.504571]\n",
      "[Epoch 81/100] [Batch 114/347] [D loss: 0.481832] [G loss: 0.514917]\n",
      "[Epoch 81/100] [Batch 115/347] [D loss: 0.487523] [G loss: 0.500158]\n",
      "[Epoch 81/100] [Batch 116/347] [D loss: 0.438387] [G loss: 0.483386]\n",
      "[Epoch 81/100] [Batch 117/347] [D loss: 0.432031] [G loss: 0.470460]\n",
      "[Epoch 81/100] [Batch 118/347] [D loss: 0.362433] [G loss: 0.455966]\n",
      "[Epoch 81/100] [Batch 119/347] [D loss: 0.345494] [G loss: 0.447645]\n",
      "[Epoch 81/100] [Batch 120/347] [D loss: 0.320633] [G loss: 0.444692]\n",
      "[Epoch 81/100] [Batch 121/347] [D loss: 0.299608] [G loss: 0.430713]\n",
      "[Epoch 81/100] [Batch 122/347] [D loss: 0.409764] [G loss: 0.415754]\n",
      "[Epoch 81/100] [Batch 123/347] [D loss: 0.450926] [G loss: 0.397025]\n",
      "[Epoch 81/100] [Batch 124/347] [D loss: 0.371174] [G loss: 0.372855]\n",
      "[Epoch 81/100] [Batch 125/347] [D loss: 0.341401] [G loss: 0.355075]\n",
      "[Epoch 81/100] [Batch 126/347] [D loss: 0.316127] [G loss: 0.342236]\n",
      "[Epoch 81/100] [Batch 127/347] [D loss: 0.326158] [G loss: 0.330703]\n",
      "[Epoch 81/100] [Batch 128/347] [D loss: 0.324564] [G loss: 0.320535]\n",
      "[Epoch 81/100] [Batch 129/347] [D loss: 0.314435] [G loss: 0.320695]\n",
      "[Epoch 81/100] [Batch 130/347] [D loss: 0.311217] [G loss: 0.344721]\n",
      "[Epoch 81/100] [Batch 131/347] [D loss: 0.287457] [G loss: 0.372522]\n",
      "[Epoch 81/100] [Batch 132/347] [D loss: 0.249006] [G loss: 0.408189]\n",
      "[Epoch 81/100] [Batch 133/347] [D loss: 0.234101] [G loss: 0.444748]\n",
      "[Epoch 81/100] [Batch 134/347] [D loss: 0.193020] [G loss: 0.472798]\n",
      "[Epoch 81/100] [Batch 135/347] [D loss: 0.162012] [G loss: 0.490651]\n",
      "[Epoch 81/100] [Batch 136/347] [D loss: 0.147410] [G loss: 0.496379]\n",
      "[Epoch 81/100] [Batch 137/347] [D loss: 0.357061] [G loss: 0.496428]\n",
      "[Epoch 81/100] [Batch 138/347] [D loss: 0.395579] [G loss: 0.492034]\n",
      "[Epoch 81/100] [Batch 139/347] [D loss: 0.413341] [G loss: 0.483488]\n",
      "[Epoch 81/100] [Batch 140/347] [D loss: 0.429380] [G loss: 0.482790]\n",
      "[Epoch 81/100] [Batch 141/347] [D loss: 0.388369] [G loss: 0.476322]\n",
      "[Epoch 81/100] [Batch 142/347] [D loss: 0.396064] [G loss: 0.469180]\n",
      "[Epoch 81/100] [Batch 143/347] [D loss: 0.388850] [G loss: 0.458669]\n",
      "[Epoch 81/100] [Batch 144/347] [D loss: 0.368067] [G loss: 0.447585]\n",
      "[Epoch 81/100] [Batch 145/347] [D loss: 0.393133] [G loss: 0.443923]\n",
      "[Epoch 81/100] [Batch 146/347] [D loss: 0.393135] [G loss: 0.433029]\n",
      "[Epoch 81/100] [Batch 147/347] [D loss: 0.406499] [G loss: 0.419485]\n",
      "[Epoch 81/100] [Batch 148/347] [D loss: 0.408411] [G loss: 0.403651]\n",
      "[Epoch 81/100] [Batch 149/347] [D loss: 0.328600] [G loss: 0.378762]\n",
      "[Epoch 81/100] [Batch 150/347] [D loss: 0.297579] [G loss: 0.348570]\n",
      "[Epoch 81/100] [Batch 151/347] [D loss: 0.289083] [G loss: 0.319127]\n",
      "[Epoch 81/100] [Batch 152/347] [D loss: 0.289517] [G loss: 0.289011]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 81/100] [Batch 153/347] [D loss: 0.305602] [G loss: 0.265133]\n",
      "[Epoch 81/100] [Batch 154/347] [D loss: 0.316535] [G loss: 0.255568]\n",
      "[Epoch 81/100] [Batch 155/347] [D loss: 0.319847] [G loss: 0.259652]\n",
      "[Epoch 81/100] [Batch 156/347] [D loss: 0.317448] [G loss: 0.266329]\n",
      "[Epoch 81/100] [Batch 157/347] [D loss: 0.303249] [G loss: 0.282202]\n",
      "[Epoch 81/100] [Batch 158/347] [D loss: 0.284950] [G loss: 0.308763]\n",
      "[Epoch 81/100] [Batch 159/347] [D loss: 0.275605] [G loss: 0.335512]\n",
      "[Epoch 81/100] [Batch 160/347] [D loss: 0.248707] [G loss: 0.369047]\n",
      "[Epoch 81/100] [Batch 161/347] [D loss: 0.229653] [G loss: 0.396345]\n",
      "[Epoch 81/100] [Batch 162/347] [D loss: 0.217268] [G loss: 0.410041]\n",
      "[Epoch 81/100] [Batch 163/347] [D loss: 0.216789] [G loss: 0.413780]\n",
      "[Epoch 81/100] [Batch 164/347] [D loss: 0.221488] [G loss: 0.424578]\n",
      "[Epoch 81/100] [Batch 165/347] [D loss: 0.225488] [G loss: 0.437422]\n",
      "[Epoch 81/100] [Batch 166/347] [D loss: 0.231351] [G loss: 0.446729]\n",
      "[Epoch 81/100] [Batch 167/347] [D loss: 0.260263] [G loss: 0.468015]\n",
      "[Epoch 81/100] [Batch 168/347] [D loss: 0.260457] [G loss: 0.477116]\n",
      "[Epoch 81/100] [Batch 169/347] [D loss: 0.409400] [G loss: 0.484039]\n",
      "[Epoch 81/100] [Batch 170/347] [D loss: 0.484171] [G loss: 0.487215]\n",
      "[Epoch 81/100] [Batch 171/347] [D loss: 0.482892] [G loss: 0.482033]\n",
      "[Epoch 81/100] [Batch 172/347] [D loss: 0.474182] [G loss: 0.476017]\n",
      "[Epoch 81/100] [Batch 173/347] [D loss: 0.464635] [G loss: 0.465069]\n",
      "[Epoch 81/100] [Batch 174/347] [D loss: 0.445104] [G loss: 0.456320]\n",
      "[Epoch 81/100] [Batch 175/347] [D loss: 0.480685] [G loss: 0.444769]\n",
      "[Epoch 81/100] [Batch 176/347] [D loss: 0.508732] [G loss: 0.428361]\n",
      "[Epoch 81/100] [Batch 177/347] [D loss: 0.501401] [G loss: 0.405576]\n",
      "[Epoch 81/100] [Batch 178/347] [D loss: 0.484412] [G loss: 0.378002]\n",
      "[Epoch 81/100] [Batch 179/347] [D loss: 0.476860] [G loss: 0.353392]\n",
      "[Epoch 81/100] [Batch 180/347] [D loss: 0.471464] [G loss: 0.330948]\n",
      "[Epoch 81/100] [Batch 181/347] [D loss: 0.470295] [G loss: 0.317647]\n",
      "[Epoch 81/100] [Batch 182/347] [D loss: 0.477074] [G loss: 0.304382]\n",
      "[Epoch 81/100] [Batch 183/347] [D loss: 0.483785] [G loss: 0.296364]\n",
      "[Epoch 81/100] [Batch 184/347] [D loss: 0.515864] [G loss: 0.291874]\n",
      "[Epoch 81/100] [Batch 185/347] [D loss: 0.526857] [G loss: 0.285731]\n",
      "[Epoch 81/100] [Batch 186/347] [D loss: 0.510809] [G loss: 0.285144]\n",
      "[Epoch 81/100] [Batch 187/347] [D loss: 0.502354] [G loss: 0.286470]\n",
      "[Epoch 81/100] [Batch 188/347] [D loss: 0.467366] [G loss: 0.286180]\n",
      "[Epoch 81/100] [Batch 189/347] [D loss: 0.420641] [G loss: 0.290882]\n",
      "[Epoch 81/100] [Batch 190/347] [D loss: 0.408906] [G loss: 0.303871]\n",
      "[Epoch 81/100] [Batch 191/347] [D loss: 0.401950] [G loss: 0.318595]\n",
      "[Epoch 81/100] [Batch 192/347] [D loss: 0.406873] [G loss: 0.335716]\n",
      "[Epoch 81/100] [Batch 193/347] [D loss: 0.476407] [G loss: 0.353615]\n",
      "[Epoch 81/100] [Batch 194/347] [D loss: 0.463965] [G loss: 0.365151]\n",
      "[Epoch 81/100] [Batch 195/347] [D loss: 0.442670] [G loss: 0.375063]\n",
      "[Epoch 81/100] [Batch 196/347] [D loss: 0.395269] [G loss: 0.383843]\n",
      "[Epoch 81/100] [Batch 197/347] [D loss: 0.397134] [G loss: 0.391238]\n",
      "[Epoch 81/100] [Batch 198/347] [D loss: 0.396784] [G loss: 0.400074]\n",
      "[Epoch 81/100] [Batch 199/347] [D loss: 0.395844] [G loss: 0.403119]\n",
      "[Epoch 81/100] [Batch 200/347] [D loss: 0.456862] [G loss: 0.404413]\n",
      "[Epoch 81/100] [Batch 201/347] [D loss: 0.491980] [G loss: 0.403245]\n",
      "[Epoch 81/100] [Batch 202/347] [D loss: 0.498969] [G loss: 0.400872]\n",
      "[Epoch 81/100] [Batch 203/347] [D loss: 0.546921] [G loss: 0.398202]\n",
      "[Epoch 81/100] [Batch 204/347] [D loss: 0.537253] [G loss: 0.398644]\n",
      "[Epoch 81/100] [Batch 205/347] [D loss: 0.535301] [G loss: 0.400153]\n",
      "[Epoch 81/100] [Batch 206/347] [D loss: 0.531565] [G loss: 0.400033]\n",
      "[Epoch 81/100] [Batch 207/347] [D loss: 0.451266] [G loss: 0.397103]\n",
      "[Epoch 81/100] [Batch 208/347] [D loss: 0.434630] [G loss: 0.394652]\n",
      "[Epoch 81/100] [Batch 209/347] [D loss: 0.423382] [G loss: 0.384692]\n",
      "[Epoch 81/100] [Batch 210/347] [D loss: 0.337276] [G loss: 0.380140]\n",
      "[Epoch 81/100] [Batch 211/347] [D loss: 0.309482] [G loss: 0.373892]\n",
      "[Epoch 81/100] [Batch 212/347] [D loss: 0.237809] [G loss: 0.373233]\n",
      "[Epoch 81/100] [Batch 213/347] [D loss: 0.230305] [G loss: 0.390526]\n",
      "[Epoch 81/100] [Batch 214/347] [D loss: 0.217483] [G loss: 0.410759]\n",
      "[Epoch 81/100] [Batch 215/347] [D loss: 0.203052] [G loss: 0.435088]\n",
      "[Epoch 81/100] [Batch 216/347] [D loss: 0.330333] [G loss: 0.458667]\n",
      "[Epoch 81/100] [Batch 217/347] [D loss: 0.405549] [G loss: 0.484917]\n",
      "[Epoch 81/100] [Batch 218/347] [D loss: 0.467814] [G loss: 0.507833]\n",
      "[Epoch 81/100] [Batch 219/347] [D loss: 0.450432] [G loss: 0.519240]\n",
      "[Epoch 81/100] [Batch 220/347] [D loss: 0.441779] [G loss: 0.525280]\n",
      "[Epoch 81/100] [Batch 221/347] [D loss: 0.477831] [G loss: 0.524729]\n",
      "[Epoch 81/100] [Batch 222/347] [D loss: 0.480657] [G loss: 0.513638]\n",
      "[Epoch 81/100] [Batch 223/347] [D loss: 0.457874] [G loss: 0.489395]\n",
      "[Epoch 81/100] [Batch 224/347] [D loss: 0.462875] [G loss: 0.458103]\n",
      "[Epoch 81/100] [Batch 225/347] [D loss: 0.465399] [G loss: 0.427404]\n",
      "[Epoch 81/100] [Batch 226/347] [D loss: 0.468699] [G loss: 0.400882]\n",
      "[Epoch 81/100] [Batch 227/347] [D loss: 0.514051] [G loss: 0.382746]\n",
      "[Epoch 81/100] [Batch 228/347] [D loss: 0.533866] [G loss: 0.367797]\n",
      "[Epoch 81/100] [Batch 229/347] [D loss: 0.533757] [G loss: 0.353819]\n",
      "[Epoch 81/100] [Batch 230/347] [D loss: 0.546900] [G loss: 0.339994]\n",
      "[Epoch 81/100] [Batch 231/347] [D loss: 0.514710] [G loss: 0.321057]\n",
      "[Epoch 81/100] [Batch 232/347] [D loss: 0.496187] [G loss: 0.310520]\n",
      "[Epoch 81/100] [Batch 233/347] [D loss: 0.427475] [G loss: 0.309019]\n",
      "[Epoch 81/100] [Batch 234/347] [D loss: 0.393170] [G loss: 0.313130]\n",
      "[Epoch 81/100] [Batch 235/347] [D loss: 0.393041] [G loss: 0.329235]\n",
      "[Epoch 81/100] [Batch 236/347] [D loss: 0.385184] [G loss: 0.348463]\n",
      "[Epoch 81/100] [Batch 237/347] [D loss: 0.447605] [G loss: 0.367034]\n",
      "[Epoch 81/100] [Batch 238/347] [D loss: 0.524218] [G loss: 0.378163]\n",
      "[Epoch 81/100] [Batch 239/347] [D loss: 0.525104] [G loss: 0.385140]\n",
      "[Epoch 81/100] [Batch 240/347] [D loss: 0.530510] [G loss: 0.394776]\n",
      "[Epoch 81/100] [Batch 241/347] [D loss: 0.532409] [G loss: 0.405225]\n",
      "[Epoch 81/100] [Batch 242/347] [D loss: 0.561015] [G loss: 0.417016]\n",
      "[Epoch 81/100] [Batch 243/347] [D loss: 0.500674] [G loss: 0.428373]\n",
      "[Epoch 81/100] [Batch 244/347] [D loss: 0.462872] [G loss: 0.429365]\n",
      "[Epoch 81/100] [Batch 245/347] [D loss: 0.465666] [G loss: 0.424825]\n",
      "[Epoch 81/100] [Batch 246/347] [D loss: 0.467141] [G loss: 0.419183]\n",
      "[Epoch 81/100] [Batch 247/347] [D loss: 0.506563] [G loss: 0.413844]\n",
      "[Epoch 81/100] [Batch 248/347] [D loss: 0.537494] [G loss: 0.418986]\n",
      "[Epoch 81/100] [Batch 249/347] [D loss: 0.512014] [G loss: 0.431271]\n",
      "[Epoch 81/100] [Batch 250/347] [D loss: 0.504765] [G loss: 0.441373]\n",
      "[Epoch 81/100] [Batch 251/347] [D loss: 0.488846] [G loss: 0.445838]\n",
      "[Epoch 81/100] [Batch 252/347] [D loss: 0.481169] [G loss: 0.448133]\n",
      "[Epoch 81/100] [Batch 253/347] [D loss: 0.423060] [G loss: 0.438934]\n",
      "[Epoch 81/100] [Batch 254/347] [D loss: 0.422742] [G loss: 0.439320]\n",
      "[Epoch 81/100] [Batch 255/347] [D loss: 0.420561] [G loss: 0.435707]\n",
      "[Epoch 81/100] [Batch 256/347] [D loss: 0.423774] [G loss: 0.427254]\n",
      "[Epoch 81/100] [Batch 257/347] [D loss: 0.398880] [G loss: 0.420701]\n",
      "[Epoch 81/100] [Batch 258/347] [D loss: 0.354916] [G loss: 0.414833]\n",
      "[Epoch 81/100] [Batch 259/347] [D loss: 0.358781] [G loss: 0.409920]\n",
      "[Epoch 81/100] [Batch 260/347] [D loss: 0.360673] [G loss: 0.408140]\n",
      "[Epoch 81/100] [Batch 261/347] [D loss: 0.352142] [G loss: 0.414126]\n",
      "[Epoch 81/100] [Batch 262/347] [D loss: 0.312871] [G loss: 0.418354]\n",
      "[Epoch 81/100] [Batch 263/347] [D loss: 0.310292] [G loss: 0.425125]\n",
      "[Epoch 81/100] [Batch 264/347] [D loss: 0.309439] [G loss: 0.435056]\n",
      "[Epoch 81/100] [Batch 265/347] [D loss: 0.319128] [G loss: 0.444255]\n",
      "[Epoch 81/100] [Batch 266/347] [D loss: 0.391083] [G loss: 0.453125]\n",
      "[Epoch 81/100] [Batch 267/347] [D loss: 0.414189] [G loss: 0.459661]\n",
      "[Epoch 81/100] [Batch 268/347] [D loss: 0.421373] [G loss: 0.462237]\n",
      "[Epoch 81/100] [Batch 269/347] [D loss: 0.426113] [G loss: 0.462073]\n",
      "[Epoch 81/100] [Batch 270/347] [D loss: 0.458643] [G loss: 0.460278]\n",
      "[Epoch 81/100] [Batch 271/347] [D loss: 0.400318] [G loss: 0.462482]\n",
      "[Epoch 81/100] [Batch 272/347] [D loss: 0.353061] [G loss: 0.482951]\n",
      "[Epoch 81/100] [Batch 273/347] [D loss: 0.321995] [G loss: 0.505035]\n",
      "[Epoch 81/100] [Batch 274/347] [D loss: 0.290422] [G loss: 0.528128]\n",
      "[Epoch 81/100] [Batch 275/347] [D loss: 0.238873] [G loss: 0.548669]\n",
      "[Epoch 81/100] [Batch 276/347] [D loss: 0.490515] [G loss: 0.551218]\n",
      "[Epoch 81/100] [Batch 277/347] [D loss: 0.521440] [G loss: 0.564379]\n",
      "[Epoch 81/100] [Batch 278/347] [D loss: 0.527895] [G loss: 0.574917]\n",
      "[Epoch 81/100] [Batch 279/347] [D loss: 0.534202] [G loss: 0.576544]\n",
      "[Epoch 81/100] [Batch 280/347] [D loss: 0.537420] [G loss: 0.576497]\n",
      "[Epoch 81/100] [Batch 281/347] [D loss: 0.545095] [G loss: 0.576242]\n",
      "[Epoch 81/100] [Batch 282/347] [D loss: 0.545708] [G loss: 0.579080]\n",
      "[Epoch 81/100] [Batch 283/347] [D loss: 0.545824] [G loss: 0.580130]\n",
      "[Epoch 81/100] [Batch 284/347] [D loss: 0.546190] [G loss: 0.582242]\n",
      "[Epoch 81/100] [Batch 285/347] [D loss: 0.548499] [G loss: 0.583143]\n",
      "[Epoch 81/100] [Batch 286/347] [D loss: 0.547338] [G loss: 0.568957]\n",
      "[Epoch 81/100] [Batch 287/347] [D loss: 0.547931] [G loss: 0.566176]\n",
      "[Epoch 81/100] [Batch 288/347] [D loss: 0.547609] [G loss: 0.563441]\n",
      "[Epoch 81/100] [Batch 289/347] [D loss: 0.546733] [G loss: 0.558357]\n",
      "[Epoch 81/100] [Batch 290/347] [D loss: 0.546036] [G loss: 0.574730]\n",
      "[Epoch 81/100] [Batch 291/347] [D loss: 0.544860] [G loss: 0.581923]\n",
      "[Epoch 81/100] [Batch 292/347] [D loss: 0.541948] [G loss: 0.585903]\n",
      "[Epoch 81/100] [Batch 293/347] [D loss: 0.489681] [G loss: 0.591637]\n",
      "[Epoch 81/100] [Batch 294/347] [D loss: 0.486859] [G loss: 0.595333]\n",
      "[Epoch 81/100] [Batch 295/347] [D loss: 0.482686] [G loss: 0.593307]\n",
      "[Epoch 81/100] [Batch 296/347] [D loss: 0.474381] [G loss: 0.590792]\n",
      "[Epoch 81/100] [Batch 297/347] [D loss: 0.525910] [G loss: 0.594083]\n",
      "[Epoch 81/100] [Batch 298/347] [D loss: 0.541075] [G loss: 0.586244]\n",
      "[Epoch 81/100] [Batch 299/347] [D loss: 0.540200] [G loss: 0.580641]\n",
      "[Epoch 81/100] [Batch 300/347] [D loss: 0.538515] [G loss: 0.577419]\n",
      "[Epoch 81/100] [Batch 301/347] [D loss: 0.538491] [G loss: 0.564492]\n",
      "[Epoch 81/100] [Batch 302/347] [D loss: 0.538995] [G loss: 0.554293]\n",
      "[Epoch 81/100] [Batch 303/347] [D loss: 0.537303] [G loss: 0.538259]\n",
      "[Epoch 81/100] [Batch 304/347] [D loss: 0.446166] [G loss: 0.524297]\n",
      "[Epoch 81/100] [Batch 305/347] [D loss: 0.352739] [G loss: 0.516513]\n",
      "[Epoch 81/100] [Batch 306/347] [D loss: 0.330715] [G loss: 0.511710]\n",
      "[Epoch 81/100] [Batch 307/347] [D loss: 0.304322] [G loss: 0.507495]\n",
      "[Epoch 81/100] [Batch 308/347] [D loss: 0.352392] [G loss: 0.496428]\n",
      "[Epoch 81/100] [Batch 309/347] [D loss: 0.501474] [G loss: 0.493784]\n",
      "[Epoch 81/100] [Batch 310/347] [D loss: 0.565059] [G loss: 0.489461]\n",
      "[Epoch 81/100] [Batch 311/347] [D loss: 0.548253] [G loss: 0.470498]\n",
      "[Epoch 81/100] [Batch 312/347] [D loss: 0.482310] [G loss: 0.447813]\n",
      "[Epoch 81/100] [Batch 313/347] [D loss: 0.442787] [G loss: 0.420859]\n",
      "[Epoch 81/100] [Batch 314/347] [D loss: 0.431583] [G loss: 0.389009]\n",
      "[Epoch 81/100] [Batch 315/347] [D loss: 0.435413] [G loss: 0.362836]\n",
      "[Epoch 81/100] [Batch 316/347] [D loss: 0.467169] [G loss: 0.350940]\n",
      "[Epoch 81/100] [Batch 317/347] [D loss: 0.492240] [G loss: 0.345383]\n",
      "[Epoch 81/100] [Batch 318/347] [D loss: 0.503403] [G loss: 0.350298]\n",
      "[Epoch 81/100] [Batch 319/347] [D loss: 0.489576] [G loss: 0.358487]\n",
      "[Epoch 81/100] [Batch 320/347] [D loss: 0.490776] [G loss: 0.356927]\n",
      "[Epoch 81/100] [Batch 321/347] [D loss: 0.476998] [G loss: 0.353231]\n",
      "[Epoch 81/100] [Batch 322/347] [D loss: 0.486262] [G loss: 0.352404]\n",
      "[Epoch 81/100] [Batch 323/347] [D loss: 0.426871] [G loss: 0.354991]\n",
      "[Epoch 81/100] [Batch 324/347] [D loss: 0.417714] [G loss: 0.361495]\n",
      "[Epoch 81/100] [Batch 325/347] [D loss: 0.416496] [G loss: 0.368976]\n",
      "[Epoch 81/100] [Batch 326/347] [D loss: 0.415988] [G loss: 0.378423]\n",
      "[Epoch 81/100] [Batch 327/347] [D loss: 0.398310] [G loss: 0.391211]\n",
      "[Epoch 81/100] [Batch 328/347] [D loss: 0.401073] [G loss: 0.401863]\n",
      "[Epoch 81/100] [Batch 329/347] [D loss: 0.399222] [G loss: 0.414586]\n",
      "[Epoch 81/100] [Batch 330/347] [D loss: 0.398271] [G loss: 0.426466]\n",
      "[Epoch 81/100] [Batch 331/347] [D loss: 0.427468] [G loss: 0.439888]\n",
      "[Epoch 81/100] [Batch 332/347] [D loss: 0.517924] [G loss: 0.468168]\n",
      "[Epoch 81/100] [Batch 333/347] [D loss: 0.485537] [G loss: 0.472751]\n",
      "[Epoch 81/100] [Batch 334/347] [D loss: 0.480486] [G loss: 0.469617]\n",
      "[Epoch 81/100] [Batch 335/347] [D loss: 0.482699] [G loss: 0.469514]\n",
      "[Epoch 81/100] [Batch 336/347] [D loss: 0.482991] [G loss: 0.467802]\n",
      "[Epoch 81/100] [Batch 337/347] [D loss: 0.524366] [G loss: 0.470714]\n",
      "[Epoch 81/100] [Batch 338/347] [D loss: 0.557907] [G loss: 0.479004]\n",
      "[Epoch 81/100] [Batch 339/347] [D loss: 0.534451] [G loss: 0.480731]\n",
      "[Epoch 81/100] [Batch 340/347] [D loss: 0.505819] [G loss: 0.479193]\n",
      "[Epoch 81/100] [Batch 341/347] [D loss: 0.512737] [G loss: 0.481920]\n",
      "[Epoch 81/100] [Batch 342/347] [D loss: 0.383199] [G loss: 0.471395]\n",
      "[Epoch 81/100] [Batch 343/347] [D loss: 0.344912] [G loss: 0.457482]\n",
      "[Epoch 81/100] [Batch 344/347] [D loss: 0.302000] [G loss: 0.456014]\n",
      "[Epoch 81/100] [Batch 345/347] [D loss: 0.217583] [G loss: 0.460092]\n",
      "[Epoch 81/100] [Batch 346/347] [D loss: 0.216300] [G loss: 0.467637]\n",
      "[Epoch 81/100] [Batch 347/347] [D loss: 0.213734] [G loss: 0.477902]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 82/100] [Batch 1/347] [D loss: 0.514852] [G loss: 0.500199]\n",
      "[Epoch 82/100] [Batch 2/347] [D loss: 0.535055] [G loss: 0.508341]\n",
      "[Epoch 82/100] [Batch 3/347] [D loss: 0.563308] [G loss: 0.520412]\n",
      "[Epoch 82/100] [Batch 4/347] [D loss: 0.563488] [G loss: 0.528977]\n",
      "[Epoch 82/100] [Batch 5/347] [D loss: 0.561329] [G loss: 0.533611]\n",
      "[Epoch 82/100] [Batch 6/347] [D loss: 0.546023] [G loss: 0.538026]\n",
      "[Epoch 82/100] [Batch 7/347] [D loss: 0.532059] [G loss: 0.535391]\n",
      "[Epoch 82/100] [Batch 8/347] [D loss: 0.533372] [G loss: 0.538117]\n",
      "[Epoch 82/100] [Batch 9/347] [D loss: 0.531928] [G loss: 0.542508]\n",
      "[Epoch 82/100] [Batch 10/347] [D loss: 0.534615] [G loss: 0.546185]\n",
      "[Epoch 82/100] [Batch 11/347] [D loss: 0.544097] [G loss: 0.557707]\n",
      "[Epoch 82/100] [Batch 12/347] [D loss: 0.546257] [G loss: 0.561855]\n",
      "[Epoch 82/100] [Batch 13/347] [D loss: 0.540151] [G loss: 0.561917]\n",
      "[Epoch 82/100] [Batch 14/347] [D loss: 0.534633] [G loss: 0.562326]\n",
      "[Epoch 82/100] [Batch 15/347] [D loss: 0.535569] [G loss: 0.553003]\n",
      "[Epoch 82/100] [Batch 16/347] [D loss: 0.534126] [G loss: 0.547247]\n",
      "[Epoch 82/100] [Batch 17/347] [D loss: 0.534744] [G loss: 0.549550]\n",
      "[Epoch 82/100] [Batch 18/347] [D loss: 0.536366] [G loss: 0.549713]\n",
      "[Epoch 82/100] [Batch 19/347] [D loss: 0.535328] [G loss: 0.554239]\n",
      "[Epoch 82/100] [Batch 20/347] [D loss: 0.537424] [G loss: 0.558266]\n",
      "[Epoch 82/100] [Batch 21/347] [D loss: 0.526790] [G loss: 0.552192]\n",
      "[Epoch 82/100] [Batch 22/347] [D loss: 0.527181] [G loss: 0.548819]\n",
      "[Epoch 82/100] [Batch 23/347] [D loss: 0.527129] [G loss: 0.544191]\n",
      "[Epoch 82/100] [Batch 24/347] [D loss: 0.506708] [G loss: 0.535096]\n",
      "[Epoch 82/100] [Batch 25/347] [D loss: 0.452424] [G loss: 0.540044]\n",
      "[Epoch 82/100] [Batch 26/347] [D loss: 0.446077] [G loss: 0.536921]\n",
      "[Epoch 82/100] [Batch 27/347] [D loss: 0.433164] [G loss: 0.536651]\n",
      "[Epoch 82/100] [Batch 28/347] [D loss: 0.420034] [G loss: 0.535575]\n",
      "[Epoch 82/100] [Batch 29/347] [D loss: 0.437200] [G loss: 0.528339]\n",
      "[Epoch 82/100] [Batch 30/347] [D loss: 0.403477] [G loss: 0.514090]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 82/100] [Batch 31/347] [D loss: 0.378333] [G loss: 0.491791]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 82/100] [Batch 32/347] [D loss: 0.371474] [G loss: 0.459935]\n",
      "[Epoch 82/100] [Batch 33/347] [D loss: 0.376877] [G loss: 0.427663]\n",
      "[Epoch 82/100] [Batch 34/347] [D loss: 0.424289] [G loss: 0.392958]\n",
      "[Epoch 82/100] [Batch 35/347] [D loss: 0.429743] [G loss: 0.361730]\n",
      "[Epoch 82/100] [Batch 36/347] [D loss: 0.465615] [G loss: 0.334587]\n",
      "[Epoch 82/100] [Batch 37/347] [D loss: 0.482168] [G loss: 0.312658]\n",
      "[Epoch 82/100] [Batch 38/347] [D loss: 0.490931] [G loss: 0.294194]\n",
      "[Epoch 82/100] [Batch 39/347] [D loss: 0.507754] [G loss: 0.287474]\n",
      "[Epoch 82/100] [Batch 40/347] [D loss: 0.539102] [G loss: 0.293743]\n",
      "[Epoch 82/100] [Batch 41/347] [D loss: 0.564043] [G loss: 0.299726]\n",
      "[Epoch 82/100] [Batch 42/347] [D loss: 0.558736] [G loss: 0.315579]\n",
      "[Epoch 82/100] [Batch 43/347] [D loss: 0.582476] [G loss: 0.339216]\n",
      "[Epoch 82/100] [Batch 44/347] [D loss: 0.558735] [G loss: 0.355955]\n",
      "[Epoch 82/100] [Batch 45/347] [D loss: 0.525321] [G loss: 0.360722]\n",
      "[Epoch 82/100] [Batch 46/347] [D loss: 0.436577] [G loss: 0.370660]\n",
      "[Epoch 82/100] [Batch 47/347] [D loss: 0.423862] [G loss: 0.380469]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 82/100] [Batch 48/347] [D loss: 0.292733] [G loss: 0.403055]\n",
      "[Epoch 82/100] [Batch 49/347] [D loss: 0.272484] [G loss: 0.434375]\n",
      "[Epoch 82/100] [Batch 50/347] [D loss: 0.258736] [G loss: 0.466020]\n",
      "[Epoch 82/100] [Batch 51/347] [D loss: 0.248192] [G loss: 0.488856]\n",
      "[Epoch 82/100] [Batch 52/347] [D loss: 0.395397] [G loss: 0.497316]\n",
      "[Epoch 82/100] [Batch 53/347] [D loss: 0.455373] [G loss: 0.493880]\n",
      "[Epoch 82/100] [Batch 54/347] [D loss: 0.437193] [G loss: 0.487600]\n",
      "[Epoch 82/100] [Batch 55/347] [D loss: 0.432008] [G loss: 0.492397]\n",
      "[Epoch 82/100] [Batch 56/347] [D loss: 0.421726] [G loss: 0.498975]\n",
      "[Epoch 82/100] [Batch 57/347] [D loss: 0.362620] [G loss: 0.502368]\n",
      "[Epoch 82/100] [Batch 58/347] [D loss: 0.368271] [G loss: 0.500321]\n",
      "[Epoch 82/100] [Batch 59/347] [D loss: 0.363366] [G loss: 0.488207]\n",
      "[Epoch 82/100] [Batch 60/347] [D loss: 0.347591] [G loss: 0.465572]\n",
      "[Epoch 82/100] [Batch 61/347] [D loss: 0.366385] [G loss: 0.440233]\n",
      "[Epoch 82/100] [Batch 62/347] [D loss: 0.364147] [G loss: 0.429043]\n",
      "[Epoch 82/100] [Batch 63/347] [D loss: 0.357920] [G loss: 0.418962]\n",
      "[Epoch 82/100] [Batch 64/347] [D loss: 0.334131] [G loss: 0.407656]\n",
      "[Epoch 82/100] [Batch 65/347] [D loss: 0.281983] [G loss: 0.408021]\n",
      "[Epoch 82/100] [Batch 66/347] [D loss: 0.287424] [G loss: 0.407458]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 82/100] [Batch 67/347] [D loss: 0.288608] [G loss: 0.400058]\n",
      "[Epoch 82/100] [Batch 68/347] [D loss: 0.291671] [G loss: 0.404521]\n",
      "[Epoch 82/100] [Batch 69/347] [D loss: 0.309684] [G loss: 0.410992]\n",
      "[Epoch 82/100] [Batch 70/347] [D loss: 0.306843] [G loss: 0.416695]\n",
      "[Epoch 82/100] [Batch 71/347] [D loss: 0.302680] [G loss: 0.436868]\n",
      "[Epoch 82/100] [Batch 72/347] [D loss: 0.310682] [G loss: 0.456152]\n",
      "[Epoch 82/100] [Batch 73/347] [D loss: 0.444550] [G loss: 0.457955]\n",
      "[Epoch 82/100] [Batch 74/347] [D loss: 0.448542] [G loss: 0.462617]\n",
      "[Epoch 82/100] [Batch 75/347] [D loss: 0.449098] [G loss: 0.465856]\n",
      "[Epoch 82/100] [Batch 76/347] [D loss: 0.451028] [G loss: 0.465234]\n",
      "[Epoch 82/100] [Batch 77/347] [D loss: 0.485367] [G loss: 0.465511]\n",
      "[Epoch 82/100] [Batch 78/347] [D loss: 0.531682] [G loss: 0.478517]\n",
      "[Epoch 82/100] [Batch 79/347] [D loss: 0.524171] [G loss: 0.482435]\n",
      "[Epoch 82/100] [Batch 80/347] [D loss: 0.424005] [G loss: 0.471281]\n",
      "[Epoch 82/100] [Batch 81/347] [D loss: 0.400137] [G loss: 0.467821]\n",
      "[Epoch 82/100] [Batch 82/347] [D loss: 0.398767] [G loss: 0.464162]\n",
      "[Epoch 82/100] [Batch 83/347] [D loss: 0.402255] [G loss: 0.456424]\n",
      "[Epoch 82/100] [Batch 84/347] [D loss: 0.523993] [G loss: 0.455891]\n",
      "[Epoch 82/100] [Batch 85/347] [D loss: 0.596258] [G loss: 0.456305]\n",
      "[Epoch 82/100] [Batch 86/347] [D loss: 0.597728] [G loss: 0.461636]\n",
      "[Epoch 82/100] [Batch 87/347] [D loss: 0.594413] [G loss: 0.471157]\n",
      "[Epoch 82/100] [Batch 88/347] [D loss: 0.597108] [G loss: 0.484323]\n",
      "[Epoch 82/100] [Batch 89/347] [D loss: 0.591145] [G loss: 0.500882]\n",
      "[Epoch 82/100] [Batch 90/347] [D loss: 0.581549] [G loss: 0.515670]\n",
      "[Epoch 82/100] [Batch 91/347] [D loss: 0.572392] [G loss: 0.528512]\n",
      "[Epoch 82/100] [Batch 92/347] [D loss: 0.564441] [G loss: 0.541946]\n",
      "[Epoch 82/100] [Batch 93/347] [D loss: 0.556868] [G loss: 0.552607]\n",
      "[Epoch 82/100] [Batch 94/347] [D loss: 0.549439] [G loss: 0.557596]\n",
      "[Epoch 82/100] [Batch 95/347] [D loss: 0.544285] [G loss: 0.563154]\n",
      "[Epoch 82/100] [Batch 96/347] [D loss: 0.541636] [G loss: 0.569252]\n",
      "[Epoch 82/100] [Batch 97/347] [D loss: 0.539300] [G loss: 0.572510]\n",
      "[Epoch 82/100] [Batch 98/347] [D loss: 0.535933] [G loss: 0.577113]\n",
      "[Epoch 82/100] [Batch 99/347] [D loss: 0.535395] [G loss: 0.579560]\n",
      "[Epoch 82/100] [Batch 100/347] [D loss: 0.534771] [G loss: 0.580991]\n",
      "[Epoch 82/100] [Batch 101/347] [D loss: 0.535353] [G loss: 0.579973]\n",
      "[Epoch 82/100] [Batch 102/347] [D loss: 0.540678] [G loss: 0.577653]\n",
      "[Epoch 82/100] [Batch 103/347] [D loss: 0.540883] [G loss: 0.578777]\n",
      "[Epoch 82/100] [Batch 104/347] [D loss: 0.538004] [G loss: 0.573601]\n",
      "[Epoch 82/100] [Batch 105/347] [D loss: 0.493393] [G loss: 0.566610]\n",
      "[Epoch 82/100] [Batch 106/347] [D loss: 0.342651] [G loss: 0.556674]\n",
      "[Epoch 82/100] [Batch 107/347] [D loss: 0.341479] [G loss: 0.554697]\n",
      "[Epoch 82/100] [Batch 108/347] [D loss: 0.330751] [G loss: 0.554410]\n",
      "[Epoch 82/100] [Batch 109/347] [D loss: 0.304834] [G loss: 0.555089]\n",
      "[Epoch 82/100] [Batch 110/347] [D loss: 0.380416] [G loss: 0.549829]\n",
      "[Epoch 82/100] [Batch 111/347] [D loss: 0.354903] [G loss: 0.549515]\n",
      "[Epoch 82/100] [Batch 112/347] [D loss: 0.326432] [G loss: 0.545846]\n",
      "[Epoch 82/100] [Batch 113/347] [D loss: 0.450616] [G loss: 0.553989]\n",
      "[Epoch 82/100] [Batch 114/347] [D loss: 0.510067] [G loss: 0.547648]\n",
      "[Epoch 82/100] [Batch 115/347] [D loss: 0.507464] [G loss: 0.515190]\n",
      "[Epoch 82/100] [Batch 116/347] [D loss: 0.453265] [G loss: 0.477314]\n",
      "[Epoch 82/100] [Batch 117/347] [D loss: 0.434011] [G loss: 0.440846]\n",
      "[Epoch 82/100] [Batch 118/347] [D loss: 0.369008] [G loss: 0.407429]\n",
      "[Epoch 82/100] [Batch 119/347] [D loss: 0.369531] [G loss: 0.380578]\n",
      "[Epoch 82/100] [Batch 120/347] [D loss: 0.371487] [G loss: 0.368912]\n",
      "[Epoch 82/100] [Batch 121/347] [D loss: 0.377680] [G loss: 0.358618]\n",
      "[Epoch 82/100] [Batch 122/347] [D loss: 0.496428] [G loss: 0.356331]\n",
      "[Epoch 82/100] [Batch 123/347] [D loss: 0.547245] [G loss: 0.359943]\n",
      "[Epoch 82/100] [Batch 124/347] [D loss: 0.481298] [G loss: 0.362175]\n",
      "[Epoch 82/100] [Batch 125/347] [D loss: 0.451088] [G loss: 0.372172]\n",
      "[Epoch 82/100] [Batch 126/347] [D loss: 0.412869] [G loss: 0.384412]\n",
      "[Epoch 82/100] [Batch 127/347] [D loss: 0.408863] [G loss: 0.394379]\n",
      "[Epoch 82/100] [Batch 128/347] [D loss: 0.388455] [G loss: 0.400304]\n",
      "[Epoch 82/100] [Batch 129/347] [D loss: 0.324955] [G loss: 0.415473]\n",
      "[Epoch 82/100] [Batch 130/347] [D loss: 0.257190] [G loss: 0.444406]\n",
      "[Epoch 82/100] [Batch 131/347] [D loss: 0.230810] [G loss: 0.468240]\n",
      "[Epoch 82/100] [Batch 132/347] [D loss: 0.209708] [G loss: 0.493644]\n",
      "[Epoch 82/100] [Batch 133/347] [D loss: 0.186784] [G loss: 0.515052]\n",
      "[Epoch 82/100] [Batch 134/347] [D loss: 0.174323] [G loss: 0.531976]\n",
      "[Epoch 82/100] [Batch 135/347] [D loss: 0.166779] [G loss: 0.543085]\n",
      "[Epoch 82/100] [Batch 136/347] [D loss: 0.166763] [G loss: 0.545450]\n",
      "[Epoch 82/100] [Batch 137/347] [D loss: 0.423261] [G loss: 0.543379]\n",
      "[Epoch 82/100] [Batch 138/347] [D loss: 0.452398] [G loss: 0.538253]\n",
      "[Epoch 82/100] [Batch 139/347] [D loss: 0.461642] [G loss: 0.529003]\n",
      "[Epoch 82/100] [Batch 140/347] [D loss: 0.470126] [G loss: 0.527925]\n",
      "[Epoch 82/100] [Batch 141/347] [D loss: 0.445175] [G loss: 0.521071]\n",
      "[Epoch 82/100] [Batch 142/347] [D loss: 0.450222] [G loss: 0.513547]\n",
      "[Epoch 82/100] [Batch 143/347] [D loss: 0.445517] [G loss: 0.502621]\n",
      "[Epoch 82/100] [Batch 144/347] [D loss: 0.431260] [G loss: 0.490755]\n",
      "[Epoch 82/100] [Batch 145/347] [D loss: 0.451307] [G loss: 0.486563]\n",
      "[Epoch 82/100] [Batch 146/347] [D loss: 0.461820] [G loss: 0.475133]\n",
      "[Epoch 82/100] [Batch 147/347] [D loss: 0.476567] [G loss: 0.462882]\n",
      "[Epoch 82/100] [Batch 148/347] [D loss: 0.489687] [G loss: 0.451982]\n",
      "[Epoch 82/100] [Batch 149/347] [D loss: 0.428388] [G loss: 0.434262]\n",
      "[Epoch 82/100] [Batch 150/347] [D loss: 0.397329] [G loss: 0.412751]\n",
      "[Epoch 82/100] [Batch 151/347] [D loss: 0.379214] [G loss: 0.387016]\n",
      "[Epoch 82/100] [Batch 152/347] [D loss: 0.366402] [G loss: 0.357807]\n",
      "[Epoch 82/100] [Batch 153/347] [D loss: 0.375961] [G loss: 0.334702]\n",
      "[Epoch 82/100] [Batch 154/347] [D loss: 0.376170] [G loss: 0.320695]\n",
      "[Epoch 82/100] [Batch 155/347] [D loss: 0.375191] [G loss: 0.319430]\n",
      "[Epoch 82/100] [Batch 156/347] [D loss: 0.370846] [G loss: 0.318813]\n",
      "[Epoch 82/100] [Batch 157/347] [D loss: 0.357811] [G loss: 0.327824]\n",
      "[Epoch 82/100] [Batch 158/347] [D loss: 0.327200] [G loss: 0.345784]\n",
      "[Epoch 82/100] [Batch 159/347] [D loss: 0.334240] [G loss: 0.365415]\n",
      "[Epoch 82/100] [Batch 160/347] [D loss: 0.316861] [G loss: 0.393854]\n",
      "[Epoch 82/100] [Batch 161/347] [D loss: 0.298398] [G loss: 0.419725]\n",
      "[Epoch 82/100] [Batch 162/347] [D loss: 0.291051] [G loss: 0.435143]\n",
      "[Epoch 82/100] [Batch 163/347] [D loss: 0.291960] [G loss: 0.441176]\n",
      "[Epoch 82/100] [Batch 164/347] [D loss: 0.293264] [G loss: 0.454549]\n",
      "[Epoch 82/100] [Batch 165/347] [D loss: 0.295730] [G loss: 0.469445]\n",
      "[Epoch 82/100] [Batch 166/347] [D loss: 0.298462] [G loss: 0.479571]\n",
      "[Epoch 82/100] [Batch 167/347] [D loss: 0.327886] [G loss: 0.501388]\n",
      "[Epoch 82/100] [Batch 168/347] [D loss: 0.327507] [G loss: 0.510380]\n",
      "[Epoch 82/100] [Batch 169/347] [D loss: 0.458410] [G loss: 0.518444]\n",
      "[Epoch 82/100] [Batch 170/347] [D loss: 0.526101] [G loss: 0.524197]\n",
      "[Epoch 82/100] [Batch 171/347] [D loss: 0.526690] [G loss: 0.523216]\n",
      "[Epoch 82/100] [Batch 172/347] [D loss: 0.525710] [G loss: 0.523887]\n",
      "[Epoch 82/100] [Batch 173/347] [D loss: 0.527527] [G loss: 0.522340]\n",
      "[Epoch 82/100] [Batch 174/347] [D loss: 0.524071] [G loss: 0.525857]\n",
      "[Epoch 82/100] [Batch 175/347] [D loss: 0.539427] [G loss: 0.530920]\n",
      "[Epoch 82/100] [Batch 176/347] [D loss: 0.548777] [G loss: 0.534991]\n",
      "[Epoch 82/100] [Batch 177/347] [D loss: 0.548334] [G loss: 0.533922]\n",
      "[Epoch 82/100] [Batch 178/347] [D loss: 0.546445] [G loss: 0.530916]\n",
      "[Epoch 82/100] [Batch 179/347] [D loss: 0.544495] [G loss: 0.530100]\n",
      "[Epoch 82/100] [Batch 180/347] [D loss: 0.543018] [G loss: 0.529159]\n",
      "[Epoch 82/100] [Batch 181/347] [D loss: 0.540853] [G loss: 0.534724]\n",
      "[Epoch 82/100] [Batch 182/347] [D loss: 0.540048] [G loss: 0.538960]\n",
      "[Epoch 82/100] [Batch 183/347] [D loss: 0.538277] [G loss: 0.543419]\n",
      "[Epoch 82/100] [Batch 184/347] [D loss: 0.540380] [G loss: 0.548206]\n",
      "[Epoch 82/100] [Batch 185/347] [D loss: 0.539950] [G loss: 0.547144]\n",
      "[Epoch 82/100] [Batch 186/347] [D loss: 0.536546] [G loss: 0.547964]\n",
      "[Epoch 82/100] [Batch 187/347] [D loss: 0.534190] [G loss: 0.546368]\n",
      "[Epoch 82/100] [Batch 188/347] [D loss: 0.528570] [G loss: 0.539368]\n",
      "[Epoch 82/100] [Batch 189/347] [D loss: 0.519171] [G loss: 0.533848]\n",
      "[Epoch 82/100] [Batch 190/347] [D loss: 0.517431] [G loss: 0.531264]\n",
      "[Epoch 82/100] [Batch 191/347] [D loss: 0.517477] [G loss: 0.528292]\n",
      "[Epoch 82/100] [Batch 192/347] [D loss: 0.517959] [G loss: 0.528151]\n",
      "[Epoch 82/100] [Batch 193/347] [D loss: 0.527173] [G loss: 0.527976]\n",
      "[Epoch 82/100] [Batch 194/347] [D loss: 0.526320] [G loss: 0.523568]\n",
      "[Epoch 82/100] [Batch 195/347] [D loss: 0.522583] [G loss: 0.519531]\n",
      "[Epoch 82/100] [Batch 196/347] [D loss: 0.515324] [G loss: 0.515384]\n",
      "[Epoch 82/100] [Batch 197/347] [D loss: 0.513966] [G loss: 0.512396]\n",
      "[Epoch 82/100] [Batch 198/347] [D loss: 0.512908] [G loss: 0.513019]\n",
      "[Epoch 82/100] [Batch 199/347] [D loss: 0.511097] [G loss: 0.510725]\n",
      "[Epoch 82/100] [Batch 200/347] [D loss: 0.519126] [G loss: 0.508332]\n",
      "[Epoch 82/100] [Batch 201/347] [D loss: 0.523453] [G loss: 0.505026]\n",
      "[Epoch 82/100] [Batch 202/347] [D loss: 0.523613] [G loss: 0.501176]\n",
      "[Epoch 82/100] [Batch 203/347] [D loss: 0.528959] [G loss: 0.497541]\n",
      "[Epoch 82/100] [Batch 204/347] [D loss: 0.526318] [G loss: 0.498231]\n",
      "[Epoch 82/100] [Batch 205/347] [D loss: 0.524762] [G loss: 0.500570]\n",
      "[Epoch 82/100] [Batch 206/347] [D loss: 0.523186] [G loss: 0.501138]\n",
      "[Epoch 82/100] [Batch 207/347] [D loss: 0.511743] [G loss: 0.500601]\n",
      "[Epoch 82/100] [Batch 208/347] [D loss: 0.507799] [G loss: 0.501227]\n",
      "[Epoch 82/100] [Batch 209/347] [D loss: 0.504347] [G loss: 0.493346]\n",
      "[Epoch 82/100] [Batch 210/347] [D loss: 0.474633] [G loss: 0.489418]\n",
      "[Epoch 82/100] [Batch 211/347] [D loss: 0.407300] [G loss: 0.479038]\n",
      "[Epoch 82/100] [Batch 212/347] [D loss: 0.233336] [G loss: 0.462671]\n",
      "[Epoch 82/100] [Batch 213/347] [D loss: 0.227324] [G loss: 0.460686]\n",
      "[Epoch 82/100] [Batch 214/347] [D loss: 0.219317] [G loss: 0.455052]\n",
      "[Epoch 82/100] [Batch 215/347] [D loss: 0.215361] [G loss: 0.450063]\n",
      "[Epoch 82/100] [Batch 216/347] [D loss: 0.395925] [G loss: 0.452310]\n",
      "[Epoch 82/100] [Batch 217/347] [D loss: 0.427161] [G loss: 0.456387]\n",
      "[Epoch 82/100] [Batch 218/347] [D loss: 0.461415] [G loss: 0.458525]\n",
      "[Epoch 82/100] [Batch 219/347] [D loss: 0.436331] [G loss: 0.449825]\n",
      "[Epoch 82/100] [Batch 220/347] [D loss: 0.417306] [G loss: 0.438516]\n",
      "[Epoch 82/100] [Batch 221/347] [D loss: 0.440442] [G loss: 0.421269]\n",
      "[Epoch 82/100] [Batch 222/347] [D loss: 0.440852] [G loss: 0.396926]\n",
      "[Epoch 82/100] [Batch 223/347] [D loss: 0.422584] [G loss: 0.363961]\n",
      "[Epoch 82/100] [Batch 224/347] [D loss: 0.433312] [G loss: 0.330460]\n",
      "[Epoch 82/100] [Batch 225/347] [D loss: 0.444443] [G loss: 0.302551]\n",
      "[Epoch 82/100] [Batch 226/347] [D loss: 0.456844] [G loss: 0.285389]\n",
      "[Epoch 82/100] [Batch 227/347] [D loss: 0.506600] [G loss: 0.281979]\n",
      "[Epoch 82/100] [Batch 228/347] [D loss: 0.528493] [G loss: 0.283227]\n",
      "[Epoch 82/100] [Batch 229/347] [D loss: 0.528965] [G loss: 0.287353]\n",
      "[Epoch 82/100] [Batch 230/347] [D loss: 0.540116] [G loss: 0.293475]\n",
      "[Epoch 82/100] [Batch 231/347] [D loss: 0.510279] [G loss: 0.294602]\n",
      "[Epoch 82/100] [Batch 232/347] [D loss: 0.489695] [G loss: 0.302156]\n",
      "[Epoch 82/100] [Batch 233/347] [D loss: 0.419470] [G loss: 0.317376]\n",
      "[Epoch 82/100] [Batch 234/347] [D loss: 0.376377] [G loss: 0.334974]\n",
      "[Epoch 82/100] [Batch 235/347] [D loss: 0.369040] [G loss: 0.361333]\n",
      "[Epoch 82/100] [Batch 236/347] [D loss: 0.357233] [G loss: 0.385958]\n",
      "[Epoch 82/100] [Batch 237/347] [D loss: 0.416990] [G loss: 0.406124]\n",
      "[Epoch 82/100] [Batch 238/347] [D loss: 0.492712] [G loss: 0.417598]\n",
      "[Epoch 82/100] [Batch 239/347] [D loss: 0.495581] [G loss: 0.423351]\n",
      "[Epoch 82/100] [Batch 240/347] [D loss: 0.497658] [G loss: 0.429099]\n",
      "[Epoch 82/100] [Batch 241/347] [D loss: 0.500189] [G loss: 0.436318]\n",
      "[Epoch 82/100] [Batch 242/347] [D loss: 0.512305] [G loss: 0.444514]\n",
      "[Epoch 82/100] [Batch 243/347] [D loss: 0.470057] [G loss: 0.450388]\n",
      "[Epoch 82/100] [Batch 244/347] [D loss: 0.442861] [G loss: 0.444375]\n",
      "[Epoch 82/100] [Batch 245/347] [D loss: 0.449887] [G loss: 0.434150]\n",
      "[Epoch 82/100] [Batch 246/347] [D loss: 0.449142] [G loss: 0.420346]\n",
      "[Epoch 82/100] [Batch 247/347] [D loss: 0.479056] [G loss: 0.409408]\n",
      "[Epoch 82/100] [Batch 248/347] [D loss: 0.501632] [G loss: 0.409724]\n",
      "[Epoch 82/100] [Batch 249/347] [D loss: 0.483130] [G loss: 0.414564]\n",
      "[Epoch 82/100] [Batch 250/347] [D loss: 0.473243] [G loss: 0.420002]\n",
      "[Epoch 82/100] [Batch 251/347] [D loss: 0.455787] [G loss: 0.422797]\n",
      "[Epoch 82/100] [Batch 252/347] [D loss: 0.444811] [G loss: 0.420829]\n",
      "[Epoch 82/100] [Batch 253/347] [D loss: 0.391009] [G loss: 0.406678]\n",
      "[Epoch 82/100] [Batch 254/347] [D loss: 0.387243] [G loss: 0.402874]\n",
      "[Epoch 82/100] [Batch 255/347] [D loss: 0.384526] [G loss: 0.394638]\n",
      "[Epoch 82/100] [Batch 256/347] [D loss: 0.384843] [G loss: 0.381145]\n",
      "[Epoch 82/100] [Batch 257/347] [D loss: 0.362971] [G loss: 0.371914]\n",
      "[Epoch 82/100] [Batch 258/347] [D loss: 0.326451] [G loss: 0.365432]\n",
      "[Epoch 82/100] [Batch 259/347] [D loss: 0.329506] [G loss: 0.360609]\n",
      "[Epoch 82/100] [Batch 260/347] [D loss: 0.329623] [G loss: 0.360092]\n",
      "[Epoch 82/100] [Batch 261/347] [D loss: 0.321462] [G loss: 0.368214]\n",
      "[Epoch 82/100] [Batch 262/347] [D loss: 0.289964] [G loss: 0.375817]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 82/100] [Batch 263/347] [D loss: 0.285388] [G loss: 0.386069]\n",
      "[Epoch 82/100] [Batch 264/347] [D loss: 0.279458] [G loss: 0.397668]\n",
      "[Epoch 82/100] [Batch 265/347] [D loss: 0.285995] [G loss: 0.408126]\n",
      "[Epoch 82/100] [Batch 266/347] [D loss: 0.344508] [G loss: 0.417437]\n",
      "[Epoch 82/100] [Batch 267/347] [D loss: 0.365222] [G loss: 0.423116]\n",
      "[Epoch 82/100] [Batch 268/347] [D loss: 0.370006] [G loss: 0.425108]\n",
      "[Epoch 82/100] [Batch 269/347] [D loss: 0.373947] [G loss: 0.424648]\n",
      "[Epoch 82/100] [Batch 270/347] [D loss: 0.400735] [G loss: 0.421776]\n",
      "[Epoch 82/100] [Batch 271/347] [D loss: 0.363780] [G loss: 0.422448]\n",
      "[Epoch 82/100] [Batch 272/347] [D loss: 0.408051] [G loss: 0.438222]\n",
      "[Epoch 82/100] [Batch 273/347] [D loss: 0.377368] [G loss: 0.453621]\n",
      "[Epoch 82/100] [Batch 274/347] [D loss: 0.348650] [G loss: 0.467042]\n",
      "[Epoch 82/100] [Batch 275/347] [D loss: 0.294190] [G loss: 0.478208]\n",
      "[Epoch 82/100] [Batch 276/347] [D loss: 0.443148] [G loss: 0.473991]\n",
      "[Epoch 82/100] [Batch 277/347] [D loss: 0.475795] [G loss: 0.482773]\n",
      "[Epoch 82/100] [Batch 278/347] [D loss: 0.484355] [G loss: 0.490369]\n",
      "[Epoch 82/100] [Batch 279/347] [D loss: 0.492796] [G loss: 0.490075]\n",
      "[Epoch 82/100] [Batch 280/347] [D loss: 0.497292] [G loss: 0.488228]\n",
      "[Epoch 82/100] [Batch 281/347] [D loss: 0.507678] [G loss: 0.487087]\n",
      "[Epoch 82/100] [Batch 282/347] [D loss: 0.508759] [G loss: 0.488485]\n",
      "[Epoch 82/100] [Batch 283/347] [D loss: 0.509050] [G loss: 0.488519]\n",
      "[Epoch 82/100] [Batch 284/347] [D loss: 0.509553] [G loss: 0.489711]\n",
      "[Epoch 82/100] [Batch 285/347] [D loss: 0.514707] [G loss: 0.489771]\n",
      "[Epoch 82/100] [Batch 286/347] [D loss: 0.512211] [G loss: 0.474828]\n",
      "[Epoch 82/100] [Batch 287/347] [D loss: 0.513019] [G loss: 0.471272]\n",
      "[Epoch 82/100] [Batch 288/347] [D loss: 0.512423] [G loss: 0.467755]\n",
      "[Epoch 82/100] [Batch 289/347] [D loss: 0.509856] [G loss: 0.461797]\n",
      "[Epoch 82/100] [Batch 290/347] [D loss: 0.507676] [G loss: 0.477102]\n",
      "[Epoch 82/100] [Batch 291/347] [D loss: 0.504669] [G loss: 0.483186]\n",
      "[Epoch 82/100] [Batch 292/347] [D loss: 0.495460] [G loss: 0.486044]\n",
      "[Epoch 82/100] [Batch 293/347] [D loss: 0.356165] [G loss: 0.489916]\n",
      "[Epoch 82/100] [Batch 294/347] [D loss: 0.343096] [G loss: 0.491671]\n",
      "[Epoch 82/100] [Batch 295/347] [D loss: 0.326941] [G loss: 0.487123]\n",
      "[Epoch 82/100] [Batch 296/347] [D loss: 0.305793] [G loss: 0.481359]\n",
      "[Epoch 82/100] [Batch 297/347] [D loss: 0.450119] [G loss: 0.480853]\n",
      "[Epoch 82/100] [Batch 298/347] [D loss: 0.471726] [G loss: 0.467457]\n",
      "[Epoch 82/100] [Batch 299/347] [D loss: 0.457705] [G loss: 0.452422]\n",
      "[Epoch 82/100] [Batch 300/347] [D loss: 0.435121] [G loss: 0.434358]\n",
      "[Epoch 82/100] [Batch 301/347] [D loss: 0.423246] [G loss: 0.398420]\n",
      "[Epoch 82/100] [Batch 302/347] [D loss: 0.417697] [G loss: 0.362264]\n",
      "[Epoch 82/100] [Batch 303/347] [D loss: 0.404697] [G loss: 0.323646]\n",
      "[Epoch 82/100] [Batch 304/347] [D loss: 0.315575] [G loss: 0.291208]\n",
      "[Epoch 82/100] [Batch 305/347] [D loss: 0.290775] [G loss: 0.273845]\n",
      "[Epoch 82/100] [Batch 306/347] [D loss: 0.305006] [G loss: 0.275336]\n",
      "[Epoch 82/100] [Batch 307/347] [D loss: 0.307504] [G loss: 0.290075]\n",
      "[Epoch 82/100] [Batch 308/347] [D loss: 0.336831] [G loss: 0.310420]\n",
      "[Epoch 82/100] [Batch 309/347] [D loss: 0.416236] [G loss: 0.342071]\n",
      "[Epoch 82/100] [Batch 310/347] [D loss: 0.532471] [G loss: 0.371174]\n",
      "[Epoch 82/100] [Batch 311/347] [D loss: 0.489572] [G loss: 0.385038]\n",
      "[Epoch 82/100] [Batch 312/347] [D loss: 0.403030] [G loss: 0.393882]\n",
      "[Epoch 82/100] [Batch 313/347] [D loss: 0.375810] [G loss: 0.397380]\n",
      "[Epoch 82/100] [Batch 314/347] [D loss: 0.369397] [G loss: 0.392745]\n",
      "[Epoch 82/100] [Batch 315/347] [D loss: 0.376109] [G loss: 0.389009]\n",
      "[Epoch 82/100] [Batch 316/347] [D loss: 0.405374] [G loss: 0.394577]\n",
      "[Epoch 82/100] [Batch 317/347] [D loss: 0.427019] [G loss: 0.401001]\n",
      "[Epoch 82/100] [Batch 318/347] [D loss: 0.437816] [G loss: 0.414306]\n",
      "[Epoch 82/100] [Batch 319/347] [D loss: 0.418299] [G loss: 0.424800]\n",
      "[Epoch 82/100] [Batch 320/347] [D loss: 0.413765] [G loss: 0.420314]\n",
      "[Epoch 82/100] [Batch 321/347] [D loss: 0.398245] [G loss: 0.409956]\n",
      "[Epoch 82/100] [Batch 322/347] [D loss: 0.407260] [G loss: 0.398174]\n",
      "[Epoch 82/100] [Batch 323/347] [D loss: 0.345833] [G loss: 0.385883]\n",
      "[Epoch 82/100] [Batch 324/347] [D loss: 0.341392] [G loss: 0.376939]\n",
      "[Epoch 82/100] [Batch 325/347] [D loss: 0.343637] [G loss: 0.367881]\n",
      "[Epoch 82/100] [Batch 326/347] [D loss: 0.347846] [G loss: 0.359533]\n",
      "[Epoch 82/100] [Batch 327/347] [D loss: 0.335924] [G loss: 0.355780]\n",
      "[Epoch 82/100] [Batch 328/347] [D loss: 0.340419] [G loss: 0.354255]\n",
      "[Epoch 82/100] [Batch 329/347] [D loss: 0.339166] [G loss: 0.357087]\n",
      "[Epoch 82/100] [Batch 330/347] [D loss: 0.337318] [G loss: 0.362707]\n",
      "[Epoch 82/100] [Batch 331/347] [D loss: 0.360412] [G loss: 0.375189]\n",
      "[Epoch 82/100] [Batch 332/347] [D loss: 0.442807] [G loss: 0.400321]\n",
      "[Epoch 82/100] [Batch 333/347] [D loss: 0.403322] [G loss: 0.403154]\n",
      "[Epoch 82/100] [Batch 334/347] [D loss: 0.396401] [G loss: 0.400392]\n",
      "[Epoch 82/100] [Batch 335/347] [D loss: 0.397670] [G loss: 0.401323]\n",
      "[Epoch 82/100] [Batch 336/347] [D loss: 0.397386] [G loss: 0.402523]\n",
      "[Epoch 82/100] [Batch 337/347] [D loss: 0.450516] [G loss: 0.407227]\n",
      "[Epoch 82/100] [Batch 338/347] [D loss: 0.492099] [G loss: 0.414959]\n",
      "[Epoch 82/100] [Batch 339/347] [D loss: 0.471330] [G loss: 0.415306]\n",
      "[Epoch 82/100] [Batch 340/347] [D loss: 0.438101] [G loss: 0.412719]\n",
      "[Epoch 82/100] [Batch 341/347] [D loss: 0.448587] [G loss: 0.414127]\n",
      "[Epoch 82/100] [Batch 342/347] [D loss: 0.324132] [G loss: 0.404939]\n",
      "[Epoch 82/100] [Batch 343/347] [D loss: 0.287057] [G loss: 0.394906]\n",
      "[Epoch 82/100] [Batch 344/347] [D loss: 0.265199] [G loss: 0.396620]\n",
      "[Epoch 82/100] [Batch 345/347] [D loss: 0.212705] [G loss: 0.408768]\n",
      "[Epoch 82/100] [Batch 346/347] [D loss: 0.203727] [G loss: 0.424475]\n",
      "[Epoch 82/100] [Batch 347/347] [D loss: 0.192976] [G loss: 0.440396]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 83/100] [Batch 1/347] [D loss: 0.450985] [G loss: 0.467813]\n",
      "[Epoch 83/100] [Batch 2/347] [D loss: 0.483373] [G loss: 0.475205]\n",
      "[Epoch 83/100] [Batch 3/347] [D loss: 0.521600] [G loss: 0.485281]\n",
      "[Epoch 83/100] [Batch 4/347] [D loss: 0.525295] [G loss: 0.490176]\n",
      "[Epoch 83/100] [Batch 5/347] [D loss: 0.526833] [G loss: 0.490477]\n",
      "[Epoch 83/100] [Batch 6/347] [D loss: 0.509568] [G loss: 0.490243]\n",
      "[Epoch 83/100] [Batch 7/347] [D loss: 0.491915] [G loss: 0.482569]\n",
      "[Epoch 83/100] [Batch 8/347] [D loss: 0.494666] [G loss: 0.480887]\n",
      "[Epoch 83/100] [Batch 9/347] [D loss: 0.491404] [G loss: 0.480315]\n",
      "[Epoch 83/100] [Batch 10/347] [D loss: 0.494525] [G loss: 0.478657]\n",
      "[Epoch 83/100] [Batch 11/347] [D loss: 0.515241] [G loss: 0.485026]\n",
      "[Epoch 83/100] [Batch 12/347] [D loss: 0.523460] [G loss: 0.484385]\n",
      "[Epoch 83/100] [Batch 13/347] [D loss: 0.506469] [G loss: 0.479858]\n",
      "[Epoch 83/100] [Batch 14/347] [D loss: 0.486589] [G loss: 0.473730]\n",
      "[Epoch 83/100] [Batch 15/347] [D loss: 0.488781] [G loss: 0.457443]\n",
      "[Epoch 83/100] [Batch 16/347] [D loss: 0.478798] [G loss: 0.442722]\n",
      "[Epoch 83/100] [Batch 17/347] [D loss: 0.479921] [G loss: 0.433965]\n",
      "[Epoch 83/100] [Batch 18/347] [D loss: 0.487900] [G loss: 0.421379]\n",
      "[Epoch 83/100] [Batch 19/347] [D loss: 0.479839] [G loss: 0.411085]\n",
      "[Epoch 83/100] [Batch 20/347] [D loss: 0.496421] [G loss: 0.399364]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 83/100] [Batch 21/347] [D loss: 0.422586] [G loss: 0.378568]\n",
      "[Epoch 83/100] [Batch 22/347] [D loss: 0.422995] [G loss: 0.362780]\n",
      "[Epoch 83/100] [Batch 23/347] [D loss: 0.428457] [G loss: 0.347977]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 83/100] [Batch 24/347] [D loss: 0.391149] [G loss: 0.332385]\n",
      "[Epoch 83/100] [Batch 25/347] [D loss: 0.306827] [G loss: 0.335657]\n",
      "[Epoch 83/100] [Batch 26/347] [D loss: 0.306888] [G loss: 0.342638]\n",
      "[Epoch 83/100] [Batch 27/347] [D loss: 0.303333] [G loss: 0.358538]\n",
      "[Epoch 83/100] [Batch 28/347] [D loss: 0.298917] [G loss: 0.381173]\n",
      "[Epoch 83/100] [Batch 29/347] [D loss: 0.312249] [G loss: 0.406343]\n",
      "[Epoch 83/100] [Batch 30/347] [D loss: 0.299020] [G loss: 0.425888]\n",
      "[Epoch 83/100] [Batch 31/347] [D loss: 0.295026] [G loss: 0.440715]\n",
      "[Epoch 83/100] [Batch 32/347] [D loss: 0.304249] [G loss: 0.449415]\n",
      "[Epoch 83/100] [Batch 33/347] [D loss: 0.322866] [G loss: 0.455541]\n",
      "[Epoch 83/100] [Batch 34/347] [D loss: 0.378051] [G loss: 0.454913]\n",
      "[Epoch 83/100] [Batch 35/347] [D loss: 0.385460] [G loss: 0.445483]\n",
      "[Epoch 83/100] [Batch 36/347] [D loss: 0.420245] [G loss: 0.436468]\n",
      "[Epoch 83/100] [Batch 37/347] [D loss: 0.430756] [G loss: 0.423487]\n",
      "[Epoch 83/100] [Batch 38/347] [D loss: 0.430180] [G loss: 0.405622]\n",
      "[Epoch 83/100] [Batch 39/347] [D loss: 0.436954] [G loss: 0.396574]\n",
      "[Epoch 83/100] [Batch 40/347] [D loss: 0.461705] [G loss: 0.388942]\n",
      "[Epoch 83/100] [Batch 41/347] [D loss: 0.481856] [G loss: 0.378751]\n",
      "[Epoch 83/100] [Batch 42/347] [D loss: 0.477171] [G loss: 0.374936]\n",
      "[Epoch 83/100] [Batch 43/347] [D loss: 0.502683] [G loss: 0.377828]\n",
      "[Epoch 83/100] [Batch 44/347] [D loss: 0.482422] [G loss: 0.373810]\n",
      "[Epoch 83/100] [Batch 45/347] [D loss: 0.453339] [G loss: 0.358680]\n",
      "[Epoch 83/100] [Batch 46/347] [D loss: 0.374712] [G loss: 0.344806]\n",
      "[Epoch 83/100] [Batch 47/347] [D loss: 0.372316] [G loss: 0.339696]\n",
      "[Epoch 83/100] [Batch 48/347] [D loss: 0.286299] [G loss: 0.350722]\n",
      "[Epoch 83/100] [Batch 49/347] [D loss: 0.271559] [G loss: 0.376352]\n",
      "[Epoch 83/100] [Batch 50/347] [D loss: 0.256959] [G loss: 0.407286]\n",
      "[Epoch 83/100] [Batch 51/347] [D loss: 0.235968] [G loss: 0.434526]\n",
      "[Epoch 83/100] [Batch 52/347] [D loss: 0.336585] [G loss: 0.449158]\n",
      "[Epoch 83/100] [Batch 53/347] [D loss: 0.383475] [G loss: 0.449267]\n",
      "[Epoch 83/100] [Batch 54/347] [D loss: 0.367186] [G loss: 0.445867]\n",
      "[Epoch 83/100] [Batch 55/347] [D loss: 0.362989] [G loss: 0.452722]\n",
      "[Epoch 83/100] [Batch 56/347] [D loss: 0.354121] [G loss: 0.460786]\n",
      "[Epoch 83/100] [Batch 57/347] [D loss: 0.298842] [G loss: 0.466468]\n",
      "[Epoch 83/100] [Batch 58/347] [D loss: 0.306421] [G loss: 0.467051]\n",
      "[Epoch 83/100] [Batch 59/347] [D loss: 0.304361] [G loss: 0.457993]\n",
      "[Epoch 83/100] [Batch 60/347] [D loss: 0.291943] [G loss: 0.439699]\n",
      "[Epoch 83/100] [Batch 61/347] [D loss: 0.310785] [G loss: 0.419339]\n",
      "[Epoch 83/100] [Batch 62/347] [D loss: 0.309987] [G loss: 0.412660]\n",
      "[Epoch 83/100] [Batch 63/347] [D loss: 0.303182] [G loss: 0.406364]\n",
      "[Epoch 83/100] [Batch 64/347] [D loss: 0.284161] [G loss: 0.399400]\n",
      "[Epoch 83/100] [Batch 65/347] [D loss: 0.238392] [G loss: 0.402773]\n",
      "[Epoch 83/100] [Batch 66/347] [D loss: 0.241054] [G loss: 0.405375]\n",
      "[Epoch 83/100] [Batch 67/347] [D loss: 0.239625] [G loss: 0.400182]\n",
      "[Epoch 83/100] [Batch 68/347] [D loss: 0.240099] [G loss: 0.404312]\n",
      "[Epoch 83/100] [Batch 69/347] [D loss: 0.257253] [G loss: 0.409710]\n",
      "[Epoch 83/100] [Batch 70/347] [D loss: 0.254303] [G loss: 0.412808]\n",
      "[Epoch 83/100] [Batch 71/347] [D loss: 0.252033] [G loss: 0.429574]\n",
      "[Epoch 83/100] [Batch 72/347] [D loss: 0.260175] [G loss: 0.444851]\n",
      "[Epoch 83/100] [Batch 73/347] [D loss: 0.390497] [G loss: 0.442757]\n",
      "[Epoch 83/100] [Batch 74/347] [D loss: 0.392430] [G loss: 0.443267]\n",
      "[Epoch 83/100] [Batch 75/347] [D loss: 0.389704] [G loss: 0.441966]\n",
      "[Epoch 83/100] [Batch 76/347] [D loss: 0.387436] [G loss: 0.436026]\n",
      "[Epoch 83/100] [Batch 77/347] [D loss: 0.422719] [G loss: 0.437739]\n",
      "[Epoch 83/100] [Batch 78/347] [D loss: 0.470697] [G loss: 0.441497]\n",
      "[Epoch 83/100] [Batch 79/347] [D loss: 0.462219] [G loss: 0.435227]\n",
      "[Epoch 83/100] [Batch 80/347] [D loss: 0.352919] [G loss: 0.416045]\n",
      "[Epoch 83/100] [Batch 81/347] [D loss: 0.333787] [G loss: 0.409009]\n",
      "[Epoch 83/100] [Batch 82/347] [D loss: 0.333707] [G loss: 0.405862]\n",
      "[Epoch 83/100] [Batch 83/347] [D loss: 0.340009] [G loss: 0.401402]\n",
      "[Epoch 83/100] [Batch 84/347] [D loss: 0.477733] [G loss: 0.403515]\n",
      "[Epoch 83/100] [Batch 85/347] [D loss: 0.559378] [G loss: 0.403041]\n",
      "[Epoch 83/100] [Batch 86/347] [D loss: 0.562284] [G loss: 0.403345]\n",
      "[Epoch 83/100] [Batch 87/347] [D loss: 0.562205] [G loss: 0.406086]\n",
      "[Epoch 83/100] [Batch 88/347] [D loss: 0.581839] [G loss: 0.409781]\n",
      "[Epoch 83/100] [Batch 89/347] [D loss: 0.587999] [G loss: 0.418000]\n",
      "[Epoch 83/100] [Batch 90/347] [D loss: 0.585069] [G loss: 0.425044]\n",
      "[Epoch 83/100] [Batch 91/347] [D loss: 0.584568] [G loss: 0.434092]\n",
      "[Epoch 83/100] [Batch 92/347] [D loss: 0.582766] [G loss: 0.446876]\n",
      "[Epoch 83/100] [Batch 93/347] [D loss: 0.578685] [G loss: 0.461034]\n",
      "[Epoch 83/100] [Batch 94/347] [D loss: 0.564394] [G loss: 0.471408]\n",
      "[Epoch 83/100] [Batch 95/347] [D loss: 0.555159] [G loss: 0.483797]\n",
      "[Epoch 83/100] [Batch 96/347] [D loss: 0.550451] [G loss: 0.497042]\n",
      "[Epoch 83/100] [Batch 97/347] [D loss: 0.544774] [G loss: 0.506849]\n",
      "[Epoch 83/100] [Batch 98/347] [D loss: 0.534226] [G loss: 0.517236]\n",
      "[Epoch 83/100] [Batch 99/347] [D loss: 0.534488] [G loss: 0.524516]\n",
      "[Epoch 83/100] [Batch 100/347] [D loss: 0.532393] [G loss: 0.529993]\n",
      "[Epoch 83/100] [Batch 101/347] [D loss: 0.533391] [G loss: 0.533164]\n",
      "[Epoch 83/100] [Batch 102/347] [D loss: 0.541036] [G loss: 0.534122]\n",
      "[Epoch 83/100] [Batch 103/347] [D loss: 0.540055] [G loss: 0.538263]\n",
      "[Epoch 83/100] [Batch 104/347] [D loss: 0.535353] [G loss: 0.536111]\n",
      "[Epoch 83/100] [Batch 105/347] [D loss: 0.455066] [G loss: 0.531417]\n",
      "[Epoch 83/100] [Batch 106/347] [D loss: 0.209992] [G loss: 0.523566]\n",
      "[Epoch 83/100] [Batch 107/347] [D loss: 0.209618] [G loss: 0.522896]\n",
      "[Epoch 83/100] [Batch 108/347] [D loss: 0.211012] [G loss: 0.522686]\n",
      "[Epoch 83/100] [Batch 109/347] [D loss: 0.195846] [G loss: 0.519203]\n",
      "[Epoch 83/100] [Batch 110/347] [D loss: 0.258711] [G loss: 0.524508]\n",
      "[Epoch 83/100] [Batch 111/347] [D loss: 0.250061] [G loss: 0.526012]\n",
      "[Epoch 83/100] [Batch 112/347] [D loss: 0.239041] [G loss: 0.524846]\n",
      "[Epoch 83/100] [Batch 113/347] [D loss: 0.417358] [G loss: 0.534978]\n",
      "[Epoch 83/100] [Batch 114/347] [D loss: 0.482091] [G loss: 0.530928]\n",
      "[Epoch 83/100] [Batch 115/347] [D loss: 0.476782] [G loss: 0.500043]\n",
      "[Epoch 83/100] [Batch 116/347] [D loss: 0.401070] [G loss: 0.464439]\n",
      "[Epoch 83/100] [Batch 117/347] [D loss: 0.382293] [G loss: 0.431492]\n",
      "[Epoch 83/100] [Batch 118/347] [D loss: 0.322842] [G loss: 0.397681]\n",
      "[Epoch 83/100] [Batch 119/347] [D loss: 0.325088] [G loss: 0.378748]\n",
      "[Epoch 83/100] [Batch 120/347] [D loss: 0.328484] [G loss: 0.371946]\n",
      "[Epoch 83/100] [Batch 121/347] [D loss: 0.333195] [G loss: 0.366372]\n",
      "[Epoch 83/100] [Batch 122/347] [D loss: 0.449667] [G loss: 0.368650]\n",
      "[Epoch 83/100] [Batch 123/347] [D loss: 0.499468] [G loss: 0.375091]\n",
      "[Epoch 83/100] [Batch 124/347] [D loss: 0.430184] [G loss: 0.380192]\n",
      "[Epoch 83/100] [Batch 125/347] [D loss: 0.398671] [G loss: 0.392428]\n",
      "[Epoch 83/100] [Batch 126/347] [D loss: 0.358401] [G loss: 0.406456]\n",
      "[Epoch 83/100] [Batch 127/347] [D loss: 0.355305] [G loss: 0.417259]\n",
      "[Epoch 83/100] [Batch 128/347] [D loss: 0.336062] [G loss: 0.423350]\n",
      "[Epoch 83/100] [Batch 129/347] [D loss: 0.280069] [G loss: 0.431004]\n",
      "[Epoch 83/100] [Batch 130/347] [D loss: 0.220030] [G loss: 0.458397]\n",
      "[Epoch 83/100] [Batch 131/347] [D loss: 0.197554] [G loss: 0.479041]\n",
      "[Epoch 83/100] [Batch 132/347] [D loss: 0.180605] [G loss: 0.499421]\n",
      "[Epoch 83/100] [Batch 133/347] [D loss: 0.167012] [G loss: 0.516608]\n",
      "[Epoch 83/100] [Batch 134/347] [D loss: 0.157120] [G loss: 0.530808]\n",
      "[Epoch 83/100] [Batch 135/347] [D loss: 0.148802] [G loss: 0.540111]\n",
      "[Epoch 83/100] [Batch 136/347] [D loss: 0.148202] [G loss: 0.541447]\n",
      "[Epoch 83/100] [Batch 137/347] [D loss: 0.405789] [G loss: 0.538570]\n",
      "[Epoch 83/100] [Batch 138/347] [D loss: 0.438792] [G loss: 0.532482]\n",
      "[Epoch 83/100] [Batch 139/347] [D loss: 0.444388] [G loss: 0.522473]\n",
      "[Epoch 83/100] [Batch 140/347] [D loss: 0.456255] [G loss: 0.520636]\n",
      "[Epoch 83/100] [Batch 141/347] [D loss: 0.416127] [G loss: 0.512793]\n",
      "[Epoch 83/100] [Batch 142/347] [D loss: 0.416029] [G loss: 0.503859]\n",
      "[Epoch 83/100] [Batch 143/347] [D loss: 0.402419] [G loss: 0.490858]\n",
      "[Epoch 83/100] [Batch 144/347] [D loss: 0.375158] [G loss: 0.475343]\n",
      "[Epoch 83/100] [Batch 145/347] [D loss: 0.393959] [G loss: 0.463763]\n",
      "[Epoch 83/100] [Batch 146/347] [D loss: 0.392261] [G loss: 0.439965]\n",
      "[Epoch 83/100] [Batch 147/347] [D loss: 0.409323] [G loss: 0.413228]\n",
      "[Epoch 83/100] [Batch 148/347] [D loss: 0.424355] [G loss: 0.379936]\n",
      "[Epoch 83/100] [Batch 149/347] [D loss: 0.366450] [G loss: 0.345784]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 83/100] [Batch 150/347] [D loss: 0.354796] [G loss: 0.321364]\n",
      "[Epoch 83/100] [Batch 151/347] [D loss: 0.359712] [G loss: 0.302544]\n",
      "[Epoch 83/100] [Batch 152/347] [D loss: 0.363761] [G loss: 0.287934]\n",
      "[Epoch 83/100] [Batch 153/347] [D loss: 0.373930] [G loss: 0.279768]\n",
      "[Epoch 83/100] [Batch 154/347] [D loss: 0.373492] [G loss: 0.284424]\n",
      "[Epoch 83/100] [Batch 155/347] [D loss: 0.361535] [G loss: 0.302142]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 83/100] [Batch 156/347] [D loss: 0.345295] [G loss: 0.321325]\n",
      "[Epoch 83/100] [Batch 157/347] [D loss: 0.317130] [G loss: 0.349917]\n",
      "[Epoch 83/100] [Batch 158/347] [D loss: 0.274345] [G loss: 0.385164]\n",
      "[Epoch 83/100] [Batch 159/347] [D loss: 0.276224] [G loss: 0.417310]\n",
      "[Epoch 83/100] [Batch 160/347] [D loss: 0.255942] [G loss: 0.449134]\n",
      "[Epoch 83/100] [Batch 161/347] [D loss: 0.247424] [G loss: 0.470230]\n",
      "[Epoch 83/100] [Batch 162/347] [D loss: 0.254124] [G loss: 0.477338]\n",
      "[Epoch 83/100] [Batch 163/347] [D loss: 0.267517] [G loss: 0.474306]\n",
      "[Epoch 83/100] [Batch 164/347] [D loss: 0.276515] [G loss: 0.479480]\n",
      "[Epoch 83/100] [Batch 165/347] [D loss: 0.277932] [G loss: 0.487390]\n",
      "[Epoch 83/100] [Batch 166/347] [D loss: 0.276575] [G loss: 0.492933]\n",
      "[Epoch 83/100] [Batch 167/347] [D loss: 0.300742] [G loss: 0.512770]\n",
      "[Epoch 83/100] [Batch 168/347] [D loss: 0.294019] [G loss: 0.516456]\n",
      "[Epoch 83/100] [Batch 169/347] [D loss: 0.435390] [G loss: 0.517382]\n",
      "[Epoch 83/100] [Batch 170/347] [D loss: 0.509084] [G loss: 0.515077]\n",
      "[Epoch 83/100] [Batch 171/347] [D loss: 0.504597] [G loss: 0.504162]\n",
      "[Epoch 83/100] [Batch 172/347] [D loss: 0.495563] [G loss: 0.492180]\n",
      "[Epoch 83/100] [Batch 173/347] [D loss: 0.491230] [G loss: 0.475559]\n",
      "[Epoch 83/100] [Batch 174/347] [D loss: 0.476642] [G loss: 0.461433]\n",
      "[Epoch 83/100] [Batch 175/347] [D loss: 0.521252] [G loss: 0.447131]\n",
      "[Epoch 83/100] [Batch 176/347] [D loss: 0.559081] [G loss: 0.433563]\n",
      "[Epoch 83/100] [Batch 177/347] [D loss: 0.559500] [G loss: 0.416535]\n",
      "[Epoch 83/100] [Batch 178/347] [D loss: 0.553679] [G loss: 0.399320]\n",
      "[Epoch 83/100] [Batch 179/347] [D loss: 0.551649] [G loss: 0.386633]\n",
      "[Epoch 83/100] [Batch 180/347] [D loss: 0.551998] [G loss: 0.374722]\n",
      "[Epoch 83/100] [Batch 181/347] [D loss: 0.550447] [G loss: 0.371517]\n",
      "[Epoch 83/100] [Batch 182/347] [D loss: 0.556270] [G loss: 0.368567]\n",
      "[Epoch 83/100] [Batch 183/347] [D loss: 0.558480] [G loss: 0.368365]\n",
      "[Epoch 83/100] [Batch 184/347] [D loss: 0.590293] [G loss: 0.370963]\n",
      "[Epoch 83/100] [Batch 185/347] [D loss: 0.598212] [G loss: 0.370811]\n",
      "[Epoch 83/100] [Batch 186/347] [D loss: 0.580073] [G loss: 0.375153]\n",
      "[Epoch 83/100] [Batch 187/347] [D loss: 0.568739] [G loss: 0.378471]\n",
      "[Epoch 83/100] [Batch 188/347] [D loss: 0.525186] [G loss: 0.378584]\n",
      "[Epoch 83/100] [Batch 189/347] [D loss: 0.465757] [G loss: 0.380559]\n",
      "[Epoch 83/100] [Batch 190/347] [D loss: 0.456628] [G loss: 0.386931]\n",
      "[Epoch 83/100] [Batch 191/347] [D loss: 0.457621] [G loss: 0.394286]\n",
      "[Epoch 83/100] [Batch 192/347] [D loss: 0.469795] [G loss: 0.403598]\n",
      "[Epoch 83/100] [Batch 193/347] [D loss: 0.545186] [G loss: 0.413450]\n",
      "[Epoch 83/100] [Batch 194/347] [D loss: 0.538790] [G loss: 0.421029]\n",
      "[Epoch 83/100] [Batch 195/347] [D loss: 0.514704] [G loss: 0.426782]\n",
      "[Epoch 83/100] [Batch 196/347] [D loss: 0.467429] [G loss: 0.431052]\n",
      "[Epoch 83/100] [Batch 197/347] [D loss: 0.468471] [G loss: 0.435679]\n",
      "[Epoch 83/100] [Batch 198/347] [D loss: 0.466461] [G loss: 0.441419]\n",
      "[Epoch 83/100] [Batch 199/347] [D loss: 0.464971] [G loss: 0.442955]\n",
      "[Epoch 83/100] [Batch 200/347] [D loss: 0.519063] [G loss: 0.444188]\n",
      "[Epoch 83/100] [Batch 201/347] [D loss: 0.552523] [G loss: 0.446456]\n",
      "[Epoch 83/100] [Batch 202/347] [D loss: 0.552481] [G loss: 0.449090]\n",
      "[Epoch 83/100] [Batch 203/347] [D loss: 0.588108] [G loss: 0.455360]\n",
      "[Epoch 83/100] [Batch 204/347] [D loss: 0.578987] [G loss: 0.466907]\n",
      "[Epoch 83/100] [Batch 205/347] [D loss: 0.574483] [G loss: 0.481978]\n",
      "[Epoch 83/100] [Batch 206/347] [D loss: 0.568267] [G loss: 0.496145]\n",
      "[Epoch 83/100] [Batch 207/347] [D loss: 0.523106] [G loss: 0.506986]\n",
      "[Epoch 83/100] [Batch 208/347] [D loss: 0.511272] [G loss: 0.516300]\n",
      "[Epoch 83/100] [Batch 209/347] [D loss: 0.502874] [G loss: 0.515228]\n",
      "[Epoch 83/100] [Batch 210/347] [D loss: 0.418843] [G loss: 0.514349]\n",
      "[Epoch 83/100] [Batch 211/347] [D loss: 0.355152] [G loss: 0.505508]\n",
      "[Epoch 83/100] [Batch 212/347] [D loss: 0.196896] [G loss: 0.490019]\n",
      "[Epoch 83/100] [Batch 213/347] [D loss: 0.197790] [G loss: 0.493159]\n",
      "[Epoch 83/100] [Batch 214/347] [D loss: 0.198054] [G loss: 0.494384]\n",
      "[Epoch 83/100] [Batch 215/347] [D loss: 0.199936] [G loss: 0.497797]\n",
      "[Epoch 83/100] [Batch 216/347] [D loss: 0.393733] [G loss: 0.509872]\n",
      "[Epoch 83/100] [Batch 217/347] [D loss: 0.447553] [G loss: 0.522480]\n",
      "[Epoch 83/100] [Batch 218/347] [D loss: 0.498766] [G loss: 0.534313]\n",
      "[Epoch 83/100] [Batch 219/347] [D loss: 0.475716] [G loss: 0.536857]\n",
      "[Epoch 83/100] [Batch 220/347] [D loss: 0.465710] [G loss: 0.536017]\n",
      "[Epoch 83/100] [Batch 221/347] [D loss: 0.494107] [G loss: 0.529631]\n",
      "[Epoch 83/100] [Batch 222/347] [D loss: 0.496233] [G loss: 0.513862]\n",
      "[Epoch 83/100] [Batch 223/347] [D loss: 0.478286] [G loss: 0.485446]\n",
      "[Epoch 83/100] [Batch 224/347] [D loss: 0.489388] [G loss: 0.453611]\n",
      "[Epoch 83/100] [Batch 225/347] [D loss: 0.499599] [G loss: 0.426305]\n",
      "[Epoch 83/100] [Batch 226/347] [D loss: 0.512482] [G loss: 0.404780]\n",
      "[Epoch 83/100] [Batch 227/347] [D loss: 0.559611] [G loss: 0.396949]\n",
      "[Epoch 83/100] [Batch 228/347] [D loss: 0.582964] [G loss: 0.394738]\n",
      "[Epoch 83/100] [Batch 229/347] [D loss: 0.585506] [G loss: 0.396015]\n",
      "[Epoch 83/100] [Batch 230/347] [D loss: 0.595855] [G loss: 0.399604]\n",
      "[Epoch 83/100] [Batch 231/347] [D loss: 0.570426] [G loss: 0.398718]\n",
      "[Epoch 83/100] [Batch 232/347] [D loss: 0.550847] [G loss: 0.402212]\n",
      "[Epoch 83/100] [Batch 233/347] [D loss: 0.465783] [G loss: 0.412882]\n",
      "[Epoch 83/100] [Batch 234/347] [D loss: 0.417662] [G loss: 0.424240]\n",
      "[Epoch 83/100] [Batch 235/347] [D loss: 0.414928] [G loss: 0.443185]\n",
      "[Epoch 83/100] [Batch 236/347] [D loss: 0.406684] [G loss: 0.460335]\n",
      "[Epoch 83/100] [Batch 237/347] [D loss: 0.472820] [G loss: 0.474935]\n",
      "[Epoch 83/100] [Batch 238/347] [D loss: 0.554156] [G loss: 0.484040]\n",
      "[Epoch 83/100] [Batch 239/347] [D loss: 0.555241] [G loss: 0.491340]\n",
      "[Epoch 83/100] [Batch 240/347] [D loss: 0.552457] [G loss: 0.500509]\n",
      "[Epoch 83/100] [Batch 241/347] [D loss: 0.551754] [G loss: 0.512046]\n",
      "[Epoch 83/100] [Batch 242/347] [D loss: 0.557168] [G loss: 0.526586]\n",
      "[Epoch 83/100] [Batch 243/347] [D loss: 0.518094] [G loss: 0.538152]\n",
      "[Epoch 83/100] [Batch 244/347] [D loss: 0.491868] [G loss: 0.537083]\n",
      "[Epoch 83/100] [Batch 245/347] [D loss: 0.502792] [G loss: 0.531016]\n",
      "[Epoch 83/100] [Batch 246/347] [D loss: 0.501885] [G loss: 0.522040]\n",
      "[Epoch 83/100] [Batch 247/347] [D loss: 0.524505] [G loss: 0.515688]\n",
      "[Epoch 83/100] [Batch 248/347] [D loss: 0.539161] [G loss: 0.521068]\n",
      "[Epoch 83/100] [Batch 249/347] [D loss: 0.530498] [G loss: 0.529104]\n",
      "[Epoch 83/100] [Batch 250/347] [D loss: 0.525856] [G loss: 0.540403]\n",
      "[Epoch 83/100] [Batch 251/347] [D loss: 0.518973] [G loss: 0.555206]\n",
      "[Epoch 83/100] [Batch 252/347] [D loss: 0.514189] [G loss: 0.562610]\n",
      "[Epoch 83/100] [Batch 253/347] [D loss: 0.477119] [G loss: 0.555814]\n",
      "[Epoch 83/100] [Batch 254/347] [D loss: 0.479764] [G loss: 0.557963]\n",
      "[Epoch 83/100] [Batch 255/347] [D loss: 0.472604] [G loss: 0.554693]\n",
      "[Epoch 83/100] [Batch 256/347] [D loss: 0.475507] [G loss: 0.541712]\n",
      "[Epoch 83/100] [Batch 257/347] [D loss: 0.452288] [G loss: 0.532671]\n",
      "[Epoch 83/100] [Batch 258/347] [D loss: 0.406306] [G loss: 0.518863]\n",
      "[Epoch 83/100] [Batch 259/347] [D loss: 0.398608] [G loss: 0.499404]\n",
      "[Epoch 83/100] [Batch 260/347] [D loss: 0.388330] [G loss: 0.478555]\n",
      "[Epoch 83/100] [Batch 261/347] [D loss: 0.368256] [G loss: 0.460302]\n",
      "[Epoch 83/100] [Batch 262/347] [D loss: 0.317959] [G loss: 0.439839]\n",
      "[Epoch 83/100] [Batch 263/347] [D loss: 0.321517] [G loss: 0.421859]\n",
      "[Epoch 83/100] [Batch 264/347] [D loss: 0.326264] [G loss: 0.411496]\n",
      "[Epoch 83/100] [Batch 265/347] [D loss: 0.342587] [G loss: 0.406064]\n",
      "[Epoch 83/100] [Batch 266/347] [D loss: 0.404110] [G loss: 0.405562]\n",
      "[Epoch 83/100] [Batch 267/347] [D loss: 0.422871] [G loss: 0.407222]\n",
      "[Epoch 83/100] [Batch 268/347] [D loss: 0.424436] [G loss: 0.409968]\n",
      "[Epoch 83/100] [Batch 269/347] [D loss: 0.427550] [G loss: 0.414119]\n",
      "[Epoch 83/100] [Batch 270/347] [D loss: 0.453156] [G loss: 0.419904]\n",
      "[Epoch 83/100] [Batch 271/347] [D loss: 0.419538] [G loss: 0.434259]\n",
      "[Epoch 83/100] [Batch 272/347] [D loss: 0.434686] [G loss: 0.469572]\n",
      "[Epoch 83/100] [Batch 273/347] [D loss: 0.367292] [G loss: 0.506819]\n",
      "[Epoch 83/100] [Batch 274/347] [D loss: 0.307314] [G loss: 0.535967]\n",
      "[Epoch 83/100] [Batch 275/347] [D loss: 0.236016] [G loss: 0.554412]\n",
      "[Epoch 83/100] [Batch 276/347] [D loss: 0.481891] [G loss: 0.553682]\n",
      "[Epoch 83/100] [Batch 277/347] [D loss: 0.508879] [G loss: 0.564959]\n",
      "[Epoch 83/100] [Batch 278/347] [D loss: 0.513931] [G loss: 0.574447]\n",
      "[Epoch 83/100] [Batch 279/347] [D loss: 0.518387] [G loss: 0.575434]\n",
      "[Epoch 83/100] [Batch 280/347] [D loss: 0.521291] [G loss: 0.574776]\n",
      "[Epoch 83/100] [Batch 281/347] [D loss: 0.525928] [G loss: 0.575365]\n",
      "[Epoch 83/100] [Batch 282/347] [D loss: 0.527289] [G loss: 0.576747]\n",
      "[Epoch 83/100] [Batch 283/347] [D loss: 0.528311] [G loss: 0.577526]\n",
      "[Epoch 83/100] [Batch 284/347] [D loss: 0.529248] [G loss: 0.579362]\n",
      "[Epoch 83/100] [Batch 285/347] [D loss: 0.533034] [G loss: 0.579962]\n",
      "[Epoch 83/100] [Batch 286/347] [D loss: 0.532613] [G loss: 0.565273]\n",
      "[Epoch 83/100] [Batch 287/347] [D loss: 0.533480] [G loss: 0.562781]\n",
      "[Epoch 83/100] [Batch 288/347] [D loss: 0.533624] [G loss: 0.559592]\n",
      "[Epoch 83/100] [Batch 289/347] [D loss: 0.532385] [G loss: 0.555489]\n",
      "[Epoch 83/100] [Batch 290/347] [D loss: 0.531133] [G loss: 0.569626]\n",
      "[Epoch 83/100] [Batch 291/347] [D loss: 0.529281] [G loss: 0.576449]\n",
      "[Epoch 83/100] [Batch 292/347] [D loss: 0.526716] [G loss: 0.579958]\n",
      "[Epoch 83/100] [Batch 293/347] [D loss: 0.505154] [G loss: 0.585550]\n",
      "[Epoch 83/100] [Batch 294/347] [D loss: 0.504282] [G loss: 0.588909]\n",
      "[Epoch 83/100] [Batch 295/347] [D loss: 0.504059] [G loss: 0.586754]\n",
      "[Epoch 83/100] [Batch 296/347] [D loss: 0.503489] [G loss: 0.584375]\n",
      "[Epoch 83/100] [Batch 297/347] [D loss: 0.524643] [G loss: 0.588001]\n",
      "[Epoch 83/100] [Batch 298/347] [D loss: 0.527199] [G loss: 0.580560]\n",
      "[Epoch 83/100] [Batch 299/347] [D loss: 0.526860] [G loss: 0.575296]\n",
      "[Epoch 83/100] [Batch 300/347] [D loss: 0.525692] [G loss: 0.572647]\n",
      "[Epoch 83/100] [Batch 301/347] [D loss: 0.526587] [G loss: 0.560939]\n",
      "[Epoch 83/100] [Batch 302/347] [D loss: 0.527276] [G loss: 0.551293]\n",
      "[Epoch 83/100] [Batch 303/347] [D loss: 0.526799] [G loss: 0.535382]\n",
      "[Epoch 83/100] [Batch 304/347] [D loss: 0.509875] [G loss: 0.522606]\n",
      "[Epoch 83/100] [Batch 305/347] [D loss: 0.497288] [G loss: 0.518994]\n",
      "[Epoch 83/100] [Batch 306/347] [D loss: 0.495691] [G loss: 0.519824]\n",
      "[Epoch 83/100] [Batch 307/347] [D loss: 0.492538] [G loss: 0.525190]\n",
      "[Epoch 83/100] [Batch 308/347] [D loss: 0.500117] [G loss: 0.526665]\n",
      "[Epoch 83/100] [Batch 309/347] [D loss: 0.519710] [G loss: 0.540547]\n",
      "[Epoch 83/100] [Batch 310/347] [D loss: 0.532008] [G loss: 0.551894]\n",
      "[Epoch 83/100] [Batch 311/347] [D loss: 0.526516] [G loss: 0.547918]\n",
      "[Epoch 83/100] [Batch 312/347] [D loss: 0.515742] [G loss: 0.541377]\n",
      "[Epoch 83/100] [Batch 313/347] [D loss: 0.511296] [G loss: 0.530522]\n",
      "[Epoch 83/100] [Batch 314/347] [D loss: 0.510643] [G loss: 0.514276]\n",
      "[Epoch 83/100] [Batch 315/347] [D loss: 0.510593] [G loss: 0.501769]\n",
      "[Epoch 83/100] [Batch 316/347] [D loss: 0.512792] [G loss: 0.501786]\n",
      "[Epoch 83/100] [Batch 317/347] [D loss: 0.513852] [G loss: 0.504092]\n",
      "[Epoch 83/100] [Batch 318/347] [D loss: 0.512758] [G loss: 0.516772]\n",
      "[Epoch 83/100] [Batch 319/347] [D loss: 0.508289] [G loss: 0.528086]\n",
      "[Epoch 83/100] [Batch 320/347] [D loss: 0.506954] [G loss: 0.525211]\n",
      "[Epoch 83/100] [Batch 321/347] [D loss: 0.503842] [G loss: 0.517109]\n",
      "[Epoch 83/100] [Batch 322/347] [D loss: 0.504977] [G loss: 0.507660]\n",
      "[Epoch 83/100] [Batch 323/347] [D loss: 0.495076] [G loss: 0.496886]\n",
      "[Epoch 83/100] [Batch 324/347] [D loss: 0.493162] [G loss: 0.489268]\n",
      "[Epoch 83/100] [Batch 325/347] [D loss: 0.492509] [G loss: 0.481363]\n",
      "[Epoch 83/100] [Batch 326/347] [D loss: 0.491909] [G loss: 0.474634]\n",
      "[Epoch 83/100] [Batch 327/347] [D loss: 0.489001] [G loss: 0.468526]\n",
      "[Epoch 83/100] [Batch 328/347] [D loss: 0.489057] [G loss: 0.461534]\n",
      "[Epoch 83/100] [Batch 329/347] [D loss: 0.486896] [G loss: 0.457516]\n",
      "[Epoch 83/100] [Batch 330/347] [D loss: 0.484401] [G loss: 0.455103]\n",
      "[Epoch 83/100] [Batch 331/347] [D loss: 0.485106] [G loss: 0.455581]\n",
      "[Epoch 83/100] [Batch 332/347] [D loss: 0.496247] [G loss: 0.472899]\n",
      "[Epoch 83/100] [Batch 333/347] [D loss: 0.488172] [G loss: 0.468379]\n",
      "[Epoch 83/100] [Batch 334/347] [D loss: 0.485632] [G loss: 0.458483]\n",
      "[Epoch 83/100] [Batch 335/347] [D loss: 0.484447] [G loss: 0.453122]\n",
      "[Epoch 83/100] [Batch 336/347] [D loss: 0.483218] [G loss: 0.448004]\n",
      "[Epoch 83/100] [Batch 337/347] [D loss: 0.490549] [G loss: 0.448751]\n",
      "[Epoch 83/100] [Batch 338/347] [D loss: 0.496051] [G loss: 0.453779]\n",
      "[Epoch 83/100] [Batch 339/347] [D loss: 0.490491] [G loss: 0.450743]\n",
      "[Epoch 83/100] [Batch 340/347] [D loss: 0.482188] [G loss: 0.443958]\n",
      "[Epoch 83/100] [Batch 341/347] [D loss: 0.483884] [G loss: 0.440611]\n",
      "[Epoch 83/100] [Batch 342/347] [D loss: 0.450163] [G loss: 0.424712]\n",
      "[Epoch 83/100] [Batch 343/347] [D loss: 0.438794] [G loss: 0.405443]\n",
      "[Epoch 83/100] [Batch 344/347] [D loss: 0.393279] [G loss: 0.397236]\n",
      "[Epoch 83/100] [Batch 345/347] [D loss: 0.296238] [G loss: 0.390825]\n",
      "[Epoch 83/100] [Batch 346/347] [D loss: 0.288076] [G loss: 0.385930]\n",
      "[Epoch 83/100] [Batch 347/347] [D loss: 0.276593] [G loss: 0.381492]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 1/347] [D loss: 0.470297] [G loss: 0.389639]\n",
      "[Epoch 84/100] [Batch 2/347] [D loss: 0.475980] [G loss: 0.384977]\n",
      "[Epoch 84/100] [Batch 3/347] [D loss: 0.486335] [G loss: 0.384010]\n",
      "[Epoch 84/100] [Batch 4/347] [D loss: 0.487700] [G loss: 0.379366]\n",
      "[Epoch 84/100] [Batch 5/347] [D loss: 0.488677] [G loss: 0.371038]\n",
      "[Epoch 84/100] [Batch 6/347] [D loss: 0.473728] [G loss: 0.363406]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 7/347] [D loss: 0.458988] [G loss: 0.350088]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 8/347] [D loss: 0.457239] [G loss: 0.343720]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 9/347] [D loss: 0.452469] [G loss: 0.339433]\n",
      "[Epoch 84/100] [Batch 10/347] [D loss: 0.453247] [G loss: 0.335166]\n",
      "[Epoch 84/100] [Batch 11/347] [D loss: 0.473347] [G loss: 0.339393]\n",
      "[Epoch 84/100] [Batch 12/347] [D loss: 0.479764] [G loss: 0.336088]\n",
      "[Epoch 84/100] [Batch 13/347] [D loss: 0.463020] [G loss: 0.329602]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 14/347] [D loss: 0.445286] [G loss: 0.323142]\n",
      "[Epoch 84/100] [Batch 15/347] [D loss: 0.446162] [G loss: 0.307925]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 16/347] [D loss: 0.439214] [G loss: 0.296436]\n",
      "[Epoch 84/100] [Batch 17/347] [D loss: 0.442091] [G loss: 0.292819]\n",
      "[Epoch 84/100] [Batch 18/347] [D loss: 0.449779] [G loss: 0.287660]\n",
      "[Epoch 84/100] [Batch 19/347] [D loss: 0.445581] [G loss: 0.287084]\n",
      "[Epoch 84/100] [Batch 20/347] [D loss: 0.458285] [G loss: 0.286444]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 21/347] [D loss: 0.410642] [G loss: 0.277671]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 22/347] [D loss: 0.410110] [G loss: 0.272622]\n",
      "[Epoch 84/100] [Batch 23/347] [D loss: 0.412317] [G loss: 0.267150]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 24/347] [D loss: 0.385658] [G loss: 0.258279]\n",
      "[Epoch 84/100] [Batch 25/347] [D loss: 0.322154] [G loss: 0.266923]\n",
      "[Epoch 84/100] [Batch 26/347] [D loss: 0.317095] [G loss: 0.274369]\n",
      "[Epoch 84/100] [Batch 27/347] [D loss: 0.311106] [G loss: 0.286967]\n",
      "[Epoch 84/100] [Batch 28/347] [D loss: 0.304861] [G loss: 0.303730]\n",
      "[Epoch 84/100] [Batch 29/347] [D loss: 0.312154] [G loss: 0.320047]\n",
      "[Epoch 84/100] [Batch 30/347] [D loss: 0.300695] [G loss: 0.331238]\n",
      "[Epoch 84/100] [Batch 31/347] [D loss: 0.296326] [G loss: 0.339945]\n",
      "[Epoch 84/100] [Batch 32/347] [D loss: 0.299203] [G loss: 0.344436]\n",
      "[Epoch 84/100] [Batch 33/347] [D loss: 0.309818] [G loss: 0.348594]\n",
      "[Epoch 84/100] [Batch 34/347] [D loss: 0.345436] [G loss: 0.348675]\n",
      "[Epoch 84/100] [Batch 35/347] [D loss: 0.349489] [G loss: 0.341773]\n",
      "[Epoch 84/100] [Batch 36/347] [D loss: 0.373877] [G loss: 0.336398]\n",
      "[Epoch 84/100] [Batch 37/347] [D loss: 0.380415] [G loss: 0.327514]\n",
      "[Epoch 84/100] [Batch 38/347] [D loss: 0.377929] [G loss: 0.316250]\n",
      "[Epoch 84/100] [Batch 39/347] [D loss: 0.380495] [G loss: 0.314449]\n",
      "[Epoch 84/100] [Batch 40/347] [D loss: 0.397555] [G loss: 0.314044]\n",
      "[Epoch 84/100] [Batch 41/347] [D loss: 0.410126] [G loss: 0.309348]\n",
      "[Epoch 84/100] [Batch 42/347] [D loss: 0.399819] [G loss: 0.309585]\n",
      "[Epoch 84/100] [Batch 43/347] [D loss: 0.417306] [G loss: 0.315521]\n",
      "[Epoch 84/100] [Batch 44/347] [D loss: 0.396425] [G loss: 0.311328]\n",
      "[Epoch 84/100] [Batch 45/347] [D loss: 0.373251] [G loss: 0.297377]\n",
      "[Epoch 84/100] [Batch 46/347] [D loss: 0.317095] [G loss: 0.282916]\n",
      "[Epoch 84/100] [Batch 47/347] [D loss: 0.318124] [G loss: 0.277630]\n",
      "[Epoch 84/100] [Batch 48/347] [D loss: 0.286204] [G loss: 0.288367]\n",
      "[Epoch 84/100] [Batch 49/347] [D loss: 0.268200] [G loss: 0.311854]\n",
      "[Epoch 84/100] [Batch 50/347] [D loss: 0.251702] [G loss: 0.339195]\n",
      "[Epoch 84/100] [Batch 51/347] [D loss: 0.225783] [G loss: 0.361911]\n",
      "[Epoch 84/100] [Batch 52/347] [D loss: 0.277687] [G loss: 0.372209]\n",
      "[Epoch 84/100] [Batch 53/347] [D loss: 0.308044] [G loss: 0.370081]\n",
      "[Epoch 84/100] [Batch 54/347] [D loss: 0.297743] [G loss: 0.365199]\n",
      "[Epoch 84/100] [Batch 55/347] [D loss: 0.293134] [G loss: 0.372076]\n",
      "[Epoch 84/100] [Batch 56/347] [D loss: 0.286436] [G loss: 0.381528]\n",
      "[Epoch 84/100] [Batch 57/347] [D loss: 0.241813] [G loss: 0.390021]\n",
      "[Epoch 84/100] [Batch 58/347] [D loss: 0.245274] [G loss: 0.394463]\n",
      "[Epoch 84/100] [Batch 59/347] [D loss: 0.243551] [G loss: 0.390062]\n",
      "[Epoch 84/100] [Batch 60/347] [D loss: 0.233190] [G loss: 0.375754]\n",
      "[Epoch 84/100] [Batch 61/347] [D loss: 0.244940] [G loss: 0.367297]\n",
      "[Epoch 84/100] [Batch 62/347] [D loss: 0.242282] [G loss: 0.357267]\n",
      "[Epoch 84/100] [Batch 63/347] [D loss: 0.232565] [G loss: 0.354964]\n",
      "[Epoch 84/100] [Batch 64/347] [D loss: 0.220215] [G loss: 0.350265]\n",
      "[Epoch 84/100] [Batch 65/347] [D loss: 0.193937] [G loss: 0.353213]\n",
      "[Epoch 84/100] [Batch 66/347] [D loss: 0.195417] [G loss: 0.350963]\n",
      "[Epoch 84/100] [Batch 67/347] [D loss: 0.194602] [G loss: 0.340963]\n",
      "[Epoch 84/100] [Batch 68/347] [D loss: 0.192243] [G loss: 0.353488]\n",
      "[Epoch 84/100] [Batch 69/347] [D loss: 0.199640] [G loss: 0.374620]\n",
      "[Epoch 84/100] [Batch 70/347] [D loss: 0.194979] [G loss: 0.380269]\n",
      "[Epoch 84/100] [Batch 71/347] [D loss: 0.193191] [G loss: 0.371305]\n",
      "[Epoch 84/100] [Batch 72/347] [D loss: 0.195751] [G loss: 0.373350]\n",
      "[Epoch 84/100] [Batch 73/347] [D loss: 0.280420] [G loss: 0.376104]\n",
      "[Epoch 84/100] [Batch 74/347] [D loss: 0.281224] [G loss: 0.370256]\n",
      "[Epoch 84/100] [Batch 75/347] [D loss: 0.279478] [G loss: 0.371346]\n",
      "[Epoch 84/100] [Batch 76/347] [D loss: 0.277310] [G loss: 0.370147]\n",
      "[Epoch 84/100] [Batch 77/347] [D loss: 0.307241] [G loss: 0.378718]\n",
      "[Epoch 84/100] [Batch 78/347] [D loss: 0.343301] [G loss: 0.386306]\n",
      "[Epoch 84/100] [Batch 79/347] [D loss: 0.336787] [G loss: 0.382623]\n",
      "[Epoch 84/100] [Batch 80/347] [D loss: 0.250202] [G loss: 0.365268]\n",
      "[Epoch 84/100] [Batch 81/347] [D loss: 0.238896] [G loss: 0.359245]\n",
      "[Epoch 84/100] [Batch 82/347] [D loss: 0.238859] [G loss: 0.357182]\n",
      "[Epoch 84/100] [Batch 83/347] [D loss: 0.244861] [G loss: 0.355016]\n",
      "[Epoch 84/100] [Batch 84/347] [D loss: 0.349296] [G loss: 0.356138]\n",
      "[Epoch 84/100] [Batch 85/347] [D loss: 0.415540] [G loss: 0.352968]\n",
      "[Epoch 84/100] [Batch 86/347] [D loss: 0.415914] [G loss: 0.347728]\n",
      "[Epoch 84/100] [Batch 87/347] [D loss: 0.415580] [G loss: 0.343270]\n",
      "[Epoch 84/100] [Batch 88/347] [D loss: 0.437350] [G loss: 0.337284]\n",
      "[Epoch 84/100] [Batch 89/347] [D loss: 0.445966] [G loss: 0.333263]\n",
      "[Epoch 84/100] [Batch 90/347] [D loss: 0.442226] [G loss: 0.325704]\n",
      "[Epoch 84/100] [Batch 91/347] [D loss: 0.444620] [G loss: 0.318155]\n",
      "[Epoch 84/100] [Batch 92/347] [D loss: 0.449138] [G loss: 0.313400]\n",
      "[Epoch 84/100] [Batch 93/347] [D loss: 0.449362] [G loss: 0.308715]\n",
      "[Epoch 84/100] [Batch 94/347] [D loss: 0.431252] [G loss: 0.302570]\n",
      "[Epoch 84/100] [Batch 95/347] [D loss: 0.419891] [G loss: 0.301584]\n",
      "[Epoch 84/100] [Batch 96/347] [D loss: 0.419563] [G loss: 0.304501]\n",
      "[Epoch 84/100] [Batch 97/347] [D loss: 0.411676] [G loss: 0.307808]\n",
      "[Epoch 84/100] [Batch 98/347] [D loss: 0.393598] [G loss: 0.315448]\n",
      "[Epoch 84/100] [Batch 99/347] [D loss: 0.391793] [G loss: 0.324213]\n",
      "[Epoch 84/100] [Batch 100/347] [D loss: 0.391881] [G loss: 0.332646]\n",
      "[Epoch 84/100] [Batch 101/347] [D loss: 0.398214] [G loss: 0.339953]\n",
      "[Epoch 84/100] [Batch 102/347] [D loss: 0.460978] [G loss: 0.345372]\n",
      "[Epoch 84/100] [Batch 103/347] [D loss: 0.467106] [G loss: 0.352290]\n",
      "[Epoch 84/100] [Batch 104/347] [D loss: 0.435672] [G loss: 0.351556]\n",
      "[Epoch 84/100] [Batch 105/347] [D loss: 0.368168] [G loss: 0.352415]\n",
      "[Epoch 84/100] [Batch 106/347] [D loss: 0.261088] [G loss: 0.361919]\n",
      "[Epoch 84/100] [Batch 107/347] [D loss: 0.231011] [G loss: 0.386352]\n",
      "[Epoch 84/100] [Batch 108/347] [D loss: 0.210458] [G loss: 0.414045]\n",
      "[Epoch 84/100] [Batch 109/347] [D loss: 0.176165] [G loss: 0.439855]\n",
      "[Epoch 84/100] [Batch 110/347] [D loss: 0.160548] [G loss: 0.458953]\n",
      "[Epoch 84/100] [Batch 111/347] [D loss: 0.162889] [G loss: 0.475564]\n",
      "[Epoch 84/100] [Batch 112/347] [D loss: 0.164975] [G loss: 0.487483]\n",
      "[Epoch 84/100] [Batch 113/347] [D loss: 0.368277] [G loss: 0.510679]\n",
      "[Epoch 84/100] [Batch 114/347] [D loss: 0.452686] [G loss: 0.519794]\n",
      "[Epoch 84/100] [Batch 115/347] [D loss: 0.464374] [G loss: 0.503665]\n",
      "[Epoch 84/100] [Batch 116/347] [D loss: 0.393425] [G loss: 0.485549]\n",
      "[Epoch 84/100] [Batch 117/347] [D loss: 0.376816] [G loss: 0.471046]\n",
      "[Epoch 84/100] [Batch 118/347] [D loss: 0.294827] [G loss: 0.453245]\n",
      "[Epoch 84/100] [Batch 119/347] [D loss: 0.272656] [G loss: 0.444415]\n",
      "[Epoch 84/100] [Batch 120/347] [D loss: 0.246246] [G loss: 0.437873]\n",
      "[Epoch 84/100] [Batch 121/347] [D loss: 0.228064] [G loss: 0.420024]\n",
      "[Epoch 84/100] [Batch 122/347] [D loss: 0.338551] [G loss: 0.399505]\n",
      "[Epoch 84/100] [Batch 123/347] [D loss: 0.373417] [G loss: 0.376366]\n",
      "[Epoch 84/100] [Batch 124/347] [D loss: 0.304990] [G loss: 0.349734]\n",
      "[Epoch 84/100] [Batch 125/347] [D loss: 0.290093] [G loss: 0.334546]\n",
      "[Epoch 84/100] [Batch 126/347] [D loss: 0.274999] [G loss: 0.325362]\n",
      "[Epoch 84/100] [Batch 127/347] [D loss: 0.285712] [G loss: 0.321199]\n",
      "[Epoch 84/100] [Batch 128/347] [D loss: 0.283444] [G loss: 0.319810]\n",
      "[Epoch 84/100] [Batch 129/347] [D loss: 0.290807] [G loss: 0.332154]\n",
      "[Epoch 84/100] [Batch 130/347] [D loss: 0.290207] [G loss: 0.366705]\n",
      "[Epoch 84/100] [Batch 131/347] [D loss: 0.254642] [G loss: 0.402687]\n",
      "[Epoch 84/100] [Batch 132/347] [D loss: 0.209352] [G loss: 0.439014]\n",
      "[Epoch 84/100] [Batch 133/347] [D loss: 0.198223] [G loss: 0.468013]\n",
      "[Epoch 84/100] [Batch 134/347] [D loss: 0.164638] [G loss: 0.487860]\n",
      "[Epoch 84/100] [Batch 135/347] [D loss: 0.138528] [G loss: 0.498329]\n",
      "[Epoch 84/100] [Batch 136/347] [D loss: 0.127813] [G loss: 0.498992]\n",
      "[Epoch 84/100] [Batch 137/347] [D loss: 0.342193] [G loss: 0.495097]\n",
      "[Epoch 84/100] [Batch 138/347] [D loss: 0.386093] [G loss: 0.488067]\n",
      "[Epoch 84/100] [Batch 139/347] [D loss: 0.406042] [G loss: 0.477519]\n",
      "[Epoch 84/100] [Batch 140/347] [D loss: 0.426353] [G loss: 0.475511]\n",
      "[Epoch 84/100] [Batch 141/347] [D loss: 0.375115] [G loss: 0.470550]\n",
      "[Epoch 84/100] [Batch 142/347] [D loss: 0.379095] [G loss: 0.472802]\n",
      "[Epoch 84/100] [Batch 143/347] [D loss: 0.364126] [G loss: 0.473928]\n",
      "[Epoch 84/100] [Batch 144/347] [D loss: 0.336147] [G loss: 0.464249]\n",
      "[Epoch 84/100] [Batch 145/347] [D loss: 0.352437] [G loss: 0.441890]\n",
      "[Epoch 84/100] [Batch 146/347] [D loss: 0.342433] [G loss: 0.431588]\n",
      "[Epoch 84/100] [Batch 147/347] [D loss: 0.345753] [G loss: 0.416015]\n",
      "[Epoch 84/100] [Batch 148/347] [D loss: 0.340321] [G loss: 0.393540]\n",
      "[Epoch 84/100] [Batch 149/347] [D loss: 0.263671] [G loss: 0.359081]\n",
      "[Epoch 84/100] [Batch 150/347] [D loss: 0.243843] [G loss: 0.323051]\n",
      "[Epoch 84/100] [Batch 151/347] [D loss: 0.250315] [G loss: 0.290127]\n",
      "[Epoch 84/100] [Batch 152/347] [D loss: 0.264220] [G loss: 0.261683]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 84/100] [Batch 153/347] [D loss: 0.284363] [G loss: 0.247819]\n",
      "[Epoch 84/100] [Batch 154/347] [D loss: 0.297311] [G loss: 0.239956]\n",
      "[Epoch 84/100] [Batch 155/347] [D loss: 0.298132] [G loss: 0.251797]\n",
      "[Epoch 84/100] [Batch 156/347] [D loss: 0.291510] [G loss: 0.268083]\n",
      "[Epoch 84/100] [Batch 157/347] [D loss: 0.270438] [G loss: 0.293773]\n",
      "[Epoch 84/100] [Batch 158/347] [D loss: 0.251961] [G loss: 0.330256]\n",
      "[Epoch 84/100] [Batch 159/347] [D loss: 0.234669] [G loss: 0.364844]\n",
      "[Epoch 84/100] [Batch 160/347] [D loss: 0.202054] [G loss: 0.401953]\n",
      "[Epoch 84/100] [Batch 161/347] [D loss: 0.187429] [G loss: 0.426772]\n",
      "[Epoch 84/100] [Batch 162/347] [D loss: 0.179599] [G loss: 0.436743]\n",
      "[Epoch 84/100] [Batch 163/347] [D loss: 0.184451] [G loss: 0.446451]\n",
      "[Epoch 84/100] [Batch 164/347] [D loss: 0.195149] [G loss: 0.443055]\n",
      "[Epoch 84/100] [Batch 165/347] [D loss: 0.199652] [G loss: 0.452817]\n",
      "[Epoch 84/100] [Batch 166/347] [D loss: 0.204258] [G loss: 0.460381]\n",
      "[Epoch 84/100] [Batch 167/347] [D loss: 0.229351] [G loss: 0.478885]\n",
      "[Epoch 84/100] [Batch 168/347] [D loss: 0.229270] [G loss: 0.487140]\n",
      "[Epoch 84/100] [Batch 169/347] [D loss: 0.384460] [G loss: 0.493017]\n",
      "[Epoch 84/100] [Batch 170/347] [D loss: 0.461066] [G loss: 0.494797]\n",
      "[Epoch 84/100] [Batch 171/347] [D loss: 0.448433] [G loss: 0.486558]\n",
      "[Epoch 84/100] [Batch 172/347] [D loss: 0.424819] [G loss: 0.476231]\n",
      "[Epoch 84/100] [Batch 173/347] [D loss: 0.401957] [G loss: 0.457916]\n",
      "[Epoch 84/100] [Batch 174/347] [D loss: 0.369013] [G loss: 0.437938]\n",
      "[Epoch 84/100] [Batch 175/347] [D loss: 0.410204] [G loss: 0.412545]\n",
      "[Epoch 84/100] [Batch 176/347] [D loss: 0.438342] [G loss: 0.382261]\n",
      "[Epoch 84/100] [Batch 177/347] [D loss: 0.430091] [G loss: 0.345627]\n",
      "[Epoch 84/100] [Batch 178/347] [D loss: 0.412769] [G loss: 0.311188]\n",
      "[Epoch 84/100] [Batch 179/347] [D loss: 0.417872] [G loss: 0.284135]\n",
      "[Epoch 84/100] [Batch 180/347] [D loss: 0.424984] [G loss: 0.263680]\n",
      "[Epoch 84/100] [Batch 181/347] [D loss: 0.433673] [G loss: 0.256363]\n",
      "[Epoch 84/100] [Batch 182/347] [D loss: 0.443701] [G loss: 0.253294]\n",
      "[Epoch 84/100] [Batch 183/347] [D loss: 0.449562] [G loss: 0.257158]\n",
      "[Epoch 84/100] [Batch 184/347] [D loss: 0.471304] [G loss: 0.266435]\n",
      "[Epoch 84/100] [Batch 185/347] [D loss: 0.476767] [G loss: 0.274429]\n",
      "[Epoch 84/100] [Batch 186/347] [D loss: 0.453283] [G loss: 0.288116]\n",
      "[Epoch 84/100] [Batch 187/347] [D loss: 0.438109] [G loss: 0.302189]\n",
      "[Epoch 84/100] [Batch 188/347] [D loss: 0.399476] [G loss: 0.313866]\n",
      "[Epoch 84/100] [Batch 189/347] [D loss: 0.347424] [G loss: 0.330065]\n",
      "[Epoch 84/100] [Batch 190/347] [D loss: 0.332262] [G loss: 0.351682]\n",
      "[Epoch 84/100] [Batch 191/347] [D loss: 0.326810] [G loss: 0.371681]\n",
      "[Epoch 84/100] [Batch 192/347] [D loss: 0.337658] [G loss: 0.390819]\n",
      "[Epoch 84/100] [Batch 193/347] [D loss: 0.421768] [G loss: 0.406456]\n",
      "[Epoch 84/100] [Batch 194/347] [D loss: 0.412252] [G loss: 0.414161]\n",
      "[Epoch 84/100] [Batch 195/347] [D loss: 0.391925] [G loss: 0.418346]\n",
      "[Epoch 84/100] [Batch 196/347] [D loss: 0.339995] [G loss: 0.418357]\n",
      "[Epoch 84/100] [Batch 197/347] [D loss: 0.342760] [G loss: 0.417170]\n",
      "[Epoch 84/100] [Batch 198/347] [D loss: 0.337651] [G loss: 0.416330]\n",
      "[Epoch 84/100] [Batch 199/347] [D loss: 0.335832] [G loss: 0.410632]\n",
      "[Epoch 84/100] [Batch 200/347] [D loss: 0.399958] [G loss: 0.402415]\n",
      "[Epoch 84/100] [Batch 201/347] [D loss: 0.433769] [G loss: 0.391846]\n",
      "[Epoch 84/100] [Batch 202/347] [D loss: 0.443090] [G loss: 0.378683]\n",
      "[Epoch 84/100] [Batch 203/347] [D loss: 0.497089] [G loss: 0.363778]\n",
      "[Epoch 84/100] [Batch 204/347] [D loss: 0.478954] [G loss: 0.351486]\n",
      "[Epoch 84/100] [Batch 205/347] [D loss: 0.472227] [G loss: 0.341783]\n",
      "[Epoch 84/100] [Batch 206/347] [D loss: 0.466933] [G loss: 0.331105]\n",
      "[Epoch 84/100] [Batch 207/347] [D loss: 0.385233] [G loss: 0.323278]\n",
      "[Epoch 84/100] [Batch 208/347] [D loss: 0.374778] [G loss: 0.321712]\n",
      "[Epoch 84/100] [Batch 209/347] [D loss: 0.370006] [G loss: 0.317331]\n",
      "[Epoch 84/100] [Batch 210/347] [D loss: 0.310137] [G loss: 0.324451]\n",
      "[Epoch 84/100] [Batch 211/347] [D loss: 0.303053] [G loss: 0.332671]\n",
      "[Epoch 84/100] [Batch 212/347] [D loss: 0.276204] [G loss: 0.357212]\n",
      "[Epoch 84/100] [Batch 213/347] [D loss: 0.240922] [G loss: 0.396894]\n",
      "[Epoch 84/100] [Batch 214/347] [D loss: 0.202152] [G loss: 0.436695]\n",
      "[Epoch 84/100] [Batch 215/347] [D loss: 0.167296] [G loss: 0.470178]\n",
      "[Epoch 84/100] [Batch 216/347] [D loss: 0.274124] [G loss: 0.491999]\n",
      "[Epoch 84/100] [Batch 217/347] [D loss: 0.367319] [G loss: 0.519022]\n",
      "[Epoch 84/100] [Batch 218/347] [D loss: 0.446997] [G loss: 0.540716]\n",
      "[Epoch 84/100] [Batch 219/347] [D loss: 0.429289] [G loss: 0.551020]\n",
      "[Epoch 84/100] [Batch 220/347] [D loss: 0.427030] [G loss: 0.555955]\n",
      "[Epoch 84/100] [Batch 221/347] [D loss: 0.466733] [G loss: 0.555169]\n",
      "[Epoch 84/100] [Batch 222/347] [D loss: 0.467519] [G loss: 0.543574]\n",
      "[Epoch 84/100] [Batch 223/347] [D loss: 0.436660] [G loss: 0.518139]\n",
      "[Epoch 84/100] [Batch 224/347] [D loss: 0.433288] [G loss: 0.491553]\n",
      "[Epoch 84/100] [Batch 225/347] [D loss: 0.425213] [G loss: 0.455767]\n",
      "[Epoch 84/100] [Batch 226/347] [D loss: 0.416357] [G loss: 0.413390]\n",
      "[Epoch 84/100] [Batch 227/347] [D loss: 0.459465] [G loss: 0.379260]\n",
      "[Epoch 84/100] [Batch 228/347] [D loss: 0.472549] [G loss: 0.344889]\n",
      "[Epoch 84/100] [Batch 229/347] [D loss: 0.465104] [G loss: 0.313377]\n",
      "[Epoch 84/100] [Batch 230/347] [D loss: 0.480763] [G loss: 0.285712]\n",
      "[Epoch 84/100] [Batch 231/347] [D loss: 0.452227] [G loss: 0.257951]\n",
      "[Epoch 84/100] [Batch 232/347] [D loss: 0.443869] [G loss: 0.243113]\n",
      "[Epoch 84/100] [Batch 233/347] [D loss: 0.405240] [G loss: 0.243588]\n",
      "[Epoch 84/100] [Batch 234/347] [D loss: 0.382799] [G loss: 0.256644]\n",
      "[Epoch 84/100] [Batch 235/347] [D loss: 0.378864] [G loss: 0.278498]\n",
      "[Epoch 84/100] [Batch 236/347] [D loss: 0.357399] [G loss: 0.310990]\n",
      "[Epoch 84/100] [Batch 237/347] [D loss: 0.392400] [G loss: 0.344569]\n",
      "[Epoch 84/100] [Batch 238/347] [D loss: 0.446331] [G loss: 0.370960]\n",
      "[Epoch 84/100] [Batch 239/347] [D loss: 0.444512] [G loss: 0.392905]\n",
      "[Epoch 84/100] [Batch 240/347] [D loss: 0.452963] [G loss: 0.412490]\n",
      "[Epoch 84/100] [Batch 241/347] [D loss: 0.456506] [G loss: 0.429856]\n",
      "[Epoch 84/100] [Batch 242/347] [D loss: 0.496917] [G loss: 0.445122]\n",
      "[Epoch 84/100] [Batch 243/347] [D loss: 0.430559] [G loss: 0.456068]\n",
      "[Epoch 84/100] [Batch 244/347] [D loss: 0.392783] [G loss: 0.453263]\n",
      "[Epoch 84/100] [Batch 245/347] [D loss: 0.395009] [G loss: 0.445698]\n",
      "[Epoch 84/100] [Batch 246/347] [D loss: 0.399748] [G loss: 0.436849]\n",
      "[Epoch 84/100] [Batch 247/347] [D loss: 0.445435] [G loss: 0.419293]\n",
      "[Epoch 84/100] [Batch 248/347] [D loss: 0.474879] [G loss: 0.418632]\n",
      "[Epoch 84/100] [Batch 249/347] [D loss: 0.435045] [G loss: 0.418584]\n",
      "[Epoch 84/100] [Batch 250/347] [D loss: 0.420966] [G loss: 0.415246]\n",
      "[Epoch 84/100] [Batch 251/347] [D loss: 0.396864] [G loss: 0.409579]\n",
      "[Epoch 84/100] [Batch 252/347] [D loss: 0.388123] [G loss: 0.400382]\n",
      "[Epoch 84/100] [Batch 253/347] [D loss: 0.344473] [G loss: 0.391225]\n",
      "[Epoch 84/100] [Batch 254/347] [D loss: 0.343352] [G loss: 0.390112]\n",
      "[Epoch 84/100] [Batch 255/347] [D loss: 0.345450] [G loss: 0.391730]\n",
      "[Epoch 84/100] [Batch 256/347] [D loss: 0.345562] [G loss: 0.393064]\n",
      "[Epoch 84/100] [Batch 257/347] [D loss: 0.324838] [G loss: 0.396233]\n",
      "[Epoch 84/100] [Batch 258/347] [D loss: 0.285227] [G loss: 0.402815]\n",
      "[Epoch 84/100] [Batch 259/347] [D loss: 0.284899] [G loss: 0.412036]\n",
      "[Epoch 84/100] [Batch 260/347] [D loss: 0.280868] [G loss: 0.422719]\n",
      "[Epoch 84/100] [Batch 261/347] [D loss: 0.270169] [G loss: 0.441000]\n",
      "[Epoch 84/100] [Batch 262/347] [D loss: 0.233506] [G loss: 0.456494]\n",
      "[Epoch 84/100] [Batch 263/347] [D loss: 0.229524] [G loss: 0.470882]\n",
      "[Epoch 84/100] [Batch 264/347] [D loss: 0.226505] [G loss: 0.483971]\n",
      "[Epoch 84/100] [Batch 265/347] [D loss: 0.240392] [G loss: 0.493836]\n",
      "[Epoch 84/100] [Batch 266/347] [D loss: 0.317247] [G loss: 0.500685]\n",
      "[Epoch 84/100] [Batch 267/347] [D loss: 0.344558] [G loss: 0.502620]\n",
      "[Epoch 84/100] [Batch 268/347] [D loss: 0.348792] [G loss: 0.500240]\n",
      "[Epoch 84/100] [Batch 269/347] [D loss: 0.351598] [G loss: 0.493385]\n",
      "[Epoch 84/100] [Batch 270/347] [D loss: 0.379661] [G loss: 0.482759]\n",
      "[Epoch 84/100] [Batch 271/347] [D loss: 0.339847] [G loss: 0.476244]\n",
      "[Epoch 84/100] [Batch 272/347] [D loss: 0.427149] [G loss: 0.489697]\n",
      "[Epoch 84/100] [Batch 273/347] [D loss: 0.401340] [G loss: 0.508440]\n",
      "[Epoch 84/100] [Batch 274/347] [D loss: 0.372477] [G loss: 0.529613]\n",
      "[Epoch 84/100] [Batch 275/347] [D loss: 0.306041] [G loss: 0.548003]\n",
      "[Epoch 84/100] [Batch 276/347] [D loss: 0.422499] [G loss: 0.545241]\n",
      "[Epoch 84/100] [Batch 277/347] [D loss: 0.469823] [G loss: 0.551863]\n",
      "[Epoch 84/100] [Batch 278/347] [D loss: 0.481420] [G loss: 0.558614]\n",
      "[Epoch 84/100] [Batch 279/347] [D loss: 0.495607] [G loss: 0.557148]\n",
      "[Epoch 84/100] [Batch 280/347] [D loss: 0.500632] [G loss: 0.554361]\n",
      "[Epoch 84/100] [Batch 281/347] [D loss: 0.522551] [G loss: 0.552424]\n",
      "[Epoch 84/100] [Batch 282/347] [D loss: 0.520016] [G loss: 0.550527]\n",
      "[Epoch 84/100] [Batch 283/347] [D loss: 0.513949] [G loss: 0.547673]\n",
      "[Epoch 84/100] [Batch 284/347] [D loss: 0.506305] [G loss: 0.544483]\n",
      "[Epoch 84/100] [Batch 285/347] [D loss: 0.517559] [G loss: 0.538722]\n",
      "[Epoch 84/100] [Batch 286/347] [D loss: 0.491336] [G loss: 0.514898]\n",
      "[Epoch 84/100] [Batch 287/347] [D loss: 0.481682] [G loss: 0.497534]\n",
      "[Epoch 84/100] [Batch 288/347] [D loss: 0.460288] [G loss: 0.475832]\n",
      "[Epoch 84/100] [Batch 289/347] [D loss: 0.417090] [G loss: 0.444815]\n",
      "[Epoch 84/100] [Batch 290/347] [D loss: 0.396108] [G loss: 0.427372]\n",
      "[Epoch 84/100] [Batch 291/347] [D loss: 0.376694] [G loss: 0.402680]\n",
      "[Epoch 84/100] [Batch 292/347] [D loss: 0.360388] [G loss: 0.380692]\n",
      "[Epoch 84/100] [Batch 293/347] [D loss: 0.263876] [G loss: 0.370369]\n",
      "[Epoch 84/100] [Batch 294/347] [D loss: 0.276497] [G loss: 0.372448]\n",
      "[Epoch 84/100] [Batch 295/347] [D loss: 0.280804] [G loss: 0.378695]\n",
      "[Epoch 84/100] [Batch 296/347] [D loss: 0.276075] [G loss: 0.391987]\n",
      "[Epoch 84/100] [Batch 297/347] [D loss: 0.407301] [G loss: 0.414847]\n",
      "[Epoch 84/100] [Batch 298/347] [D loss: 0.404353] [G loss: 0.424822]\n",
      "[Epoch 84/100] [Batch 299/347] [D loss: 0.406984] [G loss: 0.434974]\n",
      "[Epoch 84/100] [Batch 300/347] [D loss: 0.408606] [G loss: 0.445950]\n",
      "[Epoch 84/100] [Batch 301/347] [D loss: 0.419979] [G loss: 0.439780]\n",
      "[Epoch 84/100] [Batch 302/347] [D loss: 0.434365] [G loss: 0.439044]\n",
      "[Epoch 84/100] [Batch 303/347] [D loss: 0.431539] [G loss: 0.432852]\n",
      "[Epoch 84/100] [Batch 304/347] [D loss: 0.300793] [G loss: 0.427832]\n",
      "[Epoch 84/100] [Batch 305/347] [D loss: 0.224280] [G loss: 0.429540]\n",
      "[Epoch 84/100] [Batch 306/347] [D loss: 0.222380] [G loss: 0.442026]\n",
      "[Epoch 84/100] [Batch 307/347] [D loss: 0.217769] [G loss: 0.461753]\n",
      "[Epoch 84/100] [Batch 308/347] [D loss: 0.290521] [G loss: 0.480820]\n",
      "[Epoch 84/100] [Batch 309/347] [D loss: 0.456528] [G loss: 0.503930]\n",
      "[Epoch 84/100] [Batch 310/347] [D loss: 0.581554] [G loss: 0.525916]\n",
      "[Epoch 84/100] [Batch 311/347] [D loss: 0.545768] [G loss: 0.532381]\n",
      "[Epoch 84/100] [Batch 312/347] [D loss: 0.468049] [G loss: 0.531584]\n",
      "[Epoch 84/100] [Batch 313/347] [D loss: 0.432462] [G loss: 0.523664]\n",
      "[Epoch 84/100] [Batch 314/347] [D loss: 0.425317] [G loss: 0.506062]\n",
      "[Epoch 84/100] [Batch 315/347] [D loss: 0.427273] [G loss: 0.487545]\n",
      "[Epoch 84/100] [Batch 316/347] [D loss: 0.457240] [G loss: 0.478687]\n",
      "[Epoch 84/100] [Batch 317/347] [D loss: 0.477804] [G loss: 0.469088]\n",
      "[Epoch 84/100] [Batch 318/347] [D loss: 0.486478] [G loss: 0.465374]\n",
      "[Epoch 84/100] [Batch 319/347] [D loss: 0.459089] [G loss: 0.460259]\n",
      "[Epoch 84/100] [Batch 320/347] [D loss: 0.455108] [G loss: 0.444514]\n",
      "[Epoch 84/100] [Batch 321/347] [D loss: 0.439645] [G loss: 0.425687]\n",
      "[Epoch 84/100] [Batch 322/347] [D loss: 0.452815] [G loss: 0.408697]\n",
      "[Epoch 84/100] [Batch 323/347] [D loss: 0.387302] [G loss: 0.395029]\n",
      "[Epoch 84/100] [Batch 324/347] [D loss: 0.386618] [G loss: 0.387875]\n",
      "[Epoch 84/100] [Batch 325/347] [D loss: 0.390973] [G loss: 0.383074]\n",
      "[Epoch 84/100] [Batch 326/347] [D loss: 0.396953] [G loss: 0.379584]\n",
      "[Epoch 84/100] [Batch 327/347] [D loss: 0.383795] [G loss: 0.382402]\n",
      "[Epoch 84/100] [Batch 328/347] [D loss: 0.387949] [G loss: 0.389878]\n",
      "[Epoch 84/100] [Batch 329/347] [D loss: 0.384645] [G loss: 0.401800]\n",
      "[Epoch 84/100] [Batch 330/347] [D loss: 0.381086] [G loss: 0.416658]\n",
      "[Epoch 84/100] [Batch 331/347] [D loss: 0.407570] [G loss: 0.436708]\n",
      "[Epoch 84/100] [Batch 332/347] [D loss: 0.509827] [G loss: 0.468503]\n",
      "[Epoch 84/100] [Batch 333/347] [D loss: 0.462255] [G loss: 0.477331]\n",
      "[Epoch 84/100] [Batch 334/347] [D loss: 0.455517] [G loss: 0.478369]\n",
      "[Epoch 84/100] [Batch 335/347] [D loss: 0.458979] [G loss: 0.482729]\n",
      "[Epoch 84/100] [Batch 336/347] [D loss: 0.459784] [G loss: 0.485968]\n",
      "[Epoch 84/100] [Batch 337/347] [D loss: 0.522442] [G loss: 0.491561]\n",
      "[Epoch 84/100] [Batch 338/347] [D loss: 0.567693] [G loss: 0.501308]\n",
      "[Epoch 84/100] [Batch 339/347] [D loss: 0.540466] [G loss: 0.505200]\n",
      "[Epoch 84/100] [Batch 340/347] [D loss: 0.500957] [G loss: 0.505274]\n",
      "[Epoch 84/100] [Batch 341/347] [D loss: 0.514608] [G loss: 0.510164]\n",
      "[Epoch 84/100] [Batch 342/347] [D loss: 0.361717] [G loss: 0.502655]\n",
      "[Epoch 84/100] [Batch 343/347] [D loss: 0.318690] [G loss: 0.491276]\n",
      "[Epoch 84/100] [Batch 344/347] [D loss: 0.280949] [G loss: 0.490630]\n",
      "[Epoch 84/100] [Batch 345/347] [D loss: 0.197216] [G loss: 0.499419]\n",
      "[Epoch 84/100] [Batch 346/347] [D loss: 0.194286] [G loss: 0.513033]\n",
      "[Epoch 84/100] [Batch 347/347] [D loss: 0.188170] [G loss: 0.528552]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 85/100] [Batch 1/347] [D loss: 0.518115] [G loss: 0.556754]\n",
      "[Epoch 85/100] [Batch 2/347] [D loss: 0.547936] [G loss: 0.567390]\n",
      "[Epoch 85/100] [Batch 3/347] [D loss: 0.579959] [G loss: 0.581402]\n",
      "[Epoch 85/100] [Batch 4/347] [D loss: 0.579862] [G loss: 0.591665]\n",
      "[Epoch 85/100] [Batch 5/347] [D loss: 0.576906] [G loss: 0.597840]\n",
      "[Epoch 85/100] [Batch 6/347] [D loss: 0.562609] [G loss: 0.602763]\n",
      "[Epoch 85/100] [Batch 7/347] [D loss: 0.548348] [G loss: 0.600044]\n",
      "[Epoch 85/100] [Batch 8/347] [D loss: 0.552074] [G loss: 0.603151]\n",
      "[Epoch 85/100] [Batch 9/347] [D loss: 0.549946] [G loss: 0.607618]\n",
      "[Epoch 85/100] [Batch 10/347] [D loss: 0.553913] [G loss: 0.611022]\n",
      "[Epoch 85/100] [Batch 11/347] [D loss: 0.559747] [G loss: 0.622523]\n",
      "[Epoch 85/100] [Batch 12/347] [D loss: 0.561697] [G loss: 0.626989]\n",
      "[Epoch 85/100] [Batch 13/347] [D loss: 0.557622] [G loss: 0.627383]\n",
      "[Epoch 85/100] [Batch 14/347] [D loss: 0.553068] [G loss: 0.627634]\n",
      "[Epoch 85/100] [Batch 15/347] [D loss: 0.555036] [G loss: 0.618348]\n",
      "[Epoch 85/100] [Batch 16/347] [D loss: 0.554412] [G loss: 0.612685]\n",
      "[Epoch 85/100] [Batch 17/347] [D loss: 0.554729] [G loss: 0.615039]\n",
      "[Epoch 85/100] [Batch 18/347] [D loss: 0.555767] [G loss: 0.615344]\n",
      "[Epoch 85/100] [Batch 19/347] [D loss: 0.555063] [G loss: 0.620188]\n",
      "[Epoch 85/100] [Batch 20/347] [D loss: 0.555596] [G loss: 0.624486]\n",
      "[Epoch 85/100] [Batch 21/347] [D loss: 0.549188] [G loss: 0.618614]\n",
      "[Epoch 85/100] [Batch 22/347] [D loss: 0.550144] [G loss: 0.615486]\n",
      "[Epoch 85/100] [Batch 23/347] [D loss: 0.549971] [G loss: 0.611140]\n",
      "[Epoch 85/100] [Batch 24/347] [D loss: 0.525055] [G loss: 0.601278]\n",
      "[Epoch 85/100] [Batch 25/347] [D loss: 0.459808] [G loss: 0.606203]\n",
      "[Epoch 85/100] [Batch 26/347] [D loss: 0.451246] [G loss: 0.603934]\n",
      "[Epoch 85/100] [Batch 27/347] [D loss: 0.429330] [G loss: 0.603185]\n",
      "[Epoch 85/100] [Batch 28/347] [D loss: 0.406276] [G loss: 0.600737]\n",
      "[Epoch 85/100] [Batch 29/347] [D loss: 0.422416] [G loss: 0.588782]\n",
      "[Epoch 85/100] [Batch 30/347] [D loss: 0.375248] [G loss: 0.565001]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 85/100] [Batch 31/347] [D loss: 0.346010] [G loss: 0.531534]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 85/100] [Batch 32/347] [D loss: 0.340522] [G loss: 0.489089]\n",
      "[Epoch 85/100] [Batch 33/347] [D loss: 0.352447] [G loss: 0.447497]\n",
      "[Epoch 85/100] [Batch 34/347] [D loss: 0.408643] [G loss: 0.409130]\n",
      "[Epoch 85/100] [Batch 35/347] [D loss: 0.420850] [G loss: 0.375734]\n",
      "[Epoch 85/100] [Batch 36/347] [D loss: 0.462428] [G loss: 0.347900]\n",
      "[Epoch 85/100] [Batch 37/347] [D loss: 0.482072] [G loss: 0.325622]\n",
      "[Epoch 85/100] [Batch 38/347] [D loss: 0.493355] [G loss: 0.308418]\n",
      "[Epoch 85/100] [Batch 39/347] [D loss: 0.510290] [G loss: 0.303758]\n",
      "[Epoch 85/100] [Batch 40/347] [D loss: 0.543178] [G loss: 0.310911]\n",
      "[Epoch 85/100] [Batch 41/347] [D loss: 0.569480] [G loss: 0.319866]\n",
      "[Epoch 85/100] [Batch 42/347] [D loss: 0.560131] [G loss: 0.337701]\n",
      "[Epoch 85/100] [Batch 43/347] [D loss: 0.586038] [G loss: 0.363560]\n",
      "[Epoch 85/100] [Batch 44/347] [D loss: 0.555860] [G loss: 0.381676]\n",
      "[Epoch 85/100] [Batch 45/347] [D loss: 0.519330] [G loss: 0.388157]\n",
      "[Epoch 85/100] [Batch 46/347] [D loss: 0.423817] [G loss: 0.401029]\n",
      "[Epoch 85/100] [Batch 47/347] [D loss: 0.413288] [G loss: 0.413975]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 85/100] [Batch 48/347] [D loss: 0.275842] [G loss: 0.442162]\n",
      "[Epoch 85/100] [Batch 49/347] [D loss: 0.250758] [G loss: 0.478833]\n",
      "[Epoch 85/100] [Batch 50/347] [D loss: 0.236442] [G loss: 0.515909]\n",
      "[Epoch 85/100] [Batch 51/347] [D loss: 0.221618] [G loss: 0.544562]\n",
      "[Epoch 85/100] [Batch 52/347] [D loss: 0.387534] [G loss: 0.556661]\n",
      "[Epoch 85/100] [Batch 53/347] [D loss: 0.457729] [G loss: 0.555750]\n",
      "[Epoch 85/100] [Batch 54/347] [D loss: 0.439343] [G loss: 0.550119]\n",
      "[Epoch 85/100] [Batch 55/347] [D loss: 0.433197] [G loss: 0.554394]\n",
      "[Epoch 85/100] [Batch 56/347] [D loss: 0.416208] [G loss: 0.559249]\n",
      "[Epoch 85/100] [Batch 57/347] [D loss: 0.344273] [G loss: 0.560744]\n",
      "[Epoch 85/100] [Batch 58/347] [D loss: 0.348241] [G loss: 0.554512]\n",
      "[Epoch 85/100] [Batch 59/347] [D loss: 0.343352] [G loss: 0.537933]\n",
      "[Epoch 85/100] [Batch 60/347] [D loss: 0.330184] [G loss: 0.511559]\n",
      "[Epoch 85/100] [Batch 61/347] [D loss: 0.352882] [G loss: 0.482044]\n",
      "[Epoch 85/100] [Batch 62/347] [D loss: 0.351249] [G loss: 0.468071]\n",
      "[Epoch 85/100] [Batch 63/347] [D loss: 0.343701] [G loss: 0.455326]\n",
      "[Epoch 85/100] [Batch 64/347] [D loss: 0.320927] [G loss: 0.443433]\n",
      "[Epoch 85/100] [Batch 65/347] [D loss: 0.267415] [G loss: 0.444625]\n",
      "[Epoch 85/100] [Batch 66/347] [D loss: 0.272918] [G loss: 0.446304]\n",
      "[Epoch 85/100] [Batch 67/347] [D loss: 0.274234] [G loss: 0.443111]\n",
      "[Epoch 85/100] [Batch 68/347] [D loss: 0.275018] [G loss: 0.451180]\n",
      "[Epoch 85/100] [Batch 69/347] [D loss: 0.295945] [G loss: 0.463031]\n",
      "[Epoch 85/100] [Batch 70/347] [D loss: 0.292528] [G loss: 0.471253]\n",
      "[Epoch 85/100] [Batch 71/347] [D loss: 0.287826] [G loss: 0.493612]\n",
      "[Epoch 85/100] [Batch 72/347] [D loss: 0.296770] [G loss: 0.514835]\n",
      "[Epoch 85/100] [Batch 73/347] [D loss: 0.452365] [G loss: 0.518017]\n",
      "[Epoch 85/100] [Batch 74/347] [D loss: 0.457009] [G loss: 0.522478]\n",
      "[Epoch 85/100] [Batch 75/347] [D loss: 0.457621] [G loss: 0.524096]\n",
      "[Epoch 85/100] [Batch 76/347] [D loss: 0.458363] [G loss: 0.521236]\n",
      "[Epoch 85/100] [Batch 77/347] [D loss: 0.495694] [G loss: 0.517493]\n",
      "[Epoch 85/100] [Batch 78/347] [D loss: 0.544722] [G loss: 0.527184]\n",
      "[Epoch 85/100] [Batch 79/347] [D loss: 0.534847] [G loss: 0.527068]\n",
      "[Epoch 85/100] [Batch 80/347] [D loss: 0.413425] [G loss: 0.512202]\n",
      "[Epoch 85/100] [Batch 81/347] [D loss: 0.387222] [G loss: 0.505251]\n",
      "[Epoch 85/100] [Batch 82/347] [D loss: 0.384189] [G loss: 0.499910]\n",
      "[Epoch 85/100] [Batch 83/347] [D loss: 0.390541] [G loss: 0.491211]\n",
      "[Epoch 85/100] [Batch 84/347] [D loss: 0.540278] [G loss: 0.488589]\n",
      "[Epoch 85/100] [Batch 85/347] [D loss: 0.627338] [G loss: 0.487827]\n",
      "[Epoch 85/100] [Batch 86/347] [D loss: 0.630338] [G loss: 0.492314]\n",
      "[Epoch 85/100] [Batch 87/347] [D loss: 0.627792] [G loss: 0.501392]\n",
      "[Epoch 85/100] [Batch 88/347] [D loss: 0.635467] [G loss: 0.516636]\n",
      "[Epoch 85/100] [Batch 89/347] [D loss: 0.629944] [G loss: 0.536761]\n",
      "[Epoch 85/100] [Batch 90/347] [D loss: 0.619509] [G loss: 0.555775]\n",
      "[Epoch 85/100] [Batch 91/347] [D loss: 0.608586] [G loss: 0.575563]\n",
      "[Epoch 85/100] [Batch 92/347] [D loss: 0.596636] [G loss: 0.597482]\n",
      "[Epoch 85/100] [Batch 93/347] [D loss: 0.584104] [G loss: 0.614789]\n",
      "[Epoch 85/100] [Batch 94/347] [D loss: 0.573600] [G loss: 0.625415]\n",
      "[Epoch 85/100] [Batch 95/347] [D loss: 0.565800] [G loss: 0.635449]\n",
      "[Epoch 85/100] [Batch 96/347] [D loss: 0.560838] [G loss: 0.644877]\n",
      "[Epoch 85/100] [Batch 97/347] [D loss: 0.557137] [G loss: 0.650002]\n",
      "[Epoch 85/100] [Batch 98/347] [D loss: 0.553910] [G loss: 0.655204]\n",
      "[Epoch 85/100] [Batch 99/347] [D loss: 0.553103] [G loss: 0.658163]\n",
      "[Epoch 85/100] [Batch 100/347] [D loss: 0.552402] [G loss: 0.659295]\n",
      "[Epoch 85/100] [Batch 101/347] [D loss: 0.552611] [G loss: 0.658180]\n",
      "[Epoch 85/100] [Batch 102/347] [D loss: 0.554577] [G loss: 0.655773]\n",
      "[Epoch 85/100] [Batch 103/347] [D loss: 0.554630] [G loss: 0.656728]\n",
      "[Epoch 85/100] [Batch 104/347] [D loss: 0.553582] [G loss: 0.651398]\n",
      "[Epoch 85/100] [Batch 105/347] [D loss: 0.508271] [G loss: 0.644418]\n",
      "[Epoch 85/100] [Batch 106/347] [D loss: 0.357069] [G loss: 0.634978]\n",
      "[Epoch 85/100] [Batch 107/347] [D loss: 0.355891] [G loss: 0.636238]\n",
      "[Epoch 85/100] [Batch 108/347] [D loss: 0.344455] [G loss: 0.637326]\n",
      "[Epoch 85/100] [Batch 109/347] [D loss: 0.311918] [G loss: 0.639805]\n",
      "[Epoch 85/100] [Batch 110/347] [D loss: 0.397793] [G loss: 0.633826]\n",
      "[Epoch 85/100] [Batch 111/347] [D loss: 0.363149] [G loss: 0.634573]\n",
      "[Epoch 85/100] [Batch 112/347] [D loss: 0.325180] [G loss: 0.631063]\n",
      "[Epoch 85/100] [Batch 113/347] [D loss: 0.463389] [G loss: 0.636907]\n",
      "[Epoch 85/100] [Batch 114/347] [D loss: 0.528931] [G loss: 0.626844]\n",
      "[Epoch 85/100] [Batch 115/347] [D loss: 0.525973] [G loss: 0.589072]\n",
      "[Epoch 85/100] [Batch 116/347] [D loss: 0.458762] [G loss: 0.543495]\n",
      "[Epoch 85/100] [Batch 117/347] [D loss: 0.436494] [G loss: 0.499241]\n",
      "[Epoch 85/100] [Batch 118/347] [D loss: 0.358723] [G loss: 0.460467]\n",
      "[Epoch 85/100] [Batch 119/347] [D loss: 0.358338] [G loss: 0.423244]\n",
      "[Epoch 85/100] [Batch 120/347] [D loss: 0.362848] [G loss: 0.402248]\n",
      "[Epoch 85/100] [Batch 121/347] [D loss: 0.371957] [G loss: 0.387699]\n",
      "[Epoch 85/100] [Batch 122/347] [D loss: 0.505710] [G loss: 0.383867]\n",
      "[Epoch 85/100] [Batch 123/347] [D loss: 0.562823] [G loss: 0.384296]\n",
      "[Epoch 85/100] [Batch 124/347] [D loss: 0.489219] [G loss: 0.385267]\n",
      "[Epoch 85/100] [Batch 125/347] [D loss: 0.456657] [G loss: 0.396004]\n",
      "[Epoch 85/100] [Batch 126/347] [D loss: 0.413663] [G loss: 0.410244]\n",
      "[Epoch 85/100] [Batch 127/347] [D loss: 0.407936] [G loss: 0.423545]\n",
      "[Epoch 85/100] [Batch 128/347] [D loss: 0.385277] [G loss: 0.435055]\n",
      "[Epoch 85/100] [Batch 129/347] [D loss: 0.321191] [G loss: 0.457727]\n",
      "[Epoch 85/100] [Batch 130/347] [D loss: 0.248289] [G loss: 0.496612]\n",
      "[Epoch 85/100] [Batch 131/347] [D loss: 0.214826] [G loss: 0.529826]\n",
      "[Epoch 85/100] [Batch 132/347] [D loss: 0.190009] [G loss: 0.562793]\n",
      "[Epoch 85/100] [Batch 133/347] [D loss: 0.162499] [G loss: 0.590320]\n",
      "[Epoch 85/100] [Batch 134/347] [D loss: 0.150000] [G loss: 0.611096]\n",
      "[Epoch 85/100] [Batch 135/347] [D loss: 0.140818] [G loss: 0.624349]\n",
      "[Epoch 85/100] [Batch 136/347] [D loss: 0.142276] [G loss: 0.627215]\n",
      "[Epoch 85/100] [Batch 137/347] [D loss: 0.431360] [G loss: 0.624454]\n",
      "[Epoch 85/100] [Batch 138/347] [D loss: 0.471961] [G loss: 0.618379]\n",
      "[Epoch 85/100] [Batch 139/347] [D loss: 0.479958] [G loss: 0.608649]\n",
      "[Epoch 85/100] [Batch 140/347] [D loss: 0.495186] [G loss: 0.607192]\n",
      "[Epoch 85/100] [Batch 141/347] [D loss: 0.470276] [G loss: 0.600664]\n",
      "[Epoch 85/100] [Batch 142/347] [D loss: 0.473562] [G loss: 0.593836]\n",
      "[Epoch 85/100] [Batch 143/347] [D loss: 0.470565] [G loss: 0.583940]\n",
      "[Epoch 85/100] [Batch 144/347] [D loss: 0.452326] [G loss: 0.572445]\n",
      "[Epoch 85/100] [Batch 145/347] [D loss: 0.473283] [G loss: 0.567447]\n",
      "[Epoch 85/100] [Batch 146/347] [D loss: 0.481245] [G loss: 0.554052]\n",
      "[Epoch 85/100] [Batch 147/347] [D loss: 0.495919] [G loss: 0.538735]\n",
      "[Epoch 85/100] [Batch 148/347] [D loss: 0.508999] [G loss: 0.523970]\n",
      "[Epoch 85/100] [Batch 149/347] [D loss: 0.441494] [G loss: 0.501334]\n",
      "[Epoch 85/100] [Batch 150/347] [D loss: 0.405916] [G loss: 0.473905]\n",
      "[Epoch 85/100] [Batch 151/347] [D loss: 0.383421] [G loss: 0.442622]\n",
      "[Epoch 85/100] [Batch 152/347] [D loss: 0.369009] [G loss: 0.408758]\n",
      "[Epoch 85/100] [Batch 153/347] [D loss: 0.379139] [G loss: 0.379084]\n",
      "[Epoch 85/100] [Batch 154/347] [D loss: 0.380708] [G loss: 0.361622]\n",
      "[Epoch 85/100] [Batch 155/347] [D loss: 0.378299] [G loss: 0.357610]\n",
      "[Epoch 85/100] [Batch 156/347] [D loss: 0.375996] [G loss: 0.356119]\n",
      "[Epoch 85/100] [Batch 157/347] [D loss: 0.362195] [G loss: 0.364740]\n",
      "[Epoch 85/100] [Batch 158/347] [D loss: 0.329144] [G loss: 0.385049]\n",
      "[Epoch 85/100] [Batch 159/347] [D loss: 0.339079] [G loss: 0.409457]\n",
      "[Epoch 85/100] [Batch 160/347] [D loss: 0.315223] [G loss: 0.444717]\n",
      "[Epoch 85/100] [Batch 161/347] [D loss: 0.295563] [G loss: 0.474738]\n",
      "[Epoch 85/100] [Batch 162/347] [D loss: 0.287778] [G loss: 0.495684]\n",
      "[Epoch 85/100] [Batch 163/347] [D loss: 0.288682] [G loss: 0.507141]\n",
      "[Epoch 85/100] [Batch 164/347] [D loss: 0.290707] [G loss: 0.524982]\n",
      "[Epoch 85/100] [Batch 165/347] [D loss: 0.291722] [G loss: 0.542465]\n",
      "[Epoch 85/100] [Batch 166/347] [D loss: 0.292519] [G loss: 0.553862]\n",
      "[Epoch 85/100] [Batch 167/347] [D loss: 0.321909] [G loss: 0.570020]\n",
      "[Epoch 85/100] [Batch 168/347] [D loss: 0.321708] [G loss: 0.578945]\n",
      "[Epoch 85/100] [Batch 169/347] [D loss: 0.467603] [G loss: 0.586386]\n",
      "[Epoch 85/100] [Batch 170/347] [D loss: 0.542194] [G loss: 0.591657]\n",
      "[Epoch 85/100] [Batch 171/347] [D loss: 0.541056] [G loss: 0.590839]\n",
      "[Epoch 85/100] [Batch 172/347] [D loss: 0.539911] [G loss: 0.591231]\n",
      "[Epoch 85/100] [Batch 173/347] [D loss: 0.541861] [G loss: 0.589512]\n",
      "[Epoch 85/100] [Batch 174/347] [D loss: 0.537672] [G loss: 0.592582]\n",
      "[Epoch 85/100] [Batch 175/347] [D loss: 0.553562] [G loss: 0.597066]\n",
      "[Epoch 85/100] [Batch 176/347] [D loss: 0.563039] [G loss: 0.601079]\n",
      "[Epoch 85/100] [Batch 177/347] [D loss: 0.562535] [G loss: 0.600383]\n",
      "[Epoch 85/100] [Batch 178/347] [D loss: 0.561107] [G loss: 0.597007]\n",
      "[Epoch 85/100] [Batch 179/347] [D loss: 0.559397] [G loss: 0.597178]\n",
      "[Epoch 85/100] [Batch 180/347] [D loss: 0.557842] [G loss: 0.597350]\n",
      "[Epoch 85/100] [Batch 181/347] [D loss: 0.555322] [G loss: 0.603435]\n",
      "[Epoch 85/100] [Batch 182/347] [D loss: 0.554181] [G loss: 0.607865]\n",
      "[Epoch 85/100] [Batch 183/347] [D loss: 0.552230] [G loss: 0.613845]\n",
      "[Epoch 85/100] [Batch 184/347] [D loss: 0.553021] [G loss: 0.619449]\n",
      "[Epoch 85/100] [Batch 185/347] [D loss: 0.552058] [G loss: 0.619332]\n",
      "[Epoch 85/100] [Batch 186/347] [D loss: 0.548721] [G loss: 0.620767]\n",
      "[Epoch 85/100] [Batch 187/347] [D loss: 0.546496] [G loss: 0.619697]\n",
      "[Epoch 85/100] [Batch 188/347] [D loss: 0.541563] [G loss: 0.612897]\n",
      "[Epoch 85/100] [Batch 189/347] [D loss: 0.533954] [G loss: 0.607400]\n",
      "[Epoch 85/100] [Batch 190/347] [D loss: 0.532191] [G loss: 0.605190]\n",
      "[Epoch 85/100] [Batch 191/347] [D loss: 0.532390] [G loss: 0.602145]\n",
      "[Epoch 85/100] [Batch 192/347] [D loss: 0.532431] [G loss: 0.602099]\n",
      "[Epoch 85/100] [Batch 193/347] [D loss: 0.539732] [G loss: 0.602359]\n",
      "[Epoch 85/100] [Batch 194/347] [D loss: 0.539114] [G loss: 0.598009]\n",
      "[Epoch 85/100] [Batch 195/347] [D loss: 0.536096] [G loss: 0.593904]\n",
      "[Epoch 85/100] [Batch 196/347] [D loss: 0.530099] [G loss: 0.589724]\n",
      "[Epoch 85/100] [Batch 197/347] [D loss: 0.528779] [G loss: 0.586494]\n",
      "[Epoch 85/100] [Batch 198/347] [D loss: 0.527552] [G loss: 0.587229]\n",
      "[Epoch 85/100] [Batch 199/347] [D loss: 0.526018] [G loss: 0.584860]\n",
      "[Epoch 85/100] [Batch 200/347] [D loss: 0.532758] [G loss: 0.582181]\n",
      "[Epoch 85/100] [Batch 201/347] [D loss: 0.536237] [G loss: 0.578952]\n",
      "[Epoch 85/100] [Batch 202/347] [D loss: 0.536646] [G loss: 0.574677]\n",
      "[Epoch 85/100] [Batch 203/347] [D loss: 0.540788] [G loss: 0.570805]\n",
      "[Epoch 85/100] [Batch 204/347] [D loss: 0.538201] [G loss: 0.571391]\n",
      "[Epoch 85/100] [Batch 205/347] [D loss: 0.536480] [G loss: 0.573550]\n",
      "[Epoch 85/100] [Batch 206/347] [D loss: 0.534856] [G loss: 0.573992]\n",
      "[Epoch 85/100] [Batch 207/347] [D loss: 0.524547] [G loss: 0.573534]\n",
      "[Epoch 85/100] [Batch 208/347] [D loss: 0.521039] [G loss: 0.573598]\n",
      "[Epoch 85/100] [Batch 209/347] [D loss: 0.518058] [G loss: 0.565369]\n",
      "[Epoch 85/100] [Batch 210/347] [D loss: 0.494380] [G loss: 0.561325]\n",
      "[Epoch 85/100] [Batch 211/347] [D loss: 0.420391] [G loss: 0.550740]\n",
      "[Epoch 85/100] [Batch 212/347] [D loss: 0.227269] [G loss: 0.543436]\n",
      "[Epoch 85/100] [Batch 213/347] [D loss: 0.219174] [G loss: 0.541776]\n",
      "[Epoch 85/100] [Batch 214/347] [D loss: 0.209322] [G loss: 0.535719]\n",
      "[Epoch 85/100] [Batch 215/347] [D loss: 0.201629] [G loss: 0.530455]\n",
      "[Epoch 85/100] [Batch 216/347] [D loss: 0.405088] [G loss: 0.521863]\n",
      "[Epoch 85/100] [Batch 217/347] [D loss: 0.431112] [G loss: 0.524093]\n",
      "[Epoch 85/100] [Batch 218/347] [D loss: 0.467404] [G loss: 0.521881]\n",
      "[Epoch 85/100] [Batch 219/347] [D loss: 0.433893] [G loss: 0.508084]\n",
      "[Epoch 85/100] [Batch 220/347] [D loss: 0.409407] [G loss: 0.490580]\n",
      "[Epoch 85/100] [Batch 221/347] [D loss: 0.434614] [G loss: 0.465478]\n",
      "[Epoch 85/100] [Batch 222/347] [D loss: 0.435954] [G loss: 0.434620]\n",
      "[Epoch 85/100] [Batch 223/347] [D loss: 0.419940] [G loss: 0.394740]\n",
      "[Epoch 85/100] [Batch 224/347] [D loss: 0.437322] [G loss: 0.365295]\n",
      "[Epoch 85/100] [Batch 225/347] [D loss: 0.453903] [G loss: 0.334962]\n",
      "[Epoch 85/100] [Batch 226/347] [D loss: 0.471902] [G loss: 0.307903]\n",
      "[Epoch 85/100] [Batch 227/347] [D loss: 0.530543] [G loss: 0.303644]\n",
      "[Epoch 85/100] [Batch 228/347] [D loss: 0.557117] [G loss: 0.304161]\n",
      "[Epoch 85/100] [Batch 229/347] [D loss: 0.556737] [G loss: 0.309406]\n",
      "[Epoch 85/100] [Batch 230/347] [D loss: 0.569952] [G loss: 0.318085]\n",
      "[Epoch 85/100] [Batch 231/347] [D loss: 0.534189] [G loss: 0.322326]\n",
      "[Epoch 85/100] [Batch 232/347] [D loss: 0.508835] [G loss: 0.331230]\n",
      "[Epoch 85/100] [Batch 233/347] [D loss: 0.427375] [G loss: 0.352582]\n",
      "[Epoch 85/100] [Batch 234/347] [D loss: 0.375153] [G loss: 0.378678]\n",
      "[Epoch 85/100] [Batch 235/347] [D loss: 0.365230] [G loss: 0.404571]\n",
      "[Epoch 85/100] [Batch 236/347] [D loss: 0.349463] [G loss: 0.436289]\n",
      "[Epoch 85/100] [Batch 237/347] [D loss: 0.416382] [G loss: 0.461571]\n",
      "[Epoch 85/100] [Batch 238/347] [D loss: 0.501043] [G loss: 0.476431]\n",
      "[Epoch 85/100] [Batch 239/347] [D loss: 0.505807] [G loss: 0.485644]\n",
      "[Epoch 85/100] [Batch 240/347] [D loss: 0.506264] [G loss: 0.493844]\n",
      "[Epoch 85/100] [Batch 241/347] [D loss: 0.509747] [G loss: 0.502681]\n",
      "[Epoch 85/100] [Batch 242/347] [D loss: 0.519602] [G loss: 0.511652]\n",
      "[Epoch 85/100] [Batch 243/347] [D loss: 0.477069] [G loss: 0.517712]\n",
      "[Epoch 85/100] [Batch 244/347] [D loss: 0.449329] [G loss: 0.511894]\n",
      "[Epoch 85/100] [Batch 245/347] [D loss: 0.462318] [G loss: 0.501079]\n",
      "[Epoch 85/100] [Batch 246/347] [D loss: 0.460208] [G loss: 0.490968]\n",
      "[Epoch 85/100] [Batch 247/347] [D loss: 0.493046] [G loss: 0.475699]\n",
      "[Epoch 85/100] [Batch 248/347] [D loss: 0.513542] [G loss: 0.478347]\n",
      "[Epoch 85/100] [Batch 249/347] [D loss: 0.498359] [G loss: 0.485680]\n",
      "[Epoch 85/100] [Batch 250/347] [D loss: 0.486833] [G loss: 0.491088]\n",
      "[Epoch 85/100] [Batch 251/347] [D loss: 0.467311] [G loss: 0.491835]\n",
      "[Epoch 85/100] [Batch 252/347] [D loss: 0.453509] [G loss: 0.487571]\n",
      "[Epoch 85/100] [Batch 253/347] [D loss: 0.393521] [G loss: 0.473329]\n",
      "[Epoch 85/100] [Batch 254/347] [D loss: 0.387832] [G loss: 0.465169]\n",
      "[Epoch 85/100] [Batch 255/347] [D loss: 0.383308] [G loss: 0.454135]\n",
      "[Epoch 85/100] [Batch 256/347] [D loss: 0.382500] [G loss: 0.438309]\n",
      "[Epoch 85/100] [Batch 257/347] [D loss: 0.357587] [G loss: 0.423685]\n",
      "[Epoch 85/100] [Batch 258/347] [D loss: 0.315975] [G loss: 0.412387]\n",
      "[Epoch 85/100] [Batch 259/347] [D loss: 0.321493] [G loss: 0.402812]\n",
      "[Epoch 85/100] [Batch 260/347] [D loss: 0.323049] [G loss: 0.398566]\n",
      "[Epoch 85/100] [Batch 261/347] [D loss: 0.315876] [G loss: 0.403720]\n",
      "[Epoch 85/100] [Batch 262/347] [D loss: 0.284944] [G loss: 0.411016]\n",
      "[Epoch 85/100] [Batch 263/347] [D loss: 0.281389] [G loss: 0.421130]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 85/100] [Batch 264/347] [D loss: 0.274222] [G loss: 0.434676]\n",
      "[Epoch 85/100] [Batch 265/347] [D loss: 0.280519] [G loss: 0.447667]\n",
      "[Epoch 85/100] [Batch 266/347] [D loss: 0.340699] [G loss: 0.459930]\n",
      "[Epoch 85/100] [Batch 267/347] [D loss: 0.363172] [G loss: 0.467480]\n",
      "[Epoch 85/100] [Batch 268/347] [D loss: 0.367620] [G loss: 0.471065]\n",
      "[Epoch 85/100] [Batch 269/347] [D loss: 0.372951] [G loss: 0.472058]\n",
      "[Epoch 85/100] [Batch 270/347] [D loss: 0.401541] [G loss: 0.470213]\n",
      "[Epoch 85/100] [Batch 271/347] [D loss: 0.365105] [G loss: 0.472167]\n",
      "[Epoch 85/100] [Batch 272/347] [D loss: 0.395546] [G loss: 0.489990]\n",
      "[Epoch 85/100] [Batch 273/347] [D loss: 0.361512] [G loss: 0.506742]\n",
      "[Epoch 85/100] [Batch 274/347] [D loss: 0.332445] [G loss: 0.520782]\n",
      "[Epoch 85/100] [Batch 275/347] [D loss: 0.276791] [G loss: 0.531154]\n",
      "[Epoch 85/100] [Batch 276/347] [D loss: 0.449880] [G loss: 0.524997]\n",
      "[Epoch 85/100] [Batch 277/347] [D loss: 0.482441] [G loss: 0.534126]\n",
      "[Epoch 85/100] [Batch 278/347] [D loss: 0.489285] [G loss: 0.541516]\n",
      "[Epoch 85/100] [Batch 279/347] [D loss: 0.498868] [G loss: 0.540936]\n",
      "[Epoch 85/100] [Batch 280/347] [D loss: 0.502769] [G loss: 0.539098]\n",
      "[Epoch 85/100] [Batch 281/347] [D loss: 0.512254] [G loss: 0.537985]\n",
      "[Epoch 85/100] [Batch 282/347] [D loss: 0.513257] [G loss: 0.538716]\n",
      "[Epoch 85/100] [Batch 283/347] [D loss: 0.513648] [G loss: 0.538444]\n",
      "[Epoch 85/100] [Batch 284/347] [D loss: 0.514057] [G loss: 0.539495]\n",
      "[Epoch 85/100] [Batch 285/347] [D loss: 0.518504] [G loss: 0.539291]\n",
      "[Epoch 85/100] [Batch 286/347] [D loss: 0.517270] [G loss: 0.523974]\n",
      "[Epoch 85/100] [Batch 287/347] [D loss: 0.517832] [G loss: 0.520057]\n",
      "[Epoch 85/100] [Batch 288/347] [D loss: 0.517402] [G loss: 0.516225]\n",
      "[Epoch 85/100] [Batch 289/347] [D loss: 0.515076] [G loss: 0.510026]\n",
      "[Epoch 85/100] [Batch 290/347] [D loss: 0.512221] [G loss: 0.525337]\n",
      "[Epoch 85/100] [Batch 291/347] [D loss: 0.508606] [G loss: 0.531368]\n",
      "[Epoch 85/100] [Batch 292/347] [D loss: 0.500100] [G loss: 0.534000]\n",
      "[Epoch 85/100] [Batch 293/347] [D loss: 0.373121] [G loss: 0.538002]\n",
      "[Epoch 85/100] [Batch 294/347] [D loss: 0.360831] [G loss: 0.539232]\n",
      "[Epoch 85/100] [Batch 295/347] [D loss: 0.345466] [G loss: 0.534370]\n",
      "[Epoch 85/100] [Batch 296/347] [D loss: 0.323870] [G loss: 0.528349]\n",
      "[Epoch 85/100] [Batch 297/347] [D loss: 0.456652] [G loss: 0.528297]\n",
      "[Epoch 85/100] [Batch 298/347] [D loss: 0.482923] [G loss: 0.515831]\n",
      "[Epoch 85/100] [Batch 299/347] [D loss: 0.473531] [G loss: 0.504146]\n",
      "[Epoch 85/100] [Batch 300/347] [D loss: 0.455488] [G loss: 0.491933]\n",
      "[Epoch 85/100] [Batch 301/347] [D loss: 0.446557] [G loss: 0.462434]\n",
      "[Epoch 85/100] [Batch 302/347] [D loss: 0.438262] [G loss: 0.431568]\n",
      "[Epoch 85/100] [Batch 303/347] [D loss: 0.419831] [G loss: 0.393551]\n",
      "[Epoch 85/100] [Batch 304/347] [D loss: 0.301353] [G loss: 0.356803]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 85/100] [Batch 305/347] [D loss: 0.254941] [G loss: 0.332081]\n",
      "[Epoch 85/100] [Batch 306/347] [D loss: 0.271787] [G loss: 0.324982]\n",
      "[Epoch 85/100] [Batch 307/347] [D loss: 0.281940] [G loss: 0.332851]\n",
      "[Epoch 85/100] [Batch 308/347] [D loss: 0.323424] [G loss: 0.347718]\n",
      "[Epoch 85/100] [Batch 309/347] [D loss: 0.417314] [G loss: 0.373535]\n",
      "[Epoch 85/100] [Batch 310/347] [D loss: 0.535302] [G loss: 0.397554]\n",
      "[Epoch 85/100] [Batch 311/347] [D loss: 0.491095] [G loss: 0.408595]\n",
      "[Epoch 85/100] [Batch 312/347] [D loss: 0.401379] [G loss: 0.415784]\n",
      "[Epoch 85/100] [Batch 313/347] [D loss: 0.373262] [G loss: 0.418007]\n",
      "[Epoch 85/100] [Batch 314/347] [D loss: 0.366537] [G loss: 0.413034]\n",
      "[Epoch 85/100] [Batch 315/347] [D loss: 0.374453] [G loss: 0.408569]\n",
      "[Epoch 85/100] [Batch 316/347] [D loss: 0.402368] [G loss: 0.414328]\n",
      "[Epoch 85/100] [Batch 317/347] [D loss: 0.422405] [G loss: 0.421740]\n",
      "[Epoch 85/100] [Batch 318/347] [D loss: 0.431152] [G loss: 0.435881]\n",
      "[Epoch 85/100] [Batch 319/347] [D loss: 0.409539] [G loss: 0.447630]\n",
      "[Epoch 85/100] [Batch 320/347] [D loss: 0.406320] [G loss: 0.444613]\n",
      "[Epoch 85/100] [Batch 321/347] [D loss: 0.391833] [G loss: 0.437100]\n",
      "[Epoch 85/100] [Batch 322/347] [D loss: 0.401332] [G loss: 0.427727]\n",
      "[Epoch 85/100] [Batch 323/347] [D loss: 0.337581] [G loss: 0.417902]\n",
      "[Epoch 85/100] [Batch 324/347] [D loss: 0.333692] [G loss: 0.410806]\n",
      "[Epoch 85/100] [Batch 325/347] [D loss: 0.335692] [G loss: 0.402886]\n",
      "[Epoch 85/100] [Batch 326/347] [D loss: 0.340534] [G loss: 0.395086]\n",
      "[Epoch 85/100] [Batch 327/347] [D loss: 0.328757] [G loss: 0.390163]\n",
      "[Epoch 85/100] [Batch 328/347] [D loss: 0.333851] [G loss: 0.387437]\n",
      "[Epoch 85/100] [Batch 329/347] [D loss: 0.332371] [G loss: 0.389385]\n",
      "[Epoch 85/100] [Batch 330/347] [D loss: 0.329539] [G loss: 0.393771]\n",
      "[Epoch 85/100] [Batch 331/347] [D loss: 0.351077] [G loss: 0.405563]\n",
      "[Epoch 85/100] [Batch 332/347] [D loss: 0.434825] [G loss: 0.429217]\n",
      "[Epoch 85/100] [Batch 333/347] [D loss: 0.391792] [G loss: 0.431142]\n",
      "[Epoch 85/100] [Batch 334/347] [D loss: 0.383803] [G loss: 0.427586]\n",
      "[Epoch 85/100] [Batch 335/347] [D loss: 0.385006] [G loss: 0.428465]\n",
      "[Epoch 85/100] [Batch 336/347] [D loss: 0.384485] [G loss: 0.429273]\n",
      "[Epoch 85/100] [Batch 337/347] [D loss: 0.439953] [G loss: 0.433877]\n",
      "[Epoch 85/100] [Batch 338/347] [D loss: 0.481616] [G loss: 0.441567]\n",
      "[Epoch 85/100] [Batch 339/347] [D loss: 0.458416] [G loss: 0.442296]\n",
      "[Epoch 85/100] [Batch 340/347] [D loss: 0.424788] [G loss: 0.439646]\n",
      "[Epoch 85/100] [Batch 341/347] [D loss: 0.435433] [G loss: 0.442147]\n",
      "[Epoch 85/100] [Batch 342/347] [D loss: 0.308016] [G loss: 0.434597]\n",
      "[Epoch 85/100] [Batch 343/347] [D loss: 0.269949] [G loss: 0.425595]\n",
      "[Epoch 85/100] [Batch 344/347] [D loss: 0.252503] [G loss: 0.426153]\n",
      "[Epoch 85/100] [Batch 345/347] [D loss: 0.203450] [G loss: 0.439518]\n",
      "[Epoch 85/100] [Batch 346/347] [D loss: 0.193447] [G loss: 0.456327]\n",
      "[Epoch 85/100] [Batch 347/347] [D loss: 0.181414] [G loss: 0.473417]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 86/100] [Batch 1/347] [D loss: 0.441899] [G loss: 0.502063]\n",
      "[Epoch 86/100] [Batch 2/347] [D loss: 0.477412] [G loss: 0.509422]\n",
      "[Epoch 86/100] [Batch 3/347] [D loss: 0.515470] [G loss: 0.518750]\n",
      "[Epoch 86/100] [Batch 4/347] [D loss: 0.519812] [G loss: 0.522886]\n",
      "[Epoch 86/100] [Batch 5/347] [D loss: 0.522093] [G loss: 0.522222]\n",
      "[Epoch 86/100] [Batch 6/347] [D loss: 0.503419] [G loss: 0.520987]\n",
      "[Epoch 86/100] [Batch 7/347] [D loss: 0.484572] [G loss: 0.512383]\n",
      "[Epoch 86/100] [Batch 8/347] [D loss: 0.487795] [G loss: 0.509629]\n",
      "[Epoch 86/100] [Batch 9/347] [D loss: 0.481808] [G loss: 0.508057]\n",
      "[Epoch 86/100] [Batch 10/347] [D loss: 0.485395] [G loss: 0.505291]\n",
      "[Epoch 86/100] [Batch 11/347] [D loss: 0.507149] [G loss: 0.509811]\n",
      "[Epoch 86/100] [Batch 12/347] [D loss: 0.515757] [G loss: 0.507023]\n",
      "[Epoch 86/100] [Batch 13/347] [D loss: 0.493402] [G loss: 0.499503]\n",
      "[Epoch 86/100] [Batch 14/347] [D loss: 0.465355] [G loss: 0.490620]\n",
      "[Epoch 86/100] [Batch 15/347] [D loss: 0.468644] [G loss: 0.469784]\n",
      "[Epoch 86/100] [Batch 16/347] [D loss: 0.454964] [G loss: 0.450741]\n",
      "[Epoch 86/100] [Batch 17/347] [D loss: 0.457187] [G loss: 0.436352]\n",
      "[Epoch 86/100] [Batch 18/347] [D loss: 0.468442] [G loss: 0.418400]\n",
      "[Epoch 86/100] [Batch 19/347] [D loss: 0.459886] [G loss: 0.403499]\n",
      "[Epoch 86/100] [Batch 20/347] [D loss: 0.481626] [G loss: 0.391704]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 86/100] [Batch 21/347] [D loss: 0.407116] [G loss: 0.371860]\n",
      "[Epoch 86/100] [Batch 22/347] [D loss: 0.409127] [G loss: 0.358745]\n",
      "[Epoch 86/100] [Batch 23/347] [D loss: 0.417664] [G loss: 0.348245]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 86/100] [Batch 24/347] [D loss: 0.385474] [G loss: 0.338547]\n",
      "[Epoch 86/100] [Batch 25/347] [D loss: 0.304152] [G loss: 0.348674]\n",
      "[Epoch 86/100] [Batch 26/347] [D loss: 0.297492] [G loss: 0.364114]\n",
      "[Epoch 86/100] [Batch 27/347] [D loss: 0.286832] [G loss: 0.388474]\n",
      "[Epoch 86/100] [Batch 28/347] [D loss: 0.275410] [G loss: 0.418212]\n",
      "[Epoch 86/100] [Batch 29/347] [D loss: 0.285298] [G loss: 0.448696]\n",
      "[Epoch 86/100] [Batch 30/347] [D loss: 0.270903] [G loss: 0.469731]\n",
      "[Epoch 86/100] [Batch 31/347] [D loss: 0.270398] [G loss: 0.483453]\n",
      "[Epoch 86/100] [Batch 32/347] [D loss: 0.283238] [G loss: 0.489379]\n",
      "[Epoch 86/100] [Batch 33/347] [D loss: 0.306423] [G loss: 0.492421]\n",
      "[Epoch 86/100] [Batch 34/347] [D loss: 0.366993] [G loss: 0.489363]\n",
      "[Epoch 86/100] [Batch 35/347] [D loss: 0.375838] [G loss: 0.477112]\n",
      "[Epoch 86/100] [Batch 36/347] [D loss: 0.411758] [G loss: 0.466141]\n",
      "[Epoch 86/100] [Batch 37/347] [D loss: 0.420549] [G loss: 0.450480]\n",
      "[Epoch 86/100] [Batch 38/347] [D loss: 0.417346] [G loss: 0.428159]\n",
      "[Epoch 86/100] [Batch 39/347] [D loss: 0.419449] [G loss: 0.415922]\n",
      "[Epoch 86/100] [Batch 40/347] [D loss: 0.442197] [G loss: 0.403103]\n",
      "[Epoch 86/100] [Batch 41/347] [D loss: 0.460795] [G loss: 0.386921]\n",
      "[Epoch 86/100] [Batch 42/347] [D loss: 0.452034] [G loss: 0.378297]\n",
      "[Epoch 86/100] [Batch 43/347] [D loss: 0.478727] [G loss: 0.378275]\n",
      "[Epoch 86/100] [Batch 44/347] [D loss: 0.454880] [G loss: 0.372624]\n",
      "[Epoch 86/100] [Batch 45/347] [D loss: 0.428669] [G loss: 0.357578]\n",
      "[Epoch 86/100] [Batch 46/347] [D loss: 0.357698] [G loss: 0.345507]\n",
      "[Epoch 86/100] [Batch 47/347] [D loss: 0.357794] [G loss: 0.343866]\n",
      "[Epoch 86/100] [Batch 48/347] [D loss: 0.289597] [G loss: 0.360225]\n",
      "[Epoch 86/100] [Batch 49/347] [D loss: 0.268473] [G loss: 0.393085]\n",
      "[Epoch 86/100] [Batch 50/347] [D loss: 0.246369] [G loss: 0.430924]\n",
      "[Epoch 86/100] [Batch 51/347] [D loss: 0.217366] [G loss: 0.462776]\n",
      "[Epoch 86/100] [Batch 52/347] [D loss: 0.312112] [G loss: 0.479700]\n",
      "[Epoch 86/100] [Batch 53/347] [D loss: 0.364027] [G loss: 0.480849]\n",
      "[Epoch 86/100] [Batch 54/347] [D loss: 0.354295] [G loss: 0.476659]\n",
      "[Epoch 86/100] [Batch 55/347] [D loss: 0.350060] [G loss: 0.483156]\n",
      "[Epoch 86/100] [Batch 56/347] [D loss: 0.338088] [G loss: 0.491301]\n",
      "[Epoch 86/100] [Batch 57/347] [D loss: 0.275181] [G loss: 0.497599]\n",
      "[Epoch 86/100] [Batch 58/347] [D loss: 0.278334] [G loss: 0.498658]\n",
      "[Epoch 86/100] [Batch 59/347] [D loss: 0.275683] [G loss: 0.489053]\n",
      "[Epoch 86/100] [Batch 60/347] [D loss: 0.265697] [G loss: 0.468702]\n",
      "[Epoch 86/100] [Batch 61/347] [D loss: 0.283796] [G loss: 0.446279]\n",
      "[Epoch 86/100] [Batch 62/347] [D loss: 0.280579] [G loss: 0.436378]\n",
      "[Epoch 86/100] [Batch 63/347] [D loss: 0.270946] [G loss: 0.426685]\n",
      "[Epoch 86/100] [Batch 64/347] [D loss: 0.255542] [G loss: 0.417241]\n",
      "[Epoch 86/100] [Batch 65/347] [D loss: 0.218862] [G loss: 0.420100]\n",
      "[Epoch 86/100] [Batch 66/347] [D loss: 0.221340] [G loss: 0.423183]\n",
      "[Epoch 86/100] [Batch 67/347] [D loss: 0.219091] [G loss: 0.419766]\n",
      "[Epoch 86/100] [Batch 68/347] [D loss: 0.216254] [G loss: 0.426250]\n",
      "[Epoch 86/100] [Batch 69/347] [D loss: 0.229963] [G loss: 0.433801]\n",
      "[Epoch 86/100] [Batch 70/347] [D loss: 0.226294] [G loss: 0.438568]\n",
      "[Epoch 86/100] [Batch 71/347] [D loss: 0.221724] [G loss: 0.456923]\n",
      "[Epoch 86/100] [Batch 72/347] [D loss: 0.228581] [G loss: 0.473669]\n",
      "[Epoch 86/100] [Batch 73/347] [D loss: 0.361213] [G loss: 0.472098]\n",
      "[Epoch 86/100] [Batch 74/347] [D loss: 0.362320] [G loss: 0.472848]\n",
      "[Epoch 86/100] [Batch 75/347] [D loss: 0.358677] [G loss: 0.470262]\n",
      "[Epoch 86/100] [Batch 76/347] [D loss: 0.353490] [G loss: 0.463152]\n",
      "[Epoch 86/100] [Batch 77/347] [D loss: 0.386820] [G loss: 0.461091]\n",
      "[Epoch 86/100] [Batch 78/347] [D loss: 0.428060] [G loss: 0.462013]\n",
      "[Epoch 86/100] [Batch 79/347] [D loss: 0.416846] [G loss: 0.452673]\n",
      "[Epoch 86/100] [Batch 80/347] [D loss: 0.305498] [G loss: 0.429770]\n",
      "[Epoch 86/100] [Batch 81/347] [D loss: 0.288637] [G loss: 0.421535]\n",
      "[Epoch 86/100] [Batch 82/347] [D loss: 0.288516] [G loss: 0.419029]\n",
      "[Epoch 86/100] [Batch 83/347] [D loss: 0.296068] [G loss: 0.416536]\n",
      "[Epoch 86/100] [Batch 84/347] [D loss: 0.434452] [G loss: 0.418775]\n",
      "[Epoch 86/100] [Batch 85/347] [D loss: 0.520998] [G loss: 0.417542]\n",
      "[Epoch 86/100] [Batch 86/347] [D loss: 0.523554] [G loss: 0.415908]\n",
      "[Epoch 86/100] [Batch 87/347] [D loss: 0.523292] [G loss: 0.415645]\n",
      "[Epoch 86/100] [Batch 88/347] [D loss: 0.547241] [G loss: 0.416185]\n",
      "[Epoch 86/100] [Batch 89/347] [D loss: 0.555047] [G loss: 0.419244]\n",
      "[Epoch 86/100] [Batch 90/347] [D loss: 0.553152] [G loss: 0.419893]\n",
      "[Epoch 86/100] [Batch 91/347] [D loss: 0.555855] [G loss: 0.421056]\n",
      "[Epoch 86/100] [Batch 92/347] [D loss: 0.559173] [G loss: 0.424995]\n",
      "[Epoch 86/100] [Batch 93/347] [D loss: 0.559594] [G loss: 0.429427]\n",
      "[Epoch 86/100] [Batch 94/347] [D loss: 0.540383] [G loss: 0.429894]\n",
      "[Epoch 86/100] [Batch 95/347] [D loss: 0.527390] [G loss: 0.432134]\n",
      "[Epoch 86/100] [Batch 96/347] [D loss: 0.525064] [G loss: 0.437056]\n",
      "[Epoch 86/100] [Batch 97/347] [D loss: 0.516548] [G loss: 0.438639]\n",
      "[Epoch 86/100] [Batch 98/347] [D loss: 0.491060] [G loss: 0.441055]\n",
      "[Epoch 86/100] [Batch 99/347] [D loss: 0.491298] [G loss: 0.442299]\n",
      "[Epoch 86/100] [Batch 100/347] [D loss: 0.490384] [G loss: 0.441546]\n",
      "[Epoch 86/100] [Batch 101/347] [D loss: 0.498999] [G loss: 0.438082]\n",
      "[Epoch 86/100] [Batch 102/347] [D loss: 0.558846] [G loss: 0.436736]\n",
      "[Epoch 86/100] [Batch 103/347] [D loss: 0.565283] [G loss: 0.441250]\n",
      "[Epoch 86/100] [Batch 104/347] [D loss: 0.537164] [G loss: 0.439963]\n",
      "[Epoch 86/100] [Batch 105/347] [D loss: 0.440718] [G loss: 0.439892]\n",
      "[Epoch 86/100] [Batch 106/347] [D loss: 0.235716] [G loss: 0.446362]\n",
      "[Epoch 86/100] [Batch 107/347] [D loss: 0.215596] [G loss: 0.468375]\n",
      "[Epoch 86/100] [Batch 108/347] [D loss: 0.201752] [G loss: 0.494126]\n",
      "[Epoch 86/100] [Batch 109/347] [D loss: 0.174727] [G loss: 0.518129]\n",
      "[Epoch 86/100] [Batch 110/347] [D loss: 0.185381] [G loss: 0.538888]\n",
      "[Epoch 86/100] [Batch 111/347] [D loss: 0.189046] [G loss: 0.556084]\n",
      "[Epoch 86/100] [Batch 112/347] [D loss: 0.192547] [G loss: 0.568039]\n",
      "[Epoch 86/100] [Batch 113/347] [D loss: 0.402976] [G loss: 0.591138]\n",
      "[Epoch 86/100] [Batch 114/347] [D loss: 0.485171] [G loss: 0.600216]\n",
      "[Epoch 86/100] [Batch 115/347] [D loss: 0.494189] [G loss: 0.584000]\n",
      "[Epoch 86/100] [Batch 116/347] [D loss: 0.442489] [G loss: 0.565619]\n",
      "[Epoch 86/100] [Batch 117/347] [D loss: 0.440404] [G loss: 0.550754]\n",
      "[Epoch 86/100] [Batch 118/347] [D loss: 0.359936] [G loss: 0.531640]\n",
      "[Epoch 86/100] [Batch 119/347] [D loss: 0.338354] [G loss: 0.521208]\n",
      "[Epoch 86/100] [Batch 120/347] [D loss: 0.307376] [G loss: 0.511553]\n",
      "[Epoch 86/100] [Batch 121/347] [D loss: 0.285863] [G loss: 0.488143]\n",
      "[Epoch 86/100] [Batch 122/347] [D loss: 0.411112] [G loss: 0.462954]\n",
      "[Epoch 86/100] [Batch 123/347] [D loss: 0.463717] [G loss: 0.440054]\n",
      "[Epoch 86/100] [Batch 124/347] [D loss: 0.383640] [G loss: 0.414456]\n",
      "[Epoch 86/100] [Batch 125/347] [D loss: 0.356856] [G loss: 0.399337]\n",
      "[Epoch 86/100] [Batch 126/347] [D loss: 0.329090] [G loss: 0.391067]\n",
      "[Epoch 86/100] [Batch 127/347] [D loss: 0.336967] [G loss: 0.386660]\n",
      "[Epoch 86/100] [Batch 128/347] [D loss: 0.329930] [G loss: 0.382794]\n",
      "[Epoch 86/100] [Batch 129/347] [D loss: 0.312452] [G loss: 0.388413]\n",
      "[Epoch 86/100] [Batch 130/347] [D loss: 0.285564] [G loss: 0.422805]\n",
      "[Epoch 86/100] [Batch 131/347] [D loss: 0.249317] [G loss: 0.458967]\n",
      "[Epoch 86/100] [Batch 132/347] [D loss: 0.209458] [G loss: 0.500055]\n",
      "[Epoch 86/100] [Batch 133/347] [D loss: 0.186054] [G loss: 0.535187]\n",
      "[Epoch 86/100] [Batch 134/347] [D loss: 0.157080] [G loss: 0.558329]\n",
      "[Epoch 86/100] [Batch 135/347] [D loss: 0.137038] [G loss: 0.571535]\n",
      "[Epoch 86/100] [Batch 136/347] [D loss: 0.130796] [G loss: 0.574329]\n",
      "[Epoch 86/100] [Batch 137/347] [D loss: 0.384031] [G loss: 0.571595]\n",
      "[Epoch 86/100] [Batch 138/347] [D loss: 0.430278] [G loss: 0.565119]\n",
      "[Epoch 86/100] [Batch 139/347] [D loss: 0.447683] [G loss: 0.555046]\n",
      "[Epoch 86/100] [Batch 140/347] [D loss: 0.467629] [G loss: 0.553607]\n",
      "[Epoch 86/100] [Batch 141/347] [D loss: 0.436611] [G loss: 0.547076]\n",
      "[Epoch 86/100] [Batch 142/347] [D loss: 0.443067] [G loss: 0.540734]\n",
      "[Epoch 86/100] [Batch 143/347] [D loss: 0.434656] [G loss: 0.531699]\n",
      "[Epoch 86/100] [Batch 144/347] [D loss: 0.411179] [G loss: 0.521411]\n",
      "[Epoch 86/100] [Batch 145/347] [D loss: 0.427486] [G loss: 0.518529]\n",
      "[Epoch 86/100] [Batch 146/347] [D loss: 0.424631] [G loss: 0.507395]\n",
      "[Epoch 86/100] [Batch 147/347] [D loss: 0.430665] [G loss: 0.490901]\n",
      "[Epoch 86/100] [Batch 148/347] [D loss: 0.432001] [G loss: 0.467546]\n",
      "[Epoch 86/100] [Batch 149/347] [D loss: 0.344637] [G loss: 0.431870]\n",
      "[Epoch 86/100] [Batch 150/347] [D loss: 0.311956] [G loss: 0.392640]\n",
      "[Epoch 86/100] [Batch 151/347] [D loss: 0.306297] [G loss: 0.357178]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 86/100] [Batch 152/347] [D loss: 0.311476] [G loss: 0.324471]\n",
      "[Epoch 86/100] [Batch 153/347] [D loss: 0.331116] [G loss: 0.301615]\n",
      "[Epoch 86/100] [Batch 154/347] [D loss: 0.341670] [G loss: 0.294253]\n",
      "[Epoch 86/100] [Batch 155/347] [D loss: 0.340565] [G loss: 0.301911]\n",
      "[Epoch 86/100] [Batch 156/347] [D loss: 0.334669] [G loss: 0.313811]\n",
      "[Epoch 86/100] [Batch 157/347] [D loss: 0.313158] [G loss: 0.336413]\n",
      "[Epoch 86/100] [Batch 158/347] [D loss: 0.284172] [G loss: 0.372483]\n",
      "[Epoch 86/100] [Batch 159/347] [D loss: 0.273101] [G loss: 0.408625]\n",
      "[Epoch 86/100] [Batch 160/347] [D loss: 0.241636] [G loss: 0.448740]\n",
      "[Epoch 86/100] [Batch 161/347] [D loss: 0.223654] [G loss: 0.480523]\n",
      "[Epoch 86/100] [Batch 162/347] [D loss: 0.217864] [G loss: 0.494859]\n",
      "[Epoch 86/100] [Batch 163/347] [D loss: 0.227219] [G loss: 0.496048]\n",
      "[Epoch 86/100] [Batch 164/347] [D loss: 0.236738] [G loss: 0.504582]\n",
      "[Epoch 86/100] [Batch 165/347] [D loss: 0.240753] [G loss: 0.514696]\n",
      "[Epoch 86/100] [Batch 166/347] [D loss: 0.240350] [G loss: 0.522433]\n",
      "[Epoch 86/100] [Batch 167/347] [D loss: 0.264920] [G loss: 0.542210]\n",
      "[Epoch 86/100] [Batch 168/347] [D loss: 0.261169] [G loss: 0.548655]\n",
      "[Epoch 86/100] [Batch 169/347] [D loss: 0.415957] [G loss: 0.552631]\n",
      "[Epoch 86/100] [Batch 170/347] [D loss: 0.494196] [G loss: 0.552476]\n",
      "[Epoch 86/100] [Batch 171/347] [D loss: 0.484256] [G loss: 0.542828]\n",
      "[Epoch 86/100] [Batch 172/347] [D loss: 0.469483] [G loss: 0.531359]\n",
      "[Epoch 86/100] [Batch 173/347] [D loss: 0.457143] [G loss: 0.512944]\n",
      "[Epoch 86/100] [Batch 174/347] [D loss: 0.433773] [G loss: 0.493156]\n",
      "[Epoch 86/100] [Batch 175/347] [D loss: 0.477469] [G loss: 0.471180]\n",
      "[Epoch 86/100] [Batch 176/347] [D loss: 0.511728] [G loss: 0.447754]\n",
      "[Epoch 86/100] [Batch 177/347] [D loss: 0.507487] [G loss: 0.418846]\n",
      "[Epoch 86/100] [Batch 178/347] [D loss: 0.493838] [G loss: 0.389851]\n",
      "[Epoch 86/100] [Batch 179/347] [D loss: 0.493671] [G loss: 0.366681]\n",
      "[Epoch 86/100] [Batch 180/347] [D loss: 0.494975] [G loss: 0.347478]\n",
      "[Epoch 86/100] [Batch 181/347] [D loss: 0.495972] [G loss: 0.338692]\n",
      "[Epoch 86/100] [Batch 182/347] [D loss: 0.503227] [G loss: 0.332358]\n",
      "[Epoch 86/100] [Batch 183/347] [D loss: 0.508073] [G loss: 0.331141]\n",
      "[Epoch 86/100] [Batch 184/347] [D loss: 0.540281] [G loss: 0.333609]\n",
      "[Epoch 86/100] [Batch 185/347] [D loss: 0.553568] [G loss: 0.334979]\n",
      "[Epoch 86/100] [Batch 186/347] [D loss: 0.528701] [G loss: 0.340385]\n",
      "[Epoch 86/100] [Batch 187/347] [D loss: 0.515448] [G loss: 0.346623]\n",
      "[Epoch 86/100] [Batch 188/347] [D loss: 0.474346] [G loss: 0.351608]\n",
      "[Epoch 86/100] [Batch 189/347] [D loss: 0.415828] [G loss: 0.361317]\n",
      "[Epoch 86/100] [Batch 190/347] [D loss: 0.401203] [G loss: 0.378283]\n",
      "[Epoch 86/100] [Batch 191/347] [D loss: 0.396392] [G loss: 0.395721]\n",
      "[Epoch 86/100] [Batch 192/347] [D loss: 0.406183] [G loss: 0.414689]\n",
      "[Epoch 86/100] [Batch 193/347] [D loss: 0.489520] [G loss: 0.432548]\n",
      "[Epoch 86/100] [Batch 194/347] [D loss: 0.478666] [G loss: 0.443120]\n",
      "[Epoch 86/100] [Batch 195/347] [D loss: 0.455186] [G loss: 0.452283]\n",
      "[Epoch 86/100] [Batch 196/347] [D loss: 0.402657] [G loss: 0.457325]\n",
      "[Epoch 86/100] [Batch 197/347] [D loss: 0.405122] [G loss: 0.460367]\n",
      "[Epoch 86/100] [Batch 198/347] [D loss: 0.400931] [G loss: 0.464242]\n",
      "[Epoch 86/100] [Batch 199/347] [D loss: 0.400407] [G loss: 0.462392]\n",
      "[Epoch 86/100] [Batch 200/347] [D loss: 0.466950] [G loss: 0.459605]\n",
      "[Epoch 86/100] [Batch 201/347] [D loss: 0.506133] [G loss: 0.454430]\n",
      "[Epoch 86/100] [Batch 202/347] [D loss: 0.510961] [G loss: 0.448799]\n",
      "[Epoch 86/100] [Batch 203/347] [D loss: 0.562541] [G loss: 0.444373]\n",
      "[Epoch 86/100] [Batch 204/347] [D loss: 0.548068] [G loss: 0.444297]\n",
      "[Epoch 86/100] [Batch 205/347] [D loss: 0.543946] [G loss: 0.445588]\n",
      "[Epoch 86/100] [Batch 206/347] [D loss: 0.536798] [G loss: 0.445618]\n",
      "[Epoch 86/100] [Batch 207/347] [D loss: 0.445877] [G loss: 0.442746]\n",
      "[Epoch 86/100] [Batch 208/347] [D loss: 0.426104] [G loss: 0.441695]\n",
      "[Epoch 86/100] [Batch 209/347] [D loss: 0.416961] [G loss: 0.432435]\n",
      "[Epoch 86/100] [Batch 210/347] [D loss: 0.326350] [G loss: 0.430037]\n",
      "[Epoch 86/100] [Batch 211/347] [D loss: 0.300220] [G loss: 0.427660]\n",
      "[Epoch 86/100] [Batch 212/347] [D loss: 0.225460] [G loss: 0.430271]\n",
      "[Epoch 86/100] [Batch 213/347] [D loss: 0.213405] [G loss: 0.453389]\n",
      "[Epoch 86/100] [Batch 214/347] [D loss: 0.196555] [G loss: 0.478976]\n",
      "[Epoch 86/100] [Batch 215/347] [D loss: 0.178175] [G loss: 0.505442]\n",
      "[Epoch 86/100] [Batch 216/347] [D loss: 0.315458] [G loss: 0.531501]\n",
      "[Epoch 86/100] [Batch 217/347] [D loss: 0.392065] [G loss: 0.557585]\n",
      "[Epoch 86/100] [Batch 218/347] [D loss: 0.458424] [G loss: 0.579465]\n",
      "[Epoch 86/100] [Batch 219/347] [D loss: 0.433224] [G loss: 0.590165]\n",
      "[Epoch 86/100] [Batch 220/347] [D loss: 0.425725] [G loss: 0.595049]\n",
      "[Epoch 86/100] [Batch 221/347] [D loss: 0.460741] [G loss: 0.592152]\n",
      "[Epoch 86/100] [Batch 222/347] [D loss: 0.463070] [G loss: 0.577597]\n",
      "[Epoch 86/100] [Batch 223/347] [D loss: 0.440922] [G loss: 0.549217]\n",
      "[Epoch 86/100] [Batch 224/347] [D loss: 0.449228] [G loss: 0.513332]\n",
      "[Epoch 86/100] [Batch 225/347] [D loss: 0.453749] [G loss: 0.474488]\n",
      "[Epoch 86/100] [Batch 226/347] [D loss: 0.460686] [G loss: 0.439287]\n",
      "[Epoch 86/100] [Batch 227/347] [D loss: 0.509596] [G loss: 0.414082]\n",
      "[Epoch 86/100] [Batch 228/347] [D loss: 0.532947] [G loss: 0.390807]\n",
      "[Epoch 86/100] [Batch 229/347] [D loss: 0.530579] [G loss: 0.370807]\n",
      "[Epoch 86/100] [Batch 230/347] [D loss: 0.547279] [G loss: 0.353949]\n",
      "[Epoch 86/100] [Batch 231/347] [D loss: 0.513175] [G loss: 0.335084]\n",
      "[Epoch 86/100] [Batch 232/347] [D loss: 0.492903] [G loss: 0.325742]\n",
      "[Epoch 86/100] [Batch 233/347] [D loss: 0.423012] [G loss: 0.328677]\n",
      "[Epoch 86/100] [Batch 234/347] [D loss: 0.383389] [G loss: 0.339052]\n",
      "[Epoch 86/100] [Batch 235/347] [D loss: 0.378698] [G loss: 0.362462]\n",
      "[Epoch 86/100] [Batch 236/347] [D loss: 0.360948] [G loss: 0.392182]\n",
      "[Epoch 86/100] [Batch 237/347] [D loss: 0.419212] [G loss: 0.420517]\n",
      "[Epoch 86/100] [Batch 238/347] [D loss: 0.493401] [G loss: 0.440296]\n",
      "[Epoch 86/100] [Batch 239/347] [D loss: 0.495176] [G loss: 0.457118]\n",
      "[Epoch 86/100] [Batch 240/347] [D loss: 0.499119] [G loss: 0.471952]\n",
      "[Epoch 86/100] [Batch 241/347] [D loss: 0.502196] [G loss: 0.487479]\n",
      "[Epoch 86/100] [Batch 242/347] [D loss: 0.528826] [G loss: 0.502015]\n",
      "[Epoch 86/100] [Batch 243/347] [D loss: 0.465903] [G loss: 0.512450]\n",
      "[Epoch 86/100] [Batch 244/347] [D loss: 0.427579] [G loss: 0.511061]\n",
      "[Epoch 86/100] [Batch 245/347] [D loss: 0.436494] [G loss: 0.503258]\n",
      "[Epoch 86/100] [Batch 246/347] [D loss: 0.439378] [G loss: 0.492274]\n",
      "[Epoch 86/100] [Batch 247/347] [D loss: 0.487660] [G loss: 0.482923]\n",
      "[Epoch 86/100] [Batch 248/347] [D loss: 0.517526] [G loss: 0.482778]\n",
      "[Epoch 86/100] [Batch 249/347] [D loss: 0.487818] [G loss: 0.484732]\n",
      "[Epoch 86/100] [Batch 250/347] [D loss: 0.470926] [G loss: 0.487070]\n",
      "[Epoch 86/100] [Batch 251/347] [D loss: 0.443738] [G loss: 0.486121]\n",
      "[Epoch 86/100] [Batch 252/347] [D loss: 0.429894] [G loss: 0.482497]\n",
      "[Epoch 86/100] [Batch 253/347] [D loss: 0.373656] [G loss: 0.467963]\n",
      "[Epoch 86/100] [Batch 254/347] [D loss: 0.369046] [G loss: 0.464773]\n",
      "[Epoch 86/100] [Batch 255/347] [D loss: 0.369690] [G loss: 0.459801]\n",
      "[Epoch 86/100] [Batch 256/347] [D loss: 0.370575] [G loss: 0.449317]\n",
      "[Epoch 86/100] [Batch 257/347] [D loss: 0.347780] [G loss: 0.443597]\n",
      "[Epoch 86/100] [Batch 258/347] [D loss: 0.305550] [G loss: 0.442574]\n",
      "[Epoch 86/100] [Batch 259/347] [D loss: 0.308946] [G loss: 0.442360]\n",
      "[Epoch 86/100] [Batch 260/347] [D loss: 0.308230] [G loss: 0.446959]\n",
      "[Epoch 86/100] [Batch 261/347] [D loss: 0.297836] [G loss: 0.459294]\n",
      "[Epoch 86/100] [Batch 262/347] [D loss: 0.261151] [G loss: 0.470422]\n",
      "[Epoch 86/100] [Batch 263/347] [D loss: 0.257468] [G loss: 0.483060]\n",
      "[Epoch 86/100] [Batch 264/347] [D loss: 0.252888] [G loss: 0.497815]\n",
      "[Epoch 86/100] [Batch 265/347] [D loss: 0.263785] [G loss: 0.510190]\n",
      "[Epoch 86/100] [Batch 266/347] [D loss: 0.335751] [G loss: 0.519928]\n",
      "[Epoch 86/100] [Batch 267/347] [D loss: 0.362070] [G loss: 0.525351]\n",
      "[Epoch 86/100] [Batch 268/347] [D loss: 0.367308] [G loss: 0.525343]\n",
      "[Epoch 86/100] [Batch 269/347] [D loss: 0.371363] [G loss: 0.522352]\n",
      "[Epoch 86/100] [Batch 270/347] [D loss: 0.401149] [G loss: 0.516732]\n",
      "[Epoch 86/100] [Batch 271/347] [D loss: 0.354938] [G loss: 0.513768]\n",
      "[Epoch 86/100] [Batch 272/347] [D loss: 0.367162] [G loss: 0.530732]\n",
      "[Epoch 86/100] [Batch 273/347] [D loss: 0.339501] [G loss: 0.550840]\n",
      "[Epoch 86/100] [Batch 274/347] [D loss: 0.311467] [G loss: 0.570525]\n",
      "[Epoch 86/100] [Batch 275/347] [D loss: 0.255875] [G loss: 0.586150]\n",
      "[Epoch 86/100] [Batch 276/347] [D loss: 0.448024] [G loss: 0.577599]\n",
      "[Epoch 86/100] [Batch 277/347] [D loss: 0.487157] [G loss: 0.588708]\n",
      "[Epoch 86/100] [Batch 278/347] [D loss: 0.495545] [G loss: 0.595939]\n",
      "[Epoch 86/100] [Batch 279/347] [D loss: 0.508053] [G loss: 0.595235]\n",
      "[Epoch 86/100] [Batch 280/347] [D loss: 0.511606] [G loss: 0.594042]\n",
      "[Epoch 86/100] [Batch 281/347] [D loss: 0.527331] [G loss: 0.592583]\n",
      "[Epoch 86/100] [Batch 282/347] [D loss: 0.528202] [G loss: 0.592340]\n",
      "[Epoch 86/100] [Batch 283/347] [D loss: 0.527019] [G loss: 0.591294]\n",
      "[Epoch 86/100] [Batch 284/347] [D loss: 0.526634] [G loss: 0.591407]\n",
      "[Epoch 86/100] [Batch 285/347] [D loss: 0.532015] [G loss: 0.590348]\n",
      "[Epoch 86/100] [Batch 286/347] [D loss: 0.526577] [G loss: 0.573873]\n",
      "[Epoch 86/100] [Batch 287/347] [D loss: 0.527174] [G loss: 0.568965]\n",
      "[Epoch 86/100] [Batch 288/347] [D loss: 0.522564] [G loss: 0.563552]\n",
      "[Epoch 86/100] [Batch 289/347] [D loss: 0.514266] [G loss: 0.556735]\n",
      "[Epoch 86/100] [Batch 290/347] [D loss: 0.501415] [G loss: 0.567221]\n",
      "[Epoch 86/100] [Batch 291/347] [D loss: 0.480433] [G loss: 0.568090]\n",
      "[Epoch 86/100] [Batch 292/347] [D loss: 0.444034] [G loss: 0.562377]\n",
      "[Epoch 86/100] [Batch 293/347] [D loss: 0.227655] [G loss: 0.554257]\n",
      "[Epoch 86/100] [Batch 294/347] [D loss: 0.215046] [G loss: 0.542741]\n",
      "[Epoch 86/100] [Batch 295/347] [D loss: 0.210595] [G loss: 0.523667]\n",
      "[Epoch 86/100] [Batch 296/347] [D loss: 0.210126] [G loss: 0.505071]\n",
      "[Epoch 86/100] [Batch 297/347] [D loss: 0.394882] [G loss: 0.493282]\n",
      "[Epoch 86/100] [Batch 298/347] [D loss: 0.402854] [G loss: 0.468312]\n",
      "[Epoch 86/100] [Batch 299/347] [D loss: 0.402106] [G loss: 0.447139]\n",
      "[Epoch 86/100] [Batch 300/347] [D loss: 0.400733] [G loss: 0.428692]\n",
      "[Epoch 86/100] [Batch 301/347] [D loss: 0.411429] [G loss: 0.405217]\n",
      "[Epoch 86/100] [Batch 302/347] [D loss: 0.424385] [G loss: 0.385928]\n",
      "[Epoch 86/100] [Batch 303/347] [D loss: 0.425910] [G loss: 0.365958]\n",
      "[Epoch 86/100] [Batch 304/347] [D loss: 0.337458] [G loss: 0.355700]\n",
      "[Epoch 86/100] [Batch 305/347] [D loss: 0.287418] [G loss: 0.360443]\n",
      "[Epoch 86/100] [Batch 306/347] [D loss: 0.279654] [G loss: 0.382038]\n",
      "[Epoch 86/100] [Batch 307/347] [D loss: 0.263898] [G loss: 0.414963]\n",
      "[Epoch 86/100] [Batch 308/347] [D loss: 0.301406] [G loss: 0.447830]\n",
      "[Epoch 86/100] [Batch 309/347] [D loss: 0.426953] [G loss: 0.487881]\n",
      "[Epoch 86/100] [Batch 310/347] [D loss: 0.553164] [G loss: 0.523215]\n",
      "[Epoch 86/100] [Batch 311/347] [D loss: 0.512481] [G loss: 0.540622]\n",
      "[Epoch 86/100] [Batch 312/347] [D loss: 0.435906] [G loss: 0.548502]\n",
      "[Epoch 86/100] [Batch 313/347] [D loss: 0.411718] [G loss: 0.547539]\n",
      "[Epoch 86/100] [Batch 314/347] [D loss: 0.414180] [G loss: 0.536589]\n",
      "[Epoch 86/100] [Batch 315/347] [D loss: 0.420822] [G loss: 0.525026]\n",
      "[Epoch 86/100] [Batch 316/347] [D loss: 0.446619] [G loss: 0.522162]\n",
      "[Epoch 86/100] [Batch 317/347] [D loss: 0.459051] [G loss: 0.519314]\n",
      "[Epoch 86/100] [Batch 318/347] [D loss: 0.464045] [G loss: 0.523158]\n",
      "[Epoch 86/100] [Batch 319/347] [D loss: 0.433851] [G loss: 0.522560]\n",
      "[Epoch 86/100] [Batch 320/347] [D loss: 0.426545] [G loss: 0.506317]\n",
      "[Epoch 86/100] [Batch 321/347] [D loss: 0.406670] [G loss: 0.484066]\n",
      "[Epoch 86/100] [Batch 322/347] [D loss: 0.415727] [G loss: 0.462217]\n",
      "[Epoch 86/100] [Batch 323/347] [D loss: 0.347405] [G loss: 0.442083]\n",
      "[Epoch 86/100] [Batch 324/347] [D loss: 0.346032] [G loss: 0.426957]\n",
      "[Epoch 86/100] [Batch 325/347] [D loss: 0.351164] [G loss: 0.413135]\n",
      "[Epoch 86/100] [Batch 326/347] [D loss: 0.358783] [G loss: 0.402899]\n",
      "[Epoch 86/100] [Batch 327/347] [D loss: 0.349772] [G loss: 0.399601]\n",
      "[Epoch 86/100] [Batch 328/347] [D loss: 0.355684] [G loss: 0.399705]\n",
      "[Epoch 86/100] [Batch 329/347] [D loss: 0.353459] [G loss: 0.405762]\n",
      "[Epoch 86/100] [Batch 330/347] [D loss: 0.348955] [G loss: 0.416081]\n",
      "[Epoch 86/100] [Batch 331/347] [D loss: 0.368100] [G loss: 0.433009]\n",
      "[Epoch 86/100] [Batch 332/347] [D loss: 0.452415] [G loss: 0.462785]\n",
      "[Epoch 86/100] [Batch 333/347] [D loss: 0.406183] [G loss: 0.472426]\n",
      "[Epoch 86/100] [Batch 334/347] [D loss: 0.398005] [G loss: 0.474555]\n",
      "[Epoch 86/100] [Batch 335/347] [D loss: 0.399804] [G loss: 0.481142]\n",
      "[Epoch 86/100] [Batch 336/347] [D loss: 0.400222] [G loss: 0.487080]\n",
      "[Epoch 86/100] [Batch 337/347] [D loss: 0.458755] [G loss: 0.494971]\n",
      "[Epoch 86/100] [Batch 338/347] [D loss: 0.500781] [G loss: 0.505624]\n",
      "[Epoch 86/100] [Batch 339/347] [D loss: 0.476187] [G loss: 0.507876]\n",
      "[Epoch 86/100] [Batch 340/347] [D loss: 0.439532] [G loss: 0.505563]\n",
      "[Epoch 86/100] [Batch 341/347] [D loss: 0.451754] [G loss: 0.507137]\n",
      "[Epoch 86/100] [Batch 342/347] [D loss: 0.313329] [G loss: 0.497310]\n",
      "[Epoch 86/100] [Batch 343/347] [D loss: 0.273968] [G loss: 0.485967]\n",
      "[Epoch 86/100] [Batch 344/347] [D loss: 0.249056] [G loss: 0.485648]\n",
      "[Epoch 86/100] [Batch 345/347] [D loss: 0.185392] [G loss: 0.495468]\n",
      "[Epoch 86/100] [Batch 346/347] [D loss: 0.180406] [G loss: 0.509703]\n",
      "[Epoch 86/100] [Batch 347/347] [D loss: 0.172100] [G loss: 0.524918]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 87/100] [Batch 1/347] [D loss: 0.457015] [G loss: 0.552095]\n",
      "[Epoch 87/100] [Batch 2/347] [D loss: 0.491366] [G loss: 0.559839]\n",
      "[Epoch 87/100] [Batch 3/347] [D loss: 0.530662] [G loss: 0.569334]\n",
      "[Epoch 87/100] [Batch 4/347] [D loss: 0.535784] [G loss: 0.573892]\n",
      "[Epoch 87/100] [Batch 5/347] [D loss: 0.538101] [G loss: 0.574329]\n",
      "[Epoch 87/100] [Batch 6/347] [D loss: 0.511501] [G loss: 0.573289]\n",
      "[Epoch 87/100] [Batch 7/347] [D loss: 0.487701] [G loss: 0.564034]\n",
      "[Epoch 87/100] [Batch 8/347] [D loss: 0.489982] [G loss: 0.559825]\n",
      "[Epoch 87/100] [Batch 9/347] [D loss: 0.483019] [G loss: 0.555954]\n",
      "[Epoch 87/100] [Batch 10/347] [D loss: 0.486781] [G loss: 0.549627]\n",
      "[Epoch 87/100] [Batch 11/347] [D loss: 0.517431] [G loss: 0.549905]\n",
      "[Epoch 87/100] [Batch 12/347] [D loss: 0.528161] [G loss: 0.543484]\n",
      "[Epoch 87/100] [Batch 13/347] [D loss: 0.500409] [G loss: 0.532358]\n",
      "[Epoch 87/100] [Batch 14/347] [D loss: 0.469948] [G loss: 0.520135]\n",
      "[Epoch 87/100] [Batch 15/347] [D loss: 0.473692] [G loss: 0.497521]\n",
      "[Epoch 87/100] [Batch 16/347] [D loss: 0.463838] [G loss: 0.476535]\n",
      "[Epoch 87/100] [Batch 17/347] [D loss: 0.469802] [G loss: 0.463742]\n",
      "[Epoch 87/100] [Batch 18/347] [D loss: 0.485283] [G loss: 0.448670]\n",
      "[Epoch 87/100] [Batch 19/347] [D loss: 0.479044] [G loss: 0.439371]\n",
      "[Epoch 87/100] [Batch 20/347] [D loss: 0.500978] [G loss: 0.431411]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 87/100] [Batch 21/347] [D loss: 0.428037] [G loss: 0.417702]\n",
      "[Epoch 87/100] [Batch 22/347] [D loss: 0.429811] [G loss: 0.407138]\n",
      "[Epoch 87/100] [Batch 23/347] [D loss: 0.436547] [G loss: 0.400135]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 87/100] [Batch 24/347] [D loss: 0.398271] [G loss: 0.392521]\n",
      "[Epoch 87/100] [Batch 25/347] [D loss: 0.300957] [G loss: 0.405596]\n",
      "[Epoch 87/100] [Batch 26/347] [D loss: 0.295878] [G loss: 0.419484]\n",
      "[Epoch 87/100] [Batch 27/347] [D loss: 0.287892] [G loss: 0.442471]\n",
      "[Epoch 87/100] [Batch 28/347] [D loss: 0.279790] [G loss: 0.467758]\n",
      "[Epoch 87/100] [Batch 29/347] [D loss: 0.297097] [G loss: 0.493369]\n",
      "[Epoch 87/100] [Batch 30/347] [D loss: 0.282587] [G loss: 0.511584]\n",
      "[Epoch 87/100] [Batch 31/347] [D loss: 0.282123] [G loss: 0.526153]\n",
      "[Epoch 87/100] [Batch 32/347] [D loss: 0.293598] [G loss: 0.534454]\n",
      "[Epoch 87/100] [Batch 33/347] [D loss: 0.315287] [G loss: 0.538918]\n",
      "[Epoch 87/100] [Batch 34/347] [D loss: 0.376292] [G loss: 0.536211]\n",
      "[Epoch 87/100] [Batch 35/347] [D loss: 0.386084] [G loss: 0.527040]\n",
      "[Epoch 87/100] [Batch 36/347] [D loss: 0.424594] [G loss: 0.515846]\n",
      "[Epoch 87/100] [Batch 37/347] [D loss: 0.437139] [G loss: 0.500444]\n",
      "[Epoch 87/100] [Batch 38/347] [D loss: 0.438127] [G loss: 0.479161]\n",
      "[Epoch 87/100] [Batch 39/347] [D loss: 0.443236] [G loss: 0.464353]\n",
      "[Epoch 87/100] [Batch 40/347] [D loss: 0.464917] [G loss: 0.454577]\n",
      "[Epoch 87/100] [Batch 41/347] [D loss: 0.480997] [G loss: 0.442704]\n",
      "[Epoch 87/100] [Batch 42/347] [D loss: 0.472066] [G loss: 0.437308]\n",
      "[Epoch 87/100] [Batch 43/347] [D loss: 0.494278] [G loss: 0.439806]\n",
      "[Epoch 87/100] [Batch 44/347] [D loss: 0.469512] [G loss: 0.436001]\n",
      "[Epoch 87/100] [Batch 45/347] [D loss: 0.440309] [G loss: 0.420535]\n",
      "[Epoch 87/100] [Batch 46/347] [D loss: 0.362104] [G loss: 0.409214]\n",
      "[Epoch 87/100] [Batch 47/347] [D loss: 0.363510] [G loss: 0.403989]\n",
      "[Epoch 87/100] [Batch 48/347] [D loss: 0.267108] [G loss: 0.415769]\n",
      "[Epoch 87/100] [Batch 49/347] [D loss: 0.252788] [G loss: 0.440578]\n",
      "[Epoch 87/100] [Batch 50/347] [D loss: 0.241540] [G loss: 0.470757]\n",
      "[Epoch 87/100] [Batch 51/347] [D loss: 0.221521] [G loss: 0.500228]\n",
      "[Epoch 87/100] [Batch 52/347] [D loss: 0.330451] [G loss: 0.515828]\n",
      "[Epoch 87/100] [Batch 53/347] [D loss: 0.382281] [G loss: 0.519142]\n",
      "[Epoch 87/100] [Batch 54/347] [D loss: 0.370417] [G loss: 0.517329]\n",
      "[Epoch 87/100] [Batch 55/347] [D loss: 0.364261] [G loss: 0.525302]\n",
      "[Epoch 87/100] [Batch 56/347] [D loss: 0.348715] [G loss: 0.533963]\n",
      "[Epoch 87/100] [Batch 57/347] [D loss: 0.285703] [G loss: 0.539958]\n",
      "[Epoch 87/100] [Batch 58/347] [D loss: 0.288485] [G loss: 0.540461]\n",
      "[Epoch 87/100] [Batch 59/347] [D loss: 0.289548] [G loss: 0.530524]\n",
      "[Epoch 87/100] [Batch 60/347] [D loss: 0.284957] [G loss: 0.511503]\n",
      "[Epoch 87/100] [Batch 61/347] [D loss: 0.307453] [G loss: 0.488885]\n",
      "[Epoch 87/100] [Batch 62/347] [D loss: 0.303785] [G loss: 0.481913]\n",
      "[Epoch 87/100] [Batch 63/347] [D loss: 0.292134] [G loss: 0.472995]\n",
      "[Epoch 87/100] [Batch 64/347] [D loss: 0.269056] [G loss: 0.462766]\n",
      "[Epoch 87/100] [Batch 65/347] [D loss: 0.222797] [G loss: 0.465681]\n",
      "[Epoch 87/100] [Batch 66/347] [D loss: 0.226634] [G loss: 0.467752]\n",
      "[Epoch 87/100] [Batch 67/347] [D loss: 0.227907] [G loss: 0.464524]\n",
      "[Epoch 87/100] [Batch 68/347] [D loss: 0.228170] [G loss: 0.470472]\n",
      "[Epoch 87/100] [Batch 69/347] [D loss: 0.248667] [G loss: 0.477177]\n",
      "[Epoch 87/100] [Batch 70/347] [D loss: 0.246793] [G loss: 0.481526]\n",
      "[Epoch 87/100] [Batch 71/347] [D loss: 0.240207] [G loss: 0.499277]\n",
      "[Epoch 87/100] [Batch 72/347] [D loss: 0.246639] [G loss: 0.516190]\n",
      "[Epoch 87/100] [Batch 73/347] [D loss: 0.386664] [G loss: 0.514864]\n",
      "[Epoch 87/100] [Batch 74/347] [D loss: 0.386960] [G loss: 0.515695]\n",
      "[Epoch 87/100] [Batch 75/347] [D loss: 0.383821] [G loss: 0.513041]\n",
      "[Epoch 87/100] [Batch 76/347] [D loss: 0.379570] [G loss: 0.505332]\n",
      "[Epoch 87/100] [Batch 77/347] [D loss: 0.409337] [G loss: 0.499828]\n",
      "[Epoch 87/100] [Batch 78/347] [D loss: 0.448453] [G loss: 0.501989]\n",
      "[Epoch 87/100] [Batch 79/347] [D loss: 0.437513] [G loss: 0.493944]\n",
      "[Epoch 87/100] [Batch 80/347] [D loss: 0.325108] [G loss: 0.474028]\n",
      "[Epoch 87/100] [Batch 81/347] [D loss: 0.304943] [G loss: 0.468064]\n",
      "[Epoch 87/100] [Batch 82/347] [D loss: 0.302550] [G loss: 0.466249]\n",
      "[Epoch 87/100] [Batch 83/347] [D loss: 0.309914] [G loss: 0.463038]\n",
      "[Epoch 87/100] [Batch 84/347] [D loss: 0.452537] [G loss: 0.465458]\n",
      "[Epoch 87/100] [Batch 85/347] [D loss: 0.541355] [G loss: 0.464886]\n",
      "[Epoch 87/100] [Batch 86/347] [D loss: 0.543734] [G loss: 0.465093]\n",
      "[Epoch 87/100] [Batch 87/347] [D loss: 0.542666] [G loss: 0.467372]\n",
      "[Epoch 87/100] [Batch 88/347] [D loss: 0.561820] [G loss: 0.470577]\n",
      "[Epoch 87/100] [Batch 89/347] [D loss: 0.566488] [G loss: 0.478302]\n",
      "[Epoch 87/100] [Batch 90/347] [D loss: 0.563717] [G loss: 0.484089]\n",
      "[Epoch 87/100] [Batch 91/347] [D loss: 0.564392] [G loss: 0.491573]\n",
      "[Epoch 87/100] [Batch 92/347] [D loss: 0.564581] [G loss: 0.500188]\n",
      "[Epoch 87/100] [Batch 93/347] [D loss: 0.562780] [G loss: 0.511374]\n",
      "[Epoch 87/100] [Batch 94/347] [D loss: 0.547493] [G loss: 0.517882]\n",
      "[Epoch 87/100] [Batch 95/347] [D loss: 0.536641] [G loss: 0.526479]\n",
      "[Epoch 87/100] [Batch 96/347] [D loss: 0.532779] [G loss: 0.536150]\n",
      "[Epoch 87/100] [Batch 97/347] [D loss: 0.526286] [G loss: 0.542175]\n",
      "[Epoch 87/100] [Batch 98/347] [D loss: 0.507538] [G loss: 0.548254]\n",
      "[Epoch 87/100] [Batch 99/347] [D loss: 0.508068] [G loss: 0.551111]\n",
      "[Epoch 87/100] [Batch 100/347] [D loss: 0.504960] [G loss: 0.551796]\n",
      "[Epoch 87/100] [Batch 101/347] [D loss: 0.510625] [G loss: 0.549569]\n",
      "[Epoch 87/100] [Batch 102/347] [D loss: 0.541567] [G loss: 0.547695]\n",
      "[Epoch 87/100] [Batch 103/347] [D loss: 0.543177] [G loss: 0.551331]\n",
      "[Epoch 87/100] [Batch 104/347] [D loss: 0.528016] [G loss: 0.547844]\n",
      "[Epoch 87/100] [Batch 105/347] [D loss: 0.431719] [G loss: 0.543168]\n",
      "[Epoch 87/100] [Batch 106/347] [D loss: 0.175903] [G loss: 0.538795]\n",
      "[Epoch 87/100] [Batch 107/347] [D loss: 0.169493] [G loss: 0.543924]\n",
      "[Epoch 87/100] [Batch 108/347] [D loss: 0.171381] [G loss: 0.551080]\n",
      "[Epoch 87/100] [Batch 109/347] [D loss: 0.159628] [G loss: 0.561221]\n",
      "[Epoch 87/100] [Batch 110/347] [D loss: 0.194543] [G loss: 0.565327]\n",
      "[Epoch 87/100] [Batch 111/347] [D loss: 0.196963] [G loss: 0.574699]\n",
      "[Epoch 87/100] [Batch 112/347] [D loss: 0.194616] [G loss: 0.581254]\n",
      "[Epoch 87/100] [Batch 113/347] [D loss: 0.379908] [G loss: 0.599472]\n",
      "[Epoch 87/100] [Batch 114/347] [D loss: 0.448427] [G loss: 0.604962]\n",
      "[Epoch 87/100] [Batch 115/347] [D loss: 0.451755] [G loss: 0.583099]\n",
      "[Epoch 87/100] [Batch 116/347] [D loss: 0.388239] [G loss: 0.556977]\n",
      "[Epoch 87/100] [Batch 117/347] [D loss: 0.377162] [G loss: 0.533630]\n",
      "[Epoch 87/100] [Batch 118/347] [D loss: 0.305470] [G loss: 0.506272]\n",
      "[Epoch 87/100] [Batch 119/347] [D loss: 0.295506] [G loss: 0.484238]\n",
      "[Epoch 87/100] [Batch 120/347] [D loss: 0.285207] [G loss: 0.469277]\n",
      "[Epoch 87/100] [Batch 121/347] [D loss: 0.283304] [G loss: 0.452618]\n",
      "[Epoch 87/100] [Batch 122/347] [D loss: 0.402385] [G loss: 0.442055]\n",
      "[Epoch 87/100] [Batch 123/347] [D loss: 0.454083] [G loss: 0.435859]\n",
      "[Epoch 87/100] [Batch 124/347] [D loss: 0.386100] [G loss: 0.429028]\n",
      "[Epoch 87/100] [Batch 125/347] [D loss: 0.358923] [G loss: 0.431786]\n",
      "[Epoch 87/100] [Batch 126/347] [D loss: 0.323719] [G loss: 0.437824]\n",
      "[Epoch 87/100] [Batch 127/347] [D loss: 0.322609] [G loss: 0.444155]\n",
      "[Epoch 87/100] [Batch 128/347] [D loss: 0.307791] [G loss: 0.448511]\n",
      "[Epoch 87/100] [Batch 129/347] [D loss: 0.270509] [G loss: 0.460908]\n",
      "[Epoch 87/100] [Batch 130/347] [D loss: 0.223489] [G loss: 0.492525]\n",
      "[Epoch 87/100] [Batch 131/347] [D loss: 0.195878] [G loss: 0.519967]\n",
      "[Epoch 87/100] [Batch 132/347] [D loss: 0.172231] [G loss: 0.547730]\n",
      "[Epoch 87/100] [Batch 133/347] [D loss: 0.156369] [G loss: 0.569339]\n",
      "[Epoch 87/100] [Batch 134/347] [D loss: 0.144189] [G loss: 0.583882]\n",
      "[Epoch 87/100] [Batch 135/347] [D loss: 0.133540] [G loss: 0.593483]\n",
      "[Epoch 87/100] [Batch 136/347] [D loss: 0.130947] [G loss: 0.595039]\n",
      "[Epoch 87/100] [Batch 137/347] [D loss: 0.380984] [G loss: 0.591101]\n",
      "[Epoch 87/100] [Batch 138/347] [D loss: 0.423344] [G loss: 0.583791]\n",
      "[Epoch 87/100] [Batch 139/347] [D loss: 0.438719] [G loss: 0.572896]\n",
      "[Epoch 87/100] [Batch 140/347] [D loss: 0.453053] [G loss: 0.570778]\n",
      "[Epoch 87/100] [Batch 141/347] [D loss: 0.414811] [G loss: 0.563869]\n",
      "[Epoch 87/100] [Batch 142/347] [D loss: 0.414988] [G loss: 0.556568]\n",
      "[Epoch 87/100] [Batch 143/347] [D loss: 0.397010] [G loss: 0.545445]\n",
      "[Epoch 87/100] [Batch 144/347] [D loss: 0.365035] [G loss: 0.530795]\n",
      "[Epoch 87/100] [Batch 145/347] [D loss: 0.372528] [G loss: 0.518798]\n",
      "[Epoch 87/100] [Batch 146/347] [D loss: 0.364318] [G loss: 0.491076]\n",
      "[Epoch 87/100] [Batch 147/347] [D loss: 0.373529] [G loss: 0.452994]\n",
      "[Epoch 87/100] [Batch 148/347] [D loss: 0.389800] [G loss: 0.414318]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 87/100] [Batch 149/347] [D loss: 0.335951] [G loss: 0.378133]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 87/100] [Batch 150/347] [D loss: 0.329143] [G loss: 0.350966]\n",
      "[Epoch 87/100] [Batch 151/347] [D loss: 0.337367] [G loss: 0.332190]\n",
      "[Epoch 87/100] [Batch 152/347] [D loss: 0.343936] [G loss: 0.319234]\n",
      "[Epoch 87/100] [Batch 153/347] [D loss: 0.353821] [G loss: 0.312507]\n",
      "[Epoch 87/100] [Batch 154/347] [D loss: 0.351333] [G loss: 0.320480]\n",
      "[Epoch 87/100] [Batch 155/347] [D loss: 0.335860] [G loss: 0.345065]\n",
      "[Epoch 87/100] [Batch 156/347] [D loss: 0.314825] [G loss: 0.369441]\n",
      "[Epoch 87/100] [Batch 157/347] [D loss: 0.283656] [G loss: 0.402890]\n",
      "[Epoch 87/100] [Batch 158/347] [D loss: 0.241813] [G loss: 0.444768]\n",
      "[Epoch 87/100] [Batch 159/347] [D loss: 0.241521] [G loss: 0.479374]\n",
      "[Epoch 87/100] [Batch 160/347] [D loss: 0.221837] [G loss: 0.512304]\n",
      "[Epoch 87/100] [Batch 161/347] [D loss: 0.216315] [G loss: 0.532162]\n",
      "[Epoch 87/100] [Batch 162/347] [D loss: 0.227506] [G loss: 0.535947]\n",
      "[Epoch 87/100] [Batch 163/347] [D loss: 0.246888] [G loss: 0.530379]\n",
      "[Epoch 87/100] [Batch 164/347] [D loss: 0.255422] [G loss: 0.533241]\n",
      "[Epoch 87/100] [Batch 165/347] [D loss: 0.251487] [G loss: 0.539485]\n",
      "[Epoch 87/100] [Batch 166/347] [D loss: 0.241897] [G loss: 0.543986]\n",
      "[Epoch 87/100] [Batch 167/347] [D loss: 0.255197] [G loss: 0.554550]\n",
      "[Epoch 87/100] [Batch 168/347] [D loss: 0.244220] [G loss: 0.557321]\n",
      "[Epoch 87/100] [Batch 169/347] [D loss: 0.390410] [G loss: 0.555290]\n",
      "[Epoch 87/100] [Batch 170/347] [D loss: 0.462006] [G loss: 0.547900]\n",
      "[Epoch 87/100] [Batch 171/347] [D loss: 0.441071] [G loss: 0.528494]\n",
      "[Epoch 87/100] [Batch 172/347] [D loss: 0.423485] [G loss: 0.504562]\n",
      "[Epoch 87/100] [Batch 173/347] [D loss: 0.411595] [G loss: 0.474502]\n",
      "[Epoch 87/100] [Batch 174/347] [D loss: 0.395149] [G loss: 0.449858]\n",
      "[Epoch 87/100] [Batch 175/347] [D loss: 0.450560] [G loss: 0.425991]\n",
      "[Epoch 87/100] [Batch 176/347] [D loss: 0.489625] [G loss: 0.403950]\n",
      "[Epoch 87/100] [Batch 177/347] [D loss: 0.492439] [G loss: 0.380820]\n",
      "[Epoch 87/100] [Batch 178/347] [D loss: 0.482023] [G loss: 0.359515]\n",
      "[Epoch 87/100] [Batch 179/347] [D loss: 0.486944] [G loss: 0.347078]\n",
      "[Epoch 87/100] [Batch 180/347] [D loss: 0.488994] [G loss: 0.339048]\n",
      "[Epoch 87/100] [Batch 181/347] [D loss: 0.488266] [G loss: 0.341471]\n",
      "[Epoch 87/100] [Batch 182/347] [D loss: 0.491137] [G loss: 0.346119]\n",
      "[Epoch 87/100] [Batch 183/347] [D loss: 0.490643] [G loss: 0.356115]\n",
      "[Epoch 87/100] [Batch 184/347] [D loss: 0.517348] [G loss: 0.369372]\n",
      "[Epoch 87/100] [Batch 185/347] [D loss: 0.528412] [G loss: 0.380367]\n",
      "[Epoch 87/100] [Batch 186/347] [D loss: 0.501265] [G loss: 0.394271]\n",
      "[Epoch 87/100] [Batch 187/347] [D loss: 0.486725] [G loss: 0.405866]\n",
      "[Epoch 87/100] [Batch 188/347] [D loss: 0.445822] [G loss: 0.413921]\n",
      "[Epoch 87/100] [Batch 189/347] [D loss: 0.384980] [G loss: 0.423236]\n",
      "[Epoch 87/100] [Batch 190/347] [D loss: 0.373885] [G loss: 0.435678]\n",
      "[Epoch 87/100] [Batch 191/347] [D loss: 0.374847] [G loss: 0.447501]\n",
      "[Epoch 87/100] [Batch 192/347] [D loss: 0.387993] [G loss: 0.458450]\n",
      "[Epoch 87/100] [Batch 193/347] [D loss: 0.471617] [G loss: 0.467128]\n",
      "[Epoch 87/100] [Batch 194/347] [D loss: 0.462411] [G loss: 0.470306]\n",
      "[Epoch 87/100] [Batch 195/347] [D loss: 0.438367] [G loss: 0.470804]\n",
      "[Epoch 87/100] [Batch 196/347] [D loss: 0.385870] [G loss: 0.469205]\n",
      "[Epoch 87/100] [Batch 197/347] [D loss: 0.385974] [G loss: 0.466555]\n",
      "[Epoch 87/100] [Batch 198/347] [D loss: 0.379164] [G loss: 0.464611]\n",
      "[Epoch 87/100] [Batch 199/347] [D loss: 0.378115] [G loss: 0.458413]\n",
      "[Epoch 87/100] [Batch 200/347] [D loss: 0.444938] [G loss: 0.450989]\n",
      "[Epoch 87/100] [Batch 201/347] [D loss: 0.483091] [G loss: 0.443028]\n",
      "[Epoch 87/100] [Batch 202/347] [D loss: 0.491319] [G loss: 0.435137]\n",
      "[Epoch 87/100] [Batch 203/347] [D loss: 0.541964] [G loss: 0.427215]\n",
      "[Epoch 87/100] [Batch 204/347] [D loss: 0.524585] [G loss: 0.423863]\n",
      "[Epoch 87/100] [Batch 205/347] [D loss: 0.516709] [G loss: 0.423834]\n",
      "[Epoch 87/100] [Batch 206/347] [D loss: 0.508657] [G loss: 0.421535]\n",
      "[Epoch 87/100] [Batch 207/347] [D loss: 0.417032] [G loss: 0.419544]\n",
      "[Epoch 87/100] [Batch 208/347] [D loss: 0.398953] [G loss: 0.421616]\n",
      "[Epoch 87/100] [Batch 209/347] [D loss: 0.392177] [G loss: 0.417065]\n",
      "[Epoch 87/100] [Batch 210/347] [D loss: 0.312922] [G loss: 0.421887]\n",
      "[Epoch 87/100] [Batch 211/347] [D loss: 0.291673] [G loss: 0.427695]\n",
      "[Epoch 87/100] [Batch 212/347] [D loss: 0.229160] [G loss: 0.445544]\n",
      "[Epoch 87/100] [Batch 213/347] [D loss: 0.206990] [G loss: 0.478499]\n",
      "[Epoch 87/100] [Batch 214/347] [D loss: 0.181374] [G loss: 0.509226]\n",
      "[Epoch 87/100] [Batch 215/347] [D loss: 0.159775] [G loss: 0.536791]\n",
      "[Epoch 87/100] [Batch 216/347] [D loss: 0.300612] [G loss: 0.553836]\n",
      "[Epoch 87/100] [Batch 217/347] [D loss: 0.379048] [G loss: 0.578072]\n",
      "[Epoch 87/100] [Batch 218/347] [D loss: 0.445761] [G loss: 0.597611]\n",
      "[Epoch 87/100] [Batch 219/347] [D loss: 0.421402] [G loss: 0.605707]\n",
      "[Epoch 87/100] [Batch 220/347] [D loss: 0.410539] [G loss: 0.609723]\n",
      "[Epoch 87/100] [Batch 221/347] [D loss: 0.442656] [G loss: 0.606048]\n",
      "[Epoch 87/100] [Batch 222/347] [D loss: 0.443310] [G loss: 0.590313]\n",
      "[Epoch 87/100] [Batch 223/347] [D loss: 0.418846] [G loss: 0.560158]\n",
      "[Epoch 87/100] [Batch 224/347] [D loss: 0.424116] [G loss: 0.523894]\n",
      "[Epoch 87/100] [Batch 225/347] [D loss: 0.424095] [G loss: 0.480532]\n",
      "[Epoch 87/100] [Batch 226/347] [D loss: 0.429447] [G loss: 0.432321]\n",
      "[Epoch 87/100] [Batch 227/347] [D loss: 0.475386] [G loss: 0.397527]\n",
      "[Epoch 87/100] [Batch 228/347] [D loss: 0.497128] [G loss: 0.365781]\n",
      "[Epoch 87/100] [Batch 229/347] [D loss: 0.492820] [G loss: 0.341296]\n",
      "[Epoch 87/100] [Batch 230/347] [D loss: 0.512568] [G loss: 0.321904]\n",
      "[Epoch 87/100] [Batch 231/347] [D loss: 0.483862] [G loss: 0.302559]\n",
      "[Epoch 87/100] [Batch 232/347] [D loss: 0.469450] [G loss: 0.295314]\n",
      "[Epoch 87/100] [Batch 233/347] [D loss: 0.414941] [G loss: 0.303151]\n",
      "[Epoch 87/100] [Batch 234/347] [D loss: 0.377639] [G loss: 0.321585]\n",
      "[Epoch 87/100] [Batch 235/347] [D loss: 0.365153] [G loss: 0.353085]\n",
      "[Epoch 87/100] [Batch 236/347] [D loss: 0.337076] [G loss: 0.392889]\n",
      "[Epoch 87/100] [Batch 237/347] [D loss: 0.379794] [G loss: 0.431808]\n",
      "[Epoch 87/100] [Batch 238/347] [D loss: 0.444430] [G loss: 0.461039]\n",
      "[Epoch 87/100] [Batch 239/347] [D loss: 0.447743] [G loss: 0.481660]\n",
      "[Epoch 87/100] [Batch 240/347] [D loss: 0.455587] [G loss: 0.500032]\n",
      "[Epoch 87/100] [Batch 241/347] [D loss: 0.462098] [G loss: 0.513393]\n",
      "[Epoch 87/100] [Batch 242/347] [D loss: 0.491626] [G loss: 0.525662]\n",
      "[Epoch 87/100] [Batch 243/347] [D loss: 0.429285] [G loss: 0.532027]\n",
      "[Epoch 87/100] [Batch 244/347] [D loss: 0.392849] [G loss: 0.525171]\n",
      "[Epoch 87/100] [Batch 245/347] [D loss: 0.400657] [G loss: 0.511661]\n",
      "[Epoch 87/100] [Batch 246/347] [D loss: 0.404059] [G loss: 0.495843]\n",
      "[Epoch 87/100] [Batch 247/347] [D loss: 0.451129] [G loss: 0.476111]\n",
      "[Epoch 87/100] [Batch 248/347] [D loss: 0.475628] [G loss: 0.467214]\n",
      "[Epoch 87/100] [Batch 249/347] [D loss: 0.437037] [G loss: 0.461968]\n",
      "[Epoch 87/100] [Batch 250/347] [D loss: 0.414313] [G loss: 0.454876]\n",
      "[Epoch 87/100] [Batch 251/347] [D loss: 0.383853] [G loss: 0.445570]\n",
      "[Epoch 87/100] [Batch 252/347] [D loss: 0.372292] [G loss: 0.437384]\n",
      "[Epoch 87/100] [Batch 253/347] [D loss: 0.330453] [G loss: 0.422034]\n",
      "[Epoch 87/100] [Batch 254/347] [D loss: 0.326799] [G loss: 0.421932]\n",
      "[Epoch 87/100] [Batch 255/347] [D loss: 0.328893] [G loss: 0.423912]\n",
      "[Epoch 87/100] [Batch 256/347] [D loss: 0.327907] [G loss: 0.423954]\n",
      "[Epoch 87/100] [Batch 257/347] [D loss: 0.309429] [G loss: 0.427827]\n",
      "[Epoch 87/100] [Batch 258/347] [D loss: 0.271445] [G loss: 0.436843]\n",
      "[Epoch 87/100] [Batch 259/347] [D loss: 0.269787] [G loss: 0.446499]\n",
      "[Epoch 87/100] [Batch 260/347] [D loss: 0.265341] [G loss: 0.459156]\n",
      "[Epoch 87/100] [Batch 261/347] [D loss: 0.253017] [G loss: 0.478773]\n",
      "[Epoch 87/100] [Batch 262/347] [D loss: 0.218682] [G loss: 0.494331]\n",
      "[Epoch 87/100] [Batch 263/347] [D loss: 0.214574] [G loss: 0.508520]\n",
      "[Epoch 87/100] [Batch 264/347] [D loss: 0.211720] [G loss: 0.521521]\n",
      "[Epoch 87/100] [Batch 265/347] [D loss: 0.225188] [G loss: 0.528885]\n",
      "[Epoch 87/100] [Batch 266/347] [D loss: 0.297542] [G loss: 0.533566]\n",
      "[Epoch 87/100] [Batch 267/347] [D loss: 0.322945] [G loss: 0.534149]\n",
      "[Epoch 87/100] [Batch 268/347] [D loss: 0.324994] [G loss: 0.530371]\n",
      "[Epoch 87/100] [Batch 269/347] [D loss: 0.324931] [G loss: 0.522711]\n",
      "[Epoch 87/100] [Batch 270/347] [D loss: 0.347692] [G loss: 0.510994]\n",
      "[Epoch 87/100] [Batch 271/347] [D loss: 0.319553] [G loss: 0.502054]\n",
      "[Epoch 87/100] [Batch 272/347] [D loss: 0.435921] [G loss: 0.516708]\n",
      "[Epoch 87/100] [Batch 273/347] [D loss: 0.409699] [G loss: 0.537245]\n",
      "[Epoch 87/100] [Batch 274/347] [D loss: 0.375196] [G loss: 0.557074]\n",
      "[Epoch 87/100] [Batch 275/347] [D loss: 0.307508] [G loss: 0.571613]\n",
      "[Epoch 87/100] [Batch 276/347] [D loss: 0.401403] [G loss: 0.554584]\n",
      "[Epoch 87/100] [Batch 277/347] [D loss: 0.444788] [G loss: 0.565613]\n",
      "[Epoch 87/100] [Batch 278/347] [D loss: 0.459732] [G loss: 0.571793]\n",
      "[Epoch 87/100] [Batch 279/347] [D loss: 0.474422] [G loss: 0.570132]\n",
      "[Epoch 87/100] [Batch 280/347] [D loss: 0.479711] [G loss: 0.569953]\n",
      "[Epoch 87/100] [Batch 281/347] [D loss: 0.501549] [G loss: 0.568553]\n",
      "[Epoch 87/100] [Batch 282/347] [D loss: 0.496257] [G loss: 0.565532]\n",
      "[Epoch 87/100] [Batch 283/347] [D loss: 0.483442] [G loss: 0.561456]\n",
      "[Epoch 87/100] [Batch 284/347] [D loss: 0.466645] [G loss: 0.556331]\n",
      "[Epoch 87/100] [Batch 285/347] [D loss: 0.471243] [G loss: 0.546183]\n",
      "[Epoch 87/100] [Batch 286/347] [D loss: 0.434744] [G loss: 0.513668]\n",
      "[Epoch 87/100] [Batch 287/347] [D loss: 0.411648] [G loss: 0.482939]\n",
      "[Epoch 87/100] [Batch 288/347] [D loss: 0.387248] [G loss: 0.443086]\n",
      "[Epoch 87/100] [Batch 289/347] [D loss: 0.350796] [G loss: 0.400629]\n",
      "[Epoch 87/100] [Batch 290/347] [D loss: 0.342079] [G loss: 0.378048]\n",
      "[Epoch 87/100] [Batch 291/347] [D loss: 0.338823] [G loss: 0.357908]\n",
      "[Epoch 87/100] [Batch 292/347] [D loss: 0.338880] [G loss: 0.344668]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 87/100] [Batch 293/347] [D loss: 0.302353] [G loss: 0.348124]\n",
      "[Epoch 87/100] [Batch 294/347] [D loss: 0.301391] [G loss: 0.367168]\n",
      "[Epoch 87/100] [Batch 295/347] [D loss: 0.284511] [G loss: 0.392317]\n",
      "[Epoch 87/100] [Batch 296/347] [D loss: 0.257456] [G loss: 0.424975]\n",
      "[Epoch 87/100] [Batch 297/347] [D loss: 0.347252] [G loss: 0.462672]\n",
      "[Epoch 87/100] [Batch 298/347] [D loss: 0.340640] [G loss: 0.486388]\n",
      "[Epoch 87/100] [Batch 299/347] [D loss: 0.345331] [G loss: 0.503422]\n",
      "[Epoch 87/100] [Batch 300/347] [D loss: 0.349578] [G loss: 0.518071]\n",
      "[Epoch 87/100] [Batch 301/347] [D loss: 0.370718] [G loss: 0.513712]\n",
      "[Epoch 87/100] [Batch 302/347] [D loss: 0.389439] [G loss: 0.509424]\n",
      "[Epoch 87/100] [Batch 303/347] [D loss: 0.392455] [G loss: 0.497909]\n",
      "[Epoch 87/100] [Batch 304/347] [D loss: 0.263546] [G loss: 0.483453]\n",
      "[Epoch 87/100] [Batch 305/347] [D loss: 0.180783] [G loss: 0.475194]\n",
      "[Epoch 87/100] [Batch 306/347] [D loss: 0.180147] [G loss: 0.475680]\n",
      "[Epoch 87/100] [Batch 307/347] [D loss: 0.177412] [G loss: 0.483787]\n",
      "[Epoch 87/100] [Batch 308/347] [D loss: 0.240150] [G loss: 0.491564]\n",
      "[Epoch 87/100] [Batch 309/347] [D loss: 0.380245] [G loss: 0.504329]\n",
      "[Epoch 87/100] [Batch 310/347] [D loss: 0.515643] [G loss: 0.514332]\n",
      "[Epoch 87/100] [Batch 311/347] [D loss: 0.466057] [G loss: 0.507308]\n",
      "[Epoch 87/100] [Batch 312/347] [D loss: 0.360227] [G loss: 0.495303]\n",
      "[Epoch 87/100] [Batch 313/347] [D loss: 0.326667] [G loss: 0.480866]\n",
      "[Epoch 87/100] [Batch 314/347] [D loss: 0.320160] [G loss: 0.458657]\n",
      "[Epoch 87/100] [Batch 315/347] [D loss: 0.327086] [G loss: 0.438551]\n",
      "[Epoch 87/100] [Batch 316/347] [D loss: 0.355202] [G loss: 0.428833]\n",
      "[Epoch 87/100] [Batch 317/347] [D loss: 0.373124] [G loss: 0.422892]\n",
      "[Epoch 87/100] [Batch 318/347] [D loss: 0.372584] [G loss: 0.426994]\n",
      "[Epoch 87/100] [Batch 319/347] [D loss: 0.352274] [G loss: 0.432448]\n",
      "[Epoch 87/100] [Batch 320/347] [D loss: 0.355718] [G loss: 0.428382]\n",
      "[Epoch 87/100] [Batch 321/347] [D loss: 0.343432] [G loss: 0.422940]\n",
      "[Epoch 87/100] [Batch 322/347] [D loss: 0.350946] [G loss: 0.419927]\n",
      "[Epoch 87/100] [Batch 323/347] [D loss: 0.296012] [G loss: 0.421209]\n",
      "[Epoch 87/100] [Batch 324/347] [D loss: 0.291093] [G loss: 0.427064]\n",
      "[Epoch 87/100] [Batch 325/347] [D loss: 0.290881] [G loss: 0.431810]\n",
      "[Epoch 87/100] [Batch 326/347] [D loss: 0.293501] [G loss: 0.437326]\n",
      "[Epoch 87/100] [Batch 327/347] [D loss: 0.282317] [G loss: 0.446289]\n",
      "[Epoch 87/100] [Batch 328/347] [D loss: 0.286893] [G loss: 0.454371]\n",
      "[Epoch 87/100] [Batch 329/347] [D loss: 0.284632] [G loss: 0.463526]\n",
      "[Epoch 87/100] [Batch 330/347] [D loss: 0.280573] [G loss: 0.474177]\n",
      "[Epoch 87/100] [Batch 331/347] [D loss: 0.301861] [G loss: 0.488055]\n",
      "[Epoch 87/100] [Batch 332/347] [D loss: 0.391890] [G loss: 0.510200]\n",
      "[Epoch 87/100] [Batch 333/347] [D loss: 0.341330] [G loss: 0.508537]\n",
      "[Epoch 87/100] [Batch 334/347] [D loss: 0.332065] [G loss: 0.499395]\n",
      "[Epoch 87/100] [Batch 335/347] [D loss: 0.332390] [G loss: 0.493134]\n",
      "[Epoch 87/100] [Batch 336/347] [D loss: 0.330949] [G loss: 0.487656]\n",
      "[Epoch 87/100] [Batch 337/347] [D loss: 0.390881] [G loss: 0.482791]\n",
      "[Epoch 87/100] [Batch 338/347] [D loss: 0.435208] [G loss: 0.479048]\n",
      "[Epoch 87/100] [Batch 339/347] [D loss: 0.408503] [G loss: 0.465975]\n",
      "[Epoch 87/100] [Batch 340/347] [D loss: 0.375043] [G loss: 0.452111]\n",
      "[Epoch 87/100] [Batch 341/347] [D loss: 0.385956] [G loss: 0.443854]\n",
      "[Epoch 87/100] [Batch 342/347] [D loss: 0.272435] [G loss: 0.431041]\n",
      "[Epoch 87/100] [Batch 343/347] [D loss: 0.239183] [G loss: 0.421289]\n",
      "[Epoch 87/100] [Batch 344/347] [D loss: 0.236982] [G loss: 0.427476]\n",
      "[Epoch 87/100] [Batch 345/347] [D loss: 0.211613] [G loss: 0.450686]\n",
      "[Epoch 87/100] [Batch 346/347] [D loss: 0.192035] [G loss: 0.482129]\n",
      "[Epoch 87/100] [Batch 347/347] [D loss: 0.166686] [G loss: 0.512271]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 88/100] [Batch 1/347] [D loss: 0.396814] [G loss: 0.547824]\n",
      "[Epoch 88/100] [Batch 2/347] [D loss: 0.448671] [G loss: 0.558542]\n",
      "[Epoch 88/100] [Batch 3/347] [D loss: 0.509808] [G loss: 0.568465]\n",
      "[Epoch 88/100] [Batch 4/347] [D loss: 0.523841] [G loss: 0.571772]\n",
      "[Epoch 88/100] [Batch 5/347] [D loss: 0.531187] [G loss: 0.568943]\n",
      "[Epoch 88/100] [Batch 6/347] [D loss: 0.484339] [G loss: 0.564874]\n",
      "[Epoch 88/100] [Batch 7/347] [D loss: 0.442724] [G loss: 0.550664]\n",
      "[Epoch 88/100] [Batch 8/347] [D loss: 0.433712] [G loss: 0.540118]\n",
      "[Epoch 88/100] [Batch 9/347] [D loss: 0.414526] [G loss: 0.524734]\n",
      "[Epoch 88/100] [Batch 10/347] [D loss: 0.406599] [G loss: 0.501441]\n",
      "[Epoch 88/100] [Batch 11/347] [D loss: 0.461748] [G loss: 0.479874]\n",
      "[Epoch 88/100] [Batch 12/347] [D loss: 0.466493] [G loss: 0.448762]\n",
      "[Epoch 88/100] [Batch 13/347] [D loss: 0.418772] [G loss: 0.415527]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 88/100] [Batch 14/347] [D loss: 0.390464] [G loss: 0.388541]\n",
      "[Epoch 88/100] [Batch 15/347] [D loss: 0.391958] [G loss: 0.359009]\n",
      "[Epoch 88/100] [Batch 16/347] [D loss: 0.393340] [G loss: 0.339534]\n",
      "[Epoch 88/100] [Batch 17/347] [D loss: 0.406297] [G loss: 0.334119]\n",
      "[Epoch 88/100] [Batch 18/347] [D loss: 0.423957] [G loss: 0.332055]\n",
      "[Epoch 88/100] [Batch 19/347] [D loss: 0.422084] [G loss: 0.338698]\n",
      "[Epoch 88/100] [Batch 20/347] [D loss: 0.443327] [G loss: 0.350232]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 88/100] [Batch 21/347] [D loss: 0.378091] [G loss: 0.358715]\n",
      "[Epoch 88/100] [Batch 22/347] [D loss: 0.370801] [G loss: 0.374679]\n",
      "[Epoch 88/100] [Batch 23/347] [D loss: 0.368988] [G loss: 0.392143]\n",
      "[Epoch 88/100] [Batch 24/347] [D loss: 0.331196] [G loss: 0.407904]\n",
      "[Epoch 88/100] [Batch 25/347] [D loss: 0.235425] [G loss: 0.442595]\n",
      "[Epoch 88/100] [Batch 26/347] [D loss: 0.220158] [G loss: 0.473742]\n",
      "[Epoch 88/100] [Batch 27/347] [D loss: 0.208185] [G loss: 0.504857]\n",
      "[Epoch 88/100] [Batch 28/347] [D loss: 0.202859] [G loss: 0.530896]\n",
      "[Epoch 88/100] [Batch 29/347] [D loss: 0.229784] [G loss: 0.548930]\n",
      "[Epoch 88/100] [Batch 30/347] [D loss: 0.223117] [G loss: 0.558727]\n",
      "[Epoch 88/100] [Batch 31/347] [D loss: 0.230053] [G loss: 0.562046]\n",
      "[Epoch 88/100] [Batch 32/347] [D loss: 0.245560] [G loss: 0.558712]\n",
      "[Epoch 88/100] [Batch 33/347] [D loss: 0.266057] [G loss: 0.554292]\n",
      "[Epoch 88/100] [Batch 34/347] [D loss: 0.323843] [G loss: 0.543694]\n",
      "[Epoch 88/100] [Batch 35/347] [D loss: 0.325793] [G loss: 0.525749]\n",
      "[Epoch 88/100] [Batch 36/347] [D loss: 0.355223] [G loss: 0.502139]\n",
      "[Epoch 88/100] [Batch 37/347] [D loss: 0.356909] [G loss: 0.470403]\n",
      "[Epoch 88/100] [Batch 38/347] [D loss: 0.351368] [G loss: 0.432616]\n",
      "[Epoch 88/100] [Batch 39/347] [D loss: 0.356061] [G loss: 0.400029]\n",
      "[Epoch 88/100] [Batch 40/347] [D loss: 0.382279] [G loss: 0.376807]\n",
      "[Epoch 88/100] [Batch 41/347] [D loss: 0.403661] [G loss: 0.357345]\n",
      "[Epoch 88/100] [Batch 42/347] [D loss: 0.397197] [G loss: 0.350079]\n",
      "[Epoch 88/100] [Batch 43/347] [D loss: 0.422632] [G loss: 0.353781]\n",
      "[Epoch 88/100] [Batch 44/347] [D loss: 0.402127] [G loss: 0.355822]\n",
      "[Epoch 88/100] [Batch 45/347] [D loss: 0.380969] [G loss: 0.350809]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 88/100] [Batch 46/347] [D loss: 0.323521] [G loss: 0.355657]\n",
      "[Epoch 88/100] [Batch 47/347] [D loss: 0.316137] [G loss: 0.369718]\n",
      "[Epoch 88/100] [Batch 48/347] [D loss: 0.260125] [G loss: 0.401767]\n",
      "[Epoch 88/100] [Batch 49/347] [D loss: 0.225776] [G loss: 0.449549]\n",
      "[Epoch 88/100] [Batch 50/347] [D loss: 0.195660] [G loss: 0.497073]\n",
      "[Epoch 88/100] [Batch 51/347] [D loss: 0.163165] [G loss: 0.533884]\n",
      "[Epoch 88/100] [Batch 52/347] [D loss: 0.267174] [G loss: 0.547300]\n",
      "[Epoch 88/100] [Batch 53/347] [D loss: 0.336870] [G loss: 0.543616]\n",
      "[Epoch 88/100] [Batch 54/347] [D loss: 0.337406] [G loss: 0.535480]\n",
      "[Epoch 88/100] [Batch 55/347] [D loss: 0.334730] [G loss: 0.538726]\n",
      "[Epoch 88/100] [Batch 56/347] [D loss: 0.311248] [G loss: 0.545937]\n",
      "[Epoch 88/100] [Batch 57/347] [D loss: 0.235414] [G loss: 0.551746]\n",
      "[Epoch 88/100] [Batch 58/347] [D loss: 0.231389] [G loss: 0.550668]\n",
      "[Epoch 88/100] [Batch 59/347] [D loss: 0.223805] [G loss: 0.536865]\n",
      "[Epoch 88/100] [Batch 60/347] [D loss: 0.216602] [G loss: 0.511148]\n",
      "[Epoch 88/100] [Batch 61/347] [D loss: 0.233671] [G loss: 0.481885]\n",
      "[Epoch 88/100] [Batch 62/347] [D loss: 0.227807] [G loss: 0.465946]\n",
      "[Epoch 88/100] [Batch 63/347] [D loss: 0.219101] [G loss: 0.451364]\n",
      "[Epoch 88/100] [Batch 64/347] [D loss: 0.212502] [G loss: 0.436536]\n",
      "[Epoch 88/100] [Batch 65/347] [D loss: 0.193747] [G loss: 0.440082]\n",
      "[Epoch 88/100] [Batch 66/347] [D loss: 0.194457] [G loss: 0.446366]\n",
      "[Epoch 88/100] [Batch 67/347] [D loss: 0.188186] [G loss: 0.449907]\n",
      "[Epoch 88/100] [Batch 68/347] [D loss: 0.179069] [G loss: 0.462433]\n",
      "[Epoch 88/100] [Batch 69/347] [D loss: 0.187915] [G loss: 0.474442]\n",
      "[Epoch 88/100] [Batch 70/347] [D loss: 0.183780] [G loss: 0.481703]\n",
      "[Epoch 88/100] [Batch 71/347] [D loss: 0.177236] [G loss: 0.503051]\n",
      "[Epoch 88/100] [Batch 72/347] [D loss: 0.182736] [G loss: 0.521201]\n",
      "[Epoch 88/100] [Batch 73/347] [D loss: 0.315131] [G loss: 0.520217]\n",
      "[Epoch 88/100] [Batch 74/347] [D loss: 0.315858] [G loss: 0.521743]\n",
      "[Epoch 88/100] [Batch 75/347] [D loss: 0.311854] [G loss: 0.518411]\n",
      "[Epoch 88/100] [Batch 76/347] [D loss: 0.303360] [G loss: 0.508936]\n",
      "[Epoch 88/100] [Batch 77/347] [D loss: 0.328562] [G loss: 0.495468]\n",
      "[Epoch 88/100] [Batch 78/347] [D loss: 0.356328] [G loss: 0.490153]\n",
      "[Epoch 88/100] [Batch 79/347] [D loss: 0.341662] [G loss: 0.470754]\n",
      "[Epoch 88/100] [Batch 80/347] [D loss: 0.240876] [G loss: 0.443141]\n",
      "[Epoch 88/100] [Batch 81/347] [D loss: 0.228540] [G loss: 0.432327]\n",
      "[Epoch 88/100] [Batch 82/347] [D loss: 0.228082] [G loss: 0.431304]\n",
      "[Epoch 88/100] [Batch 83/347] [D loss: 0.235613] [G loss: 0.430335]\n",
      "[Epoch 88/100] [Batch 84/347] [D loss: 0.364212] [G loss: 0.432987]\n",
      "[Epoch 88/100] [Batch 85/347] [D loss: 0.447309] [G loss: 0.430541]\n",
      "[Epoch 88/100] [Batch 86/347] [D loss: 0.448771] [G loss: 0.426320]\n",
      "[Epoch 88/100] [Batch 87/347] [D loss: 0.448360] [G loss: 0.422417]\n",
      "[Epoch 88/100] [Batch 88/347] [D loss: 0.472198] [G loss: 0.417663]\n",
      "[Epoch 88/100] [Batch 89/347] [D loss: 0.479838] [G loss: 0.413843]\n",
      "[Epoch 88/100] [Batch 90/347] [D loss: 0.475115] [G loss: 0.405333]\n",
      "[Epoch 88/100] [Batch 91/347] [D loss: 0.478386] [G loss: 0.396482]\n",
      "[Epoch 88/100] [Batch 92/347] [D loss: 0.484008] [G loss: 0.389347]\n",
      "[Epoch 88/100] [Batch 93/347] [D loss: 0.483621] [G loss: 0.382716]\n",
      "[Epoch 88/100] [Batch 94/347] [D loss: 0.461249] [G loss: 0.374175]\n",
      "[Epoch 88/100] [Batch 95/347] [D loss: 0.444164] [G loss: 0.371194]\n",
      "[Epoch 88/100] [Batch 96/347] [D loss: 0.442223] [G loss: 0.372457]\n",
      "[Epoch 88/100] [Batch 97/347] [D loss: 0.431891] [G loss: 0.375087]\n",
      "[Epoch 88/100] [Batch 98/347] [D loss: 0.406489] [G loss: 0.381528]\n",
      "[Epoch 88/100] [Batch 99/347] [D loss: 0.402923] [G loss: 0.390135]\n",
      "[Epoch 88/100] [Batch 100/347] [D loss: 0.401706] [G loss: 0.401922]\n",
      "[Epoch 88/100] [Batch 101/347] [D loss: 0.408174] [G loss: 0.410284]\n",
      "[Epoch 88/100] [Batch 102/347] [D loss: 0.488908] [G loss: 0.416500]\n",
      "[Epoch 88/100] [Batch 103/347] [D loss: 0.493845] [G loss: 0.425611]\n",
      "[Epoch 88/100] [Batch 104/347] [D loss: 0.458513] [G loss: 0.427215]\n",
      "[Epoch 88/100] [Batch 105/347] [D loss: 0.374862] [G loss: 0.428713]\n",
      "[Epoch 88/100] [Batch 106/347] [D loss: 0.252177] [G loss: 0.447380]\n",
      "[Epoch 88/100] [Batch 107/347] [D loss: 0.217424] [G loss: 0.487910]\n",
      "[Epoch 88/100] [Batch 108/347] [D loss: 0.188130] [G loss: 0.526144]\n",
      "[Epoch 88/100] [Batch 109/347] [D loss: 0.149874] [G loss: 0.557040]\n",
      "[Epoch 88/100] [Batch 110/347] [D loss: 0.139717] [G loss: 0.561582]\n",
      "[Epoch 88/100] [Batch 111/347] [D loss: 0.141211] [G loss: 0.577859]\n",
      "[Epoch 88/100] [Batch 112/347] [D loss: 0.146085] [G loss: 0.587260]\n",
      "[Epoch 88/100] [Batch 113/347] [D loss: 0.374842] [G loss: 0.608538]\n",
      "[Epoch 88/100] [Batch 114/347] [D loss: 0.472308] [G loss: 0.616294]\n",
      "[Epoch 88/100] [Batch 115/347] [D loss: 0.487538] [G loss: 0.598682]\n",
      "[Epoch 88/100] [Batch 116/347] [D loss: 0.414263] [G loss: 0.580020]\n",
      "[Epoch 88/100] [Batch 117/347] [D loss: 0.404482] [G loss: 0.565543]\n",
      "[Epoch 88/100] [Batch 118/347] [D loss: 0.301934] [G loss: 0.553992]\n",
      "[Epoch 88/100] [Batch 119/347] [D loss: 0.269015] [G loss: 0.541110]\n",
      "[Epoch 88/100] [Batch 120/347] [D loss: 0.227833] [G loss: 0.527546]\n",
      "[Epoch 88/100] [Batch 121/347] [D loss: 0.203865] [G loss: 0.497530]\n",
      "[Epoch 88/100] [Batch 122/347] [D loss: 0.323250] [G loss: 0.461291]\n",
      "[Epoch 88/100] [Batch 123/347] [D loss: 0.365534] [G loss: 0.425633]\n",
      "[Epoch 88/100] [Batch 124/347] [D loss: 0.301555] [G loss: 0.393029]\n",
      "[Epoch 88/100] [Batch 125/347] [D loss: 0.290087] [G loss: 0.376056]\n",
      "[Epoch 88/100] [Batch 126/347] [D loss: 0.277988] [G loss: 0.371876]\n",
      "[Epoch 88/100] [Batch 127/347] [D loss: 0.283949] [G loss: 0.373840]\n",
      "[Epoch 88/100] [Batch 128/347] [D loss: 0.279686] [G loss: 0.378517]\n",
      "[Epoch 88/100] [Batch 129/347] [D loss: 0.286109] [G loss: 0.403487]\n",
      "[Epoch 88/100] [Batch 130/347] [D loss: 0.273049] [G loss: 0.451968]\n",
      "[Epoch 88/100] [Batch 131/347] [D loss: 0.221933] [G loss: 0.501976]\n",
      "[Epoch 88/100] [Batch 132/347] [D loss: 0.168539] [G loss: 0.541178]\n",
      "[Epoch 88/100] [Batch 133/347] [D loss: 0.154760] [G loss: 0.563407]\n",
      "[Epoch 88/100] [Batch 134/347] [D loss: 0.134983] [G loss: 0.573297]\n",
      "[Epoch 88/100] [Batch 135/347] [D loss: 0.117975] [G loss: 0.578948]\n",
      "[Epoch 88/100] [Batch 136/347] [D loss: 0.110881] [G loss: 0.577041]\n",
      "[Epoch 88/100] [Batch 137/347] [D loss: 0.361267] [G loss: 0.570796]\n",
      "[Epoch 88/100] [Batch 138/347] [D loss: 0.419147] [G loss: 0.562052]\n",
      "[Epoch 88/100] [Batch 139/347] [D loss: 0.446595] [G loss: 0.550570]\n",
      "[Epoch 88/100] [Batch 140/347] [D loss: 0.468129] [G loss: 0.548695]\n",
      "[Epoch 88/100] [Batch 141/347] [D loss: 0.426436] [G loss: 0.542802]\n",
      "[Epoch 88/100] [Batch 142/347] [D loss: 0.431707] [G loss: 0.537826]\n",
      "[Epoch 88/100] [Batch 143/347] [D loss: 0.410479] [G loss: 0.530567]\n",
      "[Epoch 88/100] [Batch 144/347] [D loss: 0.370676] [G loss: 0.522199]\n",
      "[Epoch 88/100] [Batch 145/347] [D loss: 0.374395] [G loss: 0.521807]\n",
      "[Epoch 88/100] [Batch 146/347] [D loss: 0.353113] [G loss: 0.511782]\n",
      "[Epoch 88/100] [Batch 147/347] [D loss: 0.342153] [G loss: 0.489378]\n",
      "[Epoch 88/100] [Batch 148/347] [D loss: 0.331574] [G loss: 0.448008]\n",
      "[Epoch 88/100] [Batch 149/347] [D loss: 0.255359] [G loss: 0.394293]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 88/100] [Batch 150/347] [D loss: 0.245674] [G loss: 0.348589]\n",
      "[Epoch 88/100] [Batch 151/347] [D loss: 0.261023] [G loss: 0.311982]\n",
      "[Epoch 88/100] [Batch 152/347] [D loss: 0.281507] [G loss: 0.286809]\n",
      "[Epoch 88/100] [Batch 153/347] [D loss: 0.302202] [G loss: 0.270904]\n",
      "[Epoch 88/100] [Batch 154/347] [D loss: 0.312474] [G loss: 0.272726]\n",
      "[Epoch 88/100] [Batch 155/347] [D loss: 0.306952] [G loss: 0.292202]\n",
      "[Epoch 88/100] [Batch 156/347] [D loss: 0.291122] [G loss: 0.317176]\n",
      "[Epoch 88/100] [Batch 157/347] [D loss: 0.260181] [G loss: 0.357964]\n",
      "[Epoch 88/100] [Batch 158/347] [D loss: 0.228910] [G loss: 0.408160]\n",
      "[Epoch 88/100] [Batch 159/347] [D loss: 0.206654] [G loss: 0.454723]\n",
      "[Epoch 88/100] [Batch 160/347] [D loss: 0.174238] [G loss: 0.494399]\n",
      "[Epoch 88/100] [Batch 161/347] [D loss: 0.162326] [G loss: 0.516265]\n",
      "[Epoch 88/100] [Batch 162/347] [D loss: 0.166190] [G loss: 0.519693]\n",
      "[Epoch 88/100] [Batch 163/347] [D loss: 0.185305] [G loss: 0.514850]\n",
      "[Epoch 88/100] [Batch 164/347] [D loss: 0.198035] [G loss: 0.518705]\n",
      "[Epoch 88/100] [Batch 165/347] [D loss: 0.199490] [G loss: 0.526987]\n",
      "[Epoch 88/100] [Batch 166/347] [D loss: 0.194806] [G loss: 0.534703]\n",
      "[Epoch 88/100] [Batch 167/347] [D loss: 0.213341] [G loss: 0.548697]\n",
      "[Epoch 88/100] [Batch 168/347] [D loss: 0.205842] [G loss: 0.555392]\n",
      "[Epoch 88/100] [Batch 169/347] [D loss: 0.374658] [G loss: 0.558478]\n",
      "[Epoch 88/100] [Batch 170/347] [D loss: 0.453110] [G loss: 0.556159]\n",
      "[Epoch 88/100] [Batch 171/347] [D loss: 0.418476] [G loss: 0.543477]\n",
      "[Epoch 88/100] [Batch 172/347] [D loss: 0.386160] [G loss: 0.525658]\n",
      "[Epoch 88/100] [Batch 173/347] [D loss: 0.352855] [G loss: 0.498771]\n",
      "[Epoch 88/100] [Batch 174/347] [D loss: 0.314904] [G loss: 0.468108]\n",
      "[Epoch 88/100] [Batch 175/347] [D loss: 0.360289] [G loss: 0.426685]\n",
      "[Epoch 88/100] [Batch 176/347] [D loss: 0.388509] [G loss: 0.384303]\n",
      "[Epoch 88/100] [Batch 177/347] [D loss: 0.388583] [G loss: 0.340655]\n",
      "[Epoch 88/100] [Batch 178/347] [D loss: 0.381405] [G loss: 0.304790]\n",
      "[Epoch 88/100] [Batch 179/347] [D loss: 0.394250] [G loss: 0.281954]\n",
      "[Epoch 88/100] [Batch 180/347] [D loss: 0.404399] [G loss: 0.268094]\n",
      "[Epoch 88/100] [Batch 181/347] [D loss: 0.409882] [G loss: 0.268005]\n",
      "[Epoch 88/100] [Batch 182/347] [D loss: 0.414509] [G loss: 0.273235]\n",
      "[Epoch 88/100] [Batch 183/347] [D loss: 0.412213] [G loss: 0.285353]\n",
      "[Epoch 88/100] [Batch 184/347] [D loss: 0.429563] [G loss: 0.304251]\n",
      "[Epoch 88/100] [Batch 185/347] [D loss: 0.434990] [G loss: 0.321391]\n",
      "[Epoch 88/100] [Batch 186/347] [D loss: 0.404700] [G loss: 0.344525]\n",
      "[Epoch 88/100] [Batch 187/347] [D loss: 0.386385] [G loss: 0.366268]\n",
      "[Epoch 88/100] [Batch 188/347] [D loss: 0.347940] [G loss: 0.384211]\n",
      "[Epoch 88/100] [Batch 189/347] [D loss: 0.291766] [G loss: 0.405654]\n",
      "[Epoch 88/100] [Batch 190/347] [D loss: 0.278114] [G loss: 0.428540]\n",
      "[Epoch 88/100] [Batch 191/347] [D loss: 0.277622] [G loss: 0.448269]\n",
      "[Epoch 88/100] [Batch 192/347] [D loss: 0.292947] [G loss: 0.464042]\n",
      "[Epoch 88/100] [Batch 193/347] [D loss: 0.389889] [G loss: 0.474289]\n",
      "[Epoch 88/100] [Batch 194/347] [D loss: 0.375843] [G loss: 0.474675]\n",
      "[Epoch 88/100] [Batch 195/347] [D loss: 0.351031] [G loss: 0.471305]\n",
      "[Epoch 88/100] [Batch 196/347] [D loss: 0.292052] [G loss: 0.464569]\n",
      "[Epoch 88/100] [Batch 197/347] [D loss: 0.290404] [G loss: 0.456664]\n",
      "[Epoch 88/100] [Batch 198/347] [D loss: 0.281582] [G loss: 0.450063]\n",
      "[Epoch 88/100] [Batch 199/347] [D loss: 0.279938] [G loss: 0.439448]\n",
      "[Epoch 88/100] [Batch 200/347] [D loss: 0.352803] [G loss: 0.426451]\n",
      "[Epoch 88/100] [Batch 201/347] [D loss: 0.388163] [G loss: 0.409790]\n",
      "[Epoch 88/100] [Batch 202/347] [D loss: 0.403734] [G loss: 0.393911]\n",
      "[Epoch 88/100] [Batch 203/347] [D loss: 0.454550] [G loss: 0.375371]\n",
      "[Epoch 88/100] [Batch 204/347] [D loss: 0.429870] [G loss: 0.361368]\n",
      "[Epoch 88/100] [Batch 205/347] [D loss: 0.417838] [G loss: 0.350068]\n",
      "[Epoch 88/100] [Batch 206/347] [D loss: 0.412415] [G loss: 0.341075]\n",
      "[Epoch 88/100] [Batch 207/347] [D loss: 0.333294] [G loss: 0.337682]\n",
      "[Epoch 88/100] [Batch 208/347] [D loss: 0.321499] [G loss: 0.343055]\n",
      "[Epoch 88/100] [Batch 209/347] [D loss: 0.316998] [G loss: 0.347081]\n",
      "[Epoch 88/100] [Batch 210/347] [D loss: 0.262196] [G loss: 0.365191]\n",
      "[Epoch 88/100] [Batch 211/347] [D loss: 0.258311] [G loss: 0.386816]\n",
      "[Epoch 88/100] [Batch 212/347] [D loss: 0.246260] [G loss: 0.426925]\n",
      "[Epoch 88/100] [Batch 213/347] [D loss: 0.198303] [G loss: 0.476093]\n",
      "[Epoch 88/100] [Batch 214/347] [D loss: 0.154583] [G loss: 0.513412]\n",
      "[Epoch 88/100] [Batch 215/347] [D loss: 0.123137] [G loss: 0.544157]\n",
      "[Epoch 88/100] [Batch 216/347] [D loss: 0.231273] [G loss: 0.562947]\n",
      "[Epoch 88/100] [Batch 217/347] [D loss: 0.331177] [G loss: 0.593607]\n",
      "[Epoch 88/100] [Batch 218/347] [D loss: 0.415189] [G loss: 0.621526]\n",
      "[Epoch 88/100] [Batch 219/347] [D loss: 0.383414] [G loss: 0.637708]\n",
      "[Epoch 88/100] [Batch 220/347] [D loss: 0.365403] [G loss: 0.652300]\n",
      "[Epoch 88/100] [Batch 221/347] [D loss: 0.410407] [G loss: 0.651727]\n",
      "[Epoch 88/100] [Batch 222/347] [D loss: 0.412633] [G loss: 0.636680]\n",
      "[Epoch 88/100] [Batch 223/347] [D loss: 0.382907] [G loss: 0.603999]\n",
      "[Epoch 88/100] [Batch 224/347] [D loss: 0.388767] [G loss: 0.564898]\n",
      "[Epoch 88/100] [Batch 225/347] [D loss: 0.386690] [G loss: 0.518938]\n",
      "[Epoch 88/100] [Batch 226/347] [D loss: 0.381198] [G loss: 0.471921]\n",
      "[Epoch 88/100] [Batch 227/347] [D loss: 0.417193] [G loss: 0.426004]\n",
      "[Epoch 88/100] [Batch 228/347] [D loss: 0.420032] [G loss: 0.373590]\n",
      "[Epoch 88/100] [Batch 229/347] [D loss: 0.400232] [G loss: 0.327831]\n",
      "[Epoch 88/100] [Batch 230/347] [D loss: 0.420570] [G loss: 0.289339]\n",
      "[Epoch 88/100] [Batch 231/347] [D loss: 0.397451] [G loss: 0.256906]\n",
      "[Epoch 88/100] [Batch 232/347] [D loss: 0.395173] [G loss: 0.239255]\n",
      "[Epoch 88/100] [Batch 233/347] [D loss: 0.375247] [G loss: 0.240999]\n",
      "[Epoch 88/100] [Batch 234/347] [D loss: 0.359423] [G loss: 0.257604]\n",
      "[Epoch 88/100] [Batch 235/347] [D loss: 0.348858] [G loss: 0.289804]\n",
      "[Epoch 88/100] [Batch 236/347] [D loss: 0.315640] [G loss: 0.333014]\n",
      "[Epoch 88/100] [Batch 237/347] [D loss: 0.329073] [G loss: 0.380724]\n",
      "[Epoch 88/100] [Batch 238/347] [D loss: 0.359913] [G loss: 0.422624]\n",
      "[Epoch 88/100] [Batch 239/347] [D loss: 0.356615] [G loss: 0.455775]\n",
      "[Epoch 88/100] [Batch 240/347] [D loss: 0.368227] [G loss: 0.485081]\n",
      "[Epoch 88/100] [Batch 241/347] [D loss: 0.375248] [G loss: 0.506887]\n",
      "[Epoch 88/100] [Batch 242/347] [D loss: 0.427686] [G loss: 0.522580]\n",
      "[Epoch 88/100] [Batch 243/347] [D loss: 0.354341] [G loss: 0.528974]\n",
      "[Epoch 88/100] [Batch 244/347] [D loss: 0.312885] [G loss: 0.521453]\n",
      "[Epoch 88/100] [Batch 245/347] [D loss: 0.315512] [G loss: 0.506667]\n",
      "[Epoch 88/100] [Batch 246/347] [D loss: 0.323796] [G loss: 0.488253]\n",
      "[Epoch 88/100] [Batch 247/347] [D loss: 0.374311] [G loss: 0.463655]\n",
      "[Epoch 88/100] [Batch 248/347] [D loss: 0.394629] [G loss: 0.444459]\n",
      "[Epoch 88/100] [Batch 249/347] [D loss: 0.347262] [G loss: 0.432200]\n",
      "[Epoch 88/100] [Batch 250/347] [D loss: 0.325750] [G loss: 0.419377]\n",
      "[Epoch 88/100] [Batch 251/347] [D loss: 0.300544] [G loss: 0.407598]\n",
      "[Epoch 88/100] [Batch 252/347] [D loss: 0.294917] [G loss: 0.402499]\n",
      "[Epoch 88/100] [Batch 253/347] [D loss: 0.266193] [G loss: 0.392969]\n",
      "[Epoch 88/100] [Batch 254/347] [D loss: 0.262300] [G loss: 0.402314]\n",
      "[Epoch 88/100] [Batch 255/347] [D loss: 0.260579] [G loss: 0.414126]\n",
      "[Epoch 88/100] [Batch 256/347] [D loss: 0.256117] [G loss: 0.427121]\n",
      "[Epoch 88/100] [Batch 257/347] [D loss: 0.237348] [G loss: 0.440193]\n",
      "[Epoch 88/100] [Batch 258/347] [D loss: 0.200948] [G loss: 0.458754]\n",
      "[Epoch 88/100] [Batch 259/347] [D loss: 0.195402] [G loss: 0.480215]\n",
      "[Epoch 88/100] [Batch 260/347] [D loss: 0.189003] [G loss: 0.500926]\n",
      "[Epoch 88/100] [Batch 261/347] [D loss: 0.177442] [G loss: 0.527543]\n",
      "[Epoch 88/100] [Batch 262/347] [D loss: 0.149073] [G loss: 0.544935]\n",
      "[Epoch 88/100] [Batch 263/347] [D loss: 0.147325] [G loss: 0.562935]\n",
      "[Epoch 88/100] [Batch 264/347] [D loss: 0.145916] [G loss: 0.591766]\n",
      "[Epoch 88/100] [Batch 265/347] [D loss: 0.155813] [G loss: 0.614333]\n",
      "[Epoch 88/100] [Batch 266/347] [D loss: 0.230661] [G loss: 0.626296]\n",
      "[Epoch 88/100] [Batch 267/347] [D loss: 0.257703] [G loss: 0.630057]\n",
      "[Epoch 88/100] [Batch 268/347] [D loss: 0.262366] [G loss: 0.627066]\n",
      "[Epoch 88/100] [Batch 269/347] [D loss: 0.262616] [G loss: 0.616643]\n",
      "[Epoch 88/100] [Batch 270/347] [D loss: 0.290466] [G loss: 0.592928]\n",
      "[Epoch 88/100] [Batch 271/347] [D loss: 0.274777] [G loss: 0.576422]\n",
      "[Epoch 88/100] [Batch 272/347] [D loss: 0.464518] [G loss: 0.604851]\n",
      "[Epoch 88/100] [Batch 273/347] [D loss: 0.429868] [G loss: 0.653672]\n",
      "[Epoch 88/100] [Batch 274/347] [D loss: 0.382728] [G loss: 0.733902]\n",
      "[Epoch 88/100] [Batch 275/347] [D loss: 0.288255] [G loss: 0.815684]\n",
      "[Epoch 88/100] [Batch 276/347] [D loss: 0.374424] [G loss: 0.733205]\n",
      "[Epoch 88/100] [Batch 277/347] [D loss: 0.428148] [G loss: 0.750787]\n",
      "[Epoch 88/100] [Batch 278/347] [D loss: 0.457872] [G loss: 0.788298]\n",
      "[Epoch 88/100] [Batch 279/347] [D loss: 0.479086] [G loss: 0.779559]\n",
      "[Epoch 88/100] [Batch 280/347] [D loss: 0.490440] [G loss: 0.848144]\n",
      "[Epoch 88/100] [Batch 281/347] [D loss: 0.516997] [G loss: 0.860727]\n",
      "[Epoch 88/100] [Batch 282/347] [D loss: 0.478273] [G loss: 0.850179]\n",
      "[Epoch 88/100] [Batch 283/347] [D loss: 0.431239] [G loss: 0.805587]\n",
      "[Epoch 88/100] [Batch 284/347] [D loss: 0.380559] [G loss: 0.703539]\n",
      "[Epoch 88/100] [Batch 285/347] [D loss: 0.395552] [G loss: 0.617881]\n",
      "[Epoch 88/100] [Batch 286/347] [D loss: 0.350343] [G loss: 0.522353]\n",
      "[Epoch 88/100] [Batch 287/347] [D loss: 0.335322] [G loss: 0.460395]\n",
      "[Epoch 88/100] [Batch 288/347] [D loss: 0.324870] [G loss: 0.406803]\n",
      "[Epoch 88/100] [Batch 289/347] [D loss: 0.305079] [G loss: 0.361225]\n",
      "[Epoch 88/100] [Batch 290/347] [D loss: 0.317527] [G loss: 0.338433]\n",
      "[Epoch 88/100] [Batch 291/347] [D loss: 0.327402] [G loss: 0.326386]\n",
      "[Epoch 88/100] [Batch 292/347] [D loss: 0.333414] [G loss: 0.323534]\n",
      "[Epoch 88/100] [Batch 293/347] [D loss: 0.325816] [G loss: 0.338264]\n",
      "[Epoch 88/100] [Batch 294/347] [D loss: 0.309107] [G loss: 0.369668]\n",
      "[Epoch 88/100] [Batch 295/347] [D loss: 0.277485] [G loss: 0.406172]\n",
      "[Epoch 88/100] [Batch 296/347] [D loss: 0.239442] [G loss: 0.452211]\n",
      "[Epoch 88/100] [Batch 297/347] [D loss: 0.325174] [G loss: 0.494791]\n",
      "[Epoch 88/100] [Batch 298/347] [D loss: 0.314781] [G loss: 0.531477]\n",
      "[Epoch 88/100] [Batch 299/347] [D loss: 0.321924] [G loss: 0.571221]\n",
      "[Epoch 88/100] [Batch 300/347] [D loss: 0.328246] [G loss: 0.619953]\n",
      "[Epoch 88/100] [Batch 301/347] [D loss: 0.346690] [G loss: 0.654471]\n",
      "[Epoch 88/100] [Batch 302/347] [D loss: 0.369655] [G loss: 0.677954]\n",
      "[Epoch 88/100] [Batch 303/347] [D loss: 0.380490] [G loss: 0.673661]\n",
      "[Epoch 88/100] [Batch 304/347] [D loss: 0.227527] [G loss: 0.662615]\n",
      "[Epoch 88/100] [Batch 305/347] [D loss: 0.126687] [G loss: 0.658608]\n",
      "[Epoch 88/100] [Batch 306/347] [D loss: 0.125889] [G loss: 0.660380]\n",
      "[Epoch 88/100] [Batch 307/347] [D loss: 0.121369] [G loss: 0.672890]\n",
      "[Epoch 88/100] [Batch 308/347] [D loss: 0.207150] [G loss: 0.681738]\n",
      "[Epoch 88/100] [Batch 309/347] [D loss: 0.400285] [G loss: 0.675762]\n",
      "[Epoch 88/100] [Batch 310/347] [D loss: 0.637797] [G loss: 0.647025]\n",
      "[Epoch 88/100] [Batch 311/347] [D loss: 0.536567] [G loss: 0.594961]\n",
      "[Epoch 88/100] [Batch 312/347] [D loss: 0.366374] [G loss: 0.544969]\n",
      "[Epoch 88/100] [Batch 313/347] [D loss: 0.313357] [G loss: 0.523867]\n",
      "[Epoch 88/100] [Batch 314/347] [D loss: 0.302637] [G loss: 0.487988]\n",
      "[Epoch 88/100] [Batch 315/347] [D loss: 0.311775] [G loss: 0.452612]\n",
      "[Epoch 88/100] [Batch 316/347] [D loss: 0.350983] [G loss: 0.427681]\n",
      "[Epoch 88/100] [Batch 317/347] [D loss: 0.375835] [G loss: 0.411792]\n",
      "[Epoch 88/100] [Batch 318/347] [D loss: 0.380447] [G loss: 0.412099]\n",
      "[Epoch 88/100] [Batch 319/347] [D loss: 0.366819] [G loss: 0.418060]\n",
      "[Epoch 88/100] [Batch 320/347] [D loss: 0.375128] [G loss: 0.418822]\n",
      "[Epoch 88/100] [Batch 321/347] [D loss: 0.362516] [G loss: 0.421344]\n",
      "[Epoch 88/100] [Batch 322/347] [D loss: 0.366755] [G loss: 0.429890]\n",
      "[Epoch 88/100] [Batch 323/347] [D loss: 0.304687] [G loss: 0.443300]\n",
      "[Epoch 88/100] [Batch 324/347] [D loss: 0.293339] [G loss: 0.462048]\n",
      "[Epoch 88/100] [Batch 325/347] [D loss: 0.291267] [G loss: 0.479872]\n",
      "[Epoch 88/100] [Batch 326/347] [D loss: 0.291662] [G loss: 0.497862]\n",
      "[Epoch 88/100] [Batch 327/347] [D loss: 0.280190] [G loss: 0.512804]\n",
      "[Epoch 88/100] [Batch 328/347] [D loss: 0.289055] [G loss: 0.525401]\n",
      "[Epoch 88/100] [Batch 329/347] [D loss: 0.288018] [G loss: 0.543166]\n",
      "[Epoch 88/100] [Batch 330/347] [D loss: 0.284948] [G loss: 0.564934]\n",
      "[Epoch 88/100] [Batch 331/347] [D loss: 0.313113] [G loss: 0.589159]\n",
      "[Epoch 88/100] [Batch 332/347] [D loss: 0.427658] [G loss: 0.617748]\n",
      "[Epoch 88/100] [Batch 333/347] [D loss: 0.363424] [G loss: 0.621258]\n",
      "[Epoch 88/100] [Batch 334/347] [D loss: 0.354090] [G loss: 0.613237]\n",
      "[Epoch 88/100] [Batch 335/347] [D loss: 0.357018] [G loss: 0.606680]\n",
      "[Epoch 88/100] [Batch 336/347] [D loss: 0.351687] [G loss: 0.608416]\n",
      "[Epoch 88/100] [Batch 337/347] [D loss: 0.430983] [G loss: 0.592241]\n",
      "[Epoch 88/100] [Batch 338/347] [D loss: 0.491364] [G loss: 0.580079]\n",
      "[Epoch 88/100] [Batch 339/347] [D loss: 0.452312] [G loss: 0.559816]\n",
      "[Epoch 88/100] [Batch 340/347] [D loss: 0.407551] [G loss: 0.537611]\n",
      "[Epoch 88/100] [Batch 341/347] [D loss: 0.416656] [G loss: 0.518538]\n",
      "[Epoch 88/100] [Batch 342/347] [D loss: 0.271913] [G loss: 0.497423]\n",
      "[Epoch 88/100] [Batch 343/347] [D loss: 0.235852] [G loss: 0.479547]\n",
      "[Epoch 88/100] [Batch 344/347] [D loss: 0.238125] [G loss: 0.471522]\n",
      "[Epoch 88/100] [Batch 345/347] [D loss: 0.215218] [G loss: 0.490641]\n",
      "[Epoch 88/100] [Batch 346/347] [D loss: 0.212123] [G loss: 0.511921]\n",
      "[Epoch 88/100] [Batch 347/347] [D loss: 0.194694] [G loss: 0.545117]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 1/347] [D loss: 0.429460] [G loss: 0.618762]\n",
      "[Epoch 89/100] [Batch 2/347] [D loss: 0.485882] [G loss: 0.644594]\n",
      "[Epoch 89/100] [Batch 3/347] [D loss: 0.580594] [G loss: 0.660061]\n",
      "[Epoch 89/100] [Batch 4/347] [D loss: 0.616298] [G loss: 0.656304]\n",
      "[Epoch 89/100] [Batch 5/347] [D loss: 0.620065] [G loss: 0.634790]\n",
      "[Epoch 89/100] [Batch 6/347] [D loss: 0.496553] [G loss: 0.603125]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 7/347] [D loss: 0.422575] [G loss: 0.569396]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 8/347] [D loss: 0.413784] [G loss: 0.539629]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 9/347] [D loss: 0.407141] [G loss: 0.512295]\n",
      "[Epoch 89/100] [Batch 10/347] [D loss: 0.420005] [G loss: 0.483714]\n",
      "[Epoch 89/100] [Batch 11/347] [D loss: 0.512324] [G loss: 0.463658]\n",
      "[Epoch 89/100] [Batch 12/347] [D loss: 0.520884] [G loss: 0.445845]\n",
      "[Epoch 89/100] [Batch 13/347] [D loss: 0.479627] [G loss: 0.428025]\n",
      "[Epoch 89/100] [Batch 14/347] [D loss: 0.453304] [G loss: 0.417809]\n",
      "[Epoch 89/100] [Batch 15/347] [D loss: 0.449660] [G loss: 0.406454]\n",
      "[Epoch 89/100] [Batch 16/347] [D loss: 0.445828] [G loss: 0.402215]\n",
      "[Epoch 89/100] [Batch 17/347] [D loss: 0.456025] [G loss: 0.408268]\n",
      "[Epoch 89/100] [Batch 18/347] [D loss: 0.476809] [G loss: 0.412711]\n",
      "[Epoch 89/100] [Batch 19/347] [D loss: 0.474273] [G loss: 0.423533]\n",
      "[Epoch 89/100] [Batch 20/347] [D loss: 0.500301] [G loss: 0.437382]\n",
      "[Epoch 89/100] [Batch 21/347] [D loss: 0.419721] [G loss: 0.445805]\n",
      "[Epoch 89/100] [Batch 22/347] [D loss: 0.415226] [G loss: 0.460687]\n",
      "[Epoch 89/100] [Batch 23/347] [D loss: 0.416383] [G loss: 0.476776]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 24/347] [D loss: 0.368268] [G loss: 0.493426]\n",
      "[Epoch 89/100] [Batch 25/347] [D loss: 0.251032] [G loss: 0.517705]\n",
      "[Epoch 89/100] [Batch 26/347] [D loss: 0.240331] [G loss: 0.549024]\n",
      "[Epoch 89/100] [Batch 27/347] [D loss: 0.229071] [G loss: 0.581686]\n",
      "[Epoch 89/100] [Batch 28/347] [D loss: 0.223099] [G loss: 0.615440]\n",
      "[Epoch 89/100] [Batch 29/347] [D loss: 0.260621] [G loss: 0.638951]\n",
      "[Epoch 89/100] [Batch 30/347] [D loss: 0.244754] [G loss: 0.669192]\n",
      "[Epoch 89/100] [Batch 31/347] [D loss: 0.247736] [G loss: 0.691435]\n",
      "[Epoch 89/100] [Batch 32/347] [D loss: 0.266109] [G loss: 0.712621]\n",
      "[Epoch 89/100] [Batch 33/347] [D loss: 0.285083] [G loss: 0.738204]\n",
      "[Epoch 89/100] [Batch 34/347] [D loss: 0.370553] [G loss: 0.742364]\n",
      "[Epoch 89/100] [Batch 35/347] [D loss: 0.390070] [G loss: 0.729105]\n",
      "[Epoch 89/100] [Batch 36/347] [D loss: 0.447504] [G loss: 0.711038]\n",
      "[Epoch 89/100] [Batch 37/347] [D loss: 0.466926] [G loss: 0.695810]\n",
      "[Epoch 89/100] [Batch 38/347] [D loss: 0.472049] [G loss: 0.666127]\n",
      "[Epoch 89/100] [Batch 39/347] [D loss: 0.483608] [G loss: 0.638866]\n",
      "[Epoch 89/100] [Batch 40/347] [D loss: 0.514158] [G loss: 0.616149]\n",
      "[Epoch 89/100] [Batch 41/347] [D loss: 0.525966] [G loss: 0.589512]\n",
      "[Epoch 89/100] [Batch 42/347] [D loss: 0.494003] [G loss: 0.566415]\n",
      "[Epoch 89/100] [Batch 43/347] [D loss: 0.515877] [G loss: 0.549755]\n",
      "[Epoch 89/100] [Batch 44/347] [D loss: 0.468426] [G loss: 0.526439]\n",
      "[Epoch 89/100] [Batch 45/347] [D loss: 0.431641] [G loss: 0.492906]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 46/347] [D loss: 0.353203] [G loss: 0.456203]\n",
      "[Epoch 89/100] [Batch 47/347] [D loss: 0.363650] [G loss: 0.440949]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 48/347] [D loss: 0.286036] [G loss: 0.446871]\n",
      "[Epoch 89/100] [Batch 49/347] [D loss: 0.280890] [G loss: 0.467155]\n",
      "[Epoch 89/100] [Batch 50/347] [D loss: 0.289327] [G loss: 0.487466]\n",
      "[Epoch 89/100] [Batch 51/347] [D loss: 0.263083] [G loss: 0.530664]\n",
      "[Epoch 89/100] [Batch 52/347] [D loss: 0.381491] [G loss: 0.534593]\n",
      "[Epoch 89/100] [Batch 53/347] [D loss: 0.428203] [G loss: 0.547387]\n",
      "[Epoch 89/100] [Batch 54/347] [D loss: 0.415311] [G loss: 0.577359]\n",
      "[Epoch 89/100] [Batch 55/347] [D loss: 0.408890] [G loss: 0.610872]\n",
      "[Epoch 89/100] [Batch 56/347] [D loss: 0.364204] [G loss: 0.681004]\n",
      "[Epoch 89/100] [Batch 57/347] [D loss: 0.276377] [G loss: 0.748748]\n",
      "[Epoch 89/100] [Batch 58/347] [D loss: 0.283552] [G loss: 0.780500]\n",
      "[Epoch 89/100] [Batch 59/347] [D loss: 0.291079] [G loss: 0.800497]\n",
      "[Epoch 89/100] [Batch 60/347] [D loss: 0.308654] [G loss: 0.801102]\n",
      "[Epoch 89/100] [Batch 61/347] [D loss: 0.357173] [G loss: 0.788376]\n",
      "[Epoch 89/100] [Batch 62/347] [D loss: 0.357571] [G loss: 0.789899]\n",
      "[Epoch 89/100] [Batch 63/347] [D loss: 0.335660] [G loss: 0.782121]\n",
      "[Epoch 89/100] [Batch 64/347] [D loss: 0.284090] [G loss: 0.750880]\n",
      "[Epoch 89/100] [Batch 65/347] [D loss: 0.188600] [G loss: 0.757694]\n",
      "[Epoch 89/100] [Batch 66/347] [D loss: 0.201881] [G loss: 0.735855]\n",
      "[Epoch 89/100] [Batch 67/347] [D loss: 0.224849] [G loss: 0.713155]\n",
      "[Epoch 89/100] [Batch 68/347] [D loss: 0.247058] [G loss: 0.695532]\n",
      "[Epoch 89/100] [Batch 69/347] [D loss: 0.322292] [G loss: 0.643780]\n",
      "[Epoch 89/100] [Batch 70/347] [D loss: 0.324639] [G loss: 0.631810]\n",
      "[Epoch 89/100] [Batch 71/347] [D loss: 0.300026] [G loss: 0.648428]\n",
      "[Epoch 89/100] [Batch 72/347] [D loss: 0.303496] [G loss: 0.670688]\n",
      "[Epoch 89/100] [Batch 73/347] [D loss: 0.478561] [G loss: 0.681160]\n",
      "[Epoch 89/100] [Batch 74/347] [D loss: 0.473986] [G loss: 0.685179]\n",
      "[Epoch 89/100] [Batch 75/347] [D loss: 0.476392] [G loss: 0.677096]\n",
      "[Epoch 89/100] [Batch 76/347] [D loss: 0.478872] [G loss: 0.668109]\n",
      "[Epoch 89/100] [Batch 77/347] [D loss: 0.501393] [G loss: 0.702368]\n",
      "[Epoch 89/100] [Batch 78/347] [D loss: 0.543161] [G loss: 0.699921]\n",
      "[Epoch 89/100] [Batch 79/347] [D loss: 0.532050] [G loss: 0.678284]\n",
      "[Epoch 89/100] [Batch 80/347] [D loss: 0.374933] [G loss: 0.640142]\n",
      "[Epoch 89/100] [Batch 81/347] [D loss: 0.348621] [G loss: 0.624516]\n",
      "[Epoch 89/100] [Batch 82/347] [D loss: 0.326901] [G loss: 0.634326]\n",
      "[Epoch 89/100] [Batch 83/347] [D loss: 0.334090] [G loss: 0.624655]\n",
      "[Epoch 89/100] [Batch 84/347] [D loss: 0.554237] [G loss: 0.601858]\n",
      "[Epoch 89/100] [Batch 85/347] [D loss: 0.683973] [G loss: 0.574690]\n",
      "[Epoch 89/100] [Batch 86/347] [D loss: 0.671622] [G loss: 0.548564]\n",
      "[Epoch 89/100] [Batch 87/347] [D loss: 0.661807] [G loss: 0.531559]\n",
      "[Epoch 89/100] [Batch 88/347] [D loss: 0.666636] [G loss: 0.524185]\n",
      "[Epoch 89/100] [Batch 89/347] [D loss: 0.646330] [G loss: 0.523197]\n",
      "[Epoch 89/100] [Batch 90/347] [D loss: 0.637760] [G loss: 0.506291]\n",
      "[Epoch 89/100] [Batch 91/347] [D loss: 0.640297] [G loss: 0.493274]\n",
      "[Epoch 89/100] [Batch 92/347] [D loss: 0.643868] [G loss: 0.487182]\n",
      "[Epoch 89/100] [Batch 93/347] [D loss: 0.639874] [G loss: 0.483566]\n",
      "[Epoch 89/100] [Batch 94/347] [D loss: 0.616738] [G loss: 0.477525]\n",
      "[Epoch 89/100] [Batch 95/347] [D loss: 0.592969] [G loss: 0.476855]\n",
      "[Epoch 89/100] [Batch 96/347] [D loss: 0.587205] [G loss: 0.482170]\n",
      "[Epoch 89/100] [Batch 97/347] [D loss: 0.571660] [G loss: 0.489322]\n",
      "[Epoch 89/100] [Batch 98/347] [D loss: 0.540053] [G loss: 0.499508]\n",
      "[Epoch 89/100] [Batch 99/347] [D loss: 0.532818] [G loss: 0.512863]\n",
      "[Epoch 89/100] [Batch 100/347] [D loss: 0.525377] [G loss: 0.528999]\n",
      "[Epoch 89/100] [Batch 101/347] [D loss: 0.529269] [G loss: 0.543657]\n",
      "[Epoch 89/100] [Batch 102/347] [D loss: 0.622498] [G loss: 0.552699]\n",
      "[Epoch 89/100] [Batch 103/347] [D loss: 0.622785] [G loss: 0.563550]\n",
      "[Epoch 89/100] [Batch 104/347] [D loss: 0.577960] [G loss: 0.562258]\n",
      "[Epoch 89/100] [Batch 105/347] [D loss: 0.464261] [G loss: 0.562240]\n",
      "[Epoch 89/100] [Batch 106/347] [D loss: 0.250707] [G loss: 0.574935]\n",
      "[Epoch 89/100] [Batch 107/347] [D loss: 0.227134] [G loss: 0.613451]\n",
      "[Epoch 89/100] [Batch 108/347] [D loss: 0.204122] [G loss: 0.667228]\n",
      "[Epoch 89/100] [Batch 109/347] [D loss: 0.167437] [G loss: 0.723273]\n",
      "[Epoch 89/100] [Batch 110/347] [D loss: 0.279653] [G loss: 0.646083]\n",
      "[Epoch 89/100] [Batch 111/347] [D loss: 0.261184] [G loss: 0.736335]\n",
      "[Epoch 89/100] [Batch 112/347] [D loss: 0.230377] [G loss: 0.824460]\n",
      "[Epoch 89/100] [Batch 113/347] [D loss: 0.468334] [G loss: 0.883794]\n",
      "[Epoch 89/100] [Batch 114/347] [D loss: 0.587082] [G loss: 0.961451]\n",
      "[Epoch 89/100] [Batch 115/347] [D loss: 0.619841] [G loss: 0.964775]\n",
      "[Epoch 89/100] [Batch 116/347] [D loss: 0.535278] [G loss: 0.915506]\n",
      "[Epoch 89/100] [Batch 117/347] [D loss: 0.493768] [G loss: 0.952587]\n",
      "[Epoch 89/100] [Batch 118/347] [D loss: 0.365967] [G loss: 0.975847]\n",
      "[Epoch 89/100] [Batch 119/347] [D loss: 0.339931] [G loss: 0.893075]\n",
      "[Epoch 89/100] [Batch 120/347] [D loss: 0.315916] [G loss: 0.800130]\n",
      "[Epoch 89/100] [Batch 121/347] [D loss: 0.296399] [G loss: 0.730522]\n",
      "[Epoch 89/100] [Batch 122/347] [D loss: 0.456531] [G loss: 0.686911]\n",
      "[Epoch 89/100] [Batch 123/347] [D loss: 0.508511] [G loss: 0.649211]\n",
      "[Epoch 89/100] [Batch 124/347] [D loss: 0.411391] [G loss: 0.608608]\n",
      "[Epoch 89/100] [Batch 125/347] [D loss: 0.375107] [G loss: 0.587228]\n",
      "[Epoch 89/100] [Batch 126/347] [D loss: 0.327945] [G loss: 0.583868]\n",
      "[Epoch 89/100] [Batch 127/347] [D loss: 0.324811] [G loss: 0.574957]\n",
      "[Epoch 89/100] [Batch 128/347] [D loss: 0.331017] [G loss: 0.550212]\n",
      "[Epoch 89/100] [Batch 129/347] [D loss: 0.305220] [G loss: 0.543290]\n",
      "[Epoch 89/100] [Batch 130/347] [D loss: 0.281715] [G loss: 0.553661]\n",
      "[Epoch 89/100] [Batch 131/347] [D loss: 0.261592] [G loss: 0.580476]\n",
      "[Epoch 89/100] [Batch 132/347] [D loss: 0.240357] [G loss: 0.620336]\n",
      "[Epoch 89/100] [Batch 133/347] [D loss: 0.231102] [G loss: 0.655517]\n",
      "[Epoch 89/100] [Batch 134/347] [D loss: 0.265219] [G loss: 0.639616]\n",
      "[Epoch 89/100] [Batch 135/347] [D loss: 0.235986] [G loss: 0.702683]\n",
      "[Epoch 89/100] [Batch 136/347] [D loss: 0.175833] [G loss: 0.794322]\n",
      "[Epoch 89/100] [Batch 137/347] [D loss: 0.417007] [G loss: 0.821893]\n",
      "[Epoch 89/100] [Batch 138/347] [D loss: 0.477172] [G loss: 0.856392]\n",
      "[Epoch 89/100] [Batch 139/347] [D loss: 0.554777] [G loss: 0.872135]\n",
      "[Epoch 89/100] [Batch 140/347] [D loss: 0.585322] [G loss: 0.897418]\n",
      "[Epoch 89/100] [Batch 141/347] [D loss: 0.512350] [G loss: 0.992534]\n",
      "[Epoch 89/100] [Batch 142/347] [D loss: 0.532541] [G loss: 1.040041]\n",
      "[Epoch 89/100] [Batch 143/347] [D loss: 0.516849] [G loss: 1.030875]\n",
      "[Epoch 89/100] [Batch 144/347] [D loss: 0.491700] [G loss: 0.997422]\n",
      "[Epoch 89/100] [Batch 145/347] [D loss: 0.475767] [G loss: 0.931829]\n",
      "[Epoch 89/100] [Batch 146/347] [D loss: 0.472508] [G loss: 0.856179]\n",
      "[Epoch 89/100] [Batch 147/347] [D loss: 0.472327] [G loss: 0.784140]\n",
      "[Epoch 89/100] [Batch 148/347] [D loss: 0.485059] [G loss: 0.709335]\n",
      "[Epoch 89/100] [Batch 149/347] [D loss: 0.416230] [G loss: 0.655330]\n",
      "[Epoch 89/100] [Batch 150/347] [D loss: 0.380151] [G loss: 0.614956]\n",
      "[Epoch 89/100] [Batch 151/347] [D loss: 0.352103] [G loss: 0.575592]\n",
      "[Epoch 89/100] [Batch 152/347] [D loss: 0.343269] [G loss: 0.537759]\n",
      "[Epoch 89/100] [Batch 153/347] [D loss: 0.363247] [G loss: 0.496333]\n",
      "[Epoch 89/100] [Batch 154/347] [D loss: 0.366740] [G loss: 0.470557]\n",
      "[Epoch 89/100] [Batch 155/347] [D loss: 0.369136] [G loss: 0.459985]\n",
      "[Epoch 89/100] [Batch 156/347] [D loss: 0.377211] [G loss: 0.452806]\n",
      "[Epoch 89/100] [Batch 157/347] [D loss: 0.363491] [G loss: 0.465065]\n",
      "[Epoch 89/100] [Batch 158/347] [D loss: 0.334492] [G loss: 0.486710]\n",
      "[Epoch 89/100] [Batch 159/347] [D loss: 0.340905] [G loss: 0.504039]\n",
      "[Epoch 89/100] [Batch 160/347] [D loss: 0.312590] [G loss: 0.541506]\n",
      "[Epoch 89/100] [Batch 161/347] [D loss: 0.291115] [G loss: 0.575622]\n",
      "[Epoch 89/100] [Batch 162/347] [D loss: 0.311717] [G loss: 0.580449]\n",
      "[Epoch 89/100] [Batch 163/347] [D loss: 0.302424] [G loss: 0.609591]\n",
      "[Epoch 89/100] [Batch 164/347] [D loss: 0.301519] [G loss: 0.638435]\n",
      "[Epoch 89/100] [Batch 165/347] [D loss: 0.286000] [G loss: 0.681889]\n",
      "[Epoch 89/100] [Batch 166/347] [D loss: 0.269462] [G loss: 0.732709]\n",
      "[Epoch 89/100] [Batch 167/347] [D loss: 0.275651] [G loss: 0.799402]\n",
      "[Epoch 89/100] [Batch 168/347] [D loss: 0.273566] [G loss: 0.829483]\n",
      "[Epoch 89/100] [Batch 169/347] [D loss: 0.439713] [G loss: 0.838307]\n",
      "[Epoch 89/100] [Batch 170/347] [D loss: 0.519393] [G loss: 0.851774]\n",
      "[Epoch 89/100] [Batch 171/347] [D loss: 0.508514] [G loss: 0.844298]\n",
      "[Epoch 89/100] [Batch 172/347] [D loss: 0.518535] [G loss: 0.841073]\n",
      "[Epoch 89/100] [Batch 173/347] [D loss: 0.502526] [G loss: 0.858666]\n",
      "[Epoch 89/100] [Batch 174/347] [D loss: 0.485390] [G loss: 0.883850]\n",
      "[Epoch 89/100] [Batch 175/347] [D loss: 0.519074] [G loss: 0.872541]\n",
      "[Epoch 89/100] [Batch 176/347] [D loss: 0.522170] [G loss: 0.853567]\n",
      "[Epoch 89/100] [Batch 177/347] [D loss: 0.517316] [G loss: 0.820766]\n",
      "[Epoch 89/100] [Batch 178/347] [D loss: 0.504942] [G loss: 0.784441]\n",
      "[Epoch 89/100] [Batch 179/347] [D loss: 0.500579] [G loss: 0.762492]\n",
      "[Epoch 89/100] [Batch 180/347] [D loss: 0.498319] [G loss: 0.743854]\n",
      "[Epoch 89/100] [Batch 181/347] [D loss: 0.487433] [G loss: 0.719554]\n",
      "[Epoch 89/100] [Batch 182/347] [D loss: 0.483353] [G loss: 0.696319]\n",
      "[Epoch 89/100] [Batch 183/347] [D loss: 0.474907] [G loss: 0.676208]\n",
      "[Epoch 89/100] [Batch 184/347] [D loss: 0.492540] [G loss: 0.658801]\n",
      "[Epoch 89/100] [Batch 185/347] [D loss: 0.500397] [G loss: 0.636226]\n",
      "[Epoch 89/100] [Batch 186/347] [D loss: 0.479070] [G loss: 0.614496]\n",
      "[Epoch 89/100] [Batch 187/347] [D loss: 0.464030] [G loss: 0.593793]\n",
      "[Epoch 89/100] [Batch 188/347] [D loss: 0.431057] [G loss: 0.570207]\n",
      "[Epoch 89/100] [Batch 189/347] [D loss: 0.378401] [G loss: 0.546268]\n",
      "[Epoch 89/100] [Batch 190/347] [D loss: 0.370747] [G loss: 0.528015]\n",
      "[Epoch 89/100] [Batch 191/347] [D loss: 0.374659] [G loss: 0.511517]\n",
      "[Epoch 89/100] [Batch 192/347] [D loss: 0.385371] [G loss: 0.500556]\n",
      "[Epoch 89/100] [Batch 193/347] [D loss: 0.452098] [G loss: 0.490141]\n",
      "[Epoch 89/100] [Batch 194/347] [D loss: 0.442048] [G loss: 0.482652]\n",
      "[Epoch 89/100] [Batch 195/347] [D loss: 0.424834] [G loss: 0.479461]\n",
      "[Epoch 89/100] [Batch 196/347] [D loss: 0.385900] [G loss: 0.480136]\n",
      "[Epoch 89/100] [Batch 197/347] [D loss: 0.380360] [G loss: 0.485649]\n",
      "[Epoch 89/100] [Batch 198/347] [D loss: 0.371855] [G loss: 0.494636]\n",
      "[Epoch 89/100] [Batch 199/347] [D loss: 0.371517] [G loss: 0.501934]\n",
      "[Epoch 89/100] [Batch 200/347] [D loss: 0.432565] [G loss: 0.505528]\n",
      "[Epoch 89/100] [Batch 201/347] [D loss: 0.462126] [G loss: 0.512135]\n",
      "[Epoch 89/100] [Batch 202/347] [D loss: 0.474750] [G loss: 0.516407]\n",
      "[Epoch 89/100] [Batch 203/347] [D loss: 0.500149] [G loss: 0.521232]\n",
      "[Epoch 89/100] [Batch 204/347] [D loss: 0.477549] [G loss: 0.536575]\n",
      "[Epoch 89/100] [Batch 205/347] [D loss: 0.463231] [G loss: 0.549524]\n",
      "[Epoch 89/100] [Batch 206/347] [D loss: 0.455341] [G loss: 0.557362]\n",
      "[Epoch 89/100] [Batch 207/347] [D loss: 0.382484] [G loss: 0.562842]\n",
      "[Epoch 89/100] [Batch 208/347] [D loss: 0.367357] [G loss: 0.564738]\n",
      "[Epoch 89/100] [Batch 209/347] [D loss: 0.368708] [G loss: 0.555092]\n",
      "[Epoch 89/100] [Batch 210/347] [D loss: 0.300917] [G loss: 0.553164]\n",
      "[Epoch 89/100] [Batch 211/347] [D loss: 0.269954] [G loss: 0.543610]\n",
      "[Epoch 89/100] [Batch 212/347] [D loss: 0.187274] [G loss: 0.546091]\n",
      "[Epoch 89/100] [Batch 213/347] [D loss: 0.181793] [G loss: 0.561231]\n",
      "[Epoch 89/100] [Batch 214/347] [D loss: 0.185373] [G loss: 0.558834]\n",
      "[Epoch 89/100] [Batch 215/347] [D loss: 0.181273] [G loss: 0.570639]\n",
      "[Epoch 89/100] [Batch 216/347] [D loss: 0.360053] [G loss: 0.511846]\n",
      "[Epoch 89/100] [Batch 217/347] [D loss: 0.401552] [G loss: 0.545398]\n",
      "[Epoch 89/100] [Batch 218/347] [D loss: 0.438001] [G loss: 0.573573]\n",
      "[Epoch 89/100] [Batch 219/347] [D loss: 0.408588] [G loss: 0.590370]\n",
      "[Epoch 89/100] [Batch 220/347] [D loss: 0.353094] [G loss: 0.648608]\n",
      "[Epoch 89/100] [Batch 221/347] [D loss: 0.373559] [G loss: 0.664097]\n",
      "[Epoch 89/100] [Batch 222/347] [D loss: 0.381276] [G loss: 0.665366]\n",
      "[Epoch 89/100] [Batch 223/347] [D loss: 0.386384] [G loss: 0.638578]\n",
      "[Epoch 89/100] [Batch 224/347] [D loss: 0.414024] [G loss: 0.614372]\n",
      "[Epoch 89/100] [Batch 225/347] [D loss: 0.441320] [G loss: 0.582117]\n",
      "[Epoch 89/100] [Batch 226/347] [D loss: 0.458962] [G loss: 0.557949]\n",
      "[Epoch 89/100] [Batch 227/347] [D loss: 0.481437] [G loss: 0.548424]\n",
      "[Epoch 89/100] [Batch 228/347] [D loss: 0.486655] [G loss: 0.543592]\n",
      "[Epoch 89/100] [Batch 229/347] [D loss: 0.465856] [G loss: 0.540386]\n",
      "[Epoch 89/100] [Batch 230/347] [D loss: 0.466528] [G loss: 0.531663]\n",
      "[Epoch 89/100] [Batch 231/347] [D loss: 0.432090] [G loss: 0.510782]\n",
      "[Epoch 89/100] [Batch 232/347] [D loss: 0.405190] [G loss: 0.492369]\n",
      "[Epoch 89/100] [Batch 233/347] [D loss: 0.320539] [G loss: 0.478390]\n",
      "[Epoch 89/100] [Batch 234/347] [D loss: 0.278379] [G loss: 0.468414]\n",
      "[Epoch 89/100] [Batch 235/347] [D loss: 0.277900] [G loss: 0.466088]\n",
      "[Epoch 89/100] [Batch 236/347] [D loss: 0.275337] [G loss: 0.467762]\n",
      "[Epoch 89/100] [Batch 237/347] [D loss: 0.343235] [G loss: 0.463245]\n",
      "[Epoch 89/100] [Batch 238/347] [D loss: 0.406221] [G loss: 0.452743]\n",
      "[Epoch 89/100] [Batch 239/347] [D loss: 0.411998] [G loss: 0.443231]\n",
      "[Epoch 89/100] [Batch 240/347] [D loss: 0.418551] [G loss: 0.440684]\n",
      "[Epoch 89/100] [Batch 241/347] [D loss: 0.414699] [G loss: 0.446688]\n",
      "[Epoch 89/100] [Batch 242/347] [D loss: 0.416878] [G loss: 0.472949]\n",
      "[Epoch 89/100] [Batch 243/347] [D loss: 0.363104] [G loss: 0.477065]\n",
      "[Epoch 89/100] [Batch 244/347] [D loss: 0.337453] [G loss: 0.471953]\n",
      "[Epoch 89/100] [Batch 245/347] [D loss: 0.340172] [G loss: 0.463718]\n",
      "[Epoch 89/100] [Batch 246/347] [D loss: 0.349492] [G loss: 0.453203]\n",
      "[Epoch 89/100] [Batch 247/347] [D loss: 0.392757] [G loss: 0.441494]\n",
      "[Epoch 89/100] [Batch 248/347] [D loss: 0.414713] [G loss: 0.438515]\n",
      "[Epoch 89/100] [Batch 249/347] [D loss: 0.387400] [G loss: 0.444471]\n",
      "[Epoch 89/100] [Batch 250/347] [D loss: 0.366806] [G loss: 0.453982]\n",
      "[Epoch 89/100] [Batch 251/347] [D loss: 0.340494] [G loss: 0.470552]\n",
      "[Epoch 89/100] [Batch 252/347] [D loss: 0.329974] [G loss: 0.476688]\n",
      "[Epoch 89/100] [Batch 253/347] [D loss: 0.289888] [G loss: 0.467750]\n",
      "[Epoch 89/100] [Batch 254/347] [D loss: 0.284037] [G loss: 0.471666]\n",
      "[Epoch 89/100] [Batch 255/347] [D loss: 0.286102] [G loss: 0.472572]\n",
      "[Epoch 89/100] [Batch 256/347] [D loss: 0.287465] [G loss: 0.468040]\n",
      "[Epoch 89/100] [Batch 257/347] [D loss: 0.281588] [G loss: 0.452568]\n",
      "[Epoch 89/100] [Batch 258/347] [D loss: 0.256110] [G loss: 0.448866]\n",
      "[Epoch 89/100] [Batch 259/347] [D loss: 0.259972] [G loss: 0.452869]\n",
      "[Epoch 89/100] [Batch 260/347] [D loss: 0.257970] [G loss: 0.458179]\n",
      "[Epoch 89/100] [Batch 261/347] [D loss: 0.242955] [G loss: 0.477389]\n",
      "[Epoch 89/100] [Batch 262/347] [D loss: 0.213975] [G loss: 0.487233]\n",
      "[Epoch 89/100] [Batch 263/347] [D loss: 0.209264] [G loss: 0.497130]\n",
      "[Epoch 89/100] [Batch 264/347] [D loss: 0.206302] [G loss: 0.506771]\n",
      "[Epoch 89/100] [Batch 265/347] [D loss: 0.216049] [G loss: 0.509205]\n",
      "[Epoch 89/100] [Batch 266/347] [D loss: 0.280369] [G loss: 0.501902]\n",
      "[Epoch 89/100] [Batch 267/347] [D loss: 0.298937] [G loss: 0.505166]\n",
      "[Epoch 89/100] [Batch 268/347] [D loss: 0.301586] [G loss: 0.505348]\n",
      "[Epoch 89/100] [Batch 269/347] [D loss: 0.302709] [G loss: 0.504637]\n",
      "[Epoch 89/100] [Batch 270/347] [D loss: 0.318437] [G loss: 0.507015]\n",
      "[Epoch 89/100] [Batch 271/347] [D loss: 0.288284] [G loss: 0.512378]\n",
      "[Epoch 89/100] [Batch 272/347] [D loss: 0.315893] [G loss: 0.534311]\n",
      "[Epoch 89/100] [Batch 273/347] [D loss: 0.292338] [G loss: 0.559611]\n",
      "[Epoch 89/100] [Batch 274/347] [D loss: 0.262975] [G loss: 0.595011]\n",
      "[Epoch 89/100] [Batch 275/347] [D loss: 0.217037] [G loss: 0.628778]\n",
      "[Epoch 89/100] [Batch 276/347] [D loss: 0.460861] [G loss: 0.476515]\n",
      "[Epoch 89/100] [Batch 277/347] [D loss: 0.483499] [G loss: 0.501838]\n",
      "[Epoch 89/100] [Batch 278/347] [D loss: 0.489959] [G loss: 0.527834]\n",
      "[Epoch 89/100] [Batch 279/347] [D loss: 0.507468] [G loss: 0.548222]\n",
      "[Epoch 89/100] [Batch 280/347] [D loss: 0.471823] [G loss: 0.665761]\n",
      "[Epoch 89/100] [Batch 281/347] [D loss: 0.494328] [G loss: 0.707511]\n",
      "[Epoch 89/100] [Batch 282/347] [D loss: 0.491398] [G loss: 0.701228]\n",
      "[Epoch 89/100] [Batch 283/347] [D loss: 0.486050] [G loss: 0.690270]\n",
      "[Epoch 89/100] [Batch 284/347] [D loss: 0.459186] [G loss: 0.675001]\n",
      "[Epoch 89/100] [Batch 285/347] [D loss: 0.466978] [G loss: 0.654793]\n",
      "[Epoch 89/100] [Batch 286/347] [D loss: 0.430992] [G loss: 0.610907]\n",
      "[Epoch 89/100] [Batch 287/347] [D loss: 0.408716] [G loss: 0.567035]\n",
      "[Epoch 89/100] [Batch 288/347] [D loss: 0.378513] [G loss: 0.512899]\n",
      "[Epoch 89/100] [Batch 289/347] [D loss: 0.334534] [G loss: 0.460583]\n",
      "[Epoch 89/100] [Batch 290/347] [D loss: 0.302007] [G loss: 0.420529]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 291/347] [D loss: 0.276245] [G loss: 0.388669]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 292/347] [D loss: 0.264368] [G loss: 0.358212]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 89/100] [Batch 293/347] [D loss: 0.231356] [G loss: 0.347179]\n",
      "[Epoch 89/100] [Batch 294/347] [D loss: 0.243986] [G loss: 0.345213]\n",
      "[Epoch 89/100] [Batch 295/347] [D loss: 0.251365] [G loss: 0.345703]\n",
      "[Epoch 89/100] [Batch 296/347] [D loss: 0.248882] [G loss: 0.353585]\n",
      "[Epoch 89/100] [Batch 297/347] [D loss: 0.338162] [G loss: 0.348344]\n",
      "[Epoch 89/100] [Batch 298/347] [D loss: 0.330861] [G loss: 0.354910]\n",
      "[Epoch 89/100] [Batch 299/347] [D loss: 0.324934] [G loss: 0.370940]\n",
      "[Epoch 89/100] [Batch 300/347] [D loss: 0.315776] [G loss: 0.393878]\n",
      "[Epoch 89/100] [Batch 301/347] [D loss: 0.302073] [G loss: 0.430366]\n",
      "[Epoch 89/100] [Batch 302/347] [D loss: 0.301137] [G loss: 0.453798]\n",
      "[Epoch 89/100] [Batch 303/347] [D loss: 0.315430] [G loss: 0.452587]\n",
      "[Epoch 89/100] [Batch 304/347] [D loss: 0.230167] [G loss: 0.465204]\n",
      "[Epoch 89/100] [Batch 305/347] [D loss: 0.160641] [G loss: 0.472765]\n",
      "[Epoch 89/100] [Batch 306/347] [D loss: 0.154705] [G loss: 0.480023]\n",
      "[Epoch 89/100] [Batch 307/347] [D loss: 0.145372] [G loss: 0.497112]\n",
      "[Epoch 89/100] [Batch 308/347] [D loss: 0.201155] [G loss: 0.513663]\n",
      "[Epoch 89/100] [Batch 309/347] [D loss: 0.345829] [G loss: 0.508799]\n",
      "[Epoch 89/100] [Batch 310/347] [D loss: 0.486294] [G loss: 0.525712]\n",
      "[Epoch 89/100] [Batch 311/347] [D loss: 0.438424] [G loss: 0.515966]\n",
      "[Epoch 89/100] [Batch 312/347] [D loss: 0.332730] [G loss: 0.502552]\n",
      "[Epoch 89/100] [Batch 313/347] [D loss: 0.278695] [G loss: 0.528680]\n",
      "[Epoch 89/100] [Batch 314/347] [D loss: 0.272061] [G loss: 0.515943]\n",
      "[Epoch 89/100] [Batch 315/347] [D loss: 0.277174] [G loss: 0.491551]\n",
      "[Epoch 89/100] [Batch 316/347] [D loss: 0.300816] [G loss: 0.460955]\n",
      "[Epoch 89/100] [Batch 317/347] [D loss: 0.311183] [G loss: 0.439540]\n",
      "[Epoch 89/100] [Batch 318/347] [D loss: 0.298459] [G loss: 0.435523]\n",
      "[Epoch 89/100] [Batch 319/347] [D loss: 0.272686] [G loss: 0.434048]\n",
      "[Epoch 89/100] [Batch 320/347] [D loss: 0.278976] [G loss: 0.418756]\n",
      "[Epoch 89/100] [Batch 321/347] [D loss: 0.267092] [G loss: 0.402766]\n",
      "[Epoch 89/100] [Batch 322/347] [D loss: 0.276379] [G loss: 0.388368]\n",
      "[Epoch 89/100] [Batch 323/347] [D loss: 0.232387] [G loss: 0.378890]\n",
      "[Epoch 89/100] [Batch 324/347] [D loss: 0.229818] [G loss: 0.381518]\n",
      "[Epoch 89/100] [Batch 325/347] [D loss: 0.233200] [G loss: 0.380617]\n",
      "[Epoch 89/100] [Batch 326/347] [D loss: 0.235084] [G loss: 0.384273]\n",
      "[Epoch 89/100] [Batch 327/347] [D loss: 0.232209] [G loss: 0.390803]\n",
      "[Epoch 89/100] [Batch 328/347] [D loss: 0.239604] [G loss: 0.400663]\n",
      "[Epoch 89/100] [Batch 329/347] [D loss: 0.234113] [G loss: 0.416574]\n",
      "[Epoch 89/100] [Batch 330/347] [D loss: 0.224696] [G loss: 0.428308]\n",
      "[Epoch 89/100] [Batch 331/347] [D loss: 0.239825] [G loss: 0.454432]\n",
      "[Epoch 89/100] [Batch 332/347] [D loss: 0.309836] [G loss: 0.488088]\n",
      "[Epoch 89/100] [Batch 333/347] [D loss: 0.260931] [G loss: 0.500004]\n",
      "[Epoch 89/100] [Batch 334/347] [D loss: 0.254396] [G loss: 0.501321]\n",
      "[Epoch 89/100] [Batch 335/347] [D loss: 0.257501] [G loss: 0.510253]\n",
      "[Epoch 89/100] [Batch 336/347] [D loss: 0.251287] [G loss: 0.542408]\n",
      "[Epoch 89/100] [Batch 337/347] [D loss: 0.312321] [G loss: 0.543645]\n",
      "[Epoch 89/100] [Batch 338/347] [D loss: 0.357436] [G loss: 0.540549]\n",
      "[Epoch 89/100] [Batch 339/347] [D loss: 0.327546] [G loss: 0.528068]\n",
      "[Epoch 89/100] [Batch 340/347] [D loss: 0.293997] [G loss: 0.511297]\n",
      "[Epoch 89/100] [Batch 341/347] [D loss: 0.303494] [G loss: 0.501047]\n",
      "[Epoch 89/100] [Batch 342/347] [D loss: 0.184701] [G loss: 0.487869]\n",
      "[Epoch 89/100] [Batch 343/347] [D loss: 0.152513] [G loss: 0.478052]\n",
      "[Epoch 89/100] [Batch 344/347] [D loss: 0.152494] [G loss: 0.468724]\n",
      "[Epoch 89/100] [Batch 345/347] [D loss: 0.126093] [G loss: 0.503975]\n",
      "[Epoch 89/100] [Batch 346/347] [D loss: 0.134158] [G loss: 0.499214]\n",
      "[Epoch 89/100] [Batch 347/347] [D loss: 0.129614] [G loss: 0.516797]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 90/100] [Batch 1/347] [D loss: 0.321293] [G loss: 0.627918]\n",
      "[Epoch 90/100] [Batch 2/347] [D loss: 0.368761] [G loss: 0.656895]\n",
      "[Epoch 90/100] [Batch 3/347] [D loss: 0.434373] [G loss: 0.658497]\n",
      "[Epoch 90/100] [Batch 4/347] [D loss: 0.458102] [G loss: 0.651937]\n",
      "[Epoch 90/100] [Batch 5/347] [D loss: 0.459117] [G loss: 0.620221]\n",
      "[Epoch 90/100] [Batch 6/347] [D loss: 0.352561] [G loss: 0.583071]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 90/100] [Batch 7/347] [D loss: 0.289890] [G loss: 0.550136]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 90/100] [Batch 8/347] [D loss: 0.281944] [G loss: 0.512239]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 90/100] [Batch 9/347] [D loss: 0.275598] [G loss: 0.472848]\n",
      "[Epoch 90/100] [Batch 10/347] [D loss: 0.287621] [G loss: 0.439103]\n",
      "[Epoch 90/100] [Batch 11/347] [D loss: 0.354072] [G loss: 0.413143]\n",
      "[Epoch 90/100] [Batch 12/347] [D loss: 0.355348] [G loss: 0.385924]\n",
      "[Epoch 90/100] [Batch 13/347] [D loss: 0.326087] [G loss: 0.361362]\n",
      "[Epoch 90/100] [Batch 14/347] [D loss: 0.307639] [G loss: 0.350238]\n",
      "[Epoch 90/100] [Batch 15/347] [D loss: 0.302610] [G loss: 0.343019]\n",
      "[Epoch 90/100] [Batch 16/347] [D loss: 0.298715] [G loss: 0.343037]\n",
      "[Epoch 90/100] [Batch 17/347] [D loss: 0.305689] [G loss: 0.347158]\n",
      "[Epoch 90/100] [Batch 18/347] [D loss: 0.324977] [G loss: 0.348075]\n",
      "[Epoch 90/100] [Batch 19/347] [D loss: 0.324791] [G loss: 0.359117]\n",
      "[Epoch 90/100] [Batch 20/347] [D loss: 0.341015] [G loss: 0.373542]\n",
      "[Epoch 90/100] [Batch 21/347] [D loss: 0.287688] [G loss: 0.383853]\n",
      "[Epoch 90/100] [Batch 22/347] [D loss: 0.283595] [G loss: 0.407385]\n",
      "[Epoch 90/100] [Batch 23/347] [D loss: 0.282036] [G loss: 0.428062]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 90/100] [Batch 24/347] [D loss: 0.246919] [G loss: 0.455904]\n",
      "[Epoch 90/100] [Batch 25/347] [D loss: 0.160905] [G loss: 0.480444]\n",
      "[Epoch 90/100] [Batch 26/347] [D loss: 0.152186] [G loss: 0.514615]\n",
      "[Epoch 90/100] [Batch 27/347] [D loss: 0.141198] [G loss: 0.568382]\n",
      "[Epoch 90/100] [Batch 28/347] [D loss: 0.132473] [G loss: 0.621277]\n",
      "[Epoch 90/100] [Batch 29/347] [D loss: 0.168949] [G loss: 0.620535]\n",
      "[Epoch 90/100] [Batch 30/347] [D loss: 0.148908] [G loss: 0.673604]\n",
      "[Epoch 90/100] [Batch 31/347] [D loss: 0.149449] [G loss: 0.726979]\n",
      "[Epoch 90/100] [Batch 32/347] [D loss: 0.164596] [G loss: 0.738623]\n",
      "[Epoch 90/100] [Batch 33/347] [D loss: 0.183449] [G loss: 0.777216]\n",
      "[Epoch 90/100] [Batch 34/347] [D loss: 0.262228] [G loss: 0.779621]\n",
      "[Epoch 90/100] [Batch 35/347] [D loss: 0.283024] [G loss: 0.766546]\n",
      "[Epoch 90/100] [Batch 36/347] [D loss: 0.334621] [G loss: 0.746539]\n",
      "[Epoch 90/100] [Batch 37/347] [D loss: 0.344997] [G loss: 0.743331]\n",
      "[Epoch 90/100] [Batch 38/347] [D loss: 0.337629] [G loss: 0.732374]\n",
      "[Epoch 90/100] [Batch 39/347] [D loss: 0.332621] [G loss: 0.661189]\n",
      "[Epoch 90/100] [Batch 40/347] [D loss: 0.346732] [G loss: 0.591391]\n",
      "[Epoch 90/100] [Batch 41/347] [D loss: 0.341418] [G loss: 0.534811]\n",
      "[Epoch 90/100] [Batch 42/347] [D loss: 0.308179] [G loss: 0.491969]\n",
      "[Epoch 90/100] [Batch 43/347] [D loss: 0.324679] [G loss: 0.450731]\n",
      "[Epoch 90/100] [Batch 44/347] [D loss: 0.287954] [G loss: 0.424616]\n",
      "[Epoch 90/100] [Batch 45/347] [D loss: 0.266657] [G loss: 0.382395]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 90/100] [Batch 46/347] [D loss: 0.230611] [G loss: 0.340807]\n",
      "[Epoch 90/100] [Batch 47/347] [D loss: 0.242111] [G loss: 0.329515]\n",
      "[Epoch 90/100] [Batch 48/347] [D loss: 0.227088] [G loss: 0.352652]\n",
      "[Epoch 90/100] [Batch 49/347] [D loss: 0.222255] [G loss: 0.380278]\n",
      "[Epoch 90/100] [Batch 50/347] [D loss: 0.238406] [G loss: 0.393654]\n",
      "[Epoch 90/100] [Batch 51/347] [D loss: 0.199779] [G loss: 0.473805]\n",
      "[Epoch 90/100] [Batch 52/347] [D loss: 0.274228] [G loss: 0.468348]\n",
      "[Epoch 90/100] [Batch 53/347] [D loss: 0.302116] [G loss: 0.502220]\n",
      "[Epoch 90/100] [Batch 54/347] [D loss: 0.292866] [G loss: 0.569543]\n",
      "[Epoch 90/100] [Batch 55/347] [D loss: 0.293809] [G loss: 0.621197]\n",
      "[Epoch 90/100] [Batch 56/347] [D loss: 0.238762] [G loss: 0.767872]\n",
      "[Epoch 90/100] [Batch 57/347] [D loss: 0.148472] [G loss: 0.899749]\n",
      "[Epoch 90/100] [Batch 58/347] [D loss: 0.154341] [G loss: 0.934480]\n",
      "[Epoch 90/100] [Batch 59/347] [D loss: 0.166469] [G loss: 0.936483]\n",
      "[Epoch 90/100] [Batch 60/347] [D loss: 0.191429] [G loss: 0.913363]\n",
      "[Epoch 90/100] [Batch 61/347] [D loss: 0.235490] [G loss: 0.854893]\n",
      "[Epoch 90/100] [Batch 62/347] [D loss: 0.223359] [G loss: 0.841964]\n",
      "[Epoch 90/100] [Batch 63/347] [D loss: 0.187717] [G loss: 0.814388]\n",
      "[Epoch 90/100] [Batch 64/347] [D loss: 0.141344] [G loss: 0.742436]\n",
      "[Epoch 90/100] [Batch 65/347] [D loss: 0.080921] [G loss: 0.732123]\n",
      "[Epoch 90/100] [Batch 66/347] [D loss: 0.093658] [G loss: 0.690084]\n",
      "[Epoch 90/100] [Batch 67/347] [D loss: 0.115102] [G loss: 0.643351]\n",
      "[Epoch 90/100] [Batch 68/347] [D loss: 0.135104] [G loss: 0.612911]\n",
      "[Epoch 90/100] [Batch 69/347] [D loss: 0.210116] [G loss: 0.527887]\n",
      "[Epoch 90/100] [Batch 70/347] [D loss: 0.208788] [G loss: 0.525635]\n",
      "[Epoch 90/100] [Batch 71/347] [D loss: 0.179421] [G loss: 0.552548]\n",
      "[Epoch 90/100] [Batch 72/347] [D loss: 0.175326] [G loss: 0.589036]\n",
      "[Epoch 90/100] [Batch 73/347] [D loss: 0.277301] [G loss: 0.621897]\n",
      "[Epoch 90/100] [Batch 74/347] [D loss: 0.268607] [G loss: 0.636320]\n",
      "[Epoch 90/100] [Batch 75/347] [D loss: 0.274023] [G loss: 0.630428]\n",
      "[Epoch 90/100] [Batch 76/347] [D loss: 0.276168] [G loss: 0.616114]\n",
      "[Epoch 90/100] [Batch 77/347] [D loss: 0.279442] [G loss: 0.697304]\n",
      "[Epoch 90/100] [Batch 78/347] [D loss: 0.301382] [G loss: 0.688744]\n",
      "[Epoch 90/100] [Batch 79/347] [D loss: 0.290606] [G loss: 0.658506]\n",
      "[Epoch 90/100] [Batch 80/347] [D loss: 0.185056] [G loss: 0.618118]\n",
      "[Epoch 90/100] [Batch 81/347] [D loss: 0.170298] [G loss: 0.612204]\n",
      "[Epoch 90/100] [Batch 82/347] [D loss: 0.141796] [G loss: 0.681123]\n",
      "[Epoch 90/100] [Batch 83/347] [D loss: 0.144885] [G loss: 0.703407]\n",
      "[Epoch 90/100] [Batch 84/347] [D loss: 0.342982] [G loss: 0.650414]\n",
      "[Epoch 90/100] [Batch 85/347] [D loss: 0.468530] [G loss: 0.608191]\n",
      "[Epoch 90/100] [Batch 86/347] [D loss: 0.471675] [G loss: 0.564440]\n",
      "[Epoch 90/100] [Batch 87/347] [D loss: 0.463936] [G loss: 0.527210]\n",
      "[Epoch 90/100] [Batch 88/347] [D loss: 0.453942] [G loss: 0.502577]\n",
      "[Epoch 90/100] [Batch 89/347] [D loss: 0.419320] [G loss: 0.494394]\n",
      "[Epoch 90/100] [Batch 90/347] [D loss: 0.405955] [G loss: 0.437945]\n",
      "[Epoch 90/100] [Batch 91/347] [D loss: 0.407312] [G loss: 0.384761]\n",
      "[Epoch 90/100] [Batch 92/347] [D loss: 0.413199] [G loss: 0.360740]\n",
      "[Epoch 90/100] [Batch 93/347] [D loss: 0.411249] [G loss: 0.341751]\n",
      "[Epoch 90/100] [Batch 94/347] [D loss: 0.399911] [G loss: 0.319494]\n",
      "[Epoch 90/100] [Batch 95/347] [D loss: 0.388510] [G loss: 0.308267]\n",
      "[Epoch 90/100] [Batch 96/347] [D loss: 0.390901] [G loss: 0.307141]\n",
      "[Epoch 90/100] [Batch 97/347] [D loss: 0.384475] [G loss: 0.311090]\n",
      "[Epoch 90/100] [Batch 98/347] [D loss: 0.367112] [G loss: 0.320700]\n",
      "[Epoch 90/100] [Batch 99/347] [D loss: 0.361291] [G loss: 0.341891]\n",
      "[Epoch 90/100] [Batch 100/347] [D loss: 0.350546] [G loss: 0.366066]\n",
      "[Epoch 90/100] [Batch 101/347] [D loss: 0.350625] [G loss: 0.390417]\n",
      "[Epoch 90/100] [Batch 102/347] [D loss: 0.426067] [G loss: 0.428601]\n",
      "[Epoch 90/100] [Batch 103/347] [D loss: 0.424680] [G loss: 0.464730]\n",
      "[Epoch 90/100] [Batch 104/347] [D loss: 0.387937] [G loss: 0.486836]\n",
      "[Epoch 90/100] [Batch 105/347] [D loss: 0.312067] [G loss: 0.514259]\n",
      "[Epoch 90/100] [Batch 106/347] [D loss: 0.189578] [G loss: 0.599727]\n",
      "[Epoch 90/100] [Batch 107/347] [D loss: 0.149146] [G loss: 0.724866]\n",
      "[Epoch 90/100] [Batch 108/347] [D loss: 0.107485] [G loss: 0.904174]\n",
      "[Epoch 90/100] [Batch 109/347] [D loss: 0.051932] [G loss: 1.005770]\n",
      "[Epoch 90/100] [Batch 110/347] [D loss: 0.215019] [G loss: 0.621392]\n",
      "[Epoch 90/100] [Batch 111/347] [D loss: 0.183007] [G loss: 0.731426]\n",
      "[Epoch 90/100] [Batch 112/347] [D loss: 0.160551] [G loss: 0.837008]\n",
      "[Epoch 90/100] [Batch 113/347] [D loss: 0.487040] [G loss: 0.896803]\n",
      "[Epoch 90/100] [Batch 114/347] [D loss: 0.698370] [G loss: 0.996355]\n",
      "[Epoch 90/100] [Batch 115/347] [D loss: 0.795447] [G loss: 0.982077]\n",
      "[Epoch 90/100] [Batch 116/347] [D loss: 0.612924] [G loss: 0.889436]\n",
      "[Epoch 90/100] [Batch 117/347] [D loss: 0.513099] [G loss: 0.905636]\n",
      "[Epoch 90/100] [Batch 118/347] [D loss: 0.262422] [G loss: 0.991851]\n",
      "[Epoch 90/100] [Batch 119/347] [D loss: 0.198949] [G loss: 0.892431]\n",
      "[Epoch 90/100] [Batch 120/347] [D loss: 0.161717] [G loss: 0.686741]\n",
      "[Epoch 90/100] [Batch 121/347] [D loss: 0.157468] [G loss: 0.547666]\n",
      "[Epoch 90/100] [Batch 122/347] [D loss: 0.308777] [G loss: 0.465462]\n",
      "[Epoch 90/100] [Batch 123/347] [D loss: 0.370080] [G loss: 0.407500]\n",
      "[Epoch 90/100] [Batch 124/347] [D loss: 0.322245] [G loss: 0.368903]\n",
      "[Epoch 90/100] [Batch 125/347] [D loss: 0.316861] [G loss: 0.357839]\n",
      "[Epoch 90/100] [Batch 126/347] [D loss: 0.270107] [G loss: 0.385882]\n",
      "[Epoch 90/100] [Batch 127/347] [D loss: 0.245799] [G loss: 0.412991]\n",
      "[Epoch 90/100] [Batch 128/347] [D loss: 0.266562] [G loss: 0.403647]\n",
      "[Epoch 90/100] [Batch 129/347] [D loss: 0.278180] [G loss: 0.435148]\n",
      "[Epoch 90/100] [Batch 130/347] [D loss: 0.279149] [G loss: 0.478947]\n",
      "[Epoch 90/100] [Batch 131/347] [D loss: 0.219959] [G loss: 0.568912]\n",
      "[Epoch 90/100] [Batch 132/347] [D loss: 0.163202] [G loss: 0.691390]\n",
      "[Epoch 90/100] [Batch 133/347] [D loss: 0.154419] [G loss: 0.749227]\n",
      "[Epoch 90/100] [Batch 134/347] [D loss: 0.206207] [G loss: 0.650605]\n",
      "[Epoch 90/100] [Batch 135/347] [D loss: 0.163539] [G loss: 0.709422]\n",
      "[Epoch 90/100] [Batch 136/347] [D loss: 0.097285] [G loss: 0.848026]\n",
      "[Epoch 90/100] [Batch 137/347] [D loss: 0.472482] [G loss: 0.850021]\n",
      "[Epoch 90/100] [Batch 138/347] [D loss: 0.617442] [G loss: 0.862757]\n",
      "[Epoch 90/100] [Batch 139/347] [D loss: 0.721506] [G loss: 0.857788]\n",
      "[Epoch 90/100] [Batch 140/347] [D loss: 0.775135] [G loss: 0.828585]\n",
      "[Epoch 90/100] [Batch 141/347] [D loss: 0.667631] [G loss: 0.910722]\n",
      "[Epoch 90/100] [Batch 142/347] [D loss: 0.593562] [G loss: 0.966934]\n",
      "[Epoch 90/100] [Batch 143/347] [D loss: 0.417821] [G loss: 0.934893]\n",
      "[Epoch 90/100] [Batch 144/347] [D loss: 0.293169] [G loss: 0.828736]\n",
      "[Epoch 90/100] [Batch 145/347] [D loss: 0.278176] [G loss: 0.625489]\n",
      "[Epoch 90/100] [Batch 146/347] [D loss: 0.281582] [G loss: 0.491035]\n",
      "[Epoch 90/100] [Batch 147/347] [D loss: 0.307543] [G loss: 0.403926]\n",
      "[Epoch 90/100] [Batch 148/347] [D loss: 0.354335] [G loss: 0.343276]\n",
      "[Epoch 90/100] [Batch 149/347] [D loss: 0.349285] [G loss: 0.289508]\n",
      "[Epoch 90/100] [Batch 150/347] [D loss: 0.353294] [G loss: 0.265686]\n",
      "[Epoch 90/100] [Batch 151/347] [D loss: 0.348334] [G loss: 0.267087]\n",
      "[Epoch 90/100] [Batch 152/347] [D loss: 0.342449] [G loss: 0.266143]\n",
      "[Epoch 90/100] [Batch 153/347] [D loss: 0.360047] [G loss: 0.257136]\n",
      "[Epoch 90/100] [Batch 154/347] [D loss: 0.358737] [G loss: 0.265112]\n",
      "[Epoch 90/100] [Batch 155/347] [D loss: 0.347817] [G loss: 0.288996]\n",
      "[Epoch 90/100] [Batch 156/347] [D loss: 0.328270] [G loss: 0.316894]\n",
      "[Epoch 90/100] [Batch 157/347] [D loss: 0.282010] [G loss: 0.375240]\n",
      "[Epoch 90/100] [Batch 158/347] [D loss: 0.236029] [G loss: 0.449030]\n",
      "[Epoch 90/100] [Batch 159/347] [D loss: 0.218209] [G loss: 0.520033]\n",
      "[Epoch 90/100] [Batch 160/347] [D loss: 0.177513] [G loss: 0.623866]\n",
      "[Epoch 90/100] [Batch 161/347] [D loss: 0.152601] [G loss: 0.706253]\n",
      "[Epoch 90/100] [Batch 162/347] [D loss: 0.199011] [G loss: 0.688758]\n",
      "[Epoch 90/100] [Batch 163/347] [D loss: 0.210408] [G loss: 0.735661]\n",
      "[Epoch 90/100] [Batch 164/347] [D loss: 0.229034] [G loss: 0.759128]\n",
      "[Epoch 90/100] [Batch 165/347] [D loss: 0.224539] [G loss: 0.794863]\n",
      "[Epoch 90/100] [Batch 166/347] [D loss: 0.219408] [G loss: 0.879255]\n",
      "[Epoch 90/100] [Batch 167/347] [D loss: 0.238377] [G loss: 0.941995]\n",
      "[Epoch 90/100] [Batch 168/347] [D loss: 0.230779] [G loss: 0.945619]\n",
      "[Epoch 90/100] [Batch 169/347] [D loss: 0.570967] [G loss: 0.909866]\n",
      "[Epoch 90/100] [Batch 170/347] [D loss: 0.732130] [G loss: 0.850040]\n",
      "[Epoch 90/100] [Batch 171/347] [D loss: 0.597910] [G loss: 0.769935]\n",
      "[Epoch 90/100] [Batch 172/347] [D loss: 0.532295] [G loss: 0.676205]\n",
      "[Epoch 90/100] [Batch 173/347] [D loss: 0.450174] [G loss: 0.682668]\n",
      "[Epoch 90/100] [Batch 174/347] [D loss: 0.343398] [G loss: 0.686915]\n",
      "[Epoch 90/100] [Batch 175/347] [D loss: 0.401299] [G loss: 0.579611]\n",
      "[Epoch 90/100] [Batch 176/347] [D loss: 0.411413] [G loss: 0.489024]\n",
      "[Epoch 90/100] [Batch 177/347] [D loss: 0.392904] [G loss: 0.418529]\n",
      "[Epoch 90/100] [Batch 178/347] [D loss: 0.380194] [G loss: 0.358479]\n",
      "[Epoch 90/100] [Batch 179/347] [D loss: 0.381460] [G loss: 0.322240]\n",
      "[Epoch 90/100] [Batch 180/347] [D loss: 0.377300] [G loss: 0.303636]\n",
      "[Epoch 90/100] [Batch 181/347] [D loss: 0.383977] [G loss: 0.289051]\n",
      "[Epoch 90/100] [Batch 182/347] [D loss: 0.400643] [G loss: 0.277623]\n",
      "[Epoch 90/100] [Batch 183/347] [D loss: 0.410437] [G loss: 0.276177]\n",
      "[Epoch 90/100] [Batch 184/347] [D loss: 0.447539] [G loss: 0.278402]\n",
      "[Epoch 90/100] [Batch 185/347] [D loss: 0.462850] [G loss: 0.282828]\n",
      "[Epoch 90/100] [Batch 186/347] [D loss: 0.435531] [G loss: 0.296723]\n",
      "[Epoch 90/100] [Batch 187/347] [D loss: 0.411906] [G loss: 0.311839]\n",
      "[Epoch 90/100] [Batch 188/347] [D loss: 0.364618] [G loss: 0.336906]\n",
      "[Epoch 90/100] [Batch 189/347] [D loss: 0.311150] [G loss: 0.362565]\n",
      "[Epoch 90/100] [Batch 190/347] [D loss: 0.293687] [G loss: 0.390423]\n",
      "[Epoch 90/100] [Batch 191/347] [D loss: 0.286939] [G loss: 0.420404]\n",
      "[Epoch 90/100] [Batch 192/347] [D loss: 0.293277] [G loss: 0.452566]\n",
      "[Epoch 90/100] [Batch 193/347] [D loss: 0.382020] [G loss: 0.473699]\n",
      "[Epoch 90/100] [Batch 194/347] [D loss: 0.362480] [G loss: 0.501489]\n",
      "[Epoch 90/100] [Batch 195/347] [D loss: 0.339741] [G loss: 0.531022]\n",
      "[Epoch 90/100] [Batch 196/347] [D loss: 0.287978] [G loss: 0.557781]\n",
      "[Epoch 90/100] [Batch 197/347] [D loss: 0.279447] [G loss: 0.604644]\n",
      "[Epoch 90/100] [Batch 198/347] [D loss: 0.269789] [G loss: 0.631028]\n",
      "[Epoch 90/100] [Batch 199/347] [D loss: 0.273043] [G loss: 0.640974]\n",
      "[Epoch 90/100] [Batch 200/347] [D loss: 0.390695] [G loss: 0.613804]\n",
      "[Epoch 90/100] [Batch 201/347] [D loss: 0.445886] [G loss: 0.602877]\n",
      "[Epoch 90/100] [Batch 202/347] [D loss: 0.486727] [G loss: 0.574981]\n",
      "[Epoch 90/100] [Batch 203/347] [D loss: 0.511069] [G loss: 0.536586]\n",
      "[Epoch 90/100] [Batch 204/347] [D loss: 0.457074] [G loss: 0.525690]\n",
      "[Epoch 90/100] [Batch 205/347] [D loss: 0.419213] [G loss: 0.506752]\n",
      "[Epoch 90/100] [Batch 206/347] [D loss: 0.401631] [G loss: 0.475568]\n",
      "[Epoch 90/100] [Batch 207/347] [D loss: 0.289816] [G loss: 0.449951]\n",
      "[Epoch 90/100] [Batch 208/347] [D loss: 0.279307] [G loss: 0.427356]\n",
      "[Epoch 90/100] [Batch 209/347] [D loss: 0.288551] [G loss: 0.398752]\n",
      "[Epoch 90/100] [Batch 210/347] [D loss: 0.238465] [G loss: 0.390391]\n",
      "[Epoch 90/100] [Batch 211/347] [D loss: 0.255926] [G loss: 0.374057]\n",
      "[Epoch 90/100] [Batch 212/347] [D loss: 0.273668] [G loss: 0.385625]\n",
      "[Epoch 90/100] [Batch 213/347] [D loss: 0.242949] [G loss: 0.438491]\n",
      "[Epoch 90/100] [Batch 214/347] [D loss: 0.245372] [G loss: 0.449785]\n",
      "[Epoch 90/100] [Batch 215/347] [D loss: 0.202206] [G loss: 0.515793]\n",
      "[Epoch 90/100] [Batch 216/347] [D loss: 0.409865] [G loss: 0.385110]\n",
      "[Epoch 90/100] [Batch 217/347] [D loss: 0.446536] [G loss: 0.474151]\n",
      "[Epoch 90/100] [Batch 218/347] [D loss: 0.501042] [G loss: 0.540715]\n",
      "[Epoch 90/100] [Batch 219/347] [D loss: 0.461789] [G loss: 0.597044]\n",
      "[Epoch 90/100] [Batch 220/347] [D loss: 0.342592] [G loss: 0.818092]\n",
      "[Epoch 90/100] [Batch 221/347] [D loss: 0.384817] [G loss: 0.901145]\n",
      "[Epoch 90/100] [Batch 222/347] [D loss: 0.418112] [G loss: 0.930070]\n",
      "[Epoch 90/100] [Batch 223/347] [D loss: 0.424554] [G loss: 0.897551]\n",
      "[Epoch 90/100] [Batch 224/347] [D loss: 0.472600] [G loss: 0.842744]\n",
      "[Epoch 90/100] [Batch 225/347] [D loss: 0.514032] [G loss: 0.734939]\n",
      "[Epoch 90/100] [Batch 226/347] [D loss: 0.481298] [G loss: 0.605520]\n",
      "[Epoch 90/100] [Batch 227/347] [D loss: 0.490465] [G loss: 0.476240]\n",
      "[Epoch 90/100] [Batch 228/347] [D loss: 0.463239] [G loss: 0.396363]\n",
      "[Epoch 90/100] [Batch 229/347] [D loss: 0.410853] [G loss: 0.349501]\n",
      "[Epoch 90/100] [Batch 230/347] [D loss: 0.420572] [G loss: 0.313473]\n",
      "[Epoch 90/100] [Batch 231/347] [D loss: 0.388069] [G loss: 0.273836]\n",
      "[Epoch 90/100] [Batch 232/347] [D loss: 0.383102] [G loss: 0.246746]\n",
      "[Epoch 90/100] [Batch 233/347] [D loss: 0.369624] [G loss: 0.233744]\n",
      "[Epoch 90/100] [Batch 234/347] [D loss: 0.372923] [G loss: 0.234698]\n",
      "[Epoch 90/100] [Batch 235/347] [D loss: 0.385314] [G loss: 0.253034]\n",
      "[Epoch 90/100] [Batch 236/347] [D loss: 0.375639] [G loss: 0.277666]\n",
      "[Epoch 90/100] [Batch 237/347] [D loss: 0.417167] [G loss: 0.288278]\n",
      "[Epoch 90/100] [Batch 238/347] [D loss: 0.454193] [G loss: 0.291803]\n",
      "[Epoch 90/100] [Batch 239/347] [D loss: 0.442175] [G loss: 0.310364]\n",
      "[Epoch 90/100] [Batch 240/347] [D loss: 0.446441] [G loss: 0.337552]\n",
      "[Epoch 90/100] [Batch 241/347] [D loss: 0.419045] [G loss: 0.397617]\n",
      "[Epoch 90/100] [Batch 242/347] [D loss: 0.386726] [G loss: 0.551500]\n",
      "[Epoch 90/100] [Batch 243/347] [D loss: 0.314480] [G loss: 0.586428]\n",
      "[Epoch 90/100] [Batch 244/347] [D loss: 0.277456] [G loss: 0.620452]\n",
      "[Epoch 90/100] [Batch 245/347] [D loss: 0.283532] [G loss: 0.646526]\n",
      "[Epoch 90/100] [Batch 246/347] [D loss: 0.296176] [G loss: 0.676159]\n",
      "[Epoch 90/100] [Batch 247/347] [D loss: 0.381304] [G loss: 0.644486]\n",
      "[Epoch 90/100] [Batch 248/347] [D loss: 0.418552] [G loss: 0.589581]\n",
      "[Epoch 90/100] [Batch 249/347] [D loss: 0.375960] [G loss: 0.592243]\n",
      "[Epoch 90/100] [Batch 250/347] [D loss: 0.343118] [G loss: 0.584507]\n",
      "[Epoch 90/100] [Batch 251/347] [D loss: 0.302985] [G loss: 0.594563]\n",
      "[Epoch 90/100] [Batch 252/347] [D loss: 0.285010] [G loss: 0.579048]\n",
      "[Epoch 90/100] [Batch 253/347] [D loss: 0.222914] [G loss: 0.534097]\n",
      "[Epoch 90/100] [Batch 254/347] [D loss: 0.220498] [G loss: 0.513220]\n",
      "[Epoch 90/100] [Batch 255/347] [D loss: 0.232285] [G loss: 0.491382]\n",
      "[Epoch 90/100] [Batch 256/347] [D loss: 0.239809] [G loss: 0.473914]\n",
      "[Epoch 90/100] [Batch 257/347] [D loss: 0.261443] [G loss: 0.416620]\n",
      "[Epoch 90/100] [Batch 258/347] [D loss: 0.243723] [G loss: 0.405148]\n",
      "[Epoch 90/100] [Batch 259/347] [D loss: 0.246946] [G loss: 0.410892]\n",
      "[Epoch 90/100] [Batch 260/347] [D loss: 0.243750] [G loss: 0.426662]\n",
      "[Epoch 90/100] [Batch 261/347] [D loss: 0.214289] [G loss: 0.479693]\n",
      "[Epoch 90/100] [Batch 262/347] [D loss: 0.185835] [G loss: 0.516070]\n",
      "[Epoch 90/100] [Batch 263/347] [D loss: 0.171838] [G loss: 0.556420]\n",
      "[Epoch 90/100] [Batch 264/347] [D loss: 0.160970] [G loss: 0.617268]\n",
      "[Epoch 90/100] [Batch 265/347] [D loss: 0.170511] [G loss: 0.638499]\n",
      "[Epoch 90/100] [Batch 266/347] [D loss: 0.271506] [G loss: 0.610661]\n",
      "[Epoch 90/100] [Batch 267/347] [D loss: 0.301669] [G loss: 0.620469]\n",
      "[Epoch 90/100] [Batch 268/347] [D loss: 0.309746] [G loss: 0.645200]\n",
      "[Epoch 90/100] [Batch 269/347] [D loss: 0.313816] [G loss: 0.668730]\n",
      "[Epoch 90/100] [Batch 270/347] [D loss: 0.330263] [G loss: 0.744942]\n",
      "[Epoch 90/100] [Batch 271/347] [D loss: 0.261756] [G loss: 0.800635]\n",
      "[Epoch 90/100] [Batch 272/347] [D loss: 0.264731] [G loss: 0.850754]\n",
      "[Epoch 90/100] [Batch 273/347] [D loss: 0.235386] [G loss: 0.884699]\n",
      "[Epoch 90/100] [Batch 274/347] [D loss: 0.207584] [G loss: 0.917733]\n",
      "[Epoch 90/100] [Batch 275/347] [D loss: 0.166631] [G loss: 0.934107]\n",
      "[Epoch 90/100] [Batch 276/347] [D loss: 0.653682] [G loss: 0.409298]\n",
      "[Epoch 90/100] [Batch 277/347] [D loss: 0.700906] [G loss: 0.423583]\n",
      "[Epoch 90/100] [Batch 278/347] [D loss: 0.763459] [G loss: 0.451704]\n",
      "[Epoch 90/100] [Batch 279/347] [D loss: 0.778446] [G loss: 0.440727]\n",
      "[Epoch 90/100] [Batch 280/347] [D loss: 0.708557] [G loss: 0.792188]\n",
      "[Epoch 90/100] [Batch 281/347] [D loss: 0.707296] [G loss: 0.920377]\n",
      "[Epoch 90/100] [Batch 282/347] [D loss: 0.617918] [G loss: 0.898194]\n",
      "[Epoch 90/100] [Batch 283/347] [D loss: 0.491308] [G loss: 0.823296]\n",
      "[Epoch 90/100] [Batch 284/347] [D loss: 0.374298] [G loss: 0.681051]\n",
      "[Epoch 90/100] [Batch 285/347] [D loss: 0.349676] [G loss: 0.548465]\n",
      "[Epoch 90/100] [Batch 286/347] [D loss: 0.316139] [G loss: 0.423765]\n",
      "[Epoch 90/100] [Batch 287/347] [D loss: 0.310261] [G loss: 0.338801]\n",
      "[Epoch 90/100] [Batch 288/347] [D loss: 0.319743] [G loss: 0.283517]\n",
      "[Epoch 90/100] [Batch 289/347] [D loss: 0.323871] [G loss: 0.240285]\n",
      "[Epoch 90/100] [Batch 290/347] [D loss: 0.376162] [G loss: 0.216041]\n",
      "[Epoch 90/100] [Batch 291/347] [D loss: 0.391601] [G loss: 0.215964]\n",
      "[Epoch 90/100] [Batch 292/347] [D loss: 0.399996] [G loss: 0.221098]\n",
      "[Epoch 90/100] [Batch 293/347] [D loss: 0.427127] [G loss: 0.244803]\n",
      "[Epoch 90/100] [Batch 294/347] [D loss: 0.392301] [G loss: 0.274018]\n",
      "[Epoch 90/100] [Batch 295/347] [D loss: 0.347029] [G loss: 0.301196]\n",
      "[Epoch 90/100] [Batch 296/347] [D loss: 0.304199] [G loss: 0.336030]\n",
      "[Epoch 90/100] [Batch 297/347] [D loss: 0.432731] [G loss: 0.314202]\n",
      "[Epoch 90/100] [Batch 298/347] [D loss: 0.422278] [G loss: 0.336837]\n",
      "[Epoch 90/100] [Batch 299/347] [D loss: 0.405255] [G loss: 0.388011]\n",
      "[Epoch 90/100] [Batch 300/347] [D loss: 0.389372] [G loss: 0.442299]\n",
      "[Epoch 90/100] [Batch 301/347] [D loss: 0.342969] [G loss: 0.621642]\n",
      "[Epoch 90/100] [Batch 302/347] [D loss: 0.330648] [G loss: 0.753596]\n",
      "[Epoch 90/100] [Batch 303/347] [D loss: 0.369950] [G loss: 0.757461]\n",
      "[Epoch 90/100] [Batch 304/347] [D loss: 0.239978] [G loss: 0.745187]\n",
      "[Epoch 90/100] [Batch 305/347] [D loss: 0.115851] [G loss: 0.761232]\n",
      "[Epoch 90/100] [Batch 306/347] [D loss: 0.108131] [G loss: 0.787903]\n",
      "[Epoch 90/100] [Batch 307/347] [D loss: 0.094202] [G loss: 0.814717]\n",
      "[Epoch 90/100] [Batch 308/347] [D loss: 0.201107] [G loss: 0.766094]\n",
      "[Epoch 90/100] [Batch 309/347] [D loss: 0.469287] [G loss: 0.607859]\n",
      "[Epoch 90/100] [Batch 310/347] [D loss: 0.738917] [G loss: 0.596821]\n",
      "[Epoch 90/100] [Batch 311/347] [D loss: 0.603123] [G loss: 0.540522]\n",
      "[Epoch 90/100] [Batch 312/347] [D loss: 0.418574] [G loss: 0.496535]\n",
      "[Epoch 90/100] [Batch 313/347] [D loss: 0.288263] [G loss: 0.616616]\n",
      "[Epoch 90/100] [Batch 314/347] [D loss: 0.255069] [G loss: 0.667473]\n",
      "[Epoch 90/100] [Batch 315/347] [D loss: 0.249193] [G loss: 0.628421]\n",
      "[Epoch 90/100] [Batch 316/347] [D loss: 0.299925] [G loss: 0.493123]\n",
      "[Epoch 90/100] [Batch 317/347] [D loss: 0.318669] [G loss: 0.428712]\n",
      "[Epoch 90/100] [Batch 318/347] [D loss: 0.303053] [G loss: 0.423997]\n",
      "[Epoch 90/100] [Batch 319/347] [D loss: 0.274686] [G loss: 0.426202]\n",
      "[Epoch 90/100] [Batch 320/347] [D loss: 0.284274] [G loss: 0.411355]\n",
      "[Epoch 90/100] [Batch 321/347] [D loss: 0.270550] [G loss: 0.398095]\n",
      "[Epoch 90/100] [Batch 322/347] [D loss: 0.282869] [G loss: 0.374722]\n",
      "[Epoch 90/100] [Batch 323/347] [D loss: 0.240443] [G loss: 0.356992]\n",
      "[Epoch 90/100] [Batch 324/347] [D loss: 0.236509] [G loss: 0.361999]\n",
      "[Epoch 90/100] [Batch 325/347] [D loss: 0.245832] [G loss: 0.356399]\n",
      "[Epoch 90/100] [Batch 326/347] [D loss: 0.246286] [G loss: 0.367019]\n",
      "[Epoch 90/100] [Batch 327/347] [D loss: 0.256690] [G loss: 0.363973]\n",
      "[Epoch 90/100] [Batch 328/347] [D loss: 0.270751] [G loss: 0.361396]\n",
      "[Epoch 90/100] [Batch 329/347] [D loss: 0.258635] [G loss: 0.390029]\n",
      "[Epoch 90/100] [Batch 330/347] [D loss: 0.239624] [G loss: 0.434265]\n",
      "[Epoch 90/100] [Batch 331/347] [D loss: 0.267209] [G loss: 0.465161]\n",
      "[Epoch 90/100] [Batch 332/347] [D loss: 0.354561] [G loss: 0.514025]\n",
      "[Epoch 90/100] [Batch 333/347] [D loss: 0.289027] [G loss: 0.536029]\n",
      "[Epoch 90/100] [Batch 334/347] [D loss: 0.281353] [G loss: 0.539367]\n",
      "[Epoch 90/100] [Batch 335/347] [D loss: 0.290082] [G loss: 0.550768]\n",
      "[Epoch 90/100] [Batch 336/347] [D loss: 0.266175] [G loss: 0.658643]\n",
      "[Epoch 90/100] [Batch 337/347] [D loss: 0.350153] [G loss: 0.660626]\n",
      "[Epoch 90/100] [Batch 338/347] [D loss: 0.419990] [G loss: 0.648331]\n",
      "[Epoch 90/100] [Batch 339/347] [D loss: 0.378528] [G loss: 0.625098]\n",
      "[Epoch 90/100] [Batch 340/347] [D loss: 0.331458] [G loss: 0.601627]\n",
      "[Epoch 90/100] [Batch 341/347] [D loss: 0.340798] [G loss: 0.595311]\n",
      "[Epoch 90/100] [Batch 342/347] [D loss: 0.165872] [G loss: 0.582539]\n",
      "[Epoch 90/100] [Batch 343/347] [D loss: 0.125790] [G loss: 0.554864]\n",
      "[Epoch 90/100] [Batch 344/347] [D loss: 0.137041] [G loss: 0.517225]\n",
      "[Epoch 90/100] [Batch 345/347] [D loss: 0.116187] [G loss: 0.523956]\n",
      "[Epoch 90/100] [Batch 346/347] [D loss: 0.181925] [G loss: 0.445865]\n",
      "[Epoch 90/100] [Batch 347/347] [D loss: 0.209607] [G loss: 0.414913]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 1/347] [D loss: 0.350014] [G loss: 0.610593]\n",
      "[Epoch 91/100] [Batch 2/347] [D loss: 0.393267] [G loss: 0.623986]\n",
      "[Epoch 91/100] [Batch 3/347] [D loss: 0.461133] [G loss: 0.630357]\n",
      "[Epoch 91/100] [Batch 4/347] [D loss: 0.500439] [G loss: 0.609035]\n",
      "[Epoch 91/100] [Batch 5/347] [D loss: 0.483584] [G loss: 0.572643]\n",
      "[Epoch 91/100] [Batch 6/347] [D loss: 0.370698] [G loss: 0.536833]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 7/347] [D loss: 0.284700] [G loss: 0.536112]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 8/347] [D loss: 0.279522] [G loss: 0.503986]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 9/347] [D loss: 0.277159] [G loss: 0.459248]\n",
      "[Epoch 91/100] [Batch 10/347] [D loss: 0.305166] [G loss: 0.419333]\n",
      "[Epoch 91/100] [Batch 11/347] [D loss: 0.395295] [G loss: 0.383935]\n",
      "[Epoch 91/100] [Batch 12/347] [D loss: 0.398462] [G loss: 0.367797]\n",
      "[Epoch 91/100] [Batch 13/347] [D loss: 0.365725] [G loss: 0.353898]\n",
      "[Epoch 91/100] [Batch 14/347] [D loss: 0.341890] [G loss: 0.350219]\n",
      "[Epoch 91/100] [Batch 15/347] [D loss: 0.320941] [G loss: 0.359518]\n",
      "[Epoch 91/100] [Batch 16/347] [D loss: 0.308297] [G loss: 0.368734]\n",
      "[Epoch 91/100] [Batch 17/347] [D loss: 0.324753] [G loss: 0.361648]\n",
      "[Epoch 91/100] [Batch 18/347] [D loss: 0.361783] [G loss: 0.343293]\n",
      "[Epoch 91/100] [Batch 19/347] [D loss: 0.370314] [G loss: 0.344234]\n",
      "[Epoch 91/100] [Batch 20/347] [D loss: 0.388687] [G loss: 0.355871]\n",
      "[Epoch 91/100] [Batch 21/347] [D loss: 0.335888] [G loss: 0.359172]\n",
      "[Epoch 91/100] [Batch 22/347] [D loss: 0.330747] [G loss: 0.377317]\n",
      "[Epoch 91/100] [Batch 23/347] [D loss: 0.326136] [G loss: 0.399215]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 24/347] [D loss: 0.273795] [G loss: 0.436781]\n",
      "[Epoch 91/100] [Batch 25/347] [D loss: 0.189195] [G loss: 0.451737]\n",
      "[Epoch 91/100] [Batch 26/347] [D loss: 0.182577] [G loss: 0.483776]\n",
      "[Epoch 91/100] [Batch 27/347] [D loss: 0.165402] [G loss: 0.545306]\n",
      "[Epoch 91/100] [Batch 28/347] [D loss: 0.157079] [G loss: 0.602030]\n",
      "[Epoch 91/100] [Batch 29/347] [D loss: 0.238794] [G loss: 0.519515]\n",
      "[Epoch 91/100] [Batch 30/347] [D loss: 0.211944] [G loss: 0.579799]\n",
      "[Epoch 91/100] [Batch 31/347] [D loss: 0.205941] [G loss: 0.627625]\n",
      "[Epoch 91/100] [Batch 32/347] [D loss: 0.226938] [G loss: 0.626535]\n",
      "[Epoch 91/100] [Batch 33/347] [D loss: 0.240825] [G loss: 0.691332]\n",
      "[Epoch 91/100] [Batch 34/347] [D loss: 0.344460] [G loss: 0.702017]\n",
      "[Epoch 91/100] [Batch 35/347] [D loss: 0.372526] [G loss: 0.707470]\n",
      "[Epoch 91/100] [Batch 36/347] [D loss: 0.448915] [G loss: 0.710109]\n",
      "[Epoch 91/100] [Batch 37/347] [D loss: 0.464971] [G loss: 0.728861]\n",
      "[Epoch 91/100] [Batch 38/347] [D loss: 0.456181] [G loss: 0.746050]\n",
      "[Epoch 91/100] [Batch 39/347] [D loss: 0.435462] [G loss: 0.691499]\n",
      "[Epoch 91/100] [Batch 40/347] [D loss: 0.451454] [G loss: 0.627668]\n",
      "[Epoch 91/100] [Batch 41/347] [D loss: 0.418890] [G loss: 0.573018]\n",
      "[Epoch 91/100] [Batch 42/347] [D loss: 0.371866] [G loss: 0.526396]\n",
      "[Epoch 91/100] [Batch 43/347] [D loss: 0.392475] [G loss: 0.488815]\n",
      "[Epoch 91/100] [Batch 44/347] [D loss: 0.333071] [G loss: 0.471717]\n",
      "[Epoch 91/100] [Batch 45/347] [D loss: 0.296101] [G loss: 0.426728]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 46/347] [D loss: 0.248011] [G loss: 0.368159]\n",
      "[Epoch 91/100] [Batch 47/347] [D loss: 0.266136] [G loss: 0.342917]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 48/347] [D loss: 0.241273] [G loss: 0.340686]\n",
      "[Epoch 91/100] [Batch 49/347] [D loss: 0.248328] [G loss: 0.354351]\n",
      "[Epoch 91/100] [Batch 50/347] [D loss: 0.331644] [G loss: 0.312363]\n",
      "[Epoch 91/100] [Batch 51/347] [D loss: 0.290196] [G loss: 0.365415]\n",
      "[Epoch 91/100] [Batch 52/347] [D loss: 0.445409] [G loss: 0.305986]\n",
      "[Epoch 91/100] [Batch 53/347] [D loss: 0.488996] [G loss: 0.301614]\n",
      "[Epoch 91/100] [Batch 54/347] [D loss: 0.467588] [G loss: 0.327065]\n",
      "[Epoch 91/100] [Batch 55/347] [D loss: 0.461614] [G loss: 0.359210]\n",
      "[Epoch 91/100] [Batch 56/347] [D loss: 0.331285] [G loss: 0.549271]\n",
      "[Epoch 91/100] [Batch 57/347] [D loss: 0.186091] [G loss: 0.805322]\n",
      "[Epoch 91/100] [Batch 58/347] [D loss: 0.177617] [G loss: 0.879841]\n",
      "[Epoch 91/100] [Batch 59/347] [D loss: 0.188737] [G loss: 0.892950]\n",
      "[Epoch 91/100] [Batch 60/347] [D loss: 0.232543] [G loss: 0.867964]\n",
      "[Epoch 91/100] [Batch 61/347] [D loss: 0.297735] [G loss: 0.802941]\n",
      "[Epoch 91/100] [Batch 62/347] [D loss: 0.299575] [G loss: 0.792541]\n",
      "[Epoch 91/100] [Batch 63/347] [D loss: 0.263069] [G loss: 0.795750]\n",
      "[Epoch 91/100] [Batch 64/347] [D loss: 0.207001] [G loss: 0.781087]\n",
      "[Epoch 91/100] [Batch 65/347] [D loss: 0.122155] [G loss: 0.804522]\n",
      "[Epoch 91/100] [Batch 66/347] [D loss: 0.139153] [G loss: 0.764630]\n",
      "[Epoch 91/100] [Batch 67/347] [D loss: 0.180759] [G loss: 0.689812]\n",
      "[Epoch 91/100] [Batch 68/347] [D loss: 0.215951] [G loss: 0.621188]\n",
      "[Epoch 91/100] [Batch 69/347] [D loss: 0.330500] [G loss: 0.421361]\n",
      "[Epoch 91/100] [Batch 70/347] [D loss: 0.323157] [G loss: 0.424318]\n",
      "[Epoch 91/100] [Batch 71/347] [D loss: 0.267090] [G loss: 0.482853]\n",
      "[Epoch 91/100] [Batch 72/347] [D loss: 0.257499] [G loss: 0.523534]\n",
      "[Epoch 91/100] [Batch 73/347] [D loss: 0.388229] [G loss: 0.570000]\n",
      "[Epoch 91/100] [Batch 74/347] [D loss: 0.368310] [G loss: 0.588112]\n",
      "[Epoch 91/100] [Batch 75/347] [D loss: 0.380370] [G loss: 0.562772]\n",
      "[Epoch 91/100] [Batch 76/347] [D loss: 0.390526] [G loss: 0.529243]\n",
      "[Epoch 91/100] [Batch 77/347] [D loss: 0.368740] [G loss: 0.702411]\n",
      "[Epoch 91/100] [Batch 78/347] [D loss: 0.384981] [G loss: 0.711287]\n",
      "[Epoch 91/100] [Batch 79/347] [D loss: 0.371798] [G loss: 0.679149]\n",
      "[Epoch 91/100] [Batch 80/347] [D loss: 0.233624] [G loss: 0.626220]\n",
      "[Epoch 91/100] [Batch 81/347] [D loss: 0.222261] [G loss: 0.602732]\n",
      "[Epoch 91/100] [Batch 82/347] [D loss: 0.166304] [G loss: 0.739257]\n",
      "[Epoch 91/100] [Batch 83/347] [D loss: 0.170470] [G loss: 0.766899]\n",
      "[Epoch 91/100] [Batch 84/347] [D loss: 0.467833] [G loss: 0.643795]\n",
      "[Epoch 91/100] [Batch 85/347] [D loss: 0.661937] [G loss: 0.532241]\n",
      "[Epoch 91/100] [Batch 86/347] [D loss: 0.632819] [G loss: 0.461482]\n",
      "[Epoch 91/100] [Batch 87/347] [D loss: 0.588067] [G loss: 0.391930]\n",
      "[Epoch 91/100] [Batch 88/347] [D loss: 0.549287] [G loss: 0.370575]\n",
      "[Epoch 91/100] [Batch 89/347] [D loss: 0.459386] [G loss: 0.394975]\n",
      "[Epoch 91/100] [Batch 90/347] [D loss: 0.452423] [G loss: 0.349720]\n",
      "[Epoch 91/100] [Batch 91/347] [D loss: 0.459971] [G loss: 0.310179]\n",
      "[Epoch 91/100] [Batch 92/347] [D loss: 0.468677] [G loss: 0.290442]\n",
      "[Epoch 91/100] [Batch 93/347] [D loss: 0.468495] [G loss: 0.278292]\n",
      "[Epoch 91/100] [Batch 94/347] [D loss: 0.468213] [G loss: 0.261614]\n",
      "[Epoch 91/100] [Batch 95/347] [D loss: 0.460734] [G loss: 0.257584]\n",
      "[Epoch 91/100] [Batch 96/347] [D loss: 0.460824] [G loss: 0.262451]\n",
      "[Epoch 91/100] [Batch 97/347] [D loss: 0.451031] [G loss: 0.268808]\n",
      "[Epoch 91/100] [Batch 98/347] [D loss: 0.436736] [G loss: 0.278159]\n",
      "[Epoch 91/100] [Batch 99/347] [D loss: 0.425693] [G loss: 0.297263]\n",
      "[Epoch 91/100] [Batch 100/347] [D loss: 0.406156] [G loss: 0.324078]\n",
      "[Epoch 91/100] [Batch 101/347] [D loss: 0.396188] [G loss: 0.352774]\n",
      "[Epoch 91/100] [Batch 102/347] [D loss: 0.466454] [G loss: 0.379355]\n",
      "[Epoch 91/100] [Batch 103/347] [D loss: 0.458054] [G loss: 0.420520]\n",
      "[Epoch 91/100] [Batch 104/347] [D loss: 0.422419] [G loss: 0.454756]\n",
      "[Epoch 91/100] [Batch 105/347] [D loss: 0.340594] [G loss: 0.487986]\n",
      "[Epoch 91/100] [Batch 106/347] [D loss: 0.176904] [G loss: 0.592942]\n",
      "[Epoch 91/100] [Batch 107/347] [D loss: 0.130755] [G loss: 0.714974]\n",
      "[Epoch 91/100] [Batch 108/347] [D loss: 0.095712] [G loss: 0.833464]\n",
      "[Epoch 91/100] [Batch 109/347] [D loss: 0.060437] [G loss: 0.909556]\n",
      "[Epoch 91/100] [Batch 110/347] [D loss: 0.385908] [G loss: 0.363943]\n",
      "[Epoch 91/100] [Batch 111/347] [D loss: 0.339687] [G loss: 0.425413]\n",
      "[Epoch 91/100] [Batch 112/347] [D loss: 0.292438] [G loss: 0.495515]\n",
      "[Epoch 91/100] [Batch 113/347] [D loss: 0.533233] [G loss: 0.583601]\n",
      "[Epoch 91/100] [Batch 114/347] [D loss: 0.690709] [G loss: 0.706232]\n",
      "[Epoch 91/100] [Batch 115/347] [D loss: 0.756693] [G loss: 0.719299]\n",
      "[Epoch 91/100] [Batch 116/347] [D loss: 0.658192] [G loss: 0.655002]\n",
      "[Epoch 91/100] [Batch 117/347] [D loss: 0.644805] [G loss: 0.740323]\n",
      "[Epoch 91/100] [Batch 118/347] [D loss: 0.338136] [G loss: 0.916348]\n",
      "[Epoch 91/100] [Batch 119/347] [D loss: 0.283660] [G loss: 0.879346]\n",
      "[Epoch 91/100] [Batch 120/347] [D loss: 0.226767] [G loss: 0.743873]\n",
      "[Epoch 91/100] [Batch 121/347] [D loss: 0.198377] [G loss: 0.658004]\n",
      "[Epoch 91/100] [Batch 122/347] [D loss: 0.373662] [G loss: 0.554780]\n",
      "[Epoch 91/100] [Batch 123/347] [D loss: 0.438880] [G loss: 0.481804]\n",
      "[Epoch 91/100] [Batch 124/347] [D loss: 0.347131] [G loss: 0.418380]\n",
      "[Epoch 91/100] [Batch 125/347] [D loss: 0.322589] [G loss: 0.381704]\n",
      "[Epoch 91/100] [Batch 126/347] [D loss: 0.251981] [G loss: 0.428046]\n",
      "[Epoch 91/100] [Batch 127/347] [D loss: 0.215553] [G loss: 0.452920]\n",
      "[Epoch 91/100] [Batch 128/347] [D loss: 0.249642] [G loss: 0.377905]\n",
      "[Epoch 91/100] [Batch 129/347] [D loss: 0.278162] [G loss: 0.325290]\n",
      "[Epoch 91/100] [Batch 130/347] [D loss: 0.326286] [G loss: 0.294481]\n",
      "[Epoch 91/100] [Batch 131/347] [D loss: 0.309386] [G loss: 0.311210]\n",
      "[Epoch 91/100] [Batch 132/347] [D loss: 0.284156] [G loss: 0.345140]\n",
      "[Epoch 91/100] [Batch 133/347] [D loss: 0.336905] [G loss: 0.350910]\n",
      "[Epoch 91/100] [Batch 134/347] [D loss: 0.499301] [G loss: 0.230825]\n",
      "[Epoch 91/100] [Batch 135/347] [D loss: 0.474218] [G loss: 0.243940]\n",
      "[Epoch 91/100] [Batch 136/347] [D loss: 0.348063] [G loss: 0.349396]\n",
      "[Epoch 91/100] [Batch 137/347] [D loss: 0.475841] [G loss: 0.386066]\n",
      "[Epoch 91/100] [Batch 138/347] [D loss: 0.527406] [G loss: 0.419630]\n",
      "[Epoch 91/100] [Batch 139/347] [D loss: 0.638050] [G loss: 0.460553]\n",
      "[Epoch 91/100] [Batch 140/347] [D loss: 0.718376] [G loss: 0.498837]\n",
      "[Epoch 91/100] [Batch 141/347] [D loss: 0.643437] [G loss: 0.749311]\n",
      "[Epoch 91/100] [Batch 142/347] [D loss: 0.630408] [G loss: 0.881447]\n",
      "[Epoch 91/100] [Batch 143/347] [D loss: 0.534354] [G loss: 0.865049]\n",
      "[Epoch 91/100] [Batch 144/347] [D loss: 0.422259] [G loss: 0.829715]\n",
      "[Epoch 91/100] [Batch 145/347] [D loss: 0.405265] [G loss: 0.776889]\n",
      "[Epoch 91/100] [Batch 146/347] [D loss: 0.383142] [G loss: 0.633862]\n",
      "[Epoch 91/100] [Batch 147/347] [D loss: 0.356891] [G loss: 0.527119]\n",
      "[Epoch 91/100] [Batch 148/347] [D loss: 0.391792] [G loss: 0.449770]\n",
      "[Epoch 91/100] [Batch 149/347] [D loss: 0.350870] [G loss: 0.364827]\n",
      "[Epoch 91/100] [Batch 150/347] [D loss: 0.327588] [G loss: 0.314839]\n",
      "[Epoch 91/100] [Batch 151/347] [D loss: 0.298591] [G loss: 0.304006]\n",
      "[Epoch 91/100] [Batch 152/347] [D loss: 0.285973] [G loss: 0.286767]\n",
      "[Epoch 91/100] [Batch 153/347] [D loss: 0.323416] [G loss: 0.240061]\n",
      "[Epoch 91/100] [Batch 154/347] [D loss: 0.339910] [G loss: 0.216123]\n",
      "[Epoch 91/100] [Batch 155/347] [D loss: 0.355401] [G loss: 0.205835]\n",
      "[Epoch 91/100] [Batch 156/347] [D loss: 0.375286] [G loss: 0.198926]\n",
      "[Epoch 91/100] [Batch 157/347] [D loss: 0.353604] [G loss: 0.223835]\n",
      "[Epoch 91/100] [Batch 158/347] [D loss: 0.335201] [G loss: 0.250697]\n",
      "[Epoch 91/100] [Batch 159/347] [D loss: 0.330825] [G loss: 0.259265]\n",
      "[Epoch 91/100] [Batch 160/347] [D loss: 0.290389] [G loss: 0.303865]\n",
      "[Epoch 91/100] [Batch 161/347] [D loss: 0.259836] [G loss: 0.339800]\n",
      "[Epoch 91/100] [Batch 162/347] [D loss: 0.326892] [G loss: 0.287928]\n",
      "[Epoch 91/100] [Batch 163/347] [D loss: 0.299777] [G loss: 0.353209]\n",
      "[Epoch 91/100] [Batch 164/347] [D loss: 0.294599] [G loss: 0.397331]\n",
      "[Epoch 91/100] [Batch 165/347] [D loss: 0.264295] [G loss: 0.452456]\n",
      "[Epoch 91/100] [Batch 166/347] [D loss: 0.235502] [G loss: 0.591526]\n",
      "[Epoch 91/100] [Batch 167/347] [D loss: 0.226405] [G loss: 0.735297]\n",
      "[Epoch 91/100] [Batch 168/347] [D loss: 0.225505] [G loss: 0.774591]\n",
      "[Epoch 91/100] [Batch 169/347] [D loss: 0.522653] [G loss: 0.764214]\n",
      "[Epoch 91/100] [Batch 170/347] [D loss: 0.722888] [G loss: 0.724592]\n",
      "[Epoch 91/100] [Batch 171/347] [D loss: 0.624511] [G loss: 0.641964]\n",
      "[Epoch 91/100] [Batch 172/347] [D loss: 0.630366] [G loss: 0.558318]\n",
      "[Epoch 91/100] [Batch 173/347] [D loss: 0.567341] [G loss: 0.617145]\n",
      "[Epoch 91/100] [Batch 174/347] [D loss: 0.449525] [G loss: 0.738444]\n",
      "[Epoch 91/100] [Batch 175/347] [D loss: 0.518661] [G loss: 0.667300]\n",
      "[Epoch 91/100] [Batch 176/347] [D loss: 0.494809] [G loss: 0.557419]\n",
      "[Epoch 91/100] [Batch 177/347] [D loss: 0.441806] [G loss: 0.467205]\n",
      "[Epoch 91/100] [Batch 178/347] [D loss: 0.399274] [G loss: 0.373743]\n",
      "[Epoch 91/100] [Batch 179/347] [D loss: 0.380950] [G loss: 0.326120]\n",
      "[Epoch 91/100] [Batch 180/347] [D loss: 0.355265] [G loss: 0.313838]\n",
      "[Epoch 91/100] [Batch 181/347] [D loss: 0.345073] [G loss: 0.276432]\n",
      "[Epoch 91/100] [Batch 182/347] [D loss: 0.363556] [G loss: 0.241571]\n",
      "[Epoch 91/100] [Batch 183/347] [D loss: 0.382842] [G loss: 0.221312]\n",
      "[Epoch 91/100] [Batch 184/347] [D loss: 0.445713] [G loss: 0.199983]\n",
      "[Epoch 91/100] [Batch 185/347] [D loss: 0.478673] [G loss: 0.185813]\n",
      "[Epoch 91/100] [Batch 186/347] [D loss: 0.470122] [G loss: 0.182556]\n",
      "[Epoch 91/100] [Batch 187/347] [D loss: 0.459941] [G loss: 0.181751]\n",
      "[Epoch 91/100] [Batch 188/347] [D loss: 0.410724] [G loss: 0.201365]\n",
      "[Epoch 91/100] [Batch 189/347] [D loss: 0.368514] [G loss: 0.215686]\n",
      "[Epoch 91/100] [Batch 190/347] [D loss: 0.357372] [G loss: 0.226007]\n",
      "[Epoch 91/100] [Batch 191/347] [D loss: 0.349363] [G loss: 0.242889]\n",
      "[Epoch 91/100] [Batch 192/347] [D loss: 0.352349] [G loss: 0.263372]\n",
      "[Epoch 91/100] [Batch 193/347] [D loss: 0.416566] [G loss: 0.272464]\n",
      "[Epoch 91/100] [Batch 194/347] [D loss: 0.391071] [G loss: 0.296652]\n",
      "[Epoch 91/100] [Batch 195/347] [D loss: 0.362764] [G loss: 0.328256]\n",
      "[Epoch 91/100] [Batch 196/347] [D loss: 0.312714] [G loss: 0.360864]\n",
      "[Epoch 91/100] [Batch 197/347] [D loss: 0.291755] [G loss: 0.414785]\n",
      "[Epoch 91/100] [Batch 198/347] [D loss: 0.277732] [G loss: 0.463322]\n",
      "[Epoch 91/100] [Batch 199/347] [D loss: 0.281364] [G loss: 0.485997]\n",
      "[Epoch 91/100] [Batch 200/347] [D loss: 0.395192] [G loss: 0.479591]\n",
      "[Epoch 91/100] [Batch 201/347] [D loss: 0.449698] [G loss: 0.488748]\n",
      "[Epoch 91/100] [Batch 202/347] [D loss: 0.494257] [G loss: 0.473720]\n",
      "[Epoch 91/100] [Batch 203/347] [D loss: 0.508210] [G loss: 0.474055]\n",
      "[Epoch 91/100] [Batch 204/347] [D loss: 0.467746] [G loss: 0.497399]\n",
      "[Epoch 91/100] [Batch 205/347] [D loss: 0.433260] [G loss: 0.517991]\n",
      "[Epoch 91/100] [Batch 206/347] [D loss: 0.416416] [G loss: 0.511749]\n",
      "[Epoch 91/100] [Batch 207/347] [D loss: 0.297398] [G loss: 0.502893]\n",
      "[Epoch 91/100] [Batch 208/347] [D loss: 0.278683] [G loss: 0.476873]\n",
      "[Epoch 91/100] [Batch 209/347] [D loss: 0.289838] [G loss: 0.430785]\n",
      "[Epoch 91/100] [Batch 210/347] [D loss: 0.225068] [G loss: 0.415050]\n",
      "[Epoch 91/100] [Batch 211/347] [D loss: 0.228440] [G loss: 0.369494]\n",
      "[Epoch 91/100] [Batch 212/347] [D loss: 0.209974] [G loss: 0.343823]\n",
      "[Epoch 91/100] [Batch 213/347] [D loss: 0.199257] [G loss: 0.372536]\n",
      "[Epoch 91/100] [Batch 214/347] [D loss: 0.246580] [G loss: 0.317361]\n",
      "[Epoch 91/100] [Batch 215/347] [D loss: 0.241495] [G loss: 0.330694]\n",
      "[Epoch 91/100] [Batch 216/347] [D loss: 0.562538] [G loss: 0.161924]\n",
      "[Epoch 91/100] [Batch 217/347] [D loss: 0.576684] [G loss: 0.210678]\n",
      "[Epoch 91/100] [Batch 218/347] [D loss: 0.600096] [G loss: 0.253430]\n",
      "[Epoch 91/100] [Batch 219/347] [D loss: 0.542603] [G loss: 0.293375]\n",
      "[Epoch 91/100] [Batch 220/347] [D loss: 0.360737] [G loss: 0.528281]\n",
      "[Epoch 91/100] [Batch 221/347] [D loss: 0.353078] [G loss: 0.642045]\n",
      "[Epoch 91/100] [Batch 222/347] [D loss: 0.365598] [G loss: 0.744056]\n",
      "[Epoch 91/100] [Batch 223/347] [D loss: 0.402793] [G loss: 0.753487]\n",
      "[Epoch 91/100] [Batch 224/347] [D loss: 0.476383] [G loss: 0.751168]\n",
      "[Epoch 91/100] [Batch 225/347] [D loss: 0.567177] [G loss: 0.727848]\n",
      "[Epoch 91/100] [Batch 226/347] [D loss: 0.583656] [G loss: 0.721796]\n",
      "[Epoch 91/100] [Batch 227/347] [D loss: 0.598080] [G loss: 0.652442]\n",
      "[Epoch 91/100] [Batch 228/347] [D loss: 0.555434] [G loss: 0.587808]\n",
      "[Epoch 91/100] [Batch 229/347] [D loss: 0.465432] [G loss: 0.519679]\n",
      "[Epoch 91/100] [Batch 230/347] [D loss: 0.452629] [G loss: 0.450403]\n",
      "[Epoch 91/100] [Batch 231/347] [D loss: 0.387805] [G loss: 0.406882]\n",
      "[Epoch 91/100] [Batch 232/347] [D loss: 0.346978] [G loss: 0.365865]\n",
      "[Epoch 91/100] [Batch 233/347] [D loss: 0.265234] [G loss: 0.333438]\n",
      "[Epoch 91/100] [Batch 234/347] [D loss: 0.243059] [G loss: 0.311988]\n",
      "[Epoch 91/100] [Batch 235/347] [D loss: 0.270865] [G loss: 0.304053]\n",
      "[Epoch 91/100] [Batch 236/347] [D loss: 0.293999] [G loss: 0.299394]\n",
      "[Epoch 91/100] [Batch 237/347] [D loss: 0.413935] [G loss: 0.263935]\n",
      "[Epoch 91/100] [Batch 238/347] [D loss: 0.520845] [G loss: 0.222834]\n",
      "[Epoch 91/100] [Batch 239/347] [D loss: 0.536658] [G loss: 0.207879]\n",
      "[Epoch 91/100] [Batch 240/347] [D loss: 0.563468] [G loss: 0.197578]\n",
      "[Epoch 91/100] [Batch 241/347] [D loss: 0.530816] [G loss: 0.227618]\n",
      "[Epoch 91/100] [Batch 242/347] [D loss: 0.401089] [G loss: 0.372256]\n",
      "[Epoch 91/100] [Batch 243/347] [D loss: 0.338345] [G loss: 0.391557]\n",
      "[Epoch 91/100] [Batch 244/347] [D loss: 0.298676] [G loss: 0.411843]\n",
      "[Epoch 91/100] [Batch 245/347] [D loss: 0.298320] [G loss: 0.416664]\n",
      "[Epoch 91/100] [Batch 246/347] [D loss: 0.302738] [G loss: 0.434159]\n",
      "[Epoch 91/100] [Batch 247/347] [D loss: 0.374170] [G loss: 0.420151]\n",
      "[Epoch 91/100] [Batch 248/347] [D loss: 0.416978] [G loss: 0.386989]\n",
      "[Epoch 91/100] [Batch 249/347] [D loss: 0.385385] [G loss: 0.407415]\n",
      "[Epoch 91/100] [Batch 250/347] [D loss: 0.350784] [G loss: 0.440945]\n",
      "[Epoch 91/100] [Batch 251/347] [D loss: 0.326718] [G loss: 0.482621]\n",
      "[Epoch 91/100] [Batch 252/347] [D loss: 0.314475] [G loss: 0.493848]\n",
      "[Epoch 91/100] [Batch 253/347] [D loss: 0.243760] [G loss: 0.465145]\n",
      "[Epoch 91/100] [Batch 254/347] [D loss: 0.241345] [G loss: 0.452901]\n",
      "[Epoch 91/100] [Batch 255/347] [D loss: 0.257969] [G loss: 0.431893]\n",
      "[Epoch 91/100] [Batch 256/347] [D loss: 0.267120] [G loss: 0.419908]\n",
      "[Epoch 91/100] [Batch 257/347] [D loss: 0.309409] [G loss: 0.339383]\n",
      "[Epoch 91/100] [Batch 258/347] [D loss: 0.289039] [G loss: 0.312823]\n",
      "[Epoch 91/100] [Batch 259/347] [D loss: 0.292850] [G loss: 0.318268]\n",
      "[Epoch 91/100] [Batch 260/347] [D loss: 0.289557] [G loss: 0.336042]\n",
      "[Epoch 91/100] [Batch 261/347] [D loss: 0.252611] [G loss: 0.399085]\n",
      "[Epoch 91/100] [Batch 262/347] [D loss: 0.217120] [G loss: 0.431619]\n",
      "[Epoch 91/100] [Batch 263/347] [D loss: 0.204106] [G loss: 0.467365]\n",
      "[Epoch 91/100] [Batch 264/347] [D loss: 0.197264] [G loss: 0.501702]\n",
      "[Epoch 91/100] [Batch 265/347] [D loss: 0.215384] [G loss: 0.498142]\n",
      "[Epoch 91/100] [Batch 266/347] [D loss: 0.335569] [G loss: 0.441023]\n",
      "[Epoch 91/100] [Batch 267/347] [D loss: 0.367965] [G loss: 0.439938]\n",
      "[Epoch 91/100] [Batch 268/347] [D loss: 0.379158] [G loss: 0.461282]\n",
      "[Epoch 91/100] [Batch 269/347] [D loss: 0.378210] [G loss: 0.483046]\n",
      "[Epoch 91/100] [Batch 270/347] [D loss: 0.386228] [G loss: 0.581693]\n",
      "[Epoch 91/100] [Batch 271/347] [D loss: 0.300259] [G loss: 0.650606]\n",
      "[Epoch 91/100] [Batch 272/347] [D loss: 0.240311] [G loss: 0.703197]\n",
      "[Epoch 91/100] [Batch 273/347] [D loss: 0.214065] [G loss: 0.747897]\n",
      "[Epoch 91/100] [Batch 274/347] [D loss: 0.185971] [G loss: 0.782905]\n",
      "[Epoch 91/100] [Batch 275/347] [D loss: 0.154394] [G loss: 0.801603]\n",
      "[Epoch 91/100] [Batch 276/347] [D loss: 0.773537] [G loss: 0.200580]\n",
      "[Epoch 91/100] [Batch 277/347] [D loss: 0.797777] [G loss: 0.202823]\n",
      "[Epoch 91/100] [Batch 278/347] [D loss: 0.811765] [G loss: 0.227553]\n",
      "[Epoch 91/100] [Batch 279/347] [D loss: 0.807015] [G loss: 0.231999]\n",
      "[Epoch 91/100] [Batch 280/347] [D loss: 0.733200] [G loss: 0.670318]\n",
      "[Epoch 91/100] [Batch 281/347] [D loss: 0.758616] [G loss: 0.831844]\n",
      "[Epoch 91/100] [Batch 282/347] [D loss: 0.767964] [G loss: 0.827464]\n",
      "[Epoch 91/100] [Batch 283/347] [D loss: 0.732535] [G loss: 0.819288]\n",
      "[Epoch 91/100] [Batch 284/347] [D loss: 0.706276] [G loss: 0.806580]\n",
      "[Epoch 91/100] [Batch 285/347] [D loss: 0.680562] [G loss: 0.787290]\n",
      "[Epoch 91/100] [Batch 286/347] [D loss: 0.568105] [G loss: 0.749191]\n",
      "[Epoch 91/100] [Batch 287/347] [D loss: 0.465836] [G loss: 0.665946]\n",
      "[Epoch 91/100] [Batch 288/347] [D loss: 0.400933] [G loss: 0.552153]\n",
      "[Epoch 91/100] [Batch 289/347] [D loss: 0.346439] [G loss: 0.449455]\n",
      "[Epoch 91/100] [Batch 290/347] [D loss: 0.340520] [G loss: 0.338563]\n",
      "[Epoch 91/100] [Batch 291/347] [D loss: 0.317691] [G loss: 0.306658]\n",
      "[Epoch 91/100] [Batch 292/347] [D loss: 0.315463] [G loss: 0.281079]\n",
      "[Epoch 91/100] [Batch 293/347] [D loss: 0.302204] [G loss: 0.277774]\n",
      "[Epoch 91/100] [Batch 294/347] [D loss: 0.323541] [G loss: 0.270734]\n",
      "[Epoch 91/100] [Batch 295/347] [D loss: 0.346856] [G loss: 0.257095]\n",
      "[Epoch 91/100] [Batch 296/347] [D loss: 0.365877] [G loss: 0.249851]\n",
      "[Epoch 91/100] [Batch 297/347] [D loss: 0.589325] [G loss: 0.178142]\n",
      "[Epoch 91/100] [Batch 298/347] [D loss: 0.614875] [G loss: 0.155181]\n",
      "[Epoch 91/100] [Batch 299/347] [D loss: 0.597167] [G loss: 0.165073]\n",
      "[Epoch 91/100] [Batch 300/347] [D loss: 0.567165] [G loss: 0.187108]\n",
      "[Epoch 91/100] [Batch 301/347] [D loss: 0.426856] [G loss: 0.321455]\n",
      "[Epoch 91/100] [Batch 302/347] [D loss: 0.346447] [G loss: 0.411734]\n",
      "[Epoch 91/100] [Batch 303/347] [D loss: 0.372434] [G loss: 0.411888]\n",
      "[Epoch 91/100] [Batch 304/347] [D loss: 0.289417] [G loss: 0.403271]\n",
      "[Epoch 91/100] [Batch 305/347] [D loss: 0.181267] [G loss: 0.448651]\n",
      "[Epoch 91/100] [Batch 306/347] [D loss: 0.163890] [G loss: 0.496386]\n",
      "[Epoch 91/100] [Batch 307/347] [D loss: 0.141908] [G loss: 0.558839]\n",
      "[Epoch 91/100] [Batch 308/347] [D loss: 0.246112] [G loss: 0.552817]\n",
      "[Epoch 91/100] [Batch 309/347] [D loss: 0.516517] [G loss: 0.421973]\n",
      "[Epoch 91/100] [Batch 310/347] [D loss: 0.698954] [G loss: 0.451233]\n",
      "[Epoch 91/100] [Batch 311/347] [D loss: 0.639741] [G loss: 0.434146]\n",
      "[Epoch 91/100] [Batch 312/347] [D loss: 0.518664] [G loss: 0.424158]\n",
      "[Epoch 91/100] [Batch 313/347] [D loss: 0.388254] [G loss: 0.590747]\n",
      "[Epoch 91/100] [Batch 314/347] [D loss: 0.376698] [G loss: 0.635425]\n",
      "[Epoch 91/100] [Batch 315/347] [D loss: 0.378787] [G loss: 0.652767]\n",
      "[Epoch 91/100] [Batch 316/347] [D loss: 0.409515] [G loss: 0.553061]\n",
      "[Epoch 91/100] [Batch 317/347] [D loss: 0.416326] [G loss: 0.504043]\n",
      "[Epoch 91/100] [Batch 318/347] [D loss: 0.379398] [G loss: 0.496262]\n",
      "[Epoch 91/100] [Batch 319/347] [D loss: 0.325550] [G loss: 0.503524]\n",
      "[Epoch 91/100] [Batch 320/347] [D loss: 0.326997] [G loss: 0.481409]\n",
      "[Epoch 91/100] [Batch 321/347] [D loss: 0.294552] [G loss: 0.448676]\n",
      "[Epoch 91/100] [Batch 322/347] [D loss: 0.309958] [G loss: 0.396140]\n",
      "[Epoch 91/100] [Batch 323/347] [D loss: 0.251697] [G loss: 0.353280]\n",
      "[Epoch 91/100] [Batch 324/347] [D loss: 0.250292] [G loss: 0.339225]\n",
      "[Epoch 91/100] [Batch 325/347] [D loss: 0.270740] [G loss: 0.308706]\n",
      "[Epoch 91/100] [Batch 326/347] [D loss: 0.279447] [G loss: 0.295979]\n",
      "[Epoch 91/100] [Batch 327/347] [D loss: 0.313442] [G loss: 0.260624]\n",
      "[Epoch 91/100] [Batch 328/347] [D loss: 0.349773] [G loss: 0.231055]\n",
      "[Epoch 91/100] [Batch 329/347] [D loss: 0.346974] [G loss: 0.243598]\n",
      "[Epoch 91/100] [Batch 330/347] [D loss: 0.326407] [G loss: 0.276603]\n",
      "[Epoch 91/100] [Batch 331/347] [D loss: 0.368683] [G loss: 0.295504]\n",
      "[Epoch 91/100] [Batch 332/347] [D loss: 0.444916] [G loss: 0.333568]\n",
      "[Epoch 91/100] [Batch 333/347] [D loss: 0.383348] [G loss: 0.352412]\n",
      "[Epoch 91/100] [Batch 334/347] [D loss: 0.372396] [G loss: 0.354574]\n",
      "[Epoch 91/100] [Batch 335/347] [D loss: 0.374604] [G loss: 0.365954]\n",
      "[Epoch 91/100] [Batch 336/347] [D loss: 0.324981] [G loss: 0.440131]\n",
      "[Epoch 91/100] [Batch 337/347] [D loss: 0.392647] [G loss: 0.458132]\n",
      "[Epoch 91/100] [Batch 338/347] [D loss: 0.456128] [G loss: 0.478816]\n",
      "[Epoch 91/100] [Batch 339/347] [D loss: 0.420644] [G loss: 0.487179]\n",
      "[Epoch 91/100] [Batch 340/347] [D loss: 0.383382] [G loss: 0.491341]\n",
      "[Epoch 91/100] [Batch 341/347] [D loss: 0.393131] [G loss: 0.514925]\n",
      "[Epoch 91/100] [Batch 342/347] [D loss: 0.210405] [G loss: 0.538685]\n",
      "[Epoch 91/100] [Batch 343/347] [D loss: 0.166114] [G loss: 0.522644]\n",
      "[Epoch 91/100] [Batch 344/347] [D loss: 0.162153] [G loss: 0.493233]\n",
      "[Epoch 91/100] [Batch 345/347] [D loss: 0.116067] [G loss: 0.492609]\n",
      "[Epoch 91/100] [Batch 346/347] [D loss: 0.188399] [G loss: 0.397561]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 91/100] [Batch 347/347] [D loss: 0.235470] [G loss: 0.329357]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 92/100] [Batch 1/347] [D loss: 0.429966] [G loss: 0.537901]\n",
      "[Epoch 92/100] [Batch 2/347] [D loss: 0.467236] [G loss: 0.542496]\n",
      "[Epoch 92/100] [Batch 3/347] [D loss: 0.516359] [G loss: 0.556021]\n",
      "[Epoch 92/100] [Batch 4/347] [D loss: 0.545005] [G loss: 0.544885]\n",
      "[Epoch 92/100] [Batch 5/347] [D loss: 0.538945] [G loss: 0.536211]\n",
      "[Epoch 92/100] [Batch 6/347] [D loss: 0.434807] [G loss: 0.527410]\n",
      "[Epoch 92/100] [Batch 7/347] [D loss: 0.348749] [G loss: 0.558959]\n",
      "[Epoch 92/100] [Batch 8/347] [D loss: 0.335503] [G loss: 0.539590]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 92/100] [Batch 9/347] [D loss: 0.320659] [G loss: 0.505022]\n",
      "[Epoch 92/100] [Batch 10/347] [D loss: 0.340454] [G loss: 0.457295]\n",
      "[Epoch 92/100] [Batch 11/347] [D loss: 0.424679] [G loss: 0.402829]\n",
      "[Epoch 92/100] [Batch 12/347] [D loss: 0.416554] [G loss: 0.375922]\n",
      "[Epoch 92/100] [Batch 13/347] [D loss: 0.371648] [G loss: 0.351470]\n",
      "[Epoch 92/100] [Batch 14/347] [D loss: 0.341105] [G loss: 0.335357]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 92/100] [Batch 15/347] [D loss: 0.317268] [G loss: 0.334431]\n",
      "[Epoch 92/100] [Batch 16/347] [D loss: 0.302893] [G loss: 0.342388]\n",
      "[Epoch 92/100] [Batch 17/347] [D loss: 0.322751] [G loss: 0.310478]\n",
      "[Epoch 92/100] [Batch 18/347] [D loss: 0.371453] [G loss: 0.267246]\n",
      "[Epoch 92/100] [Batch 19/347] [D loss: 0.393177] [G loss: 0.255634]\n",
      "[Epoch 92/100] [Batch 20/347] [D loss: 0.412771] [G loss: 0.261684]\n",
      "[Epoch 92/100] [Batch 21/347] [D loss: 0.380194] [G loss: 0.255329]\n",
      "[Epoch 92/100] [Batch 22/347] [D loss: 0.378614] [G loss: 0.261271]\n",
      "[Epoch 92/100] [Batch 23/347] [D loss: 0.371145] [G loss: 0.275846]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 92/100] [Batch 24/347] [D loss: 0.315902] [G loss: 0.305505]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 92/100] [Batch 25/347] [D loss: 0.254955] [G loss: 0.304174]\n",
      "[Epoch 92/100] [Batch 26/347] [D loss: 0.249093] [G loss: 0.319512]\n",
      "[Epoch 92/100] [Batch 27/347] [D loss: 0.230077] [G loss: 0.353320]\n",
      "[Epoch 92/100] [Batch 28/347] [D loss: 0.221111] [G loss: 0.390728]\n",
      "[Epoch 92/100] [Batch 29/347] [D loss: 0.324668] [G loss: 0.320601]\n",
      "[Epoch 92/100] [Batch 30/347] [D loss: 0.287811] [G loss: 0.353195]\n",
      "[Epoch 92/100] [Batch 31/347] [D loss: 0.275284] [G loss: 0.378907]\n",
      "[Epoch 92/100] [Batch 32/347] [D loss: 0.289833] [G loss: 0.372479]\n",
      "[Epoch 92/100] [Batch 33/347] [D loss: 0.290655] [G loss: 0.408414]\n",
      "[Epoch 92/100] [Batch 34/347] [D loss: 0.379073] [G loss: 0.423528]\n",
      "[Epoch 92/100] [Batch 35/347] [D loss: 0.405826] [G loss: 0.445101]\n",
      "[Epoch 92/100] [Batch 36/347] [D loss: 0.453985] [G loss: 0.484115]\n",
      "[Epoch 92/100] [Batch 37/347] [D loss: 0.468070] [G loss: 0.542432]\n",
      "[Epoch 92/100] [Batch 38/347] [D loss: 0.475402] [G loss: 0.615865]\n",
      "[Epoch 92/100] [Batch 39/347] [D loss: 0.488961] [G loss: 0.618286]\n",
      "[Epoch 92/100] [Batch 40/347] [D loss: 0.537263] [G loss: 0.645233]\n",
      "[Epoch 92/100] [Batch 41/347] [D loss: 0.511992] [G loss: 0.648953]\n",
      "[Epoch 92/100] [Batch 42/347] [D loss: 0.462758] [G loss: 0.647989]\n",
      "[Epoch 92/100] [Batch 43/347] [D loss: 0.486840] [G loss: 0.637947]\n",
      "[Epoch 92/100] [Batch 44/347] [D loss: 0.414337] [G loss: 0.645207]\n",
      "[Epoch 92/100] [Batch 45/347] [D loss: 0.351129] [G loss: 0.596608]\n",
      "[Epoch 92/100] [Batch 46/347] [D loss: 0.253862] [G loss: 0.507334]\n",
      "[Epoch 92/100] [Batch 47/347] [D loss: 0.267411] [G loss: 0.450078]\n",
      "[Epoch 92/100] [Batch 48/347] [D loss: 0.151432] [G loss: 0.426028]\n",
      "[Epoch 92/100] [Batch 49/347] [D loss: 0.162329] [G loss: 0.410026]\n",
      "[Epoch 92/100] [Batch 50/347] [D loss: 0.274832] [G loss: 0.300529]\n",
      "[Epoch 92/100] [Batch 51/347] [D loss: 0.262622] [G loss: 0.329212]\n",
      "[Epoch 92/100] [Batch 52/347] [D loss: 0.513951] [G loss: 0.233117]\n",
      "[Epoch 92/100] [Batch 53/347] [D loss: 0.593608] [G loss: 0.194977]\n",
      "[Epoch 92/100] [Batch 54/347] [D loss: 0.592584] [G loss: 0.181894]\n",
      "[Epoch 92/100] [Batch 55/347] [D loss: 0.594258] [G loss: 0.183376]\n",
      "[Epoch 92/100] [Batch 56/347] [D loss: 0.427579] [G loss: 0.327989]\n",
      "[Epoch 92/100] [Batch 57/347] [D loss: 0.254053] [G loss: 0.494545]\n",
      "[Epoch 92/100] [Batch 58/347] [D loss: 0.232884] [G loss: 0.559869]\n",
      "[Epoch 92/100] [Batch 59/347] [D loss: 0.228887] [G loss: 0.583997]\n",
      "[Epoch 92/100] [Batch 60/347] [D loss: 0.265834] [G loss: 0.550582]\n",
      "[Epoch 92/100] [Batch 61/347] [D loss: 0.323861] [G loss: 0.508233]\n",
      "[Epoch 92/100] [Batch 62/347] [D loss: 0.329846] [G loss: 0.524250]\n",
      "[Epoch 92/100] [Batch 63/347] [D loss: 0.293720] [G loss: 0.564430]\n",
      "[Epoch 92/100] [Batch 64/347] [D loss: 0.261227] [G loss: 0.584633]\n",
      "[Epoch 92/100] [Batch 65/347] [D loss: 0.193246] [G loss: 0.641434]\n",
      "[Epoch 92/100] [Batch 66/347] [D loss: 0.212587] [G loss: 0.618717]\n",
      "[Epoch 92/100] [Batch 67/347] [D loss: 0.261719] [G loss: 0.553193]\n",
      "[Epoch 92/100] [Batch 68/347] [D loss: 0.297402] [G loss: 0.483360]\n",
      "[Epoch 92/100] [Batch 69/347] [D loss: 0.394767] [G loss: 0.343565]\n",
      "[Epoch 92/100] [Batch 70/347] [D loss: 0.384702] [G loss: 0.350623]\n",
      "[Epoch 92/100] [Batch 71/347] [D loss: 0.316664] [G loss: 0.389568]\n",
      "[Epoch 92/100] [Batch 72/347] [D loss: 0.305024] [G loss: 0.414573]\n",
      "[Epoch 92/100] [Batch 73/347] [D loss: 0.439036] [G loss: 0.460196]\n",
      "[Epoch 92/100] [Batch 74/347] [D loss: 0.409466] [G loss: 0.486959]\n",
      "[Epoch 92/100] [Batch 75/347] [D loss: 0.427783] [G loss: 0.440933]\n",
      "[Epoch 92/100] [Batch 76/347] [D loss: 0.435832] [G loss: 0.415281]\n",
      "[Epoch 92/100] [Batch 77/347] [D loss: 0.413097] [G loss: 0.596542]\n",
      "[Epoch 92/100] [Batch 78/347] [D loss: 0.421497] [G loss: 0.605986]\n",
      "[Epoch 92/100] [Batch 79/347] [D loss: 0.396454] [G loss: 0.569986]\n",
      "[Epoch 92/100] [Batch 80/347] [D loss: 0.262231] [G loss: 0.517602]\n",
      "[Epoch 92/100] [Batch 81/347] [D loss: 0.253276] [G loss: 0.478042]\n",
      "[Epoch 92/100] [Batch 82/347] [D loss: 0.196521] [G loss: 0.590138]\n",
      "[Epoch 92/100] [Batch 83/347] [D loss: 0.197858] [G loss: 0.602238]\n",
      "[Epoch 92/100] [Batch 84/347] [D loss: 0.453943] [G loss: 0.479240]\n",
      "[Epoch 92/100] [Batch 85/347] [D loss: 0.608519] [G loss: 0.406623]\n",
      "[Epoch 92/100] [Batch 86/347] [D loss: 0.608451] [G loss: 0.362058]\n",
      "[Epoch 92/100] [Batch 87/347] [D loss: 0.588127] [G loss: 0.340280]\n",
      "[Epoch 92/100] [Batch 88/347] [D loss: 0.553032] [G loss: 0.369817]\n",
      "[Epoch 92/100] [Batch 89/347] [D loss: 0.462312] [G loss: 0.462138]\n",
      "[Epoch 92/100] [Batch 90/347] [D loss: 0.440907] [G loss: 0.418444]\n",
      "[Epoch 92/100] [Batch 91/347] [D loss: 0.430919] [G loss: 0.378121]\n",
      "[Epoch 92/100] [Batch 92/347] [D loss: 0.419971] [G loss: 0.353545]\n",
      "[Epoch 92/100] [Batch 93/347] [D loss: 0.402281] [G loss: 0.334140]\n",
      "[Epoch 92/100] [Batch 94/347] [D loss: 0.383860] [G loss: 0.300916]\n",
      "[Epoch 92/100] [Batch 95/347] [D loss: 0.360806] [G loss: 0.279441]\n",
      "[Epoch 92/100] [Batch 96/347] [D loss: 0.363848] [G loss: 0.261758]\n",
      "[Epoch 92/100] [Batch 97/347] [D loss: 0.362150] [G loss: 0.247953]\n",
      "[Epoch 92/100] [Batch 98/347] [D loss: 0.361343] [G loss: 0.232218]\n",
      "[Epoch 92/100] [Batch 99/347] [D loss: 0.370846] [G loss: 0.227732]\n",
      "[Epoch 92/100] [Batch 100/347] [D loss: 0.371798] [G loss: 0.231193]\n",
      "[Epoch 92/100] [Batch 101/347] [D loss: 0.376236] [G loss: 0.238150]\n",
      "[Epoch 92/100] [Batch 102/347] [D loss: 0.442667] [G loss: 0.248141]\n",
      "[Epoch 92/100] [Batch 103/347] [D loss: 0.431442] [G loss: 0.269579]\n",
      "[Epoch 92/100] [Batch 104/347] [D loss: 0.402738] [G loss: 0.283048]\n",
      "[Epoch 92/100] [Batch 105/347] [D loss: 0.354395] [G loss: 0.295634]\n",
      "[Epoch 92/100] [Batch 106/347] [D loss: 0.274747] [G loss: 0.354619]\n",
      "[Epoch 92/100] [Batch 107/347] [D loss: 0.233953] [G loss: 0.406819]\n",
      "[Epoch 92/100] [Batch 108/347] [D loss: 0.203085] [G loss: 0.457161]\n",
      "[Epoch 92/100] [Batch 109/347] [D loss: 0.176837] [G loss: 0.502260]\n",
      "[Epoch 92/100] [Batch 110/347] [D loss: 0.631673] [G loss: 0.110535]\n",
      "[Epoch 92/100] [Batch 111/347] [D loss: 0.555811] [G loss: 0.154145]\n",
      "[Epoch 92/100] [Batch 112/347] [D loss: 0.470341] [G loss: 0.205224]\n",
      "[Epoch 92/100] [Batch 113/347] [D loss: 0.556688] [G loss: 0.285852]\n",
      "[Epoch 92/100] [Batch 114/347] [D loss: 0.571340] [G loss: 0.403971]\n",
      "[Epoch 92/100] [Batch 115/347] [D loss: 0.621260] [G loss: 0.452178]\n",
      "[Epoch 92/100] [Batch 116/347] [D loss: 0.609149] [G loss: 0.481342]\n",
      "[Epoch 92/100] [Batch 117/347] [D loss: 0.633233] [G loss: 0.641121]\n",
      "[Epoch 92/100] [Batch 118/347] [D loss: 0.413826] [G loss: 0.835224]\n",
      "[Epoch 92/100] [Batch 119/347] [D loss: 0.407390] [G loss: 0.819277]\n",
      "[Epoch 92/100] [Batch 120/347] [D loss: 0.359021] [G loss: 0.789632]\n",
      "[Epoch 92/100] [Batch 121/347] [D loss: 0.323302] [G loss: 0.763530]\n",
      "[Epoch 92/100] [Batch 122/347] [D loss: 0.546431] [G loss: 0.751451]\n",
      "[Epoch 92/100] [Batch 123/347] [D loss: 0.642408] [G loss: 0.704094]\n",
      "[Epoch 92/100] [Batch 124/347] [D loss: 0.458317] [G loss: 0.596396]\n",
      "[Epoch 92/100] [Batch 125/347] [D loss: 0.390255] [G loss: 0.529601]\n",
      "[Epoch 92/100] [Batch 126/347] [D loss: 0.312721] [G loss: 0.570816]\n",
      "[Epoch 92/100] [Batch 127/347] [D loss: 0.250204] [G loss: 0.590484]\n",
      "[Epoch 92/100] [Batch 128/347] [D loss: 0.242447] [G loss: 0.437113]\n",
      "[Epoch 92/100] [Batch 129/347] [D loss: 0.223584] [G loss: 0.336770]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 92/100] [Batch 130/347] [D loss: 0.247047] [G loss: 0.275919]\n",
      "[Epoch 92/100] [Batch 131/347] [D loss: 0.268198] [G loss: 0.279675]\n",
      "[Epoch 92/100] [Batch 132/347] [D loss: 0.288103] [G loss: 0.284106]\n",
      "[Epoch 92/100] [Batch 133/347] [D loss: 0.393407] [G loss: 0.233052]\n",
      "[Epoch 92/100] [Batch 134/347] [D loss: 0.671534] [G loss: 0.091869]\n",
      "[Epoch 92/100] [Batch 135/347] [D loss: 0.713449] [G loss: 0.089233]\n",
      "[Epoch 92/100] [Batch 136/347] [D loss: 0.605864] [G loss: 0.160357]\n",
      "[Epoch 92/100] [Batch 137/347] [D loss: 0.646344] [G loss: 0.181253]\n",
      "[Epoch 92/100] [Batch 138/347] [D loss: 0.653323] [G loss: 0.182352]\n",
      "[Epoch 92/100] [Batch 139/347] [D loss: 0.678525] [G loss: 0.189759]\n",
      "[Epoch 92/100] [Batch 140/347] [D loss: 0.699941] [G loss: 0.214167]\n",
      "[Epoch 92/100] [Batch 141/347] [D loss: 0.528707] [G loss: 0.591053]\n",
      "[Epoch 92/100] [Batch 142/347] [D loss: 0.473943] [G loss: 0.779846]\n",
      "[Epoch 92/100] [Batch 143/347] [D loss: 0.493456] [G loss: 0.805802]\n",
      "[Epoch 92/100] [Batch 144/347] [D loss: 0.489595] [G loss: 0.805123]\n",
      "[Epoch 92/100] [Batch 145/347] [D loss: 0.532786] [G loss: 0.811018]\n",
      "[Epoch 92/100] [Batch 146/347] [D loss: 0.529433] [G loss: 0.783143]\n",
      "[Epoch 92/100] [Batch 147/347] [D loss: 0.489649] [G loss: 0.737981]\n",
      "[Epoch 92/100] [Batch 148/347] [D loss: 0.517548] [G loss: 0.667430]\n",
      "[Epoch 92/100] [Batch 149/347] [D loss: 0.450959] [G loss: 0.559320]\n",
      "[Epoch 92/100] [Batch 150/347] [D loss: 0.405544] [G loss: 0.483078]\n",
      "[Epoch 92/100] [Batch 151/347] [D loss: 0.338915] [G loss: 0.464954]\n",
      "[Epoch 92/100] [Batch 152/347] [D loss: 0.303979] [G loss: 0.433429]\n",
      "[Epoch 92/100] [Batch 153/347] [D loss: 0.314383] [G loss: 0.372108]\n",
      "[Epoch 92/100] [Batch 154/347] [D loss: 0.295221] [G loss: 0.317020]\n",
      "[Epoch 92/100] [Batch 155/347] [D loss: 0.289900] [G loss: 0.268391]\n",
      "[Epoch 92/100] [Batch 156/347] [D loss: 0.314528] [G loss: 0.231864]\n",
      "[Epoch 92/100] [Batch 157/347] [D loss: 0.309757] [G loss: 0.232361]\n",
      "[Epoch 92/100] [Batch 158/347] [D loss: 0.307935] [G loss: 0.235031]\n",
      "[Epoch 92/100] [Batch 159/347] [D loss: 0.339880] [G loss: 0.216671]\n",
      "[Epoch 92/100] [Batch 160/347] [D loss: 0.331726] [G loss: 0.231023]\n",
      "[Epoch 92/100] [Batch 161/347] [D loss: 0.328118] [G loss: 0.241275]\n",
      "[Epoch 92/100] [Batch 162/347] [D loss: 0.437408] [G loss: 0.170551]\n",
      "[Epoch 92/100] [Batch 163/347] [D loss: 0.424952] [G loss: 0.185439]\n",
      "[Epoch 92/100] [Batch 164/347] [D loss: 0.413688] [G loss: 0.208426]\n",
      "[Epoch 92/100] [Batch 165/347] [D loss: 0.382798] [G loss: 0.239117]\n",
      "[Epoch 92/100] [Batch 166/347] [D loss: 0.322189] [G loss: 0.354781]\n",
      "[Epoch 92/100] [Batch 167/347] [D loss: 0.284580] [G loss: 0.460810]\n",
      "[Epoch 92/100] [Batch 168/347] [D loss: 0.273255] [G loss: 0.502133]\n",
      "[Epoch 92/100] [Batch 169/347] [D loss: 0.475619] [G loss: 0.505447]\n",
      "[Epoch 92/100] [Batch 170/347] [D loss: 0.600114] [G loss: 0.510212]\n",
      "[Epoch 92/100] [Batch 171/347] [D loss: 0.558527] [G loss: 0.475001]\n",
      "[Epoch 92/100] [Batch 172/347] [D loss: 0.584987] [G loss: 0.453765]\n",
      "[Epoch 92/100] [Batch 173/347] [D loss: 0.565785] [G loss: 0.568929]\n",
      "[Epoch 92/100] [Batch 174/347] [D loss: 0.502481] [G loss: 0.733945]\n",
      "[Epoch 92/100] [Batch 175/347] [D loss: 0.615134] [G loss: 0.713991]\n",
      "[Epoch 92/100] [Batch 176/347] [D loss: 0.593292] [G loss: 0.678269]\n",
      "[Epoch 92/100] [Batch 177/347] [D loss: 0.549193] [G loss: 0.624310]\n",
      "[Epoch 92/100] [Batch 178/347] [D loss: 0.490087] [G loss: 0.545434]\n",
      "[Epoch 92/100] [Batch 179/347] [D loss: 0.463435] [G loss: 0.499689]\n",
      "[Epoch 92/100] [Batch 180/347] [D loss: 0.426252] [G loss: 0.489101]\n",
      "[Epoch 92/100] [Batch 181/347] [D loss: 0.394986] [G loss: 0.440815]\n",
      "[Epoch 92/100] [Batch 182/347] [D loss: 0.382949] [G loss: 0.400364]\n",
      "[Epoch 92/100] [Batch 183/347] [D loss: 0.369958] [G loss: 0.365298]\n",
      "[Epoch 92/100] [Batch 184/347] [D loss: 0.424635] [G loss: 0.315093]\n",
      "[Epoch 92/100] [Batch 185/347] [D loss: 0.457180] [G loss: 0.277809]\n",
      "[Epoch 92/100] [Batch 186/347] [D loss: 0.444130] [G loss: 0.254324]\n",
      "[Epoch 92/100] [Batch 187/347] [D loss: 0.433251] [G loss: 0.231856]\n",
      "[Epoch 92/100] [Batch 188/347] [D loss: 0.393663] [G loss: 0.234476]\n",
      "[Epoch 92/100] [Batch 189/347] [D loss: 0.361502] [G loss: 0.227663]\n",
      "[Epoch 92/100] [Batch 190/347] [D loss: 0.369714] [G loss: 0.216189]\n",
      "[Epoch 92/100] [Batch 191/347] [D loss: 0.381875] [G loss: 0.209630]\n",
      "[Epoch 92/100] [Batch 192/347] [D loss: 0.399603] [G loss: 0.211173]\n",
      "[Epoch 92/100] [Batch 193/347] [D loss: 0.465256] [G loss: 0.203803]\n",
      "[Epoch 92/100] [Batch 194/347] [D loss: 0.444918] [G loss: 0.211903]\n",
      "[Epoch 92/100] [Batch 195/347] [D loss: 0.417988] [G loss: 0.228484]\n",
      "[Epoch 92/100] [Batch 196/347] [D loss: 0.371282] [G loss: 0.251995]\n",
      "[Epoch 92/100] [Batch 197/347] [D loss: 0.332986] [G loss: 0.292515]\n",
      "[Epoch 92/100] [Batch 198/347] [D loss: 0.308798] [G loss: 0.330622]\n",
      "[Epoch 92/100] [Batch 199/347] [D loss: 0.303919] [G loss: 0.353896]\n",
      "[Epoch 92/100] [Batch 200/347] [D loss: 0.387230] [G loss: 0.355291]\n",
      "[Epoch 92/100] [Batch 201/347] [D loss: 0.430612] [G loss: 0.375746]\n",
      "[Epoch 92/100] [Batch 202/347] [D loss: 0.468833] [G loss: 0.394357]\n",
      "[Epoch 92/100] [Batch 203/347] [D loss: 0.476188] [G loss: 0.403601]\n",
      "[Epoch 92/100] [Batch 204/347] [D loss: 0.442310] [G loss: 0.413953]\n",
      "[Epoch 92/100] [Batch 205/347] [D loss: 0.416214] [G loss: 0.448434]\n",
      "[Epoch 92/100] [Batch 206/347] [D loss: 0.407832] [G loss: 0.458080]\n",
      "[Epoch 92/100] [Batch 207/347] [D loss: 0.309803] [G loss: 0.467007]\n",
      "[Epoch 92/100] [Batch 208/347] [D loss: 0.298773] [G loss: 0.456155]\n",
      "[Epoch 92/100] [Batch 209/347] [D loss: 0.314205] [G loss: 0.426093]\n",
      "[Epoch 92/100] [Batch 210/347] [D loss: 0.255762] [G loss: 0.415213]\n",
      "[Epoch 92/100] [Batch 211/347] [D loss: 0.239136] [G loss: 0.371875]\n",
      "[Epoch 92/100] [Batch 212/347] [D loss: 0.184565] [G loss: 0.363610]\n",
      "[Epoch 92/100] [Batch 213/347] [D loss: 0.173478] [G loss: 0.382815]\n",
      "[Epoch 92/100] [Batch 214/347] [D loss: 0.228248] [G loss: 0.320755]\n",
      "[Epoch 92/100] [Batch 215/347] [D loss: 0.238893] [G loss: 0.309588]\n",
      "[Epoch 92/100] [Batch 216/347] [D loss: 0.606443] [G loss: 0.134829]\n",
      "[Epoch 92/100] [Batch 217/347] [D loss: 0.627326] [G loss: 0.181964]\n",
      "[Epoch 92/100] [Batch 218/347] [D loss: 0.652294] [G loss: 0.218493]\n",
      "[Epoch 92/100] [Batch 219/347] [D loss: 0.601884] [G loss: 0.250208]\n",
      "[Epoch 92/100] [Batch 220/347] [D loss: 0.408535] [G loss: 0.441053]\n",
      "[Epoch 92/100] [Batch 221/347] [D loss: 0.377165] [G loss: 0.569562]\n",
      "[Epoch 92/100] [Batch 222/347] [D loss: 0.368264] [G loss: 0.685757]\n",
      "[Epoch 92/100] [Batch 223/347] [D loss: 0.407798] [G loss: 0.642864]\n",
      "[Epoch 92/100] [Batch 224/347] [D loss: 0.470842] [G loss: 0.653794]\n",
      "[Epoch 92/100] [Batch 225/347] [D loss: 0.570647] [G loss: 0.616028]\n",
      "[Epoch 92/100] [Batch 226/347] [D loss: 0.596436] [G loss: 0.616115]\n",
      "[Epoch 92/100] [Batch 227/347] [D loss: 0.616717] [G loss: 0.582317]\n",
      "[Epoch 92/100] [Batch 228/347] [D loss: 0.586511] [G loss: 0.540889]\n",
      "[Epoch 92/100] [Batch 229/347] [D loss: 0.511782] [G loss: 0.545715]\n",
      "[Epoch 92/100] [Batch 230/347] [D loss: 0.506195] [G loss: 0.549403]\n",
      "[Epoch 92/100] [Batch 231/347] [D loss: 0.452033] [G loss: 0.522455]\n",
      "[Epoch 92/100] [Batch 232/347] [D loss: 0.408324] [G loss: 0.497376]\n",
      "[Epoch 92/100] [Batch 233/347] [D loss: 0.280041] [G loss: 0.469868]\n",
      "[Epoch 92/100] [Batch 234/347] [D loss: 0.223287] [G loss: 0.447834]\n",
      "[Epoch 92/100] [Batch 235/347] [D loss: 0.229948] [G loss: 0.432479]\n",
      "[Epoch 92/100] [Batch 236/347] [D loss: 0.241248] [G loss: 0.417448]\n",
      "[Epoch 92/100] [Batch 237/347] [D loss: 0.386710] [G loss: 0.357443]\n",
      "[Epoch 92/100] [Batch 238/347] [D loss: 0.517220] [G loss: 0.290406]\n",
      "[Epoch 92/100] [Batch 239/347] [D loss: 0.547690] [G loss: 0.256525]\n",
      "[Epoch 92/100] [Batch 240/347] [D loss: 0.584792] [G loss: 0.227207]\n",
      "[Epoch 92/100] [Batch 241/347] [D loss: 0.566038] [G loss: 0.245093]\n",
      "[Epoch 92/100] [Batch 242/347] [D loss: 0.428202] [G loss: 0.395357]\n",
      "[Epoch 92/100] [Batch 243/347] [D loss: 0.359801] [G loss: 0.399425]\n",
      "[Epoch 92/100] [Batch 244/347] [D loss: 0.321679] [G loss: 0.402148]\n",
      "[Epoch 92/100] [Batch 245/347] [D loss: 0.322539] [G loss: 0.391317]\n",
      "[Epoch 92/100] [Batch 246/347] [D loss: 0.326303] [G loss: 0.390178]\n",
      "[Epoch 92/100] [Batch 247/347] [D loss: 0.388911] [G loss: 0.353389]\n",
      "[Epoch 92/100] [Batch 248/347] [D loss: 0.430271] [G loss: 0.323959]\n",
      "[Epoch 92/100] [Batch 249/347] [D loss: 0.395484] [G loss: 0.345555]\n",
      "[Epoch 92/100] [Batch 250/347] [D loss: 0.362421] [G loss: 0.373574]\n",
      "[Epoch 92/100] [Batch 251/347] [D loss: 0.346137] [G loss: 0.414699]\n",
      "[Epoch 92/100] [Batch 252/347] [D loss: 0.336943] [G loss: 0.420183]\n",
      "[Epoch 92/100] [Batch 253/347] [D loss: 0.269449] [G loss: 0.392722]\n",
      "[Epoch 92/100] [Batch 254/347] [D loss: 0.266771] [G loss: 0.378243]\n",
      "[Epoch 92/100] [Batch 255/347] [D loss: 0.280224] [G loss: 0.357070]\n",
      "[Epoch 92/100] [Batch 256/347] [D loss: 0.286412] [G loss: 0.342552]\n",
      "[Epoch 92/100] [Batch 257/347] [D loss: 0.345687] [G loss: 0.273371]\n",
      "[Epoch 92/100] [Batch 258/347] [D loss: 0.328542] [G loss: 0.276268]\n",
      "[Epoch 92/100] [Batch 259/347] [D loss: 0.331972] [G loss: 0.296349]\n",
      "[Epoch 92/100] [Batch 260/347] [D loss: 0.323890] [G loss: 0.315361]\n",
      "[Epoch 92/100] [Batch 261/347] [D loss: 0.286037] [G loss: 0.348956]\n",
      "[Epoch 92/100] [Batch 262/347] [D loss: 0.246576] [G loss: 0.380333]\n",
      "[Epoch 92/100] [Batch 263/347] [D loss: 0.233140] [G loss: 0.415384]\n",
      "[Epoch 92/100] [Batch 264/347] [D loss: 0.227942] [G loss: 0.440700]\n",
      "[Epoch 92/100] [Batch 265/347] [D loss: 0.247263] [G loss: 0.439340]\n",
      "[Epoch 92/100] [Batch 266/347] [D loss: 0.366599] [G loss: 0.387846]\n",
      "[Epoch 92/100] [Batch 267/347] [D loss: 0.401160] [G loss: 0.390163]\n",
      "[Epoch 92/100] [Batch 268/347] [D loss: 0.413877] [G loss: 0.410191]\n",
      "[Epoch 92/100] [Batch 269/347] [D loss: 0.412984] [G loss: 0.435209]\n",
      "[Epoch 92/100] [Batch 270/347] [D loss: 0.414453] [G loss: 0.516551]\n",
      "[Epoch 92/100] [Batch 271/347] [D loss: 0.326414] [G loss: 0.580226]\n",
      "[Epoch 92/100] [Batch 272/347] [D loss: 0.200055] [G loss: 0.629826]\n",
      "[Epoch 92/100] [Batch 273/347] [D loss: 0.175237] [G loss: 0.672723]\n",
      "[Epoch 92/100] [Batch 274/347] [D loss: 0.149658] [G loss: 0.725152]\n",
      "[Epoch 92/100] [Batch 275/347] [D loss: 0.120949] [G loss: 0.748497]\n",
      "[Epoch 92/100] [Batch 276/347] [D loss: 0.743467] [G loss: 0.191169]\n",
      "[Epoch 92/100] [Batch 277/347] [D loss: 0.765783] [G loss: 0.192535]\n",
      "[Epoch 92/100] [Batch 278/347] [D loss: 0.760344] [G loss: 0.216990]\n",
      "[Epoch 92/100] [Batch 279/347] [D loss: 0.753773] [G loss: 0.226663]\n",
      "[Epoch 92/100] [Batch 280/347] [D loss: 0.687345] [G loss: 0.629905]\n",
      "[Epoch 92/100] [Batch 281/347] [D loss: 0.711449] [G loss: 0.771482]\n",
      "[Epoch 92/100] [Batch 282/347] [D loss: 0.727525] [G loss: 0.758222]\n",
      "[Epoch 92/100] [Batch 283/347] [D loss: 0.717802] [G loss: 0.759017]\n",
      "[Epoch 92/100] [Batch 284/347] [D loss: 0.710229] [G loss: 0.755191]\n",
      "[Epoch 92/100] [Batch 285/347] [D loss: 0.708963] [G loss: 0.748261]\n",
      "[Epoch 92/100] [Batch 286/347] [D loss: 0.657830] [G loss: 0.740061]\n",
      "[Epoch 92/100] [Batch 287/347] [D loss: 0.626528] [G loss: 0.713905]\n",
      "[Epoch 92/100] [Batch 288/347] [D loss: 0.555835] [G loss: 0.679731]\n",
      "[Epoch 92/100] [Batch 289/347] [D loss: 0.482573] [G loss: 0.629632]\n",
      "[Epoch 92/100] [Batch 290/347] [D loss: 0.429641] [G loss: 0.497369]\n",
      "[Epoch 92/100] [Batch 291/347] [D loss: 0.362838] [G loss: 0.465508]\n",
      "[Epoch 92/100] [Batch 292/347] [D loss: 0.303041] [G loss: 0.432472]\n",
      "[Epoch 92/100] [Batch 293/347] [D loss: 0.172311] [G loss: 0.415976]\n",
      "[Epoch 92/100] [Batch 294/347] [D loss: 0.181071] [G loss: 0.386043]\n",
      "[Epoch 92/100] [Batch 295/347] [D loss: 0.204475] [G loss: 0.341776]\n",
      "[Epoch 92/100] [Batch 296/347] [D loss: 0.235644] [G loss: 0.303514]\n",
      "[Epoch 92/100] [Batch 297/347] [D loss: 0.488387] [G loss: 0.186727]\n",
      "[Epoch 92/100] [Batch 298/347] [D loss: 0.536736] [G loss: 0.152488]\n",
      "[Epoch 92/100] [Batch 299/347] [D loss: 0.542111] [G loss: 0.144518]\n",
      "[Epoch 92/100] [Batch 300/347] [D loss: 0.534464] [G loss: 0.136189]\n",
      "[Epoch 92/100] [Batch 301/347] [D loss: 0.425695] [G loss: 0.264395]\n",
      "[Epoch 92/100] [Batch 302/347] [D loss: 0.343715] [G loss: 0.336745]\n",
      "[Epoch 92/100] [Batch 303/347] [D loss: 0.368460] [G loss: 0.344254]\n",
      "[Epoch 92/100] [Batch 304/347] [D loss: 0.317650] [G loss: 0.337660]\n",
      "[Epoch 92/100] [Batch 305/347] [D loss: 0.232404] [G loss: 0.346047]\n",
      "[Epoch 92/100] [Batch 306/347] [D loss: 0.214740] [G loss: 0.361297]\n",
      "[Epoch 92/100] [Batch 307/347] [D loss: 0.191466] [G loss: 0.419510]\n",
      "[Epoch 92/100] [Batch 308/347] [D loss: 0.282444] [G loss: 0.414818]\n",
      "[Epoch 92/100] [Batch 309/347] [D loss: 0.533310] [G loss: 0.325703]\n",
      "[Epoch 92/100] [Batch 310/347] [D loss: 0.664052] [G loss: 0.364349]\n",
      "[Epoch 92/100] [Batch 311/347] [D loss: 0.620892] [G loss: 0.363310]\n",
      "[Epoch 92/100] [Batch 312/347] [D loss: 0.536934] [G loss: 0.360182]\n",
      "[Epoch 92/100] [Batch 313/347] [D loss: 0.392951] [G loss: 0.500786]\n",
      "[Epoch 92/100] [Batch 314/347] [D loss: 0.374518] [G loss: 0.576879]\n",
      "[Epoch 92/100] [Batch 315/347] [D loss: 0.383749] [G loss: 0.602042]\n",
      "[Epoch 92/100] [Batch 316/347] [D loss: 0.425096] [G loss: 0.511229]\n",
      "[Epoch 92/100] [Batch 317/347] [D loss: 0.438130] [G loss: 0.480547]\n",
      "[Epoch 92/100] [Batch 318/347] [D loss: 0.405225] [G loss: 0.504328]\n",
      "[Epoch 92/100] [Batch 319/347] [D loss: 0.358158] [G loss: 0.527265]\n",
      "[Epoch 92/100] [Batch 320/347] [D loss: 0.357417] [G loss: 0.516988]\n",
      "[Epoch 92/100] [Batch 321/347] [D loss: 0.328828] [G loss: 0.491972]\n",
      "[Epoch 92/100] [Batch 322/347] [D loss: 0.344137] [G loss: 0.441261]\n",
      "[Epoch 92/100] [Batch 323/347] [D loss: 0.270822] [G loss: 0.390513]\n",
      "[Epoch 92/100] [Batch 324/347] [D loss: 0.261186] [G loss: 0.371744]\n",
      "[Epoch 92/100] [Batch 325/347] [D loss: 0.270565] [G loss: 0.352748]\n",
      "[Epoch 92/100] [Batch 326/347] [D loss: 0.272053] [G loss: 0.349849]\n",
      "[Epoch 92/100] [Batch 327/347] [D loss: 0.294856] [G loss: 0.314772]\n",
      "[Epoch 92/100] [Batch 328/347] [D loss: 0.327391] [G loss: 0.279601]\n",
      "[Epoch 92/100] [Batch 329/347] [D loss: 0.324426] [G loss: 0.273175]\n",
      "[Epoch 92/100] [Batch 330/347] [D loss: 0.307595] [G loss: 0.280765]\n",
      "[Epoch 92/100] [Batch 331/347] [D loss: 0.359080] [G loss: 0.288888]\n",
      "[Epoch 92/100] [Batch 332/347] [D loss: 0.443017] [G loss: 0.317218]\n",
      "[Epoch 92/100] [Batch 333/347] [D loss: 0.382807] [G loss: 0.328451]\n",
      "[Epoch 92/100] [Batch 334/347] [D loss: 0.374458] [G loss: 0.320170]\n",
      "[Epoch 92/100] [Batch 335/347] [D loss: 0.380086] [G loss: 0.321066]\n",
      "[Epoch 92/100] [Batch 336/347] [D loss: 0.331671] [G loss: 0.381958]\n",
      "[Epoch 92/100] [Batch 337/347] [D loss: 0.385782] [G loss: 0.396544]\n",
      "[Epoch 92/100] [Batch 338/347] [D loss: 0.443287] [G loss: 0.412731]\n",
      "[Epoch 92/100] [Batch 339/347] [D loss: 0.407825] [G loss: 0.415505]\n",
      "[Epoch 92/100] [Batch 340/347] [D loss: 0.374166] [G loss: 0.414898]\n",
      "[Epoch 92/100] [Batch 341/347] [D loss: 0.380597] [G loss: 0.429274]\n",
      "[Epoch 92/100] [Batch 342/347] [D loss: 0.221290] [G loss: 0.430470]\n",
      "[Epoch 92/100] [Batch 343/347] [D loss: 0.178640] [G loss: 0.447792]\n",
      "[Epoch 92/100] [Batch 344/347] [D loss: 0.178971] [G loss: 0.436348]\n",
      "[Epoch 92/100] [Batch 345/347] [D loss: 0.139042] [G loss: 0.453693]\n",
      "[Epoch 92/100] [Batch 346/347] [D loss: 0.220761] [G loss: 0.349161]\n",
      "[Epoch 92/100] [Batch 347/347] [D loss: 0.275092] [G loss: 0.255581]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 93/100] [Batch 1/347] [D loss: 0.434074] [G loss: 0.438652]\n",
      "[Epoch 93/100] [Batch 2/347] [D loss: 0.460539] [G loss: 0.449540]\n",
      "[Epoch 93/100] [Batch 3/347] [D loss: 0.493951] [G loss: 0.467417]\n",
      "[Epoch 93/100] [Batch 4/347] [D loss: 0.510272] [G loss: 0.466019]\n",
      "[Epoch 93/100] [Batch 5/347] [D loss: 0.513823] [G loss: 0.463062]\n",
      "[Epoch 93/100] [Batch 6/347] [D loss: 0.437450] [G loss: 0.463117]\n",
      "[Epoch 93/100] [Batch 7/347] [D loss: 0.363345] [G loss: 0.481386]\n",
      "[Epoch 93/100] [Batch 8/347] [D loss: 0.351693] [G loss: 0.473782]\n",
      "[Epoch 93/100] [Batch 9/347] [D loss: 0.340876] [G loss: 0.457040]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 93/100] [Batch 10/347] [D loss: 0.358995] [G loss: 0.423906]\n",
      "[Epoch 93/100] [Batch 11/347] [D loss: 0.433768] [G loss: 0.387551]\n",
      "[Epoch 93/100] [Batch 12/347] [D loss: 0.423638] [G loss: 0.367655]\n",
      "[Epoch 93/100] [Batch 13/347] [D loss: 0.381755] [G loss: 0.345370]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 93/100] [Batch 14/347] [D loss: 0.351614] [G loss: 0.329435]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 93/100] [Batch 15/347] [D loss: 0.328966] [G loss: 0.328104]\n",
      "[Epoch 93/100] [Batch 16/347] [D loss: 0.314640] [G loss: 0.337905]\n",
      "[Epoch 93/100] [Batch 17/347] [D loss: 0.330974] [G loss: 0.311195]\n",
      "[Epoch 93/100] [Batch 18/347] [D loss: 0.378797] [G loss: 0.273092]\n",
      "[Epoch 93/100] [Batch 19/347] [D loss: 0.400587] [G loss: 0.249962]\n",
      "[Epoch 93/100] [Batch 20/347] [D loss: 0.416564] [G loss: 0.256842]\n",
      "[Epoch 93/100] [Batch 21/347] [D loss: 0.391014] [G loss: 0.249593]\n",
      "[Epoch 93/100] [Batch 22/347] [D loss: 0.389575] [G loss: 0.252854]\n",
      "[Epoch 93/100] [Batch 23/347] [D loss: 0.379818] [G loss: 0.266455]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 93/100] [Batch 24/347] [D loss: 0.324186] [G loss: 0.299144]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 93/100] [Batch 25/347] [D loss: 0.254383] [G loss: 0.294106]\n",
      "[Epoch 93/100] [Batch 26/347] [D loss: 0.250809] [G loss: 0.306627]\n",
      "[Epoch 93/100] [Batch 27/347] [D loss: 0.238063] [G loss: 0.333861]\n",
      "[Epoch 93/100] [Batch 28/347] [D loss: 0.233045] [G loss: 0.366625]\n",
      "[Epoch 93/100] [Batch 29/347] [D loss: 0.321963] [G loss: 0.309670]\n",
      "[Epoch 93/100] [Batch 30/347] [D loss: 0.282475] [G loss: 0.338500]\n",
      "[Epoch 93/100] [Batch 31/347] [D loss: 0.273662] [G loss: 0.357483]\n",
      "[Epoch 93/100] [Batch 32/347] [D loss: 0.291022] [G loss: 0.339293]\n",
      "[Epoch 93/100] [Batch 33/347] [D loss: 0.295864] [G loss: 0.377372]\n",
      "[Epoch 93/100] [Batch 34/347] [D loss: 0.382030] [G loss: 0.391652]\n",
      "[Epoch 93/100] [Batch 35/347] [D loss: 0.405397] [G loss: 0.405392]\n",
      "[Epoch 93/100] [Batch 36/347] [D loss: 0.447323] [G loss: 0.427336]\n",
      "[Epoch 93/100] [Batch 37/347] [D loss: 0.457425] [G loss: 0.466717]\n",
      "[Epoch 93/100] [Batch 38/347] [D loss: 0.468469] [G loss: 0.505811]\n",
      "[Epoch 93/100] [Batch 39/347] [D loss: 0.481027] [G loss: 0.502681]\n",
      "[Epoch 93/100] [Batch 40/347] [D loss: 0.515307] [G loss: 0.536147]\n",
      "[Epoch 93/100] [Batch 41/347] [D loss: 0.498297] [G loss: 0.559618]\n",
      "[Epoch 93/100] [Batch 42/347] [D loss: 0.466355] [G loss: 0.587539]\n",
      "[Epoch 93/100] [Batch 43/347] [D loss: 0.490124] [G loss: 0.598448]\n",
      "[Epoch 93/100] [Batch 44/347] [D loss: 0.439106] [G loss: 0.622311]\n",
      "[Epoch 93/100] [Batch 45/347] [D loss: 0.381101] [G loss: 0.586294]\n",
      "[Epoch 93/100] [Batch 46/347] [D loss: 0.282630] [G loss: 0.511124]\n",
      "[Epoch 93/100] [Batch 47/347] [D loss: 0.292407] [G loss: 0.457497]\n",
      "[Epoch 93/100] [Batch 48/347] [D loss: 0.148936] [G loss: 0.432042]\n",
      "[Epoch 93/100] [Batch 49/347] [D loss: 0.151368] [G loss: 0.415791]\n",
      "[Epoch 93/100] [Batch 50/347] [D loss: 0.247689] [G loss: 0.299282]\n",
      "[Epoch 93/100] [Batch 51/347] [D loss: 0.240644] [G loss: 0.327643]\n",
      "[Epoch 93/100] [Batch 52/347] [D loss: 0.483006] [G loss: 0.227446]\n",
      "[Epoch 93/100] [Batch 53/347] [D loss: 0.563576] [G loss: 0.181018]\n",
      "[Epoch 93/100] [Batch 54/347] [D loss: 0.571710] [G loss: 0.161806]\n",
      "[Epoch 93/100] [Batch 55/347] [D loss: 0.578606] [G loss: 0.154984]\n",
      "[Epoch 93/100] [Batch 56/347] [D loss: 0.421978] [G loss: 0.294017]\n",
      "[Epoch 93/100] [Batch 57/347] [D loss: 0.257154] [G loss: 0.446055]\n",
      "[Epoch 93/100] [Batch 58/347] [D loss: 0.235161] [G loss: 0.492583]\n",
      "[Epoch 93/100] [Batch 59/347] [D loss: 0.229349] [G loss: 0.491336]\n",
      "[Epoch 93/100] [Batch 60/347] [D loss: 0.262671] [G loss: 0.447810]\n",
      "[Epoch 93/100] [Batch 61/347] [D loss: 0.309781] [G loss: 0.420489]\n",
      "[Epoch 93/100] [Batch 62/347] [D loss: 0.308503] [G loss: 0.449997]\n",
      "[Epoch 93/100] [Batch 63/347] [D loss: 0.277092] [G loss: 0.446738]\n",
      "[Epoch 93/100] [Batch 64/347] [D loss: 0.260223] [G loss: 0.473212]\n",
      "[Epoch 93/100] [Batch 65/347] [D loss: 0.219496] [G loss: 0.514074]\n",
      "[Epoch 93/100] [Batch 66/347] [D loss: 0.233640] [G loss: 0.490614]\n",
      "[Epoch 93/100] [Batch 67/347] [D loss: 0.273917] [G loss: 0.436898]\n",
      "[Epoch 93/100] [Batch 68/347] [D loss: 0.303688] [G loss: 0.396259]\n",
      "[Epoch 93/100] [Batch 69/347] [D loss: 0.382511] [G loss: 0.299222]\n",
      "[Epoch 93/100] [Batch 70/347] [D loss: 0.372770] [G loss: 0.306850]\n",
      "[Epoch 93/100] [Batch 71/347] [D loss: 0.307998] [G loss: 0.345714]\n",
      "[Epoch 93/100] [Batch 72/347] [D loss: 0.295519] [G loss: 0.379750]\n",
      "[Epoch 93/100] [Batch 73/347] [D loss: 0.412015] [G loss: 0.412484]\n",
      "[Epoch 93/100] [Batch 74/347] [D loss: 0.381332] [G loss: 0.445185]\n",
      "[Epoch 93/100] [Batch 75/347] [D loss: 0.401043] [G loss: 0.414481]\n",
      "[Epoch 93/100] [Batch 76/347] [D loss: 0.410972] [G loss: 0.397948]\n",
      "[Epoch 93/100] [Batch 77/347] [D loss: 0.406042] [G loss: 0.525504]\n",
      "[Epoch 93/100] [Batch 78/347] [D loss: 0.416377] [G loss: 0.542328]\n",
      "[Epoch 93/100] [Batch 79/347] [D loss: 0.388893] [G loss: 0.526472]\n",
      "[Epoch 93/100] [Batch 80/347] [D loss: 0.263878] [G loss: 0.488031]\n",
      "[Epoch 93/100] [Batch 81/347] [D loss: 0.256791] [G loss: 0.450629]\n",
      "[Epoch 93/100] [Batch 82/347] [D loss: 0.213789] [G loss: 0.511834]\n",
      "[Epoch 93/100] [Batch 83/347] [D loss: 0.217103] [G loss: 0.507875]\n",
      "[Epoch 93/100] [Batch 84/347] [D loss: 0.429057] [G loss: 0.443155]\n",
      "[Epoch 93/100] [Batch 85/347] [D loss: 0.562730] [G loss: 0.388295]\n",
      "[Epoch 93/100] [Batch 86/347] [D loss: 0.563916] [G loss: 0.357089]\n",
      "[Epoch 93/100] [Batch 87/347] [D loss: 0.553084] [G loss: 0.340196]\n",
      "[Epoch 93/100] [Batch 88/347] [D loss: 0.530502] [G loss: 0.357377]\n",
      "[Epoch 93/100] [Batch 89/347] [D loss: 0.462260] [G loss: 0.434929]\n",
      "[Epoch 93/100] [Batch 90/347] [D loss: 0.446802] [G loss: 0.411135]\n",
      "[Epoch 93/100] [Batch 91/347] [D loss: 0.436290] [G loss: 0.381792]\n",
      "[Epoch 93/100] [Batch 92/347] [D loss: 0.424806] [G loss: 0.360448]\n",
      "[Epoch 93/100] [Batch 93/347] [D loss: 0.408293] [G loss: 0.343179]\n",
      "[Epoch 93/100] [Batch 94/347] [D loss: 0.389272] [G loss: 0.314771]\n",
      "[Epoch 93/100] [Batch 95/347] [D loss: 0.364654] [G loss: 0.291531]\n",
      "[Epoch 93/100] [Batch 96/347] [D loss: 0.367297] [G loss: 0.276864]\n",
      "[Epoch 93/100] [Batch 97/347] [D loss: 0.364470] [G loss: 0.262132]\n",
      "[Epoch 93/100] [Batch 98/347] [D loss: 0.361123] [G loss: 0.244843]\n",
      "[Epoch 93/100] [Batch 99/347] [D loss: 0.373015] [G loss: 0.239252]\n",
      "[Epoch 93/100] [Batch 100/347] [D loss: 0.376323] [G loss: 0.240973]\n",
      "[Epoch 93/100] [Batch 101/347] [D loss: 0.382858] [G loss: 0.244590]\n",
      "[Epoch 93/100] [Batch 102/347] [D loss: 0.447155] [G loss: 0.249684]\n",
      "[Epoch 93/100] [Batch 103/347] [D loss: 0.434048] [G loss: 0.270286]\n",
      "[Epoch 93/100] [Batch 104/347] [D loss: 0.405710] [G loss: 0.277717]\n",
      "[Epoch 93/100] [Batch 105/347] [D loss: 0.355277] [G loss: 0.286126]\n",
      "[Epoch 93/100] [Batch 106/347] [D loss: 0.265359] [G loss: 0.334452]\n",
      "[Epoch 93/100] [Batch 107/347] [D loss: 0.229753] [G loss: 0.373256]\n",
      "[Epoch 93/100] [Batch 108/347] [D loss: 0.204491] [G loss: 0.408002]\n",
      "[Epoch 93/100] [Batch 109/347] [D loss: 0.182420] [G loss: 0.434081]\n",
      "[Epoch 93/100] [Batch 110/347] [D loss: 0.607661] [G loss: 0.095463]\n",
      "[Epoch 93/100] [Batch 111/347] [D loss: 0.537043] [G loss: 0.139086]\n",
      "[Epoch 93/100] [Batch 112/347] [D loss: 0.457428] [G loss: 0.187451]\n",
      "[Epoch 93/100] [Batch 113/347] [D loss: 0.513729] [G loss: 0.257692]\n",
      "[Epoch 93/100] [Batch 114/347] [D loss: 0.518837] [G loss: 0.366299]\n",
      "[Epoch 93/100] [Batch 115/347] [D loss: 0.544946] [G loss: 0.422823]\n",
      "[Epoch 93/100] [Batch 116/347] [D loss: 0.532654] [G loss: 0.458509]\n",
      "[Epoch 93/100] [Batch 117/347] [D loss: 0.564008] [G loss: 0.583223]\n",
      "[Epoch 93/100] [Batch 118/347] [D loss: 0.404556] [G loss: 0.744553]\n",
      "[Epoch 93/100] [Batch 119/347] [D loss: 0.409734] [G loss: 0.728557]\n",
      "[Epoch 93/100] [Batch 120/347] [D loss: 0.375407] [G loss: 0.702630]\n",
      "[Epoch 93/100] [Batch 121/347] [D loss: 0.350362] [G loss: 0.684762]\n",
      "[Epoch 93/100] [Batch 122/347] [D loss: 0.529006] [G loss: 0.698905]\n",
      "[Epoch 93/100] [Batch 123/347] [D loss: 0.608268] [G loss: 0.697478]\n",
      "[Epoch 93/100] [Batch 124/347] [D loss: 0.494919] [G loss: 0.657655]\n",
      "[Epoch 93/100] [Batch 125/347] [D loss: 0.439002] [G loss: 0.624287]\n",
      "[Epoch 93/100] [Batch 126/347] [D loss: 0.390052] [G loss: 0.619174]\n",
      "[Epoch 93/100] [Batch 127/347] [D loss: 0.336896] [G loss: 0.632906]\n",
      "[Epoch 93/100] [Batch 128/347] [D loss: 0.270853] [G loss: 0.509440]\n",
      "[Epoch 93/100] [Batch 129/347] [D loss: 0.198550] [G loss: 0.413983]\n",
      "[Epoch 93/100] [Batch 130/347] [D loss: 0.171344] [G loss: 0.346989]\n",
      "[Epoch 93/100] [Batch 131/347] [D loss: 0.192685] [G loss: 0.337962]\n",
      "[Epoch 93/100] [Batch 132/347] [D loss: 0.222205] [G loss: 0.325213]\n",
      "[Epoch 93/100] [Batch 133/347] [D loss: 0.322943] [G loss: 0.260521]\n",
      "[Epoch 93/100] [Batch 134/347] [D loss: 0.599884] [G loss: 0.102377]\n",
      "[Epoch 93/100] [Batch 135/347] [D loss: 0.673336] [G loss: 0.090814]\n",
      "[Epoch 93/100] [Batch 136/347] [D loss: 0.593035] [G loss: 0.159870]\n",
      "[Epoch 93/100] [Batch 137/347] [D loss: 0.605183] [G loss: 0.178127]\n",
      "[Epoch 93/100] [Batch 138/347] [D loss: 0.606454] [G loss: 0.172766]\n",
      "[Epoch 93/100] [Batch 139/347] [D loss: 0.618299] [G loss: 0.174093]\n",
      "[Epoch 93/100] [Batch 140/347] [D loss: 0.645434] [G loss: 0.195936]\n",
      "[Epoch 93/100] [Batch 141/347] [D loss: 0.492826] [G loss: 0.507382]\n",
      "[Epoch 93/100] [Batch 142/347] [D loss: 0.416173] [G loss: 0.683728]\n",
      "[Epoch 93/100] [Batch 143/347] [D loss: 0.421103] [G loss: 0.731469]\n",
      "[Epoch 93/100] [Batch 144/347] [D loss: 0.427594] [G loss: 0.742534]\n",
      "[Epoch 93/100] [Batch 145/347] [D loss: 0.460639] [G loss: 0.767440]\n",
      "[Epoch 93/100] [Batch 146/347] [D loss: 0.484589] [G loss: 0.770761]\n",
      "[Epoch 93/100] [Batch 147/347] [D loss: 0.471354] [G loss: 0.780207]\n",
      "[Epoch 93/100] [Batch 148/347] [D loss: 0.528660] [G loss: 0.765143]\n",
      "[Epoch 93/100] [Batch 149/347] [D loss: 0.499493] [G loss: 0.693247]\n",
      "[Epoch 93/100] [Batch 150/347] [D loss: 0.469891] [G loss: 0.646125]\n",
      "[Epoch 93/100] [Batch 151/347] [D loss: 0.410447] [G loss: 0.632409]\n",
      "[Epoch 93/100] [Batch 152/347] [D loss: 0.377765] [G loss: 0.601250]\n",
      "[Epoch 93/100] [Batch 153/347] [D loss: 0.365454] [G loss: 0.516502]\n",
      "[Epoch 93/100] [Batch 154/347] [D loss: 0.315891] [G loss: 0.453390]\n",
      "[Epoch 93/100] [Batch 155/347] [D loss: 0.267406] [G loss: 0.404028]\n",
      "[Epoch 93/100] [Batch 156/347] [D loss: 0.254434] [G loss: 0.355361]\n",
      "[Epoch 93/100] [Batch 157/347] [D loss: 0.234407] [G loss: 0.338766]\n",
      "[Epoch 93/100] [Batch 158/347] [D loss: 0.216117] [G loss: 0.318152]\n",
      "[Epoch 93/100] [Batch 159/347] [D loss: 0.254828] [G loss: 0.277086]\n",
      "[Epoch 93/100] [Batch 160/347] [D loss: 0.258913] [G loss: 0.276448]\n",
      "[Epoch 93/100] [Batch 161/347] [D loss: 0.267314] [G loss: 0.266158]\n",
      "[Epoch 93/100] [Batch 162/347] [D loss: 0.375911] [G loss: 0.194607]\n",
      "[Epoch 93/100] [Batch 163/347] [D loss: 0.381280] [G loss: 0.213558]\n",
      "[Epoch 93/100] [Batch 164/347] [D loss: 0.386300] [G loss: 0.222952]\n",
      "[Epoch 93/100] [Batch 165/347] [D loss: 0.368498] [G loss: 0.233334]\n",
      "[Epoch 93/100] [Batch 166/347] [D loss: 0.315362] [G loss: 0.328412]\n",
      "[Epoch 93/100] [Batch 167/347] [D loss: 0.284798] [G loss: 0.423988]\n",
      "[Epoch 93/100] [Batch 168/347] [D loss: 0.275743] [G loss: 0.453208]\n",
      "[Epoch 93/100] [Batch 169/347] [D loss: 0.440795] [G loss: 0.449462]\n",
      "[Epoch 93/100] [Batch 170/347] [D loss: 0.533992] [G loss: 0.451139]\n",
      "[Epoch 93/100] [Batch 171/347] [D loss: 0.491582] [G loss: 0.417319]\n",
      "[Epoch 93/100] [Batch 172/347] [D loss: 0.523159] [G loss: 0.395387]\n",
      "[Epoch 93/100] [Batch 173/347] [D loss: 0.502623] [G loss: 0.508700]\n",
      "[Epoch 93/100] [Batch 174/347] [D loss: 0.437042] [G loss: 0.663374]\n",
      "[Epoch 93/100] [Batch 175/347] [D loss: 0.540820] [G loss: 0.653256]\n",
      "[Epoch 93/100] [Batch 176/347] [D loss: 0.536824] [G loss: 0.643770]\n",
      "[Epoch 93/100] [Batch 177/347] [D loss: 0.519396] [G loss: 0.623479]\n",
      "[Epoch 93/100] [Batch 178/347] [D loss: 0.487891] [G loss: 0.574916]\n",
      "[Epoch 93/100] [Batch 179/347] [D loss: 0.472310] [G loss: 0.548691]\n",
      "[Epoch 93/100] [Batch 180/347] [D loss: 0.448495] [G loss: 0.553374]\n",
      "[Epoch 93/100] [Batch 181/347] [D loss: 0.418189] [G loss: 0.511508]\n",
      "[Epoch 93/100] [Batch 182/347] [D loss: 0.403966] [G loss: 0.469951]\n",
      "[Epoch 93/100] [Batch 183/347] [D loss: 0.388815] [G loss: 0.439158]\n",
      "[Epoch 93/100] [Batch 184/347] [D loss: 0.430825] [G loss: 0.396966]\n",
      "[Epoch 93/100] [Batch 185/347] [D loss: 0.453566] [G loss: 0.356945]\n",
      "[Epoch 93/100] [Batch 186/347] [D loss: 0.431824] [G loss: 0.324654]\n",
      "[Epoch 93/100] [Batch 187/347] [D loss: 0.405920] [G loss: 0.295353]\n",
      "[Epoch 93/100] [Batch 188/347] [D loss: 0.368562] [G loss: 0.288269]\n",
      "[Epoch 93/100] [Batch 189/347] [D loss: 0.327283] [G loss: 0.270941]\n",
      "[Epoch 93/100] [Batch 190/347] [D loss: 0.332119] [G loss: 0.251118]\n",
      "[Epoch 93/100] [Batch 191/347] [D loss: 0.346612] [G loss: 0.235715]\n",
      "[Epoch 93/100] [Batch 192/347] [D loss: 0.365661] [G loss: 0.228662]\n",
      "[Epoch 93/100] [Batch 193/347] [D loss: 0.426567] [G loss: 0.216932]\n",
      "[Epoch 93/100] [Batch 194/347] [D loss: 0.412936] [G loss: 0.218673]\n",
      "[Epoch 93/100] [Batch 195/347] [D loss: 0.392498] [G loss: 0.228478]\n",
      "[Epoch 93/100] [Batch 196/347] [D loss: 0.355462] [G loss: 0.243731]\n",
      "[Epoch 93/100] [Batch 197/347] [D loss: 0.328685] [G loss: 0.275054]\n",
      "[Epoch 93/100] [Batch 198/347] [D loss: 0.311985] [G loss: 0.301708]\n",
      "[Epoch 93/100] [Batch 199/347] [D loss: 0.307226] [G loss: 0.321719]\n",
      "[Epoch 93/100] [Batch 200/347] [D loss: 0.374877] [G loss: 0.328415]\n",
      "[Epoch 93/100] [Batch 201/347] [D loss: 0.411114] [G loss: 0.348672]\n",
      "[Epoch 93/100] [Batch 202/347] [D loss: 0.445276] [G loss: 0.363882]\n",
      "[Epoch 93/100] [Batch 203/347] [D loss: 0.445867] [G loss: 0.371911]\n",
      "[Epoch 93/100] [Batch 204/347] [D loss: 0.415647] [G loss: 0.396510]\n",
      "[Epoch 93/100] [Batch 205/347] [D loss: 0.393824] [G loss: 0.427576]\n",
      "[Epoch 93/100] [Batch 206/347] [D loss: 0.388032] [G loss: 0.442230]\n",
      "[Epoch 93/100] [Batch 207/347] [D loss: 0.304410] [G loss: 0.453263]\n",
      "[Epoch 93/100] [Batch 208/347] [D loss: 0.298489] [G loss: 0.447755]\n",
      "[Epoch 93/100] [Batch 209/347] [D loss: 0.319868] [G loss: 0.425190]\n",
      "[Epoch 93/100] [Batch 210/347] [D loss: 0.274038] [G loss: 0.419827]\n",
      "[Epoch 93/100] [Batch 211/347] [D loss: 0.251690] [G loss: 0.386026]\n",
      "[Epoch 93/100] [Batch 212/347] [D loss: 0.186680] [G loss: 0.366898]\n",
      "[Epoch 93/100] [Batch 213/347] [D loss: 0.171759] [G loss: 0.398235]\n",
      "[Epoch 93/100] [Batch 214/347] [D loss: 0.205831] [G loss: 0.352353]\n",
      "[Epoch 93/100] [Batch 215/347] [D loss: 0.212185] [G loss: 0.353650]\n",
      "[Epoch 93/100] [Batch 216/347] [D loss: 0.542490] [G loss: 0.168039]\n",
      "[Epoch 93/100] [Batch 217/347] [D loss: 0.553787] [G loss: 0.217808]\n",
      "[Epoch 93/100] [Batch 218/347] [D loss: 0.572071] [G loss: 0.255646]\n",
      "[Epoch 93/100] [Batch 219/347] [D loss: 0.521995] [G loss: 0.286874]\n",
      "[Epoch 93/100] [Batch 220/347] [D loss: 0.370708] [G loss: 0.487049]\n",
      "[Epoch 93/100] [Batch 221/347] [D loss: 0.356614] [G loss: 0.604363]\n",
      "[Epoch 93/100] [Batch 222/347] [D loss: 0.369397] [G loss: 0.700856]\n",
      "[Epoch 93/100] [Batch 223/347] [D loss: 0.403550] [G loss: 0.715799]\n",
      "[Epoch 93/100] [Batch 224/347] [D loss: 0.468090] [G loss: 0.728193]\n",
      "[Epoch 93/100] [Batch 225/347] [D loss: 0.557002] [G loss: 0.692137]\n",
      "[Epoch 93/100] [Batch 226/347] [D loss: 0.570908] [G loss: 0.696842]\n",
      "[Epoch 93/100] [Batch 227/347] [D loss: 0.574012] [G loss: 0.654458]\n",
      "[Epoch 93/100] [Batch 228/347] [D loss: 0.544110] [G loss: 0.585335]\n",
      "[Epoch 93/100] [Batch 229/347] [D loss: 0.471116] [G loss: 0.540648]\n",
      "[Epoch 93/100] [Batch 230/347] [D loss: 0.462954] [G loss: 0.512167]\n",
      "[Epoch 93/100] [Batch 231/347] [D loss: 0.416089] [G loss: 0.487874]\n",
      "[Epoch 93/100] [Batch 232/347] [D loss: 0.376442] [G loss: 0.459075]\n",
      "[Epoch 93/100] [Batch 233/347] [D loss: 0.260789] [G loss: 0.429503]\n",
      "[Epoch 93/100] [Batch 234/347] [D loss: 0.212353] [G loss: 0.409877]\n",
      "[Epoch 93/100] [Batch 235/347] [D loss: 0.221253] [G loss: 0.395647]\n",
      "[Epoch 93/100] [Batch 236/347] [D loss: 0.234067] [G loss: 0.384312]\n",
      "[Epoch 93/100] [Batch 237/347] [D loss: 0.360405] [G loss: 0.335625]\n",
      "[Epoch 93/100] [Batch 238/347] [D loss: 0.471859] [G loss: 0.280425]\n",
      "[Epoch 93/100] [Batch 239/347] [D loss: 0.500947] [G loss: 0.246679]\n",
      "[Epoch 93/100] [Batch 240/347] [D loss: 0.536060] [G loss: 0.219195]\n",
      "[Epoch 93/100] [Batch 241/347] [D loss: 0.522157] [G loss: 0.235087]\n",
      "[Epoch 93/100] [Batch 242/347] [D loss: 0.401266] [G loss: 0.379933]\n",
      "[Epoch 93/100] [Batch 243/347] [D loss: 0.336650] [G loss: 0.387779]\n",
      "[Epoch 93/100] [Batch 244/347] [D loss: 0.301560] [G loss: 0.391566]\n",
      "[Epoch 93/100] [Batch 245/347] [D loss: 0.302479] [G loss: 0.381184]\n",
      "[Epoch 93/100] [Batch 246/347] [D loss: 0.306638] [G loss: 0.383110]\n",
      "[Epoch 93/100] [Batch 247/347] [D loss: 0.360419] [G loss: 0.382376]\n",
      "[Epoch 93/100] [Batch 248/347] [D loss: 0.395725] [G loss: 0.340115]\n",
      "[Epoch 93/100] [Batch 249/347] [D loss: 0.367817] [G loss: 0.348921]\n",
      "[Epoch 93/100] [Batch 250/347] [D loss: 0.339500] [G loss: 0.377885]\n",
      "[Epoch 93/100] [Batch 251/347] [D loss: 0.337298] [G loss: 0.419029]\n",
      "[Epoch 93/100] [Batch 252/347] [D loss: 0.333269] [G loss: 0.425929]\n",
      "[Epoch 93/100] [Batch 253/347] [D loss: 0.259554] [G loss: 0.403826]\n",
      "[Epoch 93/100] [Batch 254/347] [D loss: 0.254515] [G loss: 0.392724]\n",
      "[Epoch 93/100] [Batch 255/347] [D loss: 0.263864] [G loss: 0.380262]\n",
      "[Epoch 93/100] [Batch 256/347] [D loss: 0.268073] [G loss: 0.369677]\n",
      "[Epoch 93/100] [Batch 257/347] [D loss: 0.325072] [G loss: 0.290686]\n",
      "[Epoch 93/100] [Batch 258/347] [D loss: 0.308201] [G loss: 0.281246]\n",
      "[Epoch 93/100] [Batch 259/347] [D loss: 0.310779] [G loss: 0.304238]\n",
      "[Epoch 93/100] [Batch 260/347] [D loss: 0.301711] [G loss: 0.325267]\n",
      "[Epoch 93/100] [Batch 261/347] [D loss: 0.261599] [G loss: 0.371820]\n",
      "[Epoch 93/100] [Batch 262/347] [D loss: 0.217492] [G loss: 0.424790]\n",
      "[Epoch 93/100] [Batch 263/347] [D loss: 0.203940] [G loss: 0.462093]\n",
      "[Epoch 93/100] [Batch 264/347] [D loss: 0.200045] [G loss: 0.488009]\n",
      "[Epoch 93/100] [Batch 265/347] [D loss: 0.216677] [G loss: 0.481572]\n",
      "[Epoch 93/100] [Batch 266/347] [D loss: 0.325602] [G loss: 0.428164]\n",
      "[Epoch 93/100] [Batch 267/347] [D loss: 0.355449] [G loss: 0.428924]\n",
      "[Epoch 93/100] [Batch 268/347] [D loss: 0.372380] [G loss: 0.439581]\n",
      "[Epoch 93/100] [Batch 269/347] [D loss: 0.368769] [G loss: 0.462867]\n",
      "[Epoch 93/100] [Batch 270/347] [D loss: 0.370928] [G loss: 0.531613]\n",
      "[Epoch 93/100] [Batch 271/347] [D loss: 0.295550] [G loss: 0.594586]\n",
      "[Epoch 93/100] [Batch 272/347] [D loss: 0.206576] [G loss: 0.635504]\n",
      "[Epoch 93/100] [Batch 273/347] [D loss: 0.182113] [G loss: 0.680488]\n",
      "[Epoch 93/100] [Batch 274/347] [D loss: 0.157893] [G loss: 0.718142]\n",
      "[Epoch 93/100] [Batch 275/347] [D loss: 0.129768] [G loss: 0.739950]\n",
      "[Epoch 93/100] [Batch 276/347] [D loss: 0.589930] [G loss: 0.205706]\n",
      "[Epoch 93/100] [Batch 277/347] [D loss: 0.603741] [G loss: 0.212389]\n",
      "[Epoch 93/100] [Batch 278/347] [D loss: 0.598579] [G loss: 0.243706]\n",
      "[Epoch 93/100] [Batch 279/347] [D loss: 0.590086] [G loss: 0.258278]\n",
      "[Epoch 93/100] [Batch 280/347] [D loss: 0.630324] [G loss: 0.645224]\n",
      "[Epoch 93/100] [Batch 281/347] [D loss: 0.697223] [G loss: 0.794199]\n",
      "[Epoch 93/100] [Batch 282/347] [D loss: 0.716921] [G loss: 0.791727]\n",
      "[Epoch 93/100] [Batch 283/347] [D loss: 0.687579] [G loss: 0.786960]\n",
      "[Epoch 93/100] [Batch 284/347] [D loss: 0.662368] [G loss: 0.777048]\n",
      "[Epoch 93/100] [Batch 285/347] [D loss: 0.615041] [G loss: 0.760347]\n",
      "[Epoch 93/100] [Batch 286/347] [D loss: 0.523283] [G loss: 0.729047]\n",
      "[Epoch 93/100] [Batch 287/347] [D loss: 0.455667] [G loss: 0.663480]\n",
      "[Epoch 93/100] [Batch 288/347] [D loss: 0.400429] [G loss: 0.576174]\n",
      "[Epoch 93/100] [Batch 289/347] [D loss: 0.358199] [G loss: 0.468124]\n",
      "[Epoch 93/100] [Batch 290/347] [D loss: 0.343934] [G loss: 0.356361]\n",
      "[Epoch 93/100] [Batch 291/347] [D loss: 0.311490] [G loss: 0.331061]\n",
      "[Epoch 93/100] [Batch 292/347] [D loss: 0.301356] [G loss: 0.306174]\n",
      "[Epoch 93/100] [Batch 293/347] [D loss: 0.269233] [G loss: 0.304703]\n",
      "[Epoch 93/100] [Batch 294/347] [D loss: 0.281030] [G loss: 0.297079]\n",
      "[Epoch 93/100] [Batch 295/347] [D loss: 0.301179] [G loss: 0.277226]\n",
      "[Epoch 93/100] [Batch 296/347] [D loss: 0.322644] [G loss: 0.262802]\n",
      "[Epoch 93/100] [Batch 297/347] [D loss: 0.499535] [G loss: 0.196372]\n",
      "[Epoch 93/100] [Batch 298/347] [D loss: 0.526689] [G loss: 0.168999]\n",
      "[Epoch 93/100] [Batch 299/347] [D loss: 0.514666] [G loss: 0.173286]\n",
      "[Epoch 93/100] [Batch 300/347] [D loss: 0.488772] [G loss: 0.193328]\n",
      "[Epoch 93/100] [Batch 301/347] [D loss: 0.390766] [G loss: 0.302566]\n",
      "[Epoch 93/100] [Batch 302/347] [D loss: 0.322227] [G loss: 0.384884]\n",
      "[Epoch 93/100] [Batch 303/347] [D loss: 0.348217] [G loss: 0.399665]\n",
      "[Epoch 93/100] [Batch 304/347] [D loss: 0.291098] [G loss: 0.412341]\n",
      "[Epoch 93/100] [Batch 305/347] [D loss: 0.194725] [G loss: 0.430661]\n",
      "[Epoch 93/100] [Batch 306/347] [D loss: 0.180248] [G loss: 0.444335]\n",
      "[Epoch 93/100] [Batch 307/347] [D loss: 0.161152] [G loss: 0.497157]\n",
      "[Epoch 93/100] [Batch 308/347] [D loss: 0.235291] [G loss: 0.512039]\n",
      "[Epoch 93/100] [Batch 309/347] [D loss: 0.457922] [G loss: 0.433701]\n",
      "[Epoch 93/100] [Batch 310/347] [D loss: 0.593002] [G loss: 0.462550]\n",
      "[Epoch 93/100] [Batch 311/347] [D loss: 0.549675] [G loss: 0.447397]\n",
      "[Epoch 93/100] [Batch 312/347] [D loss: 0.471811] [G loss: 0.427700]\n",
      "[Epoch 93/100] [Batch 313/347] [D loss: 0.386458] [G loss: 0.522345]\n",
      "[Epoch 93/100] [Batch 314/347] [D loss: 0.369242] [G loss: 0.599804]\n",
      "[Epoch 93/100] [Batch 315/347] [D loss: 0.372458] [G loss: 0.620856]\n",
      "[Epoch 93/100] [Batch 316/347] [D loss: 0.395042] [G loss: 0.520140]\n",
      "[Epoch 93/100] [Batch 317/347] [D loss: 0.403426] [G loss: 0.471424]\n",
      "[Epoch 93/100] [Batch 318/347] [D loss: 0.361037] [G loss: 0.482116]\n",
      "[Epoch 93/100] [Batch 319/347] [D loss: 0.315369] [G loss: 0.495538]\n",
      "[Epoch 93/100] [Batch 320/347] [D loss: 0.314575] [G loss: 0.477205]\n",
      "[Epoch 93/100] [Batch 321/347] [D loss: 0.286919] [G loss: 0.446291]\n",
      "[Epoch 93/100] [Batch 322/347] [D loss: 0.305247] [G loss: 0.407608]\n",
      "[Epoch 93/100] [Batch 323/347] [D loss: 0.238977] [G loss: 0.405961]\n",
      "[Epoch 93/100] [Batch 324/347] [D loss: 0.228888] [G loss: 0.408326]\n",
      "[Epoch 93/100] [Batch 325/347] [D loss: 0.239788] [G loss: 0.383498]\n",
      "[Epoch 93/100] [Batch 326/347] [D loss: 0.246260] [G loss: 0.369408]\n",
      "[Epoch 93/100] [Batch 327/347] [D loss: 0.265480] [G loss: 0.338830]\n",
      "[Epoch 93/100] [Batch 328/347] [D loss: 0.298643] [G loss: 0.298626]\n",
      "[Epoch 93/100] [Batch 329/347] [D loss: 0.299260] [G loss: 0.287187]\n",
      "[Epoch 93/100] [Batch 330/347] [D loss: 0.284892] [G loss: 0.291021]\n",
      "[Epoch 93/100] [Batch 331/347] [D loss: 0.337842] [G loss: 0.305171]\n",
      "[Epoch 93/100] [Batch 332/347] [D loss: 0.418570] [G loss: 0.338875]\n",
      "[Epoch 93/100] [Batch 333/347] [D loss: 0.359736] [G loss: 0.357376]\n",
      "[Epoch 93/100] [Batch 334/347] [D loss: 0.348684] [G loss: 0.354765]\n",
      "[Epoch 93/100] [Batch 335/347] [D loss: 0.354924] [G loss: 0.360384]\n",
      "[Epoch 93/100] [Batch 336/347] [D loss: 0.317672] [G loss: 0.423621]\n",
      "[Epoch 93/100] [Batch 337/347] [D loss: 0.369792] [G loss: 0.446773]\n",
      "[Epoch 93/100] [Batch 338/347] [D loss: 0.433709] [G loss: 0.465208]\n",
      "[Epoch 93/100] [Batch 339/347] [D loss: 0.398115] [G loss: 0.471867]\n",
      "[Epoch 93/100] [Batch 340/347] [D loss: 0.365050] [G loss: 0.473554]\n",
      "[Epoch 93/100] [Batch 341/347] [D loss: 0.377580] [G loss: 0.484384]\n",
      "[Epoch 93/100] [Batch 342/347] [D loss: 0.211135] [G loss: 0.489973]\n",
      "[Epoch 93/100] [Batch 343/347] [D loss: 0.165416] [G loss: 0.481311]\n",
      "[Epoch 93/100] [Batch 344/347] [D loss: 0.161340] [G loss: 0.462260]\n",
      "[Epoch 93/100] [Batch 345/347] [D loss: 0.118973] [G loss: 0.474869]\n",
      "[Epoch 93/100] [Batch 346/347] [D loss: 0.186218] [G loss: 0.382523]\n",
      "[Epoch 93/100] [Batch 347/347] [D loss: 0.224345] [G loss: 0.329449]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 94/100] [Batch 1/347] [D loss: 0.441298] [G loss: 0.486933]\n",
      "[Epoch 94/100] [Batch 2/347] [D loss: 0.460953] [G loss: 0.493964]\n",
      "[Epoch 94/100] [Batch 3/347] [D loss: 0.484511] [G loss: 0.509405]\n",
      "[Epoch 94/100] [Batch 4/347] [D loss: 0.500304] [G loss: 0.503309]\n",
      "[Epoch 94/100] [Batch 5/347] [D loss: 0.500778] [G loss: 0.503233]\n",
      "[Epoch 94/100] [Batch 6/347] [D loss: 0.422200] [G loss: 0.506147]\n",
      "[Epoch 94/100] [Batch 7/347] [D loss: 0.348239] [G loss: 0.527499]\n",
      "[Epoch 94/100] [Batch 8/347] [D loss: 0.339034] [G loss: 0.508911]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 94/100] [Batch 9/347] [D loss: 0.324992] [G loss: 0.482005]\n",
      "[Epoch 94/100] [Batch 10/347] [D loss: 0.344962] [G loss: 0.443969]\n",
      "[Epoch 94/100] [Batch 11/347] [D loss: 0.411227] [G loss: 0.409130]\n",
      "[Epoch 94/100] [Batch 12/347] [D loss: 0.397638] [G loss: 0.386560]\n",
      "[Epoch 94/100] [Batch 13/347] [D loss: 0.354959] [G loss: 0.362181]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 94/100] [Batch 14/347] [D loss: 0.324956] [G loss: 0.343319]\n",
      "[Epoch 94/100] [Batch 15/347] [D loss: 0.307529] [G loss: 0.350334]\n",
      "[Epoch 94/100] [Batch 16/347] [D loss: 0.300594] [G loss: 0.359269]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 94/100] [Batch 17/347] [D loss: 0.313377] [G loss: 0.331583]\n",
      "[Epoch 94/100] [Batch 18/347] [D loss: 0.355437] [G loss: 0.292774]\n",
      "[Epoch 94/100] [Batch 19/347] [D loss: 0.380421] [G loss: 0.258884]\n",
      "[Epoch 94/100] [Batch 20/347] [D loss: 0.396907] [G loss: 0.261351]\n",
      "[Epoch 94/100] [Batch 21/347] [D loss: 0.381253] [G loss: 0.255483]\n",
      "[Epoch 94/100] [Batch 22/347] [D loss: 0.381514] [G loss: 0.260574]\n",
      "[Epoch 94/100] [Batch 23/347] [D loss: 0.370935] [G loss: 0.277215]\n",
      "[Epoch 94/100] [Batch 24/347] [D loss: 0.321138] [G loss: 0.303168]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 94/100] [Batch 25/347] [D loss: 0.243043] [G loss: 0.317648]\n",
      "[Epoch 94/100] [Batch 26/347] [D loss: 0.238250] [G loss: 0.331833]\n",
      "[Epoch 94/100] [Batch 27/347] [D loss: 0.228757] [G loss: 0.357011]\n",
      "[Epoch 94/100] [Batch 28/347] [D loss: 0.222436] [G loss: 0.390419]\n",
      "[Epoch 94/100] [Batch 29/347] [D loss: 0.272778] [G loss: 0.369878]\n",
      "[Epoch 94/100] [Batch 30/347] [D loss: 0.231091] [G loss: 0.400354]\n",
      "[Epoch 94/100] [Batch 31/347] [D loss: 0.222807] [G loss: 0.421399]\n",
      "[Epoch 94/100] [Batch 32/347] [D loss: 0.239413] [G loss: 0.403961]\n",
      "[Epoch 94/100] [Batch 33/347] [D loss: 0.252652] [G loss: 0.420591]\n",
      "[Epoch 94/100] [Batch 34/347] [D loss: 0.342780] [G loss: 0.432794]\n",
      "[Epoch 94/100] [Batch 35/347] [D loss: 0.365073] [G loss: 0.452422]\n",
      "[Epoch 94/100] [Batch 36/347] [D loss: 0.400453] [G loss: 0.486166]\n",
      "[Epoch 94/100] [Batch 37/347] [D loss: 0.403529] [G loss: 0.545679]\n",
      "[Epoch 94/100] [Batch 38/347] [D loss: 0.421445] [G loss: 0.590737]\n",
      "[Epoch 94/100] [Batch 39/347] [D loss: 0.440622] [G loss: 0.560063]\n",
      "[Epoch 94/100] [Batch 40/347] [D loss: 0.481350] [G loss: 0.580292]\n",
      "[Epoch 94/100] [Batch 41/347] [D loss: 0.454724] [G loss: 0.598116]\n",
      "[Epoch 94/100] [Batch 42/347] [D loss: 0.420841] [G loss: 0.613957]\n",
      "[Epoch 94/100] [Batch 43/347] [D loss: 0.448347] [G loss: 0.617857]\n",
      "[Epoch 94/100] [Batch 44/347] [D loss: 0.395561] [G loss: 0.633081]\n",
      "[Epoch 94/100] [Batch 45/347] [D loss: 0.338447] [G loss: 0.576224]\n",
      "[Epoch 94/100] [Batch 46/347] [D loss: 0.253948] [G loss: 0.497280]\n",
      "[Epoch 94/100] [Batch 47/347] [D loss: 0.266367] [G loss: 0.440430]\n",
      "[Epoch 94/100] [Batch 48/347] [D loss: 0.150632] [G loss: 0.417350]\n",
      "[Epoch 94/100] [Batch 49/347] [D loss: 0.159153] [G loss: 0.405889]\n",
      "[Epoch 94/100] [Batch 50/347] [D loss: 0.255329] [G loss: 0.304270]\n",
      "[Epoch 94/100] [Batch 51/347] [D loss: 0.254939] [G loss: 0.333075]\n",
      "[Epoch 94/100] [Batch 52/347] [D loss: 0.450612] [G loss: 0.259142]\n",
      "[Epoch 94/100] [Batch 53/347] [D loss: 0.515569] [G loss: 0.220354]\n",
      "[Epoch 94/100] [Batch 54/347] [D loss: 0.519117] [G loss: 0.208005]\n",
      "[Epoch 94/100] [Batch 55/347] [D loss: 0.526596] [G loss: 0.205842]\n",
      "[Epoch 94/100] [Batch 56/347] [D loss: 0.383963] [G loss: 0.349337]\n",
      "[Epoch 94/100] [Batch 57/347] [D loss: 0.243917] [G loss: 0.503948]\n",
      "[Epoch 94/100] [Batch 58/347] [D loss: 0.221162] [G loss: 0.567878]\n",
      "[Epoch 94/100] [Batch 59/347] [D loss: 0.213254] [G loss: 0.579683]\n",
      "[Epoch 94/100] [Batch 60/347] [D loss: 0.247480] [G loss: 0.544564]\n",
      "[Epoch 94/100] [Batch 61/347] [D loss: 0.291739] [G loss: 0.503710]\n",
      "[Epoch 94/100] [Batch 62/347] [D loss: 0.274395] [G loss: 0.581096]\n",
      "[Epoch 94/100] [Batch 63/347] [D loss: 0.240352] [G loss: 0.619388]\n",
      "[Epoch 94/100] [Batch 64/347] [D loss: 0.242510] [G loss: 0.618618]\n",
      "[Epoch 94/100] [Batch 65/347] [D loss: 0.212407] [G loss: 0.667344]\n",
      "[Epoch 94/100] [Batch 66/347] [D loss: 0.218834] [G loss: 0.646089]\n",
      "[Epoch 94/100] [Batch 67/347] [D loss: 0.259114] [G loss: 0.588179]\n",
      "[Epoch 94/100] [Batch 68/347] [D loss: 0.283904] [G loss: 0.529121]\n",
      "[Epoch 94/100] [Batch 69/347] [D loss: 0.309489] [G loss: 0.426039]\n",
      "[Epoch 94/100] [Batch 70/347] [D loss: 0.303932] [G loss: 0.433002]\n",
      "[Epoch 94/100] [Batch 71/347] [D loss: 0.249351] [G loss: 0.492593]\n",
      "[Epoch 94/100] [Batch 72/347] [D loss: 0.239703] [G loss: 0.530485]\n",
      "[Epoch 94/100] [Batch 73/347] [D loss: 0.373254] [G loss: 0.565966]\n",
      "[Epoch 94/100] [Batch 74/347] [D loss: 0.336886] [G loss: 0.608941]\n",
      "[Epoch 94/100] [Batch 75/347] [D loss: 0.355828] [G loss: 0.568849]\n",
      "[Epoch 94/100] [Batch 76/347] [D loss: 0.364481] [G loss: 0.539321]\n",
      "[Epoch 94/100] [Batch 77/347] [D loss: 0.376734] [G loss: 0.704718]\n",
      "[Epoch 94/100] [Batch 78/347] [D loss: 0.395048] [G loss: 0.717983]\n",
      "[Epoch 94/100] [Batch 79/347] [D loss: 0.361237] [G loss: 0.687138]\n",
      "[Epoch 94/100] [Batch 80/347] [D loss: 0.228257] [G loss: 0.621365]\n",
      "[Epoch 94/100] [Batch 81/347] [D loss: 0.228606] [G loss: 0.579596]\n",
      "[Epoch 94/100] [Batch 82/347] [D loss: 0.189596] [G loss: 0.700757]\n",
      "[Epoch 94/100] [Batch 83/347] [D loss: 0.195994] [G loss: 0.689432]\n",
      "[Epoch 94/100] [Batch 84/347] [D loss: 0.433172] [G loss: 0.604071]\n",
      "[Epoch 94/100] [Batch 85/347] [D loss: 0.584378] [G loss: 0.506785]\n",
      "[Epoch 94/100] [Batch 86/347] [D loss: 0.577149] [G loss: 0.459854]\n",
      "[Epoch 94/100] [Batch 87/347] [D loss: 0.554084] [G loss: 0.433443]\n",
      "[Epoch 94/100] [Batch 88/347] [D loss: 0.517809] [G loss: 0.432998]\n",
      "[Epoch 94/100] [Batch 89/347] [D loss: 0.460410] [G loss: 0.478759]\n",
      "[Epoch 94/100] [Batch 90/347] [D loss: 0.443381] [G loss: 0.440104]\n",
      "[Epoch 94/100] [Batch 91/347] [D loss: 0.429681] [G loss: 0.400210]\n",
      "[Epoch 94/100] [Batch 92/347] [D loss: 0.420400] [G loss: 0.368398]\n",
      "[Epoch 94/100] [Batch 93/347] [D loss: 0.407378] [G loss: 0.341617]\n",
      "[Epoch 94/100] [Batch 94/347] [D loss: 0.393150] [G loss: 0.310669]\n",
      "[Epoch 94/100] [Batch 95/347] [D loss: 0.371295] [G loss: 0.289154]\n",
      "[Epoch 94/100] [Batch 96/347] [D loss: 0.374108] [G loss: 0.273938]\n",
      "[Epoch 94/100] [Batch 97/347] [D loss: 0.370630] [G loss: 0.261413]\n",
      "[Epoch 94/100] [Batch 98/347] [D loss: 0.363489] [G loss: 0.250266]\n",
      "[Epoch 94/100] [Batch 99/347] [D loss: 0.370743] [G loss: 0.248977]\n",
      "[Epoch 94/100] [Batch 100/347] [D loss: 0.368709] [G loss: 0.253324]\n",
      "[Epoch 94/100] [Batch 101/347] [D loss: 0.370975] [G loss: 0.261606]\n",
      "[Epoch 94/100] [Batch 102/347] [D loss: 0.429399] [G loss: 0.271967]\n",
      "[Epoch 94/100] [Batch 103/347] [D loss: 0.416692] [G loss: 0.293449]\n",
      "[Epoch 94/100] [Batch 104/347] [D loss: 0.388479] [G loss: 0.304910]\n",
      "[Epoch 94/100] [Batch 105/347] [D loss: 0.334449] [G loss: 0.318565]\n",
      "[Epoch 94/100] [Batch 106/347] [D loss: 0.237924] [G loss: 0.367642]\n",
      "[Epoch 94/100] [Batch 107/347] [D loss: 0.201262] [G loss: 0.416015]\n",
      "[Epoch 94/100] [Batch 108/347] [D loss: 0.174545] [G loss: 0.475794]\n",
      "[Epoch 94/100] [Batch 109/347] [D loss: 0.148685] [G loss: 0.537212]\n",
      "[Epoch 94/100] [Batch 110/347] [D loss: 0.481987] [G loss: 0.167653]\n",
      "[Epoch 94/100] [Batch 111/347] [D loss: 0.414480] [G loss: 0.219907]\n",
      "[Epoch 94/100] [Batch 112/347] [D loss: 0.342049] [G loss: 0.284520]\n",
      "[Epoch 94/100] [Batch 113/347] [D loss: 0.402034] [G loss: 0.374286]\n",
      "[Epoch 94/100] [Batch 114/347] [D loss: 0.435021] [G loss: 0.520421]\n",
      "[Epoch 94/100] [Batch 115/347] [D loss: 0.486643] [G loss: 0.590821]\n",
      "[Epoch 94/100] [Batch 116/347] [D loss: 0.499281] [G loss: 0.629312]\n",
      "[Epoch 94/100] [Batch 117/347] [D loss: 0.579187] [G loss: 0.710440]\n",
      "[Epoch 94/100] [Batch 118/347] [D loss: 0.376429] [G loss: 0.860879]\n",
      "[Epoch 94/100] [Batch 119/347] [D loss: 0.355630] [G loss: 0.838696]\n",
      "[Epoch 94/100] [Batch 120/347] [D loss: 0.297448] [G loss: 0.809209]\n",
      "[Epoch 94/100] [Batch 121/347] [D loss: 0.254758] [G loss: 0.787070]\n",
      "[Epoch 94/100] [Batch 122/347] [D loss: 0.451301] [G loss: 0.781999]\n",
      "[Epoch 94/100] [Batch 123/347] [D loss: 0.499978] [G loss: 0.742861]\n",
      "[Epoch 94/100] [Batch 124/347] [D loss: 0.363367] [G loss: 0.648307]\n",
      "[Epoch 94/100] [Batch 125/347] [D loss: 0.313191] [G loss: 0.567919]\n",
      "[Epoch 94/100] [Batch 126/347] [D loss: 0.277677] [G loss: 0.550041]\n",
      "[Epoch 94/100] [Batch 127/347] [D loss: 0.239517] [G loss: 0.506850]\n",
      "[Epoch 94/100] [Batch 128/347] [D loss: 0.221195] [G loss: 0.407206]\n",
      "[Epoch 94/100] [Batch 129/347] [D loss: 0.218277] [G loss: 0.331847]\n",
      "[Epoch 94/100] [Batch 130/347] [D loss: 0.245648] [G loss: 0.284621]\n",
      "[Epoch 94/100] [Batch 131/347] [D loss: 0.266141] [G loss: 0.274412]\n",
      "[Epoch 94/100] [Batch 132/347] [D loss: 0.286328] [G loss: 0.276612]\n",
      "[Epoch 94/100] [Batch 133/347] [D loss: 0.387720] [G loss: 0.241488]\n",
      "[Epoch 94/100] [Batch 134/347] [D loss: 0.668354] [G loss: 0.121220]\n",
      "[Epoch 94/100] [Batch 135/347] [D loss: 0.702785] [G loss: 0.117742]\n",
      "[Epoch 94/100] [Batch 136/347] [D loss: 0.578239] [G loss: 0.206258]\n",
      "[Epoch 94/100] [Batch 137/347] [D loss: 0.502003] [G loss: 0.244289]\n",
      "[Epoch 94/100] [Batch 138/347] [D loss: 0.477416] [G loss: 0.262049]\n",
      "[Epoch 94/100] [Batch 139/347] [D loss: 0.473378] [G loss: 0.291108]\n",
      "[Epoch 94/100] [Batch 140/347] [D loss: 0.527313] [G loss: 0.334083]\n",
      "[Epoch 94/100] [Batch 141/347] [D loss: 0.479792] [G loss: 0.658123]\n",
      "[Epoch 94/100] [Batch 142/347] [D loss: 0.470311] [G loss: 0.822824]\n",
      "[Epoch 94/100] [Batch 143/347] [D loss: 0.499176] [G loss: 0.843093]\n",
      "[Epoch 94/100] [Batch 144/347] [D loss: 0.480723] [G loss: 0.851716]\n",
      "[Epoch 94/100] [Batch 145/347] [D loss: 0.472944] [G loss: 0.875178]\n",
      "[Epoch 94/100] [Batch 146/347] [D loss: 0.450060] [G loss: 0.866495]\n",
      "[Epoch 94/100] [Batch 147/347] [D loss: 0.395180] [G loss: 0.852495]\n",
      "[Epoch 94/100] [Batch 148/347] [D loss: 0.431831] [G loss: 0.803606]\n",
      "[Epoch 94/100] [Batch 149/347] [D loss: 0.388657] [G loss: 0.680891]\n",
      "[Epoch 94/100] [Batch 150/347] [D loss: 0.359498] [G loss: 0.582960]\n",
      "[Epoch 94/100] [Batch 151/347] [D loss: 0.304931] [G loss: 0.542301]\n",
      "[Epoch 94/100] [Batch 152/347] [D loss: 0.278707] [G loss: 0.479977]\n",
      "[Epoch 94/100] [Batch 153/347] [D loss: 0.284803] [G loss: 0.415684]\n",
      "[Epoch 94/100] [Batch 154/347] [D loss: 0.259529] [G loss: 0.358145]\n",
      "[Epoch 94/100] [Batch 155/347] [D loss: 0.244961] [G loss: 0.315315]\n",
      "[Epoch 94/100] [Batch 156/347] [D loss: 0.259107] [G loss: 0.284015]\n",
      "[Epoch 94/100] [Batch 157/347] [D loss: 0.256040] [G loss: 0.281220]\n",
      "[Epoch 94/100] [Batch 158/347] [D loss: 0.256972] [G loss: 0.279215]\n",
      "[Epoch 94/100] [Batch 159/347] [D loss: 0.282757] [G loss: 0.258708]\n",
      "[Epoch 94/100] [Batch 160/347] [D loss: 0.284056] [G loss: 0.272942]\n",
      "[Epoch 94/100] [Batch 161/347] [D loss: 0.278244] [G loss: 0.281243]\n",
      "[Epoch 94/100] [Batch 162/347] [D loss: 0.350440] [G loss: 0.221017]\n",
      "[Epoch 94/100] [Batch 163/347] [D loss: 0.333232] [G loss: 0.239668]\n",
      "[Epoch 94/100] [Batch 164/347] [D loss: 0.322773] [G loss: 0.267918]\n",
      "[Epoch 94/100] [Batch 165/347] [D loss: 0.293236] [G loss: 0.304728]\n",
      "[Epoch 94/100] [Batch 166/347] [D loss: 0.247445] [G loss: 0.428968]\n",
      "[Epoch 94/100] [Batch 167/347] [D loss: 0.238904] [G loss: 0.542305]\n",
      "[Epoch 94/100] [Batch 168/347] [D loss: 0.234683] [G loss: 0.589905]\n",
      "[Epoch 94/100] [Batch 169/347] [D loss: 0.401330] [G loss: 0.611459]\n",
      "[Epoch 94/100] [Batch 170/347] [D loss: 0.499123] [G loss: 0.657137]\n",
      "[Epoch 94/100] [Batch 171/347] [D loss: 0.432671] [G loss: 0.621503]\n",
      "[Epoch 94/100] [Batch 172/347] [D loss: 0.473834] [G loss: 0.604356]\n",
      "[Epoch 94/100] [Batch 173/347] [D loss: 0.485038] [G loss: 0.673227]\n",
      "[Epoch 94/100] [Batch 174/347] [D loss: 0.449338] [G loss: 0.803580]\n",
      "[Epoch 94/100] [Batch 175/347] [D loss: 0.577733] [G loss: 0.774053]\n",
      "[Epoch 94/100] [Batch 176/347] [D loss: 0.516477] [G loss: 0.704731]\n",
      "[Epoch 94/100] [Batch 177/347] [D loss: 0.459974] [G loss: 0.630310]\n",
      "[Epoch 94/100] [Batch 178/347] [D loss: 0.405489] [G loss: 0.513251]\n",
      "[Epoch 94/100] [Batch 179/347] [D loss: 0.388449] [G loss: 0.439243]\n",
      "[Epoch 94/100] [Batch 180/347] [D loss: 0.364290] [G loss: 0.409672]\n",
      "[Epoch 94/100] [Batch 181/347] [D loss: 0.345872] [G loss: 0.369511]\n",
      "[Epoch 94/100] [Batch 182/347] [D loss: 0.344464] [G loss: 0.330687]\n",
      "[Epoch 94/100] [Batch 183/347] [D loss: 0.349962] [G loss: 0.301609]\n",
      "[Epoch 94/100] [Batch 184/347] [D loss: 0.407042] [G loss: 0.269006]\n",
      "[Epoch 94/100] [Batch 185/347] [D loss: 0.439551] [G loss: 0.243620]\n",
      "[Epoch 94/100] [Batch 186/347] [D loss: 0.439698] [G loss: 0.228703]\n",
      "[Epoch 94/100] [Batch 187/347] [D loss: 0.430372] [G loss: 0.216343]\n",
      "[Epoch 94/100] [Batch 188/347] [D loss: 0.403272] [G loss: 0.218669]\n",
      "[Epoch 94/100] [Batch 189/347] [D loss: 0.374015] [G loss: 0.218788]\n",
      "[Epoch 94/100] [Batch 190/347] [D loss: 0.369826] [G loss: 0.220049]\n",
      "[Epoch 94/100] [Batch 191/347] [D loss: 0.371630] [G loss: 0.225022]\n",
      "[Epoch 94/100] [Batch 192/347] [D loss: 0.376057] [G loss: 0.237805]\n",
      "[Epoch 94/100] [Batch 193/347] [D loss: 0.410055] [G loss: 0.247390]\n",
      "[Epoch 94/100] [Batch 194/347] [D loss: 0.387234] [G loss: 0.265611]\n",
      "[Epoch 94/100] [Batch 195/347] [D loss: 0.360264] [G loss: 0.290417]\n",
      "[Epoch 94/100] [Batch 196/347] [D loss: 0.320151] [G loss: 0.316200]\n",
      "[Epoch 94/100] [Batch 197/347] [D loss: 0.302415] [G loss: 0.347501]\n",
      "[Epoch 94/100] [Batch 198/347] [D loss: 0.289503] [G loss: 0.382844]\n",
      "[Epoch 94/100] [Batch 199/347] [D loss: 0.287952] [G loss: 0.408082]\n",
      "[Epoch 94/100] [Batch 200/347] [D loss: 0.355220] [G loss: 0.421379]\n",
      "[Epoch 94/100] [Batch 201/347] [D loss: 0.395128] [G loss: 0.439697]\n",
      "[Epoch 94/100] [Batch 202/347] [D loss: 0.429288] [G loss: 0.466082]\n",
      "[Epoch 94/100] [Batch 203/347] [D loss: 0.427073] [G loss: 0.479756]\n",
      "[Epoch 94/100] [Batch 204/347] [D loss: 0.400732] [G loss: 0.479632]\n",
      "[Epoch 94/100] [Batch 205/347] [D loss: 0.380435] [G loss: 0.496557]\n",
      "[Epoch 94/100] [Batch 206/347] [D loss: 0.372728] [G loss: 0.505198]\n",
      "[Epoch 94/100] [Batch 207/347] [D loss: 0.291601] [G loss: 0.512923]\n",
      "[Epoch 94/100] [Batch 208/347] [D loss: 0.288860] [G loss: 0.504046]\n",
      "[Epoch 94/100] [Batch 209/347] [D loss: 0.315353] [G loss: 0.475378]\n",
      "[Epoch 94/100] [Batch 210/347] [D loss: 0.275677] [G loss: 0.466566]\n",
      "[Epoch 94/100] [Batch 211/347] [D loss: 0.234877] [G loss: 0.435034]\n",
      "[Epoch 94/100] [Batch 212/347] [D loss: 0.146706] [G loss: 0.417067]\n",
      "[Epoch 94/100] [Batch 213/347] [D loss: 0.140944] [G loss: 0.440865]\n",
      "[Epoch 94/100] [Batch 214/347] [D loss: 0.159870] [G loss: 0.412900]\n",
      "[Epoch 94/100] [Batch 215/347] [D loss: 0.167984] [G loss: 0.409016]\n",
      "[Epoch 94/100] [Batch 216/347] [D loss: 0.440195] [G loss: 0.220438]\n",
      "[Epoch 94/100] [Batch 217/347] [D loss: 0.445991] [G loss: 0.272787]\n",
      "[Epoch 94/100] [Batch 218/347] [D loss: 0.462276] [G loss: 0.312984]\n",
      "[Epoch 94/100] [Batch 219/347] [D loss: 0.420116] [G loss: 0.344558]\n",
      "[Epoch 94/100] [Batch 220/347] [D loss: 0.304027] [G loss: 0.594557]\n",
      "[Epoch 94/100] [Batch 221/347] [D loss: 0.300845] [G loss: 0.705613]\n",
      "[Epoch 94/100] [Batch 222/347] [D loss: 0.325486] [G loss: 0.785326]\n",
      "[Epoch 94/100] [Batch 223/347] [D loss: 0.363286] [G loss: 0.798284]\n",
      "[Epoch 94/100] [Batch 224/347] [D loss: 0.426454] [G loss: 0.816575]\n",
      "[Epoch 94/100] [Batch 225/347] [D loss: 0.511268] [G loss: 0.779390]\n",
      "[Epoch 94/100] [Batch 226/347] [D loss: 0.511966] [G loss: 0.743021]\n",
      "[Epoch 94/100] [Batch 227/347] [D loss: 0.487115] [G loss: 0.643926]\n",
      "[Epoch 94/100] [Batch 228/347] [D loss: 0.461569] [G loss: 0.514332]\n",
      "[Epoch 94/100] [Batch 229/347] [D loss: 0.399418] [G loss: 0.456961]\n",
      "[Epoch 94/100] [Batch 230/347] [D loss: 0.394143] [G loss: 0.442901]\n",
      "[Epoch 94/100] [Batch 231/347] [D loss: 0.356085] [G loss: 0.413380]\n",
      "[Epoch 94/100] [Batch 232/347] [D loss: 0.333983] [G loss: 0.383852]\n",
      "[Epoch 94/100] [Batch 233/347] [D loss: 0.260797] [G loss: 0.362936]\n",
      "[Epoch 94/100] [Batch 234/347] [D loss: 0.234609] [G loss: 0.350459]\n",
      "[Epoch 94/100] [Batch 235/347] [D loss: 0.247484] [G loss: 0.354165]\n",
      "[Epoch 94/100] [Batch 236/347] [D loss: 0.256948] [G loss: 0.359701]\n",
      "[Epoch 94/100] [Batch 237/347] [D loss: 0.348908] [G loss: 0.336649]\n",
      "[Epoch 94/100] [Batch 238/347] [D loss: 0.429541] [G loss: 0.306762]\n",
      "[Epoch 94/100] [Batch 239/347] [D loss: 0.450840] [G loss: 0.284249]\n",
      "[Epoch 94/100] [Batch 240/347] [D loss: 0.475116] [G loss: 0.268351]\n",
      "[Epoch 94/100] [Batch 241/347] [D loss: 0.464757] [G loss: 0.291415]\n",
      "[Epoch 94/100] [Batch 242/347] [D loss: 0.383312] [G loss: 0.426637]\n",
      "[Epoch 94/100] [Batch 243/347] [D loss: 0.316497] [G loss: 0.441715]\n",
      "[Epoch 94/100] [Batch 244/347] [D loss: 0.282535] [G loss: 0.447029]\n",
      "[Epoch 94/100] [Batch 245/347] [D loss: 0.284203] [G loss: 0.442264]\n",
      "[Epoch 94/100] [Batch 246/347] [D loss: 0.292501] [G loss: 0.441667]\n",
      "[Epoch 94/100] [Batch 247/347] [D loss: 0.342578] [G loss: 0.437152]\n",
      "[Epoch 94/100] [Batch 248/347] [D loss: 0.368807] [G loss: 0.390671]\n",
      "[Epoch 94/100] [Batch 249/347] [D loss: 0.341973] [G loss: 0.402826]\n",
      "[Epoch 94/100] [Batch 250/347] [D loss: 0.313450] [G loss: 0.425575]\n",
      "[Epoch 94/100] [Batch 251/347] [D loss: 0.323088] [G loss: 0.460230]\n",
      "[Epoch 94/100] [Batch 252/347] [D loss: 0.320985] [G loss: 0.461667]\n",
      "[Epoch 94/100] [Batch 253/347] [D loss: 0.238390] [G loss: 0.438682]\n",
      "[Epoch 94/100] [Batch 254/347] [D loss: 0.230439] [G loss: 0.428095]\n",
      "[Epoch 94/100] [Batch 255/347] [D loss: 0.234517] [G loss: 0.423518]\n",
      "[Epoch 94/100] [Batch 256/347] [D loss: 0.236169] [G loss: 0.419855]\n",
      "[Epoch 94/100] [Batch 257/347] [D loss: 0.281887] [G loss: 0.339098]\n",
      "[Epoch 94/100] [Batch 258/347] [D loss: 0.266818] [G loss: 0.314186]\n",
      "[Epoch 94/100] [Batch 259/347] [D loss: 0.271107] [G loss: 0.329985]\n",
      "[Epoch 94/100] [Batch 260/347] [D loss: 0.262056] [G loss: 0.354180]\n",
      "[Epoch 94/100] [Batch 261/347] [D loss: 0.219610] [G loss: 0.431951]\n",
      "[Epoch 94/100] [Batch 262/347] [D loss: 0.173456] [G loss: 0.508832]\n",
      "[Epoch 94/100] [Batch 263/347] [D loss: 0.158851] [G loss: 0.561201]\n",
      "[Epoch 94/100] [Batch 264/347] [D loss: 0.147553] [G loss: 0.636010]\n",
      "[Epoch 94/100] [Batch 265/347] [D loss: 0.156194] [G loss: 0.653271]\n",
      "[Epoch 94/100] [Batch 266/347] [D loss: 0.258571] [G loss: 0.589179]\n",
      "[Epoch 94/100] [Batch 267/347] [D loss: 0.285447] [G loss: 0.598226]\n",
      "[Epoch 94/100] [Batch 268/347] [D loss: 0.306494] [G loss: 0.628570]\n",
      "[Epoch 94/100] [Batch 269/347] [D loss: 0.307209] [G loss: 0.654164]\n",
      "[Epoch 94/100] [Batch 270/347] [D loss: 0.317198] [G loss: 0.719349]\n",
      "[Epoch 94/100] [Batch 271/347] [D loss: 0.256465] [G loss: 0.776614]\n",
      "[Epoch 94/100] [Batch 272/347] [D loss: 0.176618] [G loss: 0.803171]\n",
      "[Epoch 94/100] [Batch 273/347] [D loss: 0.159800] [G loss: 0.833930]\n",
      "[Epoch 94/100] [Batch 274/347] [D loss: 0.146345] [G loss: 0.851925]\n",
      "[Epoch 94/100] [Batch 275/347] [D loss: 0.125549] [G loss: 0.862487]\n",
      "[Epoch 94/100] [Batch 276/347] [D loss: 0.436162] [G loss: 0.298933]\n",
      "[Epoch 94/100] [Batch 277/347] [D loss: 0.445370] [G loss: 0.310780]\n",
      "[Epoch 94/100] [Batch 278/347] [D loss: 0.439301] [G loss: 0.343838]\n",
      "[Epoch 94/100] [Batch 279/347] [D loss: 0.429338] [G loss: 0.368361]\n",
      "[Epoch 94/100] [Batch 280/347] [D loss: 0.597882] [G loss: 0.730626]\n",
      "[Epoch 94/100] [Batch 281/347] [D loss: 0.714349] [G loss: 0.863404]\n",
      "[Epoch 94/100] [Batch 282/347] [D loss: 0.732069] [G loss: 0.849305]\n",
      "[Epoch 94/100] [Batch 283/347] [D loss: 0.673279] [G loss: 0.845663]\n",
      "[Epoch 94/100] [Batch 284/347] [D loss: 0.582814] [G loss: 0.834261]\n",
      "[Epoch 94/100] [Batch 285/347] [D loss: 0.482606] [G loss: 0.805585]\n",
      "[Epoch 94/100] [Batch 286/347] [D loss: 0.371169] [G loss: 0.722479]\n",
      "[Epoch 94/100] [Batch 287/347] [D loss: 0.317996] [G loss: 0.590954]\n",
      "[Epoch 94/100] [Batch 288/347] [D loss: 0.285392] [G loss: 0.467611]\n",
      "[Epoch 94/100] [Batch 289/347] [D loss: 0.281507] [G loss: 0.375844]\n",
      "[Epoch 94/100] [Batch 290/347] [D loss: 0.321750] [G loss: 0.257379]\n",
      "[Epoch 94/100] [Batch 291/347] [D loss: 0.325682] [G loss: 0.243735]\n",
      "[Epoch 94/100] [Batch 292/347] [D loss: 0.343893] [G loss: 0.233517]\n",
      "[Epoch 94/100] [Batch 293/347] [D loss: 0.361749] [G loss: 0.244009]\n",
      "[Epoch 94/100] [Batch 294/347] [D loss: 0.357459] [G loss: 0.249684]\n",
      "[Epoch 94/100] [Batch 295/347] [D loss: 0.352790] [G loss: 0.246006]\n",
      "[Epoch 94/100] [Batch 296/347] [D loss: 0.349712] [G loss: 0.249604]\n",
      "[Epoch 94/100] [Batch 297/347] [D loss: 0.417154] [G loss: 0.228144]\n",
      "[Epoch 94/100] [Batch 298/347] [D loss: 0.411722] [G loss: 0.222957]\n",
      "[Epoch 94/100] [Batch 299/347] [D loss: 0.386583] [G loss: 0.242864]\n",
      "[Epoch 94/100] [Batch 300/347] [D loss: 0.349714] [G loss: 0.282881]\n",
      "[Epoch 94/100] [Batch 301/347] [D loss: 0.308880] [G loss: 0.394550]\n",
      "[Epoch 94/100] [Batch 302/347] [D loss: 0.282160] [G loss: 0.492869]\n",
      "[Epoch 94/100] [Batch 303/347] [D loss: 0.313430] [G loss: 0.533164]\n",
      "[Epoch 94/100] [Batch 304/347] [D loss: 0.258688] [G loss: 0.539209]\n",
      "[Epoch 94/100] [Batch 305/347] [D loss: 0.160747] [G loss: 0.566099]\n",
      "[Epoch 94/100] [Batch 306/347] [D loss: 0.146384] [G loss: 0.617161]\n",
      "[Epoch 94/100] [Batch 307/347] [D loss: 0.122373] [G loss: 0.705852]\n",
      "[Epoch 94/100] [Batch 308/347] [D loss: 0.182348] [G loss: 0.745273]\n",
      "[Epoch 94/100] [Batch 309/347] [D loss: 0.394826] [G loss: 0.674809]\n",
      "[Epoch 94/100] [Batch 310/347] [D loss: 0.565355] [G loss: 0.705807]\n",
      "[Epoch 94/100] [Batch 311/347] [D loss: 0.511256] [G loss: 0.674293]\n",
      "[Epoch 94/100] [Batch 312/347] [D loss: 0.421321] [G loss: 0.637794]\n",
      "[Epoch 94/100] [Batch 313/347] [D loss: 0.378500] [G loss: 0.759482]\n",
      "[Epoch 94/100] [Batch 314/347] [D loss: 0.391477] [G loss: 0.810312]\n",
      "[Epoch 94/100] [Batch 315/347] [D loss: 0.400368] [G loss: 0.826162]\n",
      "[Epoch 94/100] [Batch 316/347] [D loss: 0.395617] [G loss: 0.739233]\n",
      "[Epoch 94/100] [Batch 317/347] [D loss: 0.382103] [G loss: 0.657698]\n",
      "[Epoch 94/100] [Batch 318/347] [D loss: 0.336129] [G loss: 0.622438]\n",
      "[Epoch 94/100] [Batch 319/347] [D loss: 0.295504] [G loss: 0.604051]\n",
      "[Epoch 94/100] [Batch 320/347] [D loss: 0.307049] [G loss: 0.567835]\n",
      "[Epoch 94/100] [Batch 321/347] [D loss: 0.283114] [G loss: 0.534898]\n",
      "[Epoch 94/100] [Batch 322/347] [D loss: 0.309052] [G loss: 0.477696]\n",
      "[Epoch 94/100] [Batch 323/347] [D loss: 0.235151] [G loss: 0.445630]\n",
      "[Epoch 94/100] [Batch 324/347] [D loss: 0.221635] [G loss: 0.446180]\n",
      "[Epoch 94/100] [Batch 325/347] [D loss: 0.229808] [G loss: 0.419955]\n",
      "[Epoch 94/100] [Batch 326/347] [D loss: 0.235226] [G loss: 0.408163]\n",
      "[Epoch 94/100] [Batch 327/347] [D loss: 0.242622] [G loss: 0.384873]\n",
      "[Epoch 94/100] [Batch 328/347] [D loss: 0.267010] [G loss: 0.352523]\n",
      "[Epoch 94/100] [Batch 329/347] [D loss: 0.264723] [G loss: 0.355227]\n",
      "[Epoch 94/100] [Batch 330/347] [D loss: 0.247606] [G loss: 0.380356]\n",
      "[Epoch 94/100] [Batch 331/347] [D loss: 0.298813] [G loss: 0.388059]\n",
      "[Epoch 94/100] [Batch 332/347] [D loss: 0.379862] [G loss: 0.412639]\n",
      "[Epoch 94/100] [Batch 333/347] [D loss: 0.316494] [G loss: 0.424521]\n",
      "[Epoch 94/100] [Batch 334/347] [D loss: 0.299364] [G loss: 0.419115]\n",
      "[Epoch 94/100] [Batch 335/347] [D loss: 0.307640] [G loss: 0.416424]\n",
      "[Epoch 94/100] [Batch 336/347] [D loss: 0.288341] [G loss: 0.481388]\n",
      "[Epoch 94/100] [Batch 337/347] [D loss: 0.336433] [G loss: 0.503189]\n",
      "[Epoch 94/100] [Batch 338/347] [D loss: 0.397801] [G loss: 0.523934]\n",
      "[Epoch 94/100] [Batch 339/347] [D loss: 0.361696] [G loss: 0.531248]\n",
      "[Epoch 94/100] [Batch 340/347] [D loss: 0.324469] [G loss: 0.551725]\n",
      "[Epoch 94/100] [Batch 341/347] [D loss: 0.341039] [G loss: 0.581143]\n",
      "[Epoch 94/100] [Batch 342/347] [D loss: 0.171913] [G loss: 0.602774]\n",
      "[Epoch 94/100] [Batch 343/347] [D loss: 0.121248] [G loss: 0.608070]\n",
      "[Epoch 94/100] [Batch 344/347] [D loss: 0.114785] [G loss: 0.605770]\n",
      "[Epoch 94/100] [Batch 345/347] [D loss: 0.068681] [G loss: 0.645335]\n",
      "[Epoch 94/100] [Batch 346/347] [D loss: 0.118023] [G loss: 0.520847]\n",
      "[Epoch 94/100] [Batch 347/347] [D loss: 0.148995] [G loss: 0.455498]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 95/100] [Batch 1/347] [D loss: 0.427431] [G loss: 0.643145]\n",
      "[Epoch 95/100] [Batch 2/347] [D loss: 0.447289] [G loss: 0.653158]\n",
      "[Epoch 95/100] [Batch 3/347] [D loss: 0.469886] [G loss: 0.662972]\n",
      "[Epoch 95/100] [Batch 4/347] [D loss: 0.482795] [G loss: 0.648348]\n",
      "[Epoch 95/100] [Batch 5/347] [D loss: 0.482280] [G loss: 0.656482]\n",
      "[Epoch 95/100] [Batch 6/347] [D loss: 0.396968] [G loss: 0.653715]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 95/100] [Batch 7/347] [D loss: 0.326018] [G loss: 0.638193]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 95/100] [Batch 8/347] [D loss: 0.315698] [G loss: 0.589838]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 95/100] [Batch 9/347] [D loss: 0.308151] [G loss: 0.539797]\n",
      "[Epoch 95/100] [Batch 10/347] [D loss: 0.335432] [G loss: 0.493038]\n",
      "[Epoch 95/100] [Batch 11/347] [D loss: 0.401835] [G loss: 0.455958]\n",
      "[Epoch 95/100] [Batch 12/347] [D loss: 0.391501] [G loss: 0.435396]\n",
      "[Epoch 95/100] [Batch 13/347] [D loss: 0.355239] [G loss: 0.412652]\n",
      "[Epoch 95/100] [Batch 14/347] [D loss: 0.331245] [G loss: 0.400384]\n",
      "[Epoch 95/100] [Batch 15/347] [D loss: 0.320468] [G loss: 0.390359]\n",
      "[Epoch 95/100] [Batch 16/347] [D loss: 0.318295] [G loss: 0.386447]\n",
      "[Epoch 95/100] [Batch 17/347] [D loss: 0.327774] [G loss: 0.375257]\n",
      "[Epoch 95/100] [Batch 18/347] [D loss: 0.361659] [G loss: 0.345141]\n",
      "[Epoch 95/100] [Batch 19/347] [D loss: 0.382976] [G loss: 0.333450]\n",
      "[Epoch 95/100] [Batch 20/347] [D loss: 0.391492] [G loss: 0.340467]\n",
      "[Epoch 95/100] [Batch 21/347] [D loss: 0.373764] [G loss: 0.335318]\n",
      "[Epoch 95/100] [Batch 22/347] [D loss: 0.370114] [G loss: 0.339111]\n",
      "[Epoch 95/100] [Batch 23/347] [D loss: 0.358097] [G loss: 0.355776]\n",
      "[Epoch 95/100] [Batch 24/347] [D loss: 0.311142] [G loss: 0.379093]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 95/100] [Batch 25/347] [D loss: 0.215966] [G loss: 0.396706]\n",
      "[Epoch 95/100] [Batch 26/347] [D loss: 0.209669] [G loss: 0.409474]\n",
      "[Epoch 95/100] [Batch 27/347] [D loss: 0.203853] [G loss: 0.432820]\n",
      "[Epoch 95/100] [Batch 28/347] [D loss: 0.196819] [G loss: 0.460490]\n",
      "[Epoch 95/100] [Batch 29/347] [D loss: 0.216046] [G loss: 0.467546]\n",
      "[Epoch 95/100] [Batch 30/347] [D loss: 0.174322] [G loss: 0.505362]\n",
      "[Epoch 95/100] [Batch 31/347] [D loss: 0.165993] [G loss: 0.536439]\n",
      "[Epoch 95/100] [Batch 32/347] [D loss: 0.171401] [G loss: 0.554041]\n",
      "[Epoch 95/100] [Batch 33/347] [D loss: 0.188674] [G loss: 0.597782]\n",
      "[Epoch 95/100] [Batch 34/347] [D loss: 0.277607] [G loss: 0.626960]\n",
      "[Epoch 95/100] [Batch 35/347] [D loss: 0.290500] [G loss: 0.652903]\n",
      "[Epoch 95/100] [Batch 36/347] [D loss: 0.321104] [G loss: 0.686480]\n",
      "[Epoch 95/100] [Batch 37/347] [D loss: 0.331269] [G loss: 0.740024]\n",
      "[Epoch 95/100] [Batch 38/347] [D loss: 0.374668] [G loss: 0.747489]\n",
      "[Epoch 95/100] [Batch 39/347] [D loss: 0.388087] [G loss: 0.728801]\n",
      "[Epoch 95/100] [Batch 40/347] [D loss: 0.436096] [G loss: 0.715746]\n",
      "[Epoch 95/100] [Batch 41/347] [D loss: 0.396468] [G loss: 0.699429]\n",
      "[Epoch 95/100] [Batch 42/347] [D loss: 0.359861] [G loss: 0.693141]\n",
      "[Epoch 95/100] [Batch 43/347] [D loss: 0.392061] [G loss: 0.671013]\n",
      "[Epoch 95/100] [Batch 44/347] [D loss: 0.341175] [G loss: 0.662217]\n",
      "[Epoch 95/100] [Batch 45/347] [D loss: 0.291926] [G loss: 0.580170]\n",
      "[Epoch 95/100] [Batch 46/347] [D loss: 0.228744] [G loss: 0.503553]\n",
      "[Epoch 95/100] [Batch 47/347] [D loss: 0.245830] [G loss: 0.447631]\n",
      "[Epoch 95/100] [Batch 48/347] [D loss: 0.151153] [G loss: 0.434537]\n",
      "[Epoch 95/100] [Batch 49/347] [D loss: 0.158212] [G loss: 0.434336]\n",
      "[Epoch 95/100] [Batch 50/347] [D loss: 0.236314] [G loss: 0.356063]\n",
      "[Epoch 95/100] [Batch 51/347] [D loss: 0.239576] [G loss: 0.387028]\n",
      "[Epoch 95/100] [Batch 52/347] [D loss: 0.372663] [G loss: 0.345720]\n",
      "[Epoch 95/100] [Batch 53/347] [D loss: 0.419414] [G loss: 0.317483]\n",
      "[Epoch 95/100] [Batch 54/347] [D loss: 0.422114] [G loss: 0.312197]\n",
      "[Epoch 95/100] [Batch 55/347] [D loss: 0.434970] [G loss: 0.313266]\n",
      "[Epoch 95/100] [Batch 56/347] [D loss: 0.323065] [G loss: 0.467490]\n",
      "[Epoch 95/100] [Batch 57/347] [D loss: 0.214740] [G loss: 0.678698]\n",
      "[Epoch 95/100] [Batch 58/347] [D loss: 0.180808] [G loss: 0.798811]\n",
      "[Epoch 95/100] [Batch 59/347] [D loss: 0.167648] [G loss: 0.846081]\n",
      "[Epoch 95/100] [Batch 60/347] [D loss: 0.202132] [G loss: 0.824665]\n",
      "[Epoch 95/100] [Batch 61/347] [D loss: 0.247416] [G loss: 0.804914]\n",
      "[Epoch 95/100] [Batch 62/347] [D loss: 0.244959] [G loss: 0.872584]\n",
      "[Epoch 95/100] [Batch 63/347] [D loss: 0.212021] [G loss: 0.896087]\n",
      "[Epoch 95/100] [Batch 64/347] [D loss: 0.219214] [G loss: 0.892617]\n",
      "[Epoch 95/100] [Batch 65/347] [D loss: 0.207401] [G loss: 0.900151]\n",
      "[Epoch 95/100] [Batch 66/347] [D loss: 0.191790] [G loss: 0.851839]\n",
      "[Epoch 95/100] [Batch 67/347] [D loss: 0.215768] [G loss: 0.761908]\n",
      "[Epoch 95/100] [Batch 68/347] [D loss: 0.233916] [G loss: 0.674816]\n",
      "[Epoch 95/100] [Batch 69/347] [D loss: 0.216720] [G loss: 0.554438]\n",
      "[Epoch 95/100] [Batch 70/347] [D loss: 0.220065] [G loss: 0.533932]\n",
      "[Epoch 95/100] [Batch 71/347] [D loss: 0.183169] [G loss: 0.601491]\n",
      "[Epoch 95/100] [Batch 72/347] [D loss: 0.173038] [G loss: 0.646722]\n",
      "[Epoch 95/100] [Batch 73/347] [D loss: 0.295810] [G loss: 0.667145]\n",
      "[Epoch 95/100] [Batch 74/347] [D loss: 0.258341] [G loss: 0.710891]\n",
      "[Epoch 95/100] [Batch 75/347] [D loss: 0.269679] [G loss: 0.693253]\n",
      "[Epoch 95/100] [Batch 76/347] [D loss: 0.278426] [G loss: 0.657756]\n",
      "[Epoch 95/100] [Batch 77/347] [D loss: 0.304192] [G loss: 0.798742]\n",
      "[Epoch 95/100] [Batch 78/347] [D loss: 0.325513] [G loss: 0.813018]\n",
      "[Epoch 95/100] [Batch 79/347] [D loss: 0.297879] [G loss: 0.785182]\n",
      "[Epoch 95/100] [Batch 80/347] [D loss: 0.180831] [G loss: 0.747618]\n",
      "[Epoch 95/100] [Batch 81/347] [D loss: 0.181518] [G loss: 0.722987]\n",
      "[Epoch 95/100] [Batch 82/347] [D loss: 0.152980] [G loss: 0.870615]\n",
      "[Epoch 95/100] [Batch 83/347] [D loss: 0.165236] [G loss: 0.870437]\n",
      "[Epoch 95/100] [Batch 84/347] [D loss: 0.417936] [G loss: 0.771024]\n",
      "[Epoch 95/100] [Batch 85/347] [D loss: 0.566022] [G loss: 0.631101]\n",
      "[Epoch 95/100] [Batch 86/347] [D loss: 0.547818] [G loss: 0.542478]\n",
      "[Epoch 95/100] [Batch 87/347] [D loss: 0.523895] [G loss: 0.483448]\n",
      "[Epoch 95/100] [Batch 88/347] [D loss: 0.487150] [G loss: 0.456549]\n",
      "[Epoch 95/100] [Batch 89/347] [D loss: 0.449477] [G loss: 0.459024]\n",
      "[Epoch 95/100] [Batch 90/347] [D loss: 0.436340] [G loss: 0.416178]\n",
      "[Epoch 95/100] [Batch 91/347] [D loss: 0.433424] [G loss: 0.377217]\n",
      "[Epoch 95/100] [Batch 92/347] [D loss: 0.435246] [G loss: 0.350215]\n",
      "[Epoch 95/100] [Batch 93/347] [D loss: 0.433844] [G loss: 0.329929]\n",
      "[Epoch 95/100] [Batch 94/347] [D loss: 0.429329] [G loss: 0.309087]\n",
      "[Epoch 95/100] [Batch 95/347] [D loss: 0.414827] [G loss: 0.298077]\n",
      "[Epoch 95/100] [Batch 96/347] [D loss: 0.419059] [G loss: 0.295069]\n",
      "[Epoch 95/100] [Batch 97/347] [D loss: 0.412344] [G loss: 0.293823]\n",
      "[Epoch 95/100] [Batch 98/347] [D loss: 0.397375] [G loss: 0.298379]\n",
      "[Epoch 95/100] [Batch 99/347] [D loss: 0.395003] [G loss: 0.310399]\n",
      "[Epoch 95/100] [Batch 100/347] [D loss: 0.383788] [G loss: 0.325515]\n",
      "[Epoch 95/100] [Batch 101/347] [D loss: 0.379412] [G loss: 0.343071]\n",
      "[Epoch 95/100] [Batch 102/347] [D loss: 0.440824] [G loss: 0.363740]\n",
      "[Epoch 95/100] [Batch 103/347] [D loss: 0.431334] [G loss: 0.396387]\n",
      "[Epoch 95/100] [Batch 104/347] [D loss: 0.402896] [G loss: 0.412244]\n",
      "[Epoch 95/100] [Batch 105/347] [D loss: 0.335751] [G loss: 0.425858]\n",
      "[Epoch 95/100] [Batch 106/347] [D loss: 0.195628] [G loss: 0.482958]\n",
      "[Epoch 95/100] [Batch 107/347] [D loss: 0.161352] [G loss: 0.563397]\n",
      "[Epoch 95/100] [Batch 108/347] [D loss: 0.130122] [G loss: 0.676810]\n",
      "[Epoch 95/100] [Batch 109/347] [D loss: 0.089060] [G loss: 0.775734]\n",
      "[Epoch 95/100] [Batch 110/347] [D loss: 0.319032] [G loss: 0.362348]\n",
      "[Epoch 95/100] [Batch 111/347] [D loss: 0.268697] [G loss: 0.442984]\n",
      "[Epoch 95/100] [Batch 112/347] [D loss: 0.211877] [G loss: 0.548067]\n",
      "[Epoch 95/100] [Batch 113/347] [D loss: 0.286764] [G loss: 0.685827]\n",
      "[Epoch 95/100] [Batch 114/347] [D loss: 0.350335] [G loss: 0.855052]\n",
      "[Epoch 95/100] [Batch 115/347] [D loss: 0.427682] [G loss: 0.886155]\n",
      "[Epoch 95/100] [Batch 116/347] [D loss: 0.466189] [G loss: 0.851525]\n",
      "[Epoch 95/100] [Batch 117/347] [D loss: 0.613240] [G loss: 0.839024]\n",
      "[Epoch 95/100] [Batch 118/347] [D loss: 0.372594] [G loss: 0.919486]\n",
      "[Epoch 95/100] [Batch 119/347] [D loss: 0.321362] [G loss: 0.899518]\n",
      "[Epoch 95/100] [Batch 120/347] [D loss: 0.235753] [G loss: 0.895710]\n",
      "[Epoch 95/100] [Batch 121/347] [D loss: 0.179317] [G loss: 0.885095]\n",
      "[Epoch 95/100] [Batch 122/347] [D loss: 0.321921] [G loss: 0.858053]\n",
      "[Epoch 95/100] [Batch 123/347] [D loss: 0.359402] [G loss: 0.785254]\n",
      "[Epoch 95/100] [Batch 124/347] [D loss: 0.259535] [G loss: 0.643296]\n",
      "[Epoch 95/100] [Batch 125/347] [D loss: 0.233118] [G loss: 0.540536]\n",
      "[Epoch 95/100] [Batch 126/347] [D loss: 0.228309] [G loss: 0.470414]\n",
      "[Epoch 95/100] [Batch 127/347] [D loss: 0.221033] [G loss: 0.417554]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 95/100] [Batch 128/347] [D loss: 0.214373] [G loss: 0.345414]\n",
      "[Epoch 95/100] [Batch 129/347] [D loss: 0.237819] [G loss: 0.289435]\n",
      "[Epoch 95/100] [Batch 130/347] [D loss: 0.272614] [G loss: 0.289006]\n",
      "[Epoch 95/100] [Batch 131/347] [D loss: 0.282244] [G loss: 0.309526]\n",
      "[Epoch 95/100] [Batch 132/347] [D loss: 0.290573] [G loss: 0.321313]\n",
      "[Epoch 95/100] [Batch 133/347] [D loss: 0.371584] [G loss: 0.303661]\n",
      "[Epoch 95/100] [Batch 134/347] [D loss: 0.636173] [G loss: 0.164557]\n",
      "[Epoch 95/100] [Batch 135/347] [D loss: 0.652941] [G loss: 0.166650]\n",
      "[Epoch 95/100] [Batch 136/347] [D loss: 0.510546] [G loss: 0.286954]\n",
      "[Epoch 95/100] [Batch 137/347] [D loss: 0.362137] [G loss: 0.352419]\n",
      "[Epoch 95/100] [Batch 138/347] [D loss: 0.319100] [G loss: 0.409693]\n",
      "[Epoch 95/100] [Batch 139/347] [D loss: 0.305633] [G loss: 0.524123]\n",
      "[Epoch 95/100] [Batch 140/347] [D loss: 0.379419] [G loss: 0.629886]\n",
      "[Epoch 95/100] [Batch 141/347] [D loss: 0.486502] [G loss: 0.817419]\n",
      "[Epoch 95/100] [Batch 142/347] [D loss: 0.537869] [G loss: 0.921053]\n",
      "[Epoch 95/100] [Batch 143/347] [D loss: 0.522899] [G loss: 0.935588]\n",
      "[Epoch 95/100] [Batch 144/347] [D loss: 0.419697] [G loss: 0.946583]\n",
      "[Epoch 95/100] [Batch 145/347] [D loss: 0.374440] [G loss: 0.966493]\n",
      "[Epoch 95/100] [Batch 146/347] [D loss: 0.324423] [G loss: 0.947709]\n",
      "[Epoch 95/100] [Batch 147/347] [D loss: 0.266487] [G loss: 0.902252]\n",
      "[Epoch 95/100] [Batch 148/347] [D loss: 0.289142] [G loss: 0.811245]\n",
      "[Epoch 95/100] [Batch 149/347] [D loss: 0.275943] [G loss: 0.644985]\n",
      "[Epoch 95/100] [Batch 150/347] [D loss: 0.276309] [G loss: 0.526365]\n",
      "[Epoch 95/100] [Batch 151/347] [D loss: 0.251379] [G loss: 0.484732]\n",
      "[Epoch 95/100] [Batch 152/347] [D loss: 0.245931] [G loss: 0.437785]\n",
      "[Epoch 95/100] [Batch 153/347] [D loss: 0.255613] [G loss: 0.379299]\n",
      "[Epoch 95/100] [Batch 154/347] [D loss: 0.244750] [G loss: 0.348496]\n",
      "[Epoch 95/100] [Batch 155/347] [D loss: 0.236709] [G loss: 0.328621]\n",
      "[Epoch 95/100] [Batch 156/347] [D loss: 0.245142] [G loss: 0.311168]\n",
      "[Epoch 95/100] [Batch 157/347] [D loss: 0.237182] [G loss: 0.319217]\n",
      "[Epoch 95/100] [Batch 158/347] [D loss: 0.230271] [G loss: 0.328563]\n",
      "[Epoch 95/100] [Batch 159/347] [D loss: 0.234209] [G loss: 0.322644]\n",
      "[Epoch 95/100] [Batch 160/347] [D loss: 0.227665] [G loss: 0.348479]\n",
      "[Epoch 95/100] [Batch 161/347] [D loss: 0.211089] [G loss: 0.367258]\n",
      "[Epoch 95/100] [Batch 162/347] [D loss: 0.238430] [G loss: 0.334841]\n",
      "[Epoch 95/100] [Batch 163/347] [D loss: 0.213582] [G loss: 0.375520]\n",
      "[Epoch 95/100] [Batch 164/347] [D loss: 0.205828] [G loss: 0.422463]\n",
      "[Epoch 95/100] [Batch 165/347] [D loss: 0.182871] [G loss: 0.484520]\n",
      "[Epoch 95/100] [Batch 166/347] [D loss: 0.158076] [G loss: 0.679900]\n",
      "[Epoch 95/100] [Batch 167/347] [D loss: 0.171073] [G loss: 0.844732]\n",
      "[Epoch 95/100] [Batch 168/347] [D loss: 0.180559] [G loss: 0.891841]\n",
      "[Epoch 95/100] [Batch 169/347] [D loss: 0.355133] [G loss: 0.894277]\n",
      "[Epoch 95/100] [Batch 170/347] [D loss: 0.488421] [G loss: 0.884730]\n",
      "[Epoch 95/100] [Batch 171/347] [D loss: 0.378751] [G loss: 0.844206]\n",
      "[Epoch 95/100] [Batch 172/347] [D loss: 0.399896] [G loss: 0.791629]\n",
      "[Epoch 95/100] [Batch 173/347] [D loss: 0.413646] [G loss: 0.790366]\n",
      "[Epoch 95/100] [Batch 174/347] [D loss: 0.380962] [G loss: 0.850565]\n",
      "[Epoch 95/100] [Batch 175/347] [D loss: 0.468882] [G loss: 0.774722]\n",
      "[Epoch 95/100] [Batch 176/347] [D loss: 0.410259] [G loss: 0.666180]\n",
      "[Epoch 95/100] [Batch 177/347] [D loss: 0.357134] [G loss: 0.542417]\n",
      "[Epoch 95/100] [Batch 178/347] [D loss: 0.335368] [G loss: 0.426263]\n",
      "[Epoch 95/100] [Batch 179/347] [D loss: 0.334971] [G loss: 0.368310]\n",
      "[Epoch 95/100] [Batch 180/347] [D loss: 0.325339] [G loss: 0.334011]\n",
      "[Epoch 95/100] [Batch 181/347] [D loss: 0.323879] [G loss: 0.299735]\n",
      "[Epoch 95/100] [Batch 182/347] [D loss: 0.335316] [G loss: 0.273094]\n",
      "[Epoch 95/100] [Batch 183/347] [D loss: 0.347676] [G loss: 0.256586]\n",
      "[Epoch 95/100] [Batch 184/347] [D loss: 0.397449] [G loss: 0.239803]\n",
      "[Epoch 95/100] [Batch 185/347] [D loss: 0.422960] [G loss: 0.225667]\n",
      "[Epoch 95/100] [Batch 186/347] [D loss: 0.421502] [G loss: 0.219891]\n",
      "[Epoch 95/100] [Batch 187/347] [D loss: 0.406456] [G loss: 0.216164]\n",
      "[Epoch 95/100] [Batch 188/347] [D loss: 0.380982] [G loss: 0.221500]\n",
      "[Epoch 95/100] [Batch 189/347] [D loss: 0.346498] [G loss: 0.234377]\n",
      "[Epoch 95/100] [Batch 190/347] [D loss: 0.333762] [G loss: 0.247462]\n",
      "[Epoch 95/100] [Batch 191/347] [D loss: 0.331372] [G loss: 0.265975]\n",
      "[Epoch 95/100] [Batch 192/347] [D loss: 0.332179] [G loss: 0.281148]\n",
      "[Epoch 95/100] [Batch 193/347] [D loss: 0.359732] [G loss: 0.303058]\n",
      "[Epoch 95/100] [Batch 194/347] [D loss: 0.340203] [G loss: 0.329542]\n",
      "[Epoch 95/100] [Batch 195/347] [D loss: 0.318490] [G loss: 0.359421]\n",
      "[Epoch 95/100] [Batch 196/347] [D loss: 0.284736] [G loss: 0.389528]\n",
      "[Epoch 95/100] [Batch 197/347] [D loss: 0.277508] [G loss: 0.421098]\n",
      "[Epoch 95/100] [Batch 198/347] [D loss: 0.271578] [G loss: 0.453504]\n",
      "[Epoch 95/100] [Batch 199/347] [D loss: 0.274919] [G loss: 0.488301]\n",
      "[Epoch 95/100] [Batch 200/347] [D loss: 0.336511] [G loss: 0.511987]\n",
      "[Epoch 95/100] [Batch 201/347] [D loss: 0.372313] [G loss: 0.545393]\n",
      "[Epoch 95/100] [Batch 202/347] [D loss: 0.403506] [G loss: 0.585130]\n",
      "[Epoch 95/100] [Batch 203/347] [D loss: 0.391507] [G loss: 0.610269]\n",
      "[Epoch 95/100] [Batch 204/347] [D loss: 0.368086] [G loss: 0.639670]\n",
      "[Epoch 95/100] [Batch 205/347] [D loss: 0.348240] [G loss: 0.651225]\n",
      "[Epoch 95/100] [Batch 206/347] [D loss: 0.343423] [G loss: 0.647162]\n",
      "[Epoch 95/100] [Batch 207/347] [D loss: 0.261555] [G loss: 0.634143]\n",
      "[Epoch 95/100] [Batch 208/347] [D loss: 0.259948] [G loss: 0.605084]\n",
      "[Epoch 95/100] [Batch 209/347] [D loss: 0.293334] [G loss: 0.561944]\n",
      "[Epoch 95/100] [Batch 210/347] [D loss: 0.262991] [G loss: 0.555961]\n",
      "[Epoch 95/100] [Batch 211/347] [D loss: 0.218526] [G loss: 0.529756]\n",
      "[Epoch 95/100] [Batch 212/347] [D loss: 0.122109] [G loss: 0.529351]\n",
      "[Epoch 95/100] [Batch 213/347] [D loss: 0.108882] [G loss: 0.611347]\n",
      "[Epoch 95/100] [Batch 214/347] [D loss: 0.106508] [G loss: 0.635042]\n",
      "[Epoch 95/100] [Batch 215/347] [D loss: 0.096000] [G loss: 0.688007]\n",
      "[Epoch 95/100] [Batch 216/347] [D loss: 0.295455] [G loss: 0.400996]\n",
      "[Epoch 95/100] [Batch 217/347] [D loss: 0.307398] [G loss: 0.488920]\n",
      "[Epoch 95/100] [Batch 218/347] [D loss: 0.329383] [G loss: 0.562579]\n",
      "[Epoch 95/100] [Batch 219/347] [D loss: 0.293019] [G loss: 0.620668]\n",
      "[Epoch 95/100] [Batch 220/347] [D loss: 0.266505] [G loss: 0.888734]\n",
      "[Epoch 95/100] [Batch 221/347] [D loss: 0.305827] [G loss: 0.970952]\n",
      "[Epoch 95/100] [Batch 222/347] [D loss: 0.370888] [G loss: 0.968890]\n",
      "[Epoch 95/100] [Batch 223/347] [D loss: 0.406433] [G loss: 0.932142]\n",
      "[Epoch 95/100] [Batch 224/347] [D loss: 0.466020] [G loss: 0.894482]\n",
      "[Epoch 95/100] [Batch 225/347] [D loss: 0.522825] [G loss: 0.810792]\n",
      "[Epoch 95/100] [Batch 226/347] [D loss: 0.448846] [G loss: 0.686391]\n",
      "[Epoch 95/100] [Batch 227/347] [D loss: 0.406591] [G loss: 0.468426]\n",
      "[Epoch 95/100] [Batch 228/347] [D loss: 0.405857] [G loss: 0.339251]\n",
      "[Epoch 95/100] [Batch 229/347] [D loss: 0.360546] [G loss: 0.330692]\n",
      "[Epoch 95/100] [Batch 230/347] [D loss: 0.369118] [G loss: 0.319532]\n",
      "[Epoch 95/100] [Batch 231/347] [D loss: 0.364745] [G loss: 0.294258]\n",
      "[Epoch 95/100] [Batch 232/347] [D loss: 0.370226] [G loss: 0.272791]\n",
      "[Epoch 95/100] [Batch 233/347] [D loss: 0.356669] [G loss: 0.264027]\n",
      "[Epoch 95/100] [Batch 234/347] [D loss: 0.355340] [G loss: 0.261855]\n",
      "[Epoch 95/100] [Batch 235/347] [D loss: 0.363881] [G loss: 0.282902]\n",
      "[Epoch 95/100] [Batch 236/347] [D loss: 0.354299] [G loss: 0.307757]\n",
      "[Epoch 95/100] [Batch 237/347] [D loss: 0.382006] [G loss: 0.312517]\n",
      "[Epoch 95/100] [Batch 238/347] [D loss: 0.411101] [G loss: 0.314293]\n",
      "[Epoch 95/100] [Batch 239/347] [D loss: 0.409240] [G loss: 0.315051]\n",
      "[Epoch 95/100] [Batch 240/347] [D loss: 0.414272] [G loss: 0.324368]\n",
      "[Epoch 95/100] [Batch 241/347] [D loss: 0.401614] [G loss: 0.365481]\n",
      "[Epoch 95/100] [Batch 242/347] [D loss: 0.360579] [G loss: 0.530640]\n",
      "[Epoch 95/100] [Batch 243/347] [D loss: 0.286387] [G loss: 0.616526]\n",
      "[Epoch 95/100] [Batch 244/347] [D loss: 0.243355] [G loss: 0.677253]\n",
      "[Epoch 95/100] [Batch 245/347] [D loss: 0.248151] [G loss: 0.710537]\n",
      "[Epoch 95/100] [Batch 246/347] [D loss: 0.266804] [G loss: 0.745062]\n",
      "[Epoch 95/100] [Batch 247/347] [D loss: 0.327028] [G loss: 0.765583]\n",
      "[Epoch 95/100] [Batch 248/347] [D loss: 0.346372] [G loss: 0.714972]\n",
      "[Epoch 95/100] [Batch 249/347] [D loss: 0.312276] [G loss: 0.722380]\n",
      "[Epoch 95/100] [Batch 250/347] [D loss: 0.273915] [G loss: 0.736870]\n",
      "[Epoch 95/100] [Batch 251/347] [D loss: 0.295523] [G loss: 0.767801]\n",
      "[Epoch 95/100] [Batch 252/347] [D loss: 0.292870] [G loss: 0.751963]\n",
      "[Epoch 95/100] [Batch 253/347] [D loss: 0.176121] [G loss: 0.709107]\n",
      "[Epoch 95/100] [Batch 254/347] [D loss: 0.160585] [G loss: 0.690681]\n",
      "[Epoch 95/100] [Batch 255/347] [D loss: 0.167547] [G loss: 0.699872]\n",
      "[Epoch 95/100] [Batch 256/347] [D loss: 0.172642] [G loss: 0.705359]\n",
      "[Epoch 95/100] [Batch 257/347] [D loss: 0.212048] [G loss: 0.527164]\n",
      "[Epoch 95/100] [Batch 258/347] [D loss: 0.192426] [G loss: 0.483917]\n",
      "[Epoch 95/100] [Batch 259/347] [D loss: 0.204474] [G loss: 0.503217]\n",
      "[Epoch 95/100] [Batch 260/347] [D loss: 0.196899] [G loss: 0.528326]\n",
      "[Epoch 95/100] [Batch 261/347] [D loss: 0.151489] [G loss: 0.683447]\n",
      "[Epoch 95/100] [Batch 262/347] [D loss: 0.103547] [G loss: 0.787495]\n",
      "[Epoch 95/100] [Batch 263/347] [D loss: 0.091091] [G loss: 0.841285]\n",
      "[Epoch 95/100] [Batch 264/347] [D loss: 0.088870] [G loss: 0.867541]\n",
      "[Epoch 95/100] [Batch 265/347] [D loss: 0.098086] [G loss: 0.871580]\n",
      "[Epoch 95/100] [Batch 266/347] [D loss: 0.186888] [G loss: 0.802847]\n",
      "[Epoch 95/100] [Batch 267/347] [D loss: 0.206954] [G loss: 0.790916]\n",
      "[Epoch 95/100] [Batch 268/347] [D loss: 0.228503] [G loss: 0.794286]\n",
      "[Epoch 95/100] [Batch 269/347] [D loss: 0.226378] [G loss: 0.789256]\n",
      "[Epoch 95/100] [Batch 270/347] [D loss: 0.234010] [G loss: 0.804178]\n",
      "[Epoch 95/100] [Batch 271/347] [D loss: 0.208992] [G loss: 0.830420]\n",
      "[Epoch 95/100] [Batch 272/347] [D loss: 0.284384] [G loss: 0.851111]\n",
      "[Epoch 95/100] [Batch 273/347] [D loss: 0.270152] [G loss: 0.898727]\n",
      "[Epoch 95/100] [Batch 274/347] [D loss: 0.243079] [G loss: 0.946214]\n",
      "[Epoch 95/100] [Batch 275/347] [D loss: 0.206392] [G loss: 0.988603]\n",
      "[Epoch 95/100] [Batch 276/347] [D loss: 0.318691] [G loss: 0.441876]\n",
      "[Epoch 95/100] [Batch 277/347] [D loss: 0.306893] [G loss: 0.488550]\n",
      "[Epoch 95/100] [Batch 278/347] [D loss: 0.284991] [G loss: 0.575406]\n",
      "[Epoch 95/100] [Batch 279/347] [D loss: 0.275532] [G loss: 0.637339]\n",
      "[Epoch 95/100] [Batch 280/347] [D loss: 0.613593] [G loss: 0.915610]\n",
      "[Epoch 95/100] [Batch 281/347] [D loss: 0.788472] [G loss: 1.030827]\n",
      "[Epoch 95/100] [Batch 282/347] [D loss: 0.806110] [G loss: 1.016838]\n",
      "[Epoch 95/100] [Batch 283/347] [D loss: 0.674219] [G loss: 0.995086]\n",
      "[Epoch 95/100] [Batch 284/347] [D loss: 0.477754] [G loss: 0.953027]\n",
      "[Epoch 95/100] [Batch 285/347] [D loss: 0.343690] [G loss: 0.848058]\n",
      "[Epoch 95/100] [Batch 286/347] [D loss: 0.261414] [G loss: 0.643359]\n",
      "[Epoch 95/100] [Batch 287/347] [D loss: 0.240372] [G loss: 0.445738]\n",
      "[Epoch 95/100] [Batch 288/347] [D loss: 0.249281] [G loss: 0.357709]\n",
      "[Epoch 95/100] [Batch 289/347] [D loss: 0.268896] [G loss: 0.281276]\n",
      "[Epoch 95/100] [Batch 290/347] [D loss: 0.341100] [G loss: 0.223101]\n",
      "[Epoch 95/100] [Batch 291/347] [D loss: 0.359907] [G loss: 0.217127]\n",
      "[Epoch 95/100] [Batch 292/347] [D loss: 0.378094] [G loss: 0.210436]\n",
      "[Epoch 95/100] [Batch 293/347] [D loss: 0.416399] [G loss: 0.226089]\n",
      "[Epoch 95/100] [Batch 294/347] [D loss: 0.384798] [G loss: 0.236974]\n",
      "[Epoch 95/100] [Batch 295/347] [D loss: 0.352096] [G loss: 0.243147]\n",
      "[Epoch 95/100] [Batch 296/347] [D loss: 0.323294] [G loss: 0.266125]\n",
      "[Epoch 95/100] [Batch 297/347] [D loss: 0.312336] [G loss: 0.306400]\n",
      "[Epoch 95/100] [Batch 298/347] [D loss: 0.279894] [G loss: 0.353852]\n",
      "[Epoch 95/100] [Batch 299/347] [D loss: 0.253059] [G loss: 0.394351]\n",
      "[Epoch 95/100] [Batch 300/347] [D loss: 0.218871] [G loss: 0.443019]\n",
      "[Epoch 95/100] [Batch 301/347] [D loss: 0.223184] [G loss: 0.598744]\n",
      "[Epoch 95/100] [Batch 302/347] [D loss: 0.225238] [G loss: 0.719299]\n",
      "[Epoch 95/100] [Batch 303/347] [D loss: 0.257346] [G loss: 0.765597]\n",
      "[Epoch 95/100] [Batch 304/347] [D loss: 0.206167] [G loss: 0.784714]\n",
      "[Epoch 95/100] [Batch 305/347] [D loss: 0.115108] [G loss: 0.804864]\n",
      "[Epoch 95/100] [Batch 306/347] [D loss: 0.106771] [G loss: 0.855270]\n",
      "[Epoch 95/100] [Batch 307/347] [D loss: 0.092965] [G loss: 0.917019]\n",
      "[Epoch 95/100] [Batch 308/347] [D loss: 0.142962] [G loss: 0.950086]\n",
      "[Epoch 95/100] [Batch 309/347] [D loss: 0.323470] [G loss: 0.950827]\n",
      "[Epoch 95/100] [Batch 310/347] [D loss: 0.506105] [G loss: 0.949652]\n",
      "[Epoch 95/100] [Batch 311/347] [D loss: 0.428884] [G loss: 0.888335]\n",
      "[Epoch 95/100] [Batch 312/347] [D loss: 0.318680] [G loss: 0.812399]\n",
      "[Epoch 95/100] [Batch 313/347] [D loss: 0.321543] [G loss: 0.825974]\n",
      "[Epoch 95/100] [Batch 314/347] [D loss: 0.320411] [G loss: 0.869545]\n",
      "[Epoch 95/100] [Batch 315/347] [D loss: 0.321955] [G loss: 0.847157]\n",
      "[Epoch 95/100] [Batch 316/347] [D loss: 0.307931] [G loss: 0.682917]\n",
      "[Epoch 95/100] [Batch 317/347] [D loss: 0.317222] [G loss: 0.563651]\n",
      "[Epoch 95/100] [Batch 318/347] [D loss: 0.294259] [G loss: 0.527315]\n",
      "[Epoch 95/100] [Batch 319/347] [D loss: 0.277799] [G loss: 0.523267]\n",
      "[Epoch 95/100] [Batch 320/347] [D loss: 0.291114] [G loss: 0.502826]\n",
      "[Epoch 95/100] [Batch 321/347] [D loss: 0.279933] [G loss: 0.480773]\n",
      "[Epoch 95/100] [Batch 322/347] [D loss: 0.307056] [G loss: 0.442858]\n",
      "[Epoch 95/100] [Batch 323/347] [D loss: 0.245477] [G loss: 0.430876]\n",
      "[Epoch 95/100] [Batch 324/347] [D loss: 0.228960] [G loss: 0.442027]\n",
      "[Epoch 95/100] [Batch 325/347] [D loss: 0.233574] [G loss: 0.438059]\n",
      "[Epoch 95/100] [Batch 326/347] [D loss: 0.235160] [G loss: 0.441447]\n",
      "[Epoch 95/100] [Batch 327/347] [D loss: 0.233660] [G loss: 0.435971]\n",
      "[Epoch 95/100] [Batch 328/347] [D loss: 0.247134] [G loss: 0.426640]\n",
      "[Epoch 95/100] [Batch 329/347] [D loss: 0.240940] [G loss: 0.441405]\n",
      "[Epoch 95/100] [Batch 330/347] [D loss: 0.222825] [G loss: 0.477034]\n",
      "[Epoch 95/100] [Batch 331/347] [D loss: 0.270586] [G loss: 0.500980]\n",
      "[Epoch 95/100] [Batch 332/347] [D loss: 0.352869] [G loss: 0.533494]\n",
      "[Epoch 95/100] [Batch 333/347] [D loss: 0.285900] [G loss: 0.559740]\n",
      "[Epoch 95/100] [Batch 334/347] [D loss: 0.263422] [G loss: 0.570532]\n",
      "[Epoch 95/100] [Batch 335/347] [D loss: 0.274400] [G loss: 0.590713]\n",
      "[Epoch 95/100] [Batch 336/347] [D loss: 0.265072] [G loss: 0.757259]\n",
      "[Epoch 95/100] [Batch 337/347] [D loss: 0.317544] [G loss: 0.789627]\n",
      "[Epoch 95/100] [Batch 338/347] [D loss: 0.392501] [G loss: 0.796129]\n",
      "[Epoch 95/100] [Batch 339/347] [D loss: 0.346107] [G loss: 0.778351]\n",
      "[Epoch 95/100] [Batch 340/347] [D loss: 0.303883] [G loss: 0.757904]\n",
      "[Epoch 95/100] [Batch 341/347] [D loss: 0.329378] [G loss: 0.742240]\n",
      "[Epoch 95/100] [Batch 342/347] [D loss: 0.151910] [G loss: 0.717255]\n",
      "[Epoch 95/100] [Batch 343/347] [D loss: 0.101429] [G loss: 0.697550]\n",
      "[Epoch 95/100] [Batch 344/347] [D loss: 0.097850] [G loss: 0.679770]\n",
      "[Epoch 95/100] [Batch 345/347] [D loss: 0.065066] [G loss: 0.700173]\n",
      "[Epoch 95/100] [Batch 346/347] [D loss: 0.106628] [G loss: 0.602316]\n",
      "[Epoch 95/100] [Batch 347/347] [D loss: 0.135608] [G loss: 0.534667]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 96/100] [Batch 1/347] [D loss: 0.392737] [G loss: 0.724438]\n",
      "[Epoch 96/100] [Batch 2/347] [D loss: 0.401385] [G loss: 0.774410]\n",
      "[Epoch 96/100] [Batch 3/347] [D loss: 0.424611] [G loss: 0.811809]\n",
      "[Epoch 96/100] [Batch 4/347] [D loss: 0.455813] [G loss: 0.819058]\n",
      "[Epoch 96/100] [Batch 5/347] [D loss: 0.473322] [G loss: 0.819280]\n",
      "[Epoch 96/100] [Batch 6/347] [D loss: 0.384733] [G loss: 0.804626]\n",
      "[Epoch 96/100] [Batch 7/347] [D loss: 0.307721] [G loss: 0.765491]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 96/100] [Batch 8/347] [D loss: 0.300079] [G loss: 0.711177]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 96/100] [Batch 9/347] [D loss: 0.289523] [G loss: 0.645594]\n",
      "[Epoch 96/100] [Batch 10/347] [D loss: 0.317215] [G loss: 0.578455]\n",
      "[Epoch 96/100] [Batch 11/347] [D loss: 0.387355] [G loss: 0.525318]\n",
      "[Epoch 96/100] [Batch 12/347] [D loss: 0.375567] [G loss: 0.502418]\n",
      "[Epoch 96/100] [Batch 13/347] [D loss: 0.339621] [G loss: 0.483729]\n",
      "[Epoch 96/100] [Batch 14/347] [D loss: 0.316130] [G loss: 0.472350]\n",
      "[Epoch 96/100] [Batch 15/347] [D loss: 0.310535] [G loss: 0.456555]\n",
      "[Epoch 96/100] [Batch 16/347] [D loss: 0.312831] [G loss: 0.450260]\n",
      "[Epoch 96/100] [Batch 17/347] [D loss: 0.318949] [G loss: 0.438248]\n",
      "[Epoch 96/100] [Batch 18/347] [D loss: 0.346084] [G loss: 0.411964]\n",
      "[Epoch 96/100] [Batch 19/347] [D loss: 0.361558] [G loss: 0.398601]\n",
      "[Epoch 96/100] [Batch 20/347] [D loss: 0.366703] [G loss: 0.401360]\n",
      "[Epoch 96/100] [Batch 21/347] [D loss: 0.351539] [G loss: 0.393066]\n",
      "[Epoch 96/100] [Batch 22/347] [D loss: 0.350030] [G loss: 0.395080]\n",
      "[Epoch 96/100] [Batch 23/347] [D loss: 0.341176] [G loss: 0.408036]\n",
      "[Epoch 96/100] [Batch 24/347] [D loss: 0.303889] [G loss: 0.421707]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 96/100] [Batch 25/347] [D loss: 0.208382] [G loss: 0.439900]\n",
      "[Epoch 96/100] [Batch 26/347] [D loss: 0.203188] [G loss: 0.452323]\n",
      "[Epoch 96/100] [Batch 27/347] [D loss: 0.197425] [G loss: 0.468668]\n",
      "[Epoch 96/100] [Batch 28/347] [D loss: 0.191592] [G loss: 0.495073]\n",
      "[Epoch 96/100] [Batch 29/347] [D loss: 0.192484] [G loss: 0.537399]\n",
      "[Epoch 96/100] [Batch 30/347] [D loss: 0.147444] [G loss: 0.590800]\n",
      "[Epoch 96/100] [Batch 31/347] [D loss: 0.131644] [G loss: 0.706660]\n",
      "[Epoch 96/100] [Batch 32/347] [D loss: 0.105199] [G loss: 0.783566]\n",
      "[Epoch 96/100] [Batch 33/347] [D loss: 0.128672] [G loss: 0.858489]\n",
      "[Epoch 96/100] [Batch 34/347] [D loss: 0.220626] [G loss: 0.881752]\n",
      "[Epoch 96/100] [Batch 35/347] [D loss: 0.243573] [G loss: 0.897131]\n",
      "[Epoch 96/100] [Batch 36/347] [D loss: 0.281117] [G loss: 0.902529]\n",
      "[Epoch 96/100] [Batch 37/347] [D loss: 0.303734] [G loss: 0.922025]\n",
      "[Epoch 96/100] [Batch 38/347] [D loss: 0.368973] [G loss: 0.913572]\n",
      "[Epoch 96/100] [Batch 39/347] [D loss: 0.362681] [G loss: 0.880507]\n",
      "[Epoch 96/100] [Batch 40/347] [D loss: 0.391786] [G loss: 0.838380]\n",
      "[Epoch 96/100] [Batch 41/347] [D loss: 0.331967] [G loss: 0.782395]\n",
      "[Epoch 96/100] [Batch 42/347] [D loss: 0.292190] [G loss: 0.728082]\n",
      "[Epoch 96/100] [Batch 43/347] [D loss: 0.316200] [G loss: 0.661380]\n",
      "[Epoch 96/100] [Batch 44/347] [D loss: 0.278217] [G loss: 0.606388]\n",
      "[Epoch 96/100] [Batch 45/347] [D loss: 0.244429] [G loss: 0.524546]\n",
      "[Epoch 96/100] [Batch 46/347] [D loss: 0.194635] [G loss: 0.444186]\n",
      "[Epoch 96/100] [Batch 47/347] [D loss: 0.212386] [G loss: 0.394399]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 96/100] [Batch 48/347] [D loss: 0.149645] [G loss: 0.431785]\n",
      "[Epoch 96/100] [Batch 49/347] [D loss: 0.155782] [G loss: 0.416824]\n",
      "[Epoch 96/100] [Batch 50/347] [D loss: 0.220404] [G loss: 0.340379]\n",
      "[Epoch 96/100] [Batch 51/347] [D loss: 0.227517] [G loss: 0.372679]\n",
      "[Epoch 96/100] [Batch 52/347] [D loss: 0.292592] [G loss: 0.365285]\n",
      "[Epoch 96/100] [Batch 53/347] [D loss: 0.313781] [G loss: 0.348732]\n",
      "[Epoch 96/100] [Batch 54/347] [D loss: 0.314743] [G loss: 0.354785]\n",
      "[Epoch 96/100] [Batch 55/347] [D loss: 0.323208] [G loss: 0.370286]\n",
      "[Epoch 96/100] [Batch 56/347] [D loss: 0.233474] [G loss: 0.582755]\n",
      "[Epoch 96/100] [Batch 57/347] [D loss: 0.146292] [G loss: 0.855302]\n",
      "[Epoch 96/100] [Batch 58/347] [D loss: 0.120799] [G loss: 0.953448]\n",
      "[Epoch 96/100] [Batch 59/347] [D loss: 0.113231] [G loss: 0.976184]\n",
      "[Epoch 96/100] [Batch 60/347] [D loss: 0.144970] [G loss: 0.948003]\n",
      "[Epoch 96/100] [Batch 61/347] [D loss: 0.189643] [G loss: 0.926105]\n",
      "[Epoch 96/100] [Batch 62/347] [D loss: 0.197086] [G loss: 0.952391]\n",
      "[Epoch 96/100] [Batch 63/347] [D loss: 0.160501] [G loss: 0.970014]\n",
      "[Epoch 96/100] [Batch 64/347] [D loss: 0.169094] [G loss: 0.978931]\n",
      "[Epoch 96/100] [Batch 65/347] [D loss: 0.168272] [G loss: 0.967360]\n",
      "[Epoch 96/100] [Batch 66/347] [D loss: 0.130666] [G loss: 0.910519]\n",
      "[Epoch 96/100] [Batch 67/347] [D loss: 0.140309] [G loss: 0.797729]\n",
      "[Epoch 96/100] [Batch 68/347] [D loss: 0.152538] [G loss: 0.685764]\n",
      "[Epoch 96/100] [Batch 69/347] [D loss: 0.108154] [G loss: 0.658200]\n",
      "[Epoch 96/100] [Batch 70/347] [D loss: 0.121428] [G loss: 0.620812]\n",
      "[Epoch 96/100] [Batch 71/347] [D loss: 0.122066] [G loss: 0.608094]\n",
      "[Epoch 96/100] [Batch 72/347] [D loss: 0.112105] [G loss: 0.669135]\n",
      "[Epoch 96/100] [Batch 73/347] [D loss: 0.211816] [G loss: 0.693915]\n",
      "[Epoch 96/100] [Batch 74/347] [D loss: 0.180256] [G loss: 0.755531]\n",
      "[Epoch 96/100] [Batch 75/347] [D loss: 0.184276] [G loss: 0.792725]\n",
      "[Epoch 96/100] [Batch 76/347] [D loss: 0.195547] [G loss: 0.802287]\n",
      "[Epoch 96/100] [Batch 77/347] [D loss: 0.235018] [G loss: 0.929566]\n",
      "[Epoch 96/100] [Batch 78/347] [D loss: 0.266466] [G loss: 0.963624]\n",
      "[Epoch 96/100] [Batch 79/347] [D loss: 0.238983] [G loss: 0.953863]\n",
      "[Epoch 96/100] [Batch 80/347] [D loss: 0.129343] [G loss: 0.921057]\n",
      "[Epoch 96/100] [Batch 81/347] [D loss: 0.131799] [G loss: 0.909821]\n",
      "[Epoch 96/100] [Batch 82/347] [D loss: 0.130513] [G loss: 1.004566]\n",
      "[Epoch 96/100] [Batch 83/347] [D loss: 0.150216] [G loss: 1.002903]\n",
      "[Epoch 96/100] [Batch 84/347] [D loss: 0.417580] [G loss: 0.941268]\n",
      "[Epoch 96/100] [Batch 85/347] [D loss: 0.560752] [G loss: 0.779794]\n",
      "[Epoch 96/100] [Batch 86/347] [D loss: 0.503346] [G loss: 0.587773]\n",
      "[Epoch 96/100] [Batch 87/347] [D loss: 0.461694] [G loss: 0.487018]\n",
      "[Epoch 96/100] [Batch 88/347] [D loss: 0.439978] [G loss: 0.443525]\n",
      "[Epoch 96/100] [Batch 89/347] [D loss: 0.427923] [G loss: 0.419770]\n",
      "[Epoch 96/100] [Batch 90/347] [D loss: 0.426835] [G loss: 0.378778]\n",
      "[Epoch 96/100] [Batch 91/347] [D loss: 0.434546] [G loss: 0.343769]\n",
      "[Epoch 96/100] [Batch 92/347] [D loss: 0.446894] [G loss: 0.321640]\n",
      "[Epoch 96/100] [Batch 93/347] [D loss: 0.454066] [G loss: 0.306286]\n",
      "[Epoch 96/100] [Batch 94/347] [D loss: 0.455077] [G loss: 0.291746]\n",
      "[Epoch 96/100] [Batch 95/347] [D loss: 0.444003] [G loss: 0.288238]\n",
      "[Epoch 96/100] [Batch 96/347] [D loss: 0.444065] [G loss: 0.292196]\n",
      "[Epoch 96/100] [Batch 97/347] [D loss: 0.431311] [G loss: 0.297877]\n",
      "[Epoch 96/100] [Batch 98/347] [D loss: 0.408351] [G loss: 0.312046]\n",
      "[Epoch 96/100] [Batch 99/347] [D loss: 0.395596] [G loss: 0.331865]\n",
      "[Epoch 96/100] [Batch 100/347] [D loss: 0.376840] [G loss: 0.355807]\n",
      "[Epoch 96/100] [Batch 101/347] [D loss: 0.366165] [G loss: 0.382756]\n",
      "[Epoch 96/100] [Batch 102/347] [D loss: 0.427937] [G loss: 0.409805]\n",
      "[Epoch 96/100] [Batch 103/347] [D loss: 0.421224] [G loss: 0.444771]\n",
      "[Epoch 96/100] [Batch 104/347] [D loss: 0.394656] [G loss: 0.474530]\n",
      "[Epoch 96/100] [Batch 105/347] [D loss: 0.321219] [G loss: 0.512891]\n",
      "[Epoch 96/100] [Batch 106/347] [D loss: 0.158915] [G loss: 0.601688]\n",
      "[Epoch 96/100] [Batch 107/347] [D loss: 0.119262] [G loss: 0.748158]\n",
      "[Epoch 96/100] [Batch 108/347] [D loss: 0.080061] [G loss: 0.860968]\n",
      "[Epoch 96/100] [Batch 109/347] [D loss: 0.047237] [G loss: 0.948134]\n",
      "[Epoch 96/100] [Batch 110/347] [D loss: 0.177351] [G loss: 0.663422]\n",
      "[Epoch 96/100] [Batch 111/347] [D loss: 0.134458] [G loss: 0.783316]\n",
      "[Epoch 96/100] [Batch 112/347] [D loss: 0.092248] [G loss: 0.875740]\n",
      "[Epoch 96/100] [Batch 113/347] [D loss: 0.171810] [G loss: 0.948889]\n",
      "[Epoch 96/100] [Batch 114/347] [D loss: 0.269906] [G loss: 1.037463]\n",
      "[Epoch 96/100] [Batch 115/347] [D loss: 0.330924] [G loss: 1.026008]\n",
      "[Epoch 96/100] [Batch 116/347] [D loss: 0.359814] [G loss: 0.986222]\n",
      "[Epoch 96/100] [Batch 117/347] [D loss: 0.508272] [G loss: 0.943662]\n",
      "[Epoch 96/100] [Batch 118/347] [D loss: 0.285457] [G loss: 0.978749]\n",
      "[Epoch 96/100] [Batch 119/347] [D loss: 0.221144] [G loss: 0.951256]\n",
      "[Epoch 96/100] [Batch 120/347] [D loss: 0.133255] [G loss: 0.927625]\n",
      "[Epoch 96/100] [Batch 121/347] [D loss: 0.087391] [G loss: 0.873790]\n",
      "[Epoch 96/100] [Batch 122/347] [D loss: 0.189867] [G loss: 0.797114]\n",
      "[Epoch 96/100] [Batch 123/347] [D loss: 0.237352] [G loss: 0.694079]\n",
      "[Epoch 96/100] [Batch 124/347] [D loss: 0.188526] [G loss: 0.579898]\n",
      "[Epoch 96/100] [Batch 125/347] [D loss: 0.187695] [G loss: 0.513652]\n",
      "[Epoch 96/100] [Batch 126/347] [D loss: 0.205813] [G loss: 0.472893]\n",
      "[Epoch 96/100] [Batch 127/347] [D loss: 0.206271] [G loss: 0.442360]\n",
      "[Epoch 96/100] [Batch 128/347] [D loss: 0.186643] [G loss: 0.398375]\n",
      "[Epoch 96/100] [Batch 129/347] [D loss: 0.193467] [G loss: 0.382932]\n",
      "[Epoch 96/100] [Batch 130/347] [D loss: 0.190352] [G loss: 0.419529]\n",
      "[Epoch 96/100] [Batch 131/347] [D loss: 0.180169] [G loss: 0.466984]\n",
      "[Epoch 96/100] [Batch 132/347] [D loss: 0.172202] [G loss: 0.489143]\n",
      "[Epoch 96/100] [Batch 133/347] [D loss: 0.224146] [G loss: 0.512922]\n",
      "[Epoch 96/100] [Batch 134/347] [D loss: 0.419821] [G loss: 0.357990]\n",
      "[Epoch 96/100] [Batch 135/347] [D loss: 0.433834] [G loss: 0.359451]\n",
      "[Epoch 96/100] [Batch 136/347] [D loss: 0.327436] [G loss: 0.558525]\n",
      "[Epoch 96/100] [Batch 137/347] [D loss: 0.199868] [G loss: 0.666795]\n",
      "[Epoch 96/100] [Batch 138/347] [D loss: 0.177406] [G loss: 0.784050]\n",
      "[Epoch 96/100] [Batch 139/347] [D loss: 0.176625] [G loss: 0.870295]\n",
      "[Epoch 96/100] [Batch 140/347] [D loss: 0.277753] [G loss: 0.924836]\n",
      "[Epoch 96/100] [Batch 141/347] [D loss: 0.504398] [G loss: 0.977679]\n",
      "[Epoch 96/100] [Batch 142/347] [D loss: 0.543842] [G loss: 1.058498]\n",
      "[Epoch 96/100] [Batch 143/347] [D loss: 0.520164] [G loss: 1.072609]\n",
      "[Epoch 96/100] [Batch 144/347] [D loss: 0.389481] [G loss: 1.082315]\n",
      "[Epoch 96/100] [Batch 145/347] [D loss: 0.312879] [G loss: 1.103856]\n",
      "[Epoch 96/100] [Batch 146/347] [D loss: 0.260989] [G loss: 1.079839]\n",
      "[Epoch 96/100] [Batch 147/347] [D loss: 0.204529] [G loss: 1.011260]\n",
      "[Epoch 96/100] [Batch 148/347] [D loss: 0.225271] [G loss: 0.900087]\n",
      "[Epoch 96/100] [Batch 149/347] [D loss: 0.223291] [G loss: 0.701677]\n",
      "[Epoch 96/100] [Batch 150/347] [D loss: 0.239219] [G loss: 0.579472]\n",
      "[Epoch 96/100] [Batch 151/347] [D loss: 0.231662] [G loss: 0.512760]\n",
      "[Epoch 96/100] [Batch 152/347] [D loss: 0.234995] [G loss: 0.461880]\n",
      "[Epoch 96/100] [Batch 153/347] [D loss: 0.246138] [G loss: 0.402637]\n",
      "[Epoch 96/100] [Batch 154/347] [D loss: 0.245248] [G loss: 0.372794]\n",
      "[Epoch 96/100] [Batch 155/347] [D loss: 0.244139] [G loss: 0.358675]\n",
      "[Epoch 96/100] [Batch 156/347] [D loss: 0.255130] [G loss: 0.350224]\n",
      "[Epoch 96/100] [Batch 157/347] [D loss: 0.248113] [G loss: 0.363747]\n",
      "[Epoch 96/100] [Batch 158/347] [D loss: 0.240867] [G loss: 0.381458]\n",
      "[Epoch 96/100] [Batch 159/347] [D loss: 0.234841] [G loss: 0.388082]\n",
      "[Epoch 96/100] [Batch 160/347] [D loss: 0.221600] [G loss: 0.418741]\n",
      "[Epoch 96/100] [Batch 161/347] [D loss: 0.199771] [G loss: 0.452724]\n",
      "[Epoch 96/100] [Batch 162/347] [D loss: 0.199864] [G loss: 0.453384]\n",
      "[Epoch 96/100] [Batch 163/347] [D loss: 0.167997] [G loss: 0.540790]\n",
      "[Epoch 96/100] [Batch 164/347] [D loss: 0.145798] [G loss: 0.653852]\n",
      "[Epoch 96/100] [Batch 165/347] [D loss: 0.115691] [G loss: 0.769063]\n",
      "[Epoch 96/100] [Batch 166/347] [D loss: 0.095183] [G loss: 0.923866]\n",
      "[Epoch 96/100] [Batch 167/347] [D loss: 0.142160] [G loss: 1.036659]\n",
      "[Epoch 96/100] [Batch 168/347] [D loss: 0.173570] [G loss: 1.058694]\n",
      "[Epoch 96/100] [Batch 169/347] [D loss: 0.342675] [G loss: 1.047597]\n",
      "[Epoch 96/100] [Batch 170/347] [D loss: 0.478633] [G loss: 1.026781]\n",
      "[Epoch 96/100] [Batch 171/347] [D loss: 0.339251] [G loss: 0.982090]\n",
      "[Epoch 96/100] [Batch 172/347] [D loss: 0.356751] [G loss: 0.931446]\n",
      "[Epoch 96/100] [Batch 173/347] [D loss: 0.376167] [G loss: 0.894645]\n",
      "[Epoch 96/100] [Batch 174/347] [D loss: 0.366207] [G loss: 0.920479]\n",
      "[Epoch 96/100] [Batch 175/347] [D loss: 0.446048] [G loss: 0.849471]\n",
      "[Epoch 96/100] [Batch 176/347] [D loss: 0.371847] [G loss: 0.735802]\n",
      "[Epoch 96/100] [Batch 177/347] [D loss: 0.314539] [G loss: 0.597794]\n",
      "[Epoch 96/100] [Batch 178/347] [D loss: 0.290496] [G loss: 0.459591]\n",
      "[Epoch 96/100] [Batch 179/347] [D loss: 0.297901] [G loss: 0.379383]\n",
      "[Epoch 96/100] [Batch 180/347] [D loss: 0.303163] [G loss: 0.340943]\n",
      "[Epoch 96/100] [Batch 181/347] [D loss: 0.308983] [G loss: 0.286624]\n",
      "[Epoch 96/100] [Batch 182/347] [D loss: 0.325661] [G loss: 0.262582]\n",
      "[Epoch 96/100] [Batch 183/347] [D loss: 0.343509] [G loss: 0.252953]\n",
      "[Epoch 96/100] [Batch 184/347] [D loss: 0.391351] [G loss: 0.244607]\n",
      "[Epoch 96/100] [Batch 185/347] [D loss: 0.416691] [G loss: 0.236497]\n",
      "[Epoch 96/100] [Batch 186/347] [D loss: 0.417411] [G loss: 0.236226]\n",
      "[Epoch 96/100] [Batch 187/347] [D loss: 0.402839] [G loss: 0.238476]\n",
      "[Epoch 96/100] [Batch 188/347] [D loss: 0.380302] [G loss: 0.246935]\n",
      "[Epoch 96/100] [Batch 189/347] [D loss: 0.344589] [G loss: 0.259353]\n",
      "[Epoch 96/100] [Batch 190/347] [D loss: 0.326704] [G loss: 0.278883]\n",
      "[Epoch 96/100] [Batch 191/347] [D loss: 0.318780] [G loss: 0.300838]\n",
      "[Epoch 96/100] [Batch 192/347] [D loss: 0.313670] [G loss: 0.326838]\n",
      "[Epoch 96/100] [Batch 193/347] [D loss: 0.334049] [G loss: 0.354090]\n",
      "[Epoch 96/100] [Batch 194/347] [D loss: 0.312275] [G loss: 0.383554]\n",
      "[Epoch 96/100] [Batch 195/347] [D loss: 0.290637] [G loss: 0.416845]\n",
      "[Epoch 96/100] [Batch 196/347] [D loss: 0.257039] [G loss: 0.457321]\n",
      "[Epoch 96/100] [Batch 197/347] [D loss: 0.250083] [G loss: 0.517381]\n",
      "[Epoch 96/100] [Batch 198/347] [D loss: 0.242455] [G loss: 0.582330]\n",
      "[Epoch 96/100] [Batch 199/347] [D loss: 0.243430] [G loss: 0.679302]\n",
      "[Epoch 96/100] [Batch 200/347] [D loss: 0.291743] [G loss: 0.724810]\n",
      "[Epoch 96/100] [Batch 201/347] [D loss: 0.333543] [G loss: 0.757683]\n",
      "[Epoch 96/100] [Batch 202/347] [D loss: 0.375065] [G loss: 0.767771]\n",
      "[Epoch 96/100] [Batch 203/347] [D loss: 0.371042] [G loss: 0.777284]\n",
      "[Epoch 96/100] [Batch 204/347] [D loss: 0.343372] [G loss: 0.789059]\n",
      "[Epoch 96/100] [Batch 205/347] [D loss: 0.322638] [G loss: 0.779263]\n",
      "[Epoch 96/100] [Batch 206/347] [D loss: 0.314504] [G loss: 0.771480]\n",
      "[Epoch 96/100] [Batch 207/347] [D loss: 0.229721] [G loss: 0.764901]\n",
      "[Epoch 96/100] [Batch 208/347] [D loss: 0.227943] [G loss: 0.746698]\n",
      "[Epoch 96/100] [Batch 209/347] [D loss: 0.254194] [G loss: 0.710360]\n",
      "[Epoch 96/100] [Batch 210/347] [D loss: 0.224727] [G loss: 0.683896]\n",
      "[Epoch 96/100] [Batch 211/347] [D loss: 0.169401] [G loss: 0.644907]\n",
      "[Epoch 96/100] [Batch 212/347] [D loss: 0.086811] [G loss: 0.641616]\n",
      "[Epoch 96/100] [Batch 213/347] [D loss: 0.083441] [G loss: 0.667935]\n",
      "[Epoch 96/100] [Batch 214/347] [D loss: 0.089744] [G loss: 0.694756]\n",
      "[Epoch 96/100] [Batch 215/347] [D loss: 0.086061] [G loss: 0.723736]\n",
      "[Epoch 96/100] [Batch 216/347] [D loss: 0.226792] [G loss: 0.474886]\n",
      "[Epoch 96/100] [Batch 217/347] [D loss: 0.216041] [G loss: 0.584903]\n",
      "[Epoch 96/100] [Batch 218/347] [D loss: 0.213729] [G loss: 0.677247]\n",
      "[Epoch 96/100] [Batch 219/347] [D loss: 0.187258] [G loss: 0.779419]\n",
      "[Epoch 96/100] [Batch 220/347] [D loss: 0.196681] [G loss: 0.981189]\n",
      "[Epoch 96/100] [Batch 221/347] [D loss: 0.254426] [G loss: 1.039557]\n",
      "[Epoch 96/100] [Batch 222/347] [D loss: 0.331588] [G loss: 1.035045]\n",
      "[Epoch 96/100] [Batch 223/347] [D loss: 0.387818] [G loss: 1.002897]\n",
      "[Epoch 96/100] [Batch 224/347] [D loss: 0.485394] [G loss: 0.972729]\n",
      "[Epoch 96/100] [Batch 225/347] [D loss: 0.580776] [G loss: 0.942398]\n",
      "[Epoch 96/100] [Batch 226/347] [D loss: 0.487714] [G loss: 0.835527]\n",
      "[Epoch 96/100] [Batch 227/347] [D loss: 0.365041] [G loss: 0.551937]\n",
      "[Epoch 96/100] [Batch 228/347] [D loss: 0.370729] [G loss: 0.357762]\n",
      "[Epoch 96/100] [Batch 229/347] [D loss: 0.331161] [G loss: 0.340899]\n",
      "[Epoch 96/100] [Batch 230/347] [D loss: 0.342552] [G loss: 0.328254]\n",
      "[Epoch 96/100] [Batch 231/347] [D loss: 0.345159] [G loss: 0.300871]\n",
      "[Epoch 96/100] [Batch 232/347] [D loss: 0.356995] [G loss: 0.278074]\n",
      "[Epoch 96/100] [Batch 233/347] [D loss: 0.357901] [G loss: 0.272461]\n",
      "[Epoch 96/100] [Batch 234/347] [D loss: 0.359716] [G loss: 0.273113]\n",
      "[Epoch 96/100] [Batch 235/347] [D loss: 0.365391] [G loss: 0.297636]\n",
      "[Epoch 96/100] [Batch 236/347] [D loss: 0.350362] [G loss: 0.326778]\n",
      "[Epoch 96/100] [Batch 237/347] [D loss: 0.359522] [G loss: 0.341832]\n",
      "[Epoch 96/100] [Batch 238/347] [D loss: 0.370011] [G loss: 0.353944]\n",
      "[Epoch 96/100] [Batch 239/347] [D loss: 0.364097] [G loss: 0.365250]\n",
      "[Epoch 96/100] [Batch 240/347] [D loss: 0.366217] [G loss: 0.388463]\n",
      "[Epoch 96/100] [Batch 241/347] [D loss: 0.358962] [G loss: 0.456393]\n",
      "[Epoch 96/100] [Batch 242/347] [D loss: 0.329943] [G loss: 0.671671]\n",
      "[Epoch 96/100] [Batch 243/347] [D loss: 0.251820] [G loss: 0.753360]\n",
      "[Epoch 96/100] [Batch 244/347] [D loss: 0.215365] [G loss: 0.816449]\n",
      "[Epoch 96/100] [Batch 245/347] [D loss: 0.220023] [G loss: 0.831370]\n",
      "[Epoch 96/100] [Batch 246/347] [D loss: 0.240811] [G loss: 0.836617]\n",
      "[Epoch 96/100] [Batch 247/347] [D loss: 0.296032] [G loss: 0.829615]\n",
      "[Epoch 96/100] [Batch 248/347] [D loss: 0.299978] [G loss: 0.761053]\n",
      "[Epoch 96/100] [Batch 249/347] [D loss: 0.261299] [G loss: 0.733357]\n",
      "[Epoch 96/100] [Batch 250/347] [D loss: 0.222775] [G loss: 0.716789]\n",
      "[Epoch 96/100] [Batch 251/347] [D loss: 0.246363] [G loss: 0.747484]\n",
      "[Epoch 96/100] [Batch 252/347] [D loss: 0.245960] [G loss: 0.748914]\n",
      "[Epoch 96/100] [Batch 253/347] [D loss: 0.149251] [G loss: 0.737655]\n",
      "[Epoch 96/100] [Batch 254/347] [D loss: 0.129720] [G loss: 0.775717]\n",
      "[Epoch 96/100] [Batch 255/347] [D loss: 0.130752] [G loss: 0.827919]\n",
      "[Epoch 96/100] [Batch 256/347] [D loss: 0.137093] [G loss: 0.852877]\n",
      "[Epoch 96/100] [Batch 257/347] [D loss: 0.148890] [G loss: 0.759667]\n",
      "[Epoch 96/100] [Batch 258/347] [D loss: 0.129976] [G loss: 0.721584]\n",
      "[Epoch 96/100] [Batch 259/347] [D loss: 0.141916] [G loss: 0.748625]\n",
      "[Epoch 96/100] [Batch 260/347] [D loss: 0.132364] [G loss: 0.787445]\n",
      "[Epoch 96/100] [Batch 261/347] [D loss: 0.110371] [G loss: 0.897309]\n",
      "[Epoch 96/100] [Batch 262/347] [D loss: 0.069504] [G loss: 0.978487]\n",
      "[Epoch 96/100] [Batch 263/347] [D loss: 0.066436] [G loss: 1.009375]\n",
      "[Epoch 96/100] [Batch 264/347] [D loss: 0.066751] [G loss: 1.026538]\n",
      "[Epoch 96/100] [Batch 265/347] [D loss: 0.077308] [G loss: 1.021078]\n",
      "[Epoch 96/100] [Batch 266/347] [D loss: 0.153895] [G loss: 0.980785]\n",
      "[Epoch 96/100] [Batch 267/347] [D loss: 0.167454] [G loss: 0.959274]\n",
      "[Epoch 96/100] [Batch 268/347] [D loss: 0.186981] [G loss: 0.947614]\n",
      "[Epoch 96/100] [Batch 269/347] [D loss: 0.178689] [G loss: 0.916828]\n",
      "[Epoch 96/100] [Batch 270/347] [D loss: 0.182064] [G loss: 0.888609]\n",
      "[Epoch 96/100] [Batch 271/347] [D loss: 0.188541] [G loss: 0.886253]\n",
      "[Epoch 96/100] [Batch 272/347] [D loss: 0.386955] [G loss: 0.886290]\n",
      "[Epoch 96/100] [Batch 273/347] [D loss: 0.370139] [G loss: 0.946412]\n",
      "[Epoch 96/100] [Batch 274/347] [D loss: 0.337642] [G loss: 0.997236]\n",
      "[Epoch 96/100] [Batch 275/347] [D loss: 0.293774] [G loss: 1.040772]\n",
      "[Epoch 96/100] [Batch 276/347] [D loss: 0.202414] [G loss: 0.652628]\n",
      "[Epoch 96/100] [Batch 277/347] [D loss: 0.171311] [G loss: 0.731571]\n",
      "[Epoch 96/100] [Batch 278/347] [D loss: 0.144941] [G loss: 0.842011]\n",
      "[Epoch 96/100] [Batch 279/347] [D loss: 0.135364] [G loss: 0.883317]\n",
      "[Epoch 96/100] [Batch 280/347] [D loss: 0.526263] [G loss: 1.031258]\n",
      "[Epoch 96/100] [Batch 281/347] [D loss: 0.787078] [G loss: 1.081135]\n",
      "[Epoch 96/100] [Batch 282/347] [D loss: 0.816153] [G loss: 1.065936]\n",
      "[Epoch 96/100] [Batch 283/347] [D loss: 0.652148] [G loss: 1.044997]\n",
      "[Epoch 96/100] [Batch 284/347] [D loss: 0.451211] [G loss: 1.013715]\n",
      "[Epoch 96/100] [Batch 285/347] [D loss: 0.320952] [G loss: 0.946505]\n",
      "[Epoch 96/100] [Batch 286/347] [D loss: 0.226395] [G loss: 0.764222]\n",
      "[Epoch 96/100] [Batch 287/347] [D loss: 0.192720] [G loss: 0.545325]\n",
      "[Epoch 96/100] [Batch 288/347] [D loss: 0.196819] [G loss: 0.401909]\n",
      "[Epoch 96/100] [Batch 289/347] [D loss: 0.228606] [G loss: 0.338752]\n",
      "[Epoch 96/100] [Batch 290/347] [D loss: 0.288914] [G loss: 0.262593]\n",
      "[Epoch 96/100] [Batch 291/347] [D loss: 0.302587] [G loss: 0.256838]\n",
      "[Epoch 96/100] [Batch 292/347] [D loss: 0.317921] [G loss: 0.253246]\n",
      "[Epoch 96/100] [Batch 293/347] [D loss: 0.352234] [G loss: 0.271600]\n",
      "[Epoch 96/100] [Batch 294/347] [D loss: 0.321725] [G loss: 0.287335]\n",
      "[Epoch 96/100] [Batch 295/347] [D loss: 0.288894] [G loss: 0.301930]\n",
      "[Epoch 96/100] [Batch 296/347] [D loss: 0.261883] [G loss: 0.327643]\n",
      "[Epoch 96/100] [Batch 297/347] [D loss: 0.236231] [G loss: 0.392413]\n",
      "[Epoch 96/100] [Batch 298/347] [D loss: 0.201412] [G loss: 0.464503]\n",
      "[Epoch 96/100] [Batch 299/347] [D loss: 0.174223] [G loss: 0.559743]\n",
      "[Epoch 96/100] [Batch 300/347] [D loss: 0.131959] [G loss: 0.645326]\n",
      "[Epoch 96/100] [Batch 301/347] [D loss: 0.166272] [G loss: 0.780591]\n",
      "[Epoch 96/100] [Batch 302/347] [D loss: 0.195524] [G loss: 0.856731]\n",
      "[Epoch 96/100] [Batch 303/347] [D loss: 0.233382] [G loss: 0.886987]\n",
      "[Epoch 96/100] [Batch 304/347] [D loss: 0.187479] [G loss: 0.890410]\n",
      "[Epoch 96/100] [Batch 305/347] [D loss: 0.097660] [G loss: 0.907966]\n",
      "[Epoch 96/100] [Batch 306/347] [D loss: 0.094894] [G loss: 0.942645]\n",
      "[Epoch 96/100] [Batch 307/347] [D loss: 0.077297] [G loss: 0.987844]\n",
      "[Epoch 96/100] [Batch 308/347] [D loss: 0.105311] [G loss: 1.017086]\n",
      "[Epoch 96/100] [Batch 309/347] [D loss: 0.240925] [G loss: 1.023787]\n",
      "[Epoch 96/100] [Batch 310/347] [D loss: 0.375789] [G loss: 1.011580]\n",
      "[Epoch 96/100] [Batch 311/347] [D loss: 0.303890] [G loss: 0.941227]\n",
      "[Epoch 96/100] [Batch 312/347] [D loss: 0.231933] [G loss: 0.845708]\n",
      "[Epoch 96/100] [Batch 313/347] [D loss: 0.265726] [G loss: 0.800469]\n",
      "[Epoch 96/100] [Batch 314/347] [D loss: 0.268125] [G loss: 0.849487]\n",
      "[Epoch 96/100] [Batch 315/347] [D loss: 0.271067] [G loss: 0.805750]\n",
      "[Epoch 96/100] [Batch 316/347] [D loss: 0.272657] [G loss: 0.665384]\n",
      "[Epoch 96/100] [Batch 317/347] [D loss: 0.289328] [G loss: 0.580572]\n",
      "[Epoch 96/100] [Batch 318/347] [D loss: 0.268233] [G loss: 0.557489]\n",
      "[Epoch 96/100] [Batch 319/347] [D loss: 0.254752] [G loss: 0.562944]\n",
      "[Epoch 96/100] [Batch 320/347] [D loss: 0.267850] [G loss: 0.550092]\n",
      "[Epoch 96/100] [Batch 321/347] [D loss: 0.256655] [G loss: 0.541013]\n",
      "[Epoch 96/100] [Batch 322/347] [D loss: 0.282179] [G loss: 0.515331]\n",
      "[Epoch 96/100] [Batch 323/347] [D loss: 0.209457] [G loss: 0.540702]\n",
      "[Epoch 96/100] [Batch 324/347] [D loss: 0.190690] [G loss: 0.581624]\n",
      "[Epoch 96/100] [Batch 325/347] [D loss: 0.192179] [G loss: 0.597237]\n",
      "[Epoch 96/100] [Batch 326/347] [D loss: 0.189995] [G loss: 0.628200]\n",
      "[Epoch 96/100] [Batch 327/347] [D loss: 0.182251] [G loss: 0.651131]\n",
      "[Epoch 96/100] [Batch 328/347] [D loss: 0.193127] [G loss: 0.669515]\n",
      "[Epoch 96/100] [Batch 329/347] [D loss: 0.183707] [G loss: 0.752069]\n",
      "[Epoch 96/100] [Batch 330/347] [D loss: 0.153129] [G loss: 0.834012]\n",
      "[Epoch 96/100] [Batch 331/347] [D loss: 0.216922] [G loss: 0.868646]\n",
      "[Epoch 96/100] [Batch 332/347] [D loss: 0.318028] [G loss: 0.925951]\n",
      "[Epoch 96/100] [Batch 333/347] [D loss: 0.241972] [G loss: 0.995114]\n",
      "[Epoch 96/100] [Batch 334/347] [D loss: 0.217024] [G loss: 1.013332]\n",
      "[Epoch 96/100] [Batch 335/347] [D loss: 0.246345] [G loss: 1.033107]\n",
      "[Epoch 96/100] [Batch 336/347] [D loss: 0.311298] [G loss: 1.080904]\n",
      "[Epoch 96/100] [Batch 337/347] [D loss: 0.415362] [G loss: 1.077545]\n",
      "[Epoch 96/100] [Batch 338/347] [D loss: 0.508642] [G loss: 1.015438]\n",
      "[Epoch 96/100] [Batch 339/347] [D loss: 0.369471] [G loss: 0.863746]\n",
      "[Epoch 96/100] [Batch 340/347] [D loss: 0.293341] [G loss: 0.680998]\n",
      "[Epoch 96/100] [Batch 341/347] [D loss: 0.322157] [G loss: 0.597923]\n",
      "[Epoch 96/100] [Batch 342/347] [D loss: 0.187462] [G loss: 0.535292]\n",
      "[Epoch 96/100] [Batch 343/347] [D loss: 0.164191] [G loss: 0.483474]\n",
      "[Epoch 96/100] [Batch 344/347] [D loss: 0.188829] [G loss: 0.461663]\n",
      "[Epoch 96/100] [Batch 345/347] [D loss: 0.195156] [G loss: 0.465728]\n",
      "[Epoch 96/100] [Batch 346/347] [D loss: 0.235036] [G loss: 0.443152]\n",
      "[Epoch 96/100] [Batch 347/347] [D loss: 0.263357] [G loss: 0.435317]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 97/100] [Batch 1/347] [D loss: 0.379611] [G loss: 0.509544]\n",
      "[Epoch 97/100] [Batch 2/347] [D loss: 0.381554] [G loss: 0.531704]\n",
      "[Epoch 97/100] [Batch 3/347] [D loss: 0.383032] [G loss: 0.572297]\n",
      "[Epoch 97/100] [Batch 4/347] [D loss: 0.393613] [G loss: 0.608496]\n",
      "[Epoch 97/100] [Batch 5/347] [D loss: 0.395548] [G loss: 0.672780]\n",
      "[Epoch 97/100] [Batch 6/347] [D loss: 0.339742] [G loss: 0.767988]\n",
      "[Epoch 97/100] [Batch 7/347] [D loss: 0.283295] [G loss: 0.811846]\n",
      "[Epoch 97/100] [Batch 8/347] [D loss: 0.284045] [G loss: 0.834762]\n",
      "[Epoch 97/100] [Batch 9/347] [D loss: 0.277866] [G loss: 0.853173]\n",
      "[Epoch 97/100] [Batch 10/347] [D loss: 0.304280] [G loss: 0.855582]\n",
      "[Epoch 97/100] [Batch 11/347] [D loss: 0.369840] [G loss: 0.838891]\n",
      "[Epoch 97/100] [Batch 12/347] [D loss: 0.352118] [G loss: 0.833227]\n",
      "[Epoch 97/100] [Batch 13/347] [D loss: 0.310307] [G loss: 0.820396]\n",
      "[Epoch 97/100] [Batch 14/347] [D loss: 0.280973] [G loss: 0.830561]\n",
      "[Epoch 97/100] [Batch 15/347] [D loss: 0.282075] [G loss: 0.829143]\n",
      "[Epoch 97/100] [Batch 16/347] [D loss: 0.289588] [G loss: 0.822576]\n",
      "[Epoch 97/100] [Batch 17/347] [D loss: 0.292100] [G loss: 0.791118]\n",
      "[Epoch 97/100] [Batch 18/347] [D loss: 0.324212] [G loss: 0.726720]\n",
      "[Epoch 97/100] [Batch 19/347] [D loss: 0.342193] [G loss: 0.658859]\n",
      "[Epoch 97/100] [Batch 20/347] [D loss: 0.343487] [G loss: 0.647448]\n",
      "[Epoch 97/100] [Batch 21/347] [D loss: 0.324745] [G loss: 0.637224]\n",
      "[Epoch 97/100] [Batch 22/347] [D loss: 0.328876] [G loss: 0.641164]\n",
      "[Epoch 97/100] [Batch 23/347] [D loss: 0.323727] [G loss: 0.678876]\n",
      "[Epoch 97/100] [Batch 24/347] [D loss: 0.289424] [G loss: 0.729852]\n",
      "[Epoch 97/100] [Batch 25/347] [D loss: 0.164786] [G loss: 0.752299]\n",
      "[Epoch 97/100] [Batch 26/347] [D loss: 0.160676] [G loss: 0.793978]\n",
      "[Epoch 97/100] [Batch 27/347] [D loss: 0.155788] [G loss: 0.819803]\n",
      "[Epoch 97/100] [Batch 28/347] [D loss: 0.145686] [G loss: 0.885505]\n",
      "[Epoch 97/100] [Batch 29/347] [D loss: 0.128789] [G loss: 0.955700]\n",
      "[Epoch 97/100] [Batch 30/347] [D loss: 0.071662] [G loss: 1.026269]\n",
      "[Epoch 97/100] [Batch 31/347] [D loss: 0.066179] [G loss: 1.074686]\n",
      "[Epoch 97/100] [Batch 32/347] [D loss: 0.072453] [G loss: 1.106917]\n",
      "[Epoch 97/100] [Batch 33/347] [D loss: 0.126955] [G loss: 1.118250]\n",
      "[Epoch 97/100] [Batch 34/347] [D loss: 0.235784] [G loss: 1.119760]\n",
      "[Epoch 97/100] [Batch 35/347] [D loss: 0.249213] [G loss: 1.106562]\n",
      "[Epoch 97/100] [Batch 36/347] [D loss: 0.272096] [G loss: 1.088470]\n",
      "[Epoch 97/100] [Batch 37/347] [D loss: 0.273069] [G loss: 1.085336]\n",
      "[Epoch 97/100] [Batch 38/347] [D loss: 0.340782] [G loss: 1.021608]\n",
      "[Epoch 97/100] [Batch 39/347] [D loss: 0.325353] [G loss: 0.943373]\n",
      "[Epoch 97/100] [Batch 40/347] [D loss: 0.344195] [G loss: 0.851785]\n",
      "[Epoch 97/100] [Batch 41/347] [D loss: 0.303241] [G loss: 0.787773]\n",
      "[Epoch 97/100] [Batch 42/347] [D loss: 0.283890] [G loss: 0.755479]\n",
      "[Epoch 97/100] [Batch 43/347] [D loss: 0.322219] [G loss: 0.739199]\n",
      "[Epoch 97/100] [Batch 44/347] [D loss: 0.295577] [G loss: 0.747095]\n",
      "[Epoch 97/100] [Batch 45/347] [D loss: 0.260142] [G loss: 0.702783]\n",
      "[Epoch 97/100] [Batch 46/347] [D loss: 0.202965] [G loss: 0.648464]\n",
      "[Epoch 97/100] [Batch 47/347] [D loss: 0.217732] [G loss: 0.641236]\n",
      "[Epoch 97/100] [Batch 48/347] [D loss: 0.116156] [G loss: 0.689199]\n",
      "[Epoch 97/100] [Batch 49/347] [D loss: 0.108002] [G loss: 0.777934]\n",
      "[Epoch 97/100] [Batch 50/347] [D loss: 0.147056] [G loss: 0.687684]\n",
      "[Epoch 97/100] [Batch 51/347] [D loss: 0.135418] [G loss: 0.778403]\n",
      "[Epoch 97/100] [Batch 52/347] [D loss: 0.202153] [G loss: 0.814921]\n",
      "[Epoch 97/100] [Batch 53/347] [D loss: 0.227765] [G loss: 0.853957]\n",
      "[Epoch 97/100] [Batch 54/347] [D loss: 0.241208] [G loss: 0.911176]\n",
      "[Epoch 97/100] [Batch 55/347] [D loss: 0.264994] [G loss: 0.974156]\n",
      "[Epoch 97/100] [Batch 56/347] [D loss: 0.214045] [G loss: 1.122893]\n",
      "[Epoch 97/100] [Batch 57/347] [D loss: 0.183146] [G loss: 1.238422]\n",
      "[Epoch 97/100] [Batch 58/347] [D loss: 0.178744] [G loss: 1.271133]\n",
      "[Epoch 97/100] [Batch 59/347] [D loss: 0.164824] [G loss: 1.257224]\n",
      "[Epoch 97/100] [Batch 60/347] [D loss: 0.190714] [G loss: 1.206591]\n",
      "[Epoch 97/100] [Batch 61/347] [D loss: 0.231576] [G loss: 1.160309]\n",
      "[Epoch 97/100] [Batch 62/347] [D loss: 0.221584] [G loss: 1.165079]\n",
      "[Epoch 97/100] [Batch 63/347] [D loss: 0.160061] [G loss: 1.166432]\n",
      "[Epoch 97/100] [Batch 64/347] [D loss: 0.158746] [G loss: 1.124262]\n",
      "[Epoch 97/100] [Batch 65/347] [D loss: 0.157151] [G loss: 1.080185]\n",
      "[Epoch 97/100] [Batch 66/347] [D loss: 0.111297] [G loss: 0.942399]\n",
      "[Epoch 97/100] [Batch 67/347] [D loss: 0.135363] [G loss: 0.776295]\n",
      "[Epoch 97/100] [Batch 68/347] [D loss: 0.163040] [G loss: 0.677399]\n",
      "[Epoch 97/100] [Batch 69/347] [D loss: 0.102623] [G loss: 0.722493]\n",
      "[Epoch 97/100] [Batch 70/347] [D loss: 0.117601] [G loss: 0.702877]\n",
      "[Epoch 97/100] [Batch 71/347] [D loss: 0.133700] [G loss: 0.719174]\n",
      "[Epoch 97/100] [Batch 72/347] [D loss: 0.102155] [G loss: 0.849999]\n",
      "[Epoch 97/100] [Batch 73/347] [D loss: 0.178912] [G loss: 0.914531]\n",
      "[Epoch 97/100] [Batch 74/347] [D loss: 0.141818] [G loss: 1.006643]\n",
      "[Epoch 97/100] [Batch 75/347] [D loss: 0.150681] [G loss: 1.043883]\n",
      "[Epoch 97/100] [Batch 76/347] [D loss: 0.157248] [G loss: 1.050622]\n",
      "[Epoch 97/100] [Batch 77/347] [D loss: 0.215036] [G loss: 1.105723]\n",
      "[Epoch 97/100] [Batch 78/347] [D loss: 0.246057] [G loss: 1.123571]\n",
      "[Epoch 97/100] [Batch 79/347] [D loss: 0.210653] [G loss: 1.103084]\n",
      "[Epoch 97/100] [Batch 80/347] [D loss: 0.098309] [G loss: 1.061617]\n",
      "[Epoch 97/100] [Batch 81/347] [D loss: 0.102641] [G loss: 1.018757]\n",
      "[Epoch 97/100] [Batch 82/347] [D loss: 0.107060] [G loss: 1.067979]\n",
      "[Epoch 97/100] [Batch 83/347] [D loss: 0.124390] [G loss: 1.045551]\n",
      "[Epoch 97/100] [Batch 84/347] [D loss: 0.355747] [G loss: 0.989196]\n",
      "[Epoch 97/100] [Batch 85/347] [D loss: 0.475430] [G loss: 0.876896]\n",
      "[Epoch 97/100] [Batch 86/347] [D loss: 0.421918] [G loss: 0.722394]\n",
      "[Epoch 97/100] [Batch 87/347] [D loss: 0.391055] [G loss: 0.557279]\n",
      "[Epoch 97/100] [Batch 88/347] [D loss: 0.382341] [G loss: 0.484651]\n",
      "[Epoch 97/100] [Batch 89/347] [D loss: 0.383870] [G loss: 0.436315]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 97/100] [Batch 90/347] [D loss: 0.377672] [G loss: 0.387542]\n",
      "[Epoch 97/100] [Batch 91/347] [D loss: 0.381997] [G loss: 0.349604]\n",
      "[Epoch 97/100] [Batch 92/347] [D loss: 0.388524] [G loss: 0.319529]\n",
      "[Epoch 97/100] [Batch 93/347] [D loss: 0.393997] [G loss: 0.297158]\n",
      "[Epoch 97/100] [Batch 94/347] [D loss: 0.391808] [G loss: 0.280134]\n",
      "[Epoch 97/100] [Batch 95/347] [D loss: 0.378077] [G loss: 0.273033]\n",
      "[Epoch 97/100] [Batch 96/347] [D loss: 0.377703] [G loss: 0.273985]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 97/100] [Batch 97/347] [D loss: 0.366130] [G loss: 0.282853]\n",
      "[Epoch 97/100] [Batch 98/347] [D loss: 0.339846] [G loss: 0.296083]\n",
      "[Epoch 97/100] [Batch 99/347] [D loss: 0.330332] [G loss: 0.315442]\n",
      "[Epoch 97/100] [Batch 100/347] [D loss: 0.316224] [G loss: 0.338388]\n",
      "[Epoch 97/100] [Batch 101/347] [D loss: 0.309824] [G loss: 0.368847]\n",
      "[Epoch 97/100] [Batch 102/347] [D loss: 0.372880] [G loss: 0.407437]\n",
      "[Epoch 97/100] [Batch 103/347] [D loss: 0.369732] [G loss: 0.454982]\n",
      "[Epoch 97/100] [Batch 104/347] [D loss: 0.346303] [G loss: 0.512822]\n",
      "[Epoch 97/100] [Batch 105/347] [D loss: 0.272691] [G loss: 0.564298]\n",
      "[Epoch 97/100] [Batch 106/347] [D loss: 0.129315] [G loss: 0.661676]\n",
      "[Epoch 97/100] [Batch 107/347] [D loss: 0.090281] [G loss: 0.771538]\n",
      "[Epoch 97/100] [Batch 108/347] [D loss: 0.062867] [G loss: 0.847929]\n",
      "[Epoch 97/100] [Batch 109/347] [D loss: 0.042065] [G loss: 0.910249]\n",
      "[Epoch 97/100] [Batch 110/347] [D loss: 0.114052] [G loss: 0.783763]\n",
      "[Epoch 97/100] [Batch 111/347] [D loss: 0.083221] [G loss: 0.866832]\n",
      "[Epoch 97/100] [Batch 112/347] [D loss: 0.048480] [G loss: 0.924615]\n",
      "[Epoch 97/100] [Batch 113/347] [D loss: 0.082195] [G loss: 0.956428]\n",
      "[Epoch 97/100] [Batch 114/347] [D loss: 0.141990] [G loss: 1.015087]\n",
      "[Epoch 97/100] [Batch 115/347] [D loss: 0.186637] [G loss: 1.028239]\n",
      "[Epoch 97/100] [Batch 116/347] [D loss: 0.204747] [G loss: 1.036314]\n",
      "[Epoch 97/100] [Batch 117/347] [D loss: 0.400589] [G loss: 1.034278]\n",
      "[Epoch 97/100] [Batch 118/347] [D loss: 0.249209] [G loss: 1.065449]\n",
      "[Epoch 97/100] [Batch 119/347] [D loss: 0.191964] [G loss: 1.042663]\n",
      "[Epoch 97/100] [Batch 120/347] [D loss: 0.106306] [G loss: 1.000651]\n",
      "[Epoch 97/100] [Batch 121/347] [D loss: 0.063521] [G loss: 0.946745]\n",
      "[Epoch 97/100] [Batch 122/347] [D loss: 0.155312] [G loss: 0.922598]\n",
      "[Epoch 97/100] [Batch 123/347] [D loss: 0.194872] [G loss: 0.842821]\n",
      "[Epoch 97/100] [Batch 124/347] [D loss: 0.149979] [G loss: 0.752897]\n",
      "[Epoch 97/100] [Batch 125/347] [D loss: 0.145617] [G loss: 0.645894]\n",
      "[Epoch 97/100] [Batch 126/347] [D loss: 0.171158] [G loss: 0.542541]\n",
      "[Epoch 97/100] [Batch 127/347] [D loss: 0.192402] [G loss: 0.484124]\n",
      "[Epoch 97/100] [Batch 128/347] [D loss: 0.181001] [G loss: 0.446312]\n",
      "[Epoch 97/100] [Batch 129/347] [D loss: 0.191643] [G loss: 0.425727]\n",
      "[Epoch 97/100] [Batch 130/347] [D loss: 0.185518] [G loss: 0.476478]\n",
      "[Epoch 97/100] [Batch 131/347] [D loss: 0.165603] [G loss: 0.554559]\n",
      "[Epoch 97/100] [Batch 132/347] [D loss: 0.147004] [G loss: 0.642776]\n",
      "[Epoch 97/100] [Batch 133/347] [D loss: 0.183587] [G loss: 0.763615]\n",
      "[Epoch 97/100] [Batch 134/347] [D loss: 0.334660] [G loss: 0.672197]\n",
      "[Epoch 97/100] [Batch 135/347] [D loss: 0.305461] [G loss: 0.725365]\n",
      "[Epoch 97/100] [Batch 136/347] [D loss: 0.189307] [G loss: 0.935139]\n",
      "[Epoch 97/100] [Batch 137/347] [D loss: 0.071254] [G loss: 1.015171]\n",
      "[Epoch 97/100] [Batch 138/347] [D loss: 0.084355] [G loss: 1.038239]\n",
      "[Epoch 97/100] [Batch 139/347] [D loss: 0.122723] [G loss: 1.047922]\n",
      "[Epoch 97/100] [Batch 140/347] [D loss: 0.263987] [G loss: 1.041085]\n",
      "[Epoch 97/100] [Batch 141/347] [D loss: 0.654409] [G loss: 1.030812]\n",
      "[Epoch 97/100] [Batch 142/347] [D loss: 0.748648] [G loss: 1.051976]\n",
      "[Epoch 97/100] [Batch 143/347] [D loss: 0.685605] [G loss: 1.057264]\n",
      "[Epoch 97/100] [Batch 144/347] [D loss: 0.462257] [G loss: 1.060659]\n",
      "[Epoch 97/100] [Batch 145/347] [D loss: 0.302108] [G loss: 1.083190]\n",
      "[Epoch 97/100] [Batch 146/347] [D loss: 0.223095] [G loss: 1.073864]\n",
      "[Epoch 97/100] [Batch 147/347] [D loss: 0.153568] [G loss: 1.020904]\n",
      "[Epoch 97/100] [Batch 148/347] [D loss: 0.154966] [G loss: 0.915238]\n",
      "[Epoch 97/100] [Batch 149/347] [D loss: 0.145262] [G loss: 0.682338]\n",
      "[Epoch 97/100] [Batch 150/347] [D loss: 0.160436] [G loss: 0.489961]\n",
      "[Epoch 97/100] [Batch 151/347] [D loss: 0.178105] [G loss: 0.409035]\n",
      "[Epoch 97/100] [Batch 152/347] [D loss: 0.195568] [G loss: 0.375130]\n",
      "[Epoch 97/100] [Batch 153/347] [D loss: 0.211520] [G loss: 0.343563]\n",
      "[Epoch 97/100] [Batch 154/347] [D loss: 0.226003] [G loss: 0.313189]\n",
      "[Epoch 97/100] [Batch 155/347] [D loss: 0.239252] [G loss: 0.291308]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 97/100] [Batch 156/347] [D loss: 0.257213] [G loss: 0.274484]\n",
      "[Epoch 97/100] [Batch 157/347] [D loss: 0.255067] [G loss: 0.298682]\n",
      "[Epoch 97/100] [Batch 158/347] [D loss: 0.249949] [G loss: 0.325679]\n",
      "[Epoch 97/100] [Batch 159/347] [D loss: 0.229732] [G loss: 0.355497]\n",
      "[Epoch 97/100] [Batch 160/347] [D loss: 0.210813] [G loss: 0.412260]\n",
      "[Epoch 97/100] [Batch 161/347] [D loss: 0.179533] [G loss: 0.479988]\n",
      "[Epoch 97/100] [Batch 162/347] [D loss: 0.155533] [G loss: 0.546286]\n",
      "[Epoch 97/100] [Batch 163/347] [D loss: 0.109773] [G loss: 0.739538]\n",
      "[Epoch 97/100] [Batch 164/347] [D loss: 0.069721] [G loss: 0.844186]\n",
      "[Epoch 97/100] [Batch 165/347] [D loss: 0.049212] [G loss: 0.913519]\n",
      "[Epoch 97/100] [Batch 166/347] [D loss: 0.059820] [G loss: 1.012023]\n",
      "[Epoch 97/100] [Batch 167/347] [D loss: 0.126158] [G loss: 1.067632]\n",
      "[Epoch 97/100] [Batch 168/347] [D loss: 0.185214] [G loss: 1.074267]\n",
      "[Epoch 97/100] [Batch 169/347] [D loss: 0.350725] [G loss: 1.060198]\n",
      "[Epoch 97/100] [Batch 170/347] [D loss: 0.462198] [G loss: 1.026592]\n",
      "[Epoch 97/100] [Batch 171/347] [D loss: 0.297433] [G loss: 0.989908]\n",
      "[Epoch 97/100] [Batch 172/347] [D loss: 0.297327] [G loss: 0.985354]\n",
      "[Epoch 97/100] [Batch 173/347] [D loss: 0.321097] [G loss: 0.956421]\n",
      "[Epoch 97/100] [Batch 174/347] [D loss: 0.312568] [G loss: 0.960184]\n",
      "[Epoch 97/100] [Batch 175/347] [D loss: 0.383182] [G loss: 0.876281]\n",
      "[Epoch 97/100] [Batch 176/347] [D loss: 0.314843] [G loss: 0.742702]\n",
      "[Epoch 97/100] [Batch 177/347] [D loss: 0.267946] [G loss: 0.578958]\n",
      "[Epoch 97/100] [Batch 178/347] [D loss: 0.257313] [G loss: 0.442868]\n",
      "[Epoch 97/100] [Batch 179/347] [D loss: 0.274985] [G loss: 0.374749]\n",
      "[Epoch 97/100] [Batch 180/347] [D loss: 0.285968] [G loss: 0.335699]\n",
      "[Epoch 97/100] [Batch 181/347] [D loss: 0.297167] [G loss: 0.283035]\n",
      "[Epoch 97/100] [Batch 182/347] [D loss: 0.316517] [G loss: 0.253944]\n",
      "[Epoch 97/100] [Batch 183/347] [D loss: 0.332052] [G loss: 0.251037]\n",
      "[Epoch 97/100] [Batch 184/347] [D loss: 0.375235] [G loss: 0.249629]\n",
      "[Epoch 97/100] [Batch 185/347] [D loss: 0.396760] [G loss: 0.248560]\n",
      "[Epoch 97/100] [Batch 186/347] [D loss: 0.395263] [G loss: 0.255083]\n",
      "[Epoch 97/100] [Batch 187/347] [D loss: 0.377837] [G loss: 0.264170]\n",
      "[Epoch 97/100] [Batch 188/347] [D loss: 0.356335] [G loss: 0.278663]\n",
      "[Epoch 97/100] [Batch 189/347] [D loss: 0.318149] [G loss: 0.298623]\n",
      "[Epoch 97/100] [Batch 190/347] [D loss: 0.297418] [G loss: 0.323152]\n",
      "[Epoch 97/100] [Batch 191/347] [D loss: 0.289999] [G loss: 0.352811]\n",
      "[Epoch 97/100] [Batch 192/347] [D loss: 0.283811] [G loss: 0.384776]\n",
      "[Epoch 97/100] [Batch 193/347] [D loss: 0.303028] [G loss: 0.416385]\n",
      "[Epoch 97/100] [Batch 194/347] [D loss: 0.282949] [G loss: 0.459699]\n",
      "[Epoch 97/100] [Batch 195/347] [D loss: 0.261180] [G loss: 0.525579]\n",
      "[Epoch 97/100] [Batch 196/347] [D loss: 0.223561] [G loss: 0.609503]\n",
      "[Epoch 97/100] [Batch 197/347] [D loss: 0.212677] [G loss: 0.726421]\n",
      "[Epoch 97/100] [Batch 198/347] [D loss: 0.202072] [G loss: 0.806326]\n",
      "[Epoch 97/100] [Batch 199/347] [D loss: 0.207982] [G loss: 0.854882]\n",
      "[Epoch 97/100] [Batch 200/347] [D loss: 0.275892] [G loss: 0.880562]\n",
      "[Epoch 97/100] [Batch 201/347] [D loss: 0.326188] [G loss: 0.886435]\n",
      "[Epoch 97/100] [Batch 202/347] [D loss: 0.366924] [G loss: 0.874824]\n",
      "[Epoch 97/100] [Batch 203/347] [D loss: 0.355717] [G loss: 0.853200]\n",
      "[Epoch 97/100] [Batch 204/347] [D loss: 0.314396] [G loss: 0.822693]\n",
      "[Epoch 97/100] [Batch 205/347] [D loss: 0.278512] [G loss: 0.762542]\n",
      "[Epoch 97/100] [Batch 206/347] [D loss: 0.262175] [G loss: 0.695592]\n",
      "[Epoch 97/100] [Batch 207/347] [D loss: 0.190683] [G loss: 0.611844]\n",
      "[Epoch 97/100] [Batch 208/347] [D loss: 0.200406] [G loss: 0.556697]\n",
      "[Epoch 97/100] [Batch 209/347] [D loss: 0.232406] [G loss: 0.509024]\n",
      "[Epoch 97/100] [Batch 210/347] [D loss: 0.216625] [G loss: 0.498727]\n",
      "[Epoch 97/100] [Batch 211/347] [D loss: 0.194247] [G loss: 0.497079]\n",
      "[Epoch 97/100] [Batch 212/347] [D loss: 0.163354] [G loss: 0.527382]\n",
      "[Epoch 97/100] [Batch 213/347] [D loss: 0.141986] [G loss: 0.624189]\n",
      "[Epoch 97/100] [Batch 214/347] [D loss: 0.125830] [G loss: 0.710400]\n",
      "[Epoch 97/100] [Batch 215/347] [D loss: 0.099200] [G loss: 0.773922]\n",
      "[Epoch 97/100] [Batch 216/347] [D loss: 0.165245] [G loss: 0.668499]\n",
      "[Epoch 97/100] [Batch 217/347] [D loss: 0.123948] [G loss: 0.821403]\n",
      "[Epoch 97/100] [Batch 218/347] [D loss: 0.107962] [G loss: 0.923788]\n",
      "[Epoch 97/100] [Batch 219/347] [D loss: 0.094794] [G loss: 0.979462]\n",
      "[Epoch 97/100] [Batch 220/347] [D loss: 0.183265] [G loss: 1.042666]\n",
      "[Epoch 97/100] [Batch 221/347] [D loss: 0.281808] [G loss: 1.040730]\n",
      "[Epoch 97/100] [Batch 222/347] [D loss: 0.387876] [G loss: 1.010776]\n",
      "[Epoch 97/100] [Batch 223/347] [D loss: 0.486573] [G loss: 1.013776]\n",
      "[Epoch 97/100] [Batch 224/347] [D loss: 0.556893] [G loss: 1.031954]\n",
      "[Epoch 97/100] [Batch 225/347] [D loss: 0.624930] [G loss: 1.015448]\n",
      "[Epoch 97/100] [Batch 226/347] [D loss: 0.437853] [G loss: 0.883101]\n",
      "[Epoch 97/100] [Batch 227/347] [D loss: 0.303292] [G loss: 0.534446]\n",
      "[Epoch 97/100] [Batch 228/347] [D loss: 0.316997] [G loss: 0.334237]\n",
      "[Epoch 97/100] [Batch 229/347] [D loss: 0.312513] [G loss: 0.228009]\n",
      "[Epoch 97/100] [Batch 230/347] [D loss: 0.359178] [G loss: 0.206604]\n",
      "[Epoch 97/100] [Batch 231/347] [D loss: 0.403597] [G loss: 0.183147]\n",
      "[Epoch 97/100] [Batch 232/347] [D loss: 0.446393] [G loss: 0.167162]\n",
      "[Epoch 97/100] [Batch 233/347] [D loss: 0.508422] [G loss: 0.167878]\n",
      "[Epoch 97/100] [Batch 234/347] [D loss: 0.534140] [G loss: 0.173958]\n",
      "[Epoch 97/100] [Batch 235/347] [D loss: 0.533468] [G loss: 0.206398]\n",
      "[Epoch 97/100] [Batch 236/347] [D loss: 0.495081] [G loss: 0.243670]\n",
      "[Epoch 97/100] [Batch 237/347] [D loss: 0.435442] [G loss: 0.272642]\n",
      "[Epoch 97/100] [Batch 238/347] [D loss: 0.383684] [G loss: 0.302251]\n",
      "[Epoch 97/100] [Batch 239/347] [D loss: 0.349274] [G loss: 0.331732]\n",
      "[Epoch 97/100] [Batch 240/347] [D loss: 0.329986] [G loss: 0.378677]\n",
      "[Epoch 97/100] [Batch 241/347] [D loss: 0.314061] [G loss: 0.477051]\n",
      "[Epoch 97/100] [Batch 242/347] [D loss: 0.290734] [G loss: 0.736072]\n",
      "[Epoch 97/100] [Batch 243/347] [D loss: 0.218810] [G loss: 0.839489]\n",
      "[Epoch 97/100] [Batch 244/347] [D loss: 0.189370] [G loss: 0.884294]\n",
      "[Epoch 97/100] [Batch 245/347] [D loss: 0.205268] [G loss: 0.914403]\n",
      "[Epoch 97/100] [Batch 246/347] [D loss: 0.238243] [G loss: 0.923826]\n",
      "[Epoch 97/100] [Batch 247/347] [D loss: 0.301074] [G loss: 0.956029]\n",
      "[Epoch 97/100] [Batch 248/347] [D loss: 0.294988] [G loss: 0.921660]\n",
      "[Epoch 97/100] [Batch 249/347] [D loss: 0.244116] [G loss: 0.877200]\n",
      "[Epoch 97/100] [Batch 250/347] [D loss: 0.192832] [G loss: 0.868045]\n",
      "[Epoch 97/100] [Batch 251/347] [D loss: 0.215069] [G loss: 0.869132]\n",
      "[Epoch 97/100] [Batch 252/347] [D loss: 0.208372] [G loss: 0.831523]\n",
      "[Epoch 97/100] [Batch 253/347] [D loss: 0.107434] [G loss: 0.767628]\n",
      "[Epoch 97/100] [Batch 254/347] [D loss: 0.093912] [G loss: 0.717914]\n",
      "[Epoch 97/100] [Batch 255/347] [D loss: 0.100290] [G loss: 0.721074]\n",
      "[Epoch 97/100] [Batch 256/347] [D loss: 0.104636] [G loss: 0.726023]\n",
      "[Epoch 97/100] [Batch 257/347] [D loss: 0.133645] [G loss: 0.589188]\n",
      "[Epoch 97/100] [Batch 258/347] [D loss: 0.119420] [G loss: 0.592438]\n",
      "[Epoch 97/100] [Batch 259/347] [D loss: 0.123363] [G loss: 0.651143]\n",
      "[Epoch 97/100] [Batch 260/347] [D loss: 0.106789] [G loss: 0.703129]\n",
      "[Epoch 97/100] [Batch 261/347] [D loss: 0.075563] [G loss: 0.819588]\n",
      "[Epoch 97/100] [Batch 262/347] [D loss: 0.045679] [G loss: 0.928572]\n",
      "[Epoch 97/100] [Batch 263/347] [D loss: 0.037907] [G loss: 0.974874]\n",
      "[Epoch 97/100] [Batch 264/347] [D loss: 0.035741] [G loss: 1.006075]\n",
      "[Epoch 97/100] [Batch 265/347] [D loss: 0.044745] [G loss: 1.019615]\n",
      "[Epoch 97/100] [Batch 266/347] [D loss: 0.110440] [G loss: 1.006465]\n",
      "[Epoch 97/100] [Batch 267/347] [D loss: 0.126762] [G loss: 1.009174]\n",
      "[Epoch 97/100] [Batch 268/347] [D loss: 0.152919] [G loss: 1.015726]\n",
      "[Epoch 97/100] [Batch 269/347] [D loss: 0.147429] [G loss: 1.005427]\n",
      "[Epoch 97/100] [Batch 270/347] [D loss: 0.151795] [G loss: 1.001270]\n",
      "[Epoch 97/100] [Batch 271/347] [D loss: 0.171717] [G loss: 1.000060]\n",
      "[Epoch 97/100] [Batch 272/347] [D loss: 0.390024] [G loss: 1.000524]\n",
      "[Epoch 97/100] [Batch 273/347] [D loss: 0.376180] [G loss: 1.023178]\n",
      "[Epoch 97/100] [Batch 274/347] [D loss: 0.352041] [G loss: 1.038974]\n",
      "[Epoch 97/100] [Batch 275/347] [D loss: 0.319749] [G loss: 1.050252]\n",
      "[Epoch 97/100] [Batch 276/347] [D loss: 0.102382] [G loss: 0.855262]\n",
      "[Epoch 97/100] [Batch 277/347] [D loss: 0.076755] [G loss: 0.907087]\n",
      "[Epoch 97/100] [Batch 278/347] [D loss: 0.066249] [G loss: 0.949252]\n",
      "[Epoch 97/100] [Batch 279/347] [D loss: 0.060418] [G loss: 0.954003]\n",
      "[Epoch 97/100] [Batch 280/347] [D loss: 0.357792] [G loss: 1.032046]\n",
      "[Epoch 97/100] [Batch 281/347] [D loss: 0.601797] [G loss: 1.051453]\n",
      "[Epoch 97/100] [Batch 282/347] [D loss: 0.602583] [G loss: 1.033477]\n",
      "[Epoch 97/100] [Batch 283/347] [D loss: 0.439183] [G loss: 1.005183]\n",
      "[Epoch 97/100] [Batch 284/347] [D loss: 0.293494] [G loss: 0.953715]\n",
      "[Epoch 97/100] [Batch 285/347] [D loss: 0.203592] [G loss: 0.821450]\n",
      "[Epoch 97/100] [Batch 286/347] [D loss: 0.149925] [G loss: 0.648506]\n",
      "[Epoch 97/100] [Batch 287/347] [D loss: 0.155612] [G loss: 0.449824]\n",
      "[Epoch 97/100] [Batch 288/347] [D loss: 0.190214] [G loss: 0.373368]\n",
      "[Epoch 97/100] [Batch 289/347] [D loss: 0.227449] [G loss: 0.311691]\n",
      "[Epoch 97/100] [Batch 290/347] [D loss: 0.309796] [G loss: 0.213548]\n",
      "[Epoch 97/100] [Batch 291/347] [D loss: 0.336381] [G loss: 0.217839]\n",
      "[Epoch 97/100] [Batch 292/347] [D loss: 0.355862] [G loss: 0.223387]\n",
      "[Epoch 97/100] [Batch 293/347] [D loss: 0.407988] [G loss: 0.249704]\n",
      "[Epoch 97/100] [Batch 294/347] [D loss: 0.363111] [G loss: 0.274178]\n",
      "[Epoch 97/100] [Batch 295/347] [D loss: 0.315333] [G loss: 0.296470]\n",
      "[Epoch 97/100] [Batch 296/347] [D loss: 0.274812] [G loss: 0.328276]\n",
      "[Epoch 97/100] [Batch 297/347] [D loss: 0.219710] [G loss: 0.409099]\n",
      "[Epoch 97/100] [Batch 298/347] [D loss: 0.174265] [G loss: 0.537542]\n",
      "[Epoch 97/100] [Batch 299/347] [D loss: 0.129663] [G loss: 0.684064]\n",
      "[Epoch 97/100] [Batch 300/347] [D loss: 0.081109] [G loss: 0.788787]\n",
      "[Epoch 97/100] [Batch 301/347] [D loss: 0.126598] [G loss: 0.880246]\n",
      "[Epoch 97/100] [Batch 302/347] [D loss: 0.179167] [G loss: 0.937650]\n",
      "[Epoch 97/100] [Batch 303/347] [D loss: 0.222212] [G loss: 0.961641]\n",
      "[Epoch 97/100] [Batch 304/347] [D loss: 0.179921] [G loss: 0.972973]\n",
      "[Epoch 97/100] [Batch 305/347] [D loss: 0.090880] [G loss: 0.965014]\n",
      "[Epoch 97/100] [Batch 306/347] [D loss: 0.086588] [G loss: 0.985847]\n",
      "[Epoch 97/100] [Batch 307/347] [D loss: 0.067817] [G loss: 1.019395]\n",
      "[Epoch 97/100] [Batch 308/347] [D loss: 0.079587] [G loss: 1.047529]\n",
      "[Epoch 97/100] [Batch 309/347] [D loss: 0.182892] [G loss: 1.064707]\n",
      "[Epoch 97/100] [Batch 310/347] [D loss: 0.285293] [G loss: 1.056249]\n",
      "[Epoch 97/100] [Batch 311/347] [D loss: 0.223350] [G loss: 0.999882]\n",
      "[Epoch 97/100] [Batch 312/347] [D loss: 0.166437] [G loss: 0.922719]\n",
      "[Epoch 97/100] [Batch 313/347] [D loss: 0.225465] [G loss: 0.891812]\n",
      "[Epoch 97/100] [Batch 314/347] [D loss: 0.242041] [G loss: 0.896596]\n",
      "[Epoch 97/100] [Batch 315/347] [D loss: 0.244942] [G loss: 0.868810]\n",
      "[Epoch 97/100] [Batch 316/347] [D loss: 0.221191] [G loss: 0.733606]\n",
      "[Epoch 97/100] [Batch 317/347] [D loss: 0.219365] [G loss: 0.594190]\n",
      "[Epoch 97/100] [Batch 318/347] [D loss: 0.211834] [G loss: 0.532171]\n",
      "[Epoch 97/100] [Batch 319/347] [D loss: 0.207356] [G loss: 0.529908]\n",
      "[Epoch 97/100] [Batch 320/347] [D loss: 0.219221] [G loss: 0.514730]\n",
      "[Epoch 97/100] [Batch 321/347] [D loss: 0.210215] [G loss: 0.501891]\n",
      "[Epoch 97/100] [Batch 322/347] [D loss: 0.233966] [G loss: 0.477230]\n",
      "[Epoch 97/100] [Batch 323/347] [D loss: 0.167189] [G loss: 0.528369]\n",
      "[Epoch 97/100] [Batch 324/347] [D loss: 0.138278] [G loss: 0.642942]\n",
      "[Epoch 97/100] [Batch 325/347] [D loss: 0.129523] [G loss: 0.713529]\n",
      "[Epoch 97/100] [Batch 326/347] [D loss: 0.118760] [G loss: 0.776118]\n",
      "[Epoch 97/100] [Batch 327/347] [D loss: 0.109351] [G loss: 0.830553]\n",
      "[Epoch 97/100] [Batch 328/347] [D loss: 0.114445] [G loss: 0.853339]\n",
      "[Epoch 97/100] [Batch 329/347] [D loss: 0.107396] [G loss: 0.884193]\n",
      "[Epoch 97/100] [Batch 330/347] [D loss: 0.094049] [G loss: 0.921209]\n",
      "[Epoch 97/100] [Batch 331/347] [D loss: 0.150335] [G loss: 0.936569]\n",
      "[Epoch 97/100] [Batch 332/347] [D loss: 0.244564] [G loss: 0.950121]\n",
      "[Epoch 97/100] [Batch 333/347] [D loss: 0.172034] [G loss: 0.952204]\n",
      "[Epoch 97/100] [Batch 334/347] [D loss: 0.144588] [G loss: 0.925840]\n",
      "[Epoch 97/100] [Batch 335/347] [D loss: 0.165404] [G loss: 0.897504]\n",
      "[Epoch 97/100] [Batch 336/347] [D loss: 0.208815] [G loss: 0.928117]\n",
      "[Epoch 97/100] [Batch 337/347] [D loss: 0.251874] [G loss: 0.918624]\n",
      "[Epoch 97/100] [Batch 338/347] [D loss: 0.313441] [G loss: 0.891068]\n",
      "[Epoch 97/100] [Batch 339/347] [D loss: 0.254700] [G loss: 0.837529]\n",
      "[Epoch 97/100] [Batch 340/347] [D loss: 0.215917] [G loss: 0.802272]\n",
      "[Epoch 97/100] [Batch 341/347] [D loss: 0.237070] [G loss: 0.764242]\n",
      "[Epoch 97/100] [Batch 342/347] [D loss: 0.099579] [G loss: 0.740947]\n",
      "[Epoch 97/100] [Batch 343/347] [D loss: 0.060039] [G loss: 0.732742]\n",
      "[Epoch 97/100] [Batch 344/347] [D loss: 0.064911] [G loss: 0.752991]\n",
      "[Epoch 97/100] [Batch 345/347] [D loss: 0.046587] [G loss: 0.810839]\n",
      "[Epoch 97/100] [Batch 346/347] [D loss: 0.062514] [G loss: 0.792426]\n",
      "[Epoch 97/100] [Batch 347/347] [D loss: 0.066377] [G loss: 0.803048]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 1/347] [D loss: 0.306701] [G loss: 0.913884]\n",
      "[Epoch 98/100] [Batch 2/347] [D loss: 0.329330] [G loss: 0.943781]\n",
      "[Epoch 98/100] [Batch 3/347] [D loss: 0.347790] [G loss: 0.953051]\n",
      "[Epoch 98/100] [Batch 4/347] [D loss: 0.360480] [G loss: 0.931811]\n",
      "[Epoch 98/100] [Batch 5/347] [D loss: 0.381804] [G loss: 0.914784]\n",
      "[Epoch 98/100] [Batch 6/347] [D loss: 0.308266] [G loss: 0.890681]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 7/347] [D loss: 0.238228] [G loss: 0.831789]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 8/347] [D loss: 0.226238] [G loss: 0.733111]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 9/347] [D loss: 0.217920] [G loss: 0.647282]\n",
      "[Epoch 98/100] [Batch 10/347] [D loss: 0.241160] [G loss: 0.553919]\n",
      "[Epoch 98/100] [Batch 11/347] [D loss: 0.304826] [G loss: 0.485353]\n",
      "[Epoch 98/100] [Batch 12/347] [D loss: 0.297679] [G loss: 0.469741]\n",
      "[Epoch 98/100] [Batch 13/347] [D loss: 0.270340] [G loss: 0.453942]\n",
      "[Epoch 98/100] [Batch 14/347] [D loss: 0.253598] [G loss: 0.444430]\n",
      "[Epoch 98/100] [Batch 15/347] [D loss: 0.251374] [G loss: 0.435071]\n",
      "[Epoch 98/100] [Batch 16/347] [D loss: 0.255102] [G loss: 0.429640]\n",
      "[Epoch 98/100] [Batch 17/347] [D loss: 0.259395] [G loss: 0.429381]\n",
      "[Epoch 98/100] [Batch 18/347] [D loss: 0.278799] [G loss: 0.418151]\n",
      "[Epoch 98/100] [Batch 19/347] [D loss: 0.288247] [G loss: 0.409276]\n",
      "[Epoch 98/100] [Batch 20/347] [D loss: 0.286811] [G loss: 0.418001]\n",
      "[Epoch 98/100] [Batch 21/347] [D loss: 0.271316] [G loss: 0.417875]\n",
      "[Epoch 98/100] [Batch 22/347] [D loss: 0.270538] [G loss: 0.433158]\n",
      "[Epoch 98/100] [Batch 23/347] [D loss: 0.261169] [G loss: 0.471759]\n",
      "[Epoch 98/100] [Batch 24/347] [D loss: 0.231666] [G loss: 0.580093]\n",
      "[Epoch 98/100] [Batch 25/347] [D loss: 0.126873] [G loss: 0.675812]\n",
      "[Epoch 98/100] [Batch 26/347] [D loss: 0.110014] [G loss: 0.781842]\n",
      "[Epoch 98/100] [Batch 27/347] [D loss: 0.094424] [G loss: 0.854551]\n",
      "[Epoch 98/100] [Batch 28/347] [D loss: 0.075313] [G loss: 0.917590]\n",
      "[Epoch 98/100] [Batch 29/347] [D loss: 0.061071] [G loss: 0.973806]\n",
      "[Epoch 98/100] [Batch 30/347] [D loss: 0.025755] [G loss: 1.024947]\n",
      "[Epoch 98/100] [Batch 31/347] [D loss: 0.021994] [G loss: 1.053479]\n",
      "[Epoch 98/100] [Batch 32/347] [D loss: 0.024973] [G loss: 1.054694]\n",
      "[Epoch 98/100] [Batch 33/347] [D loss: 0.077360] [G loss: 1.039984]\n",
      "[Epoch 98/100] [Batch 34/347] [D loss: 0.166267] [G loss: 1.037712]\n",
      "[Epoch 98/100] [Batch 35/347] [D loss: 0.175389] [G loss: 1.017567]\n",
      "[Epoch 98/100] [Batch 36/347] [D loss: 0.189815] [G loss: 1.018209]\n",
      "[Epoch 98/100] [Batch 37/347] [D loss: 0.194510] [G loss: 1.019294]\n",
      "[Epoch 98/100] [Batch 38/347] [D loss: 0.261218] [G loss: 1.002861]\n",
      "[Epoch 98/100] [Batch 39/347] [D loss: 0.238269] [G loss: 0.916299]\n",
      "[Epoch 98/100] [Batch 40/347] [D loss: 0.251873] [G loss: 0.863440]\n",
      "[Epoch 98/100] [Batch 41/347] [D loss: 0.215906] [G loss: 0.795291]\n",
      "[Epoch 98/100] [Batch 42/347] [D loss: 0.191985] [G loss: 0.704564]\n",
      "[Epoch 98/100] [Batch 43/347] [D loss: 0.234214] [G loss: 0.649951]\n",
      "[Epoch 98/100] [Batch 44/347] [D loss: 0.218134] [G loss: 0.614713]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 45/347] [D loss: 0.201388] [G loss: 0.555588]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 46/347] [D loss: 0.167149] [G loss: 0.501553]\n",
      "[Epoch 98/100] [Batch 47/347] [D loss: 0.180060] [G loss: 0.502823]\n",
      "[Epoch 98/100] [Batch 48/347] [D loss: 0.122288] [G loss: 0.593257]\n",
      "[Epoch 98/100] [Batch 49/347] [D loss: 0.105866] [G loss: 0.708016]\n",
      "[Epoch 98/100] [Batch 50/347] [D loss: 0.153989] [G loss: 0.637971]\n",
      "[Epoch 98/100] [Batch 51/347] [D loss: 0.137720] [G loss: 0.752383]\n",
      "[Epoch 98/100] [Batch 52/347] [D loss: 0.155855] [G loss: 0.820852]\n",
      "[Epoch 98/100] [Batch 53/347] [D loss: 0.159769] [G loss: 0.902218]\n",
      "[Epoch 98/100] [Batch 54/347] [D loss: 0.163179] [G loss: 0.966968]\n",
      "[Epoch 98/100] [Batch 55/347] [D loss: 0.190135] [G loss: 1.003993]\n",
      "[Epoch 98/100] [Batch 56/347] [D loss: 0.157993] [G loss: 1.115257]\n",
      "[Epoch 98/100] [Batch 57/347] [D loss: 0.141176] [G loss: 1.216396]\n",
      "[Epoch 98/100] [Batch 58/347] [D loss: 0.138036] [G loss: 1.251102]\n",
      "[Epoch 98/100] [Batch 59/347] [D loss: 0.124403] [G loss: 1.239732]\n",
      "[Epoch 98/100] [Batch 60/347] [D loss: 0.145774] [G loss: 1.191728]\n",
      "[Epoch 98/100] [Batch 61/347] [D loss: 0.184030] [G loss: 1.151706]\n",
      "[Epoch 98/100] [Batch 62/347] [D loss: 0.178489] [G loss: 1.153042]\n",
      "[Epoch 98/100] [Batch 63/347] [D loss: 0.119593] [G loss: 1.167275]\n",
      "[Epoch 98/100] [Batch 64/347] [D loss: 0.125085] [G loss: 1.167777]\n",
      "[Epoch 98/100] [Batch 65/347] [D loss: 0.124063] [G loss: 1.119977]\n",
      "[Epoch 98/100] [Batch 66/347] [D loss: 0.077813] [G loss: 1.027001]\n",
      "[Epoch 98/100] [Batch 67/347] [D loss: 0.092201] [G loss: 0.864434]\n",
      "[Epoch 98/100] [Batch 68/347] [D loss: 0.114733] [G loss: 0.777795]\n",
      "[Epoch 98/100] [Batch 69/347] [D loss: 0.057085] [G loss: 0.834408]\n",
      "[Epoch 98/100] [Batch 70/347] [D loss: 0.074572] [G loss: 0.792308]\n",
      "[Epoch 98/100] [Batch 71/347] [D loss: 0.098716] [G loss: 0.766635]\n",
      "[Epoch 98/100] [Batch 72/347] [D loss: 0.083795] [G loss: 0.858119]\n",
      "[Epoch 98/100] [Batch 73/347] [D loss: 0.145688] [G loss: 0.905591]\n",
      "[Epoch 98/100] [Batch 74/347] [D loss: 0.112570] [G loss: 1.020771]\n",
      "[Epoch 98/100] [Batch 75/347] [D loss: 0.115424] [G loss: 1.052228]\n",
      "[Epoch 98/100] [Batch 76/347] [D loss: 0.118108] [G loss: 1.070434]\n",
      "[Epoch 98/100] [Batch 77/347] [D loss: 0.177245] [G loss: 1.138070]\n",
      "[Epoch 98/100] [Batch 78/347] [D loss: 0.209790] [G loss: 1.165372]\n",
      "[Epoch 98/100] [Batch 79/347] [D loss: 0.177669] [G loss: 1.163988]\n",
      "[Epoch 98/100] [Batch 80/347] [D loss: 0.074231] [G loss: 1.135551]\n",
      "[Epoch 98/100] [Batch 81/347] [D loss: 0.080373] [G loss: 1.114816]\n",
      "[Epoch 98/100] [Batch 82/347] [D loss: 0.093871] [G loss: 1.157968]\n",
      "[Epoch 98/100] [Batch 83/347] [D loss: 0.116015] [G loss: 1.145544]\n",
      "[Epoch 98/100] [Batch 84/347] [D loss: 0.393885] [G loss: 1.112183]\n",
      "[Epoch 98/100] [Batch 85/347] [D loss: 0.520853] [G loss: 1.029094]\n",
      "[Epoch 98/100] [Batch 86/347] [D loss: 0.475870] [G loss: 0.906355]\n",
      "[Epoch 98/100] [Batch 87/347] [D loss: 0.401234] [G loss: 0.717280]\n",
      "[Epoch 98/100] [Batch 88/347] [D loss: 0.378647] [G loss: 0.599692]\n",
      "[Epoch 98/100] [Batch 89/347] [D loss: 0.391005] [G loss: 0.549642]\n",
      "[Epoch 98/100] [Batch 90/347] [D loss: 0.386906] [G loss: 0.497035]\n",
      "[Epoch 98/100] [Batch 91/347] [D loss: 0.389973] [G loss: 0.463656]\n",
      "[Epoch 98/100] [Batch 92/347] [D loss: 0.391715] [G loss: 0.436844]\n",
      "[Epoch 98/100] [Batch 93/347] [D loss: 0.391814] [G loss: 0.416897]\n",
      "[Epoch 98/100] [Batch 94/347] [D loss: 0.382611] [G loss: 0.396951]\n",
      "[Epoch 98/100] [Batch 95/347] [D loss: 0.360009] [G loss: 0.386702]\n",
      "[Epoch 98/100] [Batch 96/347] [D loss: 0.361076] [G loss: 0.383469]\n",
      "[Epoch 98/100] [Batch 97/347] [D loss: 0.350830] [G loss: 0.383045]\n",
      "[Epoch 98/100] [Batch 98/347] [D loss: 0.325493] [G loss: 0.388745]\n",
      "[Epoch 98/100] [Batch 99/347] [D loss: 0.323658] [G loss: 0.400064]\n",
      "[Epoch 98/100] [Batch 100/347] [D loss: 0.316713] [G loss: 0.416571]\n",
      "[Epoch 98/100] [Batch 101/347] [D loss: 0.314516] [G loss: 0.434850]\n",
      "[Epoch 98/100] [Batch 102/347] [D loss: 0.391459] [G loss: 0.451675]\n",
      "[Epoch 98/100] [Batch 103/347] [D loss: 0.387272] [G loss: 0.484141]\n",
      "[Epoch 98/100] [Batch 104/347] [D loss: 0.359209] [G loss: 0.506297]\n",
      "[Epoch 98/100] [Batch 105/347] [D loss: 0.295057] [G loss: 0.540137]\n",
      "[Epoch 98/100] [Batch 106/347] [D loss: 0.184404] [G loss: 0.673387]\n",
      "[Epoch 98/100] [Batch 107/347] [D loss: 0.128047] [G loss: 0.870404]\n",
      "[Epoch 98/100] [Batch 108/347] [D loss: 0.075682] [G loss: 1.014745]\n",
      "[Epoch 98/100] [Batch 109/347] [D loss: 0.038424] [G loss: 1.087351]\n",
      "[Epoch 98/100] [Batch 110/347] [D loss: 0.106187] [G loss: 1.007517]\n",
      "[Epoch 98/100] [Batch 111/347] [D loss: 0.071606] [G loss: 1.080897]\n",
      "[Epoch 98/100] [Batch 112/347] [D loss: 0.037595] [G loss: 1.119162]\n",
      "[Epoch 98/100] [Batch 113/347] [D loss: 0.074256] [G loss: 1.158452]\n",
      "[Epoch 98/100] [Batch 114/347] [D loss: 0.167222] [G loss: 1.167404]\n",
      "[Epoch 98/100] [Batch 115/347] [D loss: 0.219196] [G loss: 1.142700]\n",
      "[Epoch 98/100] [Batch 116/347] [D loss: 0.255295] [G loss: 1.111389]\n",
      "[Epoch 98/100] [Batch 117/347] [D loss: 0.576941] [G loss: 1.073846]\n",
      "[Epoch 98/100] [Batch 118/347] [D loss: 0.387950] [G loss: 1.053927]\n",
      "[Epoch 98/100] [Batch 119/347] [D loss: 0.303961] [G loss: 1.039553]\n",
      "[Epoch 98/100] [Batch 120/347] [D loss: 0.180441] [G loss: 1.059426]\n",
      "[Epoch 98/100] [Batch 121/347] [D loss: 0.113351] [G loss: 1.059090]\n",
      "[Epoch 98/100] [Batch 122/347] [D loss: 0.239358] [G loss: 1.059880]\n",
      "[Epoch 98/100] [Batch 123/347] [D loss: 0.274449] [G loss: 1.043305]\n",
      "[Epoch 98/100] [Batch 124/347] [D loss: 0.180667] [G loss: 0.991810]\n",
      "[Epoch 98/100] [Batch 125/347] [D loss: 0.141055] [G loss: 0.921269]\n",
      "[Epoch 98/100] [Batch 126/347] [D loss: 0.129430] [G loss: 0.785343]\n",
      "[Epoch 98/100] [Batch 127/347] [D loss: 0.126116] [G loss: 0.628954]\n",
      "[Epoch 98/100] [Batch 128/347] [D loss: 0.115960] [G loss: 0.528915]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 129/347] [D loss: 0.162946] [G loss: 0.466099]\n",
      "[Epoch 98/100] [Batch 130/347] [D loss: 0.209865] [G loss: 0.471529]\n",
      "[Epoch 98/100] [Batch 131/347] [D loss: 0.225177] [G loss: 0.492427]\n",
      "[Epoch 98/100] [Batch 132/347] [D loss: 0.239425] [G loss: 0.492514]\n",
      "[Epoch 98/100] [Batch 133/347] [D loss: 0.353190] [G loss: 0.488642]\n",
      "[Epoch 98/100] [Batch 134/347] [D loss: 0.650253] [G loss: 0.374830]\n",
      "[Epoch 98/100] [Batch 135/347] [D loss: 0.638475] [G loss: 0.389939]\n",
      "[Epoch 98/100] [Batch 136/347] [D loss: 0.519763] [G loss: 0.692433]\n",
      "[Epoch 98/100] [Batch 137/347] [D loss: 0.178328] [G loss: 0.847776]\n",
      "[Epoch 98/100] [Batch 138/347] [D loss: 0.067957] [G loss: 0.931072]\n",
      "[Epoch 98/100] [Batch 139/347] [D loss: 0.044767] [G loss: 1.003992]\n",
      "[Epoch 98/100] [Batch 140/347] [D loss: 0.093594] [G loss: 1.020352]\n",
      "[Epoch 98/100] [Batch 141/347] [D loss: 0.295137] [G loss: 1.032046]\n",
      "[Epoch 98/100] [Batch 142/347] [D loss: 0.393456] [G loss: 1.065712]\n",
      "[Epoch 98/100] [Batch 143/347] [D loss: 0.432945] [G loss: 1.081331]\n",
      "[Epoch 98/100] [Batch 144/347] [D loss: 0.358330] [G loss: 1.096433]\n",
      "[Epoch 98/100] [Batch 145/347] [D loss: 0.283260] [G loss: 1.133813]\n",
      "[Epoch 98/100] [Batch 146/347] [D loss: 0.242956] [G loss: 1.147093]\n",
      "[Epoch 98/100] [Batch 147/347] [D loss: 0.194879] [G loss: 1.152239]\n",
      "[Epoch 98/100] [Batch 148/347] [D loss: 0.216511] [G loss: 1.139730]\n",
      "[Epoch 98/100] [Batch 149/347] [D loss: 0.201982] [G loss: 1.079681]\n",
      "[Epoch 98/100] [Batch 150/347] [D loss: 0.190837] [G loss: 0.985798]\n",
      "[Epoch 98/100] [Batch 151/347] [D loss: 0.157030] [G loss: 0.885197]\n",
      "[Epoch 98/100] [Batch 152/347] [D loss: 0.140052] [G loss: 0.765530]\n",
      "[Epoch 98/100] [Batch 153/347] [D loss: 0.129814] [G loss: 0.547611]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 98/100] [Batch 154/347] [D loss: 0.150051] [G loss: 0.427210]\n",
      "[Epoch 98/100] [Batch 155/347] [D loss: 0.169495] [G loss: 0.379401]\n",
      "[Epoch 98/100] [Batch 156/347] [D loss: 0.193652] [G loss: 0.356883]\n",
      "[Epoch 98/100] [Batch 157/347] [D loss: 0.204438] [G loss: 0.359851]\n",
      "[Epoch 98/100] [Batch 158/347] [D loss: 0.215281] [G loss: 0.364379]\n",
      "[Epoch 98/100] [Batch 159/347] [D loss: 0.212947] [G loss: 0.371160]\n",
      "[Epoch 98/100] [Batch 160/347] [D loss: 0.208333] [G loss: 0.404281]\n",
      "[Epoch 98/100] [Batch 161/347] [D loss: 0.190863] [G loss: 0.440082]\n",
      "[Epoch 98/100] [Batch 162/347] [D loss: 0.175551] [G loss: 0.489703]\n",
      "[Epoch 98/100] [Batch 163/347] [D loss: 0.129033] [G loss: 0.684277]\n",
      "[Epoch 98/100] [Batch 164/347] [D loss: 0.069989] [G loss: 0.835977]\n",
      "[Epoch 98/100] [Batch 165/347] [D loss: 0.038405] [G loss: 0.920581]\n",
      "[Epoch 98/100] [Batch 166/347] [D loss: 0.035156] [G loss: 1.027850]\n",
      "[Epoch 98/100] [Batch 167/347] [D loss: 0.087146] [G loss: 1.084298]\n",
      "[Epoch 98/100] [Batch 168/347] [D loss: 0.142710] [G loss: 1.092780]\n",
      "[Epoch 98/100] [Batch 169/347] [D loss: 0.268736] [G loss: 1.083463]\n",
      "[Epoch 98/100] [Batch 170/347] [D loss: 0.385352] [G loss: 1.054473]\n",
      "[Epoch 98/100] [Batch 171/347] [D loss: 0.255092] [G loss: 1.045066]\n",
      "[Epoch 98/100] [Batch 172/347] [D loss: 0.284353] [G loss: 1.054442]\n",
      "[Epoch 98/100] [Batch 173/347] [D loss: 0.349782] [G loss: 1.055220]\n",
      "[Epoch 98/100] [Batch 174/347] [D loss: 0.401068] [G loss: 1.054634]\n",
      "[Epoch 98/100] [Batch 175/347] [D loss: 0.514561] [G loss: 1.019677]\n",
      "[Epoch 98/100] [Batch 176/347] [D loss: 0.368838] [G loss: 0.948463]\n",
      "[Epoch 98/100] [Batch 177/347] [D loss: 0.271630] [G loss: 0.796717]\n",
      "[Epoch 98/100] [Batch 178/347] [D loss: 0.220410] [G loss: 0.569421]\n",
      "[Epoch 98/100] [Batch 179/347] [D loss: 0.237281] [G loss: 0.413007]\n",
      "[Epoch 98/100] [Batch 180/347] [D loss: 0.262331] [G loss: 0.350599]\n",
      "[Epoch 98/100] [Batch 181/347] [D loss: 0.283385] [G loss: 0.284062]\n",
      "[Epoch 98/100] [Batch 182/347] [D loss: 0.313168] [G loss: 0.230895]\n",
      "[Epoch 98/100] [Batch 183/347] [D loss: 0.343394] [G loss: 0.201535]\n",
      "[Epoch 98/100] [Batch 184/347] [D loss: 0.393435] [G loss: 0.198687]\n",
      "[Epoch 98/100] [Batch 185/347] [D loss: 0.420175] [G loss: 0.195062]\n",
      "[Epoch 98/100] [Batch 186/347] [D loss: 0.424830] [G loss: 0.200914]\n",
      "[Epoch 98/100] [Batch 187/347] [D loss: 0.412284] [G loss: 0.209381]\n",
      "[Epoch 98/100] [Batch 188/347] [D loss: 0.388679] [G loss: 0.222026]\n",
      "[Epoch 98/100] [Batch 189/347] [D loss: 0.354278] [G loss: 0.242833]\n",
      "[Epoch 98/100] [Batch 190/347] [D loss: 0.329198] [G loss: 0.276880]\n",
      "[Epoch 98/100] [Batch 191/347] [D loss: 0.307266] [G loss: 0.308076]\n",
      "[Epoch 98/100] [Batch 192/347] [D loss: 0.295694] [G loss: 0.345397]\n",
      "[Epoch 98/100] [Batch 193/347] [D loss: 0.301930] [G loss: 0.389874]\n",
      "[Epoch 98/100] [Batch 194/347] [D loss: 0.274950] [G loss: 0.448199]\n",
      "[Epoch 98/100] [Batch 195/347] [D loss: 0.247696] [G loss: 0.549274]\n",
      "[Epoch 98/100] [Batch 196/347] [D loss: 0.206944] [G loss: 0.703396]\n",
      "[Epoch 98/100] [Batch 197/347] [D loss: 0.187912] [G loss: 0.839692]\n",
      "[Epoch 98/100] [Batch 198/347] [D loss: 0.180754] [G loss: 0.907002]\n",
      "[Epoch 98/100] [Batch 199/347] [D loss: 0.196371] [G loss: 0.958327]\n",
      "[Epoch 98/100] [Batch 200/347] [D loss: 0.266769] [G loss: 0.981567]\n",
      "[Epoch 98/100] [Batch 201/347] [D loss: 0.321899] [G loss: 0.992124]\n",
      "[Epoch 98/100] [Batch 202/347] [D loss: 0.391774] [G loss: 0.966935]\n",
      "[Epoch 98/100] [Batch 203/347] [D loss: 0.346955] [G loss: 0.927741]\n",
      "[Epoch 98/100] [Batch 204/347] [D loss: 0.293326] [G loss: 0.875859]\n",
      "[Epoch 98/100] [Batch 205/347] [D loss: 0.255691] [G loss: 0.793495]\n",
      "[Epoch 98/100] [Batch 206/347] [D loss: 0.237851] [G loss: 0.692153]\n",
      "[Epoch 98/100] [Batch 207/347] [D loss: 0.178561] [G loss: 0.615501]\n",
      "[Epoch 98/100] [Batch 208/347] [D loss: 0.191344] [G loss: 0.547548]\n",
      "[Epoch 98/100] [Batch 209/347] [D loss: 0.226129] [G loss: 0.488565]\n",
      "[Epoch 98/100] [Batch 210/347] [D loss: 0.216956] [G loss: 0.468338]\n",
      "[Epoch 98/100] [Batch 211/347] [D loss: 0.206549] [G loss: 0.447433]\n",
      "[Epoch 98/100] [Batch 212/347] [D loss: 0.210044] [G loss: 0.440344]\n",
      "[Epoch 98/100] [Batch 213/347] [D loss: 0.196511] [G loss: 0.504841]\n",
      "[Epoch 98/100] [Batch 214/347] [D loss: 0.200809] [G loss: 0.595995]\n",
      "[Epoch 98/100] [Batch 215/347] [D loss: 0.167551] [G loss: 0.721586]\n",
      "[Epoch 98/100] [Batch 216/347] [D loss: 0.212526] [G loss: 0.635093]\n",
      "[Epoch 98/100] [Batch 217/347] [D loss: 0.130748] [G loss: 0.854557]\n",
      "[Epoch 98/100] [Batch 218/347] [D loss: 0.081315] [G loss: 0.987389]\n",
      "[Epoch 98/100] [Batch 219/347] [D loss: 0.063685] [G loss: 1.053949]\n",
      "[Epoch 98/100] [Batch 220/347] [D loss: 0.149701] [G loss: 1.105393]\n",
      "[Epoch 98/100] [Batch 221/347] [D loss: 0.251201] [G loss: 1.100321]\n",
      "[Epoch 98/100] [Batch 222/347] [D loss: 0.376499] [G loss: 1.073162]\n",
      "[Epoch 98/100] [Batch 223/347] [D loss: 0.526365] [G loss: 1.036999]\n",
      "[Epoch 98/100] [Batch 224/347] [D loss: 0.668744] [G loss: 1.016658]\n",
      "[Epoch 98/100] [Batch 225/347] [D loss: 0.676062] [G loss: 1.014495]\n",
      "[Epoch 98/100] [Batch 226/347] [D loss: 0.471485] [G loss: 0.901130]\n",
      "[Epoch 98/100] [Batch 227/347] [D loss: 0.288918] [G loss: 0.515080]\n",
      "[Epoch 98/100] [Batch 228/347] [D loss: 0.310000] [G loss: 0.292169]\n",
      "[Epoch 98/100] [Batch 229/347] [D loss: 0.311480] [G loss: 0.252155]\n",
      "[Epoch 98/100] [Batch 230/347] [D loss: 0.361545] [G loss: 0.237536]\n",
      "[Epoch 98/100] [Batch 231/347] [D loss: 0.406774] [G loss: 0.210689]\n",
      "[Epoch 98/100] [Batch 232/347] [D loss: 0.452239] [G loss: 0.192312]\n",
      "[Epoch 98/100] [Batch 233/347] [D loss: 0.517178] [G loss: 0.189283]\n",
      "[Epoch 98/100] [Batch 234/347] [D loss: 0.549041] [G loss: 0.191197]\n",
      "[Epoch 98/100] [Batch 235/347] [D loss: 0.553749] [G loss: 0.217651]\n",
      "[Epoch 98/100] [Batch 236/347] [D loss: 0.524667] [G loss: 0.250621]\n",
      "[Epoch 98/100] [Batch 237/347] [D loss: 0.457373] [G loss: 0.274596]\n",
      "[Epoch 98/100] [Batch 238/347] [D loss: 0.395730] [G loss: 0.299942]\n",
      "[Epoch 98/100] [Batch 239/347] [D loss: 0.355123] [G loss: 0.326134]\n",
      "[Epoch 98/100] [Batch 240/347] [D loss: 0.326625] [G loss: 0.368129]\n",
      "[Epoch 98/100] [Batch 241/347] [D loss: 0.303599] [G loss: 0.445340]\n",
      "[Epoch 98/100] [Batch 242/347] [D loss: 0.282715] [G loss: 0.698296]\n",
      "[Epoch 98/100] [Batch 243/347] [D loss: 0.202712] [G loss: 0.824555]\n",
      "[Epoch 98/100] [Batch 244/347] [D loss: 0.170189] [G loss: 0.890197]\n",
      "[Epoch 98/100] [Batch 245/347] [D loss: 0.181516] [G loss: 0.922148]\n",
      "[Epoch 98/100] [Batch 246/347] [D loss: 0.213723] [G loss: 0.921294]\n",
      "[Epoch 98/100] [Batch 247/347] [D loss: 0.279614] [G loss: 0.947834]\n",
      "[Epoch 98/100] [Batch 248/347] [D loss: 0.271963] [G loss: 0.926736]\n",
      "[Epoch 98/100] [Batch 249/347] [D loss: 0.226680] [G loss: 0.915506]\n",
      "[Epoch 98/100] [Batch 250/347] [D loss: 0.175251] [G loss: 0.921064]\n",
      "[Epoch 98/100] [Batch 251/347] [D loss: 0.196431] [G loss: 0.912361]\n",
      "[Epoch 98/100] [Batch 252/347] [D loss: 0.190956] [G loss: 0.885163]\n",
      "[Epoch 98/100] [Batch 253/347] [D loss: 0.091221] [G loss: 0.820548]\n",
      "[Epoch 98/100] [Batch 254/347] [D loss: 0.076170] [G loss: 0.761037]\n",
      "[Epoch 98/100] [Batch 255/347] [D loss: 0.084372] [G loss: 0.761208]\n",
      "[Epoch 98/100] [Batch 256/347] [D loss: 0.089281] [G loss: 0.753993]\n",
      "[Epoch 98/100] [Batch 257/347] [D loss: 0.112369] [G loss: 0.638794]\n",
      "[Epoch 98/100] [Batch 258/347] [D loss: 0.101705] [G loss: 0.626449]\n",
      "[Epoch 98/100] [Batch 259/347] [D loss: 0.102938] [G loss: 0.673611]\n",
      "[Epoch 98/100] [Batch 260/347] [D loss: 0.086839] [G loss: 0.750397]\n",
      "[Epoch 98/100] [Batch 261/347] [D loss: 0.059792] [G loss: 0.870122]\n",
      "[Epoch 98/100] [Batch 262/347] [D loss: 0.031240] [G loss: 0.938215]\n",
      "[Epoch 98/100] [Batch 263/347] [D loss: 0.029704] [G loss: 0.988334]\n",
      "[Epoch 98/100] [Batch 264/347] [D loss: 0.026121] [G loss: 1.015052]\n",
      "[Epoch 98/100] [Batch 265/347] [D loss: 0.032772] [G loss: 1.022532]\n",
      "[Epoch 98/100] [Batch 266/347] [D loss: 0.090502] [G loss: 1.013987]\n",
      "[Epoch 98/100] [Batch 267/347] [D loss: 0.103046] [G loss: 1.015915]\n",
      "[Epoch 98/100] [Batch 268/347] [D loss: 0.128129] [G loss: 1.020095]\n",
      "[Epoch 98/100] [Batch 269/347] [D loss: 0.123590] [G loss: 1.011292]\n",
      "[Epoch 98/100] [Batch 270/347] [D loss: 0.126848] [G loss: 1.007642]\n",
      "[Epoch 98/100] [Batch 271/347] [D loss: 0.156001] [G loss: 1.004765]\n",
      "[Epoch 98/100] [Batch 272/347] [D loss: 0.412558] [G loss: 1.000831]\n",
      "[Epoch 98/100] [Batch 273/347] [D loss: 0.398276] [G loss: 1.016468]\n",
      "[Epoch 98/100] [Batch 274/347] [D loss: 0.374351] [G loss: 1.022532]\n",
      "[Epoch 98/100] [Batch 275/347] [D loss: 0.347129] [G loss: 1.025685]\n",
      "[Epoch 98/100] [Batch 276/347] [D loss: 0.068881] [G loss: 0.926432]\n",
      "[Epoch 98/100] [Batch 277/347] [D loss: 0.044637] [G loss: 0.950025]\n",
      "[Epoch 98/100] [Batch 278/347] [D loss: 0.030700] [G loss: 0.992925]\n",
      "[Epoch 98/100] [Batch 279/347] [D loss: 0.025305] [G loss: 1.006901]\n",
      "[Epoch 98/100] [Batch 280/347] [D loss: 0.292516] [G loss: 1.014848]\n",
      "[Epoch 98/100] [Batch 281/347] [D loss: 0.498885] [G loss: 1.014150]\n",
      "[Epoch 98/100] [Batch 282/347] [D loss: 0.488283] [G loss: 1.011741]\n",
      "[Epoch 98/100] [Batch 283/347] [D loss: 0.352945] [G loss: 1.007710]\n",
      "[Epoch 98/100] [Batch 284/347] [D loss: 0.268085] [G loss: 0.984895]\n",
      "[Epoch 98/100] [Batch 285/347] [D loss: 0.188259] [G loss: 0.926490]\n",
      "[Epoch 98/100] [Batch 286/347] [D loss: 0.135717] [G loss: 0.808575]\n",
      "[Epoch 98/100] [Batch 287/347] [D loss: 0.126458] [G loss: 0.628888]\n",
      "[Epoch 98/100] [Batch 288/347] [D loss: 0.140348] [G loss: 0.492304]\n",
      "[Epoch 98/100] [Batch 289/347] [D loss: 0.182644] [G loss: 0.394307]\n",
      "[Epoch 98/100] [Batch 290/347] [D loss: 0.246819] [G loss: 0.298965]\n",
      "[Epoch 98/100] [Batch 291/347] [D loss: 0.257587] [G loss: 0.305882]\n",
      "[Epoch 98/100] [Batch 292/347] [D loss: 0.267576] [G loss: 0.313170]\n",
      "[Epoch 98/100] [Batch 293/347] [D loss: 0.298310] [G loss: 0.340468]\n",
      "[Epoch 98/100] [Batch 294/347] [D loss: 0.266229] [G loss: 0.364985]\n",
      "[Epoch 98/100] [Batch 295/347] [D loss: 0.235088] [G loss: 0.383913]\n",
      "[Epoch 98/100] [Batch 296/347] [D loss: 0.212526] [G loss: 0.416131]\n",
      "[Epoch 98/100] [Batch 297/347] [D loss: 0.177341] [G loss: 0.502214]\n",
      "[Epoch 98/100] [Batch 298/347] [D loss: 0.132403] [G loss: 0.674203]\n",
      "[Epoch 98/100] [Batch 299/347] [D loss: 0.082368] [G loss: 0.797701]\n",
      "[Epoch 98/100] [Batch 300/347] [D loss: 0.049707] [G loss: 0.903726]\n",
      "[Epoch 98/100] [Batch 301/347] [D loss: 0.114630] [G loss: 0.935553]\n",
      "[Epoch 98/100] [Batch 302/347] [D loss: 0.174755] [G loss: 0.962047]\n",
      "[Epoch 98/100] [Batch 303/347] [D loss: 0.215204] [G loss: 0.997619]\n",
      "[Epoch 98/100] [Batch 304/347] [D loss: 0.175500] [G loss: 1.017721]\n",
      "[Epoch 98/100] [Batch 305/347] [D loss: 0.086939] [G loss: 1.009922]\n",
      "[Epoch 98/100] [Batch 306/347] [D loss: 0.081430] [G loss: 0.994526]\n",
      "[Epoch 98/100] [Batch 307/347] [D loss: 0.061035] [G loss: 1.011254]\n",
      "[Epoch 98/100] [Batch 308/347] [D loss: 0.061730] [G loss: 1.035305]\n",
      "[Epoch 98/100] [Batch 309/347] [D loss: 0.136924] [G loss: 1.051233]\n",
      "[Epoch 98/100] [Batch 310/347] [D loss: 0.215740] [G loss: 1.048113]\n",
      "[Epoch 98/100] [Batch 311/347] [D loss: 0.168341] [G loss: 1.005053]\n",
      "[Epoch 98/100] [Batch 312/347] [D loss: 0.120442] [G loss: 0.949872]\n",
      "[Epoch 98/100] [Batch 313/347] [D loss: 0.191542] [G loss: 0.902488]\n",
      "[Epoch 98/100] [Batch 314/347] [D loss: 0.210477] [G loss: 0.890337]\n",
      "[Epoch 98/100] [Batch 315/347] [D loss: 0.220337] [G loss: 0.872502]\n",
      "[Epoch 98/100] [Batch 316/347] [D loss: 0.191144] [G loss: 0.762008]\n",
      "[Epoch 98/100] [Batch 317/347] [D loss: 0.180013] [G loss: 0.644541]\n",
      "[Epoch 98/100] [Batch 318/347] [D loss: 0.170851] [G loss: 0.533530]\n",
      "[Epoch 98/100] [Batch 319/347] [D loss: 0.177248] [G loss: 0.508209]\n",
      "[Epoch 98/100] [Batch 320/347] [D loss: 0.194291] [G loss: 0.496002]\n",
      "[Epoch 98/100] [Batch 321/347] [D loss: 0.187202] [G loss: 0.493565]\n",
      "[Epoch 98/100] [Batch 322/347] [D loss: 0.208275] [G loss: 0.478106]\n",
      "[Epoch 98/100] [Batch 323/347] [D loss: 0.138844] [G loss: 0.568420]\n",
      "[Epoch 98/100] [Batch 324/347] [D loss: 0.112376] [G loss: 0.693759]\n",
      "[Epoch 98/100] [Batch 325/347] [D loss: 0.102302] [G loss: 0.745522]\n",
      "[Epoch 98/100] [Batch 326/347] [D loss: 0.097766] [G loss: 0.808622]\n",
      "[Epoch 98/100] [Batch 327/347] [D loss: 0.086639] [G loss: 0.856348]\n",
      "[Epoch 98/100] [Batch 328/347] [D loss: 0.090650] [G loss: 0.873051]\n",
      "[Epoch 98/100] [Batch 329/347] [D loss: 0.087177] [G loss: 0.915376]\n",
      "[Epoch 98/100] [Batch 330/347] [D loss: 0.073013] [G loss: 0.961867]\n",
      "[Epoch 98/100] [Batch 331/347] [D loss: 0.125471] [G loss: 0.987479]\n",
      "[Epoch 98/100] [Batch 332/347] [D loss: 0.215502] [G loss: 1.026161]\n",
      "[Epoch 98/100] [Batch 333/347] [D loss: 0.149778] [G loss: 1.040519]\n",
      "[Epoch 98/100] [Batch 334/347] [D loss: 0.124851] [G loss: 1.027969]\n",
      "[Epoch 98/100] [Batch 335/347] [D loss: 0.151003] [G loss: 1.009910]\n",
      "[Epoch 98/100] [Batch 336/347] [D loss: 0.212346] [G loss: 1.018641]\n",
      "[Epoch 98/100] [Batch 337/347] [D loss: 0.261710] [G loss: 1.009213]\n",
      "[Epoch 98/100] [Batch 338/347] [D loss: 0.317932] [G loss: 0.983849]\n",
      "[Epoch 98/100] [Batch 339/347] [D loss: 0.253328] [G loss: 0.934115]\n",
      "[Epoch 98/100] [Batch 340/347] [D loss: 0.204051] [G loss: 0.860055]\n",
      "[Epoch 98/100] [Batch 341/347] [D loss: 0.219995] [G loss: 0.769905]\n",
      "[Epoch 98/100] [Batch 342/347] [D loss: 0.096583] [G loss: 0.691277]\n",
      "[Epoch 98/100] [Batch 343/347] [D loss: 0.069047] [G loss: 0.628949]\n",
      "[Epoch 98/100] [Batch 344/347] [D loss: 0.095515] [G loss: 0.587224]\n",
      "[Epoch 98/100] [Batch 345/347] [D loss: 0.101737] [G loss: 0.640744]\n",
      "[Epoch 98/100] [Batch 346/347] [D loss: 0.123066] [G loss: 0.629869]\n",
      "[Epoch 98/100] [Batch 347/347] [D loss: 0.145773] [G loss: 0.657340]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 99/100] [Batch 1/347] [D loss: 0.274775] [G loss: 0.820289]\n",
      "[Epoch 99/100] [Batch 2/347] [D loss: 0.278203] [G loss: 0.886241]\n",
      "[Epoch 99/100] [Batch 3/347] [D loss: 0.287664] [G loss: 0.940753]\n",
      "[Epoch 99/100] [Batch 4/347] [D loss: 0.312277] [G loss: 0.981417]\n",
      "[Epoch 99/100] [Batch 5/347] [D loss: 0.356778] [G loss: 1.001587]\n",
      "[Epoch 99/100] [Batch 6/347] [D loss: 0.312713] [G loss: 0.999050]\n",
      "[Epoch 99/100] [Batch 7/347] [D loss: 0.252205] [G loss: 0.977327]\n",
      "[Epoch 99/100] [Batch 8/347] [D loss: 0.245687] [G loss: 0.951497]\n",
      "[Epoch 99/100] [Batch 9/347] [D loss: 0.227458] [G loss: 0.920150]\n",
      "[Epoch 99/100] [Batch 10/347] [D loss: 0.239244] [G loss: 0.850444]\n",
      "[Epoch 99/100] [Batch 11/347] [D loss: 0.285279] [G loss: 0.745990]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 99/100] [Batch 12/347] [D loss: 0.267975] [G loss: 0.667035]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 99/100] [Batch 13/347] [D loss: 0.242349] [G loss: 0.624378]\n",
      "[Epoch 99/100] [Batch 14/347] [D loss: 0.226100] [G loss: 0.628535]\n",
      "[Epoch 99/100] [Batch 15/347] [D loss: 0.224842] [G loss: 0.658320]\n",
      "[Epoch 99/100] [Batch 16/347] [D loss: 0.229208] [G loss: 0.677928]\n",
      "[Epoch 99/100] [Batch 17/347] [D loss: 0.235773] [G loss: 0.677865]\n",
      "[Epoch 99/100] [Batch 18/347] [D loss: 0.260801] [G loss: 0.676591]\n",
      "[Epoch 99/100] [Batch 19/347] [D loss: 0.272590] [G loss: 0.678311]\n",
      "[Epoch 99/100] [Batch 20/347] [D loss: 0.269625] [G loss: 0.752144]\n",
      "[Epoch 99/100] [Batch 21/347] [D loss: 0.244085] [G loss: 0.845261]\n",
      "[Epoch 99/100] [Batch 22/347] [D loss: 0.242909] [G loss: 0.927146]\n",
      "[Epoch 99/100] [Batch 23/347] [D loss: 0.252298] [G loss: 1.004607]\n",
      "[Epoch 99/100] [Batch 24/347] [D loss: 0.249486] [G loss: 1.044262]\n",
      "[Epoch 99/100] [Batch 25/347] [D loss: 0.114073] [G loss: 1.059430]\n",
      "[Epoch 99/100] [Batch 26/347] [D loss: 0.111097] [G loss: 1.066327]\n",
      "[Epoch 99/100] [Batch 27/347] [D loss: 0.103601] [G loss: 1.062084]\n",
      "[Epoch 99/100] [Batch 28/347] [D loss: 0.086708] [G loss: 1.061764]\n",
      "[Epoch 99/100] [Batch 29/347] [D loss: 0.064735] [G loss: 1.079807]\n",
      "[Epoch 99/100] [Batch 30/347] [D loss: 0.030270] [G loss: 1.097098]\n",
      "[Epoch 99/100] [Batch 31/347] [D loss: 0.031310] [G loss: 1.127421]\n",
      "[Epoch 99/100] [Batch 32/347] [D loss: 0.024057] [G loss: 1.149035]\n",
      "[Epoch 99/100] [Batch 33/347] [D loss: 0.064744] [G loss: 1.145335]\n",
      "[Epoch 99/100] [Batch 34/347] [D loss: 0.134220] [G loss: 1.146448]\n",
      "[Epoch 99/100] [Batch 35/347] [D loss: 0.139017] [G loss: 1.130004]\n",
      "[Epoch 99/100] [Batch 36/347] [D loss: 0.150542] [G loss: 1.107094]\n",
      "[Epoch 99/100] [Batch 37/347] [D loss: 0.151475] [G loss: 1.103824]\n",
      "[Epoch 99/100] [Batch 38/347] [D loss: 0.232183] [G loss: 1.039154]\n",
      "[Epoch 99/100] [Batch 39/347] [D loss: 0.228234] [G loss: 0.950553]\n",
      "[Epoch 99/100] [Batch 40/347] [D loss: 0.245433] [G loss: 0.858140]\n",
      "[Epoch 99/100] [Batch 41/347] [D loss: 0.222051] [G loss: 0.783357]\n",
      "[Epoch 99/100] [Batch 42/347] [D loss: 0.212292] [G loss: 0.732402]\n",
      "[Epoch 99/100] [Batch 43/347] [D loss: 0.254118] [G loss: 0.686025]\n",
      "[Epoch 99/100] [Batch 44/347] [D loss: 0.242314] [G loss: 0.686263]\n",
      "[Epoch 99/100] [Batch 45/347] [D loss: 0.216710] [G loss: 0.641152]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 99/100] [Batch 46/347] [D loss: 0.171932] [G loss: 0.591122]\n",
      "[Epoch 99/100] [Batch 47/347] [D loss: 0.184687] [G loss: 0.567281]\n",
      "[Epoch 99/100] [Batch 48/347] [D loss: 0.130493] [G loss: 0.595369]\n",
      "[Epoch 99/100] [Batch 49/347] [D loss: 0.126806] [G loss: 0.678066]\n",
      "[Epoch 99/100] [Batch 50/347] [D loss: 0.170699] [G loss: 0.624937]\n",
      "[Epoch 99/100] [Batch 51/347] [D loss: 0.160670] [G loss: 0.704091]\n",
      "[Epoch 99/100] [Batch 52/347] [D loss: 0.167340] [G loss: 0.763367]\n",
      "[Epoch 99/100] [Batch 53/347] [D loss: 0.156843] [G loss: 0.825635]\n",
      "[Epoch 99/100] [Batch 54/347] [D loss: 0.149847] [G loss: 0.926243]\n",
      "[Epoch 99/100] [Batch 55/347] [D loss: 0.148557] [G loss: 1.001923]\n",
      "[Epoch 99/100] [Batch 56/347] [D loss: 0.110610] [G loss: 1.137870]\n",
      "[Epoch 99/100] [Batch 57/347] [D loss: 0.097719] [G loss: 1.243273]\n",
      "[Epoch 99/100] [Batch 58/347] [D loss: 0.097835] [G loss: 1.278955]\n",
      "[Epoch 99/100] [Batch 59/347] [D loss: 0.088071] [G loss: 1.267641]\n",
      "[Epoch 99/100] [Batch 60/347] [D loss: 0.109857] [G loss: 1.222818]\n",
      "[Epoch 99/100] [Batch 61/347] [D loss: 0.151426] [G loss: 1.183332]\n",
      "[Epoch 99/100] [Batch 62/347] [D loss: 0.153049] [G loss: 1.177969]\n",
      "[Epoch 99/100] [Batch 63/347] [D loss: 0.103219] [G loss: 1.193220]\n",
      "[Epoch 99/100] [Batch 64/347] [D loss: 0.115251] [G loss: 1.215829]\n",
      "[Epoch 99/100] [Batch 65/347] [D loss: 0.118985] [G loss: 1.214676]\n",
      "[Epoch 99/100] [Batch 66/347] [D loss: 0.065959] [G loss: 1.163437]\n",
      "[Epoch 99/100] [Batch 67/347] [D loss: 0.068512] [G loss: 1.055381]\n",
      "[Epoch 99/100] [Batch 68/347] [D loss: 0.077514] [G loss: 0.968498]\n",
      "[Epoch 99/100] [Batch 69/347] [D loss: 0.021640] [G loss: 0.969558]\n",
      "[Epoch 99/100] [Batch 70/347] [D loss: 0.037394] [G loss: 0.911420]\n",
      "[Epoch 99/100] [Batch 71/347] [D loss: 0.055991] [G loss: 0.895761]\n",
      "[Epoch 99/100] [Batch 72/347] [D loss: 0.045403] [G loss: 0.970078]\n",
      "[Epoch 99/100] [Batch 73/347] [D loss: 0.100844] [G loss: 1.007847]\n",
      "[Epoch 99/100] [Batch 74/347] [D loss: 0.074970] [G loss: 1.076049]\n",
      "[Epoch 99/100] [Batch 75/347] [D loss: 0.079587] [G loss: 1.088972]\n",
      "[Epoch 99/100] [Batch 76/347] [D loss: 0.080346] [G loss: 1.085321]\n",
      "[Epoch 99/100] [Batch 77/347] [D loss: 0.132284] [G loss: 1.114138]\n",
      "[Epoch 99/100] [Batch 78/347] [D loss: 0.153729] [G loss: 1.115319]\n",
      "[Epoch 99/100] [Batch 79/347] [D loss: 0.121496] [G loss: 1.079159]\n",
      "[Epoch 99/100] [Batch 80/347] [D loss: 0.044304] [G loss: 1.036558]\n",
      "[Epoch 99/100] [Batch 81/347] [D loss: 0.046146] [G loss: 1.025669]\n",
      "[Epoch 99/100] [Batch 82/347] [D loss: 0.050084] [G loss: 1.083014]\n",
      "[Epoch 99/100] [Batch 83/347] [D loss: 0.070383] [G loss: 1.070477]\n",
      "[Epoch 99/100] [Batch 84/347] [D loss: 0.265333] [G loss: 1.039006]\n",
      "[Epoch 99/100] [Batch 85/347] [D loss: 0.357349] [G loss: 0.941845]\n",
      "[Epoch 99/100] [Batch 86/347] [D loss: 0.332677] [G loss: 0.799277]\n",
      "[Epoch 99/100] [Batch 87/347] [D loss: 0.311442] [G loss: 0.634360]\n",
      "[Epoch 99/100] [Batch 88/347] [D loss: 0.309778] [G loss: 0.520628]\n",
      "[Epoch 99/100] [Batch 89/347] [D loss: 0.330836] [G loss: 0.458833]\n",
      "[Epoch 99/100] [Batch 90/347] [D loss: 0.336431] [G loss: 0.410820]\n",
      "[Epoch 99/100] [Batch 91/347] [D loss: 0.340440] [G loss: 0.379099]\n",
      "[Epoch 99/100] [Batch 92/347] [D loss: 0.345464] [G loss: 0.355020]\n",
      "[Epoch 99/100] [Batch 93/347] [D loss: 0.348134] [G loss: 0.338378]\n",
      "[Epoch 99/100] [Batch 94/347] [D loss: 0.340908] [G loss: 0.321783]\n",
      "[Epoch 99/100] [Batch 95/347] [D loss: 0.320876] [G loss: 0.315508]\n",
      "[Epoch 99/100] [Batch 96/347] [D loss: 0.320497] [G loss: 0.316977]\n",
      "[Epoch 99/100] [Batch 97/347] [D loss: 0.309303] [G loss: 0.320727]\n",
      "[Epoch 99/100] [Batch 98/347] [D loss: 0.283847] [G loss: 0.330584]\n",
      "[Epoch 99/100] [Batch 99/347] [D loss: 0.279857] [G loss: 0.346638]\n",
      "[Epoch 99/100] [Batch 100/347] [D loss: 0.271690] [G loss: 0.367901]\n",
      "[Epoch 99/100] [Batch 101/347] [D loss: 0.269412] [G loss: 0.397545]\n",
      "[Epoch 99/100] [Batch 102/347] [D loss: 0.342009] [G loss: 0.428568]\n",
      "[Epoch 99/100] [Batch 103/347] [D loss: 0.335990] [G loss: 0.509858]\n",
      "[Epoch 99/100] [Batch 104/347] [D loss: 0.304688] [G loss: 0.566207]\n",
      "[Epoch 99/100] [Batch 105/347] [D loss: 0.241672] [G loss: 0.645297]\n",
      "[Epoch 99/100] [Batch 106/347] [D loss: 0.130849] [G loss: 0.797530]\n",
      "[Epoch 99/100] [Batch 107/347] [D loss: 0.078514] [G loss: 0.932399]\n",
      "[Epoch 99/100] [Batch 108/347] [D loss: 0.047984] [G loss: 0.997250]\n",
      "[Epoch 99/100] [Batch 109/347] [D loss: 0.032830] [G loss: 1.039835]\n",
      "[Epoch 99/100] [Batch 110/347] [D loss: 0.093199] [G loss: 0.999752]\n",
      "[Epoch 99/100] [Batch 111/347] [D loss: 0.075346] [G loss: 1.040772]\n",
      "[Epoch 99/100] [Batch 112/347] [D loss: 0.046342] [G loss: 1.053805]\n",
      "[Epoch 99/100] [Batch 113/347] [D loss: 0.041286] [G loss: 1.080593]\n",
      "[Epoch 99/100] [Batch 114/347] [D loss: 0.081591] [G loss: 1.082817]\n",
      "[Epoch 99/100] [Batch 115/347] [D loss: 0.117100] [G loss: 1.087492]\n",
      "[Epoch 99/100] [Batch 116/347] [D loss: 0.145062] [G loss: 1.102992]\n",
      "[Epoch 99/100] [Batch 117/347] [D loss: 0.411613] [G loss: 1.116595]\n",
      "[Epoch 99/100] [Batch 118/347] [D loss: 0.266139] [G loss: 1.134659]\n",
      "[Epoch 99/100] [Batch 119/347] [D loss: 0.212683] [G loss: 1.122859]\n",
      "[Epoch 99/100] [Batch 120/347] [D loss: 0.119845] [G loss: 1.108673]\n",
      "[Epoch 99/100] [Batch 121/347] [D loss: 0.072258] [G loss: 1.090131]\n",
      "[Epoch 99/100] [Batch 122/347] [D loss: 0.187039] [G loss: 1.069159]\n",
      "[Epoch 99/100] [Batch 123/347] [D loss: 0.235770] [G loss: 1.046665]\n",
      "[Epoch 99/100] [Batch 124/347] [D loss: 0.166756] [G loss: 1.031261]\n",
      "[Epoch 99/100] [Batch 125/347] [D loss: 0.136960] [G loss: 1.011047]\n",
      "[Epoch 99/100] [Batch 126/347] [D loss: 0.133533] [G loss: 0.959477]\n",
      "[Epoch 99/100] [Batch 127/347] [D loss: 0.126190] [G loss: 0.852790]\n",
      "[Epoch 99/100] [Batch 128/347] [D loss: 0.072747] [G loss: 0.707527]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 99/100] [Batch 129/347] [D loss: 0.096662] [G loss: 0.583203]\n",
      "[Epoch 99/100] [Batch 130/347] [D loss: 0.134482] [G loss: 0.581089]\n",
      "[Epoch 99/100] [Batch 131/347] [D loss: 0.157693] [G loss: 0.609160]\n",
      "[Epoch 99/100] [Batch 132/347] [D loss: 0.175112] [G loss: 0.616464]\n",
      "[Epoch 99/100] [Batch 133/347] [D loss: 0.274521] [G loss: 0.676380]\n",
      "[Epoch 99/100] [Batch 134/347] [D loss: 0.547168] [G loss: 0.648490]\n",
      "[Epoch 99/100] [Batch 135/347] [D loss: 0.496297] [G loss: 0.744579]\n",
      "[Epoch 99/100] [Batch 136/347] [D loss: 0.369040] [G loss: 0.991508]\n",
      "[Epoch 99/100] [Batch 137/347] [D loss: 0.084512] [G loss: 1.092852]\n",
      "[Epoch 99/100] [Batch 138/347] [D loss: 0.029740] [G loss: 1.107133]\n",
      "[Epoch 99/100] [Batch 139/347] [D loss: 0.037493] [G loss: 1.115066]\n",
      "[Epoch 99/100] [Batch 140/347] [D loss: 0.110675] [G loss: 1.116291]\n",
      "[Epoch 99/100] [Batch 141/347] [D loss: 0.420424] [G loss: 1.106742]\n",
      "[Epoch 99/100] [Batch 142/347] [D loss: 0.555075] [G loss: 1.131592]\n",
      "[Epoch 99/100] [Batch 143/347] [D loss: 0.583851] [G loss: 1.144032]\n",
      "[Epoch 99/100] [Batch 144/347] [D loss: 0.412432] [G loss: 1.156816]\n",
      "[Epoch 99/100] [Batch 145/347] [D loss: 0.290542] [G loss: 1.192444]\n",
      "[Epoch 99/100] [Batch 146/347] [D loss: 0.231544] [G loss: 1.203825]\n",
      "[Epoch 99/100] [Batch 147/347] [D loss: 0.175903] [G loss: 1.208152]\n",
      "[Epoch 99/100] [Batch 148/347] [D loss: 0.193189] [G loss: 1.194407]\n",
      "[Epoch 99/100] [Batch 149/347] [D loss: 0.175526] [G loss: 1.130748]\n",
      "[Epoch 99/100] [Batch 150/347] [D loss: 0.162929] [G loss: 1.032764]\n",
      "[Epoch 99/100] [Batch 151/347] [D loss: 0.133346] [G loss: 0.914321]\n",
      "[Epoch 99/100] [Batch 152/347] [D loss: 0.122688] [G loss: 0.766104]\n",
      "[Epoch 99/100] [Batch 153/347] [D loss: 0.125432] [G loss: 0.604847]\n",
      "[Epoch 99/100] [Batch 154/347] [D loss: 0.138943] [G loss: 0.503267]\n",
      "[Epoch 99/100] [Batch 155/347] [D loss: 0.154218] [G loss: 0.461131]\n",
      "[Epoch 99/100] [Batch 156/347] [D loss: 0.172514] [G loss: 0.439114]\n",
      "[Epoch 99/100] [Batch 157/347] [D loss: 0.173732] [G loss: 0.458617]\n",
      "[Epoch 99/100] [Batch 158/347] [D loss: 0.173126] [G loss: 0.478813]\n",
      "[Epoch 99/100] [Batch 159/347] [D loss: 0.165581] [G loss: 0.511623]\n",
      "[Epoch 99/100] [Batch 160/347] [D loss: 0.155865] [G loss: 0.569694]\n",
      "[Epoch 99/100] [Batch 161/347] [D loss: 0.134249] [G loss: 0.687442]\n",
      "[Epoch 99/100] [Batch 162/347] [D loss: 0.108149] [G loss: 0.777459]\n",
      "[Epoch 99/100] [Batch 163/347] [D loss: 0.055469] [G loss: 0.905495]\n",
      "[Epoch 99/100] [Batch 164/347] [D loss: 0.029136] [G loss: 0.974367]\n",
      "[Epoch 99/100] [Batch 165/347] [D loss: 0.021410] [G loss: 1.018659]\n",
      "[Epoch 99/100] [Batch 166/347] [D loss: 0.027329] [G loss: 1.096233]\n",
      "[Epoch 99/100] [Batch 167/347] [D loss: 0.078109] [G loss: 1.141205]\n",
      "[Epoch 99/100] [Batch 168/347] [D loss: 0.130161] [G loss: 1.145030]\n",
      "[Epoch 99/100] [Batch 169/347] [D loss: 0.220370] [G loss: 1.133587]\n",
      "[Epoch 99/100] [Batch 170/347] [D loss: 0.290233] [G loss: 1.102709]\n",
      "[Epoch 99/100] [Batch 171/347] [D loss: 0.187515] [G loss: 1.060736]\n",
      "[Epoch 99/100] [Batch 172/347] [D loss: 0.201277] [G loss: 1.032196]\n",
      "[Epoch 99/100] [Batch 173/347] [D loss: 0.250014] [G loss: 1.020812]\n",
      "[Epoch 99/100] [Batch 174/347] [D loss: 0.279936] [G loss: 1.025270]\n",
      "[Epoch 99/100] [Batch 175/347] [D loss: 0.365696] [G loss: 0.998412]\n",
      "[Epoch 99/100] [Batch 176/347] [D loss: 0.301767] [G loss: 0.915904]\n",
      "[Epoch 99/100] [Batch 177/347] [D loss: 0.234521] [G loss: 0.771590]\n",
      "[Epoch 99/100] [Batch 178/347] [D loss: 0.204154] [G loss: 0.587068]\n",
      "[Epoch 99/100] [Batch 179/347] [D loss: 0.222213] [G loss: 0.434372]\n",
      "[Epoch 99/100] [Batch 180/347] [D loss: 0.243930] [G loss: 0.383736]\n",
      "[Epoch 99/100] [Batch 181/347] [D loss: 0.261580] [G loss: 0.322205]\n",
      "[Epoch 99/100] [Batch 182/347] [D loss: 0.283113] [G loss: 0.277468]\n",
      "[Epoch 99/100] [Batch 183/347] [D loss: 0.298863] [G loss: 0.266589]\n",
      "[Epoch 99/100] [Batch 184/347] [D loss: 0.341096] [G loss: 0.262661]\n",
      "[Epoch 99/100] [Batch 185/347] [D loss: 0.365083] [G loss: 0.258444]\n",
      "[Epoch 99/100] [Batch 186/347] [D loss: 0.366966] [G loss: 0.264339]\n",
      "[Epoch 99/100] [Batch 187/347] [D loss: 0.350834] [G loss: 0.271731]\n",
      "[Epoch 99/100] [Batch 188/347] [D loss: 0.333242] [G loss: 0.286371]\n",
      "[Epoch 99/100] [Batch 189/347] [D loss: 0.296525] [G loss: 0.303468]\n",
      "[Epoch 99/100] [Batch 190/347] [D loss: 0.277583] [G loss: 0.329484]\n",
      "[Epoch 99/100] [Batch 191/347] [D loss: 0.268275] [G loss: 0.366096]\n",
      "[Epoch 99/100] [Batch 192/347] [D loss: 0.262014] [G loss: 0.401237]\n",
      "[Epoch 99/100] [Batch 193/347] [D loss: 0.273887] [G loss: 0.439068]\n",
      "[Epoch 99/100] [Batch 194/347] [D loss: 0.249290] [G loss: 0.501838]\n",
      "[Epoch 99/100] [Batch 195/347] [D loss: 0.222789] [G loss: 0.630360]\n",
      "[Epoch 99/100] [Batch 196/347] [D loss: 0.177648] [G loss: 0.745086]\n",
      "[Epoch 99/100] [Batch 197/347] [D loss: 0.167783] [G loss: 0.856821]\n",
      "[Epoch 99/100] [Batch 198/347] [D loss: 0.160999] [G loss: 0.928229]\n",
      "[Epoch 99/100] [Batch 199/347] [D loss: 0.175437] [G loss: 0.992200]\n",
      "[Epoch 99/100] [Batch 200/347] [D loss: 0.239465] [G loss: 1.018210]\n",
      "[Epoch 99/100] [Batch 201/347] [D loss: 0.294985] [G loss: 1.027355]\n",
      "[Epoch 99/100] [Batch 202/347] [D loss: 0.357616] [G loss: 1.011973]\n",
      "[Epoch 99/100] [Batch 203/347] [D loss: 0.325125] [G loss: 0.981488]\n",
      "[Epoch 99/100] [Batch 204/347] [D loss: 0.277638] [G loss: 0.923758]\n",
      "[Epoch 99/100] [Batch 205/347] [D loss: 0.237987] [G loss: 0.854410]\n",
      "[Epoch 99/100] [Batch 206/347] [D loss: 0.217769] [G loss: 0.771522]\n",
      "[Epoch 99/100] [Batch 207/347] [D loss: 0.155513] [G loss: 0.689816]\n",
      "[Epoch 99/100] [Batch 208/347] [D loss: 0.166989] [G loss: 0.626629]\n",
      "[Epoch 99/100] [Batch 209/347] [D loss: 0.198674] [G loss: 0.568250]\n",
      "[Epoch 99/100] [Batch 210/347] [D loss: 0.190815] [G loss: 0.554617]\n",
      "[Epoch 99/100] [Batch 211/347] [D loss: 0.180357] [G loss: 0.542666]\n",
      "[Epoch 99/100] [Batch 212/347] [D loss: 0.187210] [G loss: 0.559846]\n",
      "[Epoch 99/100] [Batch 213/347] [D loss: 0.167659] [G loss: 0.644463]\n",
      "[Epoch 99/100] [Batch 214/347] [D loss: 0.171764] [G loss: 0.765159]\n",
      "[Epoch 99/100] [Batch 215/347] [D loss: 0.139829] [G loss: 0.862342]\n",
      "[Epoch 99/100] [Batch 216/347] [D loss: 0.159918] [G loss: 0.818011]\n",
      "[Epoch 99/100] [Batch 217/347] [D loss: 0.089535] [G loss: 0.985505]\n",
      "[Epoch 99/100] [Batch 218/347] [D loss: 0.049427] [G loss: 1.069326]\n",
      "[Epoch 99/100] [Batch 219/347] [D loss: 0.042156] [G loss: 1.105608]\n",
      "[Epoch 99/100] [Batch 220/347] [D loss: 0.127224] [G loss: 1.129832]\n",
      "[Epoch 99/100] [Batch 221/347] [D loss: 0.221015] [G loss: 1.118254]\n",
      "[Epoch 99/100] [Batch 222/347] [D loss: 0.325225] [G loss: 1.088956]\n",
      "[Epoch 99/100] [Batch 223/347] [D loss: 0.455032] [G loss: 1.052792]\n",
      "[Epoch 99/100] [Batch 224/347] [D loss: 0.595560] [G loss: 1.035759]\n",
      "[Epoch 99/100] [Batch 225/347] [D loss: 0.668795] [G loss: 1.042001]\n",
      "[Epoch 99/100] [Batch 226/347] [D loss: 0.461393] [G loss: 0.987345]\n",
      "[Epoch 99/100] [Batch 227/347] [D loss: 0.281344] [G loss: 0.702242]\n",
      "[Epoch 99/100] [Batch 228/347] [D loss: 0.275760] [G loss: 0.348312]\n",
      "[Epoch 99/100] [Batch 229/347] [D loss: 0.272705] [G loss: 0.300560]\n",
      "[Epoch 99/100] [Batch 230/347] [D loss: 0.306900] [G loss: 0.281226]\n",
      "[Epoch 99/100] [Batch 231/347] [D loss: 0.340173] [G loss: 0.251703]\n",
      "[Epoch 99/100] [Batch 232/347] [D loss: 0.375316] [G loss: 0.232373]\n",
      "[Epoch 99/100] [Batch 233/347] [D loss: 0.424157] [G loss: 0.227357]\n",
      "[Epoch 99/100] [Batch 234/347] [D loss: 0.453079] [G loss: 0.229241]\n",
      "[Epoch 99/100] [Batch 235/347] [D loss: 0.460513] [G loss: 0.257855]\n",
      "[Epoch 99/100] [Batch 236/347] [D loss: 0.435502] [G loss: 0.292952]\n",
      "[Epoch 99/100] [Batch 237/347] [D loss: 0.381754] [G loss: 0.319121]\n",
      "[Epoch 99/100] [Batch 238/347] [D loss: 0.332632] [G loss: 0.350911]\n",
      "[Epoch 99/100] [Batch 239/347] [D loss: 0.301321] [G loss: 0.374708]\n",
      "[Epoch 99/100] [Batch 240/347] [D loss: 0.285861] [G loss: 0.438455]\n",
      "[Epoch 99/100] [Batch 241/347] [D loss: 0.269506] [G loss: 0.603348]\n",
      "[Epoch 99/100] [Batch 242/347] [D loss: 0.246675] [G loss: 0.830041]\n",
      "[Epoch 99/100] [Batch 243/347] [D loss: 0.177822] [G loss: 0.905966]\n",
      "[Epoch 99/100] [Batch 244/347] [D loss: 0.153063] [G loss: 0.947993]\n",
      "[Epoch 99/100] [Batch 245/347] [D loss: 0.167295] [G loss: 0.957825]\n",
      "[Epoch 99/100] [Batch 246/347] [D loss: 0.197273] [G loss: 0.955972]\n",
      "[Epoch 99/100] [Batch 247/347] [D loss: 0.255399] [G loss: 0.987310]\n",
      "[Epoch 99/100] [Batch 248/347] [D loss: 0.238598] [G loss: 0.959186]\n",
      "[Epoch 99/100] [Batch 249/347] [D loss: 0.190597] [G loss: 0.924037]\n",
      "[Epoch 99/100] [Batch 250/347] [D loss: 0.139985] [G loss: 0.915289]\n",
      "[Epoch 99/100] [Batch 251/347] [D loss: 0.162194] [G loss: 0.913202]\n",
      "[Epoch 99/100] [Batch 252/347] [D loss: 0.155097] [G loss: 0.870999]\n",
      "[Epoch 99/100] [Batch 253/347] [D loss: 0.073742] [G loss: 0.792874]\n",
      "[Epoch 99/100] [Batch 254/347] [D loss: 0.067953] [G loss: 0.756825]\n",
      "[Epoch 99/100] [Batch 255/347] [D loss: 0.071100] [G loss: 0.784646]\n",
      "[Epoch 99/100] [Batch 256/347] [D loss: 0.069269] [G loss: 0.824726]\n",
      "[Epoch 99/100] [Batch 257/347] [D loss: 0.080205] [G loss: 0.767327]\n",
      "[Epoch 99/100] [Batch 258/347] [D loss: 0.069293] [G loss: 0.763632]\n",
      "[Epoch 99/100] [Batch 259/347] [D loss: 0.067487] [G loss: 0.816058]\n",
      "[Epoch 99/100] [Batch 260/347] [D loss: 0.050957] [G loss: 0.853860]\n",
      "[Epoch 99/100] [Batch 261/347] [D loss: 0.035994] [G loss: 0.939549]\n",
      "[Epoch 99/100] [Batch 262/347] [D loss: 0.019501] [G loss: 1.001930]\n",
      "[Epoch 99/100] [Batch 263/347] [D loss: 0.017926] [G loss: 1.036918]\n",
      "[Epoch 99/100] [Batch 264/347] [D loss: 0.016135] [G loss: 1.053474]\n",
      "[Epoch 99/100] [Batch 265/347] [D loss: 0.023199] [G loss: 1.056622]\n",
      "[Epoch 99/100] [Batch 266/347] [D loss: 0.073058] [G loss: 1.051932]\n",
      "[Epoch 99/100] [Batch 267/347] [D loss: 0.082374] [G loss: 1.057154]\n",
      "[Epoch 99/100] [Batch 268/347] [D loss: 0.107986] [G loss: 1.055730]\n",
      "[Epoch 99/100] [Batch 269/347] [D loss: 0.102676] [G loss: 1.052549]\n",
      "[Epoch 99/100] [Batch 270/347] [D loss: 0.104969] [G loss: 1.044634]\n",
      "[Epoch 99/100] [Batch 271/347] [D loss: 0.158595] [G loss: 1.045070]\n",
      "[Epoch 99/100] [Batch 272/347] [D loss: 0.507803] [G loss: 1.043736]\n",
      "[Epoch 99/100] [Batch 273/347] [D loss: 0.488146] [G loss: 1.054354]\n",
      "[Epoch 99/100] [Batch 274/347] [D loss: 0.454425] [G loss: 1.053752]\n",
      "[Epoch 99/100] [Batch 275/347] [D loss: 0.417690] [G loss: 1.052255]\n",
      "[Epoch 99/100] [Batch 276/347] [D loss: 0.056367] [G loss: 1.004740]\n",
      "[Epoch 99/100] [Batch 277/347] [D loss: 0.023799] [G loss: 1.043134]\n",
      "[Epoch 99/100] [Batch 278/347] [D loss: 0.016130] [G loss: 1.049561]\n",
      "[Epoch 99/100] [Batch 279/347] [D loss: 0.010949] [G loss: 1.057191]\n",
      "[Epoch 99/100] [Batch 280/347] [D loss: 0.299701] [G loss: 1.035382]\n",
      "[Epoch 99/100] [Batch 281/347] [D loss: 0.578890] [G loss: 1.031904]\n",
      "[Epoch 99/100] [Batch 282/347] [D loss: 0.658980] [G loss: 1.034770]\n",
      "[Epoch 99/100] [Batch 283/347] [D loss: 0.484966] [G loss: 1.034913]\n",
      "[Epoch 99/100] [Batch 284/347] [D loss: 0.319068] [G loss: 1.027275]\n",
      "[Epoch 99/100] [Batch 285/347] [D loss: 0.212566] [G loss: 1.001541]\n",
      "[Epoch 99/100] [Batch 286/347] [D loss: 0.141413] [G loss: 0.940710]\n",
      "[Epoch 99/100] [Batch 287/347] [D loss: 0.106717] [G loss: 0.795881]\n",
      "[Epoch 99/100] [Batch 288/347] [D loss: 0.099125] [G loss: 0.604615]\n",
      "[Epoch 99/100] [Batch 289/347] [D loss: 0.142636] [G loss: 0.454939]\n",
      "[Epoch 99/100] [Batch 290/347] [D loss: 0.221875] [G loss: 0.314287]\n",
      "[Epoch 99/100] [Batch 291/347] [D loss: 0.239093] [G loss: 0.315389]\n",
      "[Epoch 99/100] [Batch 292/347] [D loss: 0.255962] [G loss: 0.319335]\n",
      "[Epoch 99/100] [Batch 293/347] [D loss: 0.301164] [G loss: 0.344259]\n",
      "[Epoch 99/100] [Batch 294/347] [D loss: 0.271398] [G loss: 0.367838]\n",
      "[Epoch 99/100] [Batch 295/347] [D loss: 0.239360] [G loss: 0.389923]\n",
      "[Epoch 99/100] [Batch 296/347] [D loss: 0.215782] [G loss: 0.422879]\n",
      "[Epoch 99/100] [Batch 297/347] [D loss: 0.168964] [G loss: 0.544244]\n",
      "[Epoch 99/100] [Batch 298/347] [D loss: 0.110345] [G loss: 0.734759]\n",
      "[Epoch 99/100] [Batch 299/347] [D loss: 0.059962] [G loss: 0.859033]\n",
      "[Epoch 99/100] [Batch 300/347] [D loss: 0.033262] [G loss: 0.951956]\n",
      "[Epoch 99/100] [Batch 301/347] [D loss: 0.100025] [G loss: 0.967901]\n",
      "[Epoch 99/100] [Batch 302/347] [D loss: 0.168358] [G loss: 0.987967]\n",
      "[Epoch 99/100] [Batch 303/347] [D loss: 0.212895] [G loss: 0.999867]\n",
      "[Epoch 99/100] [Batch 304/347] [D loss: 0.175553] [G loss: 1.019343]\n",
      "[Epoch 99/100] [Batch 305/347] [D loss: 0.088703] [G loss: 1.011264]\n",
      "[Epoch 99/100] [Batch 306/347] [D loss: 0.082316] [G loss: 1.005587]\n",
      "[Epoch 99/100] [Batch 307/347] [D loss: 0.062298] [G loss: 1.030789]\n",
      "[Epoch 99/100] [Batch 308/347] [D loss: 0.056135] [G loss: 1.053880]\n",
      "[Epoch 99/100] [Batch 309/347] [D loss: 0.120734] [G loss: 1.073543]\n",
      "[Epoch 99/100] [Batch 310/347] [D loss: 0.195028] [G loss: 1.076109]\n",
      "[Epoch 99/100] [Batch 311/347] [D loss: 0.145176] [G loss: 1.043964]\n",
      "[Epoch 99/100] [Batch 312/347] [D loss: 0.100500] [G loss: 1.003795]\n",
      "[Epoch 99/100] [Batch 313/347] [D loss: 0.185011] [G loss: 0.957188]\n",
      "[Epoch 99/100] [Batch 314/347] [D loss: 0.210836] [G loss: 0.933197]\n",
      "[Epoch 99/100] [Batch 315/347] [D loss: 0.219223] [G loss: 0.920118]\n",
      "[Epoch 99/100] [Batch 316/347] [D loss: 0.181351] [G loss: 0.840158]\n",
      "[Epoch 99/100] [Batch 317/347] [D loss: 0.152807] [G loss: 0.733566]\n",
      "[Epoch 99/100] [Batch 318/347] [D loss: 0.133870] [G loss: 0.597321]\n",
      "[Epoch 99/100] [Batch 319/347] [D loss: 0.144586] [G loss: 0.532995]\n",
      "[Epoch 99/100] [Batch 320/347] [D loss: 0.168882] [G loss: 0.495720]\n",
      "[Epoch 99/100] [Batch 321/347] [D loss: 0.170113] [G loss: 0.477246]\n",
      "[Epoch 99/100] [Batch 322/347] [D loss: 0.189977] [G loss: 0.472806]\n",
      "[Epoch 99/100] [Batch 323/347] [D loss: 0.124615] [G loss: 0.590434]\n",
      "[Epoch 99/100] [Batch 324/347] [D loss: 0.094134] [G loss: 0.715293]\n",
      "[Epoch 99/100] [Batch 325/347] [D loss: 0.083792] [G loss: 0.778661]\n",
      "[Epoch 99/100] [Batch 326/347] [D loss: 0.074475] [G loss: 0.835969]\n",
      "[Epoch 99/100] [Batch 327/347] [D loss: 0.066096] [G loss: 0.868223]\n",
      "[Epoch 99/100] [Batch 328/347] [D loss: 0.070505] [G loss: 0.879299]\n",
      "[Epoch 99/100] [Batch 329/347] [D loss: 0.070494] [G loss: 0.916017]\n",
      "[Epoch 99/100] [Batch 330/347] [D loss: 0.056822] [G loss: 0.958999]\n",
      "[Epoch 99/100] [Batch 331/347] [D loss: 0.100880] [G loss: 0.987431]\n",
      "[Epoch 99/100] [Batch 332/347] [D loss: 0.183311] [G loss: 1.014418]\n",
      "[Epoch 99/100] [Batch 333/347] [D loss: 0.120588] [G loss: 1.019801]\n",
      "[Epoch 99/100] [Batch 334/347] [D loss: 0.095260] [G loss: 1.008333]\n",
      "[Epoch 99/100] [Batch 335/347] [D loss: 0.117821] [G loss: 0.995457]\n",
      "[Epoch 99/100] [Batch 336/347] [D loss: 0.176251] [G loss: 1.008685]\n",
      "[Epoch 99/100] [Batch 337/347] [D loss: 0.222719] [G loss: 1.006328]\n",
      "[Epoch 99/100] [Batch 338/347] [D loss: 0.282039] [G loss: 0.983661]\n",
      "[Epoch 99/100] [Batch 339/347] [D loss: 0.225166] [G loss: 0.937794]\n",
      "[Epoch 99/100] [Batch 340/347] [D loss: 0.186382] [G loss: 0.906099]\n",
      "[Epoch 99/100] [Batch 341/347] [D loss: 0.204846] [G loss: 0.859971]\n",
      "[Epoch 99/100] [Batch 342/347] [D loss: 0.076650] [G loss: 0.778479]\n",
      "[Epoch 99/100] [Batch 343/347] [D loss: 0.047526] [G loss: 0.730509]\n",
      "[Epoch 99/100] [Batch 344/347] [D loss: 0.066150] [G loss: 0.702582]\n",
      "[Epoch 99/100] [Batch 345/347] [D loss: 0.071799] [G loss: 0.734607]\n",
      "[Epoch 99/100] [Batch 346/347] [D loss: 0.099618] [G loss: 0.712028]\n",
      "[Epoch 99/100] [Batch 347/347] [D loss: 0.125311] [G loss: 0.718985]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 100/100] [Batch 1/347] [D loss: 0.247097] [G loss: 0.846990]\n",
      "[Epoch 100/100] [Batch 2/347] [D loss: 0.250337] [G loss: 0.895724]\n",
      "[Epoch 100/100] [Batch 3/347] [D loss: 0.255063] [G loss: 0.941417]\n",
      "[Epoch 100/100] [Batch 4/347] [D loss: 0.275806] [G loss: 0.947343]\n",
      "[Epoch 100/100] [Batch 5/347] [D loss: 0.304469] [G loss: 0.958901]\n",
      "[Epoch 100/100] [Batch 6/347] [D loss: 0.265672] [G loss: 0.957262]\n",
      "[Epoch 100/100] [Batch 7/347] [D loss: 0.209331] [G loss: 0.926743]\n",
      "[Epoch 100/100] [Batch 8/347] [D loss: 0.205733] [G loss: 0.895989]\n",
      "[Epoch 100/100] [Batch 9/347] [D loss: 0.186438] [G loss: 0.854631]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 100/100] [Batch 10/347] [D loss: 0.200154] [G loss: 0.765045]\n",
      "[Epoch 100/100] [Batch 11/347] [D loss: 0.252971] [G loss: 0.682066]\n",
      "[Epoch 100/100] [Batch 12/347] [D loss: 0.242602] [G loss: 0.657565]\n",
      "[Epoch 100/100] [Batch 13/347] [D loss: 0.215210] [G loss: 0.632541]\n",
      "[Epoch 100/100] [Batch 14/347] [D loss: 0.200295] [G loss: 0.641856]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 100/100] [Batch 15/347] [D loss: 0.195278] [G loss: 0.680797]\n",
      "[Epoch 100/100] [Batch 16/347] [D loss: 0.200026] [G loss: 0.738392]\n",
      "[Epoch 100/100] [Batch 17/347] [D loss: 0.200981] [G loss: 0.779535]\n",
      "[Epoch 100/100] [Batch 18/347] [D loss: 0.219760] [G loss: 0.800817]\n",
      "[Epoch 100/100] [Batch 19/347] [D loss: 0.225557] [G loss: 0.814376]\n",
      "[Epoch 100/100] [Batch 20/347] [D loss: 0.216446] [G loss: 0.869013]\n",
      "[Epoch 100/100] [Batch 21/347] [D loss: 0.199088] [G loss: 0.909716]\n",
      "[Epoch 100/100] [Batch 22/347] [D loss: 0.207099] [G loss: 0.943239]\n",
      "[Epoch 100/100] [Batch 23/347] [D loss: 0.217011] [G loss: 0.985932]\n",
      "[Epoch 100/100] [Batch 24/347] [D loss: 0.213265] [G loss: 1.004468]\n",
      "[Epoch 100/100] [Batch 25/347] [D loss: 0.087011] [G loss: 1.009431]\n",
      "[Epoch 100/100] [Batch 26/347] [D loss: 0.083730] [G loss: 1.003743]\n",
      "[Epoch 100/100] [Batch 27/347] [D loss: 0.077557] [G loss: 0.991750]\n",
      "[Epoch 100/100] [Batch 28/347] [D loss: 0.065559] [G loss: 0.981324]\n",
      "[Epoch 100/100] [Batch 29/347] [D loss: 0.054538] [G loss: 0.999952]\n",
      "[Epoch 100/100] [Batch 30/347] [D loss: 0.042597] [G loss: 1.016242]\n",
      "[Epoch 100/100] [Batch 31/347] [D loss: 0.041532] [G loss: 1.051658]\n",
      "[Epoch 100/100] [Batch 32/347] [D loss: 0.023206] [G loss: 1.086261]\n",
      "[Epoch 100/100] [Batch 33/347] [D loss: 0.039400] [G loss: 1.094391]\n",
      "[Epoch 100/100] [Batch 34/347] [D loss: 0.086846] [G loss: 1.102565]\n",
      "[Epoch 100/100] [Batch 35/347] [D loss: 0.091517] [G loss: 1.099422]\n",
      "[Epoch 100/100] [Batch 36/347] [D loss: 0.106756] [G loss: 1.086737]\n",
      "[Epoch 100/100] [Batch 37/347] [D loss: 0.112698] [G loss: 1.093287]\n",
      "[Epoch 100/100] [Batch 38/347] [D loss: 0.202913] [G loss: 1.064799]\n",
      "[Epoch 100/100] [Batch 39/347] [D loss: 0.197483] [G loss: 1.015537]\n",
      "[Epoch 100/100] [Batch 40/347] [D loss: 0.214583] [G loss: 0.983192]\n",
      "[Epoch 100/100] [Batch 41/347] [D loss: 0.186675] [G loss: 0.955690]\n",
      "[Epoch 100/100] [Batch 42/347] [D loss: 0.170441] [G loss: 0.929654]\n",
      "[Epoch 100/100] [Batch 43/347] [D loss: 0.209544] [G loss: 0.911923]\n",
      "[Epoch 100/100] [Batch 44/347] [D loss: 0.194713] [G loss: 0.892473]\n",
      "[Epoch 100/100] [Batch 45/347] [D loss: 0.151901] [G loss: 0.810690]\n",
      "[Epoch 100/100] [Batch 46/347] [D loss: 0.111247] [G loss: 0.697778]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 100/100] [Batch 47/347] [D loss: 0.131832] [G loss: 0.672102]\n",
      "[Epoch 100/100] [Batch 48/347] [D loss: 0.086146] [G loss: 0.738727]\n",
      "[Epoch 100/100] [Batch 49/347] [D loss: 0.080617] [G loss: 0.811088]\n",
      "[Epoch 100/100] [Batch 50/347] [D loss: 0.135045] [G loss: 0.769996]\n",
      "[Epoch 100/100] [Batch 51/347] [D loss: 0.130566] [G loss: 0.857646]\n",
      "[Epoch 100/100] [Batch 52/347] [D loss: 0.123156] [G loss: 0.940707]\n",
      "[Epoch 100/100] [Batch 53/347] [D loss: 0.103525] [G loss: 1.020144]\n",
      "[Epoch 100/100] [Batch 54/347] [D loss: 0.103987] [G loss: 1.068272]\n",
      "[Epoch 100/100] [Batch 55/347] [D loss: 0.121785] [G loss: 1.107869]\n",
      "[Epoch 100/100] [Batch 56/347] [D loss: 0.105736] [G loss: 1.195443]\n",
      "[Epoch 100/100] [Batch 57/347] [D loss: 0.104863] [G loss: 1.261858]\n",
      "[Epoch 100/100] [Batch 58/347] [D loss: 0.108827] [G loss: 1.291535]\n",
      "[Epoch 100/100] [Batch 59/347] [D loss: 0.096936] [G loss: 1.277080]\n",
      "[Epoch 100/100] [Batch 60/347] [D loss: 0.117350] [G loss: 1.232394]\n",
      "[Epoch 100/100] [Batch 61/347] [D loss: 0.160581] [G loss: 1.193006]\n",
      "[Epoch 100/100] [Batch 62/347] [D loss: 0.162671] [G loss: 1.178976]\n",
      "[Epoch 100/100] [Batch 63/347] [D loss: 0.106696] [G loss: 1.196568]\n",
      "[Epoch 100/100] [Batch 64/347] [D loss: 0.119107] [G loss: 1.232654]\n",
      "[Epoch 100/100] [Batch 65/347] [D loss: 0.123068] [G loss: 1.250504]\n",
      "[Epoch 100/100] [Batch 66/347] [D loss: 0.060128] [G loss: 1.206808]\n",
      "[Epoch 100/100] [Batch 67/347] [D loss: 0.061586] [G loss: 1.128881]\n",
      "[Epoch 100/100] [Batch 68/347] [D loss: 0.064308] [G loss: 1.040827]\n",
      "[Epoch 100/100] [Batch 69/347] [D loss: 0.014455] [G loss: 1.023052]\n",
      "[Epoch 100/100] [Batch 70/347] [D loss: 0.024515] [G loss: 0.973617]\n",
      "[Epoch 100/100] [Batch 71/347] [D loss: 0.043501] [G loss: 0.940723]\n",
      "[Epoch 100/100] [Batch 72/347] [D loss: 0.041517] [G loss: 1.003665]\n",
      "[Epoch 100/100] [Batch 73/347] [D loss: 0.077594] [G loss: 1.024809]\n",
      "[Epoch 100/100] [Batch 74/347] [D loss: 0.054851] [G loss: 1.070332]\n",
      "[Epoch 100/100] [Batch 75/347] [D loss: 0.058065] [G loss: 1.082978]\n",
      "[Epoch 100/100] [Batch 76/347] [D loss: 0.060170] [G loss: 1.077822]\n",
      "[Epoch 100/100] [Batch 77/347] [D loss: 0.106824] [G loss: 1.110213]\n",
      "[Epoch 100/100] [Batch 78/347] [D loss: 0.125193] [G loss: 1.123843]\n",
      "[Epoch 100/100] [Batch 79/347] [D loss: 0.098621] [G loss: 1.105356]\n",
      "[Epoch 100/100] [Batch 80/347] [D loss: 0.029647] [G loss: 1.063233]\n",
      "[Epoch 100/100] [Batch 81/347] [D loss: 0.032407] [G loss: 1.041977]\n",
      "[Epoch 100/100] [Batch 82/347] [D loss: 0.036746] [G loss: 1.073732]\n",
      "[Epoch 100/100] [Batch 83/347] [D loss: 0.054201] [G loss: 1.058167]\n",
      "[Epoch 100/100] [Batch 84/347] [D loss: 0.235290] [G loss: 1.040130]\n",
      "[Epoch 100/100] [Batch 85/347] [D loss: 0.330408] [G loss: 0.976514]\n",
      "[Epoch 100/100] [Batch 86/347] [D loss: 0.310052] [G loss: 0.860618]\n",
      "[Epoch 100/100] [Batch 87/347] [D loss: 0.278485] [G loss: 0.710035]\n",
      "[Epoch 100/100] [Batch 88/347] [D loss: 0.279219] [G loss: 0.568227]\n",
      "[Epoch 100/100] [Batch 89/347] [D loss: 0.299571] [G loss: 0.491117]\n",
      "[Epoch 100/100] [Batch 90/347] [D loss: 0.306853] [G loss: 0.405044]\n",
      "[Epoch 100/100] [Batch 91/347] [D loss: 0.319774] [G loss: 0.364026]\n",
      "[Epoch 100/100] [Batch 92/347] [D loss: 0.325409] [G loss: 0.335084]\n",
      "[Epoch 100/100] [Batch 93/347] [D loss: 0.329465] [G loss: 0.311967]\n",
      "[Epoch 100/100] [Batch 94/347] [D loss: 0.326216] [G loss: 0.295395]\n",
      "[Epoch 100/100] [Batch 95/347] [D loss: 0.308455] [G loss: 0.288028]\n",
      "[Epoch 100/100] [Batch 96/347] [D loss: 0.309406] [G loss: 0.287783]\n",
      "[Epoch 100/100] [Batch 97/347] [D loss: 0.299949] [G loss: 0.292121]\n",
      "[Epoch 100/100] [Batch 98/347] [D loss: 0.277028] [G loss: 0.303288]\n",
      "[Epoch 100/100] [Batch 99/347] [D loss: 0.271009] [G loss: 0.325169]\n",
      "[Epoch 100/100] [Batch 100/347] [D loss: 0.258526] [G loss: 0.355580]\n",
      "[Epoch 100/100] [Batch 101/347] [D loss: 0.251470] [G loss: 0.388932]\n",
      "[Epoch 100/100] [Batch 102/347] [D loss: 0.322094] [G loss: 0.444251]\n",
      "[Epoch 100/100] [Batch 103/347] [D loss: 0.313830] [G loss: 0.546144]\n",
      "[Epoch 100/100] [Batch 104/347] [D loss: 0.280874] [G loss: 0.670346]\n",
      "[Epoch 100/100] [Batch 105/347] [D loss: 0.211718] [G loss: 0.763389]\n",
      "[Epoch 100/100] [Batch 106/347] [D loss: 0.107301] [G loss: 0.894671]\n",
      "[Epoch 100/100] [Batch 107/347] [D loss: 0.063967] [G loss: 0.962654]\n",
      "[Epoch 100/100] [Batch 108/347] [D loss: 0.050764] [G loss: 1.011372]\n",
      "[Epoch 100/100] [Batch 109/347] [D loss: 0.042383] [G loss: 1.042455]\n",
      "[Epoch 100/100] [Batch 110/347] [D loss: 0.126942] [G loss: 1.004301]\n",
      "[Epoch 100/100] [Batch 111/347] [D loss: 0.105993] [G loss: 1.045791]\n",
      "[Epoch 100/100] [Batch 112/347] [D loss: 0.072859] [G loss: 1.063254]\n",
      "[Epoch 100/100] [Batch 113/347] [D loss: 0.035566] [G loss: 1.090295]\n",
      "[Epoch 100/100] [Batch 114/347] [D loss: 0.050410] [G loss: 1.091545]\n",
      "[Epoch 100/100] [Batch 115/347] [D loss: 0.074880] [G loss: 1.068677]\n",
      "[Epoch 100/100] [Batch 116/347] [D loss: 0.099332] [G loss: 1.082873]\n",
      "[Epoch 100/100] [Batch 117/347] [D loss: 0.356178] [G loss: 1.095221]\n",
      "[Epoch 100/100] [Batch 118/347] [D loss: 0.226426] [G loss: 1.113551]\n",
      "[Epoch 100/100] [Batch 119/347] [D loss: 0.175784] [G loss: 1.099441]\n",
      "[Epoch 100/100] [Batch 120/347] [D loss: 0.090346] [G loss: 1.084685]\n",
      "[Epoch 100/100] [Batch 121/347] [D loss: 0.048213] [G loss: 1.065624]\n",
      "[Epoch 100/100] [Batch 122/347] [D loss: 0.148843] [G loss: 1.059103]\n",
      "[Epoch 100/100] [Batch 123/347] [D loss: 0.195706] [G loss: 1.065986]\n",
      "[Epoch 100/100] [Batch 124/347] [D loss: 0.139908] [G loss: 1.051402]\n",
      "[Epoch 100/100] [Batch 125/347] [D loss: 0.116740] [G loss: 1.039430]\n",
      "[Epoch 100/100] [Batch 126/347] [D loss: 0.121495] [G loss: 0.999393]\n",
      "[Epoch 100/100] [Batch 127/347] [D loss: 0.116917] [G loss: 0.928006]\n",
      "[Epoch 100/100] [Batch 128/347] [D loss: 0.057317] [G loss: 0.817484]\n",
      "[Epoch 100/100] [Batch 129/347] [D loss: 0.075203] [G loss: 0.719037]\n",
      "[Epoch 100/100] [Batch 130/347] [D loss: 0.102852] [G loss: 0.721540]\n",
      "[Epoch 100/100] [Batch 131/347] [D loss: 0.128880] [G loss: 0.727823]\n",
      "[Epoch 100/100] [Batch 132/347] [D loss: 0.155567] [G loss: 0.741161]\n",
      "[Epoch 100/100] [Batch 133/347] [D loss: 0.273348] [G loss: 0.745618]\n",
      "[Epoch 100/100] [Batch 134/347] [D loss: 0.590993] [G loss: 0.681460]\n",
      "[Epoch 100/100] [Batch 135/347] [D loss: 0.543213] [G loss: 0.776521]\n",
      "[Epoch 100/100] [Batch 136/347] [D loss: 0.422573] [G loss: 1.005533]\n",
      "[Epoch 100/100] [Batch 137/347] [D loss: 0.103436] [G loss: 1.073292]\n",
      "[Epoch 100/100] [Batch 138/347] [D loss: 0.025143] [G loss: 1.085755]\n",
      "[Epoch 100/100] [Batch 139/347] [D loss: 0.019259] [G loss: 1.088383]\n",
      "[Epoch 100/100] [Batch 140/347] [D loss: 0.056520] [G loss: 1.085754]\n",
      "[Epoch 100/100] [Batch 141/347] [D loss: 0.268282] [G loss: 1.075453]\n",
      "[Epoch 100/100] [Batch 142/347] [D loss: 0.365506] [G loss: 1.101054]\n",
      "[Epoch 100/100] [Batch 143/347] [D loss: 0.432792] [G loss: 1.115504]\n",
      "[Epoch 100/100] [Batch 144/347] [D loss: 0.399203] [G loss: 1.130237]\n",
      "[Epoch 100/100] [Batch 145/347] [D loss: 0.305799] [G loss: 1.168453]\n",
      "[Epoch 100/100] [Batch 146/347] [D loss: 0.265361] [G loss: 1.183181]\n",
      "[Epoch 100/100] [Batch 147/347] [D loss: 0.214117] [G loss: 1.192922]\n",
      "[Epoch 100/100] [Batch 148/347] [D loss: 0.245616] [G loss: 1.189236]\n",
      "[Epoch 100/100] [Batch 149/347] [D loss: 0.235949] [G loss: 1.153764]\n",
      "[Epoch 100/100] [Batch 150/347] [D loss: 0.225620] [G loss: 1.110821]\n",
      "[Epoch 100/100] [Batch 151/347] [D loss: 0.186766] [G loss: 1.074210]\n",
      "[Epoch 100/100] [Batch 152/347] [D loss: 0.154370] [G loss: 1.012836]\n",
      "[Epoch 100/100] [Batch 153/347] [D loss: 0.105189] [G loss: 0.892635]\n",
      "[Epoch 100/100] [Batch 154/347] [D loss: 0.072006] [G loss: 0.717634]\n",
      "Improvement-Detected, model saved\n",
      "[Epoch 100/100] [Batch 155/347] [D loss: 0.082729] [G loss: 0.527555]\n",
      "[Epoch 100/100] [Batch 156/347] [D loss: 0.132578] [G loss: 0.457579]\n",
      "[Epoch 100/100] [Batch 157/347] [D loss: 0.146480] [G loss: 0.471459]\n",
      "[Epoch 100/100] [Batch 158/347] [D loss: 0.151197] [G loss: 0.513933]\n",
      "[Epoch 100/100] [Batch 159/347] [D loss: 0.140981] [G loss: 0.615241]\n",
      "[Epoch 100/100] [Batch 160/347] [D loss: 0.117214] [G loss: 0.734481]\n",
      "[Epoch 100/100] [Batch 161/347] [D loss: 0.079756] [G loss: 0.871455]\n",
      "[Epoch 100/100] [Batch 162/347] [D loss: 0.046106] [G loss: 0.935467]\n",
      "[Epoch 100/100] [Batch 163/347] [D loss: 0.018006] [G loss: 0.998030]\n",
      "[Epoch 100/100] [Batch 164/347] [D loss: 0.013069] [G loss: 1.014518]\n",
      "[Epoch 100/100] [Batch 165/347] [D loss: 0.010846] [G loss: 1.039216]\n",
      "[Epoch 100/100] [Batch 166/347] [D loss: 0.027761] [G loss: 1.086714]\n",
      "[Epoch 100/100] [Batch 167/347] [D loss: 0.091429] [G loss: 1.118673]\n",
      "[Epoch 100/100] [Batch 168/347] [D loss: 0.149764] [G loss: 1.118705]\n",
      "[Epoch 100/100] [Batch 169/347] [D loss: 0.250754] [G loss: 1.105343]\n",
      "[Epoch 100/100] [Batch 170/347] [D loss: 0.316185] [G loss: 1.071482]\n",
      "[Epoch 100/100] [Batch 171/347] [D loss: 0.179017] [G loss: 1.054325]\n",
      "[Epoch 100/100] [Batch 172/347] [D loss: 0.181335] [G loss: 1.063211]\n",
      "[Epoch 100/100] [Batch 173/347] [D loss: 0.222737] [G loss: 1.066007]\n",
      "[Epoch 100/100] [Batch 174/347] [D loss: 0.255467] [G loss: 1.063512]\n",
      "[Epoch 100/100] [Batch 175/347] [D loss: 0.335044] [G loss: 1.033503]\n",
      "[Epoch 100/100] [Batch 176/347] [D loss: 0.267579] [G loss: 0.974213]\n",
      "[Epoch 100/100] [Batch 177/347] [D loss: 0.209443] [G loss: 0.855014]\n",
      "[Epoch 100/100] [Batch 178/347] [D loss: 0.174389] [G loss: 0.665090]\n",
      "[Epoch 100/100] [Batch 179/347] [D loss: 0.190969] [G loss: 0.480995]\n",
      "[Epoch 100/100] [Batch 180/347] [D loss: 0.223643] [G loss: 0.404573]\n",
      "[Epoch 100/100] [Batch 181/347] [D loss: 0.247360] [G loss: 0.340064]\n",
      "[Epoch 100/100] [Batch 182/347] [D loss: 0.268564] [G loss: 0.289557]\n",
      "[Epoch 100/100] [Batch 183/347] [D loss: 0.288305] [G loss: 0.264276]\n",
      "[Epoch 100/100] [Batch 184/347] [D loss: 0.332657] [G loss: 0.260835]\n",
      "[Epoch 100/100] [Batch 185/347] [D loss: 0.357334] [G loss: 0.260389]\n",
      "[Epoch 100/100] [Batch 186/347] [D loss: 0.359225] [G loss: 0.266894]\n",
      "[Epoch 100/100] [Batch 187/347] [D loss: 0.344269] [G loss: 0.276779]\n",
      "[Epoch 100/100] [Batch 188/347] [D loss: 0.325322] [G loss: 0.292965]\n",
      "[Epoch 100/100] [Batch 189/347] [D loss: 0.291142] [G loss: 0.314240]\n",
      "[Epoch 100/100] [Batch 190/347] [D loss: 0.270046] [G loss: 0.346438]\n",
      "[Epoch 100/100] [Batch 191/347] [D loss: 0.259414] [G loss: 0.382296]\n",
      "[Epoch 100/100] [Batch 192/347] [D loss: 0.251810] [G loss: 0.433610]\n",
      "[Epoch 100/100] [Batch 193/347] [D loss: 0.261093] [G loss: 0.493818]\n",
      "[Epoch 100/100] [Batch 194/347] [D loss: 0.231915] [G loss: 0.602028]\n",
      "[Epoch 100/100] [Batch 195/347] [D loss: 0.197797] [G loss: 0.760518]\n",
      "[Epoch 100/100] [Batch 196/347] [D loss: 0.149933] [G loss: 0.856401]\n",
      "[Epoch 100/100] [Batch 197/347] [D loss: 0.150871] [G loss: 0.930184]\n",
      "[Epoch 100/100] [Batch 198/347] [D loss: 0.150278] [G loss: 0.968469]\n",
      "[Epoch 100/100] [Batch 199/347] [D loss: 0.163667] [G loss: 1.005556]\n",
      "[Epoch 100/100] [Batch 200/347] [D loss: 0.219495] [G loss: 1.020617]\n",
      "[Epoch 100/100] [Batch 201/347] [D loss: 0.263481] [G loss: 1.025468]\n",
      "[Epoch 100/100] [Batch 202/347] [D loss: 0.302260] [G loss: 1.015297]\n",
      "[Epoch 100/100] [Batch 203/347] [D loss: 0.285890] [G loss: 0.998699]\n",
      "[Epoch 100/100] [Batch 204/347] [D loss: 0.254288] [G loss: 0.958844]\n",
      "[Epoch 100/100] [Batch 205/347] [D loss: 0.224540] [G loss: 0.903771]\n",
      "[Epoch 100/100] [Batch 206/347] [D loss: 0.206381] [G loss: 0.821176]\n",
      "[Epoch 100/100] [Batch 207/347] [D loss: 0.145374] [G loss: 0.736561]\n",
      "[Epoch 100/100] [Batch 208/347] [D loss: 0.157796] [G loss: 0.655947]\n",
      "[Epoch 100/100] [Batch 209/347] [D loss: 0.194742] [G loss: 0.608628]\n",
      "[Epoch 100/100] [Batch 210/347] [D loss: 0.186263] [G loss: 0.664587]\n",
      "[Epoch 100/100] [Batch 211/347] [D loss: 0.163522] [G loss: 0.717613]\n",
      "[Epoch 100/100] [Batch 212/347] [D loss: 0.148517] [G loss: 0.789532]\n",
      "[Epoch 100/100] [Batch 213/347] [D loss: 0.112906] [G loss: 0.908064]\n",
      "[Epoch 100/100] [Batch 214/347] [D loss: 0.113491] [G loss: 0.994358]\n",
      "[Epoch 100/100] [Batch 215/347] [D loss: 0.089480] [G loss: 1.043139]\n",
      "[Epoch 100/100] [Batch 216/347] [D loss: 0.103507] [G loss: 1.021692]\n",
      "[Epoch 100/100] [Batch 217/347] [D loss: 0.058329] [G loss: 1.116512]\n",
      "[Epoch 100/100] [Batch 218/347] [D loss: 0.040673] [G loss: 1.159298]\n",
      "[Epoch 100/100] [Batch 219/347] [D loss: 0.040909] [G loss: 1.187147]\n",
      "[Epoch 100/100] [Batch 220/347] [D loss: 0.143316] [G loss: 1.193170]\n",
      "[Epoch 100/100] [Batch 221/347] [D loss: 0.241091] [G loss: 1.174130]\n",
      "[Epoch 100/100] [Batch 222/347] [D loss: 0.348942] [G loss: 1.142854]\n",
      "[Epoch 100/100] [Batch 223/347] [D loss: 0.448875] [G loss: 1.104216]\n",
      "[Epoch 100/100] [Batch 224/347] [D loss: 0.495322] [G loss: 1.069648]\n",
      "[Epoch 100/100] [Batch 225/347] [D loss: 0.548949] [G loss: 1.004294]\n",
      "[Epoch 100/100] [Batch 226/347] [D loss: 0.318942] [G loss: 0.795013]\n",
      "[Epoch 100/100] [Batch 227/347] [D loss: 0.240358] [G loss: 0.380773]\n",
      "[Epoch 100/100] [Batch 228/347] [D loss: 0.305235] [G loss: 0.265334]\n",
      "[Epoch 100/100] [Batch 229/347] [D loss: 0.333174] [G loss: 0.244802]\n",
      "[Epoch 100/100] [Batch 230/347] [D loss: 0.385005] [G loss: 0.234533]\n",
      "[Epoch 100/100] [Batch 231/347] [D loss: 0.431025] [G loss: 0.212404]\n",
      "[Epoch 100/100] [Batch 232/347] [D loss: 0.464292] [G loss: 0.196647]\n",
      "[Epoch 100/100] [Batch 233/347] [D loss: 0.530183] [G loss: 0.196135]\n",
      "[Epoch 100/100] [Batch 234/347] [D loss: 0.549867] [G loss: 0.201790]\n",
      "[Epoch 100/100] [Batch 235/347] [D loss: 0.534530] [G loss: 0.233154]\n",
      "[Epoch 100/100] [Batch 236/347] [D loss: 0.488699] [G loss: 0.274708]\n",
      "[Epoch 100/100] [Batch 237/347] [D loss: 0.396991] [G loss: 0.310740]\n",
      "[Epoch 100/100] [Batch 238/347] [D loss: 0.320299] [G loss: 0.351490]\n",
      "[Epoch 100/100] [Batch 239/347] [D loss: 0.278582] [G loss: 0.398537]\n",
      "[Epoch 100/100] [Batch 240/347] [D loss: 0.254714] [G loss: 0.554141]\n",
      "[Epoch 100/100] [Batch 241/347] [D loss: 0.222938] [G loss: 0.774713]\n",
      "[Epoch 100/100] [Batch 242/347] [D loss: 0.228766] [G loss: 0.927179]\n",
      "[Epoch 100/100] [Batch 243/347] [D loss: 0.169800] [G loss: 0.964242]\n",
      "[Epoch 100/100] [Batch 244/347] [D loss: 0.151392] [G loss: 0.978226]\n",
      "[Epoch 100/100] [Batch 245/347] [D loss: 0.166085] [G loss: 0.988755]\n",
      "[Epoch 100/100] [Batch 246/347] [D loss: 0.191969] [G loss: 1.005982]\n",
      "[Epoch 100/100] [Batch 247/347] [D loss: 0.244075] [G loss: 1.034793]\n",
      "[Epoch 100/100] [Batch 248/347] [D loss: 0.219942] [G loss: 1.005401]\n",
      "[Epoch 100/100] [Batch 249/347] [D loss: 0.167696] [G loss: 0.960910]\n",
      "[Epoch 100/100] [Batch 250/347] [D loss: 0.116742] [G loss: 0.905481]\n",
      "[Epoch 100/100] [Batch 251/347] [D loss: 0.138268] [G loss: 0.902978]\n",
      "[Epoch 100/100] [Batch 252/347] [D loss: 0.132621] [G loss: 0.866606]\n",
      "[Epoch 100/100] [Batch 253/347] [D loss: 0.065593] [G loss: 0.802665]\n",
      "[Epoch 100/100] [Batch 254/347] [D loss: 0.063958] [G loss: 0.809725]\n",
      "[Epoch 100/100] [Batch 255/347] [D loss: 0.058262] [G loss: 0.838975]\n",
      "[Epoch 100/100] [Batch 256/347] [D loss: 0.057312] [G loss: 0.852940]\n",
      "[Epoch 100/100] [Batch 257/347] [D loss: 0.068594] [G loss: 0.795616]\n",
      "[Epoch 100/100] [Batch 258/347] [D loss: 0.058047] [G loss: 0.806922]\n",
      "[Epoch 100/100] [Batch 259/347] [D loss: 0.054885] [G loss: 0.851448]\n",
      "[Epoch 100/100] [Batch 260/347] [D loss: 0.041260] [G loss: 0.894224]\n",
      "[Epoch 100/100] [Batch 261/347] [D loss: 0.028965] [G loss: 0.957212]\n",
      "[Epoch 100/100] [Batch 262/347] [D loss: 0.017738] [G loss: 1.010967]\n",
      "[Epoch 100/100] [Batch 263/347] [D loss: 0.015242] [G loss: 1.044176]\n",
      "[Epoch 100/100] [Batch 264/347] [D loss: 0.011408] [G loss: 1.059080]\n",
      "[Epoch 100/100] [Batch 265/347] [D loss: 0.017201] [G loss: 1.061236]\n",
      "[Epoch 100/100] [Batch 266/347] [D loss: 0.059090] [G loss: 1.057630]\n",
      "[Epoch 100/100] [Batch 267/347] [D loss: 0.067321] [G loss: 1.062667]\n",
      "[Epoch 100/100] [Batch 268/347] [D loss: 0.089950] [G loss: 1.062181]\n",
      "[Epoch 100/100] [Batch 269/347] [D loss: 0.086343] [G loss: 1.062228]\n",
      "[Epoch 100/100] [Batch 270/347] [D loss: 0.088754] [G loss: 1.055537]\n",
      "[Epoch 100/100] [Batch 271/347] [D loss: 0.156940] [G loss: 1.057344]\n",
      "[Epoch 100/100] [Batch 272/347] [D loss: 0.553446] [G loss: 1.053102]\n",
      "[Epoch 100/100] [Batch 273/347] [D loss: 0.529365] [G loss: 1.058606]\n",
      "[Epoch 100/100] [Batch 274/347] [D loss: 0.491672] [G loss: 1.054502]\n",
      "[Epoch 100/100] [Batch 275/347] [D loss: 0.455341] [G loss: 1.049465]\n",
      "[Epoch 100/100] [Batch 276/347] [D loss: 0.059019] [G loss: 1.011506]\n",
      "[Epoch 100/100] [Batch 277/347] [D loss: 0.022971] [G loss: 1.051098]\n",
      "[Epoch 100/100] [Batch 278/347] [D loss: 0.012579] [G loss: 1.062300]\n",
      "[Epoch 100/100] [Batch 279/347] [D loss: 0.009523] [G loss: 1.053787]\n",
      "[Epoch 100/100] [Batch 280/347] [D loss: 0.283161] [G loss: 1.030192]\n",
      "[Epoch 100/100] [Batch 281/347] [D loss: 0.527371] [G loss: 1.041154]\n",
      "[Epoch 100/100] [Batch 282/347] [D loss: 0.568298] [G loss: 1.044593]\n",
      "[Epoch 100/100] [Batch 283/347] [D loss: 0.427100] [G loss: 1.047532]\n",
      "[Epoch 100/100] [Batch 284/347] [D loss: 0.311612] [G loss: 1.046439]\n",
      "[Epoch 100/100] [Batch 285/347] [D loss: 0.221530] [G loss: 1.038445]\n",
      "[Epoch 100/100] [Batch 286/347] [D loss: 0.158815] [G loss: 1.028999]\n",
      "[Epoch 100/100] [Batch 287/347] [D loss: 0.123228] [G loss: 0.994256]\n",
      "[Epoch 100/100] [Batch 288/347] [D loss: 0.088745] [G loss: 0.917499]\n",
      "[Epoch 100/100] [Batch 289/347] [D loss: 0.090400] [G loss: 0.776118]\n",
      "[Epoch 100/100] [Batch 290/347] [D loss: 0.152284] [G loss: 0.403552]\n",
      "[Epoch 100/100] [Batch 291/347] [D loss: 0.177395] [G loss: 0.378776]\n",
      "[Epoch 100/100] [Batch 292/347] [D loss: 0.194554] [G loss: 0.364745]\n",
      "[Epoch 100/100] [Batch 293/347] [D loss: 0.238062] [G loss: 0.377462]\n",
      "[Epoch 100/100] [Batch 294/347] [D loss: 0.221607] [G loss: 0.401411]\n",
      "[Epoch 100/100] [Batch 295/347] [D loss: 0.203241] [G loss: 0.414262]\n",
      "[Epoch 100/100] [Batch 296/347] [D loss: 0.192683] [G loss: 0.437360]\n",
      "[Epoch 100/100] [Batch 297/347] [D loss: 0.152722] [G loss: 0.567315]\n",
      "[Epoch 100/100] [Batch 298/347] [D loss: 0.103580] [G loss: 0.741982]\n",
      "[Epoch 100/100] [Batch 299/347] [D loss: 0.059144] [G loss: 0.851610]\n",
      "[Epoch 100/100] [Batch 300/347] [D loss: 0.032860] [G loss: 0.921120]\n",
      "[Epoch 100/100] [Batch 301/347] [D loss: 0.078934] [G loss: 0.956622]\n",
      "[Epoch 100/100] [Batch 302/347] [D loss: 0.126813] [G loss: 0.980300]\n",
      "[Epoch 100/100] [Batch 303/347] [D loss: 0.161778] [G loss: 1.005266]\n",
      "[Epoch 100/100] [Batch 304/347] [D loss: 0.132008] [G loss: 1.021259]\n",
      "[Epoch 100/100] [Batch 305/347] [D loss: 0.062616] [G loss: 1.009522]\n",
      "[Epoch 100/100] [Batch 306/347] [D loss: 0.058881] [G loss: 1.008788]\n",
      "[Epoch 100/100] [Batch 307/347] [D loss: 0.043611] [G loss: 1.038691]\n",
      "[Epoch 100/100] [Batch 308/347] [D loss: 0.035623] [G loss: 1.065396]\n",
      "[Epoch 100/100] [Batch 309/347] [D loss: 0.079965] [G loss: 1.087552]\n",
      "[Epoch 100/100] [Batch 310/347] [D loss: 0.143842] [G loss: 1.096002]\n",
      "[Epoch 100/100] [Batch 311/347] [D loss: 0.107845] [G loss: 1.065780]\n",
      "[Epoch 100/100] [Batch 312/347] [D loss: 0.076782] [G loss: 1.033085]\n",
      "[Epoch 100/100] [Batch 313/347] [D loss: 0.164724] [G loss: 0.993012]\n",
      "[Epoch 100/100] [Batch 314/347] [D loss: 0.191843] [G loss: 0.972917]\n",
      "[Epoch 100/100] [Batch 315/347] [D loss: 0.206732] [G loss: 0.955051]\n",
      "[Epoch 100/100] [Batch 316/347] [D loss: 0.167799] [G loss: 0.889522]\n",
      "[Epoch 100/100] [Batch 317/347] [D loss: 0.141011] [G loss: 0.802155]\n",
      "[Epoch 100/100] [Batch 318/347] [D loss: 0.113217] [G loss: 0.693615]\n",
      "[Epoch 100/100] [Batch 319/347] [D loss: 0.122896] [G loss: 0.612640]\n",
      "[Epoch 100/100] [Batch 320/347] [D loss: 0.145549] [G loss: 0.577860]\n",
      "[Epoch 100/100] [Batch 321/347] [D loss: 0.143807] [G loss: 0.570196]\n",
      "[Epoch 100/100] [Batch 322/347] [D loss: 0.162800] [G loss: 0.597579]\n",
      "[Epoch 100/100] [Batch 323/347] [D loss: 0.088335] [G loss: 0.754898]\n",
      "[Epoch 100/100] [Batch 324/347] [D loss: 0.065289] [G loss: 0.854829]\n",
      "[Epoch 100/100] [Batch 325/347] [D loss: 0.057460] [G loss: 0.884769]\n",
      "[Epoch 100/100] [Batch 326/347] [D loss: 0.057191] [G loss: 0.903083]\n",
      "[Epoch 100/100] [Batch 327/347] [D loss: 0.054814] [G loss: 0.917158]\n",
      "[Epoch 100/100] [Batch 328/347] [D loss: 0.057189] [G loss: 0.920949]\n",
      "[Epoch 100/100] [Batch 329/347] [D loss: 0.054355] [G loss: 0.939800]\n",
      "[Epoch 100/100] [Batch 330/347] [D loss: 0.041814] [G loss: 0.961312]\n",
      "[Epoch 100/100] [Batch 331/347] [D loss: 0.079218] [G loss: 0.982356]\n",
      "[Epoch 100/100] [Batch 332/347] [D loss: 0.151071] [G loss: 1.003854]\n",
      "[Epoch 100/100] [Batch 333/347] [D loss: 0.094485] [G loss: 1.020159]\n",
      "[Epoch 100/100] [Batch 334/347] [D loss: 0.072534] [G loss: 1.009076]\n",
      "[Epoch 100/100] [Batch 335/347] [D loss: 0.094839] [G loss: 0.995126]\n",
      "[Epoch 100/100] [Batch 336/347] [D loss: 0.151141] [G loss: 1.001865]\n",
      "[Epoch 100/100] [Batch 337/347] [D loss: 0.198861] [G loss: 0.998009]\n",
      "[Epoch 100/100] [Batch 338/347] [D loss: 0.253917] [G loss: 0.989468]\n",
      "[Epoch 100/100] [Batch 339/347] [D loss: 0.195208] [G loss: 0.954937]\n",
      "[Epoch 100/100] [Batch 340/347] [D loss: 0.158208] [G loss: 0.911172]\n",
      "[Epoch 100/100] [Batch 341/347] [D loss: 0.177685] [G loss: 0.833110]\n",
      "[Epoch 100/100] [Batch 342/347] [D loss: 0.070077] [G loss: 0.777230]\n",
      "[Epoch 100/100] [Batch 343/347] [D loss: 0.044987] [G loss: 0.765761]\n",
      "[Epoch 100/100] [Batch 344/347] [D loss: 0.063363] [G loss: 0.748811]\n",
      "[Epoch 100/100] [Batch 345/347] [D loss: 0.076531] [G loss: 0.776603]\n",
      "[Epoch 100/100] [Batch 346/347] [D loss: 0.107770] [G loss: 0.727941]\n",
      "[Epoch 100/100] [Batch 347/347] [D loss: 0.137157] [G loss: 0.752853]\n",
      "CPU times: user 1h 12min 20s, sys: 3min 17s, total: 1h 15min 38s\n",
      "Wall time: 1h 15min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedding_dim=10\n",
    "batch_size=trainX.size(0)\n",
    "value_features=1\n",
    "key_features=1\n",
    "\n",
    "#extract the number of features\n",
    "num_features=trainX.size(2)+10\n",
    "\n",
    "#Hyperparameters\n",
    "discriminator_lr=0.00005\n",
    "generator_lr=0.00005\n",
    "num_epochs=100\n",
    "batch_size=121\n",
    "criterion = nn.MSELoss()\n",
    "save = True\n",
    "gpu = True\n",
    "\n",
    "\n",
    "device=utils.assign_device(gpu)\n",
    "\n",
    "#Initializations\n",
    "train = TensorDataset(trainX, sequences)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "\n",
    "D=progressive_blocks.Discriminator(embedding_dim,seq_length,num_features,batch_size,value_features,key_features,device)\n",
    "G=progressive_blocks.Generator(embedding_dim,seq_length,num_features,batch_size,value_features,key_features,device)\n",
    "optimD = Adam(D.parameters(), lr=discriminator_lr, betas=(0.9, 0.999))\n",
    "optimG = Adam(G.parameters(), lr=generator_lr, betas=(0.9, 0.999))\n",
    "\n",
    "blocks_to_add=1\n",
    "activeG=(G.step-1)-blocks_to_add\n",
    "activeD=blocks_to_add\n",
    "timestamp=50\n",
    "\n",
    "#Training\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "        g_loss_min=1000000\n",
    "        d_loss_min=1000000\n",
    "        g_losses_temp=[]\n",
    "        d_losses_temp=[]\n",
    "\n",
    "        if (epoch%timestamp==0 and epoch!=0):\n",
    "                activeG+=1\n",
    "                activeD-=1\n",
    "\n",
    "        for i, (X, Y) in enumerate((train_loader)):\n",
    "            #print(\"i:\",i)\n",
    "            #print(\"X in (train_loader):\",X.shape)\n",
    "            #print(\"Y:\",Y.shape)\n",
    "            \n",
    "            X=X.to(device)\n",
    "            Y=Y.to(device)\n",
    "            # Generate fake data\n",
    "            \n",
    "            fake_data = G(X,(epoch/num_epochs),activeG)\n",
    "            fake_label = torch.zeros(Y.size(0))\n",
    "            \n",
    "           \n",
    "            # Train the discriminator\n",
    "            Y=Y[:,:,:fake_data.size(2)]  #we use this to adapt real sequences length to fake sequences length\n",
    "           \n",
    "            D.zero_grad()\n",
    "            d_real_loss = criterion(D(Y,X,(epoch/num_epochs),activeD), torch.ones_like(D(Y,X,(epoch/num_epochs),activeD)))\n",
    "            d_fake_loss = criterion(D(fake_data.detach(),X,(epoch/num_epochs),activeD), torch.zeros_like(D(fake_data.detach(),X,(epoch/num_epochs),activeD)))\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_losses_temp.append(d_loss.item())\n",
    "            d_loss.backward(retain_graph=False)\n",
    "            optimD.step()\n",
    "            \n",
    "            # Train the generator\n",
    "            G.zero_grad()\n",
    "            g_loss = criterion(D(fake_data,X,(epoch/num_epochs),activeD), torch.ones_like(D(fake_data,X,(epoch/num_epochs),activeD)))\n",
    "\n",
    "            # Add the moment loss\n",
    "            g_loss += moment_loss(fake_data, Y)\n",
    "            #g_loss = moment_loss(fake_data, Y)\n",
    "            g_losses_temp.append(g_loss.item())\n",
    "\n",
    "            if(g_loss<g_loss_min and d_loss<d_loss_min and save):\n",
    "                g_loss_min = g_loss\n",
    "                d_loss_min = d_loss\n",
    "                torch.save(G.state_dict(), path+'/generator.pt')\n",
    "                torch.save(G, path+'/generator_model.pt')\n",
    "                torch.save(D.state_dict(), path+'/discriminator.pt')\n",
    "                torch.save(D, path+'/discriminator_model.pt')\n",
    "                print('Improvement-Detected, model saved')\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimG.step()\n",
    "            \n",
    "            # Print the losses\n",
    "            if (i+1) % 1 == 0:\n",
    "                print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % \n",
    "                    (epoch+1, num_epochs, i+1, len(train_loader), d_loss.item(), g_loss.item()))\n",
    "        g_losses.append(torch.mean(torch.Tensor(g_losses_temp)))\n",
    "        d_losses.append(torch.mean(torch.Tensor(d_losses_temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End-training Generator Loss: tensor(0.8631)\n",
      "End-training Discriminator Loss: tensor(0.1779)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "utils.plot_training_history('PSA-GAN - M4',d_losses, g_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load=True\n",
    "\n",
    "if(load):\n",
    "    G = torch.load(path+'/generator_model.pt')\n",
    "    D = torch.load(path+'/discriminator_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_series:  torch.Size([121, 512, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.1405], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "t = training_set[:41987]\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    \n",
    "    generated_series = G(trainX[len(trainX)-batch_size:],1,(G.step-1)) #substitue trainX with testX\n",
    "    generated_series=generated_series.permute(0,2,1)\n",
    "    print(\"generated_series: \",generated_series.shape)\n",
    "    generated_series = generated_series.to(\"cpu\").detach().numpy()\n",
    "\n",
    "sc = MinMaxScaler((t[len(t)-seq_length-1:].min(axis=0),t[len(t)-seq_length-1:].max(axis=0)))\n",
    "generated_series[batch_size-1] = sc.fit_transform(generated_series[batch_size-1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 3), dpi=300)\n",
    "#plt.plot(range(len(t)-seq_length-1,len(t)-1), generated_series[batch_size-1], label='Generated series', color=\"red\")\n",
    "#plt.plot(t[:], label='Actual series', color='grey')\n",
    "\n",
    "plt.plot(generated_series[batch_size-1], label='Generated series', color=\"red\")\n",
    "plt.plot(t[len(t)-seq_length-1:], label='Actual series', )\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(G.main.attn.gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
